# Drivers
Scripts to handle running, testing, and benchmarking code generated by LLMs.
The drivers are split up by language.

## Running the prompts
Given a prompt and output data set in `generated-outputs.json` you can run each
of the generated outputs using the below command.

```bash
python run-all.py generated-outputs.json

# usage: run-all.py [-h] [-o OUTPUT] [--scratch-dir SCRATCH_DIR] [--launch-configs LAUNCH_CONFIGS] [--yes-to-all] [--dry] [--overwrite]
#                   [--exclude-models {serial,omp,mpi} [{serial,omp,mpi} ...] | --include-models {serial,omp,mpi} [{serial,omp,mpi} ...]]
#                   [--log {INFO,DEBUG,WARNING,ERROR,CRITICAL}]
#                   input_json
# 
# Run all the generated code.
# 
# positional arguments:
#   input_json            Input JSON file containing the test cases.
# 
# optional arguments:
#   -h, --help            show this help message and exit
#   -o OUTPUT, --output OUTPUT
#                         Output JSON file containing the results.
#   --scratch-dir SCRATCH_DIR
#                         If provided, put scratch files here.
#   --launch-configs LAUNCH_CONFIGS
#                         config for how to run samples.
#   --yes-to-all          If provided, automatically answer yes to all prompts.
#   --dry                 Dry run. Do not actually run the code snippets.
#   --overwrite           If ouputs are already in DB for a given prompt, then overwrite them. Default behavior is to skip existing results.
#   --exclude-models {serial,omp,mpi} [{serial,omp,mpi} ...]
#                         Exclude the given parallelism models from testing.
#   --include-models {serial,omp,mpi} [{serial,omp,mpi} ...]
#                         Only test the given parallelism models.
#   --log {INFO,DEBUG,WARNING,ERROR,CRITICAL}
#                         logging level
```

Depending on the parallel models being tested this will require a newer C++
compiler and MPI being loaded. 

### Running on Zaratan
To run the drivers on Zaratan you needc the following modules (or similar).

```bash
ml gcc/11.3.0 openmpi/gcc/11.3.0 python
```

Additionally, the default `/tmp` scratch space for building and running is 
node-local on Zaratan, so you need to pass `--scratch-dir` as some root 
directory on the _scratch_ or _home_ filesystem, since these are accessible
from all compute nodes and on the network.

## Organization of Drivers
Within `drivers/` there are subdirectories for each programming language.
In this subdirectory is a `*_driver_wrapper.py` file that handles running
code for that language.
This wrapper further uses functionality from drivers in `models/` and 
`benchmarks/` in the language subdirectory.
These define behavior for running each programming model and benchmark.

### Notes on Drivers
The benchmark drivers (in `benchmarks/`) follow the nameing convention 
`<test-name>-<model>-driver.<ext>`. Likewise, the model drivers in `models/`
follow the naming convention `<model>-driver.<ext>`. The test name is the name 
used in the prompts data set. The model is one of the parallel backend models 
available. These are used as keys in the code so this naming convention and 
spelling needs to be followed.

Make sure to run `make` in the corresponding subdirectories for models that need
to be compiled. For example in `cpp/` run `make` to build the driver binaries.

The way we currently launch executables in Python does not run them in a shell,
but rather launches them directly. Because of this running
`OMP_NUM_THREADS=4 ./a.out` does not work. So all OMP scripts take the number
of threads as the first command line argument i.e. `./a.out 4`.

Make sure you are running in a proper environment for the tests you want to run.
For example, have a GPU for cuda tests or multiple nodes for MPI. Do not 
execute `run-all.py` on a login node without the `--dry` flag.