// Driver for 00_dense_la_lu_decomp for CUDA and HIP
// /* Factorize the matrix A into A=LU where L is a lower triangular matrix and U is an upper triangular matrix.
//    Store the results for L and U into the original matrix A. 
//    A is an NxN matrix stored in row-major.
//    Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.
//    Example:
// 
//    input: [[4, 3], [6, 3]]
//    output: [[4, 3], [1.5, -1.5]]
// */
// __global__ void luFactorize(double *A, size_t N) {

#include <algorithm>
#include <numeric>
#include <random>
#include <vector>

#include "utilities.hpp"
#include "baseline.hpp"
#include "generated-code.cuh"   // code generated by LLM


#if defined(USE_CUDA)
#include <thrust/device_vector.h>
#include <thrust/copy.h>
#include <thrust/sort.h>
#include <thrust/iterator/counting_iterator.h>
#include <thrust/iterator/permutation_iterator.h>
#endif

struct Context {

    size_t N;
    dim3 blockSize, gridSize;
};

void reset(Context *ctx) {

}

Context *init() {
    Context *ctx = new Context();

    ctx->N = 100000;
    ctx->blockSize = dim3(1024);
    ctx->gridSize = dim3((ctx->N + ctx->blockSize.x - 1) / ctx->blockSize.x); // at least enough threads

    reset(ctx);
    return ctx;
}

void NO_OPTIMIZE compute(Context *ctx) {

}

void NO_OPTIMIZE best(Context *ctx) {

}

bool validate(Context *ctx) {
    const size_t TEST_SIZE = 1024;
    dim3 blockSize = dim3(1024);
    dim3 gridSize = dim3((TEST_SIZE + blockSize.x - 1) / blockSize.x); // at least enough threads

    const size_t numTries = MAX_VALIDATION_ATTEMPTS;
    for (int trialIter = 0; trialIter < numTries; trialIter += 1) {
        // set up input

        // compute correct result

        // compute test result
        
        SYNC();
        
        if () {
            return false;
        }
    }

    return true;
}

void destroy(Context *ctx) {
    delete ctx;
}
