[
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "kokkos",
        "prompt": "#include <Kokkos_Core.hpp>\n\n/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix.\n   Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(Kokkos::View<const int**> &A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "Kokkos::View<int*, Kokkos::HostSpace> component_counts(\"component counts\");\n\tKokkos::View<int*, Kokkos::HostSpace> counts_scratch(\"counts scratch\");\n\tcomponent_counts = Kokkos::View<int*>(\"component counts\", N, Kokkos::HostSpace());\n\tcounts_scratch = Kokkos::View<int*>(\"counts scratch\", N, Kokkos::HostSpace());\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& node) {\n\t\t// set counts for nodes we have already counted\n\t\tcomponent_counts(node) = 1;\n\t});\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& node) {\n\t\t// get counts for all nodes adjacent to this one\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A(node, i)!= 0) {\n\t\t\t\tcomponent_counts(i) += component_counts(node);\n\t\t\t}\n\t\t}\n\t});\n\t// find maximum counts\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int& node, int& total) {\n\t\tif (component_counts(node) > total) {\n\t\t\ttotal = component_counts(node);\n\t\t}\n\t}, Kokkos::Max<int>(*Kokkos::atomic_max(&counts_scratch[0])), Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, 1));\n\tint max = counts_scratch[0];\n\treturn max;\n}",
            "Kokkos::View<int**> A_t(\"A_t\", N, N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n\t\t[&](int i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tA_t(j, i) = A(i, j);\n\t\t\t}\n\t\t});\n\n\t// TODO\n\n\tKokkos::fence();\n\n\treturn 0;\n}",
            "using namespace Kokkos;\n  View<bool**> visited(\"visited\", N, N);\n  View<int*> num_vertices(\"num_vertices\", N);\n  View<int**> queue(\"queue\", N, N);\n  int queue_len = 0;\n  int queue_head = 0;\n\n  Kokkos::parallel_for(RangePolicy<>(0, N), [&](int i) {\n\tfor (int j = 0; j < N; j++) {\n\t  if (A(i, j)) {\n\t\tqueue(queue_len, 0) = i;\n\t\tqueue(queue_len, 1) = j;\n\t\tqueue_len++;\n\t  }\n\t}\n  });\n\n  Kokkos::parallel_for(RangePolicy<>(0, N), [&](int i) {\n\tvisited(i, i) = true;\n\tnum_vertices(i) = 1;\n  });\n\n  // TODO\n\n  // Kokkos::single(Kokkos::PerTeam(Kokkos::ParallelForTag()), [&](int team_size, int thread_rank) {\n\n  // });\n\n  Kokkos::fence();\n  return 0;\n}",
            "// TODO\n    return -1;\n}",
            "// YOUR CODE HERE\n\n\treturn 0;\n}",
            "Kokkos::View<int**> component(Kokkos::ViewAllocateWithoutInitializing(\"component\"), N, N);\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [&](int i) {\n        for (int j = 0; j < N; ++j) {\n            component(i, j) = i == j;\n        }\n    });\n    int largest_component = 1;\n    for (int i = 0; i < N; ++i) {\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [&](int j) {\n            if (A(i, j) &&!component(i, j)) {\n                component(i, j) = 1;\n                for (int k = 0; k < N; ++k) {\n                    component(i, k) = component(i, k) || component(j, k);\n                }\n            }\n        });\n    }\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (component(i, j)) {\n                ++largest_component;\n            }\n        }\n    }\n    return largest_component;\n}",
            "// This is a struct for the graph components data.\n  struct GraphComponents {\n    // This is a Kokkos view that holds the current vertex for each component.\n    Kokkos::View<int*> curr_vertex;\n    // This is a Kokkos view that holds the component for each vertex.\n    Kokkos::View<int*> comp;\n    // This is a Kokkos view that holds the number of vertices in each component.\n    Kokkos::View<int*> comp_size;\n  };\n\n  // Create a Kokkos view of the graph components data.\n  GraphComponents gc;\n\n  // Create the views.\n  gc.curr_vertex = Kokkos::View<int*>(\"curr_vertex\", N);\n  gc.comp = Kokkos::View<int*>(\"comp\", N);\n  gc.comp_size = Kokkos::View<int*>(\"comp_size\", N);\n\n  // Set the curr_vertex data.\n  // Each element of curr_vertex corresponds to a component.\n  // curr_vertex[i] is the current vertex of component i.\n  Kokkos::parallel_for(\n      \"Initialize curr_vertex\",\n      Kokkos::RangePolicy<Kokkos::Serial>(0, N),\n      KOKKOS_LAMBDA(const int i) { gc.curr_vertex(i) = i; });\n\n  // Set the comp data.\n  // Each element of comp corresponds to a vertex.\n  // comp[i] is the component that vertex i is in.\n  Kokkos::parallel_for(\n      \"Initialize comp\",\n      Kokkos::RangePolicy<Kokkos::Serial>(0, N),\n      KOKKOS_LAMBDA(const int i) { gc.comp(i) = i; });\n\n  // Set the comp_size data.\n  // Each element of comp_size corresponds to a component.\n  // comp_size[i] is the number of vertices in component i.\n  Kokkos::parallel_for(\n      \"Initialize comp_size\",\n      Kokkos::RangePolicy<Kokkos::Serial>(0, N),\n      KOKKOS_LAMBDA(const int i) { gc.comp_size(i) = 1; });\n\n  // Now, do the work:\n  // Loop through each vertex in the adjacency matrix.\n  // Each iteration of the for loop will find the largest\n  // component that vertex is in.\n  Kokkos::parallel_for(\n      \"Find largest component\",\n      Kokkos::RangePolicy<Kokkos::Serial>(0, N),\n      KOKKOS_LAMBDA(const int i) {\n        // Find the component that the vertex i is in.\n        int comp_of_i = gc.comp(i);\n        // Find the current vertex of the component comp_of_i.\n        int curr_vertex_of_comp_of_i = gc.curr_vertex(comp_of_i);\n        // Loop through the neighbors of the vertex i.\n        for (int j = 0; j < N; ++j) {\n          // If i is not a neighbor of j, then continue.\n          if (A(i, j) == 0) continue;\n          // Find the component that the neighbor j is in.\n          int comp_of_j = gc.comp(j);\n          // Find the current vertex of the component comp_of_j.\n          int curr_vertex_of_comp_of_j = gc.curr_vertex(comp_of_j);\n          // If the current vertex of comp_of_j is the same as the current vertex of comp_of_i,\n          // then the two vertices are already in the same component, so continue.\n          if (curr_vertex_of_comp_of_j == curr_vertex_of_comp_of_i) continue;\n          // Otherwise, the two vertices are in different components, so we need to\n          // merge them together.\n          // We will merge comp_of_j into comp_of_i.\n          // First, find the size of the component we are merging.\n          int comp_",
            "int num_threads = std::thread::hardware_concurrency();\n\n\tint max_vertex = 0;\n\tint* count = new int[N];\n\tKokkos::View<int*, Kokkos::HostSpace> k_count(\"k_count\", N);\n\t\n\tfor (int i = 0; i < num_threads; i++) {\n\t\tKokkos::parallel_for(\"largest_component\", Kokkos::RangePolicy<Kokkos::OpenMP>(i * (N / num_threads), (i + 1) * (N / num_threads)), KOKKOS_LAMBDA(const int& vertex) {\n\t\t\tcount[vertex] = 0;\n\t\t\tk_count(vertex) = 0;\n\t\t});\n\t}\n\n\tfor (int i = 0; i < num_threads; i++) {\n\t\tKokkos::parallel_for(\"largest_component\", Kokkos::RangePolicy<Kokkos::OpenMP>(i * (N / num_threads), (i + 1) * (N / num_threads)), KOKKOS_LAMBDA(const int& vertex) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(vertex, j) > 0) {\n\t\t\t\t\tcount[j] = count[vertex] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\n\tKokkos::deep_copy(k_count, count);\n\n\tfor (int i = 0; i < num_threads; i++) {\n\t\tKokkos::parallel_for(\"largest_component\", Kokkos::RangePolicy<Kokkos::OpenMP>(i * (N / num_threads), (i + 1) * (N / num_threads)), KOKKOS_LAMBDA(const int& vertex) {\n\t\t\tk_count(vertex) = (k_count(vertex) > max_vertex)? k_count(vertex) : max_vertex;\n\t\t});\n\t}\n\n\tKokkos::deep_copy(count, k_count);\n\tfor (int i = 0; i < N; i++) {\n\t\tmax_vertex = (count[i] > max_vertex)? count[i] : max_vertex;\n\t}\n\tdelete[] count;\n\n\treturn max_vertex;\n}",
            "using lno_t = int;\n  using size_type = int;\n\n  using Kokkos::DefaultHostExecutionSpace;\n  using Kokkos::DefaultHostExecutionSpace::size_type;\n\n  using DeviceSpace = Kokkos::DefaultHostExecutionSpace;\n  using Kokkos::HostSpace;\n  using Kokkos::View;\n  using Kokkos::subview;\n\n  // The algorithm is as follows:\n  // 1. Find the largest component with a DFS traversal.\n  // 2. Count the number of vertices in the largest component.\n\n  // 1. Find the largest component with a DFS traversal.\n  // We initialize a vector to store the largest component ID (0 for every vertex).\n  // During the DFS traversal, we update the largest component ID based on which\n  // component ID the vertex belongs to. We use a bit of a trick to do this.\n  // We initialize the component ID to be the index of the vertex.\n  // Then, the component ID of the vertices in the component will be the smallest\n  // component ID of all the vertices in the component.\n\n  // Initialize component IDs.\n  auto comp_ids = View<int*>(\"component IDs\", N);\n  Kokkos::parallel_for(\n      \"initialize component IDs\",\n      Kokkos::RangePolicy<DeviceSpace>(0, N),\n      KOKKOS_LAMBDA(const lno_t &i) { comp_ids(i) = i; });\n\n  // Visit all the vertices and update the component IDs based on which component\n  // ID the vertex belongs to.\n  Kokkos::parallel_for(\n      \"DFS traversal\",\n      Kokkos::RangePolicy<DeviceSpace>(0, N),\n      KOKKOS_LAMBDA(const lno_t &i) {\n        for (int j = 0; j < N; ++j) {\n          if (A(i, j)!= 0) {\n            // Find the smallest component ID of the vertices in the component.\n            int smallest_comp_id = comp_ids(i);\n            int comp_id_of_j = comp_ids(j);\n            if (comp_id_of_j < smallest_comp_id) {\n              smallest_comp_id = comp_id_of_j;\n            }\n            comp_ids(i) = smallest_comp_id;\n          }\n        }\n      });\n\n  // 2. Count the number of vertices in the largest component.\n  // We initialize a vector to store the component IDs of the vertices in the\n  // largest component.\n  // Then we count the number of vertices in the largest component by looping over\n  // all the vertices in the graph and checking if their component ID is in the\n  // vector of component IDs of the largest component.\n  auto largest_comp_ids = View<int*>(\"largest component IDs\", N);\n  Kokkos::parallel_for(\n      \"initialize largest component IDs\",\n      Kokkos::RangePolicy<DeviceSpace>(0, N),\n      KOKKOS_LAMBDA(const lno_t &i) {\n        if (comp_ids(i) == 0) {\n          largest_comp_ids(i) = 1;\n        } else {\n          largest_comp_ids(i) = 0;\n        }\n      });\n\n  int num_vertices_in_largest_comp = 0;\n  Kokkos::parallel_reduce(\n      \"count vertices in largest component\",\n      Kokkos::RangePolicy<DeviceSpace>(0, N),\n      KOKKOS_LAMBDA(const lno_t &i, int &num_vertices_in_largest_comp) {\n        if (largest_comp_ids(i)!= 0) {\n          num_vertices_in_largest_comp++;\n        }\n      },\n      num_vertices_in_largest_comp);\n\n  return num_vertices_in_largest_comp;\n}",
            "// Your code goes here ---------------------------\n  //int mylargest = 0;\n\n  return largest;\n}",
            "// Fill in this function\n  int *color = (int*)malloc(N*sizeof(int));\n  for(int i=0; i<N; i++){\n\tcolor[i]=i;\n  }\n  for(int i=0; i<N; i++){\n\tfor(int j=0; j<N; j++){\n\t  if(A(i,j)!=0){\n\t\tcolor[i] = color[j];\n\t  }\n\t}\n  }\n  int temp = 0;\n  for(int i=0; i<N; i++){\n\ttemp = temp>color[i]?temp:color[i];\n  }\n  return temp;\n}",
            "int max_verts = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int &lmax) {\n\t\tint verts = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\tif (A(j, k)!= 0) {\n\t\t\t\t\t\tif (A(i, k)!= 0) {\n\t\t\t\t\t\t\t++verts;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (verts > lmax)\n\t\t\tlmax = verts;\n\t}, Kokkos::Max<int>(max_verts));\n\treturn max_verts;\n}",
            "// TODO: Insert code here\n}",
            "// TODO\n    return 0;\n}",
            "/* YOUR CODE GOES HERE */\n\t\n\treturn 0;\n}",
            "// Allocate a new adjacency matrix to hold the result of each iteration\n\tKokkos::View<int**> newA(\"newA\", N, N);\n\t// Set up some variables for use in the parallel loop\n\tint largestComponentSize = 1;\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t\tnewA(i, i) = 1;\n\t});\n\tKokkos::fence();\n\t// Repeat until the adjacency matrix is fully connected (i.e. all elements are 1)\n\twhile (largestComponentSize < N) {\n\t\t// Determine the size of the largest component in newA\n\t\tint localLargestComponentSize = 0;\n\t\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int& localLargestComponentSize) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tlocalLargestComponentSize = std::max(localLargestComponentSize, newA(i, j));\n\t\t\t}\n\t\t}, largestComponentSize);\n\t\tKokkos::fence();\n\t\t// Stop if we've fully connected the graph\n\t\tif (largestComponentSize == N)\n\t\t\tbreak;\n\t\t// Otherwise, update the adjacency matrix for the next iteration\n\t\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tnewA(i, j) = 1;\n\t\t\t\t} else if (newA(i, j) == 0) {\n\t\t\t\t\tnewA(i, j) = 0;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\tif (newA(i, k) == 1 && newA(k, j) == 1) {\n\t\t\t\t\t\t\tnewA(i, j) = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\t\t// Copy the new adjacency matrix back into A\n\t\tKokkos::deep_copy(A, newA);\n\t\t// Determine the size of the largest component in A\n\t\tlargestComponentSize = 0;\n\t\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int& localLargestComponentSize) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tlocalLargestComponentSize = std::max(localLargestComponentSize, A(i, j));\n\t\t\t}\n\t\t}, largestComponentSize);\n\t\tKokkos::fence();\n\t}\n\t// Return the size of the largest component\n\treturn largestComponentSize;\n}",
            "using view_t = Kokkos::View<const int**>;\n\tusing view_t_device = typename Kokkos::View<const int**, Kokkos::LayoutStride, Kokkos::Device<Kokkos::Cuda, Kokkos::CudaUVMSpace>>;\n\tusing view_t_host = typename Kokkos::View<const int**, Kokkos::LayoutStride, Kokkos::HostSpace>;\n\tint num_vertices = 0;\n\n\t// copy A to a Kokkos view so we can call Kokkos funcs on it\n\tview_t_device A_device(Kokkos::ViewAllocateWithoutInitializing(\"A_device\"), N, N);\n\tKokkos::deep_copy(A_device, A);\n\n\t// get the number of vertices in the largest connected component\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(int i, int &max) {\n\t\tmax = std::max(max, graph_algorithms::connected_components::connected_components(A_device, i));\n\t}, Kokkos::Max<int>(num_vertices));\n\n\tKokkos::fence();\n\n\tKokkos::deep_copy(A_device, A);\n\n\treturn num_vertices;\n}",
            "return 0;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> vertex_to_component(Kokkos::ViewAllocateWithoutInitializing(\"vtc\"), N);\n\tKokkos::View<int*, Kokkos::HostSpace> component_to_vertex(Kokkos::ViewAllocateWithoutInitializing(\"ctv\"), N);\n\tKokkos::View<int*, Kokkos::HostSpace> component_sizes(Kokkos::ViewAllocateWithoutInitializing(\"cs\"), N);\n\n\t// Initialize vertex_to_component and component_to_vertex\n\tfor (int i = 0; i < N; i++) {\n\t\tvertex_to_component(i) = i;\n\t\tcomponent_to_vertex(i) = i;\n\t}\n\n\t// Find all components\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\t// If vertex i and j are connected, set them to the same component\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tint min = vertex_to_component(i) < vertex_to_component(j)? vertex_to_component(i) : vertex_to_component(j);\n\t\t\t\tint max = vertex_to_component(i) > vertex_to_component(j)? vertex_to_component(i) : vertex_to_component(j);\n\t\t\t\tvertex_to_component(j) = min;\n\t\t\t\tvertex_to_component(i) = min;\n\n\t\t\t\tcomponent_to_vertex(min) = min < component_to_vertex(min)? min : component_to_vertex(min);\n\t\t\t}\n\t\t}\n\t}\n\n\tint max_component = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\t// Set the component size\n\t\tcomponent_sizes(vertex_to_component(i)) += 1;\n\n\t\t// Set the new component if it is larger than the old one\n\t\tif (component_sizes(vertex_to_component(i)) > component_sizes(max_component)) {\n\t\t\tmax_component = vertex_to_component(i);\n\t\t}\n\t}\n\n\treturn component_sizes(max_component);\n}",
            "const int N_COMPS = 4;\n\n  // The Kokkos::View needs to be declared as a static variable\n  // (i.e. have global scope) so that the Kokkos garbage collector\n  // will properly clean it up.\n  static Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> comp(N);\n  static Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> comp_count(N_COMPS);\n  static Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> max_comp(1);\n\n  // Run the kernel with a single thread to initialize the component counts.\n  Kokkos::parallel_for(\"init_comp_counts\", 1, KOKKOS_LAMBDA (int) {\n    for (int i = 0; i < N; i++) comp(i) = i;\n    for (int i = 0; i < N_COMPS; i++) comp_count(i) = 0;\n    max_comp(0) = 0;\n  });\n\n  // Run the kernel with N threads, where each thread traverses the\n  // graph starting at the node given by its ID.\n  Kokkos::parallel_for(\"traverse_graph\", N, KOKKOS_LAMBDA (int i) {\n    // Get the component for this node.\n    int comp_id = comp(i);\n\n    // Check whether the component we're in is already connected to the\n    // largest component.\n    bool in_largest = false;\n    Kokkos::atomic_fetch_add(&comp_count(comp_id), 1);\n    for (int j = 0; j < N_COMPS; j++) {\n      if (comp_count(j) > comp_count(comp_id)) {\n        in_largest = true;\n        break;\n      }\n    }\n\n    // If the component we're in is not connected to the largest\n    // component, we will need to traverse this part of the graph and\n    // change all the node IDs to the largest component.\n    if (!in_largest) {\n      comp_count(comp_id) = N; // N is the number of nodes in the graph.\n      Kokkos::atomic_fetch_max(&max_comp(0), comp_count(comp_id));\n    }\n\n    // Traverse the graph to find all the connected nodes.\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1 && i!= j && comp(j)!= comp_id) {\n        comp(j) = comp_id;\n      }\n    }\n  });\n\n  // Copy the comp array from device to host.\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> comp_host(\"comp_host\", N);\n  Kokkos::deep_copy(comp_host, comp);\n\n  // Count the number of unique IDs in comp.\n  // This is the number of components in the graph.\n  int num_comps = 0;\n  for (int i = 0; i < N; i++) {\n    bool found = false;\n    for (int j = 0; j < num_comps; j++) {\n      if (comp_host(i) == comp_host(j)) {\n        found = true;\n        break;\n      }\n    }\n    if (!found) {\n      num_comps++;\n    }\n  }\n\n  // Now, count the number of nodes in the largest component.\n  int largest_count = 0;\n  for (int i = 0; i < N; i++) {\n    if (comp_host(i) == comp_host(max_comp(0))) {\n      largest_count++;\n    }\n  }\n\n  return largest_count;\n}",
            "// Kokkos::View<int*> to keep track of visited vertices\n\tKokkos::View<int*> visited(\"visited\", N);\n\tKokkos::deep_copy(visited, 0);\n\n\t// Auxiliary arrays to keep track of the largest component\n\tKokkos::View<int*> stack(\"stack\", N);\n\tKokkos::View<int*> stackIdx(\"stackIdx\", N);\n\n\t// Traverse each vertex to find the largest component\n\tint maxIdx = 0;\n\tint maxSize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint currSize = 0;\n\n\t\t// Stack to keep track of traversed vertices\n\t\tint stackSize = 0;\n\t\tstack[stackSize] = i;\n\t\tstackIdx[stackSize] = 0;\n\t\tstackSize++;\n\n\t\t// Traverse the neighbors of the current vertex\n\t\twhile (stackSize > 0) {\n\t\t\tint currIdx = stackSize - 1;\n\t\t\tint curr = stack[currIdx];\n\t\t\tint currIdxNbrs = stackIdx[currIdx];\n\t\t\tif (currIdxNbrs < N) {\n\t\t\t\tint nextIdx = stack[currIdx] * N + currIdxNbrs;\n\t\t\t\tint next = A(curr, currIdxNbrs);\n\n\t\t\t\t// If the neighbor has not been visited, push it to the stack\n\t\t\t\tif (visited(next) == 0) {\n\t\t\t\t\tvisited(next) = 1;\n\t\t\t\t\tstack[stackSize] = next;\n\t\t\t\t\tstackIdx[stackSize] = 0;\n\t\t\t\t\tstackSize++;\n\t\t\t\t}\n\n\t\t\t\t// Move to the next neighbor\n\t\t\t\tstackIdx[currIdx]++;\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// The current vertex is done, pop it from the stack\n\t\t\t\tstackSize--;\n\t\t\t\tcurrSize++;\n\t\t\t}\n\t\t}\n\n\t\t// Check if the current component is the largest component found so far\n\t\tif (currSize > maxSize) {\n\t\t\tmaxSize = currSize;\n\t\t\tmaxIdx = i;\n\t\t}\n\n\t\t// Reset the vertex visited flag\n\t\tKokkos::deep_copy(visited, 0);\n\t}\n\n\t// Return the vertex in the largest component\n\treturn maxIdx;\n}",
            "// TODO: replace with your code\n  int max_component_size = 0;\n  for (int i = 0; i < N; i++) {\n    if (A(i, i) == 1) {\n      int cur_component_size = 1;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j) == 1 && i!= j) {\n          cur_component_size += 1;\n          A(i, j) = 0;\n          A(j, i) = 0;\n        }\n      }\n      if (cur_component_size > max_component_size) {\n        max_component_size = cur_component_size;\n      }\n    }\n  }\n  return max_component_size;\n}",
            "// Initialize a vector of bools to keep track of which vertices have been visited\n\tKokkos::View<bool*> visited(\"visited\", N);\n\n\t// Initialize a vector of ints to keep track of the size of the largest component\n\tKokkos::View<int*> max_component_size(\"max_component_size\", 1);\n\n\t// Initialize an array to keep track of the vertex that is the last vertex to be visited\n\t// in the DFS.\n\tKokkos::View<int*> last_vertex(\"last_vertex\", 1);\n\tlast_vertex() = 0;\n\n\t// For all vertices in the graph...\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t[&](const int i) {\n\t\t\t// Initialize the vector of bools to false.\n\t\t\tvisited(i) = false;\n\t\t}\n\t);\n\n\tKokkos::fence();\n\n\t// For all vertices in the graph...\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t[&](const int i) {\n\t\t\t// If the vertex has already been visited, skip it.\n\t\t\tif (visited(i) == true) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Otherwise, it has not been visited yet, so we will visit it.\n\t\t\t// Record that it has been visited.\n\t\t\tvisited(i) = true;\n\n\t\t\t// Initialize a stack of vertices.\n\t\t\tstd::stack<int> stack;\n\n\t\t\t// Add the current vertex to the stack.\n\t\t\tstack.push(i);\n\n\t\t\t// Initialize a vector to keep track of the size of the component being visited.\n\t\t\tstd::vector<int> component_size;\n\t\t\tcomponent_size.push_back(1);\n\n\t\t\t// Continue visiting vertices as long as the stack is not empty.\n\t\t\twhile (!stack.empty()) {\n\t\t\t\t// Pop the last vertex visited from the stack.\n\t\t\t\tint v = stack.top();\n\t\t\t\tstack.pop();\n\n\t\t\t\t// Iterate over all the vertices adjacent to the current vertex.\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t// If the vertex has already been visited, skip it.\n\t\t\t\t\tif (visited(j) == true) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\t// If the current vertex is connected to the adjacent vertex...\n\t\t\t\t\tif (A(v, j) == 1) {\n\t\t\t\t\t\t// Record that the adjacent vertex has been visited.\n\t\t\t\t\t\tvisited(j) = true;\n\n\t\t\t\t\t\t// Add the adjacent vertex to the stack.\n\t\t\t\t\t\tstack.push(j);\n\n\t\t\t\t\t\t// Increment the size of the component being visited.\n\t\t\t\t\t\tcomponent_size.push_back(component_size.back() + 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Save the size of the component being visited into a Kokkos array.\n\t\t\tKokkos::View<int*> component_size_kokkos(\"component_size_kokkos\", component_size.size());\n\t\t\tKokkos::deep_copy(component_size_kokkos, component_size);\n\n\t\t\t// Keep track of the maximum size of a component.\n\t\t\t// Kokkos::Max<> does not work with the std::vector<> size() function, so we use a different\n\t\t\t// variable to track the maximum size.\n\t\t\tint component_size_max = component_size[0];\n\n\t\t\t// Find the maximum size of a component.\n\t\t\tKokkos::parallel_reduce(\n\t\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, component_size",
            "// TODO: Fill this out\n\treturn 0;\n}",
            "// TODO: Fill this in\n    return 0;\n}",
            "// Implement this function\n}",
            "Kokkos::View<int*> comp(\"comp\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&](const int& i) {\n\t\tcomp(i) = i;\n\t});\n\n\tKokkos::fence();\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&](const int& k) {\n\t\t\t\t\tif (comp(k) == comp(j)) {\n\t\t\t\t\t\tcomp(k) = comp(i);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t}\n\n\tKokkos::fence();\n\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tmax = std::max(max, comp(i));\n\t}\n\n\treturn max + 1;\n}",
            "// BEGIN_KOKKOS\n\t// Create a vector of size N that holds the vertex ID of the root of each\n\t// connected component\n\tKokkos::View<int *> root(Kokkos::ViewAllocateWithoutInitializing(\"root\"), N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\troot[i] = i;\n\t});\n\tKokkos::fence();\n\n\t// Create a vector of size N that holds the size of each connected component\n\tKokkos::View<int *> size(Kokkos::ViewAllocateWithoutInitializing(\"size\"), N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tsize[i] = 1;\n\t});\n\tKokkos::fence();\n\n\t// Find the root vertex of each connected component\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i][j]!= 0) {\n\t\t\t\t// Union: Find the root of the component with vertex ID j\n\t\t\t\tint rootI = i;\n\t\t\t\tint rootJ = j;\n\t\t\t\twhile (root[rootI]!= rootI) {\n\t\t\t\t\trootI = root[rootI];\n\t\t\t\t}\n\t\t\t\twhile (root[rootJ]!= rootJ) {\n\t\t\t\t\trootJ = root[rootJ];\n\t\t\t\t}\n\n\t\t\t\t// Merge the two components with rootI and rootJ\n\t\t\t\tif (rootI!= rootJ) {\n\t\t\t\t\tif (size[rootI] >= size[rootJ]) {\n\t\t\t\t\t\troot[rootJ] = rootI;\n\t\t\t\t\t\tsize[rootI] += size[rootJ];\n\t\t\t\t\t} else {\n\t\t\t\t\t\troot[rootI] = rootJ;\n\t\t\t\t\t\tsize[rootJ] += size[rootI];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\t// Find the root of the component containing vertex ID N - 1\n\tint rootN = N - 1;\n\twhile (root[rootN]!= rootN) {\n\t\trootN = root[rootN];\n\t}\n\n\t// END_KOKKOS\n\tint ret = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (root[i] == rootN) {\n\t\t\tret++;\n\t\t}\n\t}\n\n\treturn ret;\n}",
            "// This is a hack that avoids initializing Cuda.\n  // We will eventually replace this with something better.\n  // See: https://github.com/kokkos/kokkos/issues/1656\n  if (Kokkos::SpaceAccessibility<Kokkos::Cuda, Kokkos::HostSpace>::accessible) {\n    return -1;\n  }\n\n  Kokkos::View<int*> n_visited(\"n_visited\", N);\n  Kokkos::View<int*> n_unvisited(\"n_unvisited\", N);\n  Kokkos::View<int*> vert_is_visited(\"vert_is_visited\", N);\n  Kokkos::View<int*> vert_queue(\"vert_queue\", N);\n\n  int n_v = 0;\n\n  // Traverse the graph starting at each unvisited vertex.\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda, int>(0, N), KOKKOS_LAMBDA (int vert) {\n\n    // Already visited.\n    if (vert_is_visited(vert) == 1) {\n      return;\n    }\n\n    // Queue of vertices to visit.\n    int queue_index = 0;\n    vert_queue(queue_index) = vert;\n\n    // Keep track of how many vertices have been visited.\n    n_visited(vert) = 1;\n    n_unvisited(vert) = 0;\n\n    while (queue_index < N) {\n      vert = vert_queue(queue_index);\n      queue_index++;\n\n      // Mark vertex as visited.\n      vert_is_visited(vert) = 1;\n\n      // Traverse edges.\n      for (int i = 0; i < N; i++) {\n        if (i!= vert && A(vert, i) == 1) {\n          // Add to queue if not already visited.\n          if (vert_is_visited(i) == 0) {\n            n_unvisited(i) = 0;\n            vert_queue(queue_index) = i;\n            queue_index++;\n          }\n\n          // Increment vertices that have been visited.\n          n_visited(i)++;\n        }\n      }\n    }\n  });\n\n  // Find maximum number of vertices visited.\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda, int>(0, N), KOKKOS_LAMBDA (int i, int& max_n_v) {\n    if (n_visited(i) > max_n_v) {\n      max_n_v = n_visited(i);\n    }\n  }, Kokkos::Max<int>(n_v));\n\n  // Return number of vertices visited in largest component.\n  return n_v;\n}",
            "int maxComponent = 0;\n\tint currentComponent = 0;\n\n\t//TODO: add your code here\n\n\treturn maxComponent;\n}",
            "Kokkos::View<int*> result(\"Result\", N);\n  auto init_functor = KOKKOS_LAMBDA(const int i) {\n    result(i) = i;\n  };\n  auto join_functor = KOKKOS_LAMBDA(const int i, int& val, const bool final) {\n    if (!final) {\n      // We have multiple components. Merge them all into a single component.\n      val = std::min(val, result(i));\n    }\n  };\n  auto merge_functor = KOKKOS_LAMBDA(const int i, int& val) {\n    // Merge two components\n    val = std::min(val, result(i));\n  };\n  auto reduce_functor = KOKKOS_LAMBDA(const int i, int& val, const bool final) {\n    if (!final) {\n      result(i) = val;\n    }\n  };\n\n  Kokkos::parallel_for(\"Init\", N, init_functor);\n  Kokkos::fence();\n  for (int j = 0; j < N; j++) {\n    auto update_functor = KOKKOS_LAMBDA(const int i, int& val) {\n      if (A(i,j)) {\n        val = std::min(val, result(i));\n      }\n    };\n    Kokkos::parallel_reduce(\"Update\", N, update_functor, join_functor);\n    Kokkos::fence();\n  }\n  auto merge_functor = KOKKOS_LAMBDA(const int i, int& val) {\n    // Merge two components\n    val = std::min(val, result(i));\n  };\n  Kokkos::parallel_reduce(\"Merge\", N, merge_functor, join_functor);\n  Kokkos::fence();\n  auto reduce_functor = KOKKOS_LAMBDA(const int i, int& val, const bool final) {\n    if (!final) {\n      result(i) = val;\n    }\n  };\n  Kokkos::parallel_reduce(\"Reduce\", N, reduce_functor, join_functor);\n  Kokkos::fence();\n  int largest_component = 0;\n  int largest_component_size = 0;\n  auto get_largest_functor = KOKKOS_LAMBDA(const int i) {\n    if (result(i) == i) {\n      largest_component = i;\n      largest_component_size++;\n    }\n  };\n  Kokkos::parallel_for(\"GetLargest\", N, get_largest_functor);\n  Kokkos::fence();\n  return largest_component_size;\n}",
            "// TODO: implement this function\n\t// Hint: use Kokkos::parallel_for and Kokkos::parallel_reduce.\n\n\tKokkos::View<int*> component_sizes(\"ComponentSizes\", N);\n\n\tint max_component = 0;\n\n\t// TODO: find the size of each component and find the largest component\n\t\n\t// TODO: find the largest component\n\n\t// TODO: cleanup\n\n\treturn max_component;\n}",
            "// Declare an array of booleans to store whether a node has been visited.\n\tKokkos::View<bool*, Kokkos::HostSpace> hasVisited(\"hasVisited\", N);\n\t\n\t// Initialize hasVisited to false\n\tKokkos::parallel_for(\"Initialize hasVisited\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), KOKKOS_LAMBDA(int i) {\n\t\thasVisited(i) = false;\n\t});\n\t\n\t// Declare a work queue\n\tKokkos::View<int*, Kokkos::HostSpace> workQueue(\"workQueue\", N);\n\t\n\t// Initialize the work queue to be the indices of all nodes in the graph.\n\tint workQueueIndex = 0;\n\tKokkos::parallel_for(\"Initialize work queue\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), KOKKOS_LAMBDA(int i) {\n\t\tworkQueue(workQueueIndex) = i;\n\t\tworkQueueIndex++;\n\t});\n\t\n\t// Declare a counter for the number of nodes visited\n\tint nodesVisited = 0;\n\t\n\t// Declare a variable to keep track of the largest component size so far\n\tint largestComponentSize = 0;\n\t\n\t// While the work queue is non-empty, visit a node, then visit all of its neighbors\n\twhile (workQueueIndex > 0) {\n\t\t\n\t\t// Pick the first node in the work queue.\n\t\t// We can do this in parallel by having one thread pick a node and remove it from the queue\n\t\tint nodeToVisit = workQueue(0);\n\t\tKokkos::parallel_for(\"Remove node from work queue\", Kokkos::RangePolicy<Kokkos::HostSpace>(1, workQueueIndex), KOKKOS_LAMBDA(int i) {\n\t\t\tworkQueue(i-1) = workQueue(i);\n\t\t});\n\t\t\n\t\t// Decrement the size of the work queue.\n\t\tKokkos::fence();\n\t\tworkQueueIndex--;\n\t\tKokkos::fence();\n\t\t\n\t\t// If we've already visited this node, skip it\n\t\tif (hasVisited(nodeToVisit)) {\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\t// Mark this node as visited\n\t\tKokkos::parallel_for(\"Mark node as visited\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, 1), KOKKOS_LAMBDA(int i) {\n\t\t\thasVisited(nodeToVisit) = true;\n\t\t});\n\t\t\n\t\t// Increment the number of nodes visited\n\t\tKokkos::parallel_for(\"Increment nodes visited\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, 1), KOKKOS_LAMBDA(int i) {\n\t\t\tnodesVisited++;\n\t\t});\n\t\t\n\t\t// Iterate over all of the node's neighbors and add them to the work queue if they haven't been visited yet.\n\t\t// Keep track of the number of neighbors visited by the current node.\n\t\t// We can do this in parallel by having each thread visit its own neighbors\n\t\tint neighborsVisited = 0;\n\t\tKokkos::parallel_for(\"Add unvisited neighbors to work queue\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), KOKKOS_LAMBDA(int i) {\n\t\t\t// Skip if this neighbor hasn't been visited yet\n\t\t\tif (hasVisited(i) == false && A(nodeToVisit, i) == 1) {\n\t\t\t\tworkQueue(workQueueIndex) = i;\n\t\t\t\tworkQueueIndex++;\n\t\t\t\tneighborsVisited++;\n\t\t\t}\n\t\t});\n\t\t\n\t\t// Increment the size of the largest component if the current node had a neighbor\n\t\tif (neighborsVisited > 0) {\n\t\t\tKokkos::parallel_for(\"Increment largest component size\", Kokkos::",
            "using view_1d = Kokkos::View<int*>;\n  view_1d component(\"component\", N);\n\n  int num_components = 0;\n\n  Kokkos::parallel_for(\n    \"component\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n\n      // set the component id of node i to i\n      component(i) = i;\n\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"connect\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n\n      for (size_t j = 0; j < N; j++) {\n\n        // check if i is connected to j\n        if (A(i, j) == 1) {\n\n          // set the component of j to be the same as i\n          component(j) = i;\n\n        }\n\n      }\n\n    }\n  );\n\n  Kokkos::parallel_reduce(\n    \"count_components\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i, int &num_components) {\n\n      // check if this is a new component\n      if (component(i) == i) {\n\n        // increment the number of components\n        num_components++;\n\n      }\n\n    },\n    num_components\n  );\n\n  return num_components;\n}",
            "int num_vertices = N;\n\tKokkos::View<int*, Kokkos::HostSpace> largest_components_on_host(\"largest_components_on_host\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> temp_largest_components_on_host(\"temp_largest_components_on_host\", N);\n\n\tKokkos::deep_copy(largest_components_on_host, -1);\n\tKokkos::deep_copy(temp_largest_components_on_host, -1);\n\n\tKokkos::View<int*, Kokkos::DefaultHostExecutionSpace> largest_components_on_default_host(\"largest_components_on_default_host\", N);\n\tKokkos::View<int*, Kokkos::DefaultHostExecutionSpace> temp_largest_components_on_default_host(\"temp_largest_components_on_default_host\", N);\n\n\tKokkos::deep_copy(largest_components_on_default_host, -1);\n\tKokkos::deep_copy(temp_largest_components_on_default_host, -1);\n\n\tKokkos::View<int*, Kokkos::CudaUVMSpace> largest_components_on_cuda_uvm(\"largest_components_on_cuda_uvm\", N);\n\tKokkos::View<int*, Kokkos::CudaUVMSpace> temp_largest_components_on_cuda_uvm(\"temp_largest_components_on_cuda_uvm\", N);\n\n\tKokkos::deep_copy(largest_components_on_cuda_uvm, -1);\n\tKokkos::deep_copy(temp_largest_components_on_cuda_uvm, -1);\n\n\tKokkos::View<int*, Kokkos::CudaSpace> largest_components_on_cuda(\"largest_components_on_cuda\", N);\n\tKokkos::View<int*, Kokkos::CudaSpace> temp_largest_components_on_cuda(\"temp_largest_components_on_cuda\", N);\n\n\tKokkos::deep_copy(largest_components_on_cuda, -1);\n\tKokkos::deep_copy(temp_largest_components_on_cuda, -1);\n\n\tauto largest_component_functor = KOKKOS_LAMBDA(const int& i) {\n\t\tKokkos::parallel_for(Kokkos::TeamThreadRange(1, num_vertices), [&](const int& j) {\n\t\t\tif (A(i, j) == 1 && largest_components_on_default_host(j)!= -1) {\n\t\t\t\tlargest_components_on_default_host(i) = largest_components_on_default_host(j);\n\t\t\t}\n\t\t\telse if (A(i, j) == 1 && largest_components_on_default_host(j) == -1) {\n\t\t\t\tlargest_components_on_default_host(j) = i;\n\t\t\t}\n\t\t});\n\t};\n\tKokkos::parallel_for(\"largest_component_functor_on_default_host\", num_vertices, largest_component_functor);\n\tKokkos::deep_copy(largest_components_on_host, largest_components_on_default_host);\n\tint largest_component = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (largest_components_on_host(i) == -1) {\n\t\t\tlargest_components_on_host(i) = i;\n\t\t\tcontinue;\n\t\t}\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(largest_components_on_host(i), j) == 1 && largest_components_on_host(j)!= -1 && largest_components_on_host(j)!= largest_components_on_host(i)) {\n\t\t\t\tlargest_components_on_host(",
            "// TODO\n  return 0;\n}",
            "typedef Kokkos::Schedule<Kokkos::Dynamic> sched;\n  typedef Kokkos::RangePolicy<sched> policy;\n\n  Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::View<int*> visited_count(\"visited_count\", N);\n  Kokkos::View<int*> component_size(\"component_size\", N);\n\n  auto component_size_host = Kokkos::create_mirror_view(component_size);\n  auto visited_host = Kokkos::create_mirror_view(visited);\n  auto visited_count_host = Kokkos::create_mirror_view(visited_count);\n\n  Kokkos::deep_copy(visited, 0);\n  Kokkos::deep_copy(visited_count, 0);\n  Kokkos::deep_copy(component_size, 0);\n\n  Kokkos::parallel_for(\n\t  \"BFS\",\n\t  policy(0, N),\n\t  KOKKOS_LAMBDA (const int &i) {\n\t\t  int v = i;\n\t\t  bool found_new = true;\n\t\t  while (found_new) {\n\t\t\t  found_new = false;\n\t\t\t  for (int j = 0; j < N; ++j) {\n\t\t\t\t  if (!visited_host(j) && A(v,j)) {\n\t\t\t\t\t  visited_host(j) = 1;\n\t\t\t\t\t  component_size_host(j) = 1 + component_size_host(v);\n\t\t\t\t\t  found_new = true;\n\t\t\t\t  }\n\t\t\t  }\n\t\t\t  if (found_new) {\n\t\t\t\t  visited_count_host(v) += 1;\n\t\t\t\t  v = find_next_unvisited_vertex(visited_host, A, v);\n\t\t\t  }\n\t\t  }\n\t  }\n  );\n\n  Kokkos::deep_copy(visited, visited_host);\n  Kokkos::deep_copy(component_size, component_size_host);\n  Kokkos::deep_copy(visited_count, visited_count_host);\n\n  return compute_largest_component(visited, component_size, visited_count, N);\n\n}",
            "Kokkos::View<int*> B(\"B\", N);\n\tKokkos::parallel_for(\n\t\t\t\"largest_component\", N, KOKKOS_LAMBDA(const int i) {\n\t\t\t\tint count = 0;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (i!= j && A(i, j) == 1) {\n\t\t\t\t\t\tcount += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tB(i) = count;\n\t\t\t});\n\n\tint largest = -1;\n\tKokkos::parallel_reduce(\n\t\t\t\"find_largest_component\", N,\n\t\t\tKOKKOS_LAMBDA(const int i, int &val) {\n\t\t\t\tif (B(i) > val) {\n\t\t\t\t\tval = B(i);\n\t\t\t\t}\n\t\t\t}, largest);\n\n\treturn largest;\n}",
            "// TODO: your code here\n    Kokkos::View<int*> visited(\"visited\", N);\n    Kokkos::parallel_for(\"bfs\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i){\n        Kokkos::View<int*> work_queue(\"work_queue\", N);\n        int work_queue_size = 1;\n        work_queue(0) = i;\n        visited(i) = 1;\n        int visited_size = 1;\n        while(work_queue_size!= 0){\n            int tmp = work_queue(work_queue_size - 1);\n            for(int j = 0; j < N; j++){\n                if(A(tmp, j) == 1){\n                    if(visited(j) == 0){\n                        work_queue(work_queue_size) = j;\n                        work_queue_size++;\n                        visited(j) = 1;\n                        visited_size++;\n                    }\n                }\n            }\n            work_queue_size--;\n        }\n        });\n\n    int max_visited_size = 0;\n    int *visited_ptr = Kokkos::View<int*>(visited).data();\n    for(int i = 0; i < N; i++){\n        max_visited_size = max_visited_size < visited_ptr[i]? visited_ptr[i] : max_visited_size;\n    }\n    return max_visited_size;\n}",
            "// TODO: Implement me!\n}",
            "// TODO: Your code here\n    // You can define local variables and use the `int` and `bool` data types\n\n    Kokkos::View<int*, Kokkos::HostSpace> compSize(\"compSize\", N);\n    Kokkos::View<bool*, Kokkos::HostSpace> visited(\"visited\", N);\n\n    Kokkos::parallel_for(\"bfsInit\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i) {\n        compSize(i) = 1;\n        visited(i) = false;\n    });\n\n    Kokkos::parallel_for(\"bfs\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i) {\n        if (!visited(i)) {\n            int compCurr = i;\n            visited(i) = true;\n            for (int j = 0; j < N; j++) {\n                if (A(i, j)) {\n                    if (!visited(j)) {\n                        compCurr += compSize(j);\n                        visited(j) = true;\n                    }\n                    compSize(i) += compSize(j);\n                }\n            }\n            compSize(i) = compCurr;\n        }\n    });\n\n    int largestComponentSize = 0;\n    for (int i = 0; i < N; i++) {\n        if (compSize(i) > largestComponentSize) {\n            largestComponentSize = compSize(i);\n        }\n    }\n\n    return largestComponentSize;\n}",
            "// TODO: write code to solve this problem\n}",
            "// TODO: Replace this with your code\n\treturn 0;\n}",
            "// Create an array of booleans on the GPU, indicating if the vertex has been visited yet\n  Kokkos::View<bool*> visited(\"visited\", N);\n  Kokkos::deep_copy(visited, false);\n\n  // Create a map from each vertex to the vertex in its largest component\n  Kokkos::View<int*> map(\"map\", N);\n  Kokkos::deep_copy(map, -1);\n\n  // Create a stack of vertices to visit\n  Kokkos::View<int*> stack(\"stack\", N);\n  Kokkos::deep_copy(stack, -1);\n  int stack_size = 0;\n\n  // Kokkos parallel_for\n  Kokkos::parallel_for(\"graph\", N, KOKKOS_LAMBDA(const int& i) {\n    if (visited(i)) {\n      return;\n    }\n    visited(i) = true;\n    map(i) = i;\n    stack(stack_size++) = i;\n    while (stack_size) {\n      const int current = stack(--stack_size);\n      for (int j = 0; j < N; j++) {\n        if (!visited(j) && A(current, j)) {\n          visited(j) = true;\n          map(j) = map(current);\n          stack(stack_size++) = j;\n        }\n      }\n    }\n  });\n\n  // Sum the number of vertices in each component\n  Kokkos::View<int*> component_sizes(\"component_sizes\", N);\n  Kokkos::deep_copy(component_sizes, 0);\n  Kokkos::parallel_for(\"graph\", N, KOKKOS_LAMBDA(const int& i) {\n    Kokkos::atomic_add(&component_sizes(map(i)), 1);\n  });\n\n  int max_component_size = 0;\n  int largest_component_vertex = 0;\n  Kokkos::parallel_reduce(\"graph\", N, KOKKOS_LAMBDA(const int& i, int& max_component_size) {\n    if (component_sizes(i) > max_component_size) {\n      max_component_size = component_sizes(i);\n      largest_component_vertex = i;\n    }\n  }, Kokkos::Max<int>(max_component_size));\n  return max_component_size;\n}",
            "// TODO: Implement this function\n    return -1;\n}",
            "Kokkos::View<int*> vertex_coloring(\"vertex_coloring\", N);\n  Kokkos::View<int*> vertex_coloring_next(\"vertex_coloring_next\", N);\n\n  Kokkos::parallel_for(\n    \"init_coloring\",\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      vertex_coloring(i) = i;\n    }\n  );\n\n  int iteration = 0;\n  Kokkos::parallel_for(\n    \"BFS\",\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      int v = i;\n      for (int j = 0; j < N; j++) {\n        if (i!= j && A(i, j)!= 0) {\n          int u = j;\n          while (vertex_coloring(v)!= vertex_coloring(u)) {\n            vertex_coloring_next(v) = vertex_coloring(u);\n            v = vertex_coloring(v);\n          }\n        }\n      }\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"swap_coloring\",\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      int v = i;\n      int u = vertex_coloring_next(i);\n      while (v!= u) {\n        vertex_coloring_next(v) = vertex_coloring_next(u);\n        v = vertex_coloring_next(v);\n        u = vertex_coloring_next(u);\n      }\n    }\n  );\n\n  int max_color = 0;\n  Kokkos::parallel_reduce(\n    \"max_color\",\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA(const int i, int &update) {\n      update = Kokkos::max(vertex_coloring_next(i), update);\n    },\n    Kokkos::Max<int>(max_color)\n  );\n\n  return max_color + 1;\n}",
            "Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> component_sizes(\"component_sizes\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> component_ids(\"component_ids\", N);\n  Kokkos::View<bool*, Kokkos::LayoutRight, Kokkos::HostSpace> visited(\"visited\", N);\n\n  // initialize arrays\n  Kokkos::parallel_for(\n    \"initialize arrays\",\n    Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      component_sizes(i) = 1;\n      component_ids(i) = i;\n      visited(i) = false;\n    }\n  );\n\n  // for each vertex, if it's not already visited, explore its component\n  Kokkos::parallel_for(\n    \"bfs\",\n    Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      // if already visited, skip this vertex\n      if (visited(i)) {\n        return;\n      }\n\n      // initialize stack of vertices to explore\n      std::stack<int> stack;\n      stack.push(i);\n      visited(i) = true;\n      while (!stack.empty()) {\n        int j = stack.top();\n        stack.pop();\n\n        // update size of component containing j\n        int component_id = component_ids(j);\n        int component_size = component_sizes(component_id);\n        component_sizes(component_id) = component_size + 1;\n\n        // explore neighbors of j\n        for (int k = 0; k < N; k++) {\n          if (A(j, k) == 1 && visited(k) == false) {\n            stack.push(k);\n            visited(k) = true;\n            component_ids(k) = component_id;\n          }\n        }\n      }\n    }\n  );\n\n  // find the largest component\n  int max_component_size = 0;\n  int max_component_id = 0;\n  for (int i = 0; i < N; i++) {\n    if (component_sizes(i) > max_component_size) {\n      max_component_size = component_sizes(i);\n      max_component_id = i;\n    }\n  }\n\n  // return the number of vertices in the largest component\n  return max_component_size;\n}",
            "// Create a map to determine which vertices are reachable from each vertex\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> reachableMap(\"reachableMap\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [=] (const int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i][j]) {\n\t\t\t\treachableMap[i] = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Use Kokkos::parallel_scan to compute the size of the largest connected component in reachableMap\n\tint largestComponentSize;\n\tKokkos::parallel_scan(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [=] (const int i, int &size, bool final) {\n\t\tif (final) {\n\t\t\tlargestComponentSize = size;\n\t\t} else {\n\t\t\tsize += reachableMap[i];\n\t\t}\n\t});\n\t// Subtract 1 to convert the size of the largest connected component to the number of vertices\n\tlargestComponentSize -= 1;\n\n\treturn largestComponentSize;\n}",
            "/* Create a mask of the largest component.\n       The final mask will be a boolean vector\n       of the same size as the number of rows in the adjacency matrix A.\n       For example, for the above input, it will look like:\n\n\t\t\t[0, 1, 0, 0]\n    */\n\n    /* TODO: Implement me */\n\t// Create a 1D view of the mask\n\tKokkos::View<bool*> mask(\"mask\", N);\n\t// Set all elements to false\n\tKokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n\t\t\t\t\t\t KOKKOS_LAMBDA(int i) {\n\t\t\t\t\t\t\t mask(i) = false;\n\t\t\t\t\t\t });\n\n\tKokkos::fence();\n\n\tint count = 1;\n\t// If the element is in the largest component\n\tKokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n\t\t\t\t\t\t KOKKOS_LAMBDA(int i) {\n\t\t\t\t\t\t\t if (mask(i) == false) {\n\t\t\t\t\t\t\t\t bool isInLargestComponent = false;\n\t\t\t\t\t\t\t\t for (int j = 0; j < N; j++) {\n\t\t\t\t\t\t\t\t\t // Check if the neighboring element is also in the largest component\n\t\t\t\t\t\t\t\t\t // If not, the element is not in the largest component\n\t\t\t\t\t\t\t\t\t if (mask(j) == false && A(i, j) == 1) {\n\t\t\t\t\t\t\t\t\t\t isInLargestComponent = true;\n\t\t\t\t\t\t\t\t\t\t break;\n\t\t\t\t\t\t\t\t\t }\n\t\t\t\t\t\t\t\t }\n\t\t\t\t\t\t\t\t if (isInLargestComponent) {\n\t\t\t\t\t\t\t\t\t // Set the element to true\n\t\t\t\t\t\t\t\t\t mask(i) = true;\n\t\t\t\t\t\t\t\t\t // Increment the count\n\t\t\t\t\t\t\t\t\t count++;\n\t\t\t\t\t\t\t\t }\n\t\t\t\t\t\t\t }\n\t\t\t\t\t\t });\n\n\tKokkos::fence();\n\n    // Return the number of elements in the largest component\n    return count;\n}",
            "int largestComponent = 0;\n  // Fill in the rest of the code here...\n\n  return largestComponent;\n}",
            "using ExecPolicy = Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>, Kokkos::IndexType<int>>;\n  using Member = Kokkos::Member<ExecPolicy, int>;\n\n  Kokkos::View<int*, Kokkos::HostSpace> V(\"V\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> numComponents(\"numComponents\", N);\n\n  Kokkos::parallel_for(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i) {\n      V(i) = i;\n    });\n\n  Kokkos::parallel_for(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) {\n          if (i!= j) {\n            if (V(i) < V(j)) {\n              V(i) = V(j);\n            }\n            if (V(i) > V(j)) {\n              V(j) = V(i);\n            }\n          }\n        }\n      }\n    });\n\n  Kokkos::parallel_for(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) {\n          if (i!= j) {\n            if (V(i) < V(j)) {\n              V(i) = V(j);\n            }\n            if (V(i) > V(j)) {\n              V(j) = V(i);\n            }\n          }\n        }\n      }\n    });\n\n  int maxV = -1;\n  Kokkos::parallel_reduce(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i, int &local_max) {\n      local_max = std::max(local_max, V(i));\n    },\n    Kokkos::Max<int>(maxV));\n\n  Kokkos::parallel_for(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i) {\n      if (V(i) == maxV) {\n        numComponents(i) = 1;\n      } else {\n        numComponents(i) = 0;\n      }\n    });\n\n  Kokkos::parallel_for(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) {\n          if (i!= j) {\n            if (V(i) < V(j)) {\n              V(i) = V(j);\n            }\n            if (V(i) > V(j)) {\n              V(j) = V(i);\n            }\n          }\n        }\n      }\n    });\n\n  int maxNumComp = -1;\n  Kokkos::parallel_reduce(ExecPolicy(0, N),\n    KOKKOS_LAMBDA(const Member &i, int &local_max) {\n      local_max = std::max(local_max, numComponents(i));\n    },\n    Kokkos::Max<int>(maxNumComp));\n\n  return maxNumComp;\n}",
            "int *graph = new int[N * N];\n  int *visited = new int[N];\n\n  int largestComponentSize = 0;\n  for (int v = 0; v < N; v++) {\n    visited[v] = 0;\n  }\n  int index = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      graph[index] = A(i, j);\n      index++;\n    }\n  }\n\n  for (int u = 0; u < N; u++) {\n    if (visited[u] == 0) {\n      int count = 0;\n      std::queue<int> queue;\n      queue.push(u);\n      visited[u] = 1;\n      while (!queue.empty()) {\n        int u = queue.front();\n        queue.pop();\n        count++;\n        for (int v = 0; v < N; v++) {\n          if (graph[u * N + v] == 1 && visited[v] == 0) {\n            queue.push(v);\n            visited[v] = 1;\n          }\n        }\n      }\n      if (count > largestComponentSize) {\n        largestComponentSize = count;\n      }\n    }\n  }\n  return largestComponentSize;\n}",
            "//TODO: Implement this function\n\tint largestComponent = 0;\n\t\n\t// Create a Kokkos array of 1's with the size of the array A\n\tKokkos::View<int*> componentSize(\"componentSize\", N);\n\t// Loop through the array and count the number of vertices in each component\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponentSize[i] = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j)!= 0) {\n\t\t\t\tcomponentSize[i]++;\n\t\t\t}\n\t\t}\n\t}\n\t// Loop through the array and find the largest component\n\tfor (int i = 0; i < N; i++) {\n\t\tif (componentSize[i] > largestComponent) {\n\t\t\tlargestComponent = componentSize[i];\n\t\t}\n\t}\n\t\n\treturn largestComponent;\n}",
            "int* componentSizes = new int[N];\n\tint largestComponent = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponentSizes[i] = 1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A(i, j) == 1) {\n\t\t\t\tcomponentSizes[i]++;\n\t\t\t}\n\t\t}\n\t\tif (componentSizes[i] > largestComponent) {\n\t\t\tlargestComponent = componentSizes[i];\n\t\t}\n\t}\n\n\tint* largestComponentVertices = new int[largestComponent];\n\tint currentLargestComponentVertex = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (componentSizes[i] == largestComponent) {\n\t\t\tlargestComponentVertices[currentLargestComponentVertex++] = i;\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < currentLargestComponentVertex; j++) {\n\t\t\tif (largestComponentVertices[j] == i) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A(i, largestComponentVertices[j]) == 1) {\n\t\t\t\tcomponentSizes[i]++;\n\t\t\t}\n\t\t}\n\t\tif (componentSizes[i] == largestComponent) {\n\t\t\tlargestComponentVertices[currentLargestComponentVertex++] = i;\n\t\t}\n\t}\n\n\tdelete[] componentSizes;\n\tdelete[] largestComponentVertices;\n\n\treturn currentLargestComponentVertex;\n}",
            "// TODO: replace this with your code\n\t\n}",
            "using graph_row_view_t = Kokkos::View<const int*, Kokkos::LayoutStride, Kokkos::HostSpace>;\n\n  // Create a view of the rows of A to make it easier to iterate over them.\n  graph_row_view_t A_row_view(A.data(), N, N);\n\n  // Create a view to hold the number of vertices in the largest component.\n  Kokkos::View<int, Kokkos::HostSpace> largest_component_size(\"largest_component_size\", 1);\n  Kokkos::View<int, Kokkos::HostSpace> largest_component_size_scratch(\"largest_component_size_scratch\", 1);\n\n  // Initialize the largest component size to zero.\n  Kokkos::deep_copy(largest_component_size, 0);\n\n  // Loop over the rows of A\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t i) {\n    // Create a new view to hold the component size.\n    Kokkos::View<int, Kokkos::HostSpace> component_size(\"component_size\", 1);\n    // Initialize the component size to zero.\n    Kokkos::deep_copy(component_size, 0);\n\n    // If the vertex in row i has already been visited, skip it.\n    if (component_size(0) == 0) {\n      // Visit the vertex in row i.\n      component_size(0) = 1;\n\n      // Create a stack to keep track of the vertices to visit.\n      std::stack<int> stack;\n\n      // Push the vertex in row i onto the stack.\n      stack.push(i);\n\n      while (stack.size() > 0) {\n        // Pop the next vertex to visit off the stack.\n        int next_vertex = stack.top();\n        stack.pop();\n\n        // For each neighbor of the vertex in row next_vertex...\n        for (size_t j = 0; j < N; ++j) {\n          // If the neighbor is not already in the component...\n          if (A_row_view(next_vertex, j) && component_size(0) < A_row_view(next_vertex, j)) {\n            // Push the neighbor onto the stack.\n            stack.push(j);\n            // Add 1 to the component size.\n            component_size(0) += 1;\n          }\n        }\n      }\n\n      // Update the largest component size.\n      Kokkos::View<int, Kokkos::HostSpace> component_size_scratch(\"component_size_scratch\", 1);\n      Kokkos::deep_copy(component_size_scratch, 0);\n      Kokkos::parallel_reduce(1, KOKKOS_LAMBDA(const int&, int& lmax) {\n        lmax = Kokkos::max(lmax, component_size(0));\n      }, Kokkos::RangePolicy<Kokkos::HostSpace>(0, 1), component_size_scratch);\n\n      // Use an atomic compare-and-swap operation to update the largest component size.\n      Kokkos::atomic_compare_exchange_strong(&largest_component_size(0),\n                                             &largest_component_size_scratch(0),\n                                             Kokkos::max(largest_component_size_scratch(0), component_size_scratch(0)));\n    }\n  });\n\n  // Copy the largest component size from the device to the host.\n  int largest_component_size_host;\n  Kokkos::deep_copy(largest_component_size_host, largest_component_size);\n\n  return largest_component_size_host;\n}",
            "/* YOUR CODE HERE */\n}",
            "// Create a matrix of the same size as A, called C, where each element is 0\n\t// if the corresponding element in A is 0, and 1 otherwise.\n\n\t// Your code goes here!\n\n\t// Fill in the matrix C, which will be our workspace for this function.\n\t\n\t// Your code goes here!\n\n\t// Loop over each row in C and find the longest row in C.\n\t// Store the length of the longest row in the variable n.\n\t\n\t// Your code goes here!\n\n\t// Return the value of n.\n\t// Your code goes here!\n}",
            "// Your code goes here.\n}",
            "int *vertices = new int[N];\n  for (int i = 0; i < N; i++) {\n    vertices[i] = i;\n  }\n\n  Kokkos::View<int*> vertices_view(vertices, N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1) {\n        for (int k = 0; k < N; k++) {\n          if (A(j, k) == 1) {\n            vertices_view(i) = j;\n            break;\n          }\n        }\n      }\n    }\n  });\n  Kokkos::fence();\n\n  int *visited = new int[N];\n  for (int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n  int curr_size = 0;\n  int max_size = 0;\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    if (visited[i] == 0) {\n      int curr_vertex = i;\n      visited[i] = 1;\n      curr_size++;\n      while (curr_size > 0) {\n        for (int j = 0; j < N; j++) {\n          if (A(curr_vertex, j) == 1) {\n            if (visited[j] == 0) {\n              visited[j] = 1;\n              curr_size++;\n              curr_vertex = j;\n            }\n          }\n        }\n        curr_size--;\n      }\n      if (curr_size > max_size) {\n        max_size = curr_size;\n      }\n    }\n  });\n  Kokkos::fence();\n\n  delete[] visited;\n  delete[] vertices;\n\n  return max_size;\n}",
            "// TODO: your code here\n  int m, n;\n  m = n = N;\n  Kokkos::View<int*> A_host (\"A_host\", m*n);\n  Kokkos::View<int*> A_host_new (\"A_host_new\", m*n);\n  Kokkos::parallel_for (\"Kernel\", m*n, KOKKOS_LAMBDA (int i) {\n    A_host(i) = A(i / n, i % n);\n  });\n  Kokkos::fence();\n\n  int ans = 0;\n  Kokkos::parallel_for (\"Kernel\", m*n, KOKKOS_LAMBDA (int i) {\n    for (int j = 0; j < i; j++) {\n      if (A_host(i) && A_host(j) && A_host(i) == A_host(j)) {\n        A_host_new(i) = A_host_new(j);\n        A_host(i) = 0;\n      }\n    }\n    if (A_host(i) && A_host(i)!= i) {\n      A_host(i) = A_host_new(i);\n      A_host_new(i) = 0;\n    }\n  });\n  Kokkos::fence();\n\n  Kokkos::parallel_reduce (\"Kernel\", m*n, KOKKOS_LAMBDA (int i, int &val) {\n    if (A_host(i)) {\n      val++;\n    }\n  }, Kokkos::Sum<int>(ans));\n  Kokkos::fence();\n\n  return ans;\n}",
            "Kokkos::View<int*> flag(\"flag\", N);\n  Kokkos::View<int*> component_size(\"component_size\", N);\n  Kokkos::View<int*> component(\"component\", N);\n  Kokkos::View<int*> largest_component(\"largest_component\", N);\n  Kokkos::View<int*> component_counter(\"component_counter\", N);\n  Kokkos::View<int*> largest_component_counter(\"largest_component_counter\", N);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      flag[i] = 1;\n      component_size[i] = 1;\n      component[i] = i;\n      component_counter[i] = 1;\n    });\n\n  // Find the largest connected component\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      for (int j = i+1; j < N; j++) {\n        if (A[i][j] == 1 && flag[j] == 1) {\n          // Mark that we've been to j\n          flag[j] = 0;\n          // Update the component size of i\n          component_size[i]++;\n          // Find the component number of j\n          int k = component[j];\n          // Update the component number of j\n          component[j] = i;\n          // Update the component size of k\n          component_size[k] += component_size[j];\n        }\n      }\n    });\n\n  // Find the largest component\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      // Find the component number of i\n      int k = component[i];\n      // Update the component size\n      component_size[k]++;\n    });\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      // Find the component number of i\n      int k = component[i];\n      // Update the largest component number\n      largest_component[k] = component_size[k];\n    });\n\n  // Find the largest component number\n  int largest_component_number = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i, int &largest_component_number) {\n      if (largest_component[i] > largest_component_number) {\n        largest_component_number = largest_component[i];\n      }\n    },\n    largest_component_counter);\n\n  // Determine the number of vertices in the largest component\n  int num_largest_components = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i, int &num_largest_components) {\n      if (largest_component[i] == largest_component_number) {\n        num_largest_components++;\n      }\n    },\n    largest_component_counter);\n\n  return num_largest_components;\n}",
            "int *component_id = new int[N];\n\tint *visited = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponent_id[i] = i;\n\t\tvisited[i] = 0;\n\t}\n\tint largest_component_id = 0;\n\tint largest_component_size = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = 1;\n\t\tint current_id = i;\n\t\tint current_size = 1;\n\t\twhile (1) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(current_id, j) &&!visited[j]) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcomponent_id[j] = i;\n\t\t\t\t\tcurrent_id = j;\n\t\t\t\t\tcurrent_size++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (component_id[current_id] == i) break;\n\t\t}\n\t\tif (current_size > largest_component_size) {\n\t\t\tlargest_component_id = i;\n\t\t\tlargest_component_size = current_size;\n\t\t}\n\t}\n\tint result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component_id[i] == largest_component_id) result++;\n\t}\n\tdelete[] component_id;\n\tdelete[] visited;\n\treturn result;\n}",
            "/* TODO */\n  Kokkos::View<int*> vis(\"vis\",N);\n\n  class LCCalculator{\n  public:\n  Kokkos::View<int*> vis;\n  Kokkos::View<const int**> A;\n  LCCalculator(Kokkos::View<int*> vis, Kokkos::View<const int**> A): vis(vis),A(A){};\n\n  KOKKOS_INLINE_FUNCTION\n  void operator()(const int i) const {\n    if(vis(i)==0){\n      vis(i)=1;\n      int size=1;\n      for(int j=0;j<N;j++){\n\tif(A(i,j)){\n\t  if(vis(j)==0){\n\t    LCCalculator calculator(vis,A);\n\t    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(j,j+1),calculator);\n\t    size+=calculator.vis(j);\n\t  }\n\t}\n      }\n      vis(i)=size;\n    }\n  }\n  };\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N), LCCalculator(vis,A));\n  Kokkos::deep_copy(vis,vis);\n\n  auto max_val=Kokkos::Max<int>(vis);\n  int max=Kokkos::parallel_reduce(\"Max\", Kokkos::RangePolicy<Kokkos::Cuda>(0,N), Kokkos::Max<int>(vis), max_val);\n\n  return max;\n}",
            "// This part initializes a Kokkos View for an array of booleans.\n\t// It's a 1-D array, so it can be indexed using only one index.\n\t// It's initialized to all zeros.\n\t// This corresponds to the visited array in the previous example.\n\tKokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::deep_copy(visited, false);\n\tint largestComponentSize = 0;\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\t\t\t\t KOKKOS_LAMBDA(const int i) {\n\t\t// Avoids double counting. If the ith vertex has already been\n\t\t// visited, there's no need to recurse.\n\t\tif (visited(i)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Computes the size of the component rooted at the ith vertex.\n\t\tint componentSize = 1;\n\t\t// Marks the ith vertex as visited.\n\t\tvisited(i) = true;\n\n\t\t// Loops over all neighbors of the ith vertex.\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t// If there is an edge from the ith vertex to the jth vertex,\n\t\t\t// and the jth vertex has not been visited,\n\t\t\t// recursively call the function on the jth vertex.\n\t\t\tif (A(i, j) &&!visited(j)) {\n\t\t\t\tcomponentSize += largestComponent(A, j, visited);\n\t\t\t}\n\t\t}\n\t\t// This if-statement should only happen once per call to largestComponent.\n\t\tif (componentSize > largestComponentSize) {\n\t\t\tlargestComponentSize = componentSize;\n\t\t}\n\t});\n\tKokkos::fence();\n\treturn largestComponentSize;\n}",
            "// Your code here.\n\tKokkos::View<int**> component_sizes(\"component_sizes\", N, N);\n\tKokkos::parallel_for(\"init_component_sizes\", N, KOKKOS_LAMBDA(const int i) {\n\t\tcomponent_sizes(i, i) = 1;\n\t});\n\tKokkos::View<int**> adjacency_matrix_copy(\"adjacency_matrix_copy\", N, N);\n\tKokkos::parallel_for(\"copy_matrix\", N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tadjacency_matrix_copy(i, j) = A(i, j);\n\t\t}\n\t});\n\n\tfor (int k = 0; k < N; ++k) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (adjacency_matrix_copy(i, k) == 1) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (adjacency_matrix_copy(k, j) == 1) {\n\t\t\t\t\t\tcomponent_sizes(i, j) = std::max(component_sizes(i, j), std::min(component_sizes(i, k), component_sizes(k, j)));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint max_size = 0;\n\tKokkos::parallel_reduce(\"find_max_size\", N, KOKKOS_LAMBDA(const int i, int& lmax) {\n\t\tlmax = std::max(lmax, component_sizes(i, i));\n\t}, Kokkos::Max<int>(max_size));\n\n\treturn max_size;\n}",
            "//TODO\n  Kokkos::View<int*> vert;\n  Kokkos::View<int*> visited;\n\n  int largest_component = 0;\n\n  Kokkos::parallel_for(\"Largest Component Parallel\", \n\t\t       Kokkos::RangePolicy<Kokkos::Cuda>(0,N),\n\t\t       KOKKOS_LAMBDA(int i) {\n\t\t\t if(visited[i] == 0) {\n\t\t\t   int count = 0;\n\t\t\t   for(int j=0; j<N; j++) {\n\t\t\t     if(A[i][j] == 1) {\n\t\t\t       count++;\n\t\t\t     }\n\t\t\t   }\n\t\t\t   largest_component = max(count, largest_component);\n\t\t\t }\n\t\t       });\n\n  return largest_component;\n}",
            "const int max = 50; // TODO: Tune this.\n    Kokkos::View<int**> B(\"B\", N, N);\n\n    Kokkos::parallel_for(\"Initialize B\", N * N, KOKKOS_LAMBDA(int i) { B(i / N, i % N) = 0; });\n\n    Kokkos::parallel_for(\"Copy A to B\", N * N, KOKKOS_LAMBDA(int i) { B(i / N, i % N) = A(i / N, i % N); });\n\n    int count = 0;\n\n    for (int c = 0; c < max; c++) {\n        Kokkos::parallel_for(\"Mark connected nodes\", N * N, KOKKOS_LAMBDA(int i) {\n            if (B(i / N, i % N) == 1) {\n                for (int j = 0; j < N; j++) {\n                    if (B(i / N, j) == 1) {\n                        B(j, i % N) = 1;\n                    }\n                }\n            }\n        });\n\n        Kokkos::parallel_for(\"Count\", N * N, KOKKOS_LAMBDA(int i) { count += B(i / N, i % N); });\n\n        Kokkos::parallel_for(\"Flip nodes\", N * N, KOKKOS_LAMBDA(int i) {\n            if (B(i / N, i % N) == 1) {\n                B(i / N, i % N) = 0;\n                B(i % N, i / N) = 1;\n            }\n        });\n\n        Kokkos::parallel_for(\"Count again\", N * N, KOKKOS_LAMBDA(int i) { count += B(i / N, i % N); });\n\n        Kokkos::parallel_for(\"Update B\", N * N, KOKKOS_LAMBDA(int i) {\n            if (B(i / N, i % N) == 1) {\n                for (int j = 0; j < N; j++) {\n                    if (B(j, i % N) == 1) {\n                        B(i / N, j) = 1;\n                    }\n                }\n            }\n        });\n    }\n\n    return count;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n  using range_policy = Kokkos::RangePolicy<execution_space>;\n  using team_policy = Kokkos::TeamPolicy<execution_space>;\n  using team_member = Kokkos::TeamPolicy<execution_space>::member_type;\n\n  Kokkos::View<int**> A_copy(\"A_copy\", N, N);\n  Kokkos::parallel_for(\"copy_A_to_A_copy\", range_policy(0, N), KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      A_copy(i, j) = A(i, j);\n    }\n  });\n\n  Kokkos::View<int**> components(\"components\", N, N);\n  Kokkos::parallel_for(\"initialize_components\", range_policy(0, N), KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      components(i, j) = 0;\n    }\n  });\n\n  // TODO: parallelize this loop using Kokkos\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A_copy(i, j) == 0) {\n        components(i, j) = 1;\n      }\n    }\n  }\n\n  // TODO: parallelize this loop using Kokkos\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A_copy(i, j) == 1) {\n        if (components(i, j) > components(j, i)) {\n          components(i, j) = components(j, i);\n        }\n        else {\n          components(j, i) = components(i, j);\n        }\n      }\n    }\n  }\n\n  int count = 0;\n  int max = 0;\n\n  // TODO: parallelize this loop using Kokkos\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (components(i, j) == 0) {\n        count++;\n      }\n      else if (max < components(i, j)) {\n        max = components(i, j);\n      }\n    }\n  }\n\n  return count;\n}",
            "// TODO: insert code here.\n}",
            "// TODO: Fill in code to compute the largest component of the graph A.\n    // Return the size of the largest component of the graph.\n    // Use Kokkos to parallelize.\n\n    Kokkos::View<int*> flag(\"flag\", N);\n    Kokkos::deep_copy(flag, 0);\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) && (i < j)) {\n                flag(i) = 1;\n                break;\n            }\n        }\n    });\n\n    Kokkos::View<int*> comp(\"comp\", N);\n    Kokkos::deep_copy(comp, 0);\n\n    Kokkos::View<int*> max_comp(\"max_comp\", 1);\n    Kokkos::deep_copy(max_comp, 0);\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) && (i < j)) {\n                if (flag(j) == 0) {\n                    comp(i) = 1;\n                    break;\n                }\n            }\n        }\n    });\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n        if (flag(i)) {\n            if (comp(i) == 0) {\n                comp(i) = 1;\n            }\n        }\n    });\n\n    Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i, int &max_comp) {\n        if (comp(i) > max_comp) {\n            max_comp = comp(i);\n        }\n    }, max_comp);\n\n    return max_comp;\n}",
            "// your code here\n  // int* adjacencyArray = new int[N*N];\n  int* adjacencyArray = (int*) malloc(sizeof(int) * N * N);\n  for(size_t i = 0; i < N; ++i){\n    for(size_t j = 0; j < N; ++j){\n      adjacencyArray[i*N + j] = A(i,j);\n    }\n  }\n\n  int numComponents = 0;\n  int componentSize = 1;\n  int* vis = new int[N];\n  for(int i = 0; i < N; ++i){\n    vis[i] = 0;\n  }\n\n  int root = 0;\n  while(root < N){\n    if(vis[root] == 1){\n      root++;\n      continue;\n    }\n    int temp = root;\n    int maxSize = 0;\n    while(1){\n      if(vis[temp] == 1){\n        break;\n      }\n      vis[temp] = 1;\n      componentSize++;\n      if(adjacencyArray[temp*N + temp] == 1){\n        temp = temp;\n      } else {\n        for(int j = 0; j < N; ++j){\n          if(adjacencyArray[temp*N + j] == 1 && vis[j] == 0){\n            temp = j;\n            break;\n          }\n        }\n      }\n      if(maxSize < componentSize){\n        maxSize = componentSize;\n      }\n    }\n    componentSize = 0;\n    if(numComponents < maxSize){\n      numComponents = maxSize;\n    }\n  }\n\n  // int* adjacencyArray = new int[N*N];\n  // for(size_t i = 0; i < N; ++i){\n  //   for(size_t j = 0; j < N; ++j){\n  //     adjacencyArray[i*N + j] = A(i,j);\n  //   }\n  // }\n  //\n  // int maxSize = 0;\n  // int* vis = new int[N];\n  // for(int i = 0; i < N; ++i){\n  //   vis[i] = 0;\n  // }\n  // int* component = new int[N];\n  // int* root = new int[N];\n  // for(int i = 0; i < N; ++i){\n  //   root[i] = i;\n  // }\n  //\n  // for(int i = 0; i < N; ++i){\n  //   if(vis[i] == 1){\n  //     continue;\n  //   }\n  //   int temp = i;\n  //   int componentSize = 0;\n  //   while(1){\n  //     vis[temp] = 1;\n  //     componentSize++;\n  //     int newTemp = temp;\n  //     for(int j = 0; j < N; ++j){\n  //       if(adjacencyArray[temp*N + j] == 1 && vis[j] == 0){\n  //         newTemp = j;\n  //         break;\n  //       }\n  //     }\n  //     if(newTemp == temp){\n  //       break;\n  //     }\n  //     temp = newTemp;\n  //   }\n  //   if(maxSize < componentSize){\n  //     maxSize = componentSize;\n  //   }\n  // }\n\n  return numComponents;\n}",
            "using T = int;\n    using ExecPolicy = Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>;\n    using MemberType = Kokkos::TeamPolicy<ExecPolicy::member_type>::member_type;\n    Kokkos::View<T**> adjMatrix(\"adjMatrix\", N, N);\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        for (int j = 0; j < N; ++j) {\n            adjMatrix(i, j) = A(i, j);\n        }\n    });\n\n    Kokkos::View<T*> componentSizes(\"componentSizes\", N);\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        componentSizes(i) = 0;\n    });\n\n    Kokkos::View<T*> componentMap(\"componentMap\", N);\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        componentMap(i) = i;\n    });\n\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        for (int j = 0; j < N; ++j) {\n            if (i < j && adjMatrix(i, j) == 1) {\n                componentMap(j) = componentMap(i);\n            }\n        }\n    });\n\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        if (componentMap(i) == i) {\n            for (int j = 0; j < N; ++j) {\n                if (adjMatrix(i, j) == 1) {\n                    componentSizes(i) += 1;\n                }\n            }\n        }\n    });\n\n    Kokkos::parallel_for(ExecPolicy(0, N), KOKKOS_LAMBDA (int i) {\n        if (componentMap(i)!= i) {\n            componentSizes(componentMap(i)) += componentSizes(i);\n        }\n    });\n\n    T largestComponentSize = 0;\n    Kokkos::parallel_reduce(ExecPolicy(0, N), KOKKOS_LAMBDA (int i, T& localMax) {\n        localMax = (componentSizes(i) > localMax)? componentSizes(i) : localMax;\n    }, Kokkos::Max<T>(largestComponentSize));\n\n    return largestComponentSize;\n}",
            "// TODO\n    return -1;\n}",
            "// TODO: Your code goes here!\n\n\treturn 0;\n}",
            "// Define a Kokkos view\n\tKokkos::View<int**> B(\"B\", N, N);\n\n\t// Initialize B\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N), KOKKOS_LAMBDA(const int i, const int j) {\n\t\tB(i, j) = A(i, j);\n\t});\n\tKokkos::fence();\n\n\t// Initialize the number of components\n\tKokkos::View<int> numComponents(\"numComponents\", 1);\n\tKokkos::deep_copy(numComponents, 0);\n\n\t// While there is more than one component, remove them\n\twhile(numComponents(0) > 1) {\n\t\t// Remove one component\n\t\tKokkos::View<int> currComponent(\"currComponent\", 1);\n\t\tKokkos::deep_copy(currComponent, 0);\n\n\t\t// Find the largest component\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N), KOKKOS_LAMBDA(const int i, const int j) {\n\t\t\tif(B(i, j) > 0) {\n\t\t\t\tint min = B(i, j);\n\t\t\t\tfor(int k = 0; k < N; k++) {\n\t\t\t\t\tif(B(i, k) > 0 && B(i, k) < min) {\n\t\t\t\t\t\tmin = B(i, k);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcurrComponent(0) = min;\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\n\t\t// Remove the component\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N), KOKKOS_LAMBDA(const int i, const int j) {\n\t\t\tB(i, j) = 0;\n\t\t\tif(B(i, j) == currComponent(0)) {\n\t\t\t\tB(i, j) = 0;\n\t\t\t\tfor(int k = 0; k < N; k++) {\n\t\t\t\t\tB(i, k) = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\n\t\t// Reduce the number of components\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N), KOKKOS_LAMBDA(const int i, const int j) {\n\t\t\tif(B(i, j) > 0) {\n\t\t\t\tnumComponents(0)++;\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\t}\n\treturn numComponents(0);\n}",
            "int largestComponentSize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tstd::vector<int> queue;\n\t\tstd::vector<bool> visited(N, false);\n\t\tqueue.push_back(i);\n\t\tvisited[i] = true;\n\t\tint curSize = 1;\n\t\twhile (queue.size() > 0) {\n\t\t\tint cur = queue.back();\n\t\t\tqueue.pop_back();\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(cur, j) == 1 &&!visited[j]) {\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\tcurSize++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlargestComponentSize = std::max(largestComponentSize, curSize);\n\t}\n\n\treturn largestComponentSize;\n}",
            "const auto policy = Kokkos::RangePolicy<Kokkos::Serial, int>(0, N);\n\tKokkos::View<int*, Kokkos::HostSpace> degrees(\"degrees\", N);\n\n\tKokkos::parallel_for(policy, [&](int i) {\n\t\tint sum = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t\tdegrees(i) = sum;\n\t});\n\n\tKokkos::View<int*, Kokkos::HostSpace> largest_component_sizes(\"largest_component_sizes\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> components(\"components\", N);\n\n\tint largest_component_size = 0;\n\tint largest_component = 0;\n\tKokkos::parallel_for(policy, [&](int i) {\n\t\tint curr_component_size = 0;\n\t\tint curr_component = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(degrees(j) == degrees(i)) {\n\t\t\t\tcurr_component = j;\n\t\t\t\tcurr_component_size += 1;\n\t\t\t}\n\t\t}\n\t\tlargest_component_sizes(i) = curr_component_size;\n\t\tcomponents(i) = curr_component;\n\t});\n\n\tfor(int i = 0; i < N; ++i) {\n\t\tif(largest_component_sizes(i) > largest_component_size) {\n\t\t\tlargest_component_size = largest_component_sizes(i);\n\t\t\tlargest_component = components(i);\n\t\t}\n\t}\n\n\tint num_vertices = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tif(largest_component == components(i)) {\n\t\t\tnum_vertices += 1;\n\t\t}\n\t}\n\n\treturn num_vertices;\n}",
            "// TODO\n    return 0;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n  using memory_space    = Kokkos::DefaultExecutionSpace::memory_space;\n  using view_type       = Kokkos::View<int*, memory_space>;\n\n  view_type vertex_id(\"vertex_id\", N); // 0, 1, 2, 3\n  Kokkos::deep_copy(vertex_id, -1); // -1, -1, -1, -1\n  view_type largest_component_size(\"largest_component_size\", 1); // 0\n  Kokkos::deep_copy(largest_component_size, 0); // 0\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    if (vertex_id(i) >= 0)\n      return;\n\n    // DFS\n    int id = 0;\n    int current = i;\n    int next = -1;\n    while (current >= 0) {\n      for (int j = 0; j < N; j++) {\n        if (A(current, j))\n          next = j;\n      }\n      if (next >= 0) {\n        vertex_id(next) = id;\n        current = next;\n        next = -1;\n      } else {\n        current = -1;\n      }\n    }\n  });\n\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& num_vertices) {\n    int id = vertex_id(i);\n    if (id >= 0) {\n      if (id > num_vertices)\n        num_vertices = id;\n    }\n  }, Kokkos::RangePolicy<execution_space>(0, 1), Kokkos::Min<int>(largest_component_size));\n\n  Kokkos::deep_copy(largest_component_size, 0);\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& num_vertices) {\n    int id = vertex_id(i);\n    if (id >= 0)\n      num_vertices++;\n  }, Kokkos::RangePolicy<execution_space>(0, 1), Kokkos::Max<int>(largest_component_size));\n\n  Kokkos::deep_copy(vertex_id, -1);\n\n  return largest_component_size();\n}",
            "using Kokkos::deep_copy;\n\tusing Kokkos::create_mirror_view;\n\n\t// Create an array for tracking the number of vertices in each component.\n\tKokkos::View<int**> C(\"Component\", N, N);\n\tdeep_copy(C, 0);\n\n\t// Create mirror views of C for the host to access.\n\tauto C_host = create_mirror_view(C);\n\tauto A_host = create_mirror_view(A);\n\n\t// Run the first pass of the algorithm on the host.\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A_host(i, j) == 1) {\n\t\t\t\tC_host(i, j) = 1;\n\t\t\t\tif (j > 0) {\n\t\t\t\t\tC_host(i, j - 1) = 1;\n\t\t\t\t}\n\t\t\t\tif (i > 0) {\n\t\t\t\t\tC_host(i - 1, j) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Deep copy C_host back to C.\n\tdeep_copy(C, C_host);\n\n\t// Run the second pass of the algorithm on the device.\n\t// You can use Kokkos::parallel_for to parallelize over the loop below.\n\t// You can use Kokkos::single to parallelize the inner loop.\n\t// You can use a Kokkos::View to get the number of connected components.\n\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (C(i, j) == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "Kokkos::View<int*> B(\"B\", N);\n    Kokkos::View<int*> color(\"color\", N);\n    Kokkos::View<int*> queue(\"queue\", N);\n    Kokkos::parallel_for(\"component_1\", Kokkos::RangePolicy<Kokkos::Cuda>(0,N),\n        KOKKOS_LAMBDA(const int& i) {\n            B[i] = 1;\n            color[i] = 0;\n            queue[i] = i;\n        }\n    );\n    Kokkos::parallel_for(\"component_2\", Kokkos::RangePolicy<Kokkos::Cuda>(0,N),\n        KOKKOS_LAMBDA(const int& i) {\n            for (int j = 0; j < N; ++j) {\n                if (A(i,j) == 1) {\n                    B[i] += B[j];\n                    if (color[j] == 0) {\n                        queue[j] = i;\n                    }\n                }\n            }\n        }\n    );\n    Kokkos::parallel_for(\"component_3\", Kokkos::RangePolicy<Kokkos::Cuda>(0,N),\n        KOKKOS_LAMBDA(const int& i) {\n            if (color[i] == 0) {\n                int q = i;\n                int count = 1;\n                while (queue[q]!= q) {\n                    int tmp = q;\n                    q = queue[q];\n                    queue[tmp] = tmp;\n                    count++;\n                }\n                color[q] = 1;\n                for (int j = 0; j < N; ++j) {\n                    if (A(q,j) == 1) {\n                        B[j] = count;\n                    }\n                }\n            }\n        }\n    );\n    int max = 0;\n    for (int i = 0; i < N; ++i) {\n        if (B[i] > max) {\n            max = B[i];\n        }\n    }\n    return max;\n}",
            "return 0;\n}",
            "// TODO: Implement\n  return 0;\n}",
            "// Compute the transpose of the adjacency matrix.\n\tKokkos::View<int**> AT(\"AT\", N, N);\n\tKokkos::parallel_for(\"transpose\", N, KOKKOS_LAMBDA(const int &row) {\n\t\tfor (int col = 0; col < N; col++) {\n\t\t\tAT(col, row) = A(row, col);\n\t\t}\n\t});\n\tKokkos::fence();\n\n\t// Get the number of vertices in the largest connected component of A.\n\tint largestComponent = 0;\n\tKokkos::parallel_reduce(\"largest_component\", N, KOKKOS_LAMBDA(const int &row, int &component) {\n\t\tint numConnected = 0;\n\t\tfor (int col = 0; col < N; col++) {\n\t\t\tif (A(row, col) == 1) {\n\t\t\t\tnumConnected++;\n\t\t\t}\n\t\t}\n\n\t\t// Update the largest connected component if the current row is larger.\n\t\tif (numConnected > component) {\n\t\t\tcomponent = numConnected;\n\t\t}\n\t}, largestComponent);\n\tKokkos::fence();\n\n\treturn largestComponent;\n}",
            "// TODO: Implement\n\n\treturn -1;\n}",
            "Kokkos::View<int*> flag(\"flag\", N);\n  Kokkos::deep_copy(flag, 0);\n  int num_components = 1;\n  Kokkos::parallel_for(\n    \"largest_component\",\n    Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int k) {\n      if (flag[k] == 0) {\n        Kokkos::parallel_for(\n          Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n          KOKKOS_LAMBDA(int i) {\n            if (A[i][k] == 1) {\n              flag[i] = 1;\n            }\n          });\n        num_components++;\n      }\n    });\n\n  return num_components;\n}",
            "/* TODO: implement the function */\n\tint* visited = new int[N];\n\tfor(size_t i=0;i<N;i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\tint largest_component_size = 0;\n\tfor(size_t i=0;i<N;i++) {\n\t\tint curr_size = 0;\n\t\tif(visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tcurr_size++;\n\t\t\tfor(size_t j=0;j<N;j++) {\n\t\t\t\tif(visited[j] == 0 && A(i,j) == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcurr_size++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(curr_size > largest_component_size) {\n\t\t\t\tlargest_component_size = curr_size;\n\t\t\t}\n\t\t}\n\t}\n\treturn largest_component_size;\n}",
            "//TODO: Write your code here.\n  int maxComp = 0;\n  Kokkos::View<int*,Kokkos::HostSpace> visited(\"visited\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int &i) {\n      if (visited(i) == 0) {\n          int comp = 0;\n          Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int &j) {\n              if (A(i, j) == 1 && visited(j) == 0) {\n                  comp++;\n                  Kokkos::single(Kokkos::PerThread(i), [&](){\n                      visited(j) = 1;\n                  });\n              }\n          });\n          Kokkos::single(Kokkos::PerThread(i), [&](){\n              if (comp > maxComp)\n                  maxComp = comp;\n          });\n      }\n  });\n  return maxComp;\n}",
            "// TODO: implement\n  return 0;\n}",
            "// Your code here.\n    // Remember to use Kokkos to access A in parallel.\n    // Do not call any Kokkos routines that involve copying memory, such as Kokkos::deep_copy().\n\n    // Initialize data\n    Kokkos::View<int*> componentSize(\"componentSize\", N);\n    Kokkos::View<int*> component(\"component\", N);\n    Kokkos::View<int*> numComponents(\"numComponents\", 1);\n    Kokkos::View<int**> temp(\"temp\", N, N);\n    Kokkos::parallel_for( \"initComponentSize\", N, KOKKOS_LAMBDA(int i) {\n        componentSize(i) = 1;\n    });\n    Kokkos::deep_copy(component, componentSize);\n\n    Kokkos::deep_copy(temp, 0);\n    Kokkos::parallel_for( \"DFS\", N, KOKKOS_LAMBDA(int i) {\n        for (int j = 0; j < N; j++) {\n            if (A(i, j) == 1) {\n                if (componentSize(i) < componentSize(j)) {\n                    temp(i, j) = 1;\n                    temp(j, i) = 1;\n                }\n            }\n        }\n    });\n\n    Kokkos::parallel_for( \"unionComponent\", N, KOKKOS_LAMBDA(int i) {\n        for (int j = 0; j < N; j++) {\n            if (temp(i, j) == 1) {\n                componentSize(j) = componentSize(i) + componentSize(j);\n                component(j) = component(i);\n            }\n        }\n    });\n\n    // Find the maximum\n    int max = 0;\n    Kokkos::View<int*> max_component(\"max_component\", 1);\n    Kokkos::parallel_for( \"max_component\", N, KOKKOS_LAMBDA(int i) {\n        if (componentSize(i) > max) {\n            max = componentSize(i);\n            max_component(0) = component(i);\n        }\n    });\n    Kokkos::deep_copy(numComponents, 0);\n    Kokkos::parallel_for( \"numComponents\", N, KOKKOS_LAMBDA(int i) {\n        if (component(i) == max_component(0)) numComponents(0)++;\n    });\n    Kokkos::fence();\n\n    int max_comp = numComponents(0);\n    return max_comp;\n}",
            "Kokkos::View<int*> coloring(\"coloring\", N);\n\tKokkos::View<int*> adjacency(\"adjacency\", N);\n\tKokkos::View<int*> ccount(\"ccount\", N);\n\n\t// Set up adjacency.\n\t// adjacency[i] = index into coloring of vertex i.\n\t// If vertex i is in a coloring group, then adjacency[i] is -1.\n\tfor(int i = 0; i < N; i++) {\n\t\tadjacency[i] = -1;\n\t}\n\n\t// BFS algorithm.\n\t// TODO: parallelize\n\t// TODO: use a queue data structure for better performance.\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tif(coloring[i] == 0) {\n\t\t\tint cur = i;\n\t\t\tint next = adjacency[cur];\n\t\t\twhile(next!= -1) {\n\t\t\t\tcoloring[cur] = 1;\n\t\t\t\tccount[cur]++;\n\t\t\t\tcur = next;\n\t\t\t\tnext = adjacency[cur];\n\t\t\t}\n\t\t}\n\t});\n\n\t// Set up adjacency.\n\t// adjacency[i] = index into coloring of vertex i.\n\t// If vertex i is in a coloring group, then adjacency[i] is -1.\n\tfor(int i = 0; i < N; i++) {\n\t\tif(adjacency[i] == -1) {\n\t\t\tint cur = i;\n\t\t\tint next = adjacency[cur];\n\t\t\twhile(next!= -1) {\n\t\t\t\tccount[cur]++;\n\t\t\t\tcur = next;\n\t\t\t\tnext = adjacency[cur];\n\t\t\t}\n\t\t}\n\t}\n\n\t// Compute the maximum.\n\tKokkos::View<int*> max(\"max\");\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& max_) {\n\t\tmax_ = Kokkos::max(max_, ccount[i]);\n\t}, max);\n\tint max_val = Kokkos::create_mirror_view(max);\n\tKokkos::deep_copy(max_val, max);\n\treturn max_val;\n}",
            "// Implement this function\n  return -1;\n}",
            "// Create views for the adjacency matrix A and component sizes\n\tKokkos::View<int**> b(\"B\", N, N);\n\tKokkos::View<int*> c(\"C\", N);\n\n\t// Create a parallel loop over all indices i and j of the adjacency matrix A\n\t// and copy it into B\n\tKokkos::parallel_for(Kokkos::MDRangePolicy<Kokkos::Rank<2>>({0, 0}, {N, N}),\n\t\t\t     KOKKOS_LAMBDA (const int& i, const int& j) {\n\t\t\t\t     b(i, j) = A(i, j);\n\t\t\t     });\n\n\t// Kokkos::View<int*>::HostMirror will give you a Kokkos View of the data\n\t// that is a host-side version of the same data, which you can use to\n\t// access the data in a Kokkos parallel_for.\n\t// Calling deep_copy() will copy the data from the device into the host.\n\tKokkos::View<int*>::HostMirror b_host = Kokkos::create_mirror_view(b);\n\tb_host.deep_copy(b);\n\n\tKokkos::View<int*>::HostMirror c_host = Kokkos::create_mirror_view(c);\n\tc_host.deep_copy(c);\n\n\t// Run a sequential loop over all indices i of the adjacency matrix A and\n\t// copy the value of the largest component into C.\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint comp_size = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (b_host(i, j) == 1) {\n\t\t\t\tcomp_size += 1;\n\t\t\t\tb_host(i, j) = 0;\n\t\t\t}\n\t\t}\n\t\tc_host(i) = comp_size;\n\t}\n\n\t// Call deep_copy() to copy the updated data from the host to the device.\n\t// (b is the device version of b_host)\n\tb.deep_copy(b_host);\n\tc.deep_copy(c_host);\n\n\t// Create a parallel loop over all indices i of the component sizes C,\n\t// and find the component with the largest number of vertices.\n\tKokkos::View<int*> max(\"max\", 1);\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Rank<1>>({0}, {N}),\n\t\t\t\tKOKKOS_LAMBDA(const int i, int& max_val) {\n\t\t\t\t\tif (c(i) > max_val) {\n\t\t\t\t\t\tmax_val = c(i);\n\t\t\t\t\t}\n\t\t\t\t}, max);\n\n\t// Return the largest component size\n\treturn max(0);\n}",
            "using namespace Kokkos;\n\n  // Write code here...\n  //\n  // To help you get started, some useful constants and functions:\n\n  const int n = N;\n\n  // Allocate a matrix for the output\n  //\n  //   output: [1, 0, 0, 1]\n  //\n  View<int**> comp(\"components\", n, n);\n  // comp(i, j) = i + j * n;\n\n  // Allocate a matrix for the temporary workspace\n  //\n  //    temp: [1, 1, 1, 1]\n  //\n  View<int**> temp(\"temp\", n, n);\n  // temp(i, j) = 1;\n\n  // Return the number of vertices in the largest component of A\n  //\n  //",
            "// Initialize a vector of vertices to keep track of which ones are currently in the component.\n  Kokkos::View<int*> in_component(\"in_component\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t& i) {\n    in_component(i) = 1;\n  });\n  Kokkos::fence();\n\n  // Initialize a vector of vertices to keep track of which ones have already been visited.\n  Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t& i) {\n    visited(i) = 0;\n  });\n  Kokkos::fence();\n\n  // Iterate through the vertices of the graph, and if they have not yet been visited,\n  // check their neighbors.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t& i) {\n    if (visited(i) == 0) {\n      // Keep track of how many vertices in the component are currently in_component.\n      int count = 1;\n      // Set the vertex as visited.\n      visited(i) = 1;\n      // Check their neighbors.\n      for (size_t j = 0; j < N; j++) {\n        // If the neighbor is in the component, and has not been visited yet,\n        // check their neighbors.\n        if ((in_component(j) == 1) && (visited(j) == 0)) {\n          count += largestComponent(A, j, in_component, visited);\n        }\n      }\n      // If the component is larger than the largest component found so far,\n      // update the largest component value.\n      if (count > largest_component) {\n        largest_component = count;\n      }\n    }\n  });\n  Kokkos::fence();\n\n  // Return the number of vertices in the largest component.\n  return largest_component;\n}",
            "using ExecutionSpace = typename Kokkos::DefaultExecutionSpace;\n    Kokkos::View<int*, ExecutionSpace> size(\"size\", N);\n    Kokkos::View<int*, ExecutionSpace> level(\"level\", N);\n    Kokkos::View<int*, ExecutionSpace> parent(\"parent\", N);\n\n    // TODO: Implement using Kokkos to get the largest component of a graph\n\n    // Create the depth-first search\n\n    // Traverse the graph to find the size of each component\n\n    // Use the size of each component to compute the largest component\n\n    return 0;\n}",
            "Kokkos::View<int**> vertex_map(\"vertex_map\", N, N);\n  Kokkos::View<int*> vertex_map_buffer(\"vertex_map_buffer\", N);\n  Kokkos::View<int*> component_sizes(\"component_sizes\", N);\n\n  Kokkos::parallel_for(\"LargestComponent\", N, KOKKOS_LAMBDA (size_t i) {\n    for (size_t j = 0; j < N; j++) {\n      vertex_map(i, j) = (int)j;\n    }\n  });\n\n  // TODO: Implement the rest of the function.\n\n  return -1;\n}",
            "using ExecPolicy = Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>;\n  using MemberType = Kokkos::TeamPolicy<Kokkos::DefaultExecutionSpace>::member_type;\n\n  /* YOUR CODE GOES HERE*/\n}",
            "// TODO\n\treturn 0;\n}",
            "//\n\t// TODO: Implement this function.\n\t//\n\n\t// Hint: Use a Kokkos graph object to represent the graph.\n\t//   Graph graph(N, 0, 0);\n\t//   auto rowmap = graph.row_map;\n\t//   auto entries = graph.entries;\n\n\t// Hint: Use a Kokkos bitset to represent the \"visited\" set\n\t//   auto visited = Kokkos::Bitset<>::create();\n\n\t// Hint: Use a Kokkos view to compute the number of vertices in each connected component.\n\t//   auto components = Kokkos::View<int*>(\"components\", N);\n\n\treturn 0;\n}",
            "// TODO\n\treturn 0;\n}",
            "// Insert your solution here\n  return 0;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> componentSizes(\"componentSizes\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> componentIndices(\"componentIndices\", N);\n\tKokkos::View<bool*, Kokkos::HostSpace> used(\"used\", N);\n\tKokkos::View<bool*, Kokkos::HostSpace> stack(\"stack\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), [&](int i) {\n\t\tcomponentSizes(i) = 0;\n\t\tcomponentIndices(i) = i;\n\t\tused(i) = false;\n\t\tstack(i) = false;\n\t});\n\n\tKokkos::View<int*, Kokkos::HostSpace> componentSizeSums(\"componentSizeSums\", 1);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), [&](int i) {\n\t\tcomponentSizeSums(0) += componentSizes(i);\n\t});\n\n\tint largestComponentSize = Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), Kokkos::Max<int>(Kokkos::Max<int>(componentSizes(0), componentSizes(1))), Kokkos::Max<int>(componentSizes(2), componentSizes(3)));\n\n\tint largestComponentIndex = Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), Kokkos::Max<int>(Kokkos::Max<int>(componentIndices(0), componentIndices(1))), Kokkos::Max<int>(componentIndices(2), componentIndices(3)));\n\n\t// Recursively walk the component to find the largest component\n\t// Avoid loops by using a stack.\n\tKokkos::View<int*, Kokkos::HostSpace> stack(\"stack\", 1);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), [&](int i) {\n\t\tstack(0) = largestComponentIndex;\n\n\t\twhile (stack(0)!= -1) {\n\t\t\tif (!used(stack(0))) {\n\t\t\t\tcomponentSizes(stack(0)) = 1;\n\t\t\t\tstack(0) = componentIndices(stack(0));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tstack(0) = -1;\n\t\t\t}\n\t\t}\n\t});\n\n\treturn largestComponentSize;\n}",
            "// TODO 1: set up the graph adjacency list (adj)\n    std::vector<std::vector<int>> adj(N);\n\n    // TODO 2: set up the visited array (visited)\n    std::vector<bool> visited(N, false);\n\n    // TODO 3: set up the largest component size\n    int largestComponentSize = 0;\n\n    // TODO 4: set up the largest component vertex\n    int largestComponentVertex = 0;\n\n    // TODO 5: loop over all vertices in A\n    for (int i = 0; i < N; i++) {\n        // TODO 6: if i is not visited, add to the queue\n        if (!visited[i]) {\n            // TODO 7: add i to the queue\n            std::vector<int> queue = {i};\n\n            // TODO 8: while the queue is not empty\n            while (!queue.empty()) {\n                // TODO 9: pop the next vertex from the queue\n                int vertex = queue.back();\n                queue.pop_back();\n\n                // TODO 10: set visited[vertex] to true\n                visited[vertex] = true;\n\n                // TODO 11: add neighbors of vertex to the queue\n                for (int j = 0; j < N; j++) {\n                    if (!visited[j] && A(vertex, j)) {\n                        queue.push_back(j);\n                    }\n                }\n            }\n\n            // TODO 12: compare the size of this component to the largest\n            if (queue.size() > largestComponentSize) {\n                largestComponentSize = queue.size();\n                largestComponentVertex = i;\n            }\n        }\n    }\n\n    // TODO 13: return the largest component vertex\n    return largestComponentVertex;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> host_array(\"host_array\", N);\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> device_array(\"device_array\", N);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    int max = 0;\n    for (int j=0; j<N; j++) {\n      if (A(i,j) > 0) max += 1;\n    }\n    host_array(i) = max;\n  });\n\n  Kokkos::deep_copy(device_array, host_array);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    for (int j=0; j<i; j++) {\n      if (device_array(i) < device_array(j)) device_array(i) = device_array(j);\n    }\n  });\n\n  int max_val = 0;\n  for (int i=0; i<N; i++) {\n    if (max_val < device_array(i)) max_val = device_array(i);\n  }\n\n  return max_val;\n}",
            "// Your code goes here\n}",
            "int result;\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> componentSizes(\"componentSizes\", N);\n  Kokkos::parallel_for(\"largestComponent\", Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), [=] (int i) {\n    if (A(i,i) == 0)\n      componentSizes(i) = 0;\n    else {\n      int size = 0;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0)\n          size++;\n      }\n      componentSizes(i) = size;\n    }\n  });\n  Kokkos::parallel_reduce(\"largestComponent\", Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), [=] (int i, int& update) {\n    if (update < componentSizes(i))\n      update = componentSizes(i);\n  }, result);\n  return result;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\n  /* Create a list of vertex ids and initialize it to [0, 1,..., N - 1].\n     It is modified in the loop. */\n  Kokkos::View<int*> vlist(\"vlist\", N);\n  Kokkos::parallel_for(\n    \"init_list\",\n    Kokkos::RangePolicy<ExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) { vlist(i) = i; });\n  Kokkos::fence();\n\n  /* Loop until all edges have been processed. */\n  int largest_component = 0;\n  while (largest_component < N) {\n    /* Find a vertex v that is not in the current component.\n       It can be determined by looking at vlist.\n       If all vertices are in the component, then largest_component = N. */\n    int v = 0;\n    int v_old = 0;\n    Kokkos::parallel_reduce(\n      \"find_v\",\n      Kokkos::RangePolicy<ExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(int i, int& old_v) {\n        if (vlist(i) > 0) {\n          v = i;\n          v_old = old_v;\n        }\n      },\n      v);\n    Kokkos::fence();\n    if (v_old > v) {\n      v = v_old;\n    }\n    /* If we have seen all vertices, the component size is largest_component. */\n    if (v == 0) {\n      break;\n    }\n    /* Expand the current component to include all vertices reachable from v.\n       Update vlist and the component size.\n       Hint: use the BFS algorithm. */\n    Kokkos::parallel_for(\n      \"update_list\",\n      Kokkos::RangePolicy<ExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(int j) {\n        if (A(v, j) == 1) {\n          vlist(j) = vlist(v);\n        }\n      });\n    Kokkos::fence();\n    int cur_component_size = 0;\n    Kokkos::parallel_reduce(\n      \"cur_component\",\n      Kokkos::RangePolicy<ExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(int i, int& cur_size) {\n        if (vlist(i) == vlist(v)) {\n          ++cur_size;\n        }\n      },\n      cur_component_size);\n    Kokkos::fence();\n    /* Update the largest component size. */\n    largest_component = std::max(largest_component, cur_component_size);\n  }\n  return largest_component;\n}",
            "int local_vertices_in_component[N];\n\n  // TODO: Compute the number of vertices in the largest component\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA (const int& i) {\n      int c = 0;\n      // TODO: Update the number of vertices in the component i is in\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) {\n          // TODO: Update the number of vertices in the component i is in\n        }\n      }\n  });\n\n  int total_vertices_in_component = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA (const int& i, int& total) {\n      // TODO: Update the total number of vertices in all components\n  }, total_vertices_in_component);\n\n  return total_vertices_in_component;\n}",
            "// TODO\n\treturn 0;\n}",
            "// TODO: implement me!\n\treturn 0;\n}",
            "using Kokkos::View;\n\tusing Kokkos::parallel_for;\n\tusing Kokkos::RangePolicy;\n\n\tKokkos::View<int*, Kokkos::HostSpace> comp_sizes(\"component_sizes\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> comp_ids(\"component_ids\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> comp_idx(\"component_idx\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> comp_adj(\"component_adj\", N);\n\n\tKokkos::deep_copy(comp_sizes, 0);\n\tKokkos::deep_copy(comp_ids, 0);\n\tKokkos::deep_copy(comp_adj, 0);\n\tKokkos::deep_copy(comp_idx, 0);\n\n\t// Initialize component size and id arrays\n\tfor (int i = 0; i < N; i++) {\n\t\tcomp_sizes(i) = 1;\n\t\tcomp_ids(i) = i;\n\t}\n\n\t// Determine connected components by checking if vertices are reachable by going through any other vertex\n\tparallel_for(RangePolicy<int>(0, N),\n\t\t[&](int i) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t// Find the component id of vertex j\n\t\t\t\t\tint comp_id = comp_ids(j);\n\n\t\t\t\t\t// Find the component id of vertex i\n\t\t\t\t\tint comp_id_i = comp_ids(i);\n\n\t\t\t\t\t// If they're not in the same component, merge them\n\t\t\t\t\tif (comp_id!= comp_id_i) {\n\t\t\t\t\t\tcomp_ids(i) = comp_id;\n\n\t\t\t\t\t\t// If i's component is larger, set j's component to be i's\n\t\t\t\t\t\tif (comp_sizes(comp_id_i) >= comp_sizes(comp_id)) {\n\t\t\t\t\t\t\tcomp_ids(j) = comp_id_i;\n\t\t\t\t\t\t\tcomp_adj(j) = 1;\n\t\t\t\t\t\t\tcomp_sizes(comp_id) = comp_sizes(comp_id) + comp_sizes(comp_id_i);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Otherwise, set i's component to be j's\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tcomp_ids(i) = comp_id;\n\t\t\t\t\t\t\tcomp_adj(i) = 1;\n\t\t\t\t\t\t\tcomp_sizes(comp_id_i) = comp_sizes(comp_id) + comp_sizes(comp_id_i);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t// Find the largest component\n\tint max_comp = 0;\n\tint max_comp_size = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (comp_sizes(i) > max_comp_size) {\n\t\t\tmax_comp_size = comp_sizes(i);\n\t\t\tmax_comp = i;\n\t\t}\n\t}\n\n\t// Find the index of the largest component\n\tint max_comp_idx = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (comp_ids(i) == max_comp) {\n\t\t\tmax_comp_idx = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Count the number of vertices in the largest component\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (comp_ids(i) == max_comp) {\n\t\t\tcount++;\n\t\t}\n\t}",
            "// Write your code here\n  return 0;\n}",
            "// Your code here\n  return 0;\n}",
            "// TODO: implement this function\n}",
            "// Create views for the workspace arrays\n\t// The maximum number of vertices is N,\n\t// and the maximum number of edges is N*(N-1)/2\n\tint N_max = std::max(N, 10000);\n\tauto x = Kokkos::View<int*>(\"x\", N_max);\n\tauto lowlink = Kokkos::View<int*>(\"lowlink\", N_max);\n\tauto stack = Kokkos::View<int*>(\"stack\", N_max);\n\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int& v) {\n\t\t\tx(v) = 0;\n\t\t\tlowlink(v) = 0;\n\t\t}\n\t);\n\n\t// Use the depth-first search and Tarjan algorithm to compute the strongly connected components of the graph\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int& v) {\n\t\t\tif (x(v) == 0) {\n\t\t\t\tint i, w;\n\t\t\t\tint index = 0;\n\t\t\t\tstack(index++) = v;\n\t\t\t\tx(v) = 1;\n\t\t\t\tlowlink(v) = 1;\n\t\t\t\tfor (w = 0; w < N; w++) {\n\t\t\t\t\tif (A(v,w)!= 0) {\n\t\t\t\t\t\tif (x(w) == 0) {\n\t\t\t\t\t\t\tstack(index++) = w;\n\t\t\t\t\t\t\tx(w) = 1;\n\t\t\t\t\t\t\tlowlink(w) = lowlink(v) + 1;\n\t\t\t\t\t\t} else if (x(w) == 1) {\n\t\t\t\t\t\t\tlowlink(v) = std::min(lowlink(v), lowlink(w));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tint w;\n\t\t\t\twhile (1) {\n\t\t\t\t\tw = stack(--index);\n\t\t\t\t\tx(w) = 2;\n\t\t\t\t\tif (w == v) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\t// Compute the number of vertices in the largest component\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int& v, int& sum) {\n\t\t\tif (lowlink(v) == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t},\n\t\tKokkos::Sum<int>(N_max)\n\t);\n\n\treturn N;\n}",
            "// TODO: Fill in this function\n}",
            "int n_component = 0;\n  Kokkos::View<int*, Kokkos::HostSpace> visited(\"visited\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> comp(\"comp\", N);\n  int max_comp = 0;\n\n  Kokkos::parallel_for(\"LCC_for\", N, KOKKOS_LAMBDA(const int &i) {\n\t  if (visited(i) == 0) {\n\t\t  int comp_count = 1;\n\t\t  int curr_comp = 0;\n\t\t  std::queue<int> queue;\n\t\t  queue.push(i);\n\t\t  visited(i) = 1;\n\t\t  comp(i) = 0;\n\t\t  while (!queue.empty()) {\n\t\t\t  int curr = queue.front();\n\t\t\t  queue.pop();\n\t\t\t  for (int j = 0; j < N; j++) {\n\t\t\t\t  if (A(curr, j) == 1 && visited(j) == 0) {\n\t\t\t\t\t  visited(j) = 1;\n\t\t\t\t\t  comp(j) = curr_comp;\n\t\t\t\t\t  queue.push(j);\n\t\t\t\t\t  comp_count++;\n\t\t\t\t  }\n\t\t\t  }\n\t\t  }\n\t\t  curr_comp++;\n\t\t  if (max_comp < comp_count) {\n\t\t\t  max_comp = comp_count;\n\t\t  }\n\t  }\n  });\n\n  int curr_largest_component = 0;\n  for (int i = 0; i < N; i++) {\n\t  if (comp(i) == 0) {\n\t\t  curr_largest_component++;\n\t  }\n  }\n  return curr_largest_component;\n}",
            "// Your code goes here\n  int largestComponentSize = 0;\n  //int largestComponentSize = 1;\n  return largestComponentSize;\n}",
            "using LB = Kokkos::LayoutRight;\n    using CrsGraph = Kokkos::CrsGraph<int, LB>;\n\n    auto graph = CrsGraph();\n\n    Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::MemoryUnmanaged> colIdx(\"colIdx\", N);\n    Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::MemoryUnmanaged> rowPtr(\"rowPtr\", N + 1);\n    Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::MemoryUnmanaged> rowPtr_(\"rowPtr_\", N + 1);\n\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n        int count = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) > 0) {\n                colIdx(count) = j;\n                count++;\n            }\n        }\n        rowPtr(i) = count;\n    });\n\n    rowPtr(N) = N;\n    Kokkos::deep_copy(rowPtr_, rowPtr);\n\n    graph.create_blocked_graph_from_blocked_matrix(N, N, rowPtr_, colIdx);\n\n    // Find the largest strongly connected component in the graph\n    Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::MemoryUnmanaged> componentIds(\"componentIds\", N);\n\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n        componentIds(i) = i;\n    });\n\n    auto scc = Kokkos::create_staticcrsgraph<LB>(Kokkos::WithoutInitializing);\n    scc.template create_from_graph<Kokkos::CrsGraphConst>(graph);\n    Kokkos::TeamPolicy<Kokkos::DefaultExecutionSpace> policy(1, 1, N);\n    Kokkos::parallel_for(\"scc_loop\", policy, KOKKOS_LAMBDA(const Kokkos::TeamPolicy<Kokkos::DefaultExecutionSpace>::member_type& team) {\n        for (int i = team.league_rank(); i < N; i += team.league_size()) {\n            auto iBegin = scc.row_map(i);\n            auto iEnd = scc.row_map(i + 1);\n            for (int j = iBegin; j < iEnd; ++j) {\n                if (componentIds(i)!= componentIds(scc.entries(j))) {\n                    auto max = componentIds(i) > componentIds(scc.entries(j))? componentIds(i) : componentIds(scc.entries(j));\n                    auto min = componentIds(i) > componentIds(scc.entries(j))? componentIds(scc.entries(j)) : componentIds(i);\n                    Kokkos::single(Kokkos::PerThread(team), [=] {\n                        componentIds(min) = max;\n                    });\n                }\n            }\n        }\n    });\n\n    int maxId = -1;\n    int maxCount = -1;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n        if (componentIds(i) == i) {\n            if (maxCount < 1) {\n                maxCount = 1;\n                maxId = i;\n            }\n        }\n    });\n\n    Kokkos::fence();\n\n    return maxCount;\n}",
            "// TODO: Fill in code here\n  // You may assume the Kokkos BFS implementation is correct.\n  Kokkos::View<int*> comp(\"comp\", N);\n  Kokkos::View<int*> Q(\"Q\", N);\n  Kokkos::View<int*> Q_next(\"Q_next\", N);\n  Kokkos::View<int*> comp_next(\"comp_next\", N);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    comp[i] = i;\n  });\n  int max_size = 1;\n  int num_iter = 0;\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    int size = 0;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& j) {\n      if (A(i, j)!= 0)\n        size++;\n    });\n    if (size > max_size)\n      max_size = size;\n  });\n  while (num_iter < max_size) {\n    int num_comp = 0;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      if (comp[i] == i)\n        num_comp++;\n    });\n    int max_comp = 0;\n    Kokkos::parallel_for(num_comp, KOKKOS_LAMBDA (const int& i) {\n      int size = 0;\n      Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& j) {\n        if (comp[j] == i)\n          size++;\n      });\n      if (size > max_comp)\n        max_comp = size;\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      Q[i] = 0;\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      if (comp[i] == i) {\n        Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& j) {\n          if (A(i, j)!= 0 && comp[j]!= i) {\n            Q[i] = 1;\n          }\n        });\n      }\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      Q_next[i] = 0;\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      if (Q[i] == 1) {\n        Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& j) {\n          if (A(i, j)!= 0) {\n            Q_next[j] = 1;\n          }\n        });\n      }\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      comp_next[i] = 0;\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      if (Q_next[i] == 1) {\n        comp_next[i] = i;\n      } else {\n        comp_next[i] = comp[i];\n      }\n    });\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n      comp[i] = comp_next[i];\n    });\n    num_iter++;\n  }\n  int max_comp = 0;\n  Kokkos::parallel_for(num_comp, KOKKOS_LAMBDA (const int& i) {\n    int size = 0;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& j) {\n      if (comp[j] == i",
            "// TODO: Your code here\n\n}",
            "// Your code here!\n\n\treturn -1;\n}",
            "// TODO: implement\n\treturn 0;\n}",
            "// your code goes here\n\tint result = 0;\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA (const int& i, int& l_result) {\n\t\t\tint visited[N];\n\t\t\tfor(int j = 0; j < N; ++j) visited[j] = 0;\n\t\t\tint queue[N];\n\t\t\tint front = 0;\n\t\t\tint rear = 0;\n\t\t\tqueue[rear++] = i;\n\t\t\tvisited[i] = 1;\n\t\t\tint size = 0;\n\t\t\twhile(front!= rear) {\n\t\t\t\tint u = queue[front++];\n\t\t\t\tsize++;\n\t\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\t\tif(visited[j] == 0 && A(u, j) == 1) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tqueue[rear++] = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tl_result = std::max(l_result, size);\n\t\t},\n\t\tresult\n\t);\n\treturn result;\n}",
            "// Get the execution space.\n  using execution_space = typename Kokkos::DefaultExecutionSpace;\n\n  // Define the functor that runs on each thread.\n  struct LargestComponentFunctor {\n    const int* const adj;\n    const int N;\n    const int M;\n    int* largest;\n\n    // This constructor just saves the input parameters to be used in the operator().\n    LargestComponentFunctor(Kokkos::View<const int**> A, int N, int* l)\n        : adj(A.data()), N(N), M(A.extent(0)), largest(l) {}\n\n    // This is the operator that will run in parallel.\n    KOKKOS_INLINE_FUNCTION\n    void operator()(const int& i) const {\n\n      // i is the id of this thread.\n      // adj[i*N + j] is the value at the ith row and jth column of the matrix.\n      // largest[i] is a pointer to the output variable for this thread.\n      // This is the \"parallel for\" loop for each thread.\n      for (int j = 0; j < M; ++j) {\n        if (i!= j && adj[i*N + j]!= 0 && adj[i*N + j] < *largest) {\n          *largest = adj[i*N + j];\n        }\n      }\n    }\n  };\n\n  // Get the number of threads.\n  // This is the number of iterations in the parallel for loop.\n  const int Nthreads = Kokkos::DefaultExecutionSpace::concurrency();\n\n  // Create an array of ints to store the largest value seen so far in each thread.\n  // We will use Kokkos::View to allocate the memory and to parallelize the loop.\n  Kokkos::View<int*, execution_space> largest(Kokkos::ViewAllocateWithoutInitializing(\"largest\"), Nthreads);\n  // Initialize each value to N.\n  Kokkos::parallel_for(Nthreads, [=](int i) {\n    largest(i) = N;\n  });\n\n  // Run the functor.\n  LargestComponentFunctor functor(A, N, largest.data());\n  Kokkos::parallel_for(Nthreads, functor);\n\n  // Find the maximum value in the array.\n  int max = 0;\n  for (int i = 0; i < Nthreads; ++i) {\n    max = std::max(max, largest(i));\n  }\n  // Return the max value.\n  return max;\n}",
            "// Declare variables\n\tsize_t maxSize = 0;\n\tsize_t numVerts = 0;\n\tauto adjacency = A;\n\n\t// Create an array of flags that indicate whether each vertex has been visited yet.\n\tKokkos::View<int*, Kokkos::HostSpace> flag(\"flag\", N);\n\n\t// Initialize the flags.\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N),\n\t\t[&](const int i) {\n\t\t\tflag(i) = 0;\n\t\t}\n\t);\n\tKokkos::fence();\n\n\t// Visit each vertex and its unvisited neighbors and set their flags to 1.\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N),\n\t\t[&](const int i) {\n\t\t\tif (flag(i) == 0) {\n\t\t\t\tsize_t size = 1;\n\t\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N),\n\t\t\t\t\t[&](const int j) {\n\t\t\t\t\t\tif (adjacency(i, j) == 1 && flag(j) == 0) {\n\t\t\t\t\t\t\tsize++;\n\t\t\t\t\t\t\tflag(j) = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t);\n\t\t\t\tKokkos::fence();\n\t\t\t\tif (size > maxSize) {\n\t\t\t\t\tmaxSize = size;\n\t\t\t\t\tnumVerts = 1;\n\t\t\t\t}\n\t\t\t\telse if (size == maxSize) {\n\t\t\t\t\tnumVerts++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\tKokkos::fence();\n\n\t// Return the size of the largest connected component.\n\treturn maxSize;\n}",
            "Kokkos::View<int*> flags(\"flags\", N);\n\tauto flag_policy = Kokkos::RangePolicy<Kokkos::ExecPolicy<Kokkos::DefaultExecutionSpace>>(0, N);\n\tauto init_functor = KOKKOS_LAMBDA(const int i) {\n\t\tflags(i) = 0;\n\t};\n\tKokkos::parallel_for(\"init\", flag_policy, init_functor);\n\n\tint largest_component = 0;\n\n\twhile (true) {\n\t\tint new_component = 1;\n\t\tauto mark_component = KOKKOS_LAMBDA(const int i) {\n\t\t\tint sum = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tsum += A(i, j);\n\t\t\t}\n\t\t\tif (sum == 0) {\n\t\t\t\tflags(i) = -1;\n\t\t\t} else {\n\t\t\t\tflags(i) = 1;\n\t\t\t\tnew_component++;\n\t\t\t}\n\t\t};\n\t\tKokkos::parallel_for(\"mark\", flag_policy, mark_component);\n\n\t\tint num_nodes_marked = 0;\n\t\tauto mark_next = KOKKOS_LAMBDA(const int i) {\n\t\t\tif (flags(i) == 1) {\n\t\t\t\tflags(i) = 2;\n\t\t\t\tnum_nodes_marked++;\n\t\t\t}\n\t\t};\n\t\tKokkos::parallel_for(\"mark next\", flag_policy, mark_next);\n\t\tnew_component += num_nodes_marked;\n\n\t\tif (new_component == 0) {\n\t\t\tbreak;\n\t\t} else {\n\t\t\tlargest_component = std::max(largest_component, new_component);\n\t\t}\n\n\t\tauto clear_old = KOKKOS_LAMBDA(const int i) {\n\t\t\tif (flags(i) == 2) {\n\t\t\t\tflags(i) = 0;\n\t\t\t}\n\t\t};\n\t\tKokkos::parallel_for(\"clear old\", flag_policy, clear_old);\n\t}\n\n\treturn largest_component;\n}",
            "// TODO: YOUR CODE HERE!\n\n\treturn 0;\n}",
            "// Create a Kokkos view for the vector of vertex components.\n\t// A component is defined by its index in the vector, and the vertices in the component.\n\tKokkos::View<std::vector<std::vector<int>>**> components(\"components\", N, N);\n\n\t// Initialize the components. Each vertex is in its own component.\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int v) {\n\t\tcomponents(v, v).push_back(v);\n\t});\n\n\t// For each edge...\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int v) {\n\t\tfor (int w = v + 1; w < N; w++) {\n\t\t\t// If v and w are adjacent...\n\t\t\tif (A(v, w) > 0) {\n\t\t\t\t// Merge their components.\n\t\t\t\t// Find the component containing v.\n\t\t\t\tint component_of_v = -1;\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (std::find(components(i, v).begin(), components(i, v).end(), v)!= components(i, v).end()) {\n\t\t\t\t\t\tcomponent_of_v = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Find the component containing w.\n\t\t\t\tint component_of_w = -1;\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (std::find(components(i, w).begin(), components(i, w).end(), w)!= components(i, w).end()) {\n\t\t\t\t\t\tcomponent_of_w = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Merge the components.\n\t\t\t\t// Add all the vertices in component_of_w to component_of_v.\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (std::find(components(i, w).begin(), components(i, w).end(), w)!= components(i, w).end()) {\n\t\t\t\t\t\tfor (int vertex : components(i, w)) {\n\t\t\t\t\t\t\tcomponents(component_of_v, vertex).push_back(vertex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Remove the component of w.\n\t\t\t\tcomponents(component_of_w, w).clear();\n\t\t\t}\n\t\t}\n\t});\n\n\t// Find the largest component.\n\tint largest_component = 0;\n\tfor (int v = 0; v < N; v++) {\n\t\tif (components(v, v).size() > largest_component) {\n\t\t\tlargest_component = components(v, v).size();\n\t\t}\n\t}\n\n\treturn largest_component;\n}",
            "// Insert code here.\n}",
            "// Insert your code here\n  return 0;\n}",
            "using ExecSpace = Kokkos::DefaultExecutionSpace;\n\tKokkos::View<int*, ExecSpace> vertex_colors(\"vertex_colors\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tvertex_colors(i) = i;\n\t});\n\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1 && i < j) {\n\t\t\t\tvertex_colors(j) = vertex_colors(i);\n\t\t\t}\n\t\t}\n\t});\n\n\tint max_color = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &update) {\n\t\tupdate = (vertex_colors(i) > update)? vertex_colors(i) : update;\n\t}, Kokkos::Max<int>(max_color));\n\n\treturn max_color + 1;\n}",
            "// Kokkos::parallel_for requires the loop index to be an integer, so we need to pass a pointer\n    // to the index to the lambda function.\n    int *idx = new int;\n    *idx = 0;\n\n    // Set up the parallel_for object with the lambda function and loop bounds.\n    Kokkos::parallel_for(\"largestComponent\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n            [&] (int i) {\n                if (A(i, *idx)) {\n                    *idx = i;\n                }\n            }\n    );\n\n    // This is not thread-safe.\n    // int largestComponent = *idx;\n\n    int largestComponent;\n    Kokkos::View<int*> largestComponentKokkos(\"largestComponentKokkos\", 1);\n    Kokkos::deep_copy(largestComponentKokkos, *idx);\n\n    // Kokkos::View<int*> largestComponentKokkos(\"largestComponentKokkos\", 1);\n    // Kokkos::deep_copy(largestComponentKokkos, *idx);\n    // Kokkos::deep_copy(largestComponentKokkos, *idx);\n\n    // Kokkos::deep_copy(largestComponentKokkos, *idx);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    // Kokkos::deep_copy(largestComponent, largestComponentKokkos);\n\n    Kokkos::deep_copy(",
            "using view_t = Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace, Kokkos::MemoryTraits<Kokkos::Unmanaged>>;\n  view_t num_vertices(new int[N]); // on the host\n  view_t next_component(new int[N]); // on the host\n  view_t tmp(new int[N]); // on the host\n\n  // Init num_vertices\n  Kokkos::parallel_for(\"init num vertices\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n    num_vertices(i) = 1;\n  });\n  Kokkos::fence(); // Wait for kernel to finish\n\n  int num_components = 0;\n\n  while (true) {\n    // find largest component\n    int largest_component_size = 0;\n    int largest_component = 0;\n    Kokkos::parallel_reduce(\"find largest component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i, int& lgst) {\n      if (num_vertices(i) > lgst) {\n        lgst = num_vertices(i);\n        largest_component = i;\n      }\n    }, Kokkos::Max<int>(largest_component_size));\n\n    // No more components\n    if (largest_component_size == 0) {\n      break;\n    }\n\n    num_components++;\n\n    // Assign all vertices in the largest component to next_component\n    Kokkos::parallel_for(\"assign largest component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n      if (A(i, largest_component)) {\n        next_component(i) = 1;\n      } else {\n        next_component(i) = 0;\n      }\n    });\n\n    Kokkos::parallel_for(\"set num vertices\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n      if (next_component(i)) {\n        num_vertices(i) = largest_component_size;\n      }\n    });\n\n    Kokkos::parallel_for(\"set next component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n      if (next_component(i) &&!A(i, largest_component)) {\n        next_component(i) = 0;\n      }\n    });\n\n    // Compute intersection of next_component and num_vertices\n    Kokkos::parallel_for(\"intersect\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n      tmp(i) = next_component(i) & num_vertices(i);\n    });\n\n    Kokkos::parallel_for(\"set next component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& i) {\n      next_component(i) = tmp(i);\n    });\n  }\n\n  // Return the number of components\n  return num_components;\n}",
            "// TODO: replace this with your own implementation\n\t// Hint: you may find the following functions useful\n\t//   Kokkos::parallel_for()\n\t//   Kokkos::fence()\n\t//   Kokkos::single()\n\t//   Kokkos::atomic_fetch_add()\n\t//   Kokkos::View<int*, Kokkos::HostSpace>::pointer_on_device_t\n\t//   Kokkos::subview()\n\t//   Kokkos::deep_copy()\n\n\t// Create an NxN int array, C, to store the components of A.\n\tKokkos::View<int**> C(\"C\", N, N);\n\n\t// Initialize C to have the same values as A.\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& i) {\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& j) {\n\t\t\tC(i, j) = A(i, j);\n\t\t});\n\t});\n\n\t// Find the largest component using Kokkos.\n\tint largestComponent = 0;\n\tint numIterations = 0;\n\tint currSize = 0;\n\tbool noMoreComponents = false;\n\n\t// Loop until there are no more components, or too many iterations\n\twhile (!noMoreComponents && numIterations < N) {\n\t\t// Use Kokkos to perform BFS\n\t\t// The first time through, the components of C will have the same values as A\n\t\t// BFS will find connected components, and store them in C\n\n\t\t// TODO: perform BFS using Kokkos\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& i) {\n\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& j) {\n\t\t\t\tC(i, j) = A(i, j);\n\t\t\t});\n\t\t});\n\n\t\t// Now, C stores the components. For each component, find the largest size, and update largestComponent\n\t\t// (i, j) is a vertex in the largest component of A\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& i) {\n\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& j) {\n\t\t\t\tif (C(i, j) == 1) {\n\t\t\t\t\tcurrSize = 0;\n\t\t\t\t\t// Search for all vertices in the component\n\t\t\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int& k) {\n\t\t\t\t\t\tif (C(k, k) == 1) {\n\t\t\t\t\t\t\tcurrSize++;\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t\tKokkos::single(Kokkos::PerThread(Kokkos::DefaultExecutionSpace()), [&](){\n\t\t\t\t\t\tif (currSize > largestComponent) {\n\t\t\t\t\t\t\tlargestComponent = currSize;\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t});\n\t\t});\n\n\t\t// Check if there are any components left\n\t\t// If not, we've found the largest component\n\t\tnoMoreComponents = true;\n\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMB",
            "// TODO: Your code here!\n\n  return 0;\n}",
            "int largest_component = 0;\n\n  // Kokkos::View<int*> comp_count(\"component_count\", N);\n  // comp_count.assign(0);\n  // Kokkos::View<int*> comp(\"components\", N);\n  // comp.assign(0);\n  // Kokkos::View<int*> comp_size(\"component_size\", N);\n  // comp_size.assign(0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N), [&](const int i){\n    int largest_component_i = 0;\n    int comp_count_i = 0;\n    int comp_size_i = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) > 0) {\n        if (i == j) {\n          largest_component_i = 1;\n          comp_count_i = 1;\n          comp_size_i = 1;\n        }\n        else if (comp_count_i == 0) {\n          // Traverse the neighboring component\n          comp_count_i = 1;\n          comp_size_i = 1;\n          int component_j = j;\n          while (component_j >= 0) {\n            // Mark node component_j as visited\n            comp_size_i += 1;\n            for (int k = 0; k < N; ++k) {\n              if (A(component_j, k) > 0) {\n                if (comp(k) == 0) {\n                  // Mark node k as visited\n                  comp(k) = 1;\n                  component_j = k;\n                  break;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    comp_count(i) = comp_count_i;\n    comp_size(i) = comp_size_i;\n    largest_component = comp_size_i > largest_component? comp_size_i : largest_component;\n  });\n\n  Kokkos::View<int**> comp_count(\"component_count\", N, 1);\n  Kokkos::View<int**> comp_size(\"component_size\", N, 1);\n\n  // Print the number of components and the size of each component\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N), [&](const int i){\n    printf(\"i: %d comp_count: %d comp_size: %d\\n\", i, comp_count(i,0), comp_size(i,0));\n  });\n\n  return largest_component;\n}",
            "const int N_BLOCKS = 10;\n    const int BLOCK_SIZE = 10;\n\n    Kokkos::View<int*, Kokkos::HostSpace> block_counts(\"block_counts\", N_BLOCKS);\n\n    auto fill_block_counts_lambda = KOKKOS_LAMBDA(const int i) {\n        block_counts(i) = 0;\n        for(int j = i*BLOCK_SIZE; j < (i+1)*BLOCK_SIZE; j++) {\n            if(j < N) {\n                int count = 0;\n                for(int k = 0; k < N; k++) {\n                    if(A(j, k) == 1) {\n                        count++;\n                    }\n                }\n                block_counts(i) += count;\n            }\n        }\n    };\n\n    // Fill the block_counts array using a parallel Kokkos::RangePolicy\n    Kokkos::RangePolicy<Kokkos::Rank<2>> range(0, N_BLOCKS);\n    Kokkos::parallel_for(range, fill_block_counts_lambda);\n    Kokkos::fence();\n\n    // Find the largest block count\n    int max_count = 0;\n    for(int i = 0; i < N_BLOCKS; i++) {\n        if(block_counts(i) > max_count) {\n            max_count = block_counts(i);\n        }\n    }\n\n    return max_count;\n}",
            "// TODO: Your code here\n\tint comp_sz = 0;\n\tstd::vector<int> component_szs;\n\tstd::vector<int> visited(N, 0);\n\n\t// DFS\n\tstd::function<void(int, int)> dfs = [&](int v, int comp_id) {\n\t\tif (visited[v]!= 0) return;\n\t\tvisited[v] = comp_id;\n\t\tcomp_sz++;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A(v, i) == 1) {\n\t\t\t\tdfs(i, comp_id);\n\t\t\t}\n\t\t}\n\t};\n\n\t// Find largest component\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcomp_sz = 0;\n\t\t\tdfs(i, i + 1);\n\t\t\tcomponent_szs.push_back(comp_sz);\n\t\t}\n\t}\n\n\t// Find largest component\n\tstd::vector<int>::iterator largest_comp_sz_iter = std::max_element(component_szs.begin(), component_szs.end());\n\tint largest_component_sz = *largest_comp_sz_iter;\n\treturn largest_component_sz;\n}",
            "// TODO: implement\n  return 0;\n}",
            "Kokkos::View<int*> components(\"components\", N);\n\n    Kokkos::parallel_for(\"init_components\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA(const int& i) {\n        components(i) = i;\n    });\n\n    Kokkos::parallel_for(\"update_components\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA(const int& i) {\n        for(int j = 0; j < N; j++) {\n            if(A(i,j)) {\n                int c1 = components(i);\n                int c2 = components(j);\n                int cmin = std::min(c1, c2);\n                int cmax = std::max(c1, c2);\n                for(int k = 0; k < N; k++) {\n                    if(components(k) == cmax) {\n                        components(k) = cmin;\n                    }\n                }\n            }\n        }\n    });\n\n    Kokkos::View<int*> counts(\"counts\", N);\n    Kokkos::parallel_for(\"count_components\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA(const int& i) {\n        int c = components(i);\n        Kokkos::atomic_increment(&counts(c));\n    });\n\n    size_t max = 0;\n    for(int i = 0; i < N; i++) {\n        max = std::max(max, counts(i));\n    }\n\n    return max;\n}",
            "int num_threads = 4;\n\n\tKokkos::View<int**> V(Kokkos::ViewAllocateWithoutInitializing(\"V\"), N, N);\n\tKokkos::parallel_for(N, [&](int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tV(i,j) = 0;\n\t\t}\n\t});\n\n\tKokkos::parallel_for(N, [&](int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tV(i, j) = 1;\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::parallel_for(N, [&](int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (V(j, k) == 1) {\n\t\t\t\t\tV(i, k) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\tint largest = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int& max) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (V(i, j) == 1) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}, Kokkos::RangePolicy<Kokkos::OpenMP>(0, num_threads), largest);\n\n\treturn largest;\n}",
            "// YOUR CODE GOES HERE\n  int result;\n  int max_size = 0;\n\n  Kokkos::View<int**> comp(Kokkos::ViewAllocateWithoutInitializing(\"comp\"), N, N);\n  Kokkos::deep_copy(comp, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t       [&](const int i) {\n\t\t\t for(int j = 0; j < N; j++) {\n\t\t\t   if(i!= j) {\n\t\t\t     if(A(i, j)) {\n\t\t\t       comp(i, j) = 1;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t       });\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t       [&](const int i) {\n\t\t\t for(int j = 0; j < N; j++) {\n\t\t\t   if(i!= j) {\n\t\t\t     if(A(j, i)) {\n\t\t\t       comp(j, i) = 1;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\t\t       });\n\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\t  [&](const int i, int &max_size) {\n\t\t\t    int size = 0;\n\t\t\t    for(int j = 0; j < N; j++) {\n\t\t\t      if(comp(i, j)) {\n\t\t\t\tsize++;\n\t\t\t      }\n\t\t\t    }\n\t\t\t    if(size > max_size) {\n\t\t\t      max_size = size;\n\t\t\t    }\n\t\t\t  },\n\t\t\t  max_size);\n\n  return max_size;\n}",
            "// Your code here\n    return 0;\n}",
            "// TODO\n}",
            "// Your code here\n\n  return 0;\n}",
            "// Implement me!\n}",
            "int n_vertices = N;\n  Kokkos::View<bool**> component_sizes(\"component_sizes\", N, N);\n\n  Kokkos::parallel_for(N, [&](int i) {\n      for (int j = 0; j < N; ++j) {\n        if (A(i, j) == 1) {\n          component_sizes(i, j) = 1;\n        }\n      }\n  });\n\n  Kokkos::parallel_for(N, [&](int i) {\n    for (int j = 0; j < N; ++j) {\n      if (component_sizes(i, j) == 1) {\n        for (int k = 0; k < N; ++k) {\n          if (A(j, k) == 1) {\n            component_sizes(i, k) = 1;\n          }\n        }\n      }\n    }\n  });\n\n  Kokkos::parallel_for(N, [&](int i) {\n    for (int j = 0; j < N; ++j) {\n      if (component_sizes(i, j) == 1) {\n        for (int k = 0; k < N; ++k) {\n          if (component_sizes(i, k) == 1 && A(j, k) == 1) {\n            component_sizes(i, k) = 0;\n          }\n        }\n      }\n    }\n  });\n\n  Kokkos::parallel_for(N, [&](int i) {\n    for (int j = 0; j < N; ++j) {\n      if (component_sizes(i, j) == 0) {\n        component_sizes(i, j) = 1;\n      }\n    }\n  });\n\n  int largest_component_size = 0;\n  for (int i = 0; i < N; ++i) {\n    int component_size = 0;\n    for (int j = 0; j < N; ++j) {\n      component_size += component_sizes(i, j);\n    }\n    largest_component_size = std::max(largest_component_size, component_size);\n  }\n\n  return largest_component_size;\n}",
            "Kokkos::View<int**> B(\"B\", N, N);\n\tKokkos::deep_copy(B, A);\n\tauto comp = Kokkos::subview(B, Kokkos::ALL(), Kokkos::ALL());\n\n\tstruct LargestComponentFunctor {\n\t\tKokkos::View<int**> a;\n\t\tKokkos::View<int**> b;\n\n\t\tLargestComponentFunctor(Kokkos::View<int**> a, Kokkos::View<int**> b) :\n\t\t\ta(a), b(b) {\n\t\t}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator() (const int i, const int j) const {\n\t\t\tif (a(i,j) > 0) {\n\t\t\t\tb(i,j) = 1;\n\t\t\t\tb(j,i) = 1;\n\t\t\t}\n\t\t}\n\t};\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::TaggedParallel>(0, N, \"LargestComponent\"),\n\t\tLargestComponentFunctor(A, B));\n\tKokkos::fence();\n\n\tint largestComponent = 0;\n\tstruct MaxFunctor {\n\t\tKokkos::View<int**> b;\n\n\t\tMaxFunctor(Kokkos::View<int**> b) :\n\t\t\tb(b) {\n\t\t}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator() (const int i, const int j, int& val) const {\n\t\t\tif (b(i,j) > val) {\n\t\t\t\tval = b(i,j);\n\t\t\t}\n\t\t}\n\t};\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::TaggedParallel>(0, N, \"Max\"),\n\t\tMaxFunctor(B), Kokkos::Max<int>(largestComponent));\n\tKokkos::fence();\n\n\treturn largestComponent;\n}",
            "int num_components = 1;\n  Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (int i) {\n    visited(i) = 0;\n  });\n  Kokkos::View<int*> component_sizes(\"component_sizes\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (int i) {\n    component_sizes(i) = 0;\n  });\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (int i) {\n    // If node i has already been visited, we've already discovered its connected component and don't need to visit it again.\n    if (visited(i) == 0) {\n      Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (int j) {\n        // If there is an edge between node i and node j, and node j has not been visited, set node j's \"visited\" value to 1.\n        if (A(i, j) == 1 && visited(j) == 0) {\n          visited(j) = 1;\n        }\n      });\n      // Once we've visited all of node i's neighbors, add its size to its component size.\n      component_sizes(i)++;\n      while (visited(i) == 1) {\n        // Find any nodes connected to node i and mark them as visited.\n        Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (int j) {\n          if (A(i, j) == 1 && visited(j) == 0) {\n            visited(j) = 1;\n            // Increment component size by 1.\n            component_sizes(i)++;\n          }\n        });\n        // Once all neighbors of node i have been marked, set its \"visited\" value to 0 and move on to the next node.\n        visited(i) = 0;\n        i++;\n      }\n    }\n  });\n  // Find the component size of the largest connected component.\n  auto largest_size = Kokkos::subview(component_sizes, 0);\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(1, N), KOKKOS_LAMBDA (int i, int &l) {\n    if (component_sizes(i) > l) {\n      l = component_sizes(i);\n    }\n  }, Kokkos::Max<int>(largest_size));\n  // The number of vertices in the largest connected component is the same as the largest component size.\n  return largest_size();\n}",
            "// TODO\n\n  return 0;\n}",
            "// Implement this function\n}",
            "// Define the range of indices over which we will parallelize.\n    const int minIdx = 0;\n    const int maxIdx = static_cast<int>(N);\n\n    // Create the output array.\n    Kokkos::View<int*> vertexComponent(\"vertexComponent\", N);\n\n    // Create the functor which performs the work.\n    // The lambda function is called for each element in the range.\n    // In this case, it simply returns the component ID of the current vertex.\n    // We do this by using Kokkos::atomic_fetch_or. The atomic_fetch_or operation\n    // atomically ORs the current value of the given array element with the\n    // value that we pass in.\n    auto componentLabeler = KOKKOS_LAMBDA (const int& idx) {\n        int currentComponent = vertexComponent(idx);\n        for (int j = 0; j < N; ++j) {\n            if (A(idx, j) == 1) {\n                currentComponent |= vertexComponent(j);\n            }\n        }\n        Kokkos::atomic_fetch_or(&vertexComponent(idx), currentComponent);\n    };\n\n    // Perform the work.\n    Kokkos::parallel_for(\"componentLabeler\", minIdx, maxIdx, componentLabeler);\n    //Kokkos::fence();\n\n    // Compute the number of unique components by finding the maximum component ID.\n    // This assumes that the indices of the array are the component IDs.\n    int maxComponent = 0;\n    for (int i = 0; i < N; ++i) {\n        if (vertexComponent(i) > maxComponent) {\n            maxComponent = vertexComponent(i);\n        }\n    }\n\n    return maxComponent + 1;\n}",
            "// TODO: Fill in the body of this function.\n\n}",
            "// Your code goes here.\n\n    // Create a view of all the vertex degrees.\n\n    // Create a Kokkos::View to store the largest connected component size\n    Kokkos::View<int, Kokkos::LayoutLeft> max_component_size(\"max_component_size\", 1);\n\n    // Create a Kokkos::View of bools to store which vertices are part of the largest connected component.\n\n    // Set max_component_size to 0\n\n    // Use Kokkos::parallel_for to set the values in the bool array.\n\n    // Use Kokkos::parallel_for to find the largest connected component size.\n\n    // Return the value of max_component_size.\n    return 0;\n}",
            "Kokkos::View<int*> componentSizes(\"componentSizes\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [=] (const int i) {\n    // Count the number of vertices in the largest component reachable from vertex i.\n    int num_vertices = 0;\n    Kokkos::View<bool*> reachable_vertices(\"reachable_vertices\", N);\n    Kokkos::single(Kokkos::PerThread(reachable_vertices, num_vertices));\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [=] (const int j) {\n      if (A(i, j) == 1)\n        reachable_vertices(j) = true;\n    });\n    // Count the number of vertices that are reachable.\n    Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n        [=] (const int j, int& lsum) {\n          if (reachable_vertices(j))\n            ++lsum;\n        }, Kokkos::Sum<int>(num_vertices));\n    // Store the count in the componentSizes array.\n    componentSizes(i) = num_vertices;\n  });\n  // Find the maximum of all the component sizes.\n  int max_component_size = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n      [=] (const int i, int& lsum) {\n        if (componentSizes(i) > lsum)\n          lsum = componentSizes(i);\n      }, Kokkos::Max<int>(max_component_size));\n  // Return the maximum component size.\n  return max_component_size;\n}",
            "Kokkos::View<int*> component(\"component\", N);\n\n  // Your code here\n\n  return std::max_element(component.data(), component.data() + component.size()) - component.data();\n}",
            "int my_component = -1;\n  for (size_t i = 0; i < N; i++) {\n    Kokkos::parallel_for(\n        \"largestComponent\",\n        Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n        [&] (size_t j) {\n          if (A(i,j)) {\n            // TODO: Update my_component based on the value of A(i,j)\n            // (Hint: use the ternary operator,?:)\n            if (my_component < j)\n              my_component = j;\n          }\n        }\n    );\n    // TODO: Synchronize all threads in the parallel_for before continuing\n  }\n  return my_component;\n}",
            "/* Use Kokkos to create an array of N integers to store the size of the component each vertex belongs to.\n     The component size of vertex i is component[i] */\n  Kokkos::View<int*> component(\"component\", N);\n\n  /* Initialize the component array to hold N components of size 1 (size 0 indicates unvisited) */\n  Kokkos::parallel_for(\"initialize components\", N, KOKKOS_LAMBDA(int i) {\n    component(i) = 1;\n  });\n\n  /* For each unvisited vertex v, traverse the graph starting at v and visit all vertices reachable from v.\n     Set the component of each visited vertex to the component of v. */\n  Kokkos::parallel_for(\"traverse graph\", N, KOKKOS_LAMBDA(int v) {\n    /* Do not traverse if already visited */\n    if (component(v) == 0) {\n      return;\n    }\n\n    /* Create a stack to store the vertices to be visited */\n    std::stack<int> stack;\n\n    /* Add the starting vertex to the stack */\n    stack.push(v);\n\n    while (!stack.empty()) {\n      /* Get the current vertex */\n      int u = stack.top();\n      stack.pop();\n\n      /* Do not visit if already visited */\n      if (component(u) == 0) {\n        continue;\n      }\n\n      /* Mark the current vertex as visited */\n      component(u) = 0;\n\n      /* Iterate over the neighbors of u */\n      for (int i = 0; i < N; i++) {\n        /* If the neighbor is not a self-edge and has not been visited, add it to the stack */\n        if (i!= u && A(u, i) == 1 && component(i)!= 0) {\n          stack.push(i);\n        }\n      }\n    }\n  });\n\n  /* Iterate over the component array to find the largest component size */\n  Kokkos::parallel_reduce(\"find largest component size\", N, Kokkos::Max<int>(component),\n                          KOKKOS_LAMBDA(int i, int& max_comp) {\n    if (component(i) > max_comp) {\n      max_comp = component(i);\n    }\n  });\n\n  /* Return the largest component size */\n  return max_comp;\n}",
            "// Implement me!\n  return -1;\n}",
            "Kokkos::View<int*> v(Kokkos::ViewAllocateWithoutInitializing(\"vertices\"), N);\n\tKokkos::View<int*> w(Kokkos::ViewAllocateWithoutInitializing(\"vertices\"), N);\n\tKokkos::parallel_for(\"fill_v\", N, KOKKOS_LAMBDA(const int i) {\n\t\tv[i] = i;\n\t\tw[i] = -1;\n\t});\n\n\tint num_v = 0;\n\tKokkos::parallel_for(\"union_find\", N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tKokkos::single(Kokkos::PerThread(i), [&]() {\n\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\tif (w[i] == -1 && A(k, i) == 1) {\n\t\t\t\t\t\t\tw[i] = w[k];\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tKokkos::single(Kokkos::PerThread(i), [&]() {\n\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\tif (w[j] == -1 && A(k, j) == 1) {\n\t\t\t\t\t\t\tw[j] = w[k];\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tKokkos::single(Kokkos::PerThread(i), [&]() {\n\t\t\t\t\tif (w[i] == -1 && w[j] == -1) {\n\t\t\t\t\t\tv[i] = j;\n\t\t\t\t\t\tw[i] = j;\n\t\t\t\t\t\tnum_v++;\n\t\t\t\t\t}\n\t\t\t\t\telse if (w[i] == -1) {\n\t\t\t\t\t\tv[i] = w[j];\n\t\t\t\t\t\tw[i] = w[j];\n\t\t\t\t\t}\n\t\t\t\t\telse if (w[j] == -1) {\n\t\t\t\t\t\tv[j] = w[i];\n\t\t\t\t\t\tw[j] = w[i];\n\t\t\t\t\t}\n\t\t\t\t\telse if (v[i]!= v[j]) {\n\t\t\t\t\t\tv[j] = v[i];\n\t\t\t\t\t\tw[j] = w[i];\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t});\n\n\tint num_components = 0;\n\tKokkos::parallel_reduce(\"component_counter\", N, KOKKOS_LAMBDA(const int i, int& num_components) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (v[i] == v[j]) {\n\t\t\t\tnum_components++;\n\t\t\t}\n\t\t}\n\t}, num_components);\n\treturn num_components;\n}",
            "// TODO: Fill in the body of this function.\n\tKokkos::View<int**> A_tmp(\"A_tmp\", N, N);\n\tKokkos::parallel_for( \"fill_A_tmp\", N*N, KOKKOS_LAMBDA(int i) {\n\t\tA_tmp(i/N, i%N) = A(i/N, i%N);\n\t});\n\tKokkos::fence();\n\n\tfor (int i=0; i < N; ++i) {\n\t\tfor (int j=0; j < N; ++j) {\n\t\t\tif (A_tmp(i,j) == 1) {\n\t\t\t\tKokkos::parallel_for( \"fill_matrix\", N*N, KOKKOS_LAMBDA(int k) {\n\t\t\t\t\tif (k == i*N+j) {\n\t\t\t\t\t\tA_tmp(k/N, k%N) = 1;\n\t\t\t\t\t}\n\t\t\t\t\telse if (A(k/N, k%N) == 1) {\n\t\t\t\t\t\tA_tmp(k/N, k%N) = 1;\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tKokkos::fence();\n\n\tint largest = 0;\n\tfor (int i=0; i < N; ++i) {\n\t\tint count = 0;\n\t\tfor (int j=0; j < N; ++j) {\n\t\t\tif (A_tmp(i,j) == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tif (count > largest) {\n\t\t\tlargest = count;\n\t\t}\n\t}\n\n\treturn largest;\n}",
            "//\n\t// TODO: fill in\n\t//\n\n\treturn 0;\n}",
            "return 0;\n}",
            "// Create the component ids for all vertices\n\tKokkos::View<int*> comp_ids(\"component_ids\", N);\n\tKokkos::deep_copy(comp_ids, 0);\n\t// Create the count of vertices in each component\n\tKokkos::View<int*> comp_count(\"component_count\", N);\n\tKokkos::deep_copy(comp_count, 0);\n\t\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\t// Iterate through all neighbors to find the component id of all vertices\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tcomp_ids(i) = comp_ids(j);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t});\n\t\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\t// Iterate through all neighbors to count the vertices in each component\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1 && comp_ids(i) == comp_ids(j)) {\n\t\t\t\tcomp_count(comp_ids(i)) += 1;\n\t\t\t}\n\t\t}\n\t});\n\t\n\t// Find the component with the most vertices\n\tint max_count = 0;\n\tint max_comp_id = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (comp_count(i) > max_count) {\n\t\t\tmax_count = comp_count(i);\n\t\t\tmax_comp_id = i;\n\t\t}\n\t}\n\t\n\treturn max_count;\n}",
            "// TODO: Implement using Kokkos\n  // Hint: Use Kokkos::parallel_for to execute a for loop in parallel\n  // Hint: Use Kokkos::single to execute a for loop in parallel\n  // Hint: Use Kokkos::View to create a 1D Kokkos view of a 2D C++ array\n  // Hint: Use Kokkos::View to create a 2D Kokkos view of a 2D C++ array\n  // Hint: Use Kokkos::deep_copy to copy data from a 1D C++ array to a 1D Kokkos view\n  // Hint: Use Kokkos::deep_copy to copy data from a 2D C++ array to a 2D Kokkos view\n  // Hint: Use Kokkos::deep_copy to copy data from a 1D Kokkos view to a 2D Kokkos view\n  // Hint: Use Kokkos::deep_copy to copy data from a 2D Kokkos view to a 2D C++ array\n\n  // Create a 2D Kokkos view of A (use deep_copy to get its data)\n  Kokkos::View<int**> A_kokkos;\n  // Create a 2D Kokkos view of a C++ array of size NxN (use deep_copy to get its data)\n  int** comp_size = new int*[N];\n  for(int i=0; i<N; ++i) {\n    comp_size[i] = new int[N];\n  }\n  Kokkos::View<int**> comp_size_kokkos;\n  // Initialize each element of comp_size to 0\n  // Use parallel_for to initialize the elements\n  // Use deep_copy to copy comp_size_kokkos back to comp_size\n\n  // Create a 1D Kokkos view of size N (use deep_copy to get its data)\n  Kokkos::View<int*> component;\n  // Create a 1D C++ array of size N\n  int* component_size = new int[N];\n  // Initialize each element of component_size to 0\n  // Use parallel_for to initialize the elements\n  // Use deep_copy to copy component_kokkos back to component_size\n\n  // Create a 1D Kokkos view of size N\n  Kokkos::View<int*> component_max;\n  // Create a 1D C++ array of size N\n  int* component_max_size = new int[N];\n  // Initialize each element of component_max_size to 0\n  // Use parallel_for to initialize the elements\n  // Use deep_copy to copy component_max_kokkos back to component_max_size\n\n  // Loop over the elements of A_kokkos and find the index of the element with the largest component\n  // Use single to execute a for loop in parallel\n  // Use deep_copy to copy the result back to component_max_size\n\n  // Find the largest value in component_max_size and return it\n  // Use parallel_for to find the largest value\n  // Use single to get the largest value\n  // Use deep_copy to copy component_max_kokkos back to component_max_size\n  return 0;\n}",
            "// Use Kokkos' parallel_for to initialize a vector of N indices,\n  // where each index corresponds to a vertex in the graph\n  // and the value of the index is the vertex's index\n  Kokkos::View<int*> idxs(\"idx\", N);\n  Kokkos::parallel_for(\"init_idx\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int i) {\n    idxs(i) = i;\n  });\n\n  // Add more Kokkos parallel_for statements as needed\n\n  // Return the size of the largest component of the graph\n  return 0;\n}",
            "typedef Kokkos::DefaultExecutionSpace execution_space;\n  Kokkos::View<int*, execution_space> sizes(\"sizes\", N);\n  Kokkos::parallel_for(\"largestComponent\",\n    Kokkos::RangePolicy<execution_space>(0, N), KOKKOS_LAMBDA(const int i) {\n      int my_size = 0;\n      for (int j = 0; j < N; ++j) {\n        if (A(i, j)) {\n          my_size++;\n        }\n      }\n      sizes(i) = my_size;\n    });\n\n  int largest_size = 0;\n  Kokkos::parallel_reduce(\"largestComponent\",\n    Kokkos::RangePolicy<execution_space>(0, N), KOKKOS_LAMBDA(const int i, int& largest_size_) {\n      if (sizes(i) > largest_size_) {\n        largest_size_ = sizes(i);\n      }\n    }, Kokkos::Max<int>(largest_size));\n  return largest_size;\n}",
            "Kokkos::View<int*> component(\"Component\", N);\n\n    // Fill component with -1 to indicate that the vertex is unvisited.\n    Kokkos::parallel_for(\"ComponentInit\", N, KOKKOS_LAMBDA(const size_t i) {\n        component(i) = -1;\n    });\n\n    // Traverse the graph using BFS, updating component at each vertex as we go.\n    Kokkos::parallel_for(\"ComponentBFS\", N, KOKKOS_LAMBDA(const size_t i) {\n        if (component(i) == -1) {\n            Kokkos::View<int*> queue(\"Queue\", N);\n            queue(0) = i;\n            component(i) = 0;\n            int queueSize = 1;\n\n            for (int j = 0; j < queueSize; j++) {\n                int curr = queue(j);\n\n                Kokkos::parallel_for(\"Adjacency\", N, KOKKOS_LAMBDA(const size_t k) {\n                    if (A(curr, k) == 1 && component(k) == -1) {\n                        queue(queueSize) = k;\n                        component(k) = component(curr) + 1;\n                        queueSize++;\n                    }\n                });\n            }\n        }\n    });\n\n    // Compute the max component size in parallel.\n    int maxComponentSize = -1;\n    Kokkos::parallel_reduce(\"ComponentReduce\", N, KOKKOS_LAMBDA(const size_t i, int &maxCompSize) {\n        maxCompSize = std::max(maxCompSize, component(i));\n    }, Kokkos::Max<int>(maxComponentSize));\n\n    return maxComponentSize + 1;\n}",
            "Kokkos::View<int**> A_copy(\"A_copy\", N, N);\n\tKokkos::parallel_for(\n\t\t\"A_copy\",\n\t\tKokkos::RangePolicy<Kokkos::Serial, int>(0, N),\n\t\t[A, A_copy](const int i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tA_copy(i, j) = A(i, j);\n\t\t\t}\n\t\t}\n\t);\n\tKokkos::fence();\n\n\tKokkos::View<bool**> visited(\"visited\", N, N);\n\tKokkos::parallel_for(\n\t\t\"visited\",\n\t\tKokkos::RangePolicy<Kokkos::Serial, int>(0, N),\n\t\t[&visited](const int i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tvisited(i, j) = false;\n\t\t\t}\n\t\t}\n\t);\n\tKokkos::fence();\n\n\tint largest_component_size = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited(i, i)) {\n\t\t\tint component_size = 1;\n\t\t\tstd::queue<int> nodes_to_visit;\n\t\t\tnodes_to_visit.push(i);\n\t\t\twhile (!nodes_to_visit.empty()) {\n\t\t\t\tint current_node = nodes_to_visit.front();\n\t\t\t\tnodes_to_visit.pop();\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (!visited(current_node, j) && A_copy(current_node, j)!= 0) {\n\t\t\t\t\t\tnodes_to_visit.push(j);\n\t\t\t\t\t\tvisited(current_node, j) = true;\n\t\t\t\t\t\tcomponent_size++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tlargest_component_size = (largest_component_size < component_size)? component_size : largest_component_size;\n\t\t}\n\t}\n\n\treturn largest_component_size;\n}",
            "using ExecSpace = Kokkos::DefaultExecutionSpace;\n\tusing MemorySpace = Kokkos::DefaultHostExecutionSpace;\n\tusing Unsigned = unsigned int;\n\n\t// Declare and initialize a boolean array on the host\n\t// The entries in this array will serve as a \"marker\" for which vertices have been visited yet.\n\tauto host_marker = Kokkos::View<Unsigned*>(\"marker\", N);\n\tauto host_marker_h = Kokkos::create_mirror_view(host_marker);\n\tfor (Unsigned i = 0; i < N; i++) {\n\t\thost_marker_h(i) = i;\n\t}\n\tKokkos::deep_copy(host_marker, host_marker_h);\n\n\t// Initialize the largest component size to 1.\n\t// If there are no edges, then the largest component size is 1.\n\tunsigned largestComponentSize = 1;\n\n\t// The component sizes are stored in a host array because they are needed when the components are merged.\n\t// The component sizes are then copied back into the device memory to update the largest component size.\n\tauto componentSizes = Kokkos::View<Unsigned*>(\"componentSizes\", N);\n\tauto componentSizes_h = Kokkos::create_mirror_view(componentSizes);\n\tfor (Unsigned i = 0; i < N; i++) {\n\t\tcomponentSizes_h(i) = 1;\n\t}\n\n\t// This boolean is used to check when the execution of the algorithm is finished.\n\tbool done = false;\n\n\t// Keep track of the number of iterations of the algorithm that have been performed.\n\t// If the number of iterations exceeds the number of vertices, then there are no more components to merge.\n\tunsigned iterations = 0;\n\n\t// Define the Kokkos parallel reduction type.\n\t// The Kokkos::Sum reduction will keep track of the largest component size.\n\ttypedef Kokkos::Sum<ExecSpace> largestComponentSize_t;\n\tlargestComponentSize_t largestComponentSize_r(\"largestComponentSize_r\");\n\n\t// This loop merges the components by iterating through the adjacency matrix A.\n\twhile (!done) {\n\t\t// Initialize the largest component size to 1.\n\t\t// If there are no edges, then the largest component size is 1.\n\t\tlargestComponentSize_r = 1;\n\n\t\t// Create a parallel Kokkos loop that will iterate through the adjacency matrix.\n\t\t// Each thread will check if a connection exists between the source and target vertices.\n\t\t// If so, then the source vertex should be marked as having the same component as the target.\n\t\t// If the source vertex is already marked, then the source vertex should be removed from the component.\n\t\t// If the source vertex is not marked, then the source vertex should be added to the component.\n\t\tKokkos::parallel_reduce(Kokkos::RangePolicy<ExecSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(const size_t i, largestComponentSize_t& l) {\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j)) {\n\t\t\t\t\t\t// Use atomic operations to update the component that the source vertex is a member of.\n\t\t\t\t\t\t// If the source vertex has not been marked, then it should be added to the component.\n\t\t\t\t\t\t// If the source vertex has been marked, then it should be removed from the component.\n\t\t\t\t\t\tconst int sourceComponent = Kokkos::atomic_fetch_add(&host_marker_h(i), 0);\n\t\t\t\t\t\tconst int targetComponent = Kokkos::atomic_fetch_add(&host_marker_h(j), 0);\n\t\t\t\t\t\tif (sourceComponent!= targetComponent) {\n\t\t\t\t\t\t\t// Check which component has the largest size.\n\t\t\t\t\t\t\tif (componentSizes_h(sourceComponent) > componentSizes_h(targetComponent)) {\n\t\t\t\t\t\t\t\t// Replace the target component with the source component.\n\t\t\t\t\t\t\t\tKokkos::atomic_fetch_",
            "// your code goes here\n  return -1;\n}",
            "// Initialize a vector of component labels for each vertex in the graph\n    Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> label_vec(\"label\", N);\n\n    // Use Kokkos to assign labels to the components\n    Kokkos::parallel_for(\"largest component\", N, KOKKOS_LAMBDA (const int& i) {\n        int& my_label = label_vec(i);\n        my_label = i;\n        for (int j = 0; j < i; j++) {\n            if (A(i, j)!= 0) {\n                my_label = label_vec(j);\n            }\n        }\n    });\n    Kokkos::fence();\n\n    // Create a vector of the label counts\n    Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> label_counts(\"label_counts\", N);\n    Kokkos::parallel_for(\"label_counts\", N, KOKKOS_LAMBDA (const int& i) {\n        int& my_count = label_counts(i);\n        my_count = 0;\n        for (int j = 0; j < N; j++) {\n            if (label_vec(j) == i) {\n                my_count += 1;\n            }\n        }\n    });\n    Kokkos::fence();\n\n    // Find the label with the largest component count\n    int max_count = 0;\n    int max_label = 0;\n    for (int i = 0; i < N; i++) {\n        if (label_counts(i) > max_count) {\n            max_count = label_counts(i);\n            max_label = i;\n        }\n    }\n\n    return max_count;\n}",
            "// Use Kokkos to parallelize over the vertices of the graph\n\t// The function signature of the lambda must be\n\t// int (*function_name)(const int i, const int N)\n\t// where i is the vertex and N is the graph size\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t[&](const int i, int& largest) {\n\t\t\t// Initialize the largest component to the current vertex\n\t\t\tint largest_component = 1;\n\t\t\t// Traverse the entire graph starting from the current vertex, and\n\t\t\t// add any new nodes to the largest_component\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tlargest_component++;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Keep track of the largest component seen so far\n\t\t\tlargest = (largest > largest_component)? largest : largest_component;\n\t\t},\n\t\t// At the end of the loop, this lambda will be called with the final result\n\t\t[&](int &l) {\n\t\t\t// l is the final result and should be written to the argument.\n\t\t\t// It is also the correct answer to the problem.\n\t\t\tl = largest;\n\t\t}\n\t);\n\n\t// Return the final result\n\treturn largest;\n}",
            "Kokkos::View<bool**> vis(\"vis\", N, N);\n\tKokkos::View<int*> cnt(\"cnt\", N);\n\t// Create a Kokkos view for each row of A.\n\t// Use the range policy to iterate over each row.\n\t// Use the parallel_for algorithm.\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>, Kokkos::Schedule<Kokkos::Static>>(0, N, 0, N),\n\t\t[&](const int& i, const int& j) {\n\t\t// Use the rank-2 view to access elements of A.\n\t\tif (A(i, j) &&!vis(i, j)) {\n\t\t\t// Use the rank-1 view to access elements of vis and cnt.\n\t\t\tvis(i, j) = true;\n\t\t\tcnt(i) += 1;\n\t\t\t// Use the rank-2 view to access elements of vis.\n\t\t\t// Use the range policy to iterate over the remaining rows of A.\n\t\t\t// Use the parallel_for algorithm.\n\t\t\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Rank<2>, Kokkos::Schedule<Kokkos::Static>>(0, N, 0, N),\n\t\t\t\t[&](const int& i, const int& j) {\n\t\t\t\tif (A(i, j) &&!vis(i, j)) {\n\t\t\t\t\t// Use the rank-2 view to access elements of vis.\n\t\t\t\t\tvis(i, j) = true;\n\t\t\t\t\t// Use the rank-1 view to access elements of cnt.\n\t\t\t\t\tcnt(i) += 1;\n\t\t\t\t}\n\t\t\t});\n\t\t\t// Use the single element view to access the first element of cnt.\n\t\t\t// Use the reduce algorithm to find the maximum.\n\t\t\tKokkos::single(Kokkos::PerThread(0),\n\t\t\t\t[&]() {\n\t\t\t\tcnt(0) = Kokkos::reduce(cnt, Kokkos::MAX<int>(), 0);\n\t\t\t});\n\t\t}\n\t});\n\t// Use the single element view to access the first element of cnt.\n\t// Use the reduce algorithm to find the maximum.\n\tint max = Kokkos::reduce(cnt, Kokkos::MAX<int>(), 0);\n\treturn max;\n}",
            "// TODO: Implement\n  Kokkos::View<int*> color(\"color\", N);\n  Kokkos::parallel_for(\"Initialize color\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i) {\n    color(i) = 1;\n  });\n\n  Kokkos::View<int**> B(\"B\", N, N);\n\n  Kokkos::parallel_for(\"Initialize B\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i) {\n    Kokkos::parallel_for(\"Initialize B rows\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int j) {\n      B(i, j) = A(i, j);\n      if (i!= j) B(i, j) = 0;\n    });\n  });\n\n  Kokkos::parallel_for(\"Dump B\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i) {\n    Kokkos::parallel_for(\"Dump B rows\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int j) {\n      if (i == j)\n        printf(\"%d \", B(i, j));\n      else\n        printf(\"(%d %d) \", B(i, j), A(i, j));\n    });\n    printf(\"\\n\");\n  });\n\n  size_t max_component_size = 0;\n  Kokkos::parallel_reduce(\"Find the largest component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i, int &max_component_size) {\n    int my_component = -1;\n    int my_component_size = 0;\n\n    Kokkos::parallel_for(\"Find the largest component\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int j) {\n      if (B(i, j) == 1 && color(j) == 1) {\n        color(j) = my_component;\n        my_component_size++;\n      }\n    });\n\n    if (my_component_size > max_component_size) {\n      max_component_size = my_component_size;\n    }\n  }, max_component_size);\n\n  Kokkos::parallel_for(\"Dump color\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i) {\n    printf(\"%d \", color(i));\n  });\n  printf(\"\\n\");\n\n  return max_component_size;\n}",
            "// your code goes here\n    const int UNVISITED = 0;\n    const int VISITED = 1;\n    const int DEFUNCT = 2;\n\n    Kokkos::View<int*> component_sizes(\"Component_Sizes\", N);\n    Kokkos::View<int*> component_colors(\"Component_Colors\", N);\n\n    for (size_t i=0; i<N; ++i){\n        component_colors[i] = UNVISITED;\n    }\n\n    //Kokkos::deep_copy(component_sizes, 0);\n    component_sizes.modify_all([] (int &i) {i=0;});\n    component_sizes(0) = 1;\n\n    for (size_t i=0; i<N; ++i){\n        component_colors(i) = UNVISITED;\n    }\n\n    Kokkos::View<int*> vertex_visiting_order(\"Vertex_Visiting_Order\", N);\n\n    size_t num_visited = 1;\n    size_t num_components = 0;\n    while (num_visited < N){\n        component_colors(0) = VISITED;\n        vertex_visiting_order(0) = 0;\n        int current_vertex = 0;\n\n        int current_component_size = 1;\n        int largest_component_size = 1;\n        int largest_component_vertex = 0;\n\n        for (size_t j=0; j<N; ++j){\n            if (component_colors(vertex_visiting_order(j)) == UNVISITED){\n                Kokkos::deep_copy(component_colors.subview(0, 0, j), VISITED);\n                current_component_size++;\n\n                for (size_t k=0; k<N; ++k){\n                    if (component_colors(k) == UNVISITED and A(vertex_visiting_order(j), k) > 0){\n                        Kokkos::deep_copy(component_colors.subview(0, 0, k), VISITED);\n                        current_component_size++;\n                        Kokkos::deep_copy(vertex_visiting_order.subview(0, 0, num_visited), k);\n                        num_visited++;\n                    }\n                }\n\n                if (current_component_size > largest_component_size){\n                    largest_component_size = current_component_size;\n                    largest_component_vertex = vertex_visiting_order(j);\n                }\n\n                Kokkos::deep_copy(component_colors.subview(0, 0, vertex_visiting_order(j)), DEFUNCT);\n            }\n        }\n\n        component_sizes(num_components) = largest_component_size;\n        num_components++;\n    }\n\n    //Kokkos::deep_copy(component_colors, 0);\n    component_colors.modify_all([] (int &i) {i=0;});\n\n    int largest_component_size = 0;\n    int largest_component_vertex = 0;\n\n    for (size_t i=0; i<N; ++i){\n        if (component_sizes(i) > largest_component_size){\n            largest_component_size = component_sizes(i);\n            largest_component_vertex = i;\n        }\n    }\n\n    return largest_component_size;\n}",
            "Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::Device<Kokkos::Serial, Kokkos::HostSpace>> reachable(\"reachable\", N);\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::Device<Kokkos::Serial, Kokkos::HostSpace>> components(\"components\", N);\n\tKokkos::deep_copy(reachable, 0);\n\tKokkos::deep_copy(components, 0);\n\tint maxComponent = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\t// Initialize reachable[i] to 1, and all other reachable[j] to 0\n\t\tint j = i;\n\t\tif (i == 0) {\n\t\t\tKokkos::deep_copy(reachable, 0);\n\t\t\treachable(0) = 1;\n\t\t}\n\t\t// Mark vertices reachable[i] as reachable, starting from j\n\t\tint component = 1;\n\t\twhile (j >= 0) {\n\t\t\t// Mark all vertices reachable[j] as reachable\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (A(j,k) == 1 && reachable(k) == 0) {\n\t\t\t\t\treachable(k) = 1;\n\t\t\t\t\tcomponents(k) = component;\n\t\t\t\t}\n\t\t\t}\n\t\t\tj = -1;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (reachable(k) == 1) {\n\t\t\t\t\tj = k;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomponent++;\n\t\t}\n\t\tif (component > maxComponent) {\n\t\t\tmaxComponent = component;\n\t\t}\n\t}\n\treturn maxComponent;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> largestComponentMap(\"largestComponentMap\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> isInComponent(\"isInComponent\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> numInComponent(\"numInComponent\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> numInComponentHost(\"numInComponentHost\", N);\n  Kokkos::deep_copy(largestComponentMap, 0);\n  Kokkos::deep_copy(isInComponent, 0);\n  Kokkos::deep_copy(numInComponent, 0);\n  Kokkos::deep_copy(numInComponentHost, 0);\n\n  int LCM = 0;\n\n  // Create the first component (largest component)\n  largestComponentMap(0) = 1;\n  isInComponent(0) = 1;\n  numInComponent(0) = 1;\n  numInComponentHost(0) = 1;\n\n  for (int i = 1; i < N; i++) {\n\n    int largestInComponent = -1;\n    int largestSize = -1;\n\n    // Iterate over all the components to see which one the current vertex is connected to\n    for (int j = 0; j < N; j++) {\n      if (largestInComponent == -1) {\n        // Find the first component that the vertex is connected to\n        if (A(j, i) || A(i, j)) {\n          largestInComponent = j;\n          largestSize = numInComponent(j);\n        }\n      } else {\n        // Update largestInComponent if a new connection is found\n        if ((A(largestInComponent, i) || A(i, largestInComponent)) && numInComponent(j) > largestSize) {\n          largestInComponent = j;\n          largestSize = numInComponent(j);\n        }\n      }\n    }\n\n    // If no component is connected to vertex i, create a new component\n    if (largestInComponent == -1) {\n      largestComponentMap(i) = largestComponentMap(0);\n      isInComponent(i) = 1;\n      numInComponent(i) = 1;\n      numInComponentHost(i) = 1;\n    } else {\n      largestComponentMap(i) = largestComponentMap(largestInComponent);\n      isInComponent(i) = 1;\n      numInComponent(i) = numInComponent(largestInComponent) + 1;\n      numInComponentHost(i) = numInComponent(largestInComponent) + 1;\n    }\n\n    // Update the largest component if necessary\n    if (numInComponent(i) > numInComponent(LCM)) {\n      LCM = i;\n    }\n  }\n\n  // Copy the components back to the host\n  Kokkos::deep_copy(numInComponentHost, numInComponent);\n\n  int numComponents = 0;\n  for (int i = 0; i < N; i++) {\n    if (numInComponentHost(i) > 0) {\n      numComponents++;\n    }\n  }\n\n  return numComponents;\n}",
            "// create a 1D array of integers to store the largest component size\n\tKokkos::View<int*> largestComponent(Kokkos::ViewAllocateWithoutInitializing(\"largestComponent\"), 1);\n\t// use the CUDA execution space to perform the reduction\n\tKokkos::parallel_reduce(\"largestComponent\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t\t\t\t\t\tKOKKOS_LAMBDA(const int i, int &component) {\n\t\tint currentComponent = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\tcurrentComponent += 1;\n\t\t\t}\n\t\t}\n\t\t// perform the reduction with the max operator to find the largest component size\n\t\tcomponent = std::max(component, currentComponent);\n\t},\n\t\t\t\t\t\t\tKokkos::Max<int>(largestComponent(0)));\n\n\t// wait for the parallel_reduce to finish\n\tKokkos::fence();\n\n\treturn largestComponent(0);\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\tusing size_type = Kokkos::View<int*>::size_type;\n\n\t// Initialize the array B to be the identity matrix.\n\tKokkos::View<int**> B(\"B\", N, N);\n\tKokkos::deep_copy(B, 0);\n\tfor (int i=0; i<N; i++) {\n\t\tB(i,i) = 1;\n\t}\n\n\t// Use Kokkos to compute the largest component\n\tsize_type num_vertices = N;\n\tfor (int it=0; it<N; it++) {\n\t\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\t\tint max_val = -1;\n\t\t\tint argmax = -1;\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\tif (B(i,j) == 0) {\n\t\t\t\t\tif (A(i,j) > max_val) {\n\t\t\t\t\t\tmax_val = A(i,j);\n\t\t\t\t\t\targmax = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (max_val > -1) {\n\t\t\t\tB(i,argmax) = 1;\n\t\t\t\tnum_vertices--;\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\t}\n\n\treturn num_vertices;\n}",
            "Kokkos::View<int*> flag(\"flag\", N);\n  Kokkos::View<int*> result(\"result\", 1);\n  Kokkos::View<int*> size(\"size\", 1);\n\n  Kokkos::deep_copy(flag, 0);\n  Kokkos::deep_copy(result, 0);\n  Kokkos::deep_copy(size, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Serial>(0, N), [=] (int i) {\n    if (flag[i] == 0) {\n      int component_size = dfs_visit(A, i, flag);\n      if (component_size > result[0]) {\n        result[0] = component_size;\n        size[0] = 1;\n      } else if (component_size == result[0]) {\n        size[0]++;\n      }\n    }\n  });\n\n  return result[0] * size[0];\n}",
            "using namespace Kokkos;\n\n\t// Your code here\n\t\n\t// The following variables are defined to help with defining\n\t// Kokkos parallel ranges.\n\t//\n\t// N: the number of vertices in the graph (the size of A)\n\t// N_THREADS: the number of threads per Kokkos parallel for loop\n\t// N_LOOPS: the number of times the Kokkos parallel for loop will be executed\n\t// loop_size: the number of vertices each thread will operate on\n\tconst int N_THREADS = 256;\n\tconst int N_LOOPS = (N+N_THREADS-1)/N_THREADS;\n\tconst int loop_size = (N+N_LOOPS-1)/N_LOOPS;\n\t\n\tView<int*> degree(Kokkos::ViewAllocateWithoutInitializing(\"degree\"), N);\n\tView<int*> visited(Kokkos::ViewAllocateWithoutInitializing(\"visited\"), N);\n\tKokkos::parallel_for(N_LOOPS, KOKKOS_LAMBDA(const int i){\n\t\tfor (int j = 0; j < loop_size; ++j) {\n\t\t\tint index = i*loop_size + j;\n\t\t\tif (index >= N) break;\n\t\t\tint current_degree = 0;\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (A(index, k)!= 0) ++current_degree;\n\t\t\t}\n\t\t\tdegree(index) = current_degree;\n\t\t}\n\t});\n\tKokkos::fence();\n\tKokkos::parallel_for(N_LOOPS, KOKKOS_LAMBDA(const int i){\n\t\tfor (int j = 0; j < loop_size; ++j) {\n\t\t\tint index = i*loop_size + j;\n\t\t\tif (index >= N) break;\n\t\t\tint current_degree = 0;\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (A(index, k)!= 0) ++current_degree;\n\t\t\t}\n\t\t\tdegree(index) = current_degree;\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint max_degree = 0;\n\tint max_degree_index = 0;\n\tKokkos::parallel_reduce(N_LOOPS, KOKKOS_LAMBDA(const int i, int &m){\n\t\tfor (int j = 0; j < loop_size; ++j) {\n\t\t\tint index = i*loop_size + j;\n\t\t\tif (index >= N) break;\n\t\t\tif (degree(index) > m) {\n\t\t\t\tm = degree(index);\n\t\t\t\tmax_degree_index = index;\n\t\t\t}\n\t\t}\n\t}, max_degree);\n\tKokkos::fence();\n\n\tKokkos::parallel_for(N_LOOPS, KOKKOS_LAMBDA(const int i){\n\t\tfor (int j = 0; j < loop_size; ++j) {\n\t\t\tint index = i*loop_size + j;\n\t\t\tif (index >= N) break;\n\t\t\tif (index!= max_degree_index) visited(index) = 1;\n\t\t}\n\t});\n\tKokkos::fence();\n\tint count = 0;\n\tKokkos::parallel_reduce(N_LOOPS, KOKKOS_LAMBDA(const int i, int &c){\n\t\tfor (int j = 0; j < loop_size; ++j) {\n\t\t\tint index = i*loop_size + j;\n\t\t\tif (index >= N) break;\n\t\t\tif (visited(index) == 0) ++c;\n\t\t}\n\t}, count);\n\tKokkos::fence();\n\n\treturn count;\n}",
            "// Initialize the vertex set\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> vertexSet(\"vertexSet\", N);\n  Kokkos::deep_copy(vertexSet, 0);\n\n  // Kokkos functor to set the vertex set\n  class setVertexSet {\n    public:\n      setVertexSet(Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &vertexSet, Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &visited, int &visitedCount, const int vertex, int &N) : vertexSet(vertexSet), visited(visited), visitedCount(visitedCount), vertex(vertex), N(N) {}\n      KOKKOS_INLINE_FUNCTION\n      void operator() (const int &i) const {\n        vertexSet(vertex) = i;\n      }\n    private:\n      Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> vertexSet;\n      Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> visited;\n      int visitedCount;\n      int vertex;\n      int N;\n  };\n\n  // Kokkos functor to compute the visitedCount\n  class countVisited {\n    public:\n      countVisited(Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &visited, int &visitedCount, const int vertex) : visited(visited), visitedCount(visitedCount), vertex(vertex) {}\n      KOKKOS_INLINE_FUNCTION\n      void operator() (const int &i) const {\n        if (vertex == i)\n          visitedCount++;\n      }\n    private:\n      Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> visited;\n      int visitedCount;\n      int vertex;\n  };\n\n  // Kokkos functor to compute the largest component size\n  class computeLargestComponentSize {\n    public:\n      computeLargestComponentSize(Kokkos::View<const int**> &A, Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &vertexSet, const int N) : A(A), vertexSet(vertexSet), N(N) {}\n      KOKKOS_INLINE_FUNCTION\n      void operator() (const int &i, int &largestComponentSize) const {\n        if (vertexSet(i)!= 0) {\n          // Compute the size of this component\n          int vertexSize = 0;\n          for (int j = 0; j < N; j++) {\n            if (vertexSet(i) == vertexSet(j)) {\n              vertexSize++;\n            }\n          }\n\n          // If the size of this component is the largest, update the largestComponentSize\n          if (largestComponentSize < vertexSize) {\n            largestComponentSize = vertexSize;\n          }\n        }\n      }\n    private:\n      Kokkos::View<const int**> A;\n      Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> vertexSet;\n      const int N;\n  };\n\n  // Kokkos functor to compute the component size and the component with the largest size\n  class computeComponent {\n    public:\n      computeComponent(Kokkos::View<const int**> &A, Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &vertexSet, Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> &visited, int &largestComponentSize, int &largestComponent, const int N) : A(A), vertexSet(vertexSet), visited(visited), largestComponentSize(largestComponentSize), largestComponent(largestComponent), N(N) {}\n      KOKKOS_INLINE_FUNCTION\n      void operator() (const int &i) const {\n        // If this vertex is unvisited,\n        if (visited(i) == 0) {\n          // Add this vertex to the vertex set\n          int vertexSetSize = 0;\n          Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), setVertex",
            "// Your code here\n}",
            "// TODO: implement this function\n\n  int *component_map = new int[N];\n  int *component_sizes = new int[N];\n  for (int i = 0; i < N; i++) {\n    component_map[i] = i;\n    component_sizes[i] = 0;\n  }\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < i; j++) {\n      if (A(i, j)!= 0) {\n        int comp1 = findComponent(i, component_map);\n        int comp2 = findComponent(j, component_map);\n        if (comp1!= comp2) {\n          component_map[comp1] = comp2;\n          component_sizes[comp2] += component_sizes[comp1];\n        }\n      }\n    }\n  }\n\n  int largest_component = 0;\n  int max_size = 0;\n  for (int i = 0; i < N; i++) {\n    int size = component_sizes[findComponent(i, component_map)];\n    if (size > max_size) {\n      max_size = size;\n      largest_component = i;\n    }\n  }\n\n  delete[] component_map;\n  delete[] component_sizes;\n\n  return largest_component;\n}",
            "using Kokkos::ALL;\n  using Kokkos::AUTO;\n\n  // TODO: Replace 0 with an appropriate value\n  Kokkos::View<int*, AUTO> adj_vertices(0);\n  Kokkos::View<int*, AUTO> component_sizes(0);\n  Kokkos::View<int*, AUTO> num_visited(0);\n  Kokkos::View<int*, AUTO> current_component(0);\n  Kokkos::View<int*, AUTO> max_component(0);\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_reduce(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i, int& total) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    },\n    KOKKOS_LAMBDA (int& total, const int& value) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_scan(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i, int& total, const bool flag) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    },\n    KOKKOS_LAMBDA (int& total, const bool flag) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i) {\n      // TODO: Replace 0 with an appropriate value\n      adj_vertices(i) = 0;\n    }\n  );\n\n  Kokkos::parallel_reduce(\n    \"LargestComponent\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA (const int i, int& total) {\n      // TODO",
            "// TODO\n\treturn 0;\n}",
            "// Your code here\n\tKokkos::View<int*> componentSize(\"component size\", N);\n\tKokkos::parallel_for(\"init_componentSize\", N, KOKKOS_LAMBDA(const int& i){componentSize[i] = 1;});\n\tKokkos::View<int*> visited(\"visited\", N);\n\tKokkos::parallel_for(\"init_visited\", N, KOKKOS_LAMBDA(const int& i){visited[i] = 0;});\n\n\tfor (int i = 0; i < N; i++){\n\t\tif (visited[i] == 0){\n\t\t\tint count = 0;\n\t\t\tKokkos::View<int*> component(\"component\", N);\n\t\t\tKokkos::parallel_for(\"init_component\", N, KOKKOS_LAMBDA(const int& j){component[j] = 0;});\n\t\t\tKokkos::View<int*> toVisit(\"toVisit\", N);\n\t\t\tKokkos::parallel_for(\"init_toVisit\", N, KOKKOS_LAMBDA(const int& j){toVisit[j] = 1;});\n\t\t\tKokkos::parallel_for(\"DFS\", N, KOKKOS_LAMBDA(const int& j){\n\t\t\t\tif (visited[j] == 0){\n\t\t\t\t\tcomponent[j] = 1;\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcount++;\n\t\t\t\t\tfor (int k = 0; k < N; k++){\n\t\t\t\t\t\tif (A(j,k) == 1 && toVisit[k] == 1){\n\t\t\t\t\t\t\tcomponent[k] = 1;\n\t\t\t\t\t\t\ttoVisit[k] = 0;\n\t\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t\t\tcount++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t\tcomponentSize[i] = count;\n\t\t}\n\t}\n\t\n\tint maxCount = 0;\n\tint maxId = 0;\n\tfor (int i = 0; i < N; i++){\n\t\tif (componentSize[i] > maxCount){\n\t\t\tmaxCount = componentSize[i];\n\t\t\tmaxId = i;\n\t\t}\n\t}\n\n\treturn maxCount;\n\n}",
            "Kokkos::View<int*> is_visited(\"is_visited\", N);\n\n  Kokkos::parallel_for(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      is_visited[i] = 0;\n    }\n  );\n\n  Kokkos::parallel_for(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      if (is_visited[i] == 0) {\n        DFS(i, A, is_visited, N);\n      }\n    }\n  );\n\n  int largest_component = 0;\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(int i, int &largest_component) {\n      if (is_visited[i] == 1) {\n        largest_component += 1;\n      }\n    },\n    Kokkos::Sum<int>(largest_component)\n  );\n\n  return largest_component;\n}",
            "Kokkos::View<int**> M(\"M\", N, N);\n\n  // Use Kokkos parallel_for to initialize all values in M to -1.\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ReduceComm<Kokkos::ReduceCommIdentity<int> >, Kokkos::Schedule<Kokkos::Dynamic> >(0, N), \n    KOKKOS_LAMBDA(int i) {\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ReduceComm<Kokkos::ReduceCommIdentity<int> >, Kokkos::Schedule<Kokkos::Dynamic> >(0, N), \n      [&] (int j) {\n        M(i, j) = -1;\n      }\n    );\n  }\n  );\n\n  Kokkos::fence();\n\n  int largest_component_size = 0;\n  int component_size = 0;\n\n  // Use Kokkos parallel_for to find the largest component size\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ReduceComm<Kokkos::ReduceCommIdentity<int> >, Kokkos::Schedule<Kokkos::Dynamic> >(0, N), \n    KOKKOS_LAMBDA(int i) {\n    // If this vertex has not been visited yet, then visit it.\n    if (M(i, i) == -1) {\n      component_size = 0;\n      // Use Kokkos parallel_for to do a BFS search from this vertex.\n      Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ReduceComm<Kokkos::ReduceCommIdentity<int> >, Kokkos::Schedule<Kokkos::Dynamic> >(0, N), \n        [&] (int j) {\n          if (M(i, j) == -1) {\n            M(i, j) = i;\n            // The value of j that has not been visited yet and whose neighboring vertex i has already been visited will be pushed into the stack\n            if (M(j, j) == -1) {\n              M(i, j) = i;\n            }\n          }\n        }\n      );\n\n      // Use Kokkos parallel_for to do a BFS search on the current vertex that has already been visited\n      Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ReduceComm<Kokkos::ReduceCommIdentity<int> >, Kokkos::Schedule<Kokkos::Dynamic> >(0, N), \n        [&] (int j) {\n          if (M(i, j) == -1) {\n            M(i, j) = i;\n          }\n        }\n      );\n\n      for (int j = 0; j < N; j++) {\n        // When the vertex has been visited, we will update the component_size.\n        if (M(i, j) == i) {\n          component_size += 1;\n        }\n      }\n      if (component_size > largest_component_size) {\n        largest_component_size = component_size;\n      }\n    }\n  }\n  );\n\n  // Return the largest component size.\n  return largest_component_size;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> vertices(\"vertices\");\n  Kokkos::View<bool*, Kokkos::HostSpace> reachable(\"reachable\");\n  Kokkos::View<bool*, Kokkos::HostSpace> visited(\"visited\");\n  Kokkos::View<bool*, Kokkos::HostSpace> color(\"color\");\n\n  Kokkos::View<int*, Kokkos::HostSpace>::HostMirror verticesHost(\"verticesHost\");\n  Kokkos::View<bool*, Kokkos::HostSpace>::HostMirror reachableHost(\"reachableHost\");\n  Kokkos::View<bool*, Kokkos::HostSpace>::HostMirror visitedHost(\"visitedHost\");\n  Kokkos::View<bool*, Kokkos::HostSpace>::HostMirror colorHost(\"colorHost\");\n\n  int numComponents = 0;\n\n  // Use Kokkos to allocate memory\n  Kokkos::parallel_for(\"fillArrays\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i) {\n    verticesHost(i) = i;\n    reachableHost(i) = false;\n    visitedHost(i) = false;\n    colorHost(i) = false;\n  });\n\n  vertices = verticesHost;\n  reachable = reachableHost;\n  visited = visitedHost;\n  color = colorHost;\n\n  // Use Kokkos to iterate over the matrix, looking for the largest component\n  Kokkos::parallel_for(\"findConnected\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i) {\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) == 1) {\n        reachableHost(j) = true;\n      }\n    }\n  });\n\n  Kokkos::parallel_for(\"findConnected2\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i) {\n    if (reachableHost(i)) {\n      numComponents = numComponents + 1;\n      //printf(\"Vertex %d has been visited\\n\", i);\n      while (reachableHost(i)) {\n        //printf(\"  Visiting vertex %d\\n\", i);\n        visitedHost(i) = true;\n        for (int j = 0; j < N; j++) {\n          if (A(i,j) == 1) {\n            if (visitedHost(j)) {\n              colorHost(i) = true;\n              //printf(\"  %d is already visited\\n\", j);\n              reachableHost(j) = false;\n            }\n            else {\n              colorHost(i) = false;\n              //printf(\"  %d is not yet visited\\n\", j);\n            }\n          }\n        }\n      }\n    }\n  });\n\n  Kokkos::parallel_for(\"findConnected3\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i) {\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) == 1) {\n        if (colorHost(i) == colorHost(j)) {\n          reachableHost(i) = false;\n          reachableHost(j) = false;\n        }\n      }\n    }\n  });\n\n  Kokkos::parallel_reduce(\"findConnected4\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA(const int& i, int& numConnected) {\n    if (reachableHost(i)) {\n      numConnected = numConnected + 1;\n    }\n  }, numComponents);\n\n  //printf(\"Largest component of graph has %d vertices\\n\", numComponents);\n\n  return numComponents;\n\n}",
            "//\n  // TODO\n  //\n\n  return 0;\n}",
            "int local_component_size = 0;\n\n\tKokkos::View<int*, Kokkos::HostSpace> component_size(\"component_size\", N);\n\tKokkos::deep_copy(component_size, -1);\n\t\n\t// TODO\n\t\n\tint max_size = 0;\n\tint max_size_idx = 0;\n\tKokkos::deep_copy(component_size, -1);\n\tfor(int i = 0; i < N; i++){\n\t\tif(component_size(i) == -1){\n\t\t\tint current_component_size = 0;\n\t\t\tqueue<int> q;\n\t\t\tq.push(i);\n\t\t\tcomponent_size(i) = 1;\n\t\t\tcurrent_component_size++;\n\t\t\twhile(!q.empty()){\n\t\t\t\tint current_node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\t\tif(A(current_node, j)!= 0){\n\t\t\t\t\t\tif(component_size(j) == -1){\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t\tcomponent_size(j) = 1;\n\t\t\t\t\t\t\tcurrent_component_size++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(current_component_size > max_size){\n\t\t\t\tmax_size = current_component_size;\n\t\t\t\tmax_size_idx = i;\n\t\t\t}\n\t\t}\n\t}\n\n\t// TODO\n\t\n\treturn max_size;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\tusing View = Kokkos::View<int*, ExecutionSpace>;\n\tusing View_Host = typename View::HostMirror;\n\n\tconst int numVertices = N;\n\tView largestComponentSize(\"Largest Component Size\", numVertices);\n\t// use the smallest value type that can represent the largest number of vertices\n\tKokkos::fill_async(largestComponentSize, 1);\n\tView_Host largestComponentSize_host = Kokkos::create_mirror_view(largestComponentSize);\n\tKokkos::deep_copy(largestComponentSize_host, largestComponentSize);\n\n\t// compute the sizes of the connected components\n\tKokkos::parallel_for(\"Compute Component Sizes\", Kokkos::RangePolicy<ExecutionSpace>(0, N), KOKKOS_LAMBDA(int i) {\n\t\tint rowSize = 1;\n\t\tfor (int j = i+1; j < numVertices; j++) {\n\t\t\tif (A(i, j)!= 0 || A(j, i)!= 0) {\n\t\t\t\trowSize += largestComponentSize_host(j);\n\t\t\t}\n\t\t}\n\t\tlargestComponentSize_host(i) = rowSize;\n\t});\n\tKokkos::deep_copy(largestComponentSize, largestComponentSize_host);\n\n\t// find the largest component size\n\tint largestComponentSize_host_host;\n\tKokkos::deep_copy(largestComponentSize_host, largestComponentSize);\n\tKokkos::parallel_reduce(\"Find Largest Component Size\", Kokkos::RangePolicy<ExecutionSpace>(0, numVertices),\n\t\t\t[=](const int &i, int &maxSize) {\n\t\t\t\tif (largestComponentSize_host(i) > maxSize) {\n\t\t\t\t\tmaxSize = largestComponentSize_host(i);\n\t\t\t\t}\n\t\t\t},\n\t\t\tKokkos::Max<int>(largestComponentSize_host_host));\n\n\t// find the size of the largest connected component\n\tint largestComponentSize_host_host_host;\n\tKokkos::deep_copy(largestComponentSize_host_host, largestComponentSize_host);\n\tKokkos::parallel_reduce(\"Find Largest Component Size\", Kokkos::RangePolicy<ExecutionSpace>(0, numVertices),\n\t\t\t[=](const int &i, int &maxSize) {\n\t\t\t\tif (largestComponentSize_host_host(i) == largestComponentSize_host_host_host) {\n\t\t\t\t\tmaxSize = largestComponentSize_host_host(i);\n\t\t\t\t}\n\t\t\t},\n\t\t\tKokkos::Max<int>(largestComponentSize_host_host_host));\n\n\treturn largestComponentSize_host_host_host;\n}",
            "// You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.\n  // You may need to make a copy of the graph, which you can use to solve this.\n  // You may use whatever data structures you want.\n  // You can assume that the graph is undirected.\n  // You can use the Kokkos::View functions, as well as Kokkos::parallel_for and Kokkos::parallel_reduce, to solve this.",
            "// TODO\n\n  return 0;\n}",
            "//TODO: Your code here\n  Kokkos::View<int*, Kokkos::HostSpace> v(\"v\");\n  Kokkos::parallel_for(\"LargestComponent::get_connected_components\", N,\n    KOKKOS_LAMBDA (const int i) {\n      Kokkos::View<int*, Kokkos::HostSpace> w(\"w\");\n      Kokkos::parallel_for(\"LargestComponent::bfs\", N,\n        KOKKOS_LAMBDA (const int j) {\n          if (A(i,j)) {\n            v(j) = 1;\n            w(j) = 0;\n          }\n        }\n      );\n      Kokkos::parallel_for(\"LargestComponent::bfs2\", N,\n        KOKKOS_LAMBDA (const int j) {\n          if (v(j)) {\n            int flag = 0;\n            if (i==j) {\n              flag = 1;\n            } else {\n              Kokkos::parallel_for(\"LargestComponent::bfs3\", N,\n                KOKKOS_LAMBDA (const int k) {\n                  if (A(j,k)) {\n                    if (v(k)) {\n                      flag = 1;\n                    }\n                  }\n                }\n              );\n            }\n            if (!flag) {\n              w(j) = 1;\n            }\n          }\n        }\n      );\n      Kokkos::parallel_for(\"LargestComponent::bfs4\", N,\n        KOKKOS_LAMBDA (const int j) {\n          if (w(j)) {\n            v(j) = 0;\n          }\n        }\n      );\n    }\n  );\n\n  int largest = 0;\n  Kokkos::parallel_reduce(\"LargestComponent::get_largest_component\", N,\n    KOKKOS_LAMBDA (const int i, int &num) {\n      if (v(i)) {\n        num++;\n        largest = num;\n      }\n    },\n    KOKKOS_LAMBDA (int &l, const int r) {\n      if (r > largest) {\n        l = r;\n        largest = l;\n      }\n    }\n  );\n\n  return largest;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "omp",
        "prompt": "#include <omp.h>\n\n/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int *visited = new int[N];\n    std::fill(visited, visited+N, 0);\n\n    int max = 0;\n\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; i++){\n        if(visited[i] == 0){\n            int count = 0;\n            std::stack<int> stack;\n            stack.push(i);\n            while(!stack.empty()){\n                int vertex = stack.top();\n                stack.pop();\n                visited[vertex] = 1;\n                count++;\n\n                for(size_t j = 0; j < N; j++){\n                    if(A[i*N+j] == 1 && visited[j] == 0){\n                        stack.push(j);\n                    }\n                }\n            }\n\n            if(count > max){\n                max = count;\n            }\n        }\n    }\n\n    delete [] visited;\n\n    return max;\n}",
            "// your code here\n  std::vector<int> num(N, 1);\n  int max = 1;\n#pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] && i!= j) {\n        if (num[i] < num[j]) {\n          num[i] += num[j];\n          num[j] = num[i];\n        } else if (num[i] > num[j]) {\n          num[j] += num[i];\n          num[i] = num[j];\n        }\n      }\n    }\n  }\n#pragma omp parallel for reduction(max : max)\n  for (size_t i = 0; i < N; i++) {\n    max = std::max(max, num[i]);\n  }\n  return max;\n}",
            "std::vector<bool> marked(N, false);\n\n    std::function<void(int)> dfs = [&](int v) {\n        if (!marked[v]) {\n            marked[v] = true;\n            for (int i = 0; i < N; ++i) {\n                if (A[N * v + i] &&!marked[i]) {\n                    dfs(i);\n                }\n            }\n        }\n    };\n\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!marked[i]) {\n            dfs(i);\n            ++count;\n        }\n    }\n\n    return count;\n}",
            "// TODO: YOUR CODE HERE\n    int max_component = 0;\n\n    int* component = new int[N];\n    int* visited = new int[N];\n    memset(visited, 0, sizeof(int) * N);\n\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            int curr_component = 0;\n            std::queue<int> Q;\n            Q.push(i);\n            visited[i] = 1;\n            while (Q.size() > 0) {\n                int curr = Q.front();\n                Q.pop();\n                curr_component++;\n                for (int j = 0; j < N; j++) {\n                    if (A[curr * N + j] == 1) {\n                        if (visited[j] == 0) {\n                            Q.push(j);\n                            visited[j] = 1;\n                        }\n                    }\n                }\n            }\n\n            if (curr_component > max_component)\n                max_component = curr_component;\n        }\n    }\n\n    delete[] component;\n    delete[] visited;\n\n    return max_component;\n}",
            "// TODO: Your code goes here!\n\n  // Note that the for loop should iterate over the components\n  // This will ensure that each loop iteration is responsible for a unique component\n\n  return -1;\n}",
            "int count = 0;\n\tbool* visited = new bool[N];\n\tstd::fill(visited, visited + N, false);\n\tstd::vector<int> queue;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tqueue.push_back(i);\n\t\t\twhile (queue.size()) {\n\t\t\t\tauto& curr = queue.back();\n\t\t\t\tif (visited[curr]) {\n\t\t\t\t\tqueue.pop_back();\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tvisited[curr] = true;\n\t\t\t\tqueue.pop_back();\n\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[curr * N + j] &&!visited[j]) {\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// Implement this function\n\tint *visited = new int[N];\n\tint *componentSize = new int[N];\n\tint maxComponentSize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tcomponentSize[i] = 1;\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tint curComponentSize = 0;\n\t\t\tint curComponentIndex = i;\n\t\t\tstd::vector<int> queue;\n\t\t\tqueue.push_back(curComponentIndex);\n\t\t\twhile (queue.size() > 0) {\n\t\t\t\tcurComponentIndex = queue.front();\n\t\t\t\tqueue.erase(queue.begin());\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[curComponentIndex * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tcomponentSize[j] = componentSize[i];\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcurComponentSize++;\n\t\t\t}\n\t\t\tif (curComponentSize > maxComponentSize) {\n\t\t\t\tmaxComponentSize = curComponentSize;\n\t\t\t}\n\t\t}\n\t}\n\n\tint totalVertices = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\ttotalVertices += componentSize[i];\n\t}\n\n\treturn totalVertices;\n}",
            "int ans = 0;\n\n  #pragma omp parallel\n  {\n    std::vector<int> comp(N, -1);\n    int thid = omp_get_thread_num();\n    int nthreads = omp_get_num_threads();\n    int nblock = N / nthreads;\n    int nleft = N % nthreads;\n\n    #pragma omp for\n    for (size_t i = 0; i < N; i++) {\n      if (comp[i] == -1) {\n        comp[i] = i;\n        for (size_t j = 0; j < N; j++) {\n          if (i!= j && A[i * N + j] && comp[j] == -1) {\n            comp[j] = i;\n          }\n        }\n      }\n    }\n\n    int max_size = 0;\n    for (size_t i = 0; i < N; i++) {\n      if (comp[i] > max_size) {\n        max_size = comp[i];\n      }\n    }\n    #pragma omp critical\n    {\n      if (max_size > ans) {\n        ans = max_size;\n      }\n    }\n  }\n\n  return ans;\n}",
            "// TODO: Fill this in.\n\tint *visited = new int[N];\n\tint visited_count = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tvisited[i] = 0;\n\t}\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tvisited_count++;\n\t\t\t}\n\t\t\tif (i + 1 < N) {\n\t\t\t\tdfs(A, i, visited, visited_count);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn visited_count;\n}",
            "int* comp = new int[N]();\n\tint* visited = new int[N]();\n\tint* adj = new int[N]();\n\tint* adj_comp = new int[N]();\n\tint comp_size = 0;\n\n\tomp_set_num_threads(8);\n\t#pragma omp parallel for schedule(guided)\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tcomp[i] = 0;\n\t\tadj[i] = 0;\n\t\tadj_comp[i] = 0;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tadj[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcomp[i] = 1;\n\t\t\tcomp_size++;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tif (comp[j]!= 1) {\n\t\t\t\t\t\tcomp[j] = 1;\n\t\t\t\t\t\tcomp_size++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tadj_comp[i] = adj[i];\n\t\t}\n\t}\n\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (max < adj_comp[i]) {\n\t\t\tmax = adj_comp[i];\n\t\t}\n\t}\n\n\tdelete[] visited;\n\tdelete[] comp;\n\tdelete[] adj;\n\tdelete[] adj_comp;\n\n\treturn comp_size;\n}",
            "int largestComponentSize = 0;\n    std::vector<bool> visited(N, false);\n\n    #pragma omp parallel for default(shared) schedule(dynamic) \\\n    firstprivate(N) private(largestComponentSize)\n    for (int v = 0; v < N; ++v) {\n        if (visited[v]) {\n            continue;\n        }\n        std::vector<int> stack;\n        stack.push_back(v);\n        while (stack.size() > 0) {\n            int top = stack.back();\n            stack.pop_back();\n            visited[top] = true;\n            for (int i = 0; i < N; ++i) {\n                if (!visited[i] && (A[N * top + i] == 1)) {\n                    stack.push_back(i);\n                }\n            }\n        }\n\n        #pragma omp critical\n        if (largestComponentSize < stack.size()) {\n            largestComponentSize = stack.size();\n        }\n    }\n\n    return largestComponentSize;\n}",
            "int count = 0;\n    bool *visited = new bool[N]();\n    int *scc = new int[N]();\n    int *low = new int[N]();\n    int *dfs_num = new int[N]();\n    int *dfs_stack = new int[N]();\n    int dfs_stack_top = 0;\n    int dfs_num_counter = 0;\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(static)\n        for(size_t v = 0; v < N; ++v) {\n            if (!visited[v]) {\n                tarjan(A, N, v, visited, scc, low, dfs_num, dfs_stack, dfs_stack_top, dfs_num_counter);\n            }\n        }\n    }\n    int max_scc = 0;\n    for (int i = 0; i < N; i++) {\n        if (max_scc < scc[i]) {\n            max_scc = scc[i];\n        }\n    }\n    count = max_scc;\n    delete[] visited;\n    delete[] scc;\n    delete[] low;\n    delete[] dfs_num;\n    delete[] dfs_stack;\n    return count;\n}",
            "std::vector<bool> isVisited(N, false);\n  int maxComponentSize = 0;\n  for(int i=0;i<N;i++){\n    if(isVisited[i] == false){\n      int componentSize = 0;\n      std::vector<int> queue;\n      queue.push_back(i);\n      isVisited[i] = true;\n      while(!queue.empty()){\n        int current = queue.front();\n        queue.erase(queue.begin());\n        for(int j=0;j<N;j++){\n          if(A[i*N+j]==1 && isVisited[j] == false){\n            isVisited[j] = true;\n            queue.push_back(j);\n            componentSize++;\n          }\n        }\n      }\n      if(componentSize > maxComponentSize){\n        maxComponentSize = componentSize;\n      }\n    }\n  }\n  return maxComponentSize;\n}",
            "// TODO: add code here\n\n  return 0;\n}",
            "#pragma omp parallel for schedule(static)\n\tfor (int i = 0; i < N; i++) {\n\t\t// Implement your solution here.\n\t}\n}",
            "std::vector<int> vis(N, 0);\n\n  int ans = 0;\n  for (int i = 0; i < N; i++) {\n    if (vis[i] == 0) {\n      std::vector<int> stack;\n      stack.push_back(i);\n      while (!stack.empty()) {\n        int top = stack.back();\n        stack.pop_back();\n        if (vis[top] == 0) {\n          vis[top] = 1;\n          ans++;\n          for (int j = 0; j < N; j++) {\n            if (A[top*N + j] == 1) {\n              stack.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return ans;\n}",
            "// Your code goes here\n}",
            "std::vector<bool> visited(N);\n  std::vector<int> parent(N);\n  std::vector<int> rank(N);\n  int largestComponent = 0;\n  for (size_t i = 0; i < N; ++i) {\n    parent[i] = -1;\n    rank[i] = 1;\n  }\n\n  /*\n  // Serial DFS\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n    int numVertices = 0;\n    numVertices += dfs(i, A, visited, parent);\n    if (numVertices > largestComponent) {\n      largestComponent = numVertices;\n    }\n  }\n  */\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n    int numVertices = 0;\n    numVertices += dfs(i, A, visited, parent);\n    #pragma omp critical\n    {\n      if (numVertices > largestComponent) {\n        largestComponent = numVertices;\n      }\n    }\n  }\n\n  return largestComponent;\n}",
            "int largestComponent = 0;\n\n    // TODO: implement\n\n    return largestComponent;\n}",
            "int num_vertices = 0;\n    int largest_component = 0;\n    int visited[N];\n\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n\n    int vertex = 0;\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            int num = 0;\n            vertex = i;\n            #pragma omp parallel for\n            for (int j = 0; j < N; j++) {\n                if (A[N * vertex + i] == 1) {\n                    num++;\n                }\n            }\n            visited[i] = 1;\n            num_vertices++;\n        }\n    }\n    if (largest_component < num_vertices) {\n        largest_component = num_vertices;\n    }\n    return largest_component;\n}",
            "// TODO: your code here\n    return -1;\n}",
            "// Your code here\n\treturn 0;\n}",
            "auto components = new bool[N];\n\tbool is_component_found = false;\n\tsize_t max_component_size = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!components[i]) {\n\t\t\tsize_t current_component_size = 1;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (!components[j]) {\n\t\t\t\t\tcomponents[j] = true;\n\t\t\t\t\tif (A[i * N + j]) {\n\t\t\t\t\t\tcurrent_component_size += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!is_component_found || current_component_size > max_component_size) {\n\t\t\t\tis_component_found = true;\n\t\t\t\tmax_component_size = current_component_size;\n\t\t\t}\n\t\t}\n\t}\n\treturn max_component_size;\n}",
            "std::vector<int> A_cp(A.size(), 0);\n\tstd::vector<bool> visited(N, false);\n\n\tint max_comp = 0;\n\n\t// iterate over every row of the adjacency matrix\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == false) {\n\t\t\tint comp = 1;\n\t\t\tstd::queue<int> Q;\n\t\t\tQ.push(i);\n\t\t\tvisited[i] = true;\n\n\t\t\t// check the component size in the adjacency matrix starting from i\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tint node = Q.front();\n\t\t\t\tQ.pop();\n\n\t\t\t\t// if A_cp[node] == 0, we will assign a unique value to it\n\t\t\t\tif (A_cp[node] == 0)\n\t\t\t\t\tA_cp[node] = 1;\n\n\t\t\t\t// push the neighbors into the queue\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (i!= j &&!visited[j] && A[N*node+j]) {\n\t\t\t\t\t\tQ.push(j);\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcomp++;\n\t\t\t}\n\n\t\t\tif (comp > max_comp)\n\t\t\t\tmax_comp = comp;\n\t\t}\n\t}\n\n\treturn max_comp;\n}",
            "omp_set_num_threads(omp_get_num_procs());\n\tint thread_num = omp_get_num_threads();\n\tint max_size = 0;\n\t\n\t#pragma omp parallel num_threads(thread_num)\n\t{\n\t\t\n\t\tint size = 0;\n\t\tint current_thread_id = omp_get_thread_num();\n\t\tint start = current_thread_id * (N/thread_num);\n\t\tint end = start + (N/thread_num);\n\t\t\n\t\tif (current_thread_id == thread_num-1){\n\t\t\tend = N;\n\t\t}\n\t\t\n\t\tint* visited = new int[N];\n\t\t\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tvisited[i] = 0;\n\t\t}\n\t\t\n\t\tfor (int i = start; i < end; i++){\n\t\t\tif (visited[i] == 0){\n\t\t\t\tsize++;\n\t\t\t\t\n\t\t\t\t#pragma omp parallel for\n\t\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\t\tif (A[i*N+j] == 1){\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (size > max_size){\n\t\t\tmax_size = size;\n\t\t}\n\t\tdelete[] visited;\n\t}\n\t\n\treturn max_size;\n}",
            "int maxCnt = 0;\n\tstd::vector<bool> visited(N, false);\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i])\n\t\t\tcontinue;\n\t\tint cnt = 0;\n\t\tstd::vector<int> queue;\n\t\tqueue.push_back(i);\n\t\twhile (queue.size() > 0) {\n\t\t\tint idx = queue.back();\n\t\t\tqueue.pop_back();\n\t\t\tif (visited[idx])\n\t\t\t\tcontinue;\n\t\t\tvisited[idx] = true;\n\t\t\tcnt++;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (visited[j] || A[idx * N + j] == 0)\n\t\t\t\t\tcontinue;\n\t\t\t\tqueue.push_back(j);\n\t\t\t}\n\t\t}\n\t\tmaxCnt = (cnt > maxCnt)? cnt : maxCnt;\n\t}\n\treturn maxCnt;\n}",
            "/* TODO: YOUR CODE HERE */\n  std::vector<bool> visited(N, false);\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == false) {\n      count++;\n      std::vector<int> toVisit{i};\n      while (toVisit.size() > 0) {\n        int currentVertex = toVisit[0];\n        toVisit.erase(toVisit.begin());\n        if (visited[currentVertex]) {\n          continue;\n        }\n        visited[currentVertex] = true;\n        for (int j = 0; j < N; j++) {\n          if (A[currentVertex * N + j] == 1) {\n            toVisit.push_back(j);\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> v(N, 0);\n    std::vector<int> visited(N, 0);\n    int comp_size = 0;\n    int max_comp_size = 0;\n\n    //#pragma omp parallel for private(v, visited)\n    for (size_t i = 0; i < N; i++) {\n        v[i] = 0;\n        visited[i] = 0;\n\n        // Traverse the current component\n        int size = 0;\n        if (A[i*N + i] == 1 && visited[i] == 0) {\n            dfs(A, i, N, visited, v, size);\n            comp_size = size;\n        }\n        if (comp_size > max_comp_size) {\n            max_comp_size = comp_size;\n        }\n    }\n\n    return max_comp_size;\n}",
            "int largestComponentSize = 0;\n\tint count = 0;\n\tint* visited = new int[N];\n\tfor (int i = 0; i < N; ++i) {\n\t\tvisited[i] = 0;\n\t}\n\n\tomp_set_num_threads(4);\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp parallel for\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j]!= 0 && visited[j] == 0) {\n\t\t\t\t\t#pragma omp critical\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t++count;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tlargestComponentSize = count;\n\n\tdelete[] visited;\n\treturn largestComponentSize;\n}",
            "omp_set_num_threads(4);\n\t#pragma omp parallel\n\t{\n\t\tint *A_cpy;\n\t\tint *components;\n\t\tint *current_components;\n\t\tA_cpy = (int *)malloc(N*N*sizeof(int));\n\t\tcomponents = (int *)malloc(N*sizeof(int));\n\t\tcurrent_components = (int *)malloc(N*sizeof(int));\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t{\n\t\t\t\tA_cpy[i * N + j] = A[i * N + j];\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tcomponents[i] = 1;\n\t\t}\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tcurrent_components[i] = 1;\n\t\t}\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t{\n\t\t\t\tif ((i == j) || (A_cpy[i * N + j] == 0))\n\t\t\t\t\tcontinue;\n\t\t\t\t#pragma omp critical\n\t\t\t\t{\n\t\t\t\t\tif (current_components[j] == 0)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tif (A_cpy[i * N + j] == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\tA_cpy[i * N + j] = 2;\n\t\t\t\t\t\tA_cpy[j * N + i] = 2;\n\t\t\t\t\t\tcurrent_components[j] = 0;\n\t\t\t\t\t\tcomponents[i] += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t\t{\n\t\t\t\t\tif (current_components[j] == 0)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tif (A_cpy[i * N + j] == 2)\n\t\t\t\t\t{\n\t\t\t\t\t\tA_cpy[i * N + j] = 3;\n\t\t\t\t\t\tA_cpy[j * N + i] = 3;\n\t\t\t\t\t\tcurrent_components[j] = 0;\n\t\t\t\t\t\tcomponents[i] += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint max = 0;\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tif (components[i] > max)\n\t\t\t\tmax = components[i];\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (max > components[omp_get_thread_num()])\n\t\t\t\tcomponents[omp_get_thread_num()] = max;\n\t\t}\n\t\tfree(A_cpy);\n\t\tfree(components);\n\t\tfree(current_components);\n\t}\n\n\treturn components[0];\n}",
            "std::vector<std::vector<int>> connectedComponents(N, std::vector<int> (N, 0));\n  int sizeOfLargestComponent = 0;\n  int sizeOfCurrentComponent = 0;\n  int largestComponent = 0;\n  int visited = 0;\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      visited = 0;\n      if (i == j)\n        continue;\n      if (A[i*N + j] == 1) {\n        connectedComponents[i][j] = 1;\n        connectedComponents[j][i] = 1;\n      }\n      if (A[i*N + j] == 1 && visited == 0) {\n        sizeOfCurrentComponent = 1;\n        std::vector<int> bfsTraversal(N, 0);\n        std::queue<int> q;\n        q.push(i);\n        bfsTraversal[i] = 1;\n\n        while (!q.empty()) {\n          int u = q.front();\n          q.pop();\n          for (int v = 0; v < N; v++) {\n            if (connectedComponents[u][v] == 1 && bfsTraversal[v] == 0) {\n              bfsTraversal[v] = 1;\n              q.push(v);\n              sizeOfCurrentComponent++;\n            }\n          }\n        }\n        if (sizeOfLargestComponent < sizeOfCurrentComponent) {\n          sizeOfLargestComponent = sizeOfCurrentComponent;\n          largestComponent = i;\n        }\n      }\n    }\n  }\n  return sizeOfLargestComponent;\n}",
            "/* your code here */\n}",
            "//TODO: write your code here\n  std::vector<int> visited(N,0);\n  std::vector<int> components(N,0);\n  int max_component = 0;\n  int count = 0;\n  int count_current = 0;\n  int component = 0;\n\n  for(size_t i = 0; i < N; i++){\n      if(!visited[i]){\n          component = i;\n          visited[i] = 1;\n          components[i] = 1;\n          count_current = 1;\n          for(size_t j = 0; j < N; j++){\n            if(!visited[j] && A[i*N + j]){\n              visited[j] = 1;\n              components[j] = component;\n              count_current++;\n            }\n          }\n          if(count_current > count){\n              count = count_current;\n              max_component = component;\n          }\n      }\n  }\n\n  int max_component_count = 0;\n\n  for(size_t i = 0; i < N; i++){\n      if(components[i] == max_component){\n          max_component_count++;\n      }\n  }\n\n  return max_component_count;\n}",
            "// TODO: Your code here\n  std::vector<int> connected(N, 0);\n  std::vector<int> component(N, 0);\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        component[i] = std::max(component[i], connected[j] + 1);\n      }\n    }\n  }\n\n  int largest = 0;\n  for (int i = 0; i < N; i++) {\n    largest = std::max(largest, component[i]);\n  }\n\n  return largest;\n}",
            "// Your code here\n\n\tint i, j, k, largestComponent = 0;\n\n\t#pragma omp parallel for private(j) firstprivate(N) reduction(+:largestComponent)\n\tfor(i = 0; i < N; i++) {\n\t\tfor(j = 0; j < N; j++) {\n\t\t\tif(i == j)\n\t\t\t\tcontinue;\n\t\t\t\n\t\t\tif(A[i*N+j]!= 0) {\n\t\t\t\tlargestComponent++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn largestComponent;\n}",
            "int visited[N];\n\n    for (size_t i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n\n    int max = 0;\n\n    #pragma omp parallel for schedule(dynamic)\n    for (size_t i = 0; i < N; i++) {\n\n        for (size_t j = 0; j < N; j++) {\n\n            if (A[i * N + j]) {\n\n                #pragma omp critical\n                {\n                    if (!visited[j]) {\n                        int size = 1;\n\n                        #pragma omp parallel for schedule(dynamic)\n                        for (size_t k = 0; k < N; k++) {\n                            if (A[k * N + j]) {\n                                size++;\n                                visited[k] = 1;\n                            }\n                        }\n\n                        if (max < size) {\n                            max = size;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return max;\n}",
            "std::vector<bool> visited(N, false);\n  int largestComponentSize = 0;\n  // TODO: Parallelize this loop with OpenMP\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      visited[i] = true;\n      int localComponentSize = 0;\n      std::queue<int> q;\n      q.push(i);\n      while (!q.empty()) {\n        int j = q.front();\n        q.pop();\n        localComponentSize++;\n        for (size_t k = 0; k < N; ++k) {\n          if (A[N * j + k] == 1 &&!visited[k]) {\n            q.push(k);\n            visited[k] = true;\n          }\n        }\n      }\n      largestComponentSize = std::max(largestComponentSize, localComponentSize);\n    }\n  }\n  return largestComponentSize;\n}",
            "// TODO: Replace with a single-line for loop\n    for (int i=0; i<N; i++){\n        for (int j=0; j<N; j++){\n            if (A[i*N+j] == 1){\n                A[j*N+i] = 1;\n            }\n        }\n    }\n\n    // TODO: Replace with a single-line for loop\n    for (int k=0; k<N; k++){\n        for (int i=0; i<N; i++){\n            for (int j=0; j<N; j++){\n                if (A[i*N+k] == 1 && A[k*N+j] == 1){\n                    A[i*N+j] = 1;\n                }\n            }\n        }\n    }\n\n    int count = 0;\n    // TODO: Replace with a single-line for loop\n    for (int i=0; i<N; i++){\n        for (int j=0; j<N; j++){\n            if (A[i*N+j] == 1){\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> num(N, 0);\n\n#pragma omp parallel for shared(visited, num)\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      int cn = 1;\n      std::queue<int> q;\n      q.push(i);\n      visited[i] = 1;\n\n      while (!q.empty()) {\n        int j = q.front();\n        q.pop();\n        for (int k = 0; k < N; k++) {\n          if (A[N * j + k] == 1 && visited[k] == 0) {\n            q.push(k);\n            visited[k] = 1;\n            cn++;\n          }\n        }\n      }\n      num[i] = cn;\n    }\n  }\n\n  int res = 0;\n  int idx = 0;\n  for (int i = 0; i < N; i++) {\n    if (num[i] > res) {\n      res = num[i];\n      idx = i;\n    }\n  }\n  return res;\n}",
            "// We will solve the problem in three steps.  In step 1, we will initialize an array S of size N\n    // to store the set of vertices in the same component as a vertex.  In step 2, we will calculate\n    // S[i] = argmax_{j!= i} A[i,j] using a parallel loop.  In step 3, we will return the largest\n    // component size by counting the number of unique values in S.\n\n    // The first step: initialize the array S.\n    std::vector<int> S(N, -1);\n\n    // The second step: in parallel, find the largest component size.\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int largest = -1;\n        for (size_t j = 0; j < N; ++j) {\n            if (j!= i && A[i * N + j] > largest) {\n                largest = A[i * N + j];\n            }\n        }\n        S[i] = largest;\n    }\n\n    // The third step: count the number of unique values in S.\n    std::vector<int> count(N, 0);\n    for (int i : S) {\n        count[i]++;\n    }\n\n    int largest = 0;\n    for (int i : count) {\n        if (i > largest) {\n            largest = i;\n        }\n    }\n\n    return largest;\n}",
            "// TODO: use OpenMP to compute in parallel\n    return 0;\n}",
            "int max_size = 0;\n  int max_size_comp = 0;\n\n  //#pragma omp parallel\n  //{\n\n    //#pragma omp for reduction(+:max_size)\n    //for (int i = 0; i < N; i++) {\n    //  for (int j = 0; j < N; j++) {\n    //    if (A[i*N + j] == 1) {\n    //      max_size++;\n    //    }\n    //  }\n    //}\n\n  for (int i = 0; i < N; i++) {\n    int size = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        size++;\n      }\n    }\n    if (max_size < size) {\n      max_size = size;\n      max_size_comp = i;\n    }\n  }\n  //}\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        A[i*N + j] = 0;\n        if (i == max_size_comp || j == max_size_comp) {\n          A[i*N + j] = 1;\n        }\n      }\n    }\n  }\n\n  count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        count++;\n      }\n    }\n  }\n\n  return max_size;\n}",
            "int largestComponent = 0;\n    // TODO: Fill this in\n    return largestComponent;\n}",
            "int num_threads = 0;\n\tint component_size = 0;\n\t\n\tint *visited = new int[N]();\n\tint *stack = new int[N]();\n\tint *adj = new int[N];\n\t\n\tstd::fill(visited, visited + N, 0);\n\tstd::fill(adj, adj + N, 0);\n\t\n\t#pragma omp parallel num_threads(num_threads)\n\t{\n\t\t\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tstack[0] = i;\n\t\t\t\tint top = 0;\n\t\t\t\twhile (top >= 0) {\n\t\t\t\t\tint vertex = stack[top];\n\t\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (adj[j] == 0 && A[j * N + vertex] == 1) {\n\t\t\t\t\t\t\tstack[++top] = j;\n\t\t\t\t\t\t\tadj[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tvisited[vertex] = 1;\n\t\t\t\t\t--top;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) component_size++;\n\t}\n\t\n\tdelete[] visited;\n\tdelete[] stack;\n\tdelete[] adj;\n\t\n\treturn component_size;\n}",
            "auto getComponent = [&](size_t i) {\n    std::vector<size_t> visited;\n    std::stack<size_t> st;\n    st.push(i);\n\n    while (!st.empty()) {\n      size_t v = st.top();\n      st.pop();\n\n      visited.push_back(v);\n\n      for (size_t j = 0; j < N; j++) {\n        if (A[N * v + j] && std::find(visited.begin(), visited.end(), j) == visited.end()) {\n          st.push(j);\n        }\n      }\n    }\n\n    return visited.size();\n  };\n\n  std::vector<int> components(N);\n  std::vector<int> component_sizes(N);\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    components[i] = i;\n    component_sizes[i] = getComponent(i);\n  }\n\n  size_t max_size = 0;\n  size_t max_i = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (component_sizes[i] > max_size) {\n      max_size = component_sizes[i];\n      max_i = i;\n    }\n  }\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    if (components[i]!= max_i) {\n      components[i] = max_i;\n    }\n  }\n\n  size_t max_component_size = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (components[i] == max_i) {\n      max_component_size += component_sizes[i];\n    }\n  }\n\n  return max_component_size;\n}",
            "// TODO: Your code here\n    int n = N;\n    int count = 0;\n    std::vector<int> visited(n,0);\n    int max_count = 0;\n    int max_size = 0;\n    for (int i=0;i<n;i++){\n        if (visited[i] == 0){\n            visited[i] = 1;\n            count++;\n            for (int j=0;j<n;j++){\n                if (visited[j] == 0 && A[i*n+j]!= 0){\n                    visited[j] = 1;\n                    count++;\n                }\n            }\n            if (count > max_count){\n                max_count = count;\n                max_size = i;\n            }\n            count = 0;\n        }\n    }\n    int largest_component = 0;\n    for (int i=0;i<n;i++){\n        if (A[i*n+max_size]!= 0){\n            visited[i] = 1;\n            largest_component++;\n        }\n    }\n    return largest_component;\n}",
            "/* YOUR CODE GOES HERE */\n  // You can use omp_get_num_threads() and omp_get_thread_num() functions\n  // to determine the number of threads and the ID of the thread.\n  // You can use omp_set_num_threads() function to set the number of threads.\n\n  // You can use the code below to obtain the size of the graph\n  // (i.e. the number of vertices)\n\n  int* component;\n  int* visited;\n  int counter = 0;\n  component = new int[N];\n  visited = new int[N];\n  for(int i = 0; i < N; i++)\n    {\n      component[i] = i;\n      visited[i] = 0;\n    }\n\n  int max = 0;\n  for(int i = 0; i < N; i++)\n    {\n      if(!visited[i])\n\t{\n\t  int size = dfs(i, component, visited, A, N);\n\t  if(size > max)\n\t    {\n\t      max = size;\n\t    }\n\t}\n    }\n\n  delete[] component;\n  delete[] visited;\n  return max;\n}",
            "std::vector<int> labels(N, -1);\n\tint ncomponents = 0;\n\n\t// TODO: Your code goes here\n#pragma omp parallel\n\t{\n\t\tint thread_id = omp_get_thread_num();\n\t\tint nthreads = omp_get_num_threads();\n\t\tint chunk = N / nthreads + 1;\n\n\t\tfor (int i = thread_id * chunk; i < std::min(N, (thread_id + 1) * chunk); ++i) {\n\t\t\tif (labels[i] == -1) {\n\t\t\t\tlabels[i] = i;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (labels[j] == -1 && A[i * N + j] == 1) {\n\t\t\t\t\t\tlabels[j] = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tint max_label = 0;\n\t\tfor (int i = thread_id * chunk; i < std::min(N, (thread_id + 1) * chunk); ++i) {\n\t\t\tmax_label = std::max(max_label, labels[i]);\n\t\t}\n#pragma omp critical\n\t\tncomponents = std::max(ncomponents, max_label);\n\t}\n\treturn ncomponents + 1;\n}",
            "const int M = N * N;\n  // Create a boolean array to store the visited nodes\n  std::vector<int> visited(N, 0);\n\n  #pragma omp parallel for\n  for (int i = 0; i < M; i++) {\n    if (A[i] == 1 &&!visited[i]) {\n      // Depth-first search\n      std::vector<int> stack;\n      stack.push_back(i);\n      while (!stack.empty()) {\n        int node = stack.back();\n        stack.pop_back();\n        visited[node] = 1;\n        // Explore all unvisited neighbours\n        for (int j = 0; j < N; j++) {\n          if (A[N * node + j] == 1 &&!visited[j]) {\n            stack.push_back(j);\n          }\n        }\n      }\n    }\n  }\n\n  // Count the number of 1s in the visited vector\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited[i]) {\n      count++;\n    }\n  }\n  return count;\n}",
            "std::vector<bool> component(N, 0);\n  int max_component_size = 0;\n  int component_size = 0;\n\n#pragma omp parallel for shared(component) \\\n    default(none) schedule(dynamic, 1)\n  for (size_t i = 0; i < N; ++i) {\n    if (component[i]) {\n      continue;\n    }\n    component_size = 0;\n    std::vector<bool> visited(N, 0);\n    std::vector<size_t> stack;\n    stack.push_back(i);\n    while (!stack.empty()) {\n      auto const index = stack.back();\n      stack.pop_back();\n      if (visited[index]) {\n        continue;\n      }\n      component_size++;\n      visited[index] = true;\n      for (size_t j = 0; j < N; ++j) {\n        if (A[index * N + j]) {\n          stack.push_back(j);\n        }\n      }\n    }\n    if (component_size > max_component_size) {\n      max_component_size = component_size;\n    }\n  }\n  return max_component_size;\n}",
            "if (A.size()!= N * N)\n    throw std::length_error(\"A is not an NxN matrix\");\n\n  std::vector<int> visited(N, 0);\n  int max_size = 0;\n  int curr_size = 0;\n\n#pragma omp parallel for private(curr_size) reduction(max:max_size)\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i])\n      continue;\n    curr_size = 0;\n    dfs(i, A, visited, curr_size);\n    if (max_size < curr_size)\n      max_size = curr_size;\n  }\n\n  return max_size;\n}",
            "// Implement me!\n\treturn -1;\n}",
            "int numOfThreads = omp_get_max_threads();\n  std::vector<int> componentCount(N, 0);\n  std::vector<bool> visited(N, false);\n  int maxComponentSize = 0;\n  #pragma omp parallel num_threads(numOfThreads)\n  {\n    int myComponentSize = 0;\n    int myComponentId = 0;\n    #pragma omp for\n    for (int i = 0; i < N; ++i) {\n      if (!visited[i]) {\n        myComponentId = i;\n        myComponentSize = 1;\n        std::vector<int> stack = {i};\n        visited[i] = true;\n        while (!stack.empty()) {\n          int node = stack.back();\n          stack.pop_back();\n          for (int j = 0; j < N; ++j) {\n            if (A[node * N + j] &&!visited[j]) {\n              stack.push_back(j);\n              visited[j] = true;\n              myComponentSize++;\n            }\n          }\n        }\n        #pragma omp critical\n        {\n          if (myComponentSize > maxComponentSize) {\n            maxComponentSize = myComponentSize;\n          }\n        }\n      }\n    }\n  }\n  return maxComponentSize;\n}",
            "int max = 0;\n\t\n\t#pragma omp parallel for reduction(max: max)\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i * N + i] == 1) {\n\t\t\tint count = 0;\n\t\t\tstd::vector<bool> visit(N, false);\n\t\t\tstd::queue<int> q;\n\t\t\tvisit[i] = true;\n\t\t\tq.push(i);\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint id = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (!visit[j] && A[id * N + j] == 1) {\n\t\t\t\t\t\tvisit[j] = true;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t++count;\n\t\t\t}\n\t\t\tif (count > max) {\n\t\t\t\tmax = count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn max;\n}",
            "std::vector<bool> vertices(N, false);\n\tint count = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (A[i * N + i] &&!vertices[i]) {\n\t\t\tint k = i;\n\t\t\twhile (!vertices[k]) {\n\t\t\t\tvertices[k] = true;\n\t\t\t\tk = A[k * N + i];\n\t\t\t}\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "}",
            "std::vector<int> B(N);\n    std::vector<int> C(N);\n    std::vector<int> D(N);\n    std::vector<int> E(N);\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                B[i] = 1;\n                C[j] = 1;\n            }\n        }\n    }\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (B[i] && C[j]) {\n                E[i] = 1;\n            }\n        }\n    }\n\n    int count = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (E[i]) {\n            count++;\n        }\n    }\n    return count;\n}",
            "// TODO\n\tint visited[N];\n\tint largest_component_size = 0;\n\tint current_component_size = 0;\n\tfor (int i = 0; i < N; ++i)\n\t\tvisited[i] = 0;\n\tint x = 0;\n\tint y = 0;\n\tint index;\n\tint temp = 0;\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for private(x) schedule(dynamic)\n\t\tfor (x = 0; x < N; x++) {\n\t\t\tif (visited[x] == 0) {\n\t\t\t\tcurrent_component_size = 0;\n\t\t\t\tvisited[x] = 1;\n\t\t\t\tcurrent_component_size++;\n\t\t\t\tindex = x;\n\t\t\t\twhile (A[index * N + x]!= 0) {\n\t\t\t\t\tvisited[index] = 1;\n\t\t\t\t\tcurrent_component_size++;\n\t\t\t\t\tindex = A[index * N + x] - 1;\n\t\t\t\t}\n\t\t\t\t#pragma omp critical\n\t\t\t\t{\n\t\t\t\t\tif (current_component_size > largest_component_size) {\n\t\t\t\t\t\tlargest_component_size = current_component_size;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn largest_component_size;\n}",
            "// TODO: Fill in your code here\n  std::vector<bool> reachable(N, false);\n\n  // OMP - Parallel for for-loop\n  // Loop over all rows in the adjacency matrix\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        reachable[i] = true;\n        break;\n      }\n    }\n  }\n\n  // Count the number of reachable vertices in the graph\n  size_t reachable_count = 0;\n  for(auto& v : reachable) {\n    if (v) {\n      reachable_count++;\n    }\n  }\n\n  return reachable_count;\n}",
            "// your code here\n  std::vector<int> comp(N, 0);\n  std::vector<int> colors(N, 0);\n  int color = 0;\n  int c = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (colors[i] == 0) {\n      color = dfs(i, color, comp, colors, A, N);\n      color++;\n    }\n  }\n\n  int max_c = 0;\n  for (int i = 0; i < N; i++) {\n    if (comp[i] > max_c) {\n      max_c = comp[i];\n    }\n  }\n\n  return max_c;\n}",
            "int count = 0;\n\tbool* visited = new bool[N];\n\tfor (size_t i = 0; i < N; ++i) visited[i] = false;\n\tstd::vector<int> q;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tq.clear();\n\t\tq.push_back(i);\n\t\twhile (q.size()) {\n\t\t\tint u = q.back();\n\t\t\tq.pop_back();\n\t\t\tvisited[u] = true;\n\t\t\t++count;\n\t\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\t\tif (A[v * N + u]) q.push_back(v);\n\t\t\t}\n\t\t}\n\t}\n\tdelete[] visited;\n\treturn count;\n}",
            "int size = 0;\n\tint maxSize = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> queue;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tqueue.push_back(i);\n\n\t\t\twhile (queue.size() > 0) {\n\t\t\t\tint curr = queue.back();\n\t\t\t\tqueue.pop_back();\n\t\t\t\t++size;\n\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (visited[j] == 0 && A[curr * N + j] > 0) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (size > maxSize) {\n\t\t\t\tmaxSize = size;\n\t\t\t}\n\n\t\t\tsize = 0;\n\t\t\tvisited.assign(N, 0);\n\t\t}\n\t}\n\n\treturn maxSize;\n}",
            "std::vector<int> B;\n\n  int max_component_size = 0;\n  // Initialize B\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i == j) {\n        B.push_back(1);\n      } else if (A[i * N + j] == 1) {\n        B.push_back(0);\n      }\n    }\n  }\n\n  while (true) {\n    // Find all vertices that are not yet in the largest component\n    std::vector<int> next_largest_component;\n\n    for (size_t i = 0; i < B.size(); i++) {\n      if (B[i] == 0) {\n        next_largest_component.push_back(i);\n      }\n    }\n\n    // Exit if no such vertex exists\n    if (next_largest_component.size() == 0) break;\n\n    // Find the current largest component size\n    int current_component_size = 0;\n    for (size_t i = 0; i < B.size(); i++) {\n      if (B[i] == 1) current_component_size++;\n    }\n\n    // Assign all vertices in the largest component to the largest component\n    for (size_t i = 0; i < next_largest_component.size(); i++) {\n      for (size_t j = 0; j < B.size(); j++) {\n        if (B[j] == 0 && A[next_largest_component[i] * N + j] == 1) B[j] = 1;\n      }\n    }\n\n    // Check if this component is larger than the current largest component\n    int next_component_size = 0;\n    for (size_t i = 0; i < B.size(); i++) {\n      if (B[i] == 1) next_component_size++;\n    }\n\n    if (next_component_size > current_component_size) {\n      max_component_size = next_component_size;\n    }\n  }\n\n  return max_component_size;\n}",
            "int *visited = new int[N];\n    memset(visited, 0, N*sizeof(int));\n\n    #pragma omp parallel\n    {\n        #pragma omp for\n        for (size_t i = 0; i < N; i++) {\n            if (visited[i] == 0) {\n                int v = i;\n                dfs(A, N, v, visited);\n            }\n        }\n    }\n\n    int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i] == 1) {\n            count++;\n        }\n    }\n\n    return count;\n}",
            "std::vector<bool> vis(N);\n    std::vector<int> num_vertices(N);\n\n    std::fill(num_vertices.begin(), num_vertices.end(), 0);\n    std::fill(vis.begin(), vis.end(), false);\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                if (vis[i] == true) {\n                    if (vis[j] == false) {\n                        vis[j] = true;\n                        num_vertices[i]++;\n                    }\n                } else if (vis[j] == true) {\n                    vis[i] = true;\n                    num_vertices[j]++;\n                }\n            }\n        }\n    }\n\n    size_t max_num_vertices = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (num_vertices[i] > max_num_vertices) {\n            max_num_vertices = num_vertices[i];\n        }\n    }\n\n    return max_num_vertices;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> component(N, 0);\n\tstd::vector<int> component_size(N, 0);\n\n\t#pragma omp parallel for schedule(dynamic,100)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tstd::vector<int> queue;\n\t\t\tqueue.push_back(i);\n\t\t\twhile (!queue.empty()) {\n\t\t\t\tint top = queue.back();\n\t\t\t\tqueue.pop_back();\n\t\t\t\tvisited[top] = 1;\n\t\t\t\tcomponent[top] = i+1;\n\t\t\t\tcomponent_size[i]++;\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[N*i+j] && visited[j] == 0) {\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint largest = 0;\n\tsize_t component_num = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i] > largest) {\n\t\t\tlargest = component[i];\n\t\t\tcomponent_num = 0;\n\t\t}\n\t\tif (component[i] == largest) {\n\t\t\tcomponent_num += component_size[i];\n\t\t}\n\t}\n\n\treturn component_num;\n}",
            "std::vector<int> visited(N, 0);\n\tint largestComponentSize = 1;\n\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tstd::vector<int> component;\n\t\t\tint currentComponentSize = 1;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = 1;\n\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint current = q.front();\n\t\t\t\tq.pop();\n\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (visited[j] == 0 && A[current * N + j]!= 0) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tcurrentComponentSize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (currentComponentSize > largestComponentSize) {\n\t\t\t\tlargestComponentSize = currentComponentSize;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn largestComponentSize;\n}",
            "std::vector<int> visited(N, 0);\n    size_t max_component = 0;\n#pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        size_t component = 0;\n        if (visited[i] == 0) {\n            std::queue<size_t> q;\n            q.push(i);\n            visited[i] = 1;\n            while (q.size() > 0) {\n                size_t v = q.front();\n                q.pop();\n                component++;\n                for (size_t j = 0; j < N; j++) {\n                    if (A[N * v + j] == 1 && visited[j] == 0) {\n                        q.push(j);\n                        visited[j] = 1;\n                    }\n                }\n            }\n        }\n        if (component > max_component) {\n            max_component = component;\n        }\n    }\n    return max_component;\n}",
            "// You need to fill in the missing code here\n\treturn -1;\n}",
            "std::vector<int> visited(N);\n  int max = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      int n = 0;\n      std::vector<int> stack;\n      stack.push_back(i);\n      visited[i] = 1;\n      while (!stack.empty()) {\n        int j = stack.back();\n        stack.pop_back();\n        for (int k = 0; k < N; ++k) {\n          if (A[i * N + k] == 1 && visited[k] == 0) {\n            visited[k] = 1;\n            stack.push_back(k);\n            ++n;\n          }\n        }\n      }\n      if (n > max) {\n        max = n;\n      }\n    }\n  }\n  return max;\n}",
            "omp_set_num_threads(4);\n\tint visited[N][N];\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tvisited[i][j]=0;\n\t\t}\n\t}\n\n\tint *adjMat = new int[N*N];\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tadjMat[i*N+j] = A[i*N+j];\n\t\t}\n\t}\n\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(adjMat[i*N+j] == 1 && visited[i][j] == 0)\n\t\t\t{\n\t\t\t\tbfs(adjMat,visited,i,j,N);\n\t\t\t}\n\t\t}\n\t}\n\n\tint max_cnt = 0;\n\tint cur_cnt = 0;\n\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(visited[i][j] == 1)\n\t\t\t{\n\t\t\t\tcur_cnt++;\n\t\t\t}\n\t\t}\n\t\tif(cur_cnt > max_cnt)\n\t\t{\n\t\t\tmax_cnt = cur_cnt;\n\t\t}\n\t\tcur_cnt = 0;\n\t}\n\n\tdelete [] adjMat;\n\treturn max_cnt;\n}",
            "std::vector<bool> visited(N);\n  std::queue<int> to_visit;\n  int largest_component = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == false) {\n      largest_component = 0;\n      to_visit.push(i);\n      while (!to_visit.empty()) {\n        auto curr = to_visit.front();\n        to_visit.pop();\n        if (!visited[curr]) {\n          visited[curr] = true;\n          largest_component++;\n          for (int j = 0; j < N; j++) {\n            if (A[curr*N+j]!= 0 &&!visited[j])\n              to_visit.push(j);\n          }\n        }\n      }\n    }\n  }\n\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (!visited[i])\n      count++;\n  }\n\n  return largest_component;\n}",
            "/*\n\tTODO: Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n\n\tHints:\n\t- Use a parallel for loop (#pragma omp parallel for) to iteratre over the matrix.\n\t- Use an atomic operation (#pragma omp atomic) to increment the count of vertices in the largest component.\n\t*/\n\n\tint largestComponent = 0;\n\n\t// TODO: Write the parallel for loop here\n\n\n\treturn largestComponent;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> parent(N, -1);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            // The first component is initially the parent of itself.\n            parent[i] = i;\n            dfs(i, A, visited, parent);\n        }\n    }\n\n    std::vector<int> componentSizes(N, 0);\n    for (size_t i = 0; i < N; ++i) {\n        if (parent[i]!= -1) {\n            int root = i;\n            while (parent[root]!= -1) {\n                root = parent[root];\n            }\n            // Count the number of vertices in the component.\n            componentSizes[root]++;\n        }\n    }\n\n    int maxSize = 0;\n    int component = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (componentSizes[i] > maxSize) {\n            maxSize = componentSizes[i];\n            component = i;\n        }\n    }\n\n    return maxSize;\n}",
            "std::vector<std::vector<int>> components(N, std::vector<int>(N, 0));\n  std::vector<bool> visited(N, false);\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (visited[i]) continue;\n    std::queue<int> q;\n    q.push(i);\n    while (!q.empty()) {\n      int v = q.front(); q.pop();\n      visited[v] = true;\n      for (int j = 0; j < N; j++) {\n        if (A[v*N + j] &&!visited[j]) q.push(j);\n      }\n    }\n  }\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1 && visited[i] && visited[j]) components[i][j] = 1;\n    }\n  }\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) continue;\n    for (int j = 0; j < N; j++) {\n      if (components[i][j] == 1) {\n        for (int k = 0; k < N; k++) {\n          if (components[j][k] == 1) components[i][k] = 1;\n        }\n      }\n    }\n  }\n\n  int max = 0;\n  #pragma omp parallel for reduction(max:max)\n  for (int i = 0; i < N; i++) {\n    int c = 0;\n    for (int j = 0; j < N; j++) {\n      if (components[i][j] == 1) c++;\n    }\n    if (c > max) max = c;\n  }\n\n  return max;\n}",
            "std::vector<bool> visited(N);\n\n    #pragma omp parallel\n    {\n        int id = omp_get_thread_num();\n        int num_threads = omp_get_num_threads();\n        int start = id * N / num_threads;\n        int end = (id + 1) * N / num_threads;\n\n        // Check if a vertex in A is reachable from vertex i, starting at i.\n        // Do a DFS and stop when all vertices in the graph are visited.\n        // For every vertex i that can be reached from vertex 0, set visited[i] to true.\n        // Every vertex that is not visited is in a component by itself.\n        // Return the number of vertices in the largest component.\n        #pragma omp for schedule(dynamic, 1)\n        for (int i = 0; i < N; ++i) {\n            if (!visited[i]) {\n                std::vector<int> s;\n                s.push_back(i);\n                while (!s.empty()) {\n                    int v = s.back();\n                    s.pop_back();\n                    visited[v] = true;\n                    for (int j = 0; j < N; ++j) {\n                        if (A[v * N + j] == 1 &&!visited[j]) {\n                            s.push_back(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return std::count(visited.begin(), visited.end(), true);\n}",
            "int maxSize = 0;\n  int * visited = new int[N];\n  std::fill(visited, visited + N, 0);\n  int * toVisit = new int[N];\n  int * nextToVisit = new int[N];\n  int nextToVisitSize = 0;\n  int toVisitSize = 0;\n  int size = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      toVisit[toVisitSize++] = i;\n    }\n  }\n\n  while (toVisitSize > 0) {\n    for (int i = 0; i < toVisitSize; i++) {\n      int current = toVisit[i];\n      for (int j = 0; j < N; j++) {\n        if (A[current * N + j] == 1 && visited[j] == 0) {\n          nextToVisit[nextToVisitSize++] = j;\n          visited[j] = 1;\n        }\n      }\n    }\n    size += toVisitSize;\n    maxSize = std::max(maxSize, size);\n    std::swap(toVisit, nextToVisit);\n    toVisitSize = nextToVisitSize;\n    nextToVisitSize = 0;\n  }\n\n  delete [] toVisit;\n  delete [] nextToVisit;\n  delete [] visited;\n  return maxSize;\n}",
            "std::vector<int> v(N, 0);\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n\tv[i] = 1;\n      }\n    }\n  }\n  int size = 0;\n  int max_size = 0;\n  int count = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += v[j];\n    }\n    size = sum;\n    #pragma omp critical\n    {\n      if (max_size < size) {\n\tmax_size = size;\n      }\n    }\n  }\n  return max_size;\n}",
            "int n_threads, thread_id, max_comp;\n\tstd::vector<int> num_of_components(N, 1);\n\tstd::vector<int> num_of_components_reduced(N, 1);\n\n\tomp_set_num_threads(N);\n#pragma omp parallel private(thread_id, n_threads)\n\t{\n\t\tthread_id = omp_get_thread_num();\n\t\tn_threads = omp_get_num_threads();\n\n\t\t// Iterate over all the rows\n\t\tfor (size_t i = thread_id; i < N; i += n_threads) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (i!= j && A[i*N + j]) {\n\t\t\t\t\t// Update num_of_components with the min\n\t\t\t\t\tnum_of_components[i] = std::min(num_of_components[i], num_of_components[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n#pragma omp barrier\n\n\t\t// Reduce\n\t\tfor (size_t i = 0; i < N; i += n_threads) {\n\t\t\tnum_of_components_reduced[i] = num_of_components[i];\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] && i!= j) {\n\t\t\t\t\tnum_of_components_reduced[i] = std::min(num_of_components_reduced[i], num_of_components[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n#pragma omp barrier\n\n\t\t// Iterate over all the rows\n\t\tfor (size_t i = thread_id; i < N; i += n_threads) {\n\t\t\tnum_of_components[i] = num_of_components_reduced[i];\n\t\t}\n\n#pragma omp barrier\n\n\t}\n\n\t// Find the maximum component\n\tfor (size_t i = 0; i < N; i++) {\n\t\tmax_comp = std::max(max_comp, num_of_components[i]);\n\t}\n\n\treturn max_comp;\n}",
            "std::vector<int> colors(N, -1); // -1: unvisited, 0: in component, 1: in component\n\tint component = 0;\n\tint num_vertices = 0;\n\tint max_vertices = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\tcolors[i] = 0;\n\t\tcomponent++;\n\t\twhile (!q.empty()) {\n\t\t\tint v = q.front();\n\t\t\tq.pop();\n\t\t\tnum_vertices++;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[v * N + j] == 1 && colors[j] == -1) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t\tcolors[j] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\tmax_vertices = max_vertices > num_vertices? max_vertices : num_vertices;\n\t\tnum_vertices = 0;\n\t\t#pragma omp",
            "auto visited = std::vector<bool>(N, false);\n    auto visited_count = std::vector<int>(N, 0);\n    auto components = std::vector<int>(N, 0);\n    auto num = 0;\n\n    #pragma omp parallel for schedule(dynamic)\n    for(size_t i = 0; i < N; i++) {\n        if(visited[i]) {\n            continue;\n        }\n        num = 0;\n        std::stack<int> s;\n        s.push(i);\n        visited[i] = true;\n        visited_count[i] += 1;\n        while(!s.empty()) {\n            auto index = s.top();\n            s.pop();\n            for(size_t j = 0; j < N; j++) {\n                if(A[index * N + j] &&!visited[j]) {\n                    s.push(j);\n                    visited[j] = true;\n                    visited_count[j] += 1;\n                }\n            }\n        }\n        for(size_t k = 0; k < N; k++) {\n            if(visited[k]) {\n                components[k] = num;\n            }\n        }\n        num++;\n    }\n    auto max = std::vector<int>(N, 0);\n    for(size_t i = 0; i < N; i++) {\n        if(visited_count[i] > max[components[i]]) {\n            max[components[i]] = visited_count[i];\n        }\n    }\n    auto count = 0;\n    for(auto i = 0; i < N; i++) {\n        count += max[i];\n    }\n    return count;\n}",
            "auto compSizes = std::vector<int>(N, 1);\n    std::vector<bool> visited(N, false);\n\n    #pragma omp parallel\n    {\n        #pragma omp for\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (A[i * N + j] &&!visited[i] &&!visited[j]) {\n                    compSizes[i] += compSizes[j];\n                }\n            }\n        }\n        #pragma omp for\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (A[i * N + j]) {\n                    visited[i] = true;\n                    visited[j] = true;\n                }\n            }\n        }\n    }\n\n    auto maxCompSize = std::max_element(compSizes.begin(), compSizes.end());\n    return std::distance(compSizes.begin(), maxCompSize);\n}",
            "int L = 0;\n\t#pragma omp parallel\n\t{\n\t\tint maxL = 0;\n\t\tstd::vector<bool> visited(N);\n\t\tint i, j;\n\t\t#pragma omp for\n\t\tfor (i = 0; i < N; ++i) {\n\t\t\tfor (j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j]!= 0 &&!visited[j]) {\n\t\t\t\t\tint l = 1;\n\t\t\t\t\tstd::queue<int> Q;\n\t\t\t\t\tQ.push(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\twhile (!Q.empty()) {\n\t\t\t\t\t\tint node = Q.front();\n\t\t\t\t\t\tQ.pop();\n\t\t\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\t\t\tif (A[node * N + k]!= 0 &&!visited[k]) {\n\t\t\t\t\t\t\t\tQ.push(k);\n\t\t\t\t\t\t\t\tvisited[k] = true;\n\t\t\t\t\t\t\t\tl++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tmaxL = std::max(maxL, l);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tL = std::max(L, maxL);\n\t\t}\n\t}\n\treturn L;\n}",
            "size_t result = 0;\n\n\t#pragma omp parallel for schedule(dynamic, 10) shared(A, N, result)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tstd::vector<int> component;\n\t\tstd::vector<bool> visited;\n\t\tvisited.reserve(N);\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tvisited.push_back(false);\n\n\t\tif (!visited[i]) {\n\t\t\tcomponent.push_back(i);\n\t\t\tvisited[i] = true;\n\t\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\t\tif (A[i * N + j]) {\n\t\t\t\t\tcomponent.push_back(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (result < component.size()) {\n\t\t\t\tresult = component.size();\n\t\t\t\tstd::cout << \"New largest component: \" << result << std::endl;\n\t\t\t\tstd::cout << \"Thread id: \" << omp_get_thread_num() << std::endl;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int* dist = new int[N];\n\tint* prev = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = -1;\n\t\tprev[i] = -1;\n\t}\n\tint* dist_new = new int[N];\n\tint* prev_new = new int[N];\n\n\tdist[0] = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist[j] == -1 && A[j*N + i] == 1) {\n\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\tprev[j] = i;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 1; i < N; i++) {\n\t\tif (dist_new[i] == -1) {\n\t\t\tdist_new[i] = dist[i];\n\t\t\tprev_new[i] = prev[i];\n\t\t}\n\t}\n\n\twhile (true) {\n\t\tbool flag = false;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (dist[j] == -1 && A[j*N + i] == 1) {\n\t\t\t\t\tint temp = 1;\n\t\t\t\t\twhile (prev[i]!= i) {\n\t\t\t\t\t\ttemp += dist[i];\n\t\t\t\t\t\ti = prev[i];\n\t\t\t\t\t}\n\t\t\t\t\tif (temp > dist_new[j]) {\n\t\t\t\t\t\tdist_new[j] = temp;\n\t\t\t\t\t\tprev_new[j] = i;\n\t\t\t\t\t\tflag = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (flag == false)\n\t\t\tbreak;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tdist[i] = dist_new[i];\n\t\t\tprev[i] = prev_new[i];\n\t\t}\n\t}\n\n\tint max_len = 0;\n\tint max_i = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (dist[i] > max_len) {\n\t\t\tmax_len = dist[i];\n\t\t\tmax_i = i;\n\t\t}\n\t}\n\n\treturn max_len;\n}",
            "// TODO: write your code here\n    if (A.size()!= N * N) {\n        throw std::runtime_error(\"wrong size\");\n    }\n    std::vector<int> colors(N, -1);\n    std::vector<int> size(N, 1);\n\n    int largest_component_size = 0;\n#pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        if (colors[i] == -1) {\n            int c = i;\n            int s = 0;\n            std::queue<int> bfs;\n            bfs.push(i);\n\n            while (!bfs.empty()) {\n                int v = bfs.front();\n                bfs.pop();\n                for (size_t w = 0; w < N; w++) {\n                    if (A[v * N + w] == 1) {\n                        if (colors[w] == -1) {\n                            colors[w] = c;\n                            bfs.push(w);\n                        }\n                        else if (colors[w] == c) {\n                            continue;\n                        }\n                        else {\n                            int vc = colors[v];\n                            int wc = colors[w];\n                            for (size_t k = 0; k < N; k++) {\n                                if (colors[k] == wc) {\n                                    colors[k] = vc;\n                                }\n                            }\n                            size[vc] += size[wc];\n                            colors[wc] = -1;\n                        }\n                    }\n                }\n                s++;\n            }\n            if (s > largest_component_size) {\n                largest_component_size = s;\n            }\n        }\n    }\n\n    int largest_component_color = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (colors[i] == -1) {\n            largest_component_color = i;\n        }\n    }\n    for (size_t i = 0; i < N; i++) {\n        if (colors[i] == largest_component_color) {\n            colors[i] = 0;\n        }\n        else {\n            colors[i] = 1;\n        }\n    }\n\n    return largest_component_size;\n}",
            "if (N==0) return 0;\n  std::vector<int> visited(N,0);\n  std::vector<int> queue;\n  std::vector<int> q(N,0);\n  std::vector<int> v(N,0);\n  std::vector<int> c(N,0);\n  int qh = 0, qt = 0;\n  int vh = 0, vt = 0;\n  int ch = 0, ct = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      q[qt++] = i;\n      v[vt++] = i;\n      c[ct++] = 0;\n      visited[i] = 1;\n      #pragma omp parallel for\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          if (visited[j] == 0) {\n            q[qt++] = j;\n            visited[j] = 1;\n            v[vt++] = j;\n            c[ct++] = 0;\n          }\n        }\n      }\n      while (qh!= qt) {\n        int u = q[qh++];\n        #pragma omp parallel for\n        for (int j = 0; j < N; j++) {\n          if (A[u * N + j] == 1) {\n            if (visited[j] == 0) {\n              q[qt++] = j;\n              v[vt++] = j;\n              c[ct++] = 0;\n              visited[j] = 1;\n            }\n          }\n        }\n      }\n    }\n  }\n  int max = c[0];\n  int max_u = v[0];\n  for (int i = 1; i < vt; i++) {\n    if (max < c[i]) {\n      max = c[i];\n      max_u = v[i];\n    }\n  }\n  visited[max_u] = 0;\n  int count = 1;\n  #pragma omp parallel for\n  for (int i = 0; i < vt; i++) {\n    if (v[i] == max_u) continue;\n    #pragma omp parallel for\n    for (int j = 0; j < vt; j++) {\n      if (A[v[i] * N + v[j]] == 1) {\n        if (v[j] == max_u) {\n          c[i] = 0;\n          break;\n        }\n      }\n    }\n    if (c[i] == 1) count++;\n  }\n  return count;\n}",
            "omp_set_num_threads(omp_get_num_procs());\n\tstd::vector<bool> visted(N);\n\tstd::queue<int> q;\n\tint count = 0;\n\tint size = 0;\n\tint curSize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visted[i]) {\n\t\t\tq.push(i);\n\t\t\tcount++;\n\t\t\tcurSize++;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint cur = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisted[cur] = true;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[cur * N + j] == 1 &&!visted[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tcurSize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (curSize > size) {\n\t\t\t\tsize = curSize;\n\t\t\t}\n\t\t\tcurSize = 0;\n\t\t}\n\t}\n\treturn size;\n}",
            "if (N == 1) {\n        return 1;\n    }\n    auto const A_begin = A.begin();\n    std::vector<int> B(N, 0);\n    std::vector<int> C(N, 0);\n    std::vector<int> D(N, 0);\n    auto const B_begin = B.begin();\n    auto const C_begin = C.begin();\n    auto const D_begin = D.begin();\n    int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i!= j) {\n                if (*(A_begin + i * N + j)!= 0) {\n                    *(C_begin + i) += 1;\n                }\n            }\n        }\n    }\n    for (size_t i = 0; i < N; i++) {\n        if (*(C_begin + i) > 1) {\n            *(D_begin + count) = i;\n            count++;\n        }\n    }\n    for (size_t i = 0; i < count; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i!= j) {\n                if (*(A_begin + *(D_begin + i) * N + j)!= 0) {\n                    *(B_begin + j) += 1;\n                }\n            }\n        }\n    }\n    for (size_t i = 0; i < count; i++) {\n        for (size_t j = 0; j < count; j++) {\n            if (i!= j) {\n                if (*(B_begin + *(D_begin + i))!= 0 && *(B_begin + *(D_begin + j))!= 0) {\n                    return largestComponent(A, N);\n                }\n            }\n        }\n    }\n    return count;\n}",
            "int largest_comp = 0;\n\tint temp_comp = 0;\n\tint *color = new int[N];\n\n\tstd::fill(color, color+N, 0);\n\n#pragma omp parallel for\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tif(color[i] == 0 && color[j] == 0) {\n\t\t\t\t\tcolor[i] = 1;\n\t\t\t\t\tcolor[j] = 1;\n\t\t\t\t\ttemp_comp++;\n\t\t\t\t} else if(color[i] == 1 && color[j] == 0) {\n\t\t\t\t\tcolor[j] = 1;\n\t\t\t\t\ttemp_comp++;\n\t\t\t\t} else if(color[i] == 0 && color[j] == 1) {\n\t\t\t\t\tcolor[i] = 1;\n\t\t\t\t\ttemp_comp++;\n\t\t\t\t} else if(color[i] == 1 && color[j] == 1) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif(temp_comp > largest_comp) {\n\t\tlargest_comp = temp_comp;\n\t}\n\n\tdelete [] color;\n\n\treturn largest_comp;\n}",
            "auto comp = std::vector<int>(N, 1);\n\tstd::fill(comp.begin(), comp.end(), 1);\n\tstd::vector<int> comp_new = std::vector<int>(N, 1);\n\tstd::fill(comp_new.begin(), comp_new.end(), 1);\n\n\tint count = 0;\n\tbool changed = false;\n\tomp_set_num_threads(8);\n\n\tdo {\n\t\tchanged = false;\n\t\tcount++;\n#pragma omp parallel for num_threads(8)\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tint max = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\t\tif (comp[j] > max) {\n\t\t\t\t\t\tmax = comp[j];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomp_new[i] = max;\n\t\t}\n\t\tomp_set_lock(&lock);\n\t\tif (count == 1) {\n\t\t\tomp_init_lock(&lock);\n\t\t}\n\t\tomp_unset_lock(&lock);\n\t\tomp_set_lock(&lock);\n\t\tchanged = (comp == comp_new);\n\t\tomp_unset_lock(&lock);\n\t\tcomp = comp_new;\n\t} while (!changed);\n\n\tint max = 0;\n\tfor (auto i : comp) {\n\t\tif (i > max) {\n\t\t\tmax = i;\n\t\t}\n\t}\n\treturn max;\n}",
            "#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(A[i*N + j] == 1){\n\t\t\t\t\tA[j*N + i] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint ncomp = 0;\n\tstd::vector<bool> used(N, false);\n\tstd::queue<int> queue;\n\n\t// bfs through the matrix\n\tfor(int i = 0; i < N; i++){\n\t\tif(used[i]){\n\t\t\tcontinue;\n\t\t}\n\n\t\tqueue.push(i);\n\n\t\twhile(!queue.empty()){\n\t\t\tint curr = queue.front();\n\t\t\tqueue.pop();\n\t\t\tif(used[curr]){\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tused[curr] = true;\n\t\t\tncomp++;\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(A[curr*N + j] == 1){\n\t\t\t\t\tqueue.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ncomp;\n}",
            "int nComp = 0;\n\tint largestComp = 0;\n\n\tstd::vector<int> parent(N, 0);\n\tfor(int i = 0; i < N; ++i) {\n\t\tparent[i] = i;\n\t}\n\n\tfor(int i = 0; i < N; ++i) {\n\t\tfor(int j = i; j < N; ++j) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tint p1 = find(parent, i);\n\t\t\t\tint p2 = find(parent, j);\n\t\t\t\tif(p1!= p2) {\n\t\t\t\t\tparent[p1] = p2;\n\t\t\t\t\tnComp--;\n\t\t\t\t\tif(nComp == 1) {\n\t\t\t\t\t\tlargestComp = p1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn largestComp;\n}",
            "#pragma omp parallel\n    {\n        std::vector<int> visited(N, 0);\n\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; i++) {\n            int cur = 0;\n            std::queue<int> q;\n            q.push(i);\n            while(!q.empty()) {\n                int node = q.front();\n                q.pop();\n                if (visited[node] == 1)\n                    continue;\n                cur++;\n                visited[node] = 1;\n                for (int j = 0; j < N; j++) {\n                    if (visited[j] == 0 && A[N*node + j] == 1)\n                        q.push(j);\n                }\n            }\n            #pragma omp critical\n            {\n                if (cur > visited[0]) {\n                    visited[0] = cur;\n                }\n            }\n        }\n    }\n\n    return visited[0];\n}",
            "int n_verts = N;\n\n    int comp = 0;\n    std::vector<bool> visited(n_verts);\n\n    #pragma omp parallel for\n    for (int i = 0; i < n_verts; i++) {\n        if (!visited[i]) {\n            #pragma omp critical\n            comp++;\n            visited[i] = true;\n            for (int j = i+1; j < n_verts; j++) {\n                if (A[i*N + j]!= 0 &&!visited[j]) {\n                    #pragma omp critical\n                    comp++;\n                    visited[j] = true;\n                }\n            }\n        }\n    }\n\n    return comp;\n}",
            "int num_thread=0;\n    std::vector<std::vector<int>> components(N);\n    std::vector<int> num_vertices(N, 0);\n    std::vector<bool> visited(N, false);\n    std::vector<std::pair<int, int>> to_visit;\n    int largest_component_size=0;\n\n    // Parallel region\n    #pragma omp parallel\n    {\n        // Find the number of threads\n        #pragma omp single\n        {\n            num_thread = omp_get_num_threads();\n            printf(\"Number of threads: %d\\n\", num_thread);\n        }\n\n        // Each thread visits each vertex\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; i++) {\n            if (visited[i] == false) {\n                std::vector<int> component;\n                // Start from the vertex, find all vertices that can be reached\n                to_visit.push_back(std::make_pair(i, 0));\n                while (to_visit.size()!= 0) {\n                    std::pair<int, int> vertex = to_visit.back();\n                    to_visit.pop_back();\n                    if (visited[vertex.first] == false) {\n                        // Mark the vertex as visited\n                        visited[vertex.first] = true;\n                        // Add the vertex to the component\n                        component.push_back(vertex.first);\n                        // Push all vertices that can be reached\n                        for (int j = 0; j < N; j++) {\n                            if (A[vertex.first * N + j] == 1) {\n                                to_visit.push_back(std::make_pair(j, vertex.second + 1));\n                            }\n                        }\n                    }\n                }\n                // The component can be added to the vector of components\n                components[i] = component;\n            }\n        }\n\n        // Find the largest component and its size\n        #pragma omp critical\n        {\n            for (int i = 0; i < components.size(); i++) {\n                num_vertices[i] = components[i].size();\n            }\n            for (int i = 0; i < num_vertices.size(); i++) {\n                if (num_vertices[i] > largest_component_size) {\n                    largest_component_size = num_vertices[i];\n                }\n            }\n        }\n    }\n\n    // Return the size of the largest component\n    return largest_component_size;\n}",
            "int size = 0;\n\tstd::vector<int> component(N, 0);\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component[i] == 0) {\n\t\t\tcomponent[i] = 1;\n\t\t\tint index = i;\n\t\t\twhile (index >= 0) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[N * index + j] == 1) {\n\t\t\t\t\t\tif (component[j] == 0) {\n\t\t\t\t\t\t\tcomponent[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tindex = -1;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (component[j] == 1) {\n\t\t\t\t\t\tindex = j;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tsize++;\n\t\t}\n\t}\n\treturn size;\n}",
            "std::vector<int> connected(N, 0);\n    std::vector<int> visited(N, 0);\n    int largestComponentSize = 0;\n\n    for(int i = 0; i < N; i++) {\n        if(!visited[i]) {\n            largestComponentSize = maxComponentSize(A, connected, visited, i);\n        }\n    }\n\n    return largestComponentSize;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> parent(N, -1);\n  int max_vertex = -1;\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      max_vertex = i;\n      max_vertex = dfs(A, i, visited, parent);\n    }\n  }\n  return max_vertex;\n}",
            "/* TODO: Your code here */\n\n\treturn 0;\n}",
            "/* Your code goes here */\n}",
            "std::vector<int> c(N, 1);\n    std::vector<int> s(N, 0);\n    #pragma omp parallel for schedule(dynamic)\n    for(int i = 0; i < N; i++)\n    {\n        for(int j = 0; j < N; j++)\n        {\n            if(A[N*i + j] == 1)\n            {\n                int ind1 = i, ind2 = j;\n                #pragma omp atomic\n                s[ind1]++;\n                #pragma omp atomic\n                s[ind2]++;\n            }\n        }\n    }\n    #pragma omp parallel for schedule(dynamic)\n    for(int i = 0; i < N; i++)\n    {\n        int val = 0;\n        int ind = 0;\n        for(int j = 0; j < N; j++)\n        {\n            if(s[j] > val)\n            {\n                val = s[j];\n                ind = j;\n            }\n        }\n        c[i] = ind + 1;\n    }\n    int res = 0;\n    for(int i = 0; i < N; i++)\n    {\n        if(c[i] > res)\n        {\n            res = c[i];\n        }\n    }\n    return res;\n}",
            "int maxComponentSize = 0;\n\tstd::vector<int> visited(N, 0);\n\n#pragma omp parallel for num_threads(4) schedule(dynamic)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tint currentComponentSize = 0;\n\t\t\tstd::vector<int> currentComponent = { i };\n\t\t\t// DFS\n\t\t\twhile (!currentComponent.empty()) {\n\t\t\t\tint vertex = currentComponent.back();\n\t\t\t\tcurrentComponent.pop_back();\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[N * vertex + j] &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tcurrentComponent.push_back(j);\n\t\t\t\t\t\t++currentComponentSize;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (currentComponentSize > maxComponentSize) {\n\t\t\t\tmaxComponentSize = currentComponentSize;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxComponentSize;\n}",
            "/* CODE HERE */\n  return 1;\n}",
            "if (N == 1) { return 1; }\n  std::vector<int> D(N);\n  int largest = 0;\n\n  #pragma omp parallel for\n  for (int i=0; i < N; ++i) {\n    D[i] = 1;\n  }\n\n  #pragma omp parallel for\n  for (int i=0; i < N; ++i) {\n    for (int j=0; j < N; ++j) {\n      if (i == j) {\n        continue;\n      }\n\n      if (A[i*N+j] == 1) {\n        #pragma omp atomic\n        ++D[j];\n      }\n    }\n  }\n\n  for (int i=0; i < N; ++i) {\n    largest = std::max(largest, D[i]);\n  }\n\n  return largest;\n}",
            "/* Your solution goes here! */\n\t//#pragma omp parallel for\n\t//for (int i = 0; i < N; i++)\n\t//{\n\t//\tA[i] = 1;\n\t//}\n\n\tint comp = 1;\n\tint compSize = 1;\n\tstd::vector<bool> visited(N, false);\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!visited[i])\n\t\t{\n\t\t\tcompSize = dfs(A, visited, i, N, compSize);\n\t\t\tcomp = std::max(comp, compSize);\n\t\t}\n\t}\n\n\treturn comp;\n}",
            "omp_set_num_threads(1);\n\tint largest = 0;\n\tstd::vector<int> count(N, 1);\n\n\t// TODO: implement this\n\n\treturn largest;\n}",
            "std::vector<int> v(N, 0);\n\tint m = 0;\n#pragma omp parallel for num_threads(4)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tv[i]++;\n\t\t\t\tv[j]++;\n\t\t\t}\n\t\t}\n\t}\n#pragma omp parallel for num_threads(4)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (v[i] > m) {\n\t\t\tm = v[i];\n\t\t}\n\t}\n\treturn m;\n}",
            "// TODO: Complete this function\n\tint numberOfVertices = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint *A_thread = new int[N * N];\n\t\t#pragma omp for schedule(static)\n\t\tfor (size_t i = 0; i < N * N; i++)\n\t\t{\n\t\t\tA_thread[i] = A[i];\n\t\t}\n\n\t\t#pragma omp single\n\t\t{\n\t\t\tstd::fill_n(A_thread, N * N, 0);\n\t\t}\n\n\t\t#pragma omp for schedule(static) reduction(+: numberOfVertices)\n\t\tfor (size_t i = 0; i < N; i++)\n\t\t{\n\t\t\tstd::vector<int> s;\n\t\t\ts.push_back(i);\n\t\t\twhile (s.size()!= 0)\n\t\t\t{\n\t\t\t\tint x = s.back();\n\t\t\t\ts.pop_back();\n\t\t\t\tfor (size_t j = 0; j < N; j++)\n\t\t\t\t{\n\t\t\t\t\tif (A_thread[x * N + j] == 1 && A[x * N + j] == 1 && A_thread[j * N + x] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\ts.push_back(j);\n\t\t\t\t\t\tA_thread[j * N + x] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tA_thread[x * N + x] = 1;\n\t\t\t\tnumberOfVertices++;\n\t\t\t}\n\t\t}\n\t}\n\treturn numberOfVertices;\n}",
            "int const THREADS = omp_get_max_threads();\n\tstd::vector<int> S(THREADS * N);\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++)\n\t\tS[omp_get_thread_num() * N + i] = i;\n\n\tfor (size_t k = 0; k < N; k++) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[i * N + k]) {\n\t\t\t\tint a = S[omp_get_thread_num() * N + i];\n\t\t\t\tint b = S[omp_get_thread_num() * N + k];\n\t\t\t\tif (a < b)\n\t\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t\t\tif (S[omp_get_thread_num() * N + j] == b)\n\t\t\t\t\t\t\tS[omp_get_thread_num() * N + j] = a;\n\t\t\t\telse if (a > b)\n\t\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t\t\tif (S[omp_get_thread_num() * N + j] == a)\n\t\t\t\t\t\t\tS[omp_get_thread_num() * N + j] = b;\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> max(THREADS, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < THREADS; j++) {\n\t\t\tif (S[j * N + i] > max[j])\n\t\t\t\tmax[j] = S[j * N + i];\n\t\t}\n\t}\n\n\tint maxi = 0;\n\tfor (int i = 1; i < THREADS; i++)\n\t\tif (max[i] > maxi)\n\t\t\tmaxi = max[i];\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t\tif (S[omp_get_thread_num() * N + i] == maxi)\n\t\t\tcount++;\n\treturn count;\n}",
            "std::vector<bool> used(N, false);\n  std::queue<int> q;\n  std::vector<int> vertex_queue;\n  int max_size = 0;\n  int curr_size = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (used[i])\n      continue;\n    curr_size = 0;\n    q.push(i);\n    while (!q.empty()) {\n      int vertex = q.front();\n      q.pop();\n      if (used[vertex])\n        continue;\n      used[vertex] = true;\n      curr_size++;\n      vertex_queue.push_back(vertex);\n\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 &&!used[j])\n          q.push(j);\n      }\n    }\n    if (curr_size > max_size)\n      max_size = curr_size;\n  }\n\n  return max_size;\n}",
            "/*\n  int largest = 0;\n  int *sizes = new int[N];\n  memset(sizes, 0, N*sizeof(int));\n  int visited[N];\n  memset(visited, 0, N*sizeof(int));\n  int *queue = new int[N];\n  for(int i=0; i<N; i++) {\n    if(!visited[i]) {\n      queue[0] = i;\n      int front = 0;\n      int back = 0;\n      while(front <= back) {\n        int current = queue[front++];\n        visited[current] = 1;\n        sizes[current]++;\n        for(int j=0; j<N; j++) {\n          if(A[current*N + j]) {\n            if(!visited[j]) {\n              queue[++back] = j;\n            }\n          }\n        }\n      }\n      largest = max(largest, sizes[i]);\n    }\n  }\n  delete[] queue;\n  delete[] sizes;\n  return largest;\n  */\n\n  int largest = 0;\n  int *sizes = new int[N];\n  memset(sizes, 0, N*sizeof(int));\n  int visited[N];\n  memset(visited, 0, N*sizeof(int));\n  int *queue = new int[N];\n  #pragma omp parallel\n  {\n    #pragma omp for\n    for(int i=0; i<N; i++) {\n      if(!visited[i]) {\n        queue[0] = i;\n        int front = 0;\n        int back = 0;\n        while(front <= back) {\n          int current = queue[front++];\n          visited[current] = 1;\n          sizes[current]++;\n          for(int j=0; j<N; j++) {\n            if(A[current*N + j]) {\n              if(!visited[j]) {\n                queue[++back] = j;\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  largest = sizes[0];\n  for(int i=1; i<N; i++) {\n    largest = max(largest, sizes[i]);\n  }\n  delete[] queue;\n  delete[] sizes;\n  return largest;\n}",
            "std::vector<int> visited(N, 0);\n  int n = 0;\n  int largest = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      #pragma omp parallel for reduction(max:largest)\n      for (size_t j = 0; j < N; j++) {\n        if (!visited[j] && A[i*N+j] == 1) {\n          visited[j] = 1;\n          largest = std::max(largest, largestComponent(A, j, visited));\n        }\n      }\n    }\n  }\n  return largest;\n}",
            "// TODO\n    int max_component = 0;\n    std::vector<int> mark(N, 0);\n\n    #pragma omp parallel for reduction(max : max_component)\n    for(size_t i = 0; i < N; ++i)\n    {\n        for(size_t j = 0; j < N; ++j)\n        {\n            if(A[i*N+j] == 1)\n            {\n                mark[j] = 1;\n            }\n        }\n        int num = 0;\n        for(size_t j = 0; j < N; ++j)\n        {\n            num += mark[j];\n        }\n        max_component = std::max(max_component, num);\n        std::fill(mark.begin(), mark.end(), 0);\n    }\n    return max_component;\n}",
            "int visited[N][N];\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < N; j++)\n      visited[i][j] = 0;\n\n  int component_number = 0;\n\n  // Fill code here.\n\n  return component_number;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> id(N, 0);\n  int maxSize = 0;\n\n  /* Add your code here */\n\n  return maxSize;\n}",
            "int max_component_size = -1;\n  int component_size = 0;\n  std::vector<bool> visited;\n  visited.resize(N, false);\n\n  // loop over all the vertices in the graph\n  #pragma omp parallel for reduction(max: max_component_size)\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      // start a new component\n      component_size = 0;\n      // mark the starting vertex as visited\n      visited[i] = true;\n      // loop over the neighbors of the starting vertex\n      for (int j = 0; j < N; j++) {\n        // check if we have a valid edge from vertex i to vertex j\n        if (A[i * N + j] == 1 &&!visited[j]) {\n          visited[j] = true;\n          component_size++;\n        }\n      }\n      max_component_size = std::max(max_component_size, component_size);\n    }\n  }\n  return max_component_size;\n}",
            "std::vector<int> num(N, 1);\n  std::vector<int> visited(N, 0);\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N+j] == 1 && visited[i] < visited[j]) {\n        num[j] += num[i];\n        visited[i] = visited[j];\n      }\n    }\n  }\n  int max = 0;\n  for (int i = 0; i < N; i++) {\n    if (num[i] > max) {\n      max = num[i];\n    }\n  }\n  return max;\n}",
            "std::vector<int> component(N, 0);\n\tint largestComponentSize = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i] == 0) {\n\t\t\t// if we've not visited this vertex yet, find the size of the connected component\n\t\t\tint size = findConnectedComponent(A, i, component);\n\t\t\t// compare the size against the previously found largest component size\n\t\t\tif (size > largestComponentSize) {\n\t\t\t\tlargestComponentSize = size;\n\t\t\t}\n\t\t}\n\t}\n\treturn largestComponentSize;\n}",
            "std::vector<int> visited(N, 0);\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            size_t size = 0;\n            std::queue<int> Q;\n            Q.push(i);\n            visited[i] = 1;\n            while (!Q.empty()) {\n                int vertex = Q.front();\n                Q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[vertex * N + j] == 1 && visited[j] == 0) {\n                        Q.push(j);\n                        visited[j] = 1;\n                        size += 1;\n                    }\n                }\n            }\n\n            #pragma omp critical\n            if (size > visited.size()) {\n                visited.assign(N, 0);\n            }\n        }\n    }\n    return visited.size();\n}",
            "#pragma omp parallel for num_threads(8)\n  for(size_t i = 0; i < N; i++){\n    for(size_t j = 0; j < N; j++){\n      if (A[i * N + j] == 1){\n        #pragma omp critical\n        A[j * N + i] = 1;\n      }\n    }\n  }\n\n  #pragma omp parallel for num_threads(8)\n  for(size_t i = 0; i < N; i++){\n    for(size_t j = 0; j < N; j++){\n      if(A[i * N + j] == 1){\n        for(size_t k = 0; k < N; k++){\n          A[i * N + k] = 1;\n        }\n      }\n    }\n  }\n  #pragma omp parallel for num_threads(8)\n  for(size_t i = 0; i < N; i++){\n    int count = 0;\n    for(size_t j = 0; j < N; j++){\n      if(A[i * N + j] == 1){\n        count++;\n      }\n    }\n    if(count == N){\n      return N;\n    }\n  }\n  return 0;\n}",
            "int* V = new int[N];\n\tint* S = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tV[i] = i;\n\t\tS[i] = 1;\n\t}\n\n\tint count = 1;\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] && i!= j) {\n\t\t\t\t// check if j is in S\n\t\t\t\tbool found = false;\n\t\t\t\tfor (int k = 0; k < count; k++) {\n\t\t\t\t\tif (S[k] == j) {\n\t\t\t\t\t\t// append V[i] to S[k]\n\t\t\t\t\t\tS[k] = V[i];\n\t\t\t\t\t\tfound = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (!found) {\n\t\t\t\t\t// add V[i] to S\n\t\t\t\t\tS[count] = V[i];\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tmax += S[i] == i;\n\t}\n\n\tdelete[] V;\n\tdelete[] S;\n\n\treturn max;\n}",
            "#pragma omp parallel\n\t{\n\t\tint largest = 0;\n\t\t#pragma omp for\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tint largest_component_size = 0;\n\t\t\tstd::vector<int> connected(N, false);\n\t\t\tconnected[i] = true;\n\t\t\tint queue_size = 1;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile(queue_size!= 0) {\n\t\t\t\tint node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[node * N + j] &&!connected[j]) {\n\t\t\t\t\t\tconnected[j] = true;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tqueue_size++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tqueue_size--;\n\t\t\t\tlargest_component_size++;\n\t\t\t}\n\t\t\tif (largest_component_size > largest)\n\t\t\t\tlargest = largest_component_size;\n\t\t}\n\t\t#pragma omp critical\n\t\tif (largest > largest_component)\n\t\t\tlargest_component = largest;\n\t}\n\treturn largest_component;\n}",
            "#pragma omp parallel\n  {\n    #pragma omp single\n    {\n    }\n  }\n\n  return 0;\n}",
            "int visited[N];\n\tfor(int i=0; i<N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\tint size = 0;\n\tint count = 0;\n\tstd::vector<int> largest(N);\n\tint largest_size = 0;\n\tint flag = 0;\n\n\tfor(int i=0; i<N; i++) {\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tif(visited[i] == 0) {\n\t\t\t\t\tfor(int k=i; k<N; k++) {\n\t\t\t\t\t\tif(A[k*N + j] == 1) {\n\t\t\t\t\t\t\tlargest[count] = j;\n\t\t\t\t\t\t\tcount++;\n\t\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t\t\tsize++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif(size > largest_size) {\n\t\t\t\t\t\tlargest_size = size;\n\t\t\t\t\t\tflag = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(flag == 1) {\n\t\t\tsize = 0;\n\t\t\tcount = 0;\n\t\t\tfor(int i=0; i<N; i++) {\n\t\t\t\tvisited[i] = 0;\n\t\t\t}\n\t\t\tflag = 0;\n\t\t}\n\t}\n\treturn largest_size;\n}",
            "// TODO: implement this function in OpenMP\n}",
            "std::vector<int> c(N, 0); // component number for each vertex\n\tint max = 1; // component counter\n\n\t// TODO: Use a work-efficient parallel algorithm to compute the result.\n\t// For each vertex i:\n\t//   - if c[i] > 0, c[i] is the component number for vertex i.\n\t//   - otherwise, recursively check component numbers for all neighbors of vertex i.\n\t//     - if a neighbor is in a different component, update the component number for vertex i to the largest component number.\n\t//     - otherwise, use a local counter to maintain the largest component number seen so far.\n\t//   - set c[i] to the largest component number seen so far.\n\n\t// You may want to use a separate counter variable to keep track of the largest component number seen so far.\n\t// You may want to keep track of the component number of each vertex separately.\n\n\t// Note: you may assume that A[i][j] == 0 if i!= j.\n\n\t// #pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\n\t\tint largest = 0;\n\n\t\tfor (int j = 0; j < N; ++j) {\n\n\t\t\tif (A[i*N + j]!= 0) {\n\n\t\t\t\tif (c[j] > 0) {\n\n\t\t\t\t\tc[i] = std::max(c[i], c[j]);\n\t\t\t\t}\n\t\t\t\telse {\n\n\t\t\t\t\tint component = largestComponent(A, N);\n\n\t\t\t\t\tif (c[j] == 0) {\n\t\t\t\t\t\tc[j] = component;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (component > largest) {\n\t\t\t\t\t\tlargest = component;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tc[i] = largest;\n\t}\n\n\treturn c[0];\n}",
            "// TODO\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> component;\n\n  #pragma omp parallel for num_threads(1)\n  for (int i = 0; i < N; ++i) {\n    // BFS\n    if (visited[i] == false) {\n      std::queue<int> q;\n      q.push(i);\n      while (q.empty() == false) {\n        int x = q.front();\n        q.pop();\n        if (visited[x] == false) {\n          component.push_back(x);\n          visited[x] = true;\n          for (int j = 0; j < N; ++j) {\n            if (A[N*x+j] == 1 && visited[j] == false) {\n              q.push(j);\n            }\n          }\n        }\n      }\n    }\n  }\n  return component.size();\n}",
            "int visited[N];\n  std::fill(visited, visited + N, false);\n  int largest_component = 0;\n  #pragma omp parallel for schedule(static)\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      int component = 0;\n      std::vector<int> stack = {i};\n      while (stack.size() > 0) {\n        int n = stack.back();\n        stack.pop_back();\n        if (visited[n])\n          continue;\n        visited[n] = true;\n        component++;\n        for (size_t j = 0; j < N; j++) {\n          if (A[N * n + j] > 0 &&!visited[j])\n            stack.push_back(j);\n        }\n      }\n      #pragma omp critical\n      if (component > largest_component) {\n        largest_component = component;\n      }\n    }\n  }\n  return largest_component;\n}",
            "std::vector<int> visited(N);\n  std::fill(visited.begin(), visited.end(), 0);\n  int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for(size_t i = 0; i < N; i++) {\n    if(visited[i] == 0) {\n      visited[i] = 1;\n      count++;\n      for(size_t j = 0; j < N; j++) {\n        if(A[i * N + j] == 1) {\n          visited[j] = 1;\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N);\n    int component_size = 0;\n    #pragma omp parallel for reduction(+:component_size)\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i])\n            continue;\n        // traverse the subgraph defined by A[i] using BFS\n        std::queue<int> q;\n        q.push(i);\n        while (!q.empty()) {\n            int const node = q.front();\n            q.pop();\n            if (visited[node])\n                continue;\n            ++component_size;\n            visited[node] = 1;\n            for (int i = 0; i < N; ++i) {\n                if (A[node * N + i] == 1 &&!visited[i])\n                    q.push(i);\n            }\n        }\n    }\n    return component_size;\n}",
            "// Implement this function\n\tint max_component = 0;\n\tstd::vector<bool> visited(N, false);\n\n\t// Start with the first row\n\tfor (size_t col = 0; col < N; ++col) {\n\t\tif (!visited[col] && A[col * N] == 1) {\n\t\t\t// Set up the stack\n\t\t\tstd::stack<size_t> stack;\n\t\t\tstack.push(col);\n\n\t\t\t// Do DFS\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tsize_t v = stack.top();\n\t\t\t\tstack.pop();\n\n\t\t\t\t// Mark v as visited\n\t\t\t\tvisited[v] = true;\n\n\t\t\t\t// Add neighbors to stack\n\t\t\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\t\t\t// Check if A[v][col] is 1\n\t\t\t\t\tif (A[v * N + col] == 1 &&!visited[col]) {\n\t\t\t\t\t\tstack.push(col);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Compute the largest component\n\tfor (size_t i = 0; i < visited.size(); ++i) {\n\t\tif (visited[i]) {\n\t\t\tmax_component++;\n\t\t}\n\t}\n\n\treturn max_component;\n}",
            "std::vector<int> visited(N, false);\n  int largestComponent = 0;\n\n  #pragma omp parallel for shared(A, visited, N, largestComponent)\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      int currentComponent = 0;\n      std::queue<int> q;\n      q.push(i);\n      visited[i] = true;\n\n      while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        ++currentComponent;\n\n        for (int j = 0; j < N; ++j) {\n          if (A[N * v + j]) {\n            if (!visited[j]) {\n              q.push(j);\n              visited[j] = true;\n            }\n          }\n        }\n      }\n\n      #pragma omp critical\n      if (currentComponent > largestComponent) {\n        largestComponent = currentComponent;\n      }\n    }\n  }\n\n  return largestComponent;\n}",
            "int L = 0;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tstd::vector<int> visited(N, 0);\n\t\tstd::queue<int> q;\n\t\tvisited[i] = 1;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint u = q.front();\n\t\t\tq.pop();\n\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\tif (A[N * u + v] == 1 && visited[v] == 0) {\n\t\t\t\t\tvisited[v] = 1;\n\t\t\t\t\tq.push(v);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn 0;\n}",
            "if (N == 0) {\n        return 0;\n    }\n\n    std::vector<bool> visited(N);\n\n    auto dfs = [&A, N, &visited](size_t start) {\n        std::vector<size_t> stack;\n        stack.push_back(start);\n        while (!stack.empty()) {\n            auto i = stack.back();\n            stack.pop_back();\n\n            if (visited[i]) {\n                continue;\n            }\n\n            visited[i] = true;\n\n            for (size_t j = 0; j < N; ++j) {\n                if (i == j) {\n                    continue;\n                }\n\n                if (A[i*N + j]) {\n                    stack.push_back(j);\n                }\n            }\n        }\n    };\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) {\n            continue;\n        }\n\n        dfs(i);\n    }\n\n    return std::count(visited.begin(), visited.end(), true);\n}",
            "int count = 0;\n    bool *visited = new bool[N];\n    for (int i = 0; i < N; i++) {\n        visited[i] = false;\n    }\n    std::queue<int> q;\n    q.push(0);\n    visited[0] = true;\n    while (!q.empty()) {\n        int current = q.front();\n        q.pop();\n        for (int i = 0; i < N; i++) {\n            if (A[current * N + i] == 1 &&!visited[i]) {\n                q.push(i);\n                visited[i] = true;\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "// --------------------------------------------------------------------\n\t// TODO: Implement this function\n\t// --------------------------------------------------------------------\n\tint n = (int)N;\n\tint* v = new int[n];\n\tint* w = new int[n];\n\n\tint maxi = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < n; i++) {\n\t\tv[i] = 0;\n\t\tw[i] = 0;\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < n; i++) {\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (A[i*n+j] == 1) {\n\t\t\t\tw[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < n; i++) {\n\t\tif (v[i] == 0) {\n\t\t\t//BFS\n\t\t\tqueue<int> bfs;\n\t\t\tbfs.push(i);\n\t\t\tv[i] = 1;\n\n\t\t\twhile (!bfs.empty()) {\n\t\t\t\tint u = bfs.front();\n\t\t\t\tbfs.pop();\n\t\t\t\tfor (int j = 0; j < n; j++) {\n\t\t\t\t\tif (A[u*n+j] == 1 && v[j] == 0) {\n\t\t\t\t\t\tbfs.push(j);\n\t\t\t\t\t\tv[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < n; i++) {\n\t\tmaxi = (w[i] > maxi)? w[i] : maxi;\n\t}\n\n\tdelete[] v;\n\tdelete[] w;\n\n\treturn maxi;\n}",
            "std::vector<int> visited(N, 0);\n  int cmp = 0;\n  std::vector<int> queue;\n\n  // Traverse the graph in BFS order\n#pragma omp parallel\n#pragma omp single\n  {\n#pragma omp taskloop shared(A, queue, visited, cmp) untied\n    for (int i = 0; i < N; ++i) {\n      if (!visited[i]) {\n        queue.push_back(i);\n        cmp++;\n        visited[i] = 1;\n        while (queue.size() > 0) {\n          int cur = queue.front();\n          queue.erase(queue.begin());\n          for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] &&!visited[j]) {\n              visited[j] = 1;\n              queue.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // Sum up all components in the graph\n  int sum = 0;\n  for (int i = 0; i < N; ++i) {\n    sum += visited[i];\n  }\n\n  return sum;\n}",
            "std::vector<bool> in_component(N);\n  std::vector<bool> in_stack(N);\n  std::vector<int>  order;\n  order.reserve(N);\n\n  auto not_seen = [&] (int i) {\n    return i >= 0 && i < int(N) &&!in_component[i];\n  };\n\n  auto not_seen_and_in_stack = [&] (int i) {\n    return i >= 0 && i < int(N) &&!in_component[i] && in_stack[i];\n  };\n\n  auto stack_pop = [&] () {\n    int i;\n    for (i = order.size() - 1; i >= 0 &&!not_seen_and_in_stack(order[i]); --i) {}\n    if (i < 0)\n      return -1;\n    else {\n      in_stack[order[i]] = false;\n      order.pop_back();\n      return order[i];\n    }\n  };\n\n  auto dfs = [&] (int v) {\n    in_stack[v] = true;\n    in_component[v] = true;\n    order.push_back(v);\n\n    for (int u = 0; u < int(N); ++u) {\n      if (A[N*v + u] && not_seen(u)) {\n        dfs(u);\n      }\n    }\n  };\n\n  std::fill(in_component.begin(), in_component.end(), false);\n  std::fill(in_stack.begin(), in_stack.end(), false);\n  order.clear();\n\n#pragma omp parallel for\n  for (int v = 0; v < int(N); ++v)\n    if (!in_component[v])\n      dfs(v);\n\n  std::fill(in_component.begin(), in_component.end(), false);\n  while (!order.empty()) {\n    int v = stack_pop();\n    in_component[v] = true;\n  }\n\n  int max_component_size = 0;\n  int component_size;\n  for (int i = 0; i < int(N); ++i) {\n    component_size = 0;\n    for (int j = 0; j < int(N); ++j)\n      component_size += in_component[j];\n    max_component_size = std::max(max_component_size, component_size);\n  }\n\n  return max_component_size;\n}",
            "int max = 0;\n  std::vector<int> visited(N, 0);\n\n  for (int i = 0; i < N; i++) {\n\n    if (visited[i] == 0) {\n      visited[i] = 1;\n      int count = 1;\n      for (int j = 0; j < N; j++) {\n        if (i == j) continue;\n        if (A[i * N + j] == 1) {\n          if (visited[j] == 0) {\n            count++;\n            visited[j] = 1;\n          }\n        }\n      }\n      if (count > max) {\n        max = count;\n      }\n    }\n  }\n\n  return max;\n}",
            "// Implement in parallel\n\n  int max = 0;\n  std::vector<int> visited(N, 0);\n\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      int visited_count = 0;\n      std::vector<int> queue;\n      queue.push_back(i);\n\n      while (queue.size() > 0) {\n        int curr = queue.front();\n        visited[curr] = 1;\n        visited_count++;\n        queue.erase(queue.begin());\n\n        for (int j = 0; j < N; j++) {\n          if (visited[j] == 0 && A[curr * N + j]!= 0) {\n            queue.push_back(j);\n          }\n        }\n      }\n\n      if (visited_count > max) {\n        max = visited_count;\n      }\n    }\n  }\n\n  return max;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n#pragma omp parallel for shared(visited, count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint vertex = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[vertex] = true;\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[vertex * N + j] > 0 &&!visited[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> comp(N);\n\tstd::vector<bool> visited(N, false);\n\tstd::queue<int> q;\n\tint ans = 0;\n\t\n\tomp_set_dynamic(0);\n\tomp_set_num_threads(4);\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tq.push(i);\n\t\t\tint curr = 0;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint curr_i = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[curr_i] = true;\n\t\t\t\tcomp[curr_i] = curr;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[curr_i * N + j] &&!visited[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurr++;\n\t\t}\n\t}\n\t\n\tint max_comp = 0;\n\t#pragma omp parallel for reduction(max: max_comp)\n\tfor (int i = 0; i < N; ++i) {\n\t\tmax_comp = std::max(max_comp, comp[i]);\n\t}\n\treturn max_comp + 1;\n}",
            "std::vector<int> component(N, 0);\n\tint largest_component = 0;\n\tomp_lock_t lock;\n\tomp_init_lock(&lock);\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tcomponent[i] = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tif (i < j) {\n\t\t\t\t\tomp_set_lock(&lock);\n\t\t\t\t\tif (component[i] == 0) {\n\t\t\t\t\t\tcomponent[i] = component[j] + 1;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (component[j] == 0) {\n\t\t\t\t\t\t\tcomponent[j] = component[i] + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tif (component[i] == component[j]) {\n\t\t\t\t\t\t\t\tcomponent[i] = component[j] + 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tif (component[i] < component[j]) {\n\t\t\t\t\t\t\t\t\tcomponent[i] = component[j];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\tcomponent[j] = component[i];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tomp_unset_lock(&lock);\n\t\t\t\t}\n\t\t\t\telse if (i > j) {\n\t\t\t\t\tomp_set_lock(&lock);\n\t\t\t\t\tif (component[j] == 0) {\n\t\t\t\t\t\tcomponent[j] = component[i] + 1;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (component[i] == 0) {\n\t\t\t\t\t\t\tcomponent[i] = component[j] + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tif (component[i] == component[j]) {\n\t\t\t\t\t\t\t\tcomponent[i] = component[j] + 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tif (component[i] < component[j]) {\n\t\t\t\t\t\t\t\t\tcomponent[i] = component[j];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\tcomponent[j] = component[i];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tomp_unset_lock(&lock);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tomp_destroy_lock(&lock);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i]) {\n\t\t\tlargest_component += component[i];\n\t\t}\n\t}\n\treturn largest_component;\n}",
            "int max = 0;\n  #pragma omp parallel for schedule(dynamic, 1) reduction(max:max)\n  for (int i = 0; i < N; i++) {\n    // Do work\n  }\n  return max;\n}",
            "// TODO: Implement this function\n}",
            "// TODO: Use OpenMP to compute the largest component of the graph.\n    //       A is an NxN adjacency matrix stored in row-major.\n    //       You may assume that A contains all zeros and ones.\n    //       You may modify this code to return the number of vertices\n    //       in the largest component.\n    //\n    //       Hint:\n    //\n    //       You can use a parallel for loop to compute the largest\n    //       component of the graph:\n    //\n    //         #pragma omp parallel for\n    //         for (int i = 0; i < N; ++i) {\n    //           // Your code here.\n    //         }\n\n    //...\n}",
            "int max = 0;\n    bool *visited = new bool[N];\n    for(int i=0;i<N;i++){\n        visited[i] = false;\n    }\n\n    #pragma omp parallel for reduction(+:max)\n    for(int i=0;i<N;i++){\n        if(!visited[i]){\n            int count = 1;\n            visited[i] = true;\n            for(int j=0;j<N;j++){\n                if(A[i*N+j] == 1 &&!visited[j]){\n                    count += 1;\n                    visited[j] = true;\n                }\n            }\n            max = max > count? max : count;\n        }\n    }\n    delete[] visited;\n    return max;\n}",
            "int* visited = new int[N];\n    for (size_t i = 0; i < N; ++i)\n        visited[i] = 0;\n\n    int* compSize = new int[N];\n    for (size_t i = 0; i < N; ++i)\n        compSize[i] = 0;\n\n    int* maxCompSize = new int;\n    *maxCompSize = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            dfs(A, visited, i, N, compSize);\n            if (*maxCompSize < compSize[i])\n                *maxCompSize = compSize[i];\n        }\n    }\n\n    return *maxCompSize;\n}",
            "// TODO: Complete this function\n\tint nV = N;\n\tstd::vector<bool> visited(N,false);\n\tstd::vector<int> component(N);\n\t\n\t//std::cout << \"visited \" << std::endl;\n\t//for (int i=0;i<visited.size();i++){\n\t\t//std::cout << visited[i] << \" \";\n\t//}\n\t//std::cout << std::endl;\n\t\n\tfor (int i=0; i<visited.size();i++){\n\t\tif(!visited[i]){\n\t\t\tint count =0;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = true;\n\t\t\twhile(!q.empty()){\n\t\t\t\tint vert = q.front();\n\t\t\t\t//std::cout << \"vert \" << vert << std::endl;\n\t\t\t\tq.pop();\n\t\t\t\tfor (int j=0;j<N;j++){\n\t\t\t\t\t//std::cout << \"vert \" << vert << \" j \" << j << std::endl;\n\t\t\t\t\tif (A[vert*N + j] == 1 &&!visited[j]){\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomponent[i] = count;\n\t\t}\n\t}\n\t\n\tint max = component[0];\n\tfor (int i=0;i<N;i++){\n\t\tif (component[i] > max){\n\t\t\tmax = component[i];\n\t\t}\n\t}\n\treturn max;\n}",
            "// Your code goes here!\n}",
            "int c = 0;\n\t// TODO\n\treturn c;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> stack;\n  std::vector<int> max_size(N, 0);\n\n  /*\n  * We can use a stack to implement DFS.\n  * We start from node 0, and continue expanding its neighbors, and count how many nodes we have reached.\n  * We can do this for every node, and the result will be the size of the largest component.\n  */\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]!= 0) {\n      continue;\n    }\n    visited[i] = 1;\n    stack.push_back(i);\n    int cur_size = 1;\n    while (stack.size()!= 0) {\n      int cur_node = stack[stack.size() - 1];\n      stack.pop_back();\n      for (int j = 0; j < N; ++j) {\n        if (A[cur_node * N + j] == 1 && visited[j] == 0) {\n          stack.push_back(j);\n          visited[j] = 1;\n          cur_size++;\n        }\n      }\n    }\n    max_size[i] = cur_size;\n  }\n\n  int max_size_id = 0;\n  int max_size_value = 0;\n  for (int i = 0; i < N; ++i) {\n    if (max_size[i] > max_size_value) {\n      max_size_value = max_size[i];\n      max_size_id = i;\n    }\n  }\n\n  return max_size_value;\n}",
            "// Implement this\n}",
            "// your code goes here!\n    int* component = new int[N];\n    int max = 1;\n    for(int i=0; i<N; i++) {\n        if(component[i] == 0) {\n            component[i] = 1;\n            for(int j=i; j<N; j++) {\n                if(component[j] == 0 && A[i*N + j] == 1) {\n                    component[j] = 1;\n                }\n            }\n            int count = 0;\n            for(int j=0; j<N; j++) {\n                if(component[j] == 1) {\n                    count++;\n                }\n            }\n            if(count > max) {\n                max = count;\n            }\n        }\n    }\n    return max;\n}",
            "int size = N;\n\tstd::vector<int> visited = std::vector<int>(N, 0);\n\tstd::vector<int> component = std::vector<int>(N, 0);\n\tint index = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tindex = i;\n\t\t\tint visited_index = i;\n\t\t\twhile (visited_index < N) {\n\t\t\t\tvisited_index = dfs(A, visited, index, component, N, visited_index);\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint max_component = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component[i] > max_component) {\n\t\t\tmax_component = component[i];\n\t\t}\n\t}\n\treturn max_component;\n}",
            "// Your code here\n\n\tint component[N];\n\tmemset(component, 0, sizeof(component));\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (component[i] == 0) {\n\t\t\tsize_t count = 0;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\t\tcomponent[j] = ++count;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint max = 0;\n\tfor (int i : component) {\n\t\tif (i > max) {\n\t\t\tmax = i;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int res = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> cnt(N, 0);\n\tstd::vector<int> next(N, -1);\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i)\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tif (A[i*N + j] && i!= j) {\n\t\t\t\t++cnt[i];\n\t\t\t\tif (visited[j] == 0) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tnext[j] = i;\n\t\t\t\t}\n\t\t\t}\n\n\tint curr = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tcurr = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\twhile (true) {\n\t\t++res;\n\t\tint next_id = curr;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[curr*N + i] && next[i] == -1) {\n\t\t\t\tnext_id = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (curr == next_id)\n\t\t\tbreak;\n\t\tcurr = next_id;\n\t}\n\treturn res;\n}",
            "std::vector<int> components(N, 0);\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcomponents[i] = std::max(components[i], components[j]);\n\t\t\t}\n\t\t}\n\t}\n\n\tsize_t max = 0;\n\tsize_t max_idx = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (components[i] > max) {\n\t\t\tmax = components[i];\n\t\t\tmax_idx = i;\n\t\t}\n\t}\n\n\t// The rest is just a quick sanity check to make sure that the solution is correct.\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tassert(components[i] == components[j]);\n\t\t\t}\n\t\t}\n\t}\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (i == max_idx) {\n\t\t\tassert(components[i] == max);\n\t\t}\n\t\telse {\n\t\t\tassert(components[i] < max);\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int result = 0;\n\tint threads = omp_get_num_threads();\n\tstd::vector<int> visited(N, 0);\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (visited[i] == 0)\n\t\t{\n\t\t\tomp_set_lock(lock);\n\t\t\tvisited[i] = 1;\n\t\t\tomp_unset_lock(lock);\n\n\t\t\tint counter = 0;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile (q.empty()!= true)\n\t\t\t{\n\t\t\t\tint v = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tomp_set_lock(lock);\n\t\t\t\tvisited[v] = 1;\n\t\t\t\tomp_unset_lock(lock);\n\t\t\t\tcounter++;\n\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t{\n\t\t\t\t\tif (visited[j] == 0 && A[v * N + j] == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\tomp_set_lock(lock);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tomp_unset_lock(lock);\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (counter > result)\n\t\t\t{\n\t\t\t\tresult = counter;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int largest_component = 0;\n  #pragma omp parallel for reduction(max : largest_component)\n  for (int i=0; i<N; ++i) {\n    int cur_component = 0;\n    for (int j=0; j<N; ++j) {\n      if (A[i*N + j]) {\n        ++cur_component;\n      }\n    }\n    largest_component = std::max(largest_component, cur_component);\n  }\n  return largest_component;\n}",
            "int largest_component = 0;\n\n#pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    std::vector<bool> visited(N, false);\n    std::vector<int> to_visit{i};\n    visited[i] = true;\n\n    while (!to_visit.empty()) {\n      int v = to_visit.back();\n      to_visit.pop_back();\n\n      for (int j = 0; j < N; j++) {\n        if (A[v * N + j] == 1 &&!visited[j]) {\n          visited[j] = true;\n          to_visit.push_back(j);\n        }\n      }\n    }\n\n    if (visited.size() > largest_component) {\n      largest_component = visited.size();\n    }\n  }\n  return largest_component;\n}",
            "#pragma omp parallel\n  {\n    // your code here\n  }\n}",
            "/* Your solution goes here */\n}",
            "// Use OpenMP to compute in parallel.\n    int n_threads;\n    #pragma omp parallel\n    {\n        n_threads = omp_get_num_threads();\n    }\n\n    int *counts = new int[n_threads];\n    for (int i = 0; i < n_threads; i++) {\n        counts[i] = 0;\n    }\n\n    #pragma omp parallel for\n    for (size_t row = 0; row < N; row++) {\n        for (size_t col = 0; col < N; col++) {\n            if (A[row * N + col]) {\n                counts[omp_get_thread_num()]++;\n            }\n        }\n    }\n\n    int max_count = counts[0];\n    for (int i = 1; i < n_threads; i++) {\n        if (counts[i] > max_count) {\n            max_count = counts[i];\n        }\n    }\n\n    return max_count;\n}",
            "int nthreads = omp_get_max_threads();\n  int *nv = new int[nthreads];\n  #pragma omp parallel num_threads(nthreads)\n  {\n    int tid = omp_get_thread_num();\n    nv[tid] = 0;\n\n    #pragma omp for schedule(static, 1)\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + i]!= 0) {\n        nv[tid]++;\n      }\n    }\n  }\n\n  int max_nv = 0;\n  for (int i = 0; i < nthreads; i++) {\n    if (nv[i] > max_nv) {\n      max_nv = nv[i];\n    }\n  }\n\n  return max_nv;\n}",
            "// TODO: Implement.\n    return 0;\n}",
            "#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (A[i * N + i] == 0) {\n\t\t\tA[i * N + i] = 1;\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (size_t j = 0; j < N; ++j) {\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (i < j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tA[i * N + j] = 0;\n\t\t\t\t\tA[j * N + i] = 0;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tA[i * N + j] = 0;\n\t\t\t\t\tA[j * N + i] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint largestComponentSize = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint componentSize = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcomponentSize++;\n\t\t\t}\n\t\t}\n\t\tif (componentSize > largestComponentSize) {\n\t\t\tlargestComponentSize = componentSize;\n\t\t}\n\t}\n\n\treturn largestComponentSize;\n}",
            "std::vector<bool> visited(N);\n\tstd::vector<int> component_size(N, 0);\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\t// check if vertex has already been visited\n\t\tif (visited[i] == 0) {\n\t\t\tstd::vector<int> stack;\n\t\t\tstack.push_back(i);\n\t\t\twhile (stack.size()!= 0) {\n\t\t\t\tint curr = stack.back();\n\t\t\t\tstack.pop_back();\n\t\t\t\tvisited[curr] = true;\n\t\t\t\t// check neighbors of curr vertex\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i * N + j] == 1 && visited[j] == false) {\n\t\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponent_size[i] = visited[i];\n\t}\n\n\tint size = *std::max_element(component_size.begin(), component_size.end());\n\treturn size;\n}",
            "auto count = A.size();\n\tstd::vector<int> visited(count, 0);\n\tstd::vector<int> nums(count, 0);\n#pragma omp parallel for\n\tfor (size_t i = 0; i < count; i++) {\n\t\tauto cur = i;\n\t\tif (!visited[cur]) {\n\t\t\tint cnt = 0;\n\t\t\twhile (!visited[cur]) {\n\t\t\t\tvisited[cur] = 1;\n\t\t\t\tcnt++;\n\t\t\t\tcur = A[cur];\n\t\t\t}\n\t\t\tnums[i] = cnt;\n\t\t}\n\t}\n\tint maxCnt = 0;\n\tint maxId = 0;\n\tfor (size_t i = 0; i < count; i++) {\n\t\tif (maxCnt < nums[i]) {\n\t\t\tmaxCnt = nums[i];\n\t\t\tmaxId = i;\n\t\t}\n\t}\n\treturn maxCnt;\n}",
            "int* component = new int[N];\n\n\tstd::fill(component, component+N, 0);\n\n\tomp_set_num_threads(omp_get_max_threads());\n\t#pragma omp parallel\n\t{\n\t\tstd::vector<bool> visited(N, false);\n\t\tint start;\n\n\t\t#pragma omp for\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tif(!visited[i]) {\n\t\t\t\tstart = i;\n\n\t\t\t\tvisited[i] = true;\n\t\t\t\tcomponent[i] = 1;\n\t\t\t\tstd::queue<int> q;\n\t\t\t\tq.push(i);\n\n\t\t\t\twhile(!q.empty()) {\n\t\t\t\t\tint x = q.front();\n\t\t\t\t\tq.pop();\n\n\t\t\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\t\t\tif(!visited[j] && A[x*N + j] > 0) {\n\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t\tcomponent[j] = 1;\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxComponent = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tmaxComponent = std::max(maxComponent, component[i]);\n\t}\n\n\tdelete[] component;\n\treturn maxComponent;\n}",
            "const int N_THREADS = 4;\n    const int BLOCK_SIZE = 100000;\n    std::vector<int> visited(N, 0);\n    std::vector<int> curr_visited(N, 0);\n    int curr_max = 0;\n    int max = 0;\n    int k = 0;\n    int index = 0;\n    bool found = false;\n\n    omp_set_num_threads(N_THREADS);\n\n    #pragma omp parallel private(curr_visited, curr_max, k, index, found)\n    {\n        curr_visited = std::vector<int>(N, 0);\n        #pragma omp for schedule(dynamic, BLOCK_SIZE)\n        for (int i = 0; i < N; i++) {\n            curr_max = 0;\n            found = false;\n\n            if (visited[i] == 0) {\n                curr_visited[i] = 1;\n                for (int j = 0; j < N; j++) {\n                    if (i == j)\n                        continue;\n\n                    if (A[N * i + j] == 1 && curr_visited[j] == 0) {\n                        curr_visited[j] = 1;\n                        for (int m = 0; m < N; m++) {\n                            if (A[N * j + m] == 1 && curr_visited[m] == 0) {\n                                curr_visited[m] = 1;\n                                curr_max++;\n                            }\n                        }\n                    }\n                }\n                curr_max++;\n\n                #pragma omp critical\n                {\n                    if (curr_max > max) {\n                        max = curr_max;\n                        k = i;\n                    }\n                }\n            }\n        }\n\n        #pragma omp for schedule(dynamic, BLOCK_SIZE)\n        for (int i = 0; i < N; i++) {\n            if (visited[i] == 0 && i!= k) {\n                found = false;\n                for (int j = 0; j < N; j++) {\n                    if (i == j)\n                        continue;\n\n                    if (A[N * i + j] == 1 && visited[j] == 1) {\n                        found = true;\n                        break;\n                    }\n                }\n                if (!found) {\n                    #pragma omp atomic\n                    visited[i] = 1;\n                }\n            }\n        }\n    }\n\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 1)\n            count++;\n    }\n    return count;\n}",
            "// TODO: add your code here\n\n    std::vector<bool> visited(N, false);\n    std::vector<int> component_size(N, 0);\n\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            size_t size = 0;\n            std::vector<int> stk;\n            stk.push_back(i);\n\n            while (!stk.empty()) {\n                int j = stk.back();\n                stk.pop_back();\n\n                if (visited[j]) continue;\n\n                visited[j] = true;\n                size++;\n                component_size[i]++;\n\n                for (int k = 0; k < N; k++) {\n                    if (A[i * N + k] == 1) {\n                        stk.push_back(k);\n                    }\n                }\n            }\n\n            for (int j = 0; j < N; j++) {\n                if (visited[j]) continue;\n                component_size[j] = size;\n            }\n        }\n    }\n\n    int max_comp = 0;\n    for (int i = 0; i < N; i++) {\n        if (component_size[i] > max_comp) max_comp = component_size[i];\n    }\n\n    return max_comp;\n}",
            "// The vertices of the graph\n\tstd::vector<std::vector<int>> adj(N, std::vector<int>());\n\t// The current component\n\tstd::vector<int> component(N, 0);\n\t// The size of the current component\n\tint size = 0;\n\t// The size of the largest component\n\tint max = 0;\n\n\t// Build the adjacency lists\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[i * N + j])\n\t\t\t\tadj[i].push_back(j);\n\n\t// Compute the size of the largest component\n\t#pragma omp parallel for shared(adj, component, max) schedule(static)\n\tfor (int i = 0; i < N; i++) {\n\t\t// If the vertex is already in a component, skip it\n\t\tif (component[i] == 1)\n\t\t\tcontinue;\n\n\t\t// Mark all vertices reachable from i\n\t\tcomponent[i] = 1;\n\t\tsize = 1;\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint curr = q.front();\n\t\t\tq.pop();\n\t\t\tfor (int j = 0; j < adj[curr].size(); j++) {\n\t\t\t\tint v = adj[curr][j];\n\t\t\t\tif (component[v] == 0) {\n\t\t\t\t\tcomponent[v] = 1;\n\t\t\t\t\tq.push(v);\n\t\t\t\t\tsize++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (size > max)\n\t\t\t\tmax = size;\n\t\t}\n\t\t// Reset the component\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tcomponent[j] = 0;\n\t}\n\n\t// Count the vertices in the largest component\n\tsize = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tif (component[i] == 1)\n\t\t\tsize++;\n\n\treturn size;\n}",
            "std::vector<bool> vis(N, false);\n    std::vector<int> d(N, 1);\n\n    int cnt = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!vis[i]) {\n            cnt++;\n            vis[i] = true;\n            for (int j = 0; j < N; ++j) {\n                if (A[i * N + j]!= 0 &&!vis[j]) {\n                    d[j] = std::max(d[j], d[i] + 1);\n                }\n            }\n        }\n    }\n    return cnt;\n}",
            "// TODO: fill in\n}",
            "std::vector<int> compSize(N, 0);\n\tomp_set_num_threads(omp_get_num_procs());\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tfor (int j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (i!= j && A[N * i + j] == 1)\n\t\t\t\tcompSize[i]++;\n\t\t}\n\t}\n\n\tint maxSize = 0;\n\tint maxId = 0;\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tif (compSize[i] > maxSize)\n\t\t{\n\t\t\tmaxSize = compSize[i];\n\t\t\tmaxId = i;\n\t\t}\n\t}\n\n\tint largestComp = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::stack<int> stack;\n\tstack.push(maxId);\n\twhile (!stack.empty())\n\t{\n\t\tint i = stack.top();\n\t\tstack.pop();\n\t\tif (visited[i] == 1)\n\t\t\tcontinue;\n\t\tvisited[i] = 1;\n\t\tlargestComp++;\n\t\tfor (int j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (A[N * i + j] == 1)\n\t\t\t\tstack.push(j);\n\t\t}\n\t}\n\n\treturn largestComp;\n}",
            "int ans = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint max = 0;\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tint cur = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t\tcur++;\n\t\t\t}\n\t\t\tif (cur > max)\n\t\t\t\tmax = cur;\n\t\t}\n\n\t\t#pragma omp critical\n\t\tif (max > ans)\n\t\t\tans = max;\n\t}\n\n\treturn ans;\n}",
            "/* TODO: Your code here */\n\tstd::vector<int> isVisited(N, 0);\n\tint cnt = 0;\n\n\tfor(int i = 0; i < N; i++){\n\t\tif(isVisited[i]!= 1){\n\t\t\tisVisited[i] = 1;\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(isVisited[j]!= 1 && A[i * N + j] == 1){\n\t\t\t\t\tisVisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcnt++;\n\t\t}\n\t}\n\treturn cnt;\n}",
            "std::vector<bool> visited(N, false);\n\n\tstd::function<int(int)> dfs = [&](int v) {\n\t\tvisited[v] = true;\n\t\tint c = 1;\n\n\t\tfor (size_t w = 0; w < N; ++w) {\n\t\t\tif (A[v * N + w] == 1 &&!visited[w]) {\n\t\t\t\tc += dfs(w);\n\t\t\t}\n\t\t}\n\n\t\treturn c;\n\t};\n\n\tstd::vector<int> component_sizes(N, 0);\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcomponent_sizes[i] = dfs(i);\n\t\t}\n\t}\n\n\treturn *std::max_element(component_sizes.begin(), component_sizes.end());\n}",
            "std::vector<bool> visited(N, false);\n\n    // TODO:\n    // Find and mark all the vertices in the largest connected component\n\n    // TODO:\n    // Count the number of vertices in the largest component\n\n    return n_largest_component;\n}",
            "int component_size = 1;\n  std::vector<int> components(N, 0);\n  int largest_component_size = 0;\n  int current_component_size = 0;\n  int current_vertex = 0;\n\n#pragma omp parallel for schedule(static) \\\n  default(none) shared(A, N, components, largest_component_size) \\\n  private(current_component_size, current_vertex)\n  for (int i = 0; i < N; ++i) {\n    current_vertex = i;\n    current_component_size = 0;\n\n    // Traverse the current component\n    do {\n      current_component_size += 1;\n      components[current_vertex] = component_size;\n      current_vertex = -1;\n\n      // Find the next vertex in the current component\n      for (int j = 0; j < N; ++j) {\n        if (A[i*N+j] == 1 && components[j] == 0) {\n          current_vertex = j;\n          break;\n        }\n      }\n    } while (current_vertex!= -1);\n\n    if (current_component_size > largest_component_size) {\n      largest_component_size = current_component_size;\n      component_size += 1;\n    }\n  }\n  return largest_component_size;\n}",
            "std::vector<int> comp(N, 0);\n    std::vector<int> q(N, 0);\n    int q_front = 0, q_back = 0;\n    int curr_comp = 0;\n\n    for (int i = 0; i < N; ++i) {\n        if (comp[i]!= 0) {\n            continue;\n        }\n\n        q[q_back] = i;\n        ++q_back;\n        comp[i] = curr_comp + 1;\n\n        #pragma omp parallel for\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1 && comp[j] == 0) {\n                q[q_back] = j;\n                ++q_back;\n                comp[j] = curr_comp + 1;\n            }\n        }\n\n        ++curr_comp;\n        while (q_front!= q_back) {\n            #pragma omp parallel for\n            for (int k = 0; k < N; ++k) {\n                if (A[q[q_front] * N + k] == 1 && comp[k] == 0) {\n                    q[q_back] = k;\n                    ++q_back;\n                    comp[k] = curr_comp + 1;\n                }\n            }\n            ++q_front;\n        }\n    }\n\n    int max_comp = 0;\n    for (int i = 0; i < N; ++i) {\n        max_comp = std::max(max_comp, comp[i]);\n    }\n\n    return max_comp;\n}",
            "int largest = 0;\n\t// Fill in your code here\n\n\treturn largest;\n}",
            "/* Your code here */\n    std::vector<int> visited(N, 0);\n    int count = 0;\n    int max_count = 0;\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            count = DFS(i, N, A, visited);\n            if (count > max_count) {\n                max_count = count;\n            }\n        }\n    }\n    return max_count;\n}",
            "// TODO: your code goes here\n}",
            "auto isConnected = std::vector<bool>(N);\n    int largestComponent = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        isConnected[i] = false;\n        #pragma omp parallel for\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                isConnected[j] = true;\n            }\n        }\n        int count = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (isConnected[j]) {\n                count++;\n            }\n        }\n        if (count > largestComponent) {\n            largestComponent = count;\n        }\n    }\n    return largestComponent;\n}",
            "std::vector<int> component(N, -1);\n    int compId = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        std::queue<int> q;\n        q.push(i);\n        component[i] = compId;\n        while (!q.empty()) {\n            int node = q.front();\n            q.pop();\n            for (int j = 0; j < N; ++j) {\n                if (A[N*node + j] == 1 && component[j] < 0) {\n                    q.push(j);\n                    component[j] = compId;\n                }\n            }\n        }\n        ++compId;\n    }\n\n    int maxSize = 0;\n    int maxComp = 0;\n    for (int i = 0; i < compId; ++i) {\n        int size = 0;\n        for (int j = 0; j < N; ++j) {\n            if (component[j] == i) {\n                ++size;\n            }\n        }\n        if (size > maxSize) {\n            maxSize = size;\n            maxComp = i;\n        }\n    }\n\n    int result = 0;\n    for (int i = 0; i < N; ++i) {\n        if (component[i] == maxComp) {\n            ++result;\n        }\n    }\n\n    return result;\n}",
            "std::vector<int> color(N,0);\n    std::vector<int> counter(N,0);\n    std::vector<int> max_component_size(1,1);\n\n    #pragma omp parallel\n    {\n        int nth = omp_get_thread_num();\n        int nthreads = omp_get_num_threads();\n        //printf(\"Thread %d/%d\\n\", nth, nthreads);\n\n        #pragma omp for\n        for(int i = 0; i < N; i++) {\n            for(int j = i+1; j < N; j++) {\n                if(A[N*i + j] == 1) {\n                    #pragma omp critical\n                    {\n                        color[i] = nth;\n                        color[j] = nth;\n                        counter[nth]++;\n                    }\n                }\n            }\n        }\n    }\n\n    int max_component_size_value = 0;\n    for(int i = 0; i < N; i++) {\n        if(max_component_size_value < counter[i]) {\n            max_component_size[0] = counter[i];\n        }\n    }\n\n    return max_component_size[0];\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> numVisited(N,0);\n    int numOfVertices = 0;\n#pragma omp parallel for num_threads(N)\n    for(int i = 0; i < N; i++)\n    {\n        if(A[i*N+i] == 1)\n        {\n            numOfVertices++;\n            visited[i] = true;\n            #pragma omp parallel for num_threads(N)\n            for(int j = 0; j < N; j++)\n            {\n                if(A[i*N+j] == 1 &&!visited[j])\n                {\n                    visited[j] = true;\n                    numVisited[i]++;\n                }\n            }\n        }\n    }\n    int max = numVisited[0];\n    for(int i = 0; i < N; i++)\n    {\n        if(max < numVisited[i])\n            max = numVisited[i];\n    }\n    return max;\n}",
            "int max_value = -1;\n  int max_idx = -1;\n  for (int i = 0; i < N; i++) {\n    int value = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        value += 1;\n      }\n    }\n    if (value > max_value) {\n      max_value = value;\n      max_idx = i;\n    }\n  }\n  return max_value;\n}",
            "std::vector<int> components(N, 1);\n    #pragma omp parallel for\n    for(size_t i=0; i<N; ++i){\n        for(size_t j=0; j<N; ++j){\n            if(A[i*N + j] == 1 && i!= j){\n                if(components[i] > components[j]){\n                    components[j] = components[i];\n                }else{\n                    components[i] = components[j];\n                }\n            }\n        }\n    }\n    int max = 0;\n    #pragma omp parallel for reduction(max:max)\n    for(size_t i=0; i<N; ++i){\n        if(max < components[i]){\n            max = components[i];\n        }\n    }\n    return max;\n}",
            "// Implement me!\n}",
            "std::vector<std::vector<bool>> visited(N, std::vector<bool>(N, false));\n    std::vector<int> stack;\n    int size = 0;\n\n    #pragma omp parallel for schedule(dynamic)\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (i == j) continue;\n            if (visited[i][j]) continue;\n            if (A[i * N + j] == 0) continue;\n\n            stack.clear();\n            stack.push_back(i);\n            visited[i][j] = true;\n            visited[j][i] = true;\n            while (stack.size() > 0) {\n                auto v = stack.back();\n                stack.pop_back();\n                for (int j = 0; j < N; ++j) {\n                    if (v == j) continue;\n                    if (visited[v][j]) continue;\n                    if (A[v * N + j] == 0) continue;\n\n                    visited[v][j] = true;\n                    visited[j][v] = true;\n                    stack.push_back(j);\n                }\n            }\n            size += stack.size();\n        }\n    }\n    return size;\n}",
            "if (A.size()!= N * N) {\n\t\tthrow std::invalid_argument(\"A must be N x N\");\n\t}\n\n\t#pragma omp parallel\n\t{\n\t\tint nthreads = omp_get_num_threads();\n\t\t#pragma omp single\n\t\t{\n\t\t\tprintf(\"Using %d threads.\\n\", nthreads);\n\t\t}\n\t}\n\n\tstd::vector<int> component;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\t// If vertex i is not in component, add it and check for neighbours.\n\t\tif (component[i] == 0) {\n\t\t\tcomponent[i] = 1;\n\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[N * i + j] == 1 && component[j] == 0) {\n\t\t\t\t\tcomponent[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the size of the largest component.\n\tint largest = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component[i] == 1) {\n\t\t\tlargest++;\n\t\t}\n\t}\n\n\treturn largest;\n}",
            "// Add your code here\n\n    return 0;\n}",
            "std::vector<int> visited(N, false);\n\n\tint max_component = 1;\n\n\t#pragma omp parallel\n\t{\n\t\tstd::vector<int> thread_visited(N, false);\n\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (!visited[i]) {\n\t\t\t\tint thread_component = 1;\n\t\t\t\tbfs(i, A, N, thread_visited);\n\n\t\t\t\t#pragma omp critical\n\t\t\t\t{\n\t\t\t\t\tmax_component = std::max(max_component, thread_component);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (thread_visited[i]) {\n\t\t\t\t#pragma omp critical\n\t\t\t\t{\n\t\t\t\t\tvisited[i] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn max_component;\n}",
            "int largestComponent = 1;\n\n  // Your code here\n\n  return largestComponent;\n}",
            "int *visited = (int*)malloc(sizeof(int)*N);\n\tint *count = (int*)malloc(sizeof(int)*N);\n\tfor(int i=0; i<N; i++) {\n\t\tvisited[i]=0;\n\t\tcount[i]=0;\n\t}\n\tint cnt=0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(visited[i]==0) {\n\t\t\tvisit(i, A, visited, count, N);\n\t\t\tcnt++;\n\t\t}\n\t}\n\n\tint max=0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(count[i]>max) {\n\t\t\tmax=count[i];\n\t\t}\n\t}\n\n\tfree(visited);\n\tfree(count);\n\treturn max;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "serial",
        "prompt": "/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "/*\n\t\tKahn's algorithm.\n\t\thttps://en.wikipedia.org/wiki/Topological_sorting#Kahn%27s_algorithm\n\t*/\n\tstd::vector<int> indegree(N, 0);\n\tstd::vector<std::vector<int>> adjacency(N);\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(A[i*N+j]) {\n\t\t\t\tadjacency[i].push_back(j);\n\t\t\t\t++indegree[j];\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::queue<int> S;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tif(indegree[i] == 0) S.push(i);\n\t}\n\n\tsize_t counter = 0;\n\twhile(!S.empty()) {\n\t\t++counter;\n\t\tint vertex = S.front();\n\t\tS.pop();\n\t\tfor(int neighbor : adjacency[vertex]) {\n\t\t\tif(--indegree[neighbor] == 0) S.push(neighbor);\n\t\t}\n\t}\n\n\treturn counter;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> stack;\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            stack.push_back(i);\n            visited[i] = true;\n            while (!stack.empty()) {\n                int u = stack.back();\n                stack.pop_back();\n                for (int v = 0; v < N; ++v) {\n                    if (!visited[v] && A[u * N + v]) {\n                        stack.push_back(v);\n                        visited[v] = true;\n                        count++;\n                    }\n                }\n            }\n        }\n    }\n    return count;\n}",
            "int const MAX_SIZE = 200; // Maximum size of the graph\n\tint D[MAX_SIZE];\n\tint C[MAX_SIZE];\n\tbool V[MAX_SIZE];\n\tint S = 0, T = 0;\n\tint m = 0, n = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tD[i] = -1;\n\t\tC[i] = -1;\n\t\tV[i] = false;\n\t}\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tif (i == j) continue;\n\t\t\t\tif (D[i] == -1) {\n\t\t\t\t\tD[i] = j;\n\t\t\t\t\tC[i] = 1;\n\t\t\t\t\tS++;\n\t\t\t\t\tV[i] = true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tif (D[i]!= j) {\n\t\t\t\t\t\tD[i] = j;\n\t\t\t\t\t\tC[i]++;\n\t\t\t\t\t\tS++;\n\t\t\t\t\t\tV[i] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\twhile (S > 0) {\n\t\tm = MAX_SIZE;\n\t\tn = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (V[i] == true) {\n\t\t\t\tif (C[i] < m) {\n\t\t\t\t\tm = C[i];\n\t\t\t\t\tn = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tV[n] = false;\n\t\tS -= C[n];\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (V[i] == true && D[i] == n) {\n\t\t\t\tD[i] = D[n];\n\t\t\t\tC[i]++;\n\t\t\t\tS++;\n\t\t\t}\n\t\t}\n\t\tT++;\n\t}\n\treturn T;\n}",
            "std::vector<int> visited(N, 0);\n\tint max = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(i, A, visited, max);\n\t\t}\n\t}\n\treturn max;\n}",
            "int compCount = 0;\n\tint maxCompSize = 0;\n\tbool* visited = new bool[N];\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tstd::queue<int> Q;\n\t\t\tQ.push(i);\n\t\t\tvisited[i] = true;\n\t\t\tint compSize = 0;\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tint curr = Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tcompSize++;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[curr*N + j] == 1) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tQ.push(j);\n\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (maxCompSize < compSize) {\n\t\t\t\tmaxCompSize = compSize;\n\t\t\t}\n\t\t\tcompCount++;\n\t\t}\n\t}\n\treturn maxCompSize;\n}",
            "std::vector<int> componentSize(N, 0);\n  std::vector<int> nextNode(N, -1);\n\n  int numComponents = 0;\n  // Iterate through A from left to right, top to bottom.\n  // Use BFS to find all the components in the graph.\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 0) continue;\n      if (componentSize[i] == 0) {\n        // i is the root of a new component\n        componentSize[i] = 1;\n        numComponents++;\n      }\n      if (componentSize[j] == 0) {\n        // j is the root of a new component\n        componentSize[j] = 1;\n        nextNode[i] = j;\n        numComponents++;\n      }\n\n      // If j is already in a component, merge the two components.\n      if (componentSize[j]!= 0) {\n        componentSize[i] += componentSize[j];\n        nextNode[i] = j;\n      }\n    }\n  }\n\n  // Iterate through A from left to right, top to bottom.\n  // Add the root of each component to the next node.\n  // If a component has multiple roots, keep track of the largest root.\n  int maxRoot = -1;\n  int maxRootSize = 0;\n  for (int i = 0; i < N; i++) {\n    if (componentSize[i] == 0) continue;\n    // i is the root of a component\n    componentSize[i] = 0;\n    if (componentSize[nextNode[i]] < maxRootSize) {\n      maxRootSize = componentSize[nextNode[i]];\n      maxRoot = nextNode[i];\n    }\n  }\n\n  return maxRootSize;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> stack;\n\tint largest = 0;\n\t\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 1) {\n\t\t\tcontinue;\n\t\t}\n\t\tstack.push_back(i);\n\t\t\n\t\twhile (!stack.empty()) {\n\t\t\tint curr = stack.back();\n\t\t\tstack.pop_back();\n\t\t\t\n\t\t\tif (visited[curr] == 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\n\t\t\tvisited[curr] = 1;\n\t\t\t\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[N * curr + j] == 1) {\n\t\t\t\t\tstack.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tlargest = std::max(largest, std::count(visited.begin(), visited.end(), 1));\n\t}\n\t\n\treturn largest;\n}",
            "std::vector<int> visited(N, 0);\n    std::queue<int> q;\n\n    q.push(0);\n    visited[0] = 1;\n    int count = 1;\n\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        for (int i = 0; i < N; i++) {\n            if (visited[i] == 0 && A[v * N + i]) {\n                q.push(i);\n                visited[i] = 1;\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]!= 1) {\n\t\t\t++count;\n\t\t\tstd::stack<int> stack;\n\t\t\tstack.push(i);\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tint node = stack.top();\n\t\t\t\tstack.pop();\n\t\t\t\tvisited[node] = 1;\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[node * N + j] == 1 && visited[j]!= 1) {\n\t\t\t\t\t\tstack.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\n\tauto dfs = [&](size_t cur, std::vector<int>& visited) {\n\t\tvisited[cur] = 1;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (visited[i]!= 1 && A[cur * N + i] == 1) {\n\t\t\t\tdfs(i, visited);\n\t\t\t}\n\t\t}\n\t};\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]!= 1) {\n\t\t\tcount++;\n\t\t\tdfs(i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N);\n    int largest = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n\n        int size = 0;\n        std::queue<int> q;\n        q.push(i);\n\n        while (!q.empty()) {\n            size += 1;\n            int u = q.front();\n            q.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (A[N * u + j]) {\n                    if (!visited[j]) {\n                        visited[j] = true;\n                        q.push(j);\n                    }\n                }\n            }\n        }\n        largest = std::max(largest, size);\n    }\n    return largest;\n}",
            "// Create a vector representing whether we've visited each node or not.\n\tstd::vector<bool> visited(N, false);\n\t// We'll store the components in a set.\n\tstd::set<int> components;\n\t// For each node...\n\tfor (size_t i = 0; i < N; ++i) {\n\t\t//...if we haven't visited it...\n\t\tif (!visited[i]) {\n\t\t\t//...keep track of the current component by storing the index of the node we're visiting.\n\t\t\tint currentComponent = i;\n\t\t\t// We have to keep going until there are no more unvisited nodes.\n\t\t\twhile (true) {\n\t\t\t\t// We'll keep track of whether we found any nodes we haven't visited.\n\t\t\t\tbool foundNew = false;\n\t\t\t\t// For each adjacent node...\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\t//...if it's adjacent...\n\t\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t\t//...and we haven't visited it...\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\t//...set its component to the same as ours.\n\t\t\t\t\t\t\tcurrentComponent = j;\n\t\t\t\t\t\t\t// We found a new node.\n\t\t\t\t\t\t\tfoundNew = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Mark it as visited.\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// If we didn't find any new nodes, we're done.\n\t\t\t\tif (!foundNew) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Add the current component to the set.\n\t\t\tcomponents.insert(currentComponent);\n\t\t}\n\t}\n\t// Return the size of the largest component.\n\treturn *std::max_element(std::begin(components), std::end(components));\n}",
            "assert(N * N == A.size());\n\tif (N == 0) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<int> visited(N);\n\tvisited[0] = 1;\n\n\tstd::stack<std::pair<int, int>> stack;\n\tstack.push({0, 0});\n\n\t// Traverse the graph using a DFS approach\n\twhile (!stack.empty()) {\n\t\tauto [x, y] = stack.top();\n\t\tstack.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * x + i] == 1 && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tstack.push({i, 0});\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the number of vertices visited\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 1) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  int component_count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      // use depth-first traversal to find all vertices\n      // reachable from vertex i.\n      dfs(A, N, i, visited, component_count);\n      ++component_count;\n    }\n  }\n  return component_count;\n}",
            "// TODO: your code here\n    return 0;\n}",
            "std::vector<int> colors;\n\tint nextColor = 0;\n\tcolors.resize(N, -1);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (colors[i] == -1) {\n\t\t\tdfs(A, N, i, nextColor, colors);\n\t\t\t++nextColor;\n\t\t}\n\t}\n\tstd::cout << \"Colors: \" << std::endl;\n\tprintVec(colors);\n\tstd::cout << \"Next Color: \" << nextColor << std::endl;\n\treturn nextColor - 1;\n}",
            "int max_component_size = 0;\n    std::vector<bool> visited(N);\n    for (size_t i = 0; i < N; ++i) {\n        int component_size = 0;\n        DFS(A, N, i, visited, component_size);\n        max_component_size = std::max(max_component_size, component_size);\n    }\n    return max_component_size;\n}",
            "std::vector<bool> visited(N, false);\n\n  // bfs\n  std::function<void(size_t)> dfs = [&dfs, &A, &visited](size_t u) {\n    visited[u] = true;\n    for (size_t v = 0; v < N; ++v) {\n      if (A[u * N + v] == 1 &&!visited[v]) {\n        dfs(v);\n      }\n    }\n  };\n\n  size_t max_component_size = 0;\n  for (size_t v = 0; v < N; ++v) {\n    if (!visited[v]) {\n      dfs(v);\n      max_component_size = std::max(max_component_size, std::count(visited.begin(), visited.end(), true));\n    }\n  }\n\n  return max_component_size;\n}",
            "//\n}",
            "std::vector<int> b(N, 0);\n\n  for (size_t i = 0; i < N; i++) {\n    if (b[i] == 1) { continue; }\n\n    std::queue<int> q;\n    q.push(i);\n    b[i] = 1;\n\n    while (!q.empty()) {\n      int i = q.front();\n      q.pop();\n\n      for (size_t j = 0; j < N; j++) {\n        if (A[i*N + j] == 1 && b[j] == 0) {\n          q.push(j);\n          b[j] = 1;\n        }\n      }\n    }\n  }\n\n  return std::count(b.begin(), b.end(), 1);\n}",
            "// Write your code here\n    std::vector<bool> visited;\n    visited.resize(N, false);\n    int size = 0;\n    \n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            dfs(A, visited, i);\n            ++size;\n        }\n    }\n    \n    return size;\n}",
            "// Write your code here\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> componentSize(N, 0);\n\tstd::queue<int> q;\n\n\tint largest = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tint currentComponentSize = 0;\n\t\t\tq.push(i);\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint curr = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tif (!visited[curr]) {\n\t\t\t\t\t++currentComponentSize;\n\t\t\t\t\tvisited[curr] = true;\n\t\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (!visited[j] && A[curr * N + j]) {\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomponentSize[i] = currentComponentSize;\n\t\t\tlargest = std::max(largest, currentComponentSize);\n\t\t}\n\t}\n\n\treturn largest;\n}",
            "return std::max_element(A.begin(), A.end()) - A.begin();\n}",
            "int count = 0;\n\n  // Find connected component size for each node\n  std::vector<int> connected_size(N, 0);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        connected_size[i]++;\n      }\n    }\n  }\n\n  // Find largest component size\n  for (size_t i = 0; i < N; ++i) {\n    count = std::max(count, connected_size[i]);\n  }\n\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> parent(N, -1);\n    std::vector<int> component(N, 0);\n    int result = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            dfs_visit(A, visited, parent, component, result, i);\n        }\n    }\n    return result;\n}",
            "std::vector<int> dist(N, -1);\n    std::queue<int> q;\n    q.push(0);\n    dist[0] = 0;\n\n    while (!q.empty()) {\n        int i = q.front();\n        q.pop();\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1 && dist[j] == -1) {\n                q.push(j);\n                dist[j] = dist[i] + 1;\n            }\n        }\n    }\n    int maxDist = -1;\n    for (int i = 0; i < dist.size(); ++i) {\n        if (dist[i] > maxDist) {\n            maxDist = dist[i];\n        }\n    }\n    return maxDist + 1;\n}",
            "// TODO: Implement\n\n\t// 1. check for input parameters\n\tif (A.size()!= N*N) {\n\t\tstd::cout << \"Invalid input parameters.\" << std::endl;\n\t\treturn 0;\n\t}\n\t// 2. calculate the size of the largest connected component\n\tstd::vector<int> visited(N,0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A,i,N,visited);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "auto visited = std::vector<bool>(N, false);\n    auto count = std::vector<int>(N, 0);\n    auto res = 0;\n\n    std::function<void(int, int)> dfs = [&dfs, &count, &visited](int i, int p) {\n        if (i >= visited.size()) {\n            return;\n        }\n        if (visited[i]) {\n            return;\n        }\n\n        visited[i] = true;\n        count[i] = 1;\n\n        if (A[i * N + p] == 1) {\n            dfs(i, i);\n        }\n        for (int j = 0; j < N; ++j) {\n            if (A[j * N + i] == 1 && visited[j] == false) {\n                dfs(j, i);\n                count[i] += count[j];\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        if (visited[i] == false) {\n            dfs(i, i);\n            res = std::max(res, count[i]);\n        }\n    }\n\n    return res;\n}",
            "// TODO: Your code goes here\n  return 0;\n}",
            "if (N == 0) {\n    return 0;\n  }\n\n  // Create a map that stores how many vertices are there in each connected component.\n  std::unordered_map<int, int> components;\n  int currComponent = 0;\n\n  for (int i = 0; i < N; ++i) {\n    // Check if we have already encountered this vertex, if so skip it.\n    if (components.find(i)!= components.end()) {\n      continue;\n    }\n\n    // Traverse the vertices connected to i and update the components map\n    std::stack<int> stack{};\n    stack.push(i);\n    components[i] = currComponent;\n\n    while (!stack.empty()) {\n      int v = stack.top();\n      stack.pop();\n\n      for (int j = 0; j < N; ++j) {\n        if (A[v * N + j] == 1) {\n          if (components.find(j) == components.end()) {\n            stack.push(j);\n            components[j] = currComponent;\n          }\n        }\n      }\n    }\n\n    ++currComponent;\n  }\n\n  // Find the largest component.\n  int maxComponent = 0;\n  for (auto const& e : components) {\n    maxComponent = std::max(maxComponent, e.second);\n  }\n\n  // Count the number of vertices in the largest component.\n  int numVertices = 0;\n  for (auto const& e : components) {\n    if (e.second == maxComponent) {\n      ++numVertices;\n    }\n  }\n\n  return numVertices;\n}",
            "std::vector<int> sizes;\n\tsizes.reserve(N);\n\tstd::vector<int> stack;\n\tstd::vector<bool> used(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!used[i]) {\n\t\t\tstack.push_back(i);\n\t\t\tint size = 0;\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tsize++;\n\t\t\t\tint vertex = stack.back();\n\t\t\t\tstack.pop_back();\n\t\t\t\tused[vertex] = true;\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[vertex * N + j] &&!used[j]) {\n\t\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tsizes.push_back(size);\n\t\t}\n\t}\n\tstd::sort(sizes.begin(), sizes.end());\n\treturn sizes.back();\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> graph(N * N, 0);\n\tstd::queue<int> queue;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tgraph[i * N + j] = 1;\n\t\t\t\tgraph[j * N + i] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t// BFS\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tqueue.push(i);\n\t\t\tvisited[i] = 1;\n\n\t\t\twhile (!queue.empty()) {\n\t\t\t\tsize_t u = queue.front();\n\t\t\t\tqueue.pop();\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (graph[u * N + j] && visited[j] == 0) {\n\t\t\t\t\t\tqueue.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint max_comp = 0;\n\tfor (int i : visited) {\n\t\tif (i) ++max_comp;\n\t}\n\n\treturn max_comp;\n}",
            "std::vector<int> visited(N, -1);\n\tstd::queue<int> Q;\n\tint largest_comp = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == -1) {\n\t\t\tQ.push(i);\n\t\t\tvisited[i] = i;\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tint curr = Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[curr*N+j] && visited[j] == -1) {\n\t\t\t\t\t\tvisited[j] = i;\n\t\t\t\t\t\tQ.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tlargest_comp = std::max(largest_comp, visited.size());\n\t\t\tvisited.clear();\n\t\t}\n\t}\n\treturn largest_comp;\n}",
            "std::vector<int> visited(N);\n    int res = 0;\n    for (int i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            res = std::max(res, depthFirstSearch(A, N, i, visited));\n        }\n    }\n    return res;\n}",
            "// Write your code here\n    std::unordered_map<int, std::set<int>> Adj;\n    std::set<int> Visited;\n    int largestComponent = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        std::set<int> temp;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                temp.insert(j);\n            }\n        }\n        Adj[i] = temp;\n    }\n\n    for (size_t i = 0; i < N; i++) {\n        if (Visited.find(i)!= Visited.end()) continue;\n        std::queue<int> Q;\n        Q.push(i);\n        while (!Q.empty()) {\n            int v = Q.front();\n            Q.pop();\n            if (Visited.find(v)!= Visited.end()) continue;\n            Visited.insert(v);\n            for (auto x : Adj[v]) {\n                Q.push(x);\n            }\n        }\n        largestComponent = std::max(largestComponent, static_cast<int>(Visited.size()));\n        Visited.clear();\n    }\n    return largestComponent;\n}",
            "std::vector<int> parents(N, -1);\n    int num_of_components = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (parents[i] == -1) {\n            // If the current element is the parent of itself, then\n            // this is the root of a new component.\n            dfs(A, i, parents);\n            num_of_components++;\n        }\n    }\n\n    return num_of_components;\n}",
            "std::vector<int> colors(N, 0);\n    std::vector<int> count(N, 0);\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                count[colors[i]]++;\n                count[colors[j]]++;\n                colors[i] = colors[j];\n            }\n        }\n    }\n\n    size_t result = 0;\n    for (auto const& v : count) {\n        if (v > result)\n            result = v;\n    }\n    return result;\n}",
            "// Initialize a visited array for the adjacency matrix\n\tstd::vector<bool> visited(N, false);\n\t// Initialize a vector for the nodes in the largest component\n\tstd::vector<size_t> L;\n\t// Start the search from the first node\n\tdfs(A, N, L, visited, 0);\n\n\t// Return the size of the largest component\n\treturn L.size();\n}",
            "std::vector<int> labels;\n  int num_labels = 0;\n  for (int i = 0; i < N; ++i) {\n    if (labels.size() < N) {\n      labels.push_back(i);\n      num_labels++;\n    }\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        int label = find_label(labels, j);\n        merge(labels, i, label);\n      }\n    }\n  }\n  return num_labels;\n}",
            "//...\n}",
            "int result = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::function<void(int)> dfs = [&](int i) {\n\t\tvisited[i] = 1;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1 && visited[j] == 0) {\n\t\t\t\tdfs(j);\n\t\t\t}\n\t\t}\n\t};\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(i);\n\t\t\t++result;\n\t\t}\n\t}\n\treturn result;\n}",
            "// A is a 2D array, a vector of vectors, but we treat it as a single\n\t// dimensional array of size N*N. \n\tint index = 0;\n\n\t// Use the DFS algorithm to find the largest connected component.\n\tstd::vector<bool> vis(N, false);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!vis[i]) {\n\t\t\tvis[i] = true;\n\t\t\tdfs(A, vis, index, i);\n\t\t}\n\t}\n\n\t// Count how many vertices have been visited.\n\tint count = 0;\n\tfor (bool b : vis) {\n\t\tif (b) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::unordered_map<int,int> visited;\n  std::queue<int> q;\n  visited[0] = 1;\n  q.push(0);\n  while(!q.empty()){\n    int curr = q.front();\n    q.pop();\n    for(size_t i = 0; i < N; ++i){\n      if(A[curr*N+i] &&!visited[i]){\n        visited[i] = 1;\n        q.push(i);\n      }\n    }\n  }\n  return visited.size();\n}",
            "std::vector<int> visited(N, 0);\n    int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            dfs(A, i, visited, count);\n        }\n    }\n    return count;\n}",
            "int count = 0;\n    std::vector<bool> visited(N, false);\n    std::function<void(int)> f = [&](int i) -> void {\n        if (visited[i])\n            return;\n        visited[i] = true;\n        ++count;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                f(j);\n            }\n        }\n    };\n    for (int i = 0; i < N; i++) {\n        f(i);\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n    std::vector<std::vector<int>> G(N);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                G[i].push_back(j);\n            }\n        }\n    }\n\n    int ret = 0;\n    int current_component = 1;\n    int start = 0;\n    visited[start] = 1;\n\n    std::function<void(int)> dfs = [&dfs, &G, &visited, &current_component](int v) {\n        for (auto u : G[v]) {\n            if (visited[u] == 0) {\n                visited[u] = 1;\n                ++current_component;\n                dfs(u);\n            }\n        }\n    };\n\n    dfs(start);\n    ret = std::max(ret, current_component);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            current_component = 1;\n            dfs(i);\n            ret = std::max(ret, current_component);\n        }\n    }\n\n    return ret;\n}",
            "std::vector<int> visited(N, 0);\n\tint component = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tcomponent++;\n\t\t\tDFS(i, visited, A, N);\n\t\t}\n\t}\n\n\treturn component;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::queue<int> q;\n\tint ans = 0;\n\n\t// Start from the first index\n\tq.push(0);\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\n\t\tif (visited[v] == 1)\n\t\t\tcontinue;\n\n\t\t// Mark the node visited\n\t\tvisited[v] = 1;\n\n\t\t// Add the adjacent nodes to the queue\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[v * N + i] == 1)\n\t\t\t\tq.push(i);\n\t\t}\n\n\t\tans++;\n\t}\n\n\treturn ans;\n}",
            "if (A.size()!= N * N) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<bool> visited(N, false);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tvisited[i] = true;\n\t\t\tDFS(A, visited, N, i);\n\t\t}\n\t}\n\n\tsize_t size = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\t++size;\n\t\t}\n\t}\n\n\treturn size;\n}",
            "std::vector<bool> visited(N);\n\tint largestComponent = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tif(!visited[i]) {\n\t\t\tdfs(A, N, visited, i);\n\t\t\tlargestComponent++;\n\t\t}\n\t}\n\treturn largestComponent;\n}",
            "// Your code goes here!\n}",
            "std::vector<int> visited(N);\n\tstd::vector<int> stack;\n\tstack.reserve(N);\n\tint i, j;\n\n\tint c = 0;\n\tfor(i = 0; i < N; ++i) {\n\t\tif(visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tstack.push_back(i);\n\t\tvisited[i] = true;\n\t\twhile(!stack.empty()) {\n\t\t\tj = stack.back();\n\t\t\tstack.pop_back();\n\t\t\tif(j < N &&!visited[j]) {\n\t\t\t\tstack.push_back(j);\n\t\t\t\tvisited[j] = true;\n\t\t\t}\n\t\t}\n\t\t++c;\n\t}\n\n\treturn c;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<std::pair<int,int>> edgeList;\n\tstd::queue<int> q;\n\tint currentNode = 0;\n\tint currentComponent = 0;\n\tint maxComponent = 0;\n\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = i; j < N; j++)\n\t\t\tif (i!= j && A[i*N + j] == 1 && A[j*N + i] == 1)\n\t\t\t\tedgeList.push_back(std::pair<int,int>(i,j));\n\n\tif (edgeList.size() == 0) {\n\t\tstd::cout << \"Graph is a single component\" << std::endl;\n\t\treturn N;\n\t}\n\n\tfor (auto iter = edgeList.begin(); iter!= edgeList.end(); iter++) {\n\t\tif (!visited[iter->first]) {\n\t\t\tcurrentComponent++;\n\t\t\tvisited[iter->first] = 1;\n\t\t\tq.push(iter->first);\n\t\t\twhile (!q.empty()) {\n\t\t\t\tcurrentNode = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (A[currentNode*N + i] == 1) {\n\t\t\t\t\t\tif (!visited[i]) {\n\t\t\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\t\t\tq.push(i);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (currentComponent > maxComponent)\n\t\t\tmaxComponent = currentComponent;\n\t\tcurrentComponent = 0;\n\t}\n\n\treturn maxComponent;\n}",
            "// TODO: Fill this in\n    return 0;\n}",
            "std::vector<int> D(N, -1);\n    std::vector<int> color(N, -1);\n    int cnt = 0;\n\n    auto dfs = [&D, &color, &cnt](int i) -> void {\n        color[i] = 1;\n        D[i] = ++cnt;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                if (D[j] == -1) {\n                    dfs(j);\n                } else if (color[j] == 0) {\n                    color[j] = 2;\n                }\n                D[i] = std::min(D[i], D[j]);\n            }\n        }\n        color[i] = 2;\n    };\n\n    for (size_t i = 0; i < N; ++i) {\n        if (D[i] == -1) {\n            dfs(i);\n        }\n    }\n\n    int max = 0;\n    for (auto v : D) {\n        if (v!= -1) {\n            max = std::max(max, v);\n        }\n    }\n    return max;\n}",
            "int count = 0;\n\tint num = 0;\n\t// check which vertices are in the largest component\n\tstd::vector<bool> visited(N, false);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tvisited[i] = true;\n\t\t\tnum++;\n\t\t\tdfs(A, i, N, visited);\n\t\t}\n\t}\n\treturn num;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<std::vector<size_t>> graph(N);\n\tsize_t largest = 1;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\tgraph[i].push_back(j);\n\t\t\t\tgraph[j].push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\tstd::function<void(size_t, size_t)> dfs = [&](size_t node, size_t comp) {\n\t\tvisited[node] = 1;\n\t\tfor (auto const& n : graph[node]) {\n\t\t\tif (!visited[n]) {\n\t\t\t\tdfs(n, comp);\n\t\t\t}\n\t\t}\n\t};\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i, largest);\n\t\t\t++largest;\n\t\t}\n\t}\n\treturn largest - 1;\n}",
            "// write your code here\n\tif (A.empty() || N == 0) {\n\t\treturn 0;\n\t}\n\n\tint i, j;\n\tint visited = 0;\n\tint count = 0;\n\tint index = 0;\n\tstd::vector<int> visit;\n\tfor (i = 0; i < N; i++) {\n\t\tvisit.push_back(0);\n\t}\n\n\tfor (i = 0; i < N; i++) {\n\t\tif (!visit[i]) {\n\t\t\tdfs(A, i, i, 0, visited, count, index, visit);\n\t\t\tif (count < visited) {\n\t\t\t\tcount = visited;\n\t\t\t\tindex = i;\n\t\t\t}\n\t\t\tvisited = 0;\n\t\t}\n\t}\n\tif (visit[index]) {\n\t\tdfs(A, index, index, 0, visited, count, index, visit);\n\t\tif (count < visited) {\n\t\t\tcount = visited;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "size_t numConnectedComponents = 0;\n    std::vector<bool> marked(N, false);\n    for (size_t i = 0; i < N; ++i) {\n        if (!marked[i]) {\n            numConnectedComponents++;\n            marked[i] = true;\n            std::queue<size_t> q;\n            q.push(i);\n            while (!q.empty()) {\n                size_t v = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[i * N + j] == 1 &&!marked[j]) {\n                        q.push(j);\n                        marked[j] = true;\n                    }\n                }\n            }\n        }\n    }\n    return numConnectedComponents;\n}",
            "return largestComponent(A.data(), N);\n}",
            "std::vector<bool> visited(N, false);\n\tint largest = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tsize_t component = 0;\n\t\tstd::queue<size_t> q;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tsize_t idx = q.front();\n\t\t\tq.pop();\n\t\t\tif (visited[idx]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tvisited[idx] = true;\n\t\t\t++component;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[idx * N + j] &&!visited[j]) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tlargest = std::max(largest, component);\n\t}\n\treturn largest;\n}",
            "int num_vertices = 0;\n\tint largest_component_size = 0;\n\t\n\t// BFS through each vertex in the graph\n\tfor (int vertex = 0; vertex < N; vertex++) {\n\t\tstd::vector<bool> visited(N, false);\n\t\tstd::queue<int> q;\n\t\t\n\t\t// Add current vertex to queue\n\t\tq.push(vertex);\n\t\tvisited[vertex] = true;\n\t\t\n\t\t// BFS through the graph and count the vertices in each connected component\n\t\twhile (!q.empty()) {\n\t\t\tint curr_vertex = q.front();\n\t\t\tq.pop();\n\t\t\t\n\t\t\t// Only count the vertex if it is not already visited\n\t\t\tif (visited[curr_vertex] == false) {\n\t\t\t\tnum_vertices++;\n\t\t\t\tvisited[curr_vertex] = true;\n\t\t\t}\n\t\t\t\n\t\t\t// Add adjacent vertices to queue\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[curr_vertex * N + i] == 1 && visited[i] == false) {\n\t\t\t\t\tq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// If the current component size is greater than the largest component size,\n\t\t// then store the current component size as the largest component size\n\t\tif (num_vertices > largest_component_size) {\n\t\t\tlargest_component_size = num_vertices;\n\t\t}\n\t\t\n\t\t// Reset vertex count\n\t\tnum_vertices = 0;\n\t}\n\t\n\treturn largest_component_size;\n}",
            "std::vector<bool> visited(N);\n    std::queue<size_t> q;\n    size_t maxComponent = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] || A[i] == 0) {\n            continue;\n        }\n\n        q.push(i);\n        size_t component = 1;\n\n        while (!q.empty()) {\n            size_t index = q.front();\n            q.pop();\n\n            if (visited[index]) {\n                continue;\n            }\n\n            visited[index] = true;\n\n            for (size_t j = 0; j < N; ++j) {\n                if (A[index] & (1 << j)) {\n                    q.push(j);\n                }\n            }\n\n            ++component;\n        }\n\n        maxComponent = std::max(maxComponent, component);\n    }\n\n    return maxComponent;\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> components;\n    // start from the first vertex, find all vertices in the largest component\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            std::vector<int> component;\n            dfs(A, i, visited, component);\n            components.push_back(component.size());\n        }\n    }\n    // return the size of the largest component\n    return *std::max_element(components.begin(), components.end());\n}",
            "std::vector<int> visited(N, 0);\n    std::queue<int> Q;\n    std::vector<int> count(N, 0);\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            visited[i] = 1;\n            Q.push(i);\n            count[i] = 1;\n            while (!Q.empty()) {\n                int v = Q.front();\n                Q.pop();\n                for (size_t j = 0; j < N; j++) {\n                    if (A[v * N + j] &&!visited[j]) {\n                        visited[j] = 1;\n                        count[i]++;\n                        Q.push(j);\n                    }\n                }\n            }\n        }\n    }\n    int max = 0;\n    for (int i : count) {\n        if (i > max) {\n            max = i;\n        }\n    }\n    return max;\n}",
            "std::vector<bool> visited(N, false);\n\n\tstd::function<void(int)> dfs = [&](int const i) {\n\t\tvisited[i] = true;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1 &&!visited[j]) {\n\t\t\t\tdfs(j);\n\t\t\t}\n\t\t}\n\t};\n\n\tint largest_component = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i);\n\t\t\t++largest_component;\n\t\t}\n\t}\n\treturn largest_component;\n}",
            "std::vector<int> color(N, 0);\n    std::vector<std::vector<int>> adj(N);\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i!= j && A[N * i + j]) {\n                adj[i].push_back(j);\n            }\n        }\n    }\n\n    int counter = 0;\n    int largest = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!color[i]) {\n            color[i] = 1;\n            counter++;\n            largest = std::max(largest, count_component(color, adj[i], 1));\n        }\n    }\n    return largest;\n}",
            "// Fill code here.\n}",
            "std::vector<int> visited(N, 0);\n  std::queue<int> q;\n  int count = 0;\n  int current;\n\n  for (int i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      ++count;\n      visited[i] = 1;\n      q.push(i);\n\n      while (!q.empty()) {\n        current = q.front();\n        q.pop();\n\n        for (int j = 0; j < N; ++j) {\n          if (A[current * N + j] == 1 && visited[j] == 0) {\n            visited[j] = 1;\n            q.push(j);\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> V = { 0 };\n\n  for (size_t i = 1; i < N; i++) {\n    if (A[i * N + i]!= 0) {\n      V.push_back(i);\n    }\n  }\n\n  std::sort(V.begin(), V.end());\n\n  std::vector<int> next(N, -1);\n  std::vector<bool> used(N, false);\n\n  int count = 0;\n  for (size_t i = 0; i < V.size(); i++) {\n    if (!used[V[i]]) {\n      used[V[i]] = true;\n      count++;\n      for (size_t j = i + 1; j < V.size() && V[j] < N; j++) {\n        if (A[V[i] * N + V[j]]!= 0) {\n          next[V[j]] = V[i];\n        }\n      }\n    }\n  }\n\n  for (size_t i = 0; i < V.size(); i++) {\n    if (!used[V[i]] && next[V[i]] == -1) {\n      used[V[i]] = true;\n      count++;\n      for (size_t j = i + 1; j < V.size() && V[j] < N; j++) {\n        if (A[V[i] * N + V[j]]!= 0) {\n          next[V[j]] = V[i];\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "//\n    // Checking if N < 0\n    if (N < 0) return -1;\n\n    //\n    // Checking if N == 0\n    if (N == 0) return 0;\n\n    //\n    // Checking if N == 1\n    if (N == 1) {\n        if (A[0] == 0) return 0;\n        return 1;\n    }\n\n    //\n    // Checking if N == 2\n    if (N == 2) {\n        if (A[0] == 0 || A[1] == 0) return 1;\n        return 2;\n    }\n\n    //\n    // Main function\n    int ans = 0;\n    std::vector<bool> visited(N);\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == false) {\n            std::queue<size_t> q;\n            q.push(i);\n            visited[i] = true;\n            while (not q.empty()) {\n                size_t size = q.size();\n                for (size_t i = 0; i < size; ++i) {\n                    auto x = q.front();\n                    q.pop();\n                    for (size_t j = 0; j < N; ++j) {\n                        if (visited[j] == false and A[x * N + j] > 0) {\n                            q.push(j);\n                            visited[j] = true;\n                        }\n                    }\n                }\n            }\n            ++ans;\n        }\n    }\n\n    return ans;\n}",
            "// TODO\n}",
            "if (A.empty()) return 0;\n  std::vector<int> labels(N, 0);\n  size_t count = 1;\n\n  auto recur = [&](size_t node, size_t label) {\n    labels[node] = label;\n    for (size_t i = 0; i < N; ++i) {\n      if (A[node * N + i] && labels[i] == 0) {\n        recur(i, label);\n      }\n    }\n  };\n\n  // Start from node 0, and find the largest component.\n  // Note: this could be optimized to start from the first 1 and find the largest.\n  for (size_t i = 0; i < N; ++i) {\n    if (labels[i] == 0) {\n      recur(i, count);\n      ++count;\n    }\n  }\n\n  return count - 1;\n}",
            "int result = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::queue<int> q;\n\n\t// Find the first node not visited and add it to the queue.\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i] && A[i * N + i] == 1) {\n\t\t\tvisited[i] = true;\n\t\t\tq.push(i);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Start searching for connections.\n\twhile (q.size() > 0) {\n\t\tint node = q.front();\n\t\tq.pop();\n\t\tresult++;\n\n\t\t// For each node connected to the current node.\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t// If the current node is connected to a node not yet visited, add it to the queue.\n\t\t\tif (A[node * N + i] == 1 &&!visited[i]) {\n\t\t\t\tvisited[i] = true;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "std::vector<int> visited(N, 0);\n\n\tauto dfs = [&A, &visited, N](int v) {\n\t\tvisited[v] = 1;\n\t\tfor (auto i = 0u; i < N; ++i) {\n\t\t\tif (!visited[i] && A[v * N + i]) {\n\t\t\t\tdfs(i);\n\t\t\t}\n\t\t}\n\t};\n\n\tint result = 0;\n\tfor (auto i = 0u; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i);\n\t\t\tresult++;\n\t\t}\n\t}\n\n\treturn result;\n}",
            "const size_t N2 = N * N;\n\n\tstd::vector<int> C(N2);\n\tfor (size_t i = 0; i < N2; ++i)\n\t\tC[i] = i;\n\n\tsize_t largest_component_size = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\tunion_find(C, i * N + j);\n\t\t\t\tunion_find(C, i * N + j + 1);\n\t\t\t\tunion_find(C, (i + 1) * N + j);\n\t\t\t\tunion_find(C, (i + 1) * N + j + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::unordered_map<int, int> component_sizes;\n\tfor (size_t i = 0; i < N2; ++i) {\n\t\tint parent = find(C, i);\n\t\t++component_sizes[parent];\n\t}\n\n\tfor (auto& cs : component_sizes)\n\t\tlargest_component_size = std::max(largest_component_size, cs.second);\n\n\treturn largest_component_size;\n}",
            "auto adj_list = toAdjList(A, N);\n\tstd::vector<int> order;\n\n\t// 1. Find a topological ordering of the vertices.\n\t{\n\t\tstd::unordered_set<int> visited;\n\t\tvisited.reserve(N);\n\t\tstd::vector<int> stack;\n\t\tstack.reserve(N);\n\t\t// Use a recursive function to find a topological ordering.\n\t\t// The order will be stored in the given vector.\n\t\tauto findOrdering = [&visited, &stack, &order, &adj_list](int vertex) -> void {\n\t\t\tif (visited.contains(vertex)) { return; }\n\t\t\tvisited.insert(vertex);\n\t\t\tfor (auto neighbor : adj_list[vertex]) {\n\t\t\t\tfindOrdering(neighbor);\n\t\t\t}\n\t\t\tstack.push_back(vertex);\n\t\t};\n\t\tfor (auto vertex : adj_list) {\n\t\t\tfindOrdering(vertex.first);\n\t\t}\n\t\tstd::copy(stack.rbegin(), stack.rend(), std::back_inserter(order));\n\t}\n\n\t// 2. Find the largest component by removing all vertices that are not in the largest component.\n\tstd::unordered_set<int> largest;\n\tlargest.reserve(N);\n\tauto findLargest = [&largest, &order](int vertex) -> void {\n\t\tif (largest.contains(vertex)) { return; }\n\t\tlargest.insert(vertex);\n\t\tfor (auto neighbor : adj_list[vertex]) {\n\t\t\tfindLargest(neighbor);\n\t\t}\n\t};\n\tfindLargest(order[0]);\n\n\treturn largest.size();\n}",
            "if (A.empty() || A.size()!= N*N) {\n\t\tthrow std::invalid_argument(\"Invalid input\");\n\t}\n\n\tint numOfComponents = 0;\n\tstd::vector<int> seen(N, 0);\n\n\tstd::function<void(int)> traverse = [&](int i) {\n\t\tseen[i] = 1;\n\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] &&!seen[j]) {\n\t\t\t\ttraverse(j);\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (seen[i] == 0) {\n\t\t\ttraverse(i);\n\t\t\t++numOfComponents;\n\t\t}\n\t}\n\n\treturn numOfComponents;\n}",
            "/*\n   * 1. Store the nodes in an adjacency list, in an unordered_map.\n   * 2. Create a queue and push the nodes in the first column of the adjacency matrix into it.\n   * 3. Create a set to store the nodes that have already been visited.\n   * 4. While there are nodes in the queue, pop a node and see if it is in the visited set.\n   *    If yes, skip it. If no, add it to the visited set.\n   *    For each node in the first column, check if it has an edge to the rest of the rows. If yes,\n   *    add the nodes from the rest of the rows into the queue.\n   * 5. The final count is the size of the visited set.\n   */\n  auto adj_list = create_adjacency_list(A, N);\n  std::queue<int> nodes_to_visit;\n  for (int i = 0; i < N; i++) {\n    if (A[i * N + i] == 1) {\n      nodes_to_visit.push(i);\n    }\n  }\n  std::unordered_set<int> visited;\n  while (!nodes_to_visit.empty()) {\n    int node = nodes_to_visit.front();\n    nodes_to_visit.pop();\n    if (visited.find(node)!= visited.end()) {\n      continue;\n    }\n    visited.insert(node);\n    auto it = adj_list.find(node);\n    if (it!= adj_list.end()) {\n      for (auto const& other : it->second) {\n        nodes_to_visit.push(other);\n      }\n    }\n  }\n  return visited.size();\n}",
            "// Your code here\n\tint result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tstd::vector<bool> visited(N);\n\t\tbfs(A, visited, i, N);\n\t\tresult = std::max(result, countComponent(visited, N));\n\t}\n\treturn result;\n}",
            "std::vector<int> D(N, -1);\n\tint max_size = 0;\n\tstd::function<void(int)> dfs = [&A, &D, &dfs](int u) {\n\t\tD[u] = 1;\n\t\tfor (size_t v = 0; v < N; ++v)\n\t\t\tif (A[u * N + v] && D[v] == -1)\n\t\t\t\tdfs(v);\n\t};\n\tfor (size_t v = 0; v < N; ++v)\n\t\tif (D[v] == -1) {\n\t\t\tdfs(v);\n\t\t\tmax_size = std::max(max_size,\n\t\t\t\t\tstatic_cast<int>(std::count(D.begin(), D.end(), 1)));\n\t\t}\n\treturn max_size;\n}",
            "std::vector<int> color;\n\tint max_color{0};\n\tfor (int i = 0; i < N; i++) {\n\t\t// color each vertex\n\t\t// coloring each vertex\n\t\t// at the beginning, all vertices are unvisited (marked as -1)\n\t\tcolor.push_back(-1);\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\t// if the vertex i is connected to the vertex j\n\t\t\t// it means that we have a path between the two\n\t\t\tif (A[i*N + j]) {\n\t\t\t\t// if the vertex j has a color\n\t\t\t\tif (color[j]!= -1) {\n\t\t\t\t\t// check the color of the vertex j\n\t\t\t\t\tif (color[j] > max_color) {\n\t\t\t\t\t\t// if the color of the vertex j is higher than the current maximum\n\t\t\t\t\t\t// it means that we have a path between the vertex i and the vertex j\n\t\t\t\t\t\t// and we need to recolor the vertex i with the color of the vertex j\n\t\t\t\t\t\tcolor[i] = color[j];\n\t\t\t\t\t}\n\t\t\t\t\telse if (color[j] < max_color) {\n\t\t\t\t\t\t// if the color of the vertex j is lower than the current maximum\n\t\t\t\t\t\t// it means that we have a path between the vertex j and the vertex i\n\t\t\t\t\t\t// and we need to recolor the vertex j with the color of the vertex i\n\t\t\t\t\t\tcolor[j] = color[i];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t// if the vertex j does not have a color\n\t\t\t\t\t// it means that we have a path between the vertex i and the vertex j\n\t\t\t\t\t// and we need to recolor the vertex j with the color of the vertex i\n\t\t\t\t\tcolor[j] = color[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (color[i] == -1) {\n\t\t\t// if the vertex i does not have a color, it means that we cannot reach it\n\t\t\t// from any other vertex\n\t\t\t// and we need to recolor the vertex i with the current maximum + 1\n\t\t\tcolor[i] = max_color + 1;\n\t\t}\n\t\t// we need to save the current maximum color\n\t\tif (max_color < color[i]) {\n\t\t\tmax_color = color[i];\n\t\t}\n\t}\n\t// if we cannot reach some vertex from any other vertex,\n\t// the number of vertices in the largest component is N - number of vertices unreachable\n\treturn N - std::count(color.begin(), color.end(), -1);\n}",
            "// TODO\n    std::vector<bool> isVisited(N, false);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!isVisited[i]) {\n            std::vector<int> stack;\n            stack.push_back(i);\n            isVisited[i] = true;\n\n            while (!stack.empty()) {\n                auto u = stack.back();\n                stack.pop_back();\n\n                for (size_t v = 0; v < N; ++v) {\n                    if (A[u * N + v] == 1 &&!isVisited[v]) {\n                        stack.push_back(v);\n                        isVisited[v] = true;\n                    }\n                }\n            }\n        }\n    }\n\n    int count = 0;\n\n    for (bool v : isVisited) {\n        if (v) {\n            ++count;\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> components(N, -1);\n\tstd::vector<std::vector<size_t>> adjacency(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tadjacency[i].push_back(j);\n\t\t\t\tadjacency[j].push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\n\tsize_t largest = 0;\n\tsize_t largestComponentId = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (components[i] == -1) {\n\t\t\tstd::vector<size_t> queue;\n\t\t\tqueue.push_back(i);\n\n\t\t\tsize_t id = 0;\n\n\t\t\twhile (not queue.empty()) {\n\t\t\t\tsize_t const v = queue.back();\n\t\t\t\tqueue.pop_back();\n\n\t\t\t\tif (components[v] == -1) {\n\t\t\t\t\tcomponents[v] = id;\n\n\t\t\t\t\tfor (size_t const u : adjacency[v]) {\n\t\t\t\t\t\tif (components[u] == -1) {\n\t\t\t\t\t\t\tqueue.push_back(u);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (id > largest) {\n\t\t\t\tlargest = id;\n\t\t\t\tlargestComponentId = i;\n\t\t\t}\n\t\t}\n\t}\n\n\tsize_t largestComponent = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (components[i] == largestComponentId) {\n\t\t\tlargestComponent++;\n\t\t}\n\t}\n\n\treturn largestComponent;\n}",
            "std::vector<bool> visited(N);\n\tstd::vector<bool> not_visited(N);\n\n\tint components = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (not_visited[i]) {\n\t\t\tcomponents++;\n\t\t\tvisited[i] = true;\n\t\t\tDFS(A, i, visited, not_visited);\n\t\t}\n\t}\n\n\treturn components;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::stack<size_t> nodesToVisit;\n\n\tstd::function<void(size_t)> search = [&A, &visited, &nodesToVisit, &search](size_t node) {\n\t\tvisited[node] = true;\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[node * N + i]!= 0 &&!visited[i]) {\n\t\t\t\tsearch(i);\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tnodesToVisit.push(i);\n\t\t\tsearch(i);\n\t\t}\n\t}\n\n\treturn nodesToVisit.size();\n}",
            "int res = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\n\t\tstd::vector<int> stk;\n\t\tstk.push_back(i);\n\t\tvisited[i] = true;\n\n\t\twhile (!stk.empty()) {\n\t\t\tint j = stk.back();\n\t\t\tstk.pop_back();\n\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (A[j*N + k] &&!visited[k]) {\n\t\t\t\t\tstk.push_back(k);\n\t\t\t\t\tvisited[k] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tres = std::max(res, (int)visited.size());\n\t}\n\n\treturn res;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<size_t> connected(N, 0);\n\tsize_t n = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++n;\n\t\t\tDFS(A, N, i, visited, connected);\n\t\t}\n\t}\n\tstd::sort(connected.begin(), connected.end());\n\treturn connected.back();\n}",
            "// This is where your code goes.\n  return 0;\n}",
            "std::vector<int> result(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (result[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint node = q.front();\n\t\t\tq.pop();\n\t\t\tif (result[node]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tresult[node] = 1;\n\t\t\t++count;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[N * node + j]) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n    int maxCount = 0;\n    int currCount = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        currCount = 0;\n        dfs(i, A, visited, N, currCount);\n        maxCount = std::max(maxCount, currCount);\n    }\n    return maxCount;\n}",
            "// Return the number of vertices in the largest component of the graph\n    // defined by the adjacency matrix A.\n    //\n    // Example:\n    //\n    //   Input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n    //   Output: 2\n    //\n\n    if (N == 0) {\n        return 0;\n    }\n\n    int count = 0;\n    std::unordered_map<int, int> parents;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (parents.count(i) == 0) {\n            ++count;\n            parents[i] = i;\n            for (size_t j = i + 1; j < N; ++j) {\n                if (A[i * N + j] == 1) {\n                    parents[j] = i;\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "//...\n}",
            "std::vector<bool> visited(N);\n    std::queue<int> Q;\n    size_t res = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            visited[i] = true;\n            Q.push(i);\n            ++res;\n            while (!Q.empty()) {\n                int u = Q.front();\n                Q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (!visited[j] && A[u * N + j]!= 0) {\n                        visited[j] = true;\n                        Q.push(j);\n                    }\n                }\n            }\n        }\n    }\n    return res;\n}",
            "// Write your code here\n\tstd::vector<bool> visited(N, false);\n\tstd::queue<int> q;\n\tint components = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\t++components;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tauto curr = q.front();\n\t\t\tq.pop();\n\t\t\tvisited[curr] = true;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[curr * N + j] == 0 || visited[j]) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tq.push(j);\n\t\t\t}\n\t\t}\n\t}\n\treturn components;\n}",
            "std::vector<int> D;\n    D.reserve(N);\n    std::iota(std::back_inserter(D), 0);\n    std::vector<std::pair<int, int>> edges;\n    for (int i = 0; i < N; i++)\n        for (int j = 0; j < N; j++)\n            if (A[i * N + j]!= 0) {\n                edges.emplace_back(i, j);\n            }\n    std::sort(std::begin(edges), std::end(edges), [&A](auto const& a, auto const& b) {\n        return A[a.first * N + a.second] < A[b.first * N + b.second];\n    });\n\n    for (auto const& [src, dest] : edges) {\n        auto p_src = std::find(std::begin(D), std::end(D), src);\n        auto p_dest = std::find(std::begin(D), std::end(D), dest);\n        auto p_src_parent = std::find_if(std::begin(D), std::end(D), [&p_src](auto const& d) { return d == *p_src; });\n        auto p_dest_parent = std::find_if(std::begin(D), std::end(D), [&p_dest](auto const& d) { return d == *p_dest; });\n        auto p_src_parent_root = std::find_if(std::begin(D), std::end(D), [&p_src_parent](auto const& d) {\n            return d == *p_src_parent;\n        });\n        auto p_dest_parent_root = std::find_if(std::begin(D), std::end(D), [&p_dest_parent](auto const& d) {\n            return d == *p_dest_parent;\n        });\n        if (p_src_parent_root == p_dest_parent_root) {\n            if (p_src_parent > p_dest_parent) {\n                auto tmp = *p_dest_parent;\n                *p_dest_parent = *p_src_parent;\n                *p_src_parent = tmp;\n            }\n            continue;\n        }\n        *p_dest_parent = *p_src_parent;\n        *p_src_parent = *p_dest_parent;\n    }\n\n    return std::distance(std::adjacent_find(std::begin(D), std::end(D)), std::end(D));\n}",
            "if (A.size()!= N * N)\n    return -1;\n\n  // Construct an adjacency list representation of the graph.\n  std::vector<std::vector<size_t>> adjList(N);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        adjList[i].push_back(j);\n      }\n    }\n  }\n\n  // Traverse the graph to find the number of components in the graph.\n  std::vector<bool> visited(N, false);\n  size_t connectedComponents = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      size_t connectedVertices = 0;\n      std::function<void(size_t)> dfs = [&](size_t v) {\n        visited[v] = true;\n        ++connectedVertices;\n        for (size_t w : adjList[v]) {\n          if (!visited[w]) {\n            dfs(w);\n          }\n        }\n      };\n      dfs(i);\n      connectedComponents += connectedVertices;\n    }\n  }\n  return connectedComponents;\n}",
            "std::vector<int> component(N, 0);\n\tcomponent[0] = 1;\n\tfor (size_t i = 1; i < N; ++i)\n\t\tfor (size_t j = 0; j < i; ++j)\n\t\t\tif (A[i * N + j])\n\t\t\t\tcomponent[i] = component[j];\n\tstd::vector<int> componentSizes(N, 0);\n\tfor (size_t i = 0; i < N; ++i)\n\t\t++componentSizes[component[i]];\n\tint maxComponentSize = *std::max_element(componentSizes.begin(), componentSizes.end());\n\treturn maxComponentSize;\n}",
            "std::vector<int> mark(N, 0);\n\tint maxMark = 0;\n\tint maxMarked = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (mark[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tint currMark = 0;\n\t\t++currMark;\n\t\tmark[i] = currMark;\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint top = q.front();\n\t\t\tq.pop();\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[top * N + j] == 1 && mark[j]!= currMark) {\n\t\t\t\t\t++currMark;\n\t\t\t\t\tmark[j] = currMark;\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (maxMark <= currMark) {\n\t\t\tmaxMark = currMark;\n\t\t\tmaxMarked = i;\n\t\t}\n\t}\n\n\treturn maxMark;\n}",
            "// your code goes here\n\t// The graph must be undirected and only contain 1s and 0s.\n\tif (A.size()!= N * N) {\n\t\tthrow std::invalid_argument(\"The matrix is not square.\");\n\t}\n\tstd::vector<int> B = A;\n\tstd::vector<int> DFS(N, 0);\n\tstd::vector<int> DFS_R(N, 0);\n\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (DFS[i] == 0) {\n\t\t\tDFS_Helper(B, N, DFS, DFS_R, i, 0);\n\t\t\tmax = std::max(max, CountConnected(DFS, N));\n\t\t}\n\t}\n\n\treturn max;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\tstd::vector<int> mark(N);\n\tint max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (mark[i] == 0) {\n\t\t\tint count = 0;\n\t\t\tdfs(A, N, i, mark, count);\n\t\t\tif (count > max) {\n\t\t\t\tmax = count;\n\t\t\t}\n\t\t}\n\t}\n\treturn max;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::queue<int> q;\n\tint largest_component_size = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tq.push(i);\n\n\t\t\twhile (q.size()) {\n\t\t\t\tint u = q.front();\n\t\t\t\tvisited[u] = 1;\n\t\t\t\tq.pop();\n\n\t\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\t\tif (A[N * u + v] == 1 && visited[v] == 0)\n\t\t\t\t\t\tq.push(v);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (largest_component_size < count(visited.begin(), visited.end(), 1))\n\t\t\t\tlargest_component_size = count(visited.begin(), visited.end(), 1);\n\t\t}\n\t}\n\n\treturn largest_component_size;\n}",
            "std::vector<bool> visited(N, false);\n\tint res = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++res;\n\t\t\tdfs(A, N, visited, i);\n\t\t}\n\t}\n\n\treturn res;\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> component_size(N);\n\n    for (size_t i = 0; i < N; ++i) {\n        dfs(A, i, visited, component_size);\n    }\n    return *std::max_element(component_size.begin(), component_size.end());\n}",
            "std::vector<int> component_sizes(N, 1);\n    for(int row = 0; row < N; ++row) {\n        for(int col = 0; col < N; ++col) {\n            if(A[row * N + col] == 1) {\n                if(component_sizes[row] > component_sizes[col]) {\n                    component_sizes[col] = component_sizes[row];\n                } else {\n                    component_sizes[row] = component_sizes[col];\n                }\n            }\n        }\n    }\n    int max_component_size = 0;\n    for(int i = 0; i < N; ++i) {\n        if(component_sizes[i] > max_component_size) {\n            max_component_size = component_sizes[i];\n        }\n    }\n    return max_component_size;\n}",
            "std::vector<int> visited(N);\n    std::queue<int> queue;\n    int largest = 0;\n\n    for(size_t i=0; i<N; ++i) {\n        if(!visited[i]) {\n            queue.push(i);\n            while(!queue.empty()) {\n                auto current = queue.front();\n                queue.pop();\n                visited[current] = 1;\n                largest++;\n                for(size_t j=0; j<N; ++j) {\n                    if(A[current*N + j] &&!visited[j]) {\n                        queue.push(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return largest;\n}",
            "auto isConnected = [&A, N](int const &i, int const &j) {\n\t\treturn A[i * N + j] == 1;\n\t};\n\n\tauto connectedComponents = [&isConnected, N](int &i, std::vector<int> &visited) {\n\t\tif (visited[i]) {\n\t\t\treturn;\n\t\t}\n\t\tvisited[i] = true;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (isConnected(i, j)) {\n\t\t\t\tconnectedComponents(j, visited);\n\t\t\t}\n\t\t}\n\t};\n\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tconnectedComponents(i, visited);\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// TODO: implement\n\tstd::vector<int> adjacencyMatrix = A;\n\tstd::vector<int> visited(N, 0);\n\tint counter = 0;\n\n\tfor (int i = 0; i < adjacencyMatrix.size(); i++) {\n\t\tif (adjacencyMatrix[i]!= 0 && visited[i] == 0) {\n\t\t\tDFS(adjacencyMatrix, i, visited);\n\t\t\tcounter++;\n\t\t}\n\t}\n\n\treturn counter;\n}",
            "std::vector<int> vertices(N, 0);\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (vertices[i] == 0) {\n            ++count;\n            dfs(A, vertices, i);\n        }\n    }\n    return count;\n}",
            "// your code here\n\tstd::vector<int> visited(N,0);\n\tint max_component=0;\n\tfor(int i=0;i<N;i++){\n\t\tif(visited[i]==0){\n\t\t\tint component=dfs(A,visited,i);\n\t\t\tmax_component=std::max(component,max_component);\n\t\t}\n\t}\n\treturn max_component;\n}",
            "std::vector<int> visited(N, 0);\n  int max_com = 0;\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n    dfs(A, N, visited, i, max_com);\n  }\n  return max_com;\n}",
            "std::unordered_map<int, std::vector<int>> graph;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tgraph[i] = std::vector<int>();\n\t}\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tgraph[i].push_back(j);\n\t\t\t}\n\t\t}\n\t}\n\tint componentCount = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::function<void(int)> dfs = [&graph, &visited, &dfs, &componentCount](int vertex) {\n\t\tvisited[vertex] = 1;\n\t\tfor (int neighbor : graph[vertex]) {\n\t\t\tif (!visited[neighbor]) {\n\t\t\t\tdfs(neighbor);\n\t\t\t}\n\t\t}\n\t\tcomponentCount++;\n\t};\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i);\n\t\t}\n\t}\n\treturn componentCount;\n}",
            "//...\n\n    // Find number of connected components\n    std::vector<bool> visited(N, false);\n    int num_components = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i]) continue;\n\n        std::queue<int> Q;\n        Q.push(i);\n\n        while (!Q.empty()) {\n            int curr = Q.front();\n            Q.pop();\n\n            if (visited[curr]) continue;\n            visited[curr] = true;\n            for (size_t j = 0; j < N; j++) {\n                if (A[curr * N + j] &&!visited[j]) Q.push(j);\n            }\n        }\n\n        num_components++;\n    }\n\n    return num_components;\n}",
            "std::vector<bool> visited(N, false);\n    std::queue<size_t> q;\n    size_t components = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            q.push(i);\n            ++components;\n            while (!q.empty()) {\n                size_t v = q.front();\n                q.pop();\n                for (size_t u = 0; u < N; ++u) {\n                    if (!visited[u] && A[v * N + u]) {\n                        q.push(u);\n                        visited[u] = true;\n                    }\n                }\n            }\n        }\n    }\n    return components;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::stack<int> nodes;\n\tnodes.push(0);\n\n\twhile (!nodes.empty()) {\n\t\tint node = nodes.top();\n\t\tnodes.pop();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node * N + i] &&!visited[i]) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tnodes.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor (int v : visited) {\n\t\tif (v) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int result = 0;\n  if (N > 0) {\n    std::vector<int> visited(N, 0);\n    dfs(visited, A, 0, 0, N);\n    result = std::count(visited.begin(), visited.end(), 1);\n  }\n  return result;\n}",
            "// TODO: insert implementation\n    return 0;\n}",
            "return largestComponent(A, N, 0, N - 1, 0);\n}",
            "// Create a vector of N bool values for the connected component\n\tstd::vector<bool> connected(N, false);\n\t// For each vertex\n\tfor(int i = 0; i < N; i++){\n\t\t// If the vertex is not part of a connected component\n\t\tif(!connected[i]){\n\t\t\t// Do a BFS on the graph starting at the vertex\n\t\t\tbfs(A, connected, i);\n\t\t}\n\t}\n\t// Return the number of vertices in the connected component\n\tint connected_count = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tif(connected[i])\n\t\t\tconnected_count++;\n\t}\n\treturn connected_count;\n}",
            "std::vector<bool> visited(N, false);\n\tint max_size = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tint size = 0;\n\t\tstd::stack<int> s;\n\t\ts.push(i);\n\t\twhile (!s.empty()) {\n\t\t\tint u = s.top();\n\t\t\ts.pop();\n\t\t\tif (visited[u]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tsize++;\n\t\t\tvisited[u] = true;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[u * N + j]) {\n\t\t\t\t\ts.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmax_size = std::max(max_size, size);\n\t}\n\n\treturn max_size;\n}",
            "std::vector<int> reachable(N, 0);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1 && reachable[i] == 0) {\n                int count = 0;\n                std::queue<int> q;\n                q.push(i);\n                reachable[i] = 1;\n                ++count;\n                while (!q.empty()) {\n                    int curr = q.front();\n                    q.pop();\n                    for (int j = 0; j < N; ++j) {\n                        if (A[curr * N + j] == 1 && reachable[j] == 0) {\n                            q.push(j);\n                            reachable[j] = 1;\n                            ++count;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    int max_count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        max_count = std::max(max_count, reachable[i]);\n    }\n    return max_count;\n}",
            "std::vector<int> V(N, 1);\n\tstd::vector<int> W(N, 1);\n\tstd::vector<int> VW(N, 1);\n\tstd::vector<int> C(N, 0);\n\tstd::vector<int> C1(N, 1);\n\n\tint count = 1;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tV[i] = std::max(V[i], C1[j]);\n\t\t\t\tW[j] = std::max(W[j], C1[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tVW[i] = std::max(VW[i], V[j] + W[j]);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (VW[i] == count) {\n\t\t\tC[i] = count;\n\t\t}\n\t\telse {\n\t\t\tcount++;\n\t\t\tC[i] = count;\n\t\t}\n\t}\n\n\tint max_component = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tmax_component = std::max(max_component, C[i]);\n\t}\n\n\treturn max_component;\n}",
            "// Write your code here\n    std::vector<bool> visited(N);\n    int comp_size = 0;\n\n    for (int i = 0; i < N; i++) {\n        if (visited[i]) {\n            continue;\n        }\n\n        comp_size = 0;\n        std::queue<int> queue;\n        queue.push(i);\n        visited[i] = true;\n\n        while (!queue.empty()) {\n            int node = queue.front();\n            queue.pop();\n\n            for (int j = 0; j < N; j++) {\n                if (A[node * N + j] == 1 &&!visited[j]) {\n                    queue.push(j);\n                    visited[j] = true;\n                }\n            }\n            comp_size++;\n        }\n\n        if (comp_size > comp_size) {\n            comp_size = comp_size;\n        }\n    }\n\n    return comp_size;\n}",
            "// TODO: insert your code here\n    std::vector<bool> visited(N, false);\n    std::queue<int> bfsQueue;\n    bfsQueue.push(0);\n    int largestComponent = 0;\n    while(!bfsQueue.empty()) {\n        int currentVertex = bfsQueue.front();\n        bfsQueue.pop();\n        visited[currentVertex] = true;\n        largestComponent++;\n        for(int i = 0; i < N; i++) {\n            if(A[currentVertex * N + i] == 1 &&!visited[i]) {\n                bfsQueue.push(i);\n            }\n        }\n    }\n    return largestComponent;\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> components(N, -1);\n    std::stack<int> toVisit;\n\n    // Find first component\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i]) {\n            continue;\n        }\n        toVisit.push(i);\n\n        while (!toVisit.empty()) {\n            int const cur = toVisit.top();\n            toVisit.pop();\n\n            if (visited[cur]) {\n                continue;\n            }\n            visited[cur] = true;\n            components[cur] = 0;\n\n            for (size_t j = 0; j < N; j++) {\n                if (A[i * N + j]) {\n                    toVisit.push(j);\n                }\n            }\n        }\n    }\n\n    // Merge components\n    int component = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (components[i] == -1) {\n            component++;\n            for (size_t j = 0; j < N; j++) {\n                if (components[j] == -1) {\n                    components[j] = component;\n                }\n                else if (components[j] == component) {\n                    components[j] = component;\n                }\n                else if (components[j]!= component) {\n                    components[j] = components[j] - component + 1;\n                }\n            }\n        }\n    }\n\n    // Find max component\n    std::vector<int> counts(component + 1, 0);\n    for (size_t i = 0; i < N; i++) {\n        counts[components[i]]++;\n    }\n\n    int maxComponent = 0;\n    int maxCount = 0;\n    for (size_t i = 0; i < component; i++) {\n        if (counts[i] > maxCount) {\n            maxCount = counts[i];\n            maxComponent = i;\n        }\n    }\n\n    return maxCount;\n}",
            "// 1. \u5efa\u56fe\uff0c\u7528DFS\n\t// 2. \u8fde\u901a\u5757\n\t// 3. \u6700\u5927\u7684\u8fde\u901a\u5757\n\t// 4. \u8fde\u901a\u5757\u6570\u76ee\n\n\t// 0. \u521d\u59cb\u5316\u6570\u636e\n\tstd::vector<bool> vis(N, false);\n\tstd::vector<std::vector<int>> graph(N);\n\tint count = 0;\n\n\t// 1. \u5efa\u56fe\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tgraph[i].push_back(j);\n\t\t\t}\n\t\t}\n\n\t// 2. \u8fde\u901a\u5757\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (vis[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tdfs(graph, vis, i, count);\n\t}\n\n\t// 3. \u6700\u5927\u7684\u8fde\u901a\u5757\n\tint maxComponentCount = 0;\n\tfor (int i = 0; i < count; i++) {\n\t\tif (vis[i] == false) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (maxComponentCount < countComponent(graph, vis, i)) {\n\t\t\tmaxComponentCount = countComponent(graph, vis, i);\n\t\t}\n\t}\n\n\t// 4. \u8fde\u901a\u5757\u6570\u76ee\n\treturn maxComponentCount;\n}",
            "std::vector<int> B(N, 0);\n  std::vector<int> C(N, 0);\n  std::vector<int> D(N, 0);\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 0)\n        continue;\n      B[i]++;\n      C[j]++;\n    }\n  }\n\n  for (size_t i = 0; i < N; i++) {\n    D[i] = B[i] + C[i];\n  }\n\n  return *std::max_element(D.begin(), D.end());\n}",
            "std::vector<int> visited(N, 0);\n    int largest_component = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            int current = 0;\n            dfs(A, N, i, visited, current);\n            largest_component = std::max(largest_component, current);\n        }\n    }\n    return largest_component;\n}",
            "std::vector<int> visited(N, 0);\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\tdfs(A, i, visited, N);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> count(N);\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        count[i] = 1;\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[N * i + j] == 1 &&!visited[j]) {\n                count[i] += count[j];\n                visited[j] = true;\n            }\n        }\n    }\n    return *std::max_element(count.begin(), count.end());\n}",
            "/* O(N) */\n    size_t count = 0;\n    std::vector<bool> visited(N, false);\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        count++;\n        std::queue<size_t> q;\n        q.push(i);\n        visited[i] = true;\n        while (!q.empty()) {\n            size_t v = q.front(); q.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (A[v * N + j] &&!visited[j]) {\n                    q.push(j);\n                    visited[j] = true;\n                }\n            }\n        }\n    }\n    return count;\n}",
            "// Find all connected components\n  std::vector<bool> component(N, false);\n  std::vector<bool> found(N, false);\n  for (size_t i = 0; i < N; i++) {\n    if (found[i]) continue;\n\n    std::vector<size_t> queue = {i};\n    found[i] = true;\n    while (queue.size()) {\n      size_t j = queue.back();\n      queue.pop_back();\n\n      if (found[j]) continue;\n      found[j] = true;\n\n      for (size_t k = 0; k < N; k++) {\n        if (A[j * N + k] == 1) {\n          queue.push_back(k);\n        }\n      }\n    }\n\n    for (size_t j = 0; j < N; j++) {\n      component[j] = component[j] || found[j];\n    }\n  }\n\n  // Find largest connected component\n  size_t largest = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (component[i]) largest++;\n  }\n\n  return largest;\n}",
            "int const UNVISITED = 0;\n    int const IN_PROGRESS = 1;\n    int const COMPLETE = 2;\n\n    std::vector<int> vStatus(N, UNVISITED);\n    std::vector<int> vParent(N, 0);\n    int maxComponentSize = 0;\n    int componentSize = 0;\n    int index = 0;\n\n    // start traversing from each unvisited vertex\n    for (size_t i = 0; i < N; ++i) {\n        if (vStatus[i] == UNVISITED) {\n            componentSize = 0;\n            dfs_util(A, vStatus, vParent, i, IN_PROGRESS, componentSize, UNVISITED, COMPLETE, index);\n            if (componentSize > maxComponentSize)\n                maxComponentSize = componentSize;\n        }\n    }\n\n    return maxComponentSize;\n}",
            "// build adjacency list (graph)\n\tstd::vector<std::vector<int>> graph(N, std::vector<int>());\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tgraph[i].push_back(j);\n\t\t\t}\n\t\t}\n\t}\n\n\t// set of visited vertices\n\tstd::vector<bool> visited(N, false);\n\n\tint component_size = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcomponent_size += traverse(graph, visited, i);\n\t\t}\n\t}\n\n\treturn component_size;\n}",
            "int m = 0;\n\t// check if row has a 1 in it, if so set that as the starting point.\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (A[i * N] == 1) {\n\t\t\tm = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\t// use dfs to find all the points connected to the start node and return how many.\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> num_in_component(N, 0);\n\t// std::cout << \"m: \" << m << std::endl;\n\tstd::vector<int> component;\n\t// dfs(A, N, m, 1, visited, num_in_component, component);\n\tdfs(A, N, m, num_in_component, visited);\n\n\t// find the largest component\n\tint largest_comp = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tlargest_comp = std::max(largest_comp, num_in_component[i]);\n\t}\n\t// std::cout << \"largest_comp: \" << largest_comp << std::endl;\n\treturn largest_comp;\n}",
            "std::vector<std::vector<int>> G(N, std::vector<int>(N, 0));\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            G[i][j] = A[i * N + j];\n        }\n    }\n    std::vector<int> visited(N, 0);\n    std::vector<int> visited_component(N, -1);\n    int current_component = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(visited[i] == 0) {\n            visited[i] = 1;\n            dfs_recursive(G, visited, visited_component, current_component, i);\n            ++current_component;\n        }\n    }\n    int max_count = 0;\n    int component_count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(visited_component[i] == -1) {\n            ++component_count;\n        } else {\n            max_count = std::max(max_count, visited_component[i]);\n        }\n    }\n    return component_count;\n}",
            "std::vector<int> visited(N, 0);\n  std::queue<int> q;\n\n  for (int i = 0; i < N; i++)\n    if (!visited[i]) {\n      q.push(i);\n      visited[i] = 1;\n\n      while (!q.empty()) {\n        auto const top = q.front();\n        q.pop();\n\n        for (int j = 0; j < N; j++) {\n          if (!visited[j] && A[top * N + j]) {\n            q.push(j);\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n\n  int count = 0;\n  for (int i = 0; i < N; i++)\n    if (visited[i])\n      count++;\n\n  return count;\n}",
            "size_t num_components = 0;\n    std::vector<int> comp(N, 0);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!comp[i]) {\n            ++num_components;\n            comp[i] = 1;\n            std::queue<size_t> q;\n            q.push(i);\n            while (!q.empty()) {\n                auto const vertex = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[N * vertex + j] &&!comp[j]) {\n                        comp[j] = 1;\n                        q.push(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return num_components;\n}",
            "// Write your code here\n\tint result = 0;\n\t// \u521b\u5efavisited\u6570\u7ec4\uff0c\u7528\u4e8e\u6807\u8bb0\u5df2\u7ecf\u8bbf\u95ee\u8fc7\u7684\u70b9\n\tstd::vector<bool> visited(N, false);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == false) {\n\t\t\tdfs(i, A, visited, N);\n\t\t\tresult++;\n\t\t}\n\t}\n\n\treturn result;\n}",
            "std::vector<bool> visited(N);\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            dfs(i, A, N, visited);\n        }\n    }\n    int count = 0;\n    for (bool v : visited) {\n        if (v) {\n            count++;\n        }\n    }\n    return count;\n}",
            "const int BFS_DIST = 1;\n\tconst int UNVISITED = 0;\n\tconst int INFINITY = 100000;\n\t//int visited[100] = { 0 };\n\n\tstd::vector<int> visited(N, 0);\n\n\tstd::deque<int> d;\n\tint current = 0;\n\tint index = 0;\n\tint count = 0;\n\tint maxCount = 0;\n\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!visited[i])\n\t\t{\n\t\t\td.push_back(i);\n\t\t\tvisited[i] = BFS_DIST;\n\t\t\twhile (!d.empty())\n\t\t\t{\n\t\t\t\tindex = d.front();\n\t\t\t\td.pop_front();\n\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t{\n\t\t\t\t\tif (A[index * N + j] == 1 && visited[j]!= BFS_DIST)\n\t\t\t\t\t{\n\t\t\t\t\t\td.push_back(j);\n\t\t\t\t\t\tvisited[j] = BFS_DIST;\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (count > maxCount)\n\t\t\t{\n\t\t\t\tmaxCount = count;\n\t\t\t}\n\t\t\tcount = 0;\n\t\t}\n\t}\n\n\treturn maxCount;\n}",
            "int max = 0;\n\tbool* visited = new bool[N];\n\tfor(int i=0;i<N;i++)\n\t\tvisited[i] = false;\n\n\tfor(int i=0;i<N;i++)\n\t\tif(visited[i] == false){\n\t\t\tDFS(i, A, visited, N);\n\t\t\tmax = std::max(max, currentComponentSize);\n\t\t\tcurrentComponentSize = 0;\n\t\t}\n\n\tdelete[] visited;\n\treturn max;\n}",
            "if (A.size()!= N * N)\n    throw std::invalid_argument(\"Size of adjacency matrix is incorrect.\");\n\n  std::vector<int> vertices(N);\n  std::iota(vertices.begin(), vertices.end(), 0);\n\n  int count = 0;\n  for (int i = 0; i < N; ++i) {\n    if (!A[i * N + i])\n      continue;\n\n    std::vector<int> v;\n    for (int j = i; j < N; ++j) {\n      if (A[i * N + j])\n        v.push_back(j);\n    }\n\n    std::sort(v.begin(), v.end(), [&A, &N](int i, int j) {\n      return A[i * N + i] > A[j * N + j];\n    });\n    count = std::max(count, dfs(A, v, N, std::unordered_set<int>(), vertices));\n  }\n\n  return count;\n}",
            "/* YOUR CODE GOES HERE */\n    // TODO: Replace with your code\n    std::vector<bool> visited(N, false);\n\n    auto check = [&visited](int v) {\n        if (!visited[v]) {\n            visited[v] = true;\n            for (int i = 0; i < N; ++i) {\n                if (A[v * N + i] == 1) {\n                    check(i);\n                }\n            }\n        }\n    };\n\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            check(i);\n            ++count;\n        }\n    }\n\n    return count;\n}",
            "int result = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::function<void(int)> dfs = [&](int i) -> void {\n\t\tif (visited[i] == 1) {\n\t\t\treturn;\n\t\t}\n\n\t\t++result;\n\t\tvisited[i] = 1;\n\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tdfs(j);\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tdfs(i);\n\t}\n\n\treturn result;\n}",
            "std::vector<int> comp_sizes(N, 0);\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1)\n                comp_sizes[i]++;\n        }\n    }\n\n    // Find the largest component\n    int largest_comp_size = 0;\n    for (int i = 0; i < N; ++i) {\n        if (comp_sizes[i] > largest_comp_size) {\n            largest_comp_size = comp_sizes[i];\n        }\n    }\n    return largest_comp_size;\n}",
            "int max_component_size = 0;\n    std::vector<int> component_sizes(N, 0);\n    std::vector<int> visited(N, 0);\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            max_component_size = std::max(max_component_size, dfs(i, A, visited, component_sizes));\n        }\n    }\n    return max_component_size;\n}",
            "std::vector<int> visited(N, 0);\n\n    auto dfs = [&A, &visited](int i) {\n        if (visited[i] == 1)\n            return;\n        visited[i] = 1;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1)\n                dfs(j);\n        }\n    };\n\n    size_t res = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            dfs(i);\n            ++res;\n        }\n    }\n\n    return res;\n}",
            "std::vector<std::vector<int>> graph(N);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tgraph[i].resize(N);\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tgraph[i][j] = A[i*N + j];\n\t\t}\n\t}\n\n\tstd::vector<bool> visited(N);\n\tstd::fill(visited.begin(), visited.end(), false);\n\n\tint largest = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tint size = bfs(graph, i, visited);\n\t\t\tlargest = std::max(largest, size);\n\t\t}\n\t}\n\treturn largest;\n}",
            "std::vector<int> visited(N, 0);\n    int largestComponentSize = 0;\n\n    for (int i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            int visitedCount = 0;\n            dfs(A, visited, i, N, visitedCount);\n            largestComponentSize = std::max(largestComponentSize, visitedCount);\n        }\n    }\n    return largestComponentSize;\n}",
            "// TODO: add your code here\n\tstd::vector<int> color(N, 0);\n\tint count = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!color[i]) {\n\t\t\tcount++;\n\t\t\tdfs(i, A, color, N);\n\t\t}\n\t}\n\treturn count;\n}",
            "// Use DFS to visit each node of the graph\n    std::vector<bool> visited(N, false);\n    int numComponents = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            dfs(A, i, N, visited);\n            numComponents++;\n        }\n    }\n\n    return numComponents;\n}",
            "return std::accumulate(A.begin(), A.end(), 0) / N;\n}",
            "if (N < 1) {\n\t\treturn 0;\n\t}\n\tstd::vector<std::vector<bool>> graph(N, std::vector<bool>(N, false));\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tgraph[i][j] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Mark all visited vertices as 1 and unvisited vertices as 0\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> queue;\n\tqueue.push_back(0);\n\tvisited[0] = 1;\n\tsize_t count = 1;\n\n\twhile (!queue.empty()) {\n\t\tauto current = queue.back();\n\t\tqueue.pop_back();\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (graph[current][i] && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tqueue.push_back(i);\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// This function is implemented using BFS\n  int maxSize = 0;\n  for (size_t i = 0; i < N; ++i) {\n    std::vector<bool> visited(N, false);\n    std::queue<int> Q;\n    Q.push(i);\n    visited[i] = true;\n    int size = 0;\n    while (!Q.empty()) {\n      auto u = Q.front();\n      Q.pop();\n      for (size_t j = 0; j < N; ++j) {\n        if (A[u * N + j] == 1 &&!visited[j]) {\n          visited[j] = true;\n          size++;\n          Q.push(j);\n        }\n      }\n    }\n    maxSize = std::max(maxSize, size);\n  }\n\n  return maxSize;\n}",
            "if (N == 1) {\n\t\treturn 1;\n\t}\n\n\tstd::vector<std::vector<int>> components;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tcomponents.push_back({ i });\n\t}\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tfor (size_t l = 0; l < N; l++) {\n\t\t\t\t\t\tif (A[k * N + l] == 1) {\n\t\t\t\t\t\t\tbool found = false;\n\t\t\t\t\t\t\tfor (auto& component : components) {\n\t\t\t\t\t\t\t\tif (std::find(component.begin(), component.end(), i)!= component.end() &&\n\t\t\t\t\t\t\t\t\tstd::find(component.begin(), component.end(), k)!= component.end()) {\n\t\t\t\t\t\t\t\t\tfound = true;\n\t\t\t\t\t\t\t\t\tfor (auto vertex : component) {\n\t\t\t\t\t\t\t\t\t\tcomponents[j].push_back(vertex);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tcomponent.clear();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (std::find(component.begin(), component.end(), j)!= component.end() &&\n\t\t\t\t\t\t\t\t\tstd::find(component.begin(), component.end(), l)!= component.end()) {\n\t\t\t\t\t\t\t\t\tfound = true;\n\t\t\t\t\t\t\t\t\tfor (auto vertex : component) {\n\t\t\t\t\t\t\t\t\t\tcomponents[i].push_back(vertex);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tcomponent.clear();\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!found) {\n\t\t\t\t\t\t\t\tcomponents.push_back({ i, j, k, l });\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint max_size = 0;\n\tfor (auto& component : components) {\n\t\tif (component.size() > max_size) {\n\t\t\tmax_size = component.size();\n\t\t}\n\t}\n\treturn max_size;\n}",
            "auto visited = std::vector<bool>(N, false);\n\tauto largestComponentSize = 0;\n\n\tauto dfs = [&](auto&& dfs, int const& u) -> void {\n\t\tvisited[u] = true;\n\t\tfor (auto v = 0; v < N; ++v) {\n\t\t\tif (!visited[v] && A[u * N + v]) {\n\t\t\t\tdfs(dfs, v);\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (auto u = 0; u < N; ++u) {\n\t\tif (!visited[u]) {\n\t\t\tdfs(dfs, u);\n\t\t}\n\t}\n\n\tfor (auto const& b : visited) {\n\t\tif (b) {\n\t\t\t++largestComponentSize;\n\t\t}\n\t}\n\n\treturn largestComponentSize;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::function<int(int, int)> dfs = [&](int n, int parent) -> int {\n\t\tif (n >= N)\n\t\t\treturn 0;\n\t\tvisited[n] = 1;\n\t\tint sum = 1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[n * N + i] && i!= parent) {\n\t\t\t\tsum += dfs(i, n);\n\t\t\t}\n\t\t}\n\t\treturn sum;\n\t};\n\n\tint max_sum = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tmax_sum = std::max(max_sum, dfs(i, -1));\n\t\t}\n\t}\n\treturn max_sum;\n}",
            "std::vector<int> adj(N * N, 0);\n  std::vector<bool> visited(N, false);\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        adj[i * N + j] = 1;\n      }\n    }\n  }\n\n  size_t max_num = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      size_t cnt = dfs(adj, visited, N, i);\n      if (cnt > max_num) {\n        max_num = cnt;\n      }\n    }\n  }\n\n  return max_num;\n}",
            "if (A.size()!= N*N)\n        throw std::invalid_argument(\"invalid matrix\");\n    // TODO\n    int largestComponent = 1;\n    int visited = 0;\n    for (size_t i = 0; i < N; ++i)\n        if (A[i] == 1)\n            ++visited;\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j] == 1)\n                for (size_t k = 0; k < N; ++k)\n                    if (A[j * N + k] == 1 && A[i * N + k] == 0) {\n                        A[i * N + k] = 1;\n                        A[k * N + i] = 1;\n                        ++visited;\n                    }\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j] == 1)\n                ++largestComponent;\n    return largestComponent;\n}",
            "// 1. Create an adjacency list from the matrix (only consider the upper triangular matrix)\n  std::vector<std::vector<size_t>> adjList(N);\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        adjList[i].push_back(j);\n        adjList[j].push_back(i);\n      }\n    }\n  }\n  // 2. Perform a depth-first search starting from each vertex\n  std::vector<bool> visited(N, false);\n  size_t maxSize = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == false) {\n      std::stack<size_t> st;\n      st.push(i);\n      visited[i] = true;\n      size_t size = 1;\n      while (!st.empty()) {\n        size_t cur = st.top();\n        st.pop();\n        for (size_t j = 0; j < adjList[cur].size(); j++) {\n          if (visited[adjList[cur][j]] == false) {\n            visited[adjList[cur][j]] = true;\n            st.push(adjList[cur][j]);\n            size++;\n          }\n        }\n      }\n      if (size > maxSize) {\n        maxSize = size;\n      }\n    }\n  }\n  // 3. Return the size of the largest component\n  return maxSize;\n}",
            "std::vector<int> vis(N, -1);\n\tstd::stack<int> stk;\n\tint idx = 0;\n\tint count = 0;\n\t\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (vis[i] == -1) {\n\t\t\tstk.push(i);\n\t\t\twhile (!stk.empty()) {\n\t\t\t\tint cur = stk.top();\n\t\t\t\tstk.pop();\n\t\t\t\tif (vis[cur] == -1) {\n\t\t\t\t\tvis[cur] = idx;\n\t\t\t\t\t++count;\n\t\t\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\t\t\tif (A[cur*N + i] == 1 && vis[i] == -1) {\n\t\t\t\t\t\t\tstk.push(i);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t++idx;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "size_t count = 0;\n\tbool visited[N];\n\tstd::fill_n(visited, N, false);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = true;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tauto v = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[v * N + j] == 1 &&!visited[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// write your code here\n\tif (A.empty()) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\tint max = 0;\n\tfor (int i : visited) {\n\t\tif (i > max) {\n\t\t\tmax = i;\n\t\t}\n\t}\n\treturn max;\n}",
            "std::vector<std::vector<bool>> visited(N, std::vector<bool>(N, false));\n    std::vector<int> ret(N, 0);\n    int maxSize = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                ret[i] = 1;\n                break;\n            }\n        }\n    }\n\n    for (size_t i = 0; i < N; i++) {\n        if (ret[i] == 0) {\n            int size = 1;\n            for (size_t j = 0; j < N; j++) {\n                if (A[j * N + i] == 1) {\n                    visited[j][i] = true;\n                    visited[i][j] = true;\n                    size++;\n                }\n            }\n            maxSize = maxSize > size? maxSize : size;\n        }\n    }\n    return maxSize;\n}",
            "std::vector<int> vertex(N);\n\n    for (size_t i = 0; i < N; i++) {\n        vertex[i] = i;\n    }\n\n    auto find = [&](int const& x) {\n        int xr = x;\n        while (xr!= vertex[xr]) {\n            xr = vertex[xr];\n        }\n\n        int yr = x;\n        while (yr!= xr) {\n            int tmp = vertex[yr];\n            vertex[yr] = xr;\n            yr = tmp;\n        }\n\n        return xr;\n    };\n\n    auto unite = [&](int const& x, int const& y) {\n        vertex[find(y)] = find(x);\n    };\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                unite(i, j);\n            }\n        }\n    }\n\n    std::set<int> components;\n    for (size_t i = 0; i < N; i++) {\n        components.insert(find(i));\n    }\n\n    return components.size();\n}",
            "// TODO: write your solution here\n  std::vector<int> visited(N, 0);\n  int cnt = 0;\n\n  for(size_t i = 0; i < N; i++) {\n    if(visited[i] == 1)\n      continue;\n\n    int start = i;\n    std::stack<int> stack;\n    stack.push(start);\n    visited[start] = 1;\n    cnt++;\n\n    while(!stack.empty()) {\n      int curr = stack.top();\n      stack.pop();\n\n      for(size_t j = 0; j < N; j++) {\n        if(A[curr * N + j] == 1) {\n          if(visited[j] == 0) {\n            stack.push(j);\n            visited[j] = 1;\n            cnt++;\n          }\n        }\n      }\n    }\n  }\n\n  return cnt;\n}",
            "if (A.size()!= N * N) {\n        throw std::invalid_argument(\"NxN matrix expected\");\n    }\n\n    std::vector<bool> visited(N, false);\n    std::vector<std::vector<size_t>> components;\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i]) {\n            continue;\n        }\n        std::vector<size_t> component;\n        dfs(A, visited, i, component);\n        components.push_back(component);\n    }\n\n    auto max_component = *std::max_element(components.begin(), components.end(), [](std::vector<size_t> const& c1, std::vector<size_t> const& c2) {\n        return c1.size() < c2.size();\n    });\n    return max_component.size();\n}",
            "if (N == 1) {\n    return 1;\n  }\n\n  int count = 0;\n  std::vector<bool> visted(N);\n\n  for (size_t i = 0; i < N; i++) {\n    if (!visted[i]) {\n      count++;\n      std::queue<int> q;\n      q.push(i);\n      while (!q.empty()) {\n        int n = q.front();\n        q.pop();\n        for (size_t j = 0; j < N; j++) {\n          if (!visted[j] && A[n * N + j] == 1) {\n            q.push(j);\n            visted[j] = true;\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n    std::queue<std::size_t> q;\n    std::size_t componentSize = 0;\n    std::size_t maxComponentSize = 0;\n\n    for (std::size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            q.push(i);\n            ++componentSize;\n\n            while (!q.empty()) {\n                std::size_t curIdx = q.front();\n                q.pop();\n\n                if (!visited[curIdx]) {\n                    visited[curIdx] = true;\n                    componentSize += 1;\n\n                    for (std::size_t j = 0; j < N; ++j) {\n                        if (A[curIdx * N + j] &&!visited[j]) {\n                            q.push(j);\n                        }\n                    }\n                }\n            }\n\n            if (componentSize > maxComponentSize) {\n                maxComponentSize = componentSize;\n            }\n\n            componentSize = 0;\n            visited.assign(N, false);\n        }\n    }\n\n    return maxComponentSize;\n}",
            "// TODO: Fill in the implementation\n\t// std::vector<bool> visited(N, false);\n\tstd::vector<bool> visited(N);\n\tstd::vector<int> count(N);\n\tstd::vector<int> index(N);\n\tstd::queue<int> q;\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tbfs(A, visited, count, index, q, i);\n\t\t\tif (count[i] > max)\n\t\t\t\tmax = count[i];\n\t\t}\n\t}\n\treturn max;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::function<void(int)> dfs = [&A, &visited, &dfs](int start){\n\t\tif (visited[start] == 1) return;\n\t\tvisited[start] = 1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[start * N + i]) dfs(i);\n\t\t}\n\t};\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = 1;\n\t\tdfs(i);\n\t\tmax = std::max(max, 1);\n\t}\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = 1;\n\t\tdfs(i);\n\t\tmax = std::max(max, 1);\n\t}\n\treturn max;\n}",
            "std::vector<int> components(N, 0);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                int i_c = components[i];\n                int j_c = components[j];\n                if (i_c == 0 && j_c == 0) {\n                    i_c = ++components[i];\n                    j_c = i_c;\n                } else if (i_c == 0 && j_c > 0) {\n                    i_c = j_c;\n                    j_c = i_c;\n                } else if (j_c == 0 && i_c > 0) {\n                    j_c = i_c;\n                    i_c = j_c;\n                } else if (i_c!= j_c) {\n                    int smallest = std::min(i_c, j_c);\n                    int largest = std::max(i_c, j_c);\n                    for (size_t k = 0; k < N; ++k) {\n                        if (components[k] == largest) {\n                            components[k] = smallest;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    int max_components = 0;\n    for (size_t i = 0; i < N; ++i) {\n        max_components = std::max(max_components, components[i]);\n    }\n    return max_components;\n}",
            "// your code here\n}",
            "std::vector<bool> visited(N, false);\n\tstd::stack<int> stack;\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) continue;\n\t\tcount++;\n\t\tstack.push(i);\n\t\twhile (!stack.empty()) {\n\t\t\tint const v = stack.top();\n\t\t\tstack.pop();\n\t\t\tvisited[v] = true;\n\t\t\tfor (size_t w = 0; w < N; w++) {\n\t\t\t\tif (A[N * v + w] &&!visited[w]) {\n\t\t\t\t\tstack.push(w);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\n\tauto findSet = [&A, N](size_t vertex) -> size_t {\n\t\tif (A[vertex * N + vertex] == 0) {\n\t\t\tsize_t tmp = findSet(A[vertex * N + vertex]);\n\t\t\tA[vertex * N + vertex] = tmp;\n\t\t\treturn tmp;\n\t\t}\n\n\t\treturn vertex;\n\t};\n\n\tauto unionSets = [&A, N](size_t vertexA, size_t vertexB) {\n\t\tsize_t setA = findSet(vertexA);\n\t\tsize_t setB = findSet(vertexB);\n\n\t\tif (setA!= setB) {\n\t\t\tA[setA * N + setB] = setB;\n\t\t\tA[setB * N + setA] = setA;\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tcount++;\n\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tunionSets(i, j);\n\t\t\t}\n\t\t}\n\t}\n\n\tint max = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tmax = std::max(max, static_cast<int>(findSet(i)));\n\t}\n\n\treturn max + 1;\n}",
            "std::vector<int> component_sizes(N, 1); // Component sizes\n    std::vector<int> component_map(N, 0); // Map each vertex to its component\n    for (size_t v = 0; v < N; ++v) {\n        // Find the next vertex that is unassigned\n        if (component_map[v]!= 0) {\n            continue;\n        }\n\n        // This vertex is the root of a new component\n        int this_component = v;\n        component_sizes[this_component] = 1;\n        for (size_t w = 0; w < N; ++w) {\n            if (A[v * N + w] == 1) {\n                // There is an edge from this vertex to w\n                if (component_map[w] == 0) {\n                    // w is unassigned\n                    component_map[w] = this_component;\n                    component_sizes[this_component]++;\n                } else if (component_map[w]!= this_component) {\n                    // w is assigned to a different component\n                    int w_component = component_map[w];\n                    int new_component = this_component;\n                    for (size_t x = 0; x < N; ++x) {\n                        if (component_map[x] == w_component) {\n                            // Assign x to the new component\n                            component_map[x] = new_component;\n                            component_sizes[new_component]++;\n                        }\n                    }\n                    component_sizes[new_component] += component_sizes[w_component];\n                    component_sizes[w_component] = 0;\n                }\n            }\n        }\n    }\n\n    int component_size = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (component_sizes[i] > component_size) {\n            component_size = component_sizes[i];\n        }\n    }\n    return component_size;\n}",
            "std::vector<int> dist(N, -1);\n    std::vector<int> parent(N);\n    int cnt = 0;\n    int n = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (dist[i] == -1) {\n            DFS(A, dist, parent, i);\n            ++cnt;\n        }\n        n = std::max(n, dist[i]);\n    }\n\n    return cnt;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<size_t> parents(N, 0);\n\tstd::vector<size_t> sizes(N, 1);\n\tint largest = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tstd::stack<int> dfs;\n\t\t\tdfs.push(i);\n\n\t\t\twhile (!dfs.empty()) {\n\t\t\t\tint node = dfs.top();\n\t\t\t\tdfs.pop();\n\n\t\t\t\tif (!visited[node]) {\n\t\t\t\t\tvisited[node] = true;\n\t\t\t\t\tparents[node] = node;\n\n\t\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (A[N*node + j] == 1) {\n\t\t\t\t\t\t\tdfs.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint maxsize = 0;\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (parents[i] == node) {\n\t\t\t\t\tint size = sizes[i];\n\t\t\t\t\tmaxsize = (size > maxsize)? size : maxsize;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tlargest = (maxsize > largest)? maxsize : largest;\n\t\t}\n\t}\n\n\treturn largest;\n}",
            "int count = 0;\n    std::vector<bool> visited(N, false);\n    std::queue<int> q;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            q.push(i);\n            while (!q.empty()) {\n                auto const& idx = q.front();\n                if (visited[idx]) {\n                    q.pop();\n                    continue;\n                }\n                visited[idx] = true;\n                count++;\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[idx * N + j]!= 0 &&!visited[j]) {\n                        q.push(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "assert(N > 0 && \"N must be positive\");\n    assert(A.size() == N * N && \"Invalid input size\");\n    auto const& N2 = N * N;\n    auto const& A_begin = A.begin();\n    auto const& A_end = A.end();\n\n    std::vector<int> B(N2);\n    auto const& B_begin = B.begin();\n\n    std::vector<int> C(N);\n    auto const& C_begin = C.begin();\n\n    auto const& adj = [&A_begin, &N](int i, int j) {\n        return A_begin[i * N + j];\n    };\n    auto const& adj_ref = [&A_begin, &N](int i, int j) -> int& {\n        return A_begin[i * N + j];\n    };\n\n    // Compute the transitive closure of A\n    auto const& transitive_closure = [&N, &A, &adj, &adj_ref](std::vector<int> const& B, std::vector<int> const& C) {\n        std::fill(B_begin, B_end, 0);\n        std::fill(C_begin, C_end, 0);\n\n        // Populate B with the adjacency matrix\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (adj(i, j)) {\n                    B[i * N + j] = 1;\n                }\n            }\n        }\n\n        // Populate C with the adjacency matrix\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (adj(i, j)) {\n                    C[j] = 1;\n                }\n            }\n        }\n\n        for (size_t k = 0; k < N; ++k) {\n            for (size_t i = 0; i < N; ++i) {\n                for (size_t j = 0; j < N; ++j) {\n                    if (B[i * N + k] && B[k * N + j]) {\n                        B[i * N + j] = 1;\n                    }\n                }\n            }\n\n            for (size_t i = 0; i < N; ++i) {\n                for (size_t j = 0; j < N; ++j) {\n                    if (C[i] && B[i * N + j]) {\n                        C[j] = 1;\n                    }\n                }\n            }\n        }\n\n        // Copy B back into A\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                adj_ref(i, j) = B[i * N + j];\n            }\n        }\n    };\n\n    // Compute the connected components of A\n    auto const& connected_components = [&N, &A, &adj, &adj_ref]() {\n        auto const& N2 = N * N;\n        std::vector<int> B(N2, 1);\n        auto const& B_begin = B.begin();\n        auto const& B_end = B.end();\n\n        std::vector<int> C(N, 0);\n        auto const& C_begin = C.begin();\n\n        auto const& D = [&N, &B, &C]() -> int {\n            for (size_t i = 0; i < N; ++i) {\n                C[i] = i;\n            }\n\n            int n = 0;\n            for (size_t i = 0; i < N; ++i) {\n                for (size_t j = 0; j < N; ++j) {\n                    if (B[i * N + j]) {\n                        C[n++] = i;\n                        break;\n                    }\n                }\n            }\n\n            return n;\n        };\n\n        auto const& e = [&",
            "std::vector<bool> visited(N);\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      dfs(A, i, visited);\n    }\n  }\n  return count;\n}",
            "int component_count = 0;\n\n    std::vector<int> visited;\n    visited.resize(N, 0);\n\n    // Mark all the nodes as unvisited\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n\n    // Traverse the graph and get the number of connected components\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            traverse(A, visited, i);\n            component_count++;\n        }\n    }\n\n    return component_count;\n}",
            "std::vector<int> parents(N);\n\tstd::iota(parents.begin(), parents.end(), 0);\n\n\tstd::function<int(int)> find = [&parents](int const i) -> int {\n\t\treturn (i!= parents[i])? parents[i] = find(parents[i]) : i;\n\t};\n\n\tauto const is_connected = [&find](int i, int j) -> bool {\n\t\treturn find(i) == find(j);\n\t};\n\n\tsize_t largest = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j]) {\n\t\t\t\tif (is_connected(i, j)) {\n\t\t\t\t\tlargest = std::max(largest, 1 + (i > j? parents[j] : parents[i]));\n\t\t\t\t} else {\n\t\t\t\t\tparents[find(i)] = find(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn largest;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tint max = 0;\n\t\n\tfor (int i = 0; i < N; ++i) {\n\t\t\n\t\tif (visited[i] == 0) {\n\t\t\t\n\t\t\tcount = dfs(A, visited, i, 0, N);\n\t\t\t\n\t\t\tif (count > max) {\n\t\t\t\tmax = count;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn max;\n}",
            "// Create a graph with node ids 1,2,...,N\n  std::unordered_map<int, std::unordered_set<int>> graph;\n  for (int i = 0; i < N; i++) {\n    graph[i + 1] = std::unordered_set<int>();\n  }\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]) {\n        graph[i + 1].insert(j + 1);\n      }\n    }\n  }\n\n  // Do a DFS search on each unvisited node in graph,\n  // and assign all visited nodes to the component id.\n  // Start with component id 1.\n  int componentId = 1;\n  std::unordered_set<int> visitedNodes;\n  for (int i = 0; i < N; i++) {\n    if (visitedNodes.find(i + 1) == visitedNodes.end()) {\n      std::queue<int> q;\n      q.push(i + 1);\n      visitedNodes.insert(i + 1);\n      int curr = i + 1;\n      while (!q.empty()) {\n        curr = q.front();\n        q.pop();\n        auto it = graph[curr].begin();\n        while (it!= graph[curr].end()) {\n          if (visitedNodes.find(*it) == visitedNodes.end()) {\n            visitedNodes.insert(*it);\n            q.push(*it);\n          }\n          it++;\n        }\n      }\n    }\n  }\n\n  // Count the number of nodes in each component\n  std::unordered_map<int, int> componentSizes;\n  for (auto it = visitedNodes.begin(); it!= visitedNodes.end(); it++) {\n    componentSizes[*it]++;\n  }\n\n  // Find the component with the largest size\n  int maxSize = 0;\n  int maxComponent = 0;\n  for (auto it = componentSizes.begin(); it!= componentSizes.end(); it++) {\n    if (it->second > maxSize) {\n      maxComponent = it->first;\n      maxSize = it->second;\n    }\n  }\n\n  // Count the number of vertices in the largest component\n  return maxSize;\n}",
            "// TODO: implement\n  std::vector<bool> visited;\n  visited.resize(N, false);\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == false) {\n      //std::cout << \"i is \" << i << std::endl;\n      //std::cout << \"count is \" << count << std::endl;\n      count++;\n      BFS(i, visited, A, N);\n      //std::cout << \"count is \" << count << std::endl;\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n    std::vector<int> v(N, 0);\n    int result = 0;\n    int count = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            count = 0;\n            dfs(A, N, v, visited, i, count);\n            result = std::max(count, result);\n        }\n    }\n    return result;\n}",
            "// Return the largest component\n    int count = 0;\n    std::vector<bool> visited(N, false);\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            visited[i] = true;\n            bfs(A, visited, i, N);\n            ++count;\n        }\n    }\n\n    return count;\n}",
            "// TODO: write your code here\n\tstd::vector<int> V(N);\n\tstd::iota(V.begin(), V.end(), 0);\n\tstd::vector<int> id(N);\n\tstd::vector<int> sz(N);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tint x = find(V, id, j);\n\t\t\t\tint y = find(V, id, i);\n\t\t\t\tunion_set(V, id, x, y, sz);\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> cnt(N);\n\tstd::for_each(id.begin(), id.end(), [&cnt](auto x) { ++cnt[x]; });\n\tint largest = *std::max_element(cnt.begin(), cnt.end());\n\treturn largest;\n}",
            "// Write your code here\n\tint count = 0;\n\tint result = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i] == 0) {\n\t\t\t++count;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[j] == 0) {\n\t\t\t\t\tint index = 0;\n\t\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\t\tif (A[k] == 0) {\n\t\t\t\t\t\t\tif (index == 0) {\n\t\t\t\t\t\t\t\tA[k] = j + 1;\n\t\t\t\t\t\t\t\tindex = 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse if (A[k] == 0) {\n\t\t\t\t\t\t\t\tA[k] = j + 1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tresult = max(result, count);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount = 0;\n\t\t}\n\t}\n\treturn result;\n}",
            "std::vector<int> group_id(N, -1);\n    int cnt = 0;\n    // DFS from first unvisited node\n    for (int i = 0; i < N; ++i) {\n        if (group_id[i] < 0) {\n            dfs(i, i, group_id, A, N);\n            ++cnt;\n        }\n    }\n    return cnt;\n}",
            "if (A.empty()) return 0;\n\tstd::vector<int> visited(N, 0);\n\tint largest_component = 1;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tint current = i;\n\t\t\tint count = 0;\n\t\t\twhile (current!= -1) {\n\t\t\t\tvisited[current] = 1;\n\t\t\t\tcount++;\n\t\t\t\tif (A[current] == 0) {\n\t\t\t\t\tcurrent = -1;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tcurrent = findNext(A[current]);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (count > largest_component) {\n\t\t\t\tlargest_component = count;\n\t\t\t}\n\t\t}\n\t}\n\treturn largest_component;\n}",
            "std::vector<int> component_sizes;\n    // DFS:\n    for (size_t i = 0; i < N; i++) {\n        std::set<int> visited;\n        std::queue<int> q;\n        q.push(i);\n        int count = 0;\n        while (!q.empty()) {\n            int cur = q.front();\n            q.pop();\n            if (visited.find(cur)!= visited.end())\n                continue;\n            visited.insert(cur);\n            for (int j = 0; j < N; j++) {\n                if (A[cur * N + j] == 1)\n                    q.push(j);\n            }\n            count++;\n        }\n        component_sizes.push_back(count);\n    }\n\n    return *std::max_element(component_sizes.begin(), component_sizes.end());\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tstd::queue<size_t> q;\n\t\tq.push(i);\n\t\tvisited[i] = true;\n\t\tcount++;\n\n\t\twhile (!q.empty()) {\n\t\t\tsize_t vertex = q.front();\n\t\t\tq.pop();\n\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[vertex * N + j]) {\n\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint maxSize = 0;\n\tint currSize = 0;\n\tint currNode = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcurrSize = 1;\n\t\t\tDFS(A, visited, i, N);\n\t\t\tif (currSize > maxSize) maxSize = currSize;\n\t\t}\n\t}\n\n\treturn maxSize;\n}",
            "std::vector<int> visited(N, 0);\n    int largest_component = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            largest_component = largestComponentRecursive(A, visited, i, 0);\n        }\n    }\n    return largest_component;\n}",
            "// write your code here\n\tstd::vector<int> components(N);\n\tstd::vector<int> component_size(N, 0);\n\n\t// DFS\n\tstd::function<void(int)> dfs = [&](int i) {\n\t\tif (components[i]) return;\n\t\tcomponents[i] = i + 1;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdfs(j);\n\t\t\t\tif (components[j]) {\n\t\t\t\t\tif (components[i]!= components[j]) {\n\t\t\t\t\t\t// union\n\t\t\t\t\t\tint c1 = components[i], c2 = components[j];\n\t\t\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\t\t\tif (components[k] == c2) {\n\t\t\t\t\t\t\t\tcomponents[k] = c1;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tdfs(i);\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (component_size[components[i] - 1] < component_size[i]) {\n\t\t\tcomponent_size[components[i] - 1] = component_size[i];\n\t\t}\n\t}\n\n\tint max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tmax = std::max(max, component_size[i]);\n\t}\n\treturn max;\n}",
            "// TODO: complete this function\n}",
            "std::vector<int> visited(N, 0);\n\n  int largest = 0;\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      int curr = 0;\n      dfs(i, A, N, visited, curr);\n      largest = std::max(largest, curr);\n    }\n  }\n  return largest;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "hip",
        "prompt": "/* Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   Store the result in largestComponentSize.\n   A is an NxN adjacency matrix stored in row-major.\n   Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void largestComponent(const int *A, size_t N, int *largestComponentSize) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "extern __shared__ int sdata[];\n  unsigned int t = threadIdx.x;\n  unsigned int b = blockIdx.x;\n  unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Initialize the shared data array with zeros.\n  sdata[t] = 0;\n\n  __syncthreads();\n\n  // Loop over columns of A, until the end of the row.\n  for (int j = 0; j < N; j++) {\n    // Atomically add the value of A[i,j] to the value of sdata[i].\n    atomicAdd(&sdata[i], A[b * N + j]);\n  }\n\n  // Sync all threads to make sure all the addition is complete.\n  __syncthreads();\n\n  // Loop over the threads in the block to find the maximum value in sdata.\n  for (unsigned int s = 1; s < blockDim.x; s *= 2) {\n    int index = 2 * s * t;\n\n    // If a[index] is larger than a[index+s], copy a[index+s] to a[index].\n    if (index + s < 2 * blockDim.x) {\n      if (sdata[index] < sdata[index + s]) {\n        sdata[index] = sdata[index + s];\n      }\n    }\n    // Sync all threads to make sure all the comparison is complete.\n    __syncthreads();\n  }\n\n  // If the thread is index 0, copy the value of sdata[0] to largestComponentSize.\n  if (t == 0) {\n    largestComponentSize[b] = sdata[0];\n  }\n}",
            "// TODO: implement using AMD HIP\n}",
            "// TODO\n}",
            "int largestComponentSizeLocal = 1;\n\n  // Define shared memory to store the adjacency matrix in the shared memory of each thread block\n  __shared__ int smem[BLOCK_SIZE][BLOCK_SIZE];\n  int blockOffset = threadIdx.x + blockIdx.x * BLOCK_SIZE;\n  int numElements = (N - blockOffset) > BLOCK_SIZE? BLOCK_SIZE : (N - blockOffset);\n\n  for (int i = 0; i < numElements; i++) {\n    smem[threadIdx.x][i] = A[i + blockOffset];\n  }\n  __syncthreads();\n\n  for (int i = 0; i < numElements; i++) {\n    int neighbor = threadIdx.x + i * BLOCK_SIZE;\n    if (neighbor < N && smem[threadIdx.x][i]) {\n      largestComponentSizeLocal += 1;\n    }\n  }\n\n  if (largestComponentSizeLocal > *largestComponentSize) {\n    *largestComponentSize = largestComponentSizeLocal;\n  }\n}",
            "int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n\n    int i = tx + bx * blockDim.x;\n    int j = ty + by * blockDim.y;\n\n    __shared__ int visited[MAX_SIZE][MAX_SIZE];\n\n    if(i < N && j < N) {\n        visited[tx][ty] = A[i * N + j];\n        __syncthreads();\n        if(i < N && j < N) {\n            for(int k = 0; k < N; k++) {\n                if(i!= j && j!= k && k!= i && visited[tx][ty] == 1 && visited[ty][k] == 1) {\n                    visited[tx][ty] = 0;\n                }\n            }\n        }\n        __syncthreads();\n        if(i == tx && j == ty) {\n            if(visited[tx][ty] == 1) {\n                *largestComponentSize = *largestComponentSize + 1;\n            }\n        }\n    }\n}",
            "// TODO: implement the kernel\n\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid >= N) return;\n\tint row = tid;\n\tint compID = A[row];\n\tbool flag = false;\n\tint count = 0;\n\tfor (int col = 0; col < N; ++col) {\n\t\tif (row == col) continue;\n\t\tif (A[row * N + col] == 1 && A[col * N + row] == 1) {\n\t\t\tflag = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!flag) {\n\t\t//printf(\"%d %d\\n\", row, compID);\n\t\t++count;\n\t\t*largestComponentSize = *largestComponentSize + 1;\n\t}\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (x == y) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t\tint cSize = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[x * N + i] || A[i * N + x]) cSize++;\n\t\t}\n\t\tatomicMax(largestComponentSize, cSize);\n\t}\n}",
            "// Set up the shared memory for the BFS kernel.\n  __shared__ int sharedQueue[N];\n  __shared__ bool sharedVisited[N];\n\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if (tid < N) {\n    // initialize the shared memory\n    sharedVisited[tid] = false;\n    sharedQueue[tid] = -1;\n  }\n  __syncthreads();\n\n  // Set up the local queue for the BFS\n  int queueIndex = 0;\n  sharedQueue[queueIndex] = tid;\n  sharedVisited[tid] = true;\n  queueIndex++;\n  // This is the loop that performs BFS.\n  while (queueIndex > 0) {\n    __syncthreads();\n    int queueFront = sharedQueue[0];\n    queueIndex--;\n    for (int k = 0; k < N; k++) {\n      if (A[queueFront * N + k] == 1 &&!sharedVisited[k]) {\n        // The vertex k is adjacent to queueFront.\n        // Add k to the queue.\n        sharedQueue[queueIndex] = k;\n        queueIndex++;\n        sharedVisited[k] = true;\n      }\n    }\n  }\n  // Write the size of the largest component to the global memory.\n  if (tid == 0) {\n    *largestComponentSize = queueIndex;\n  }\n}",
            "const int i = threadIdx.y;\n\tconst int j = threadIdx.x;\n\tconst int m = blockDim.y;\n\tconst int n = blockDim.x;\n\t__shared__ int adj[BLOCKSIZE][BLOCKSIZE];\n\n\tadj[i][j] = A[i * N + j];\n\t__syncthreads();\n\n\tif (i == 0) {\n\t\tfor (int j = 1; j < n; ++j) {\n\t\t\tif (adj[0][j] == 0) {\n\t\t\t\tadj[0][j] = adj[j][0];\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor (int j = 1; j < n; ++j) {\n\t\t\tif (adj[0][0] == 0) {\n\t\t\t\tadj[0][0] = adj[0][j];\n\t\t\t} else if (adj[0][j] == 0) {\n\t\t\t\tadj[0][j] = adj[0][0];\n\t\t\t} else {\n\t\t\t\tadj[0][j] = adj[0][0] < adj[0][j]? adj[0][0] : adj[0][j];\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor (int i = 1; i < m; ++i) {\n\t\t\tfor (int j = 0; j < n; ++j) {\n\t\t\t\tif (adj[i][j] == 0) {\n\t\t\t\t\tadj[i][j] = adj[0][j];\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\n\t__syncthreads();\n\tif (i == 0 && j == 0) {\n\t\tint largestComponent = 1;\n\t\tfor (int i = 1; i < m; ++i) {\n\t\t\tfor (int j = 1; j < n; ++j) {\n\t\t\t\tif (adj[i][j] > largestComponent) {\n\t\t\t\t\tlargestComponent = adj[i][j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t*largestComponentSize = largestComponent;\n\t}\n}",
            "int largestComponentSize_private = 0;\n    int n = blockIdx.x;\n    if (A[n*N + n]) {\n        largestComponentSize_private = dfs(A, n, N);\n    }\n    atomicMax(largestComponentSize, largestComponentSize_private);\n}",
            "extern __shared__ int shared[];\n    int *shared_adjacency = shared;\n    int *shared_visited = shared + N;\n    int *shared_levels = shared + 2 * N;\n    int *shared_components = shared + 3 * N;\n\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    int level = 0;\n\n    // Initialize shared arrays\n    if (tid < N) {\n        shared_visited[tid] = 0;\n        shared_levels[tid] = INT_MAX;\n        shared_components[tid] = tid;\n    }\n    __syncthreads();\n\n    for (int k = 0; k < N; k++) {\n        if (tid < N) {\n            shared_adjacency[tid] = A[tid * N + k];\n            shared_adjacency[k] = A[k * N + tid];\n        }\n        __syncthreads();\n\n        if (tid < N) {\n            if (shared_adjacency[tid]) {\n                level = max(level, shared_levels[tid] + 1);\n            }\n            if (shared_adjacency[k] && shared_levels[k] == INT_MAX) {\n                shared_levels[k] = level;\n                shared_components[k] = tid;\n            }\n        }\n        __syncthreads();\n    }\n\n    // Find the largest component\n    if (tid < N) {\n        if (shared_levels[tid]!= INT_MAX) {\n            shared_visited[tid] = 1;\n        }\n        __syncthreads();\n\n        int compId = INT_MAX;\n        for (int i = 0; i < N; i++) {\n            if (shared_visited[i]) {\n                compId = min(compId, shared_components[i]);\n            }\n        }\n        if (shared_visited[tid]) {\n            shared_components[tid] = compId;\n        }\n        __syncthreads();\n\n        int visited = 0;\n        for (int i = 0; i < N; i++) {\n            if (shared_components[i] == compId) {\n                shared_visited[i] = 1;\n                visited++;\n            }\n        }\n        __syncthreads();\n\n        if (tid == 0) {\n            atomicAdd(largestComponentSize, visited);\n        }\n    }\n}",
            "int *S;\n    S = (int *)malloc(N*sizeof(int));\n    int nThreads = gridDim.x * blockDim.x;\n    int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n    int i, j, size;\n    int parent, root, max;\n\n    // init\n    for(i = 0; i < N; i++) {\n        S[i] = i;\n    }\n\n    // find the root of each element\n    for(i = 0; i < N; i++) {\n        root = i;\n        while(S[root] < N) {\n            root = S[root];\n        }\n\n        // point all nodes to the root\n        for(j = 0; j < N; j++) {\n            parent = j;\n            while(S[parent] < N) {\n                parent = S[parent];\n            }\n\n            // check if root and parent are same\n            if(root == parent) {\n                continue;\n            }\n\n            // check if root is smaller\n            if(S[parent] > S[root]) {\n                S[parent] = S[root];\n            }\n        }\n    }\n\n    // count number of nodes that have root value as i\n    size = 0;\n    for(i = 0; i < N; i++) {\n        if(S[i] == i) {\n            size++;\n        }\n    }\n\n    // get the max of all sizes\n    max = size;\n    for(i = 0; i < nThreads; i++) {\n        if(max < atomicAdd(&S[i], 0)) {\n            max = atomicAdd(&S[i], 0);\n        }\n    }\n\n    // write the max to the memory location pointed by largestComponentSize\n    if(threadID == 0) {\n        *largestComponentSize = max;\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (i >= N || j >= N) {\n    return;\n  }\n\n  atomicMax(largestComponentSize, A[i*N + j] + A[j*N + i]);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (index < N*N) {\n    if (A[index]!= 0)\n      atomicAdd(largestComponentSize, 1);\n  }\n}",
            "__shared__ int componentSize[BLOCK_SIZE];\n  __shared__ int componentVisited[BLOCK_SIZE];\n\n  // Initialize the shared memory arrays\n  int i = blockIdx.x;\n  if (threadIdx.x == 0) {\n    componentSize[threadIdx.x] = 1;\n    componentVisited[threadIdx.x] = 0;\n  }\n  __syncthreads();\n\n  // Compute the number of vertices in the component rooted at i\n  if (i < N) {\n    int sum = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        sum++;\n      }\n    }\n    componentSize[threadIdx.x] = sum;\n  }\n  __syncthreads();\n\n  // Compute the sum of the number of vertices in each component\n  for (int offset = BLOCK_SIZE / 2; offset > 0; offset /= 2) {\n    if (threadIdx.x < offset) {\n      componentSize[threadIdx.x] += componentSize[threadIdx.x + offset];\n    }\n    __syncthreads();\n  }\n\n  // Store the result in the global memory\n  if (threadIdx.x == 0) {\n    atomicAdd(largestComponentSize, componentSize[0]);\n  }\n}",
            "__shared__ int scc[1024];\n\n\tint tid = threadIdx.x;\n\tint bid = blockIdx.x;\n\tint size = blockDim.x;\n\tint index = bid * size + tid;\n\tscc[tid] = 0;\n\n\t__syncthreads();\n\tif (index < N) {\n\t\tint row = index;\n\t\tint col = A[index];\n\t\t// Perform a breadth-first search starting at index\n\t\twhile (col >= 0) {\n\t\t\tint next = A[col];\n\t\t\tA[col] = -1;\n\t\t\tcol = next;\n\t\t}\n\n\t\t// Mark all vertices in the SCC with a negative value\n\t\tint curr = A[row];\n\t\twhile (curr >= 0) {\n\t\t\tscc[tid] = 1;\n\t\t\tint next = A[curr];\n\t\t\tA[curr] = -1;\n\t\t\tcurr = next;\n\t\t}\n\n\t\t// Find the max value in the SCC\n\t\tint max = scc[tid];\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tmax = (scc[i] > max)? scc[i] : max;\n\t\t}\n\n\t\t// Reduction to get the max value\n\t\tfor (int i = size / 2; i > 0; i /= 2) {\n\t\t\tif (tid < i)\n\t\t\t\tmax = (max > scc[tid + i])? max : scc[tid + i];\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\n\t// Store the largest component size\n\tif (tid == 0) {\n\t\t*largestComponentSize = max;\n\t}\n}",
            "const int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    const int x = tid / N;\n    const int y = tid % N;\n    const int id = y * N + x;\n    if (tid >= N * N) return;\n    if (x == y) {\n        atomicAdd(largestComponentSize, A[id]!= 0? 1 : 0);\n    } else {\n        atomicMin(&A[id], A[y * N + x]!= 0? 0 : 1);\n    }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n  int numVertices = N;\n\n  __shared__ int componentSizes[CUDA_MAX_GRID_SIZE];\n  __shared__ int componentSizesAccum[CUDA_MAX_GRID_SIZE];\n\n  if(index < numVertices) {\n    int currentVertexComponentSize = 0;\n\n    for(int i = 0; i < numVertices; i++) {\n      if(A[index + (i * numVertices)] == 1) {\n        currentVertexComponentSize += 1;\n      }\n    }\n\n    componentSizes[threadIdx.x] = currentVertexComponentSize;\n    componentSizesAccum[threadIdx.x] = 0;\n  }\n\n  __syncthreads();\n\n  if(threadIdx.x < numVertices) {\n    for(int stride = 1; stride < blockDim.x; stride <<= 1) {\n      __syncthreads();\n\n      if((threadIdx.x & stride) == 0 && threadIdx.x + stride < numVertices) {\n        componentSizesAccum[threadIdx.x] += componentSizes[threadIdx.x + stride];\n      }\n    }\n\n    __syncthreads();\n\n    if(threadIdx.x == 0) {\n      *largestComponentSize = *largestComponentSize < componentSizesAccum[0]? componentSizesAccum[0] : *largestComponentSize;\n    }\n  }\n}",
            "// TODO: Complete this code\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i >= N || j >= N)\n        return;\n\n    if (A[i * N + j] == 1) {\n        atomicMin(largestComponentSize, N - 1);\n        return;\n    }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index >= N) {\n        return;\n    }\n    int value = 0;\n    for (int i = 0; i < N; ++i) {\n        if (A[index * N + i]) {\n            value++;\n        }\n    }\n    atomicMax(largestComponentSize, value);\n}",
            "// __shared__ int visited[N];\n\t__shared__ int localVisited[BLOCK_SIZE];\n\t__shared__ int componentSize[BLOCK_SIZE];\n\t__shared__ int componentId[BLOCK_SIZE];\n\t__shared__ int numComponents;\n\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint bid = blockIdx.x;\n\tint i;\n\n\t// Each thread looks at 1 vertex\n\tif(tid < N) {\n\t\t// Initialize visited array for each vertex\n\t\t// visited[tid] = 0;\n\t\tlocalVisited[threadIdx.x] = 0;\n\t\tcomponentSize[threadIdx.x] = 0;\n\t\tcomponentId[threadIdx.x] = 0;\n\n\t\tfor(i = 0; i < N; ++i) {\n\t\t\t// If vertex has not been visited and there is an edge, mark visited and add to the component size\n\t\t\tif(localVisited[threadIdx.x] == 0 && A[tid + i*N] == 1) {\n\t\t\t\tlocalVisited[threadIdx.x] = 1;\n\t\t\t\tcomponentSize[threadIdx.x]++;\n\t\t\t}\n\t\t}\n\n\t\t// Compute the maximum component size\n\t\tfor(i = 1; i < blockDim.x; ++i) {\n\t\t\tif(componentSize[i] > componentSize[0]) {\n\t\t\t\tcomponentSize[0] = componentSize[i];\n\t\t\t\tcomponentId[0] = i;\n\t\t\t}\n\t\t}\n\n\t\tif(threadIdx.x == 0) {\n\t\t\tnumComponents = 0;\n\t\t}\n\n\t\t// Set the current number of components\n\t\tatomicAdd(&numComponents, 1);\n\n\t\t// Synchronize to make sure each thread has finished calculating its component size\n\t\t__syncthreads();\n\n\t\t// Thread 0 stores the maximum component size\n\t\tif(threadIdx.x == 0) {\n\t\t\t*largestComponentSize = componentSize[0];\n\t\t}\n\t}\n}",
            "const int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Each thread processes a single cell in the adjacency matrix\n\tif (row < N && col < N && A[row*N+col]!= 0) {\n\t\t// Find the size of the largest component in the current cell\n\t\tint size = 0;\n\t\tint start = row*N+col;\n\t\tint *visited = (int *)calloc(N*N, sizeof(int));\n\n\t\t// Use a stack to process the graph in depth-first order\n\t\t// The stack contains the starting vertex of a connected component\n\t\tint *stack = (int *)malloc(N*N*sizeof(int));\n\t\tint top = 0;\n\t\tstack[top] = start;\n\t\tvisited[start] = 1;\n\n\t\t// Process all the connected components in the current cell\n\t\twhile (top!= -1) {\n\t\t\t// Get the starting vertex of the current connected component\n\t\t\tstart = stack[top];\n\n\t\t\t// Search adjacent vertices\n\t\t\t// If the vertex has not been visited, push it to the stack and mark it as visited\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tint adj = row*N+k;\n\t\t\t\tif (A[start*N+k]!= 0 &&!visited[adj]) {\n\t\t\t\t\tvisited[adj] = 1;\n\t\t\t\t\ttop++;\n\t\t\t\t\tstack[top] = adj;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Remove the starting vertex from the stack\n\t\t\ttop--;\n\t\t}\n\t\t// Store the size of the largest component in the current cell\n\t\tsize = *max_element(visited, visited+N*N);\n\t\tatomicMax(largestComponentSize, size);\n\n\t\t// Free the memory\n\t\tfree(stack);\n\t\tfree(visited);\n\t}\n}",
            "// TODO\n}",
            "// TODO\n\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  int tid = threadIdx.x;\n  __shared__ int component[256];\n  __shared__ int sdata[256];\n\n  if (idx < N) {\n    component[tid] = -1;\n    sdata[tid] = 0;\n  }\n  __syncthreads();\n\n  if (idx < N) {\n    int index = 0;\n    int n = A[idx + N*idx];\n    int start = 0;\n    int end = N;\n    int maxSize = 0;\n    while(start < end) {\n      int mid = (start + end) / 2;\n      if (A[idx + N*mid] > n) {\n        end = mid;\n      } else {\n        start = mid + 1;\n      }\n    }\n    component[tid] = start;\n    __syncthreads();\n\n    if (tid == 0) {\n      int minIndex = component[0];\n      for (int i = 1; i < blockDim.x; i++) {\n        if (component[i] < minIndex) {\n          minIndex = component[i];\n        }\n      }\n      component[0] = minIndex;\n      for (int i = 1; i < blockDim.x; i++) {\n        if (component[i] == minIndex) {\n          sdata[i] = 1;\n        }\n      }\n    }\n    __syncthreads();\n\n    if (tid == 0) {\n      for (int i = 0; i < blockDim.x; i++) {\n        if (sdata[i] == 1) {\n          sdata[i] = 0;\n        }\n      }\n    }\n    __syncthreads();\n\n    int size = 1;\n    for (int i = 0; i < blockDim.x; i++) {\n      if (component[i] == minIndex) {\n        sdata[i] = 1;\n        size++;\n      }\n    }\n    __syncthreads();\n\n    for (int i = 0; i < blockDim.x; i++) {\n      if (sdata[i] == 1) {\n        sdata[i] = 0;\n      }\n    }\n    __syncthreads();\n\n    if (tid == 0) {\n      maxSize = size;\n    }\n    __syncthreads();\n\n    int sum = 0;\n    for (int i = 0; i < blockDim.x; i++) {\n      sum += sdata[i];\n    }\n    __syncthreads();\n\n    if (tid == 0) {\n      if (maxSize == sum) {\n        *largestComponentSize = sum;\n      }\n    }\n  }\n}",
            "__shared__ int data[BLOCK_SIZE][BLOCK_SIZE + 1];\n\n\tconst int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tconst int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (i < N && j < N) {\n\t\tdata[threadIdx.y][threadIdx.x] = A[i * N + j];\n\t}\n\n\t__syncthreads();\n\n\tif (i >= N || j >= N || i == j) {\n\t\treturn;\n\t}\n\n\tint value = 0;\n\n\tfor (int k = 0; k < BLOCK_SIZE; k++) {\n\t\tvalue |= data[threadIdx.x][k] & data[k][threadIdx.y];\n\t}\n\n\tatomicMax(largestComponentSize, value);\n}",
            "__shared__ int scc[SCC_BLOCK_SIZE];\n  __shared__ bool mark[SCC_BLOCK_SIZE];\n  __shared__ bool mark2[SCC_BLOCK_SIZE];\n  __shared__ int id[SCC_BLOCK_SIZE];\n  __shared__ int size[SCC_BLOCK_SIZE];\n  __shared__ int *adj_list;\n\n  int blockSize = blockDim.x;\n  int tid = threadIdx.x;\n  int i, u, v, start, end;\n\n  // Compute the size of the connected component containing v\n  int compSize(int v) {\n    mark2[tid] = false;\n    int cnt = 1;\n    mark[tid] = true;\n    scc[tid] = v;\n    __syncthreads();\n    // Traverse the adjacency list of v, marking each vertex in the scc and\n    // increasing the size of the scc\n    for (i = 0; i < blockSize; i++) {\n      v = scc[i];\n      if (v!= -1 &&!mark2[i]) {\n        start = A[N * v + v];\n        end = A[N * v + v + 1];\n        for (u = start; u < end; u++) {\n          if (!mark[id[u]]) {\n            scc[i] = id[u];\n            mark[id[u]] = true;\n            cnt++;\n            break;\n          }\n        }\n        mark2[i] = true;\n      }\n    }\n    __syncthreads();\n    return cnt;\n  }\n\n  // Find the largest scc in the graph\n  int maxComp = 0;\n  int maxCompId = -1;\n  for (i = 0; i < blockSize; i++) {\n    if (mark[i]) {\n      int tmp = compSize(i);\n      if (tmp > maxComp) {\n        maxComp = tmp;\n        maxCompId = i;\n      }\n    }\n  }\n  __syncthreads();\n  if (maxCompId == tid) {\n    *largestComponentSize = maxComp;\n  }\n}",
            "// TODO: Your code here\n    extern __shared__ int shared_a[];\n    int bsize = blockDim.x;\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n    int offset = bid * bsize;\n    //shared_a[tid] = A[offset + tid];\n    //__syncthreads();\n    int cnt = 0;\n    for (int i = 0; i < bsize; i++) {\n        shared_a[i] = A[offset + i];\n        if (shared_a[i] == 1) cnt++;\n    }\n    __syncthreads();\n    for (int i = 1; i < bsize; i <<= 1) {\n        if (tid >= i) {\n            shared_a[tid] = (shared_a[tid] == 1 || shared_a[tid - i] == 1);\n        }\n        __syncthreads();\n    }\n    //if (tid == 0) shared_a[0] = 1;\n    //__syncthreads();\n    if (shared_a[0] == 1) atomicAdd(largestComponentSize, 1);\n}",
            "const int vertex = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int gridSize = blockDim.x * gridDim.x;\n\tconst int globalVertex = vertex + gridSize;\n\n\tif (globalVertex >= N)\n\t\treturn;\n\n\tint vertexComponent = vertex;\n\tbool visited[N];\n\tint numVisited = 0;\n\n\tif (vertexComponent >= N)\n\t\treturn;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = false;\n\t}\n\n\tvisited[vertexComponent] = true;\n\tnumVisited = 1;\n\n\twhile (vertexComponent < N && numVisited < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[vertexComponent * N + j] == 1 &&!visited[j]) {\n\t\t\t\tvisited[j] = true;\n\t\t\t\tnumVisited++;\n\t\t\t\tvertexComponent = j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(largestComponentSize, numVisited);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\t__shared__ int numVisited;\n\t__shared__ int largest;\n\n\t// TODO: use shared memory to store the number of visited nodes and the current size of the largest component\n\n\tfor (int i = tid; i < N; i += stride) {\n\t\tint count = 0;\n\t\tint c = 1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\t// TODO: set largest to the largest component size of the current thread's subgraph\n\t\t\n\t}\n\n\t// TODO: use atomicAdd to update the number of visited nodes\n\t// TODO: use atomicMax to update the largest component size\n\n\t// Write the result to global memory\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = largest;\n\t}\n}",
            "const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int count = 0;\n    if (x >= N || y >= N) {\n        return;\n    }\n\n    if (A[x + y * N]) {\n        int tmp = 1;\n        if (x < N - 1 && A[x + 1 + y * N]) {\n            tmp++;\n        }\n        if (x > 0 && A[x - 1 + y * N]) {\n            tmp++;\n        }\n        if (y < N - 1 && A[x + (y + 1) * N]) {\n            tmp++;\n        }\n        if (y > 0 && A[x + (y - 1) * N]) {\n            tmp++;\n        }\n        atomicAdd(largestComponentSize, tmp);\n    }\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n    if(id >= N) {\n        return;\n    }\n    int cSize = 0;\n    for(int i = 0; i < N; i++) {\n        cSize += A[id*N + i];\n    }\n    if(cSize > *largestComponentSize) {\n        *largestComponentSize = cSize;\n    }\n}",
            "// 2D thread index (within the 2D grid)\n  int x = threadIdx.x + blockDim.x * blockIdx.x;\n  int y = threadIdx.y + blockDim.y * blockIdx.y;\n  // if (x == 0 && y == 0) {\n  //   printf(\"threadIdx: (%d, %d), blockIdx: (%d, %d), blockDim: (%d, %d), gridDim: (%d, %d)\\n\",\n  //          threadIdx.x, threadIdx.y, blockIdx.x, blockIdx.y, blockDim.x, blockDim.y, gridDim.x, gridDim.y);\n  // }\n  if (x >= N || y >= N) return;\n  int index = x * N + y;\n  if (x == y) {\n    if (A[index] == 0) {\n      atomicMin(largestComponentSize, 0);\n    }\n    else {\n      atomicMin(largestComponentSize, A[index]);\n    }\n    return;\n  }\n\n  if (A[index] == 1) {\n    atomicAdd(largestComponentSize, 1);\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        int j, isRoot = 1;\n        // Loop over all the vertices.\n        for (j = 0; j < N; j++) {\n            // If the vertex is not the same as the current vertex\n            // and it has a higher value, then the vertex is part of a\n            // different connected component.\n            if (A[N * i + j] && i!= j) {\n                isRoot = 0;\n                break;\n            }\n        }\n\n        // Atomically increment the result if the vertex is part of\n        // the largest connected component.\n        if (isRoot) {\n            atomicAdd(largestComponentSize, 1);\n        }\n    }\n}",
            "int x = blockIdx.x;\n    int y = blockIdx.y;\n    if (x < N && y < N && A[x + y * N]) {\n        atomicAdd(largestComponentSize, 1);\n    }\n}",
            "// Fill this in.\n\n}",
            "__shared__ int sdata[BLOCK_SIZE];\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  sdata[threadIdx.x] = A[i * N + i];\n  __syncthreads();\n  for (unsigned int s = BLOCK_SIZE / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      sdata[threadIdx.x] = sdata[threadIdx.x] + sdata[threadIdx.x + s];\n    }\n    __syncthreads();\n  }\n  if (threadIdx.x == 0)\n    atomicAdd(largestComponentSize, sdata[0]);\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i == j) {\n\t\t// This thread will calculate the largest component size.\n\t\t// The largest component size is the number of vertices in the largest strongly connected component.\n\t\t// We use a flood-fill algorithm to determine the largest strongly connected component of the graph.\n\t\t// This algorithm works by starting at the vertex with the largest out-degree and flooding from there.\n\t\t// In other words, we start at the largest vertex and flood from there.\n\t\t// We flood in both directions, in and out.\n\t\t// We use a stack to keep track of the vertices we've already flooded.\n\t\t// A vertex is marked \"visited\" when it is pushed on the stack.\n\n\t\tint largestComponentSize = 0;\n\t\tint stackSize = 0;\n\t\tint stack[N];\n\t\tint visited[N] = { 0 };\n\n\t\t// We will start by looking at the vertex with the largest out-degree.\n\t\tint largestIndex = 0;\n\t\tfor (int i = 1; i < N; ++i) {\n\t\t\tif (A[i * N + i] > A[largestIndex * N + largestIndex]) {\n\t\t\t\tlargestIndex = i;\n\t\t\t}\n\t\t}\n\n\t\t// Push the vertex with the largest out-degree on the stack.\n\t\tstack[stackSize] = largestIndex;\n\t\tvisited[largestIndex] = 1;\n\t\t++stackSize;\n\n\t\t// Loop while there is more in the stack.\n\t\twhile (stackSize > 0) {\n\t\t\t// Pop a vertex off the stack.\n\t\t\tint index = stack[--stackSize];\n\t\t\tlargestComponentSize++;\n\n\t\t\t// Flood in both directions.\n\t\t\t// Flood out.\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t// If the vertex has not been visited and there is an edge from index to j, then push j on the stack.\n\t\t\t\tif (A[index * N + j] &&!visited[j]) {\n\t\t\t\t\tstack[stackSize] = j;\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t++stackSize;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Flood in.\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\t// If the vertex has not been visited and there is an edge from i to index, then push i on the stack.\n\t\t\t\tif (A[i * N + index] &&!visited[i]) {\n\t\t\t\t\tstack[stackSize] = i;\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\t++stackSize;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Write the result.\n\t\t*largestComponentSize = largestComponentSize;\n\t}\n}",
            "extern __shared__ int sharedA[];\n\n\tconst int *sA = sharedA + blockDim.x*blockIdx.y;\n\tint *sAx = sharedA + blockDim.x*blockIdx.y + threadIdx.x;\n\n\tif(threadIdx.x < N) sA[threadIdx.x] = A[threadIdx.x*N+blockIdx.y];\n\t__syncthreads();\n\n\tfor(int i = 0; i < N; i++) {\n\t\tif(sAx[i] > 0) {\n\t\t\tsAx[i] = 0;\n\t\t\tif(threadIdx.x < N)\n\t\t\t\tfor(int j = 0; j < N; j++)\n\t\t\t\t\tsAx[i] += sA[j];\n\t\t\t__syncthreads();\n\n\t\t\tif(threadIdx.x == 0) atomicAdd(largestComponentSize, 1);\n\t\t\tbreak;\n\t\t}\n\t}\n}",
            "int i, j;\n    int nComponents = 0;\n    int componentSize = 0;\n    for(i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {\n        bool hasComponent = false;\n        for(j = 0; j < N; j++) {\n            if (A[i + j * N] == 1) {\n                hasComponent = true;\n                break;\n            }\n        }\n        if (hasComponent) {\n            nComponents++;\n            componentSize = 0;\n            for(j = 0; j < N; j++) {\n                if (A[j + i * N] == 1) {\n                    componentSize++;\n                }\n            }\n            if (componentSize > *largestComponentSize) {\n                *largestComponentSize = componentSize;\n            }\n        }\n    }\n    __syncthreads();\n}",
            "const int row = blockIdx.x;\n\tconst int col = threadIdx.x;\n\n\t// shared memory to store the current size of the largest component\n\textern __shared__ int sharedComponentSize[];\n\tsharedComponentSize[threadIdx.x] = 0;\n\n\t// synchronize threads in the block\n\t__syncthreads();\n\n\t// each thread checks to see if the value at (row, col) is 1. If it is, then the thread will\n\t// add 1 to the size of the largest component. If the size of the largest component exceeds\n\t// the size of the component the thread currently has, then the thread will replace the size\n\t// of the largest component with its own component size.\n\tif (A[row * N + col] == 1) {\n\t\t// if the size of the largest component is less than the thread's size, then the largest\n\t\t// component size is updated to be the thread's size.\n\t\tif (sharedComponentSize[col] < sharedComponentSize[row]) {\n\t\t\tsharedComponentSize[col] = sharedComponentSize[row];\n\t\t}\n\t\tsharedComponentSize[col] += 1;\n\t}\n\n\t// synchronize threads in the block\n\t__syncthreads();\n\n\t// if the thread has the largest component size, then copy its value to the array containing\n\t// the largest component size.\n\tif (sharedComponentSize[row] == sharedComponentSize[col]) {\n\t\tatomicMax(largestComponentSize, sharedComponentSize[row]);\n\t}\n}",
            "const int r = blockIdx.x * blockDim.x + threadIdx.x;\n    const int c = blockIdx.y * blockDim.y + threadIdx.y;\n    if (r >= N || c >= N)\n        return;\n    __shared__ int S[BLOCKDIM][BLOCKDIM];\n    if (A[r * N + c] > 0) {\n        S[threadIdx.y][threadIdx.x] = 1;\n        __syncthreads();\n        for (int i = 0; i < N; i++)\n            if (S[threadIdx.y][threadIdx.x] > 0 && i!= r && i!= c)\n                S[threadIdx.y][threadIdx.x] += S[threadIdx.y][i] + S[i][threadIdx.x];\n        __syncthreads();\n        atomicMax(largestComponentSize, S[threadIdx.y][threadIdx.x]);\n    }\n}",
            "int tid = blockDim.x * blockIdx.y * gridDim.x\t//rows preceeding current row in grid\n\t\t+ blockDim.x * blockIdx.x\t\t\t\t//blocks preceeding current block\n\t\t+ threadIdx.x;\n\n\tif (tid >= N) return;\n\n\t// if tid is not reachable from itself, it is in a separate component\n\tif (!A[tid * N + tid]) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "__shared__ int cache[1024];\n\tcache[threadIdx.x] = 0;\n\n\tint mySize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[blockIdx.x * N + i] == 1) {\n\t\t\tmySize += 1;\n\t\t}\n\t}\n\n\t__syncthreads();\n\tatomicAdd(cache + threadIdx.x, mySize);\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tfor (int i = 1; i < blockDim.x; i++) {\n\t\t\tcache[0] = max(cache[0], cache[i]);\n\t\t}\n\t\t*largestComponentSize = cache[0];\n\t}\n}",
            "// Each thread handles a vertex\n\tconst int id = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// Find the largest connected component\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[id * N + i]) {\n\t\t\t// Increment the value at position i\n\t\t\tatomicAdd(A + i * N + i, 1);\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i * N + id]) {\n\t\t\t// Increment the value at position id\n\t\t\tatomicAdd(A + id * N + id, 1);\n\t\t}\n\t}\n\n\tmax = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[id * N + i] > max) {\n\t\t\tmax = A[id * N + i];\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i * N + id] > max) {\n\t\t\tmax = A[i * N + id];\n\t\t}\n\t}\n\n\tatomicAdd(largestComponentSize, max);\n}",
            "__shared__ int adj[BLOCKDIM][BLOCKDIM];\n\t__shared__ int visited[BLOCKDIM][BLOCKDIM];\n\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint row = ty + by*blockDim.y;\n\tint col = tx + bx*blockDim.x;\n\n\tadj[ty][tx] = A[row*N + col];\n\n\t__syncthreads();\n\n\tif (row < N && col < N) {\n\t\tint row_size = 0, col_size = 0;\n\t\tbool b = false;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (adj[row][i]) {\n\t\t\t\trow_size++;\n\t\t\t}\n\t\t\tif (adj[i][col]) {\n\t\t\t\tcol_size++;\n\t\t\t}\n\t\t}\n\n\t\tif (row_size > 1 || col_size > 1) {\n\t\t\tb = true;\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tvisited[ty][tx] = b;\n\t\t__syncthreads();\n\n\t\tif (visited[ty][tx]) {\n\t\t\tif (row < col) {\n\t\t\t\tif (!visited[col][row]) {\n\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\t\tif (adj[i][row]) {\n\t\t\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (adj[i][col]) {\n\t\t\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (row > col) {\n\t\t\t\tif (!visited[row][col]) {\n\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\t\tif (adj[i][row]) {\n\t\t\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (adj[i][col]) {\n\t\t\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (adj[i][row]) {\n\t\t\t\t\t\tatomicAdd(largestComponentSize, 2);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint pos = i * N + j;\n\tif (i < N && j < N) {\n\t\tatomicAdd(largestComponentSize, (A[pos] == 1));\n\t}\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n\tint num_th = blockDim.x*gridDim.x;\n\tint *visited = (int *)malloc(N*sizeof(int));\n\tfor(int i=0; i<N; i++)\n\t\tvisited[i] = -1;\n\tint largestComponentSize = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(visited[i] == -1) {\n\t\t\tint size = 0;\n\t\t\tdfs(A, N, i, visited, &size);\n\t\t\tlargestComponentSize = max(largestComponentSize, size);\n\t\t}\n\t}\n\t*largestComponentSize = largestComponentSize;\n}",
            "__shared__ int sdata[N];\n\n\tint idx = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\t// Initialize the local block data.\n\tsdata[threadIdx.x] = A[idx];\n\n\t// Loop through the elements in the block.\n\tfor (int i = idx + stride; i < N; i += stride) {\n\t\tsdata[threadIdx.x] |= A[i];\n\t}\n\n\t// Ensure all data is ready for next reduction.\n\t__syncthreads();\n\n\t// Perform reduction.\n\tfor (int i = blockDim.x / 2; i >= 1; i >>= 1) {\n\t\tif (threadIdx.x < i) {\n\t\t\tsdata[threadIdx.x] |= sdata[threadIdx.x + i];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(largestComponentSize, __popc(sdata[0]));\n\t}\n}",
            "unsigned int x = blockIdx.x;\n\tunsigned int y = blockIdx.y;\n\tunsigned int z = threadIdx.z;\n\tunsigned int i = blockIdx.z * blockDim.z + threadIdx.z;\n\n\tif (i == 0)\n\t\t*largestComponentSize = 0;\n\n\t__shared__ int componentSize[BLOCKDIM_Z];\n\tcomponentSize[i] = 0;\n\n\t// Traverse the adjacency matrix\n\tif (x < N && y < N) {\n\t\tif (A[x * N + y]) {\n\t\t\tcomponentSize[i] = 1;\n\t\t}\n\t}\n\n\t// Block-wise reduction\n\t__syncthreads();\n\tif (i < 16) {\n\t\tcomponentSize[i] += componentSize[i + 16];\n\t}\n\t__syncthreads();\n\tif (i < 8) {\n\t\tcomponentSize[i] += componentSize[i + 8];\n\t}\n\t__syncthreads();\n\tif (i < 4) {\n\t\tcomponentSize[i] += componentSize[i + 4];\n\t}\n\t__syncthreads();\n\tif (i < 2) {\n\t\tcomponentSize[i] += componentSize[i + 2];\n\t}\n\t__syncthreads();\n\tif (i < 1) {\n\t\tcomponentSize[i] += componentSize[i + 1];\n\t}\n\t__syncthreads();\n\n\t// Store the result in the first element of the componentSize array\n\tif (i == 0) {\n\t\tatomicAdd(largestComponentSize, componentSize[0]);\n\t}\n}",
            "int tx = threadIdx.x; // thread index in x-direction\n\tint ty = threadIdx.y; // thread index in y-direction\n\n\t// Declare shared memory for adjacency matrix (it's NxN)\n\t// The shared memory is used to store the rows of the adjacency matrix that this thread block\n\t// is responsible for\n\t__shared__ int adjMatrix[TILE_DIM][TILE_DIM];\n\n\tint currentVertexIndex = tx + ty * blockDim.x;\n\n\t// If the thread is not within the bounds of the adjacency matrix then\n\t// it is not responsible for any computation. It may as well return.\n\tif (currentVertexIndex >= N) {\n\t\treturn;\n\t}\n\n\t// The adjacency matrix is a square matrix with size NxN. The threads are organized in\n\t// blocks with size NxN. Each block processes one tile of the adjacency matrix.\n\t// Each thread within a block can process one row of the tile.\n\t// The blocks are organized in a 2-dimensional grid of size NxN.\n\t// The grid has one block per tile, so the total number of blocks is equal to the\n\t// number of tiles in the adjacency matrix.\n\t//\n\t// The grid needs to know which tile it is responsible for. The blocks are distributed\n\t// such that the first block is responsible for the tile in the upper left corner, the\n\t// second block is responsible for the tile in the upper right corner, the third block\n\t// is responsible for the tile in the lower left corner, etc.\n\t//\n\t// In order to know which tile it is responsible for, the grid needs to know\n\t// in which row and column it is located.\n\t//\n\t// First, determine the row in which the block is located\n\tint tileRowIndex = ty;\n\t// Then, determine the column in which the block is located\n\tint tileColumnIndex = tx;\n\n\t// Determine the offset into the adjacency matrix where this block's tile starts\n\tint adjMatrixTileStart = tileRowIndex * N + tileColumnIndex;\n\t// Determine the offset into the adjacency matrix where this block's tile ends\n\tint adjMatrixTileEnd = adjMatrixTileStart + TILE_DIM;\n\n\t// Load the rows of the adjacency matrix that this block is responsible for into shared memory\n\tint i = 0;\n\tfor (int j = adjMatrixTileStart; j < adjMatrixTileEnd; j++) {\n\t\tadjMatrix[ty][i] = A[j * N + currentVertexIndex];\n\t\ti++;\n\t}\n\t// Synchronize to ensure all the data has been loaded into the shared memory before\n\t// continuing\n\t__syncthreads();\n\n\t// Check if the current vertex is connected to any other vertex in its row\n\tint anyNeighboursInRow = 0;\n\tfor (int i = 0; i < TILE_DIM; i++) {\n\t\tif (adjMatrix[ty][i]!= 0) {\n\t\t\tanyNeighboursInRow = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Check if the current vertex is connected to any other vertex in its column\n\tint anyNeighboursInCol = 0;\n\tfor (int i = 0; i < TILE_DIM; i++) {\n\t\tif (adjMatrix[i][tx]!= 0) {\n\t\t\tanyNeighboursInCol = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// If the current vertex is not connected to any other vertex in its row or column,\n\t// then it is part of the largest connected component.\n\t// (The current vertex itself is not included in the adjacency matrix, so the current\n\t// vertex index is not considered part of the adjacency matrix)\n\t// Use atomicAdd to ensure all threads in the block are able to write to\n\t// largestComponentSize\n\tif (anyNeighboursInRow == 0 && anyNeighboursInCol == 0) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "__shared__ int largestComponent[256];\n  __shared__ int numThreadsInLargestComponent;\n\n  // Initialize the shared memory\n  if (threadIdx.x == 0) {\n    *largestComponentSize = 0;\n    numThreadsInLargestComponent = 0;\n  }\n  __syncthreads();\n\n  // Find the largest component size\n  for (int i = 0; i < N; i++) {\n    if (A[blockIdx.x * N + i] == 1 && A[blockIdx.x * N + blockIdx.x] == 0) {\n      atomicAdd(&numThreadsInLargestComponent, 1);\n    }\n  }\n  __syncthreads();\n\n  if (numThreadsInLargestComponent > *largestComponentSize) {\n    largestComponent[threadIdx.x] = numThreadsInLargestComponent;\n  } else {\n    largestComponent[threadIdx.x] = 0;\n  }\n  __syncthreads();\n\n  // Reduce the largest component size\n  for (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n    if (threadIdx.x < offset) {\n      largestComponent[threadIdx.x] += largestComponent[threadIdx.x + offset];\n    }\n    __syncthreads();\n  }\n\n  // Store the result\n  if (threadIdx.x == 0) {\n    *largestComponentSize = largestComponent[0];\n  }\n  __syncthreads();\n}",
            "// TODO: Implement this function\n}",
            "int row = blockIdx.x;\n  int col = blockIdx.y;\n  int thread = threadIdx.x;\n  int threadsPerRow = blockDim.x;\n\n  // Each thread in the block performs one pass through the matrix\n  // This is a \"triangle\" pass:\n  // The first thread processes A[0][1].\n  // The next thread processes A[1][2], and so on.\n  // The last thread processes A[N-2][N-1]\n  if (row < N && col < N && thread < N && thread < N - row && col < N - thread) {\n    // Each thread checks if A[row][col] is connected to a vertex in the largest component.\n    // If the vertex is connected, it finds the size of the largest component.\n    if (A[row * N + col] == 1) {\n      // Process the other row elements (in the row that vertex A[row][col] belongs to).\n      for (int i = row + 1; i < N; i++) {\n        // Each thread processes one element (row and column) at a time.\n        if (A[row * N + i] == 1) {\n          // Update largestComponentSize to be the maximum of the two.\n          atomicMax(largestComponentSize, i - row);\n        }\n      }\n\n      // Process the other column elements (in the column that vertex A[row][col] belongs to).\n      for (int i = col + 1; i < N; i++) {\n        // Each thread processes one element (row and column) at a time.\n        if (A[i * N + col] == 1) {\n          // Update largestComponentSize to be the maximum of the two.\n          atomicMax(largestComponentSize, i - col);\n        }\n      }\n    }\n  }\n}",
            "// TODO\n\n\t// 1. Find the index of the current thread in the 2D grid (i,j)\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// 2. Find the size of the largest connected component\n\t//    (i.e., the largest size of a component of which node i is a member)\n\tint maxSize = 0;\n\tfor (int k = 0; k < N; k++)\n\t\tmaxSize = max(maxSize, connectedComponentSize(A, N, i, k));\n\n\t// 3. Find the largest connected component\n\tint largestComponent = 0;\n\tfor (int k = 0; k < N; k++)\n\t\tlargestComponent += connectedComponentSize(A, N, i, k) == maxSize;\n\n\t// 4. Store the size of the largest connected component\n\t//    in the largestComponentSize variable\n\t//    (Hint: use atomic functions to increment the variable)\n\tatomicAdd(largestComponentSize, largestComponent);\n}",
            "int x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint r = threadIdx.x;\n\tint c = threadIdx.y;\n\n\t__shared__ int B[BLOCK_SIZE][BLOCK_SIZE];\n\n\tB[r][c] = A[x * N + y];\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < BLOCK_SIZE; i += WARP_SIZE) {\n\t\tfor (int j = 0; j < BLOCK_SIZE; j += WARP_SIZE) {\n\t\t\tif (B[r][c] == B[i][j]) {\n\t\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t\t\tB[r][c] = 0;\n\t\t\t}\n\t\t}\n\t}\n}",
            "const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx >= N)\n        return;\n    __shared__ int visited[1024];\n    visited[threadIdx.x] = 0;\n    __syncthreads();\n    int s = idx;\n    while (A[s * N + s] == 0) {\n        s = visited[s];\n    }\n    visited[idx] = s;\n    for (int i = idx + blockDim.x; i < N; i += blockDim.x) {\n        if (A[i * N + s]!= 0) {\n            visited[i] = s;\n        }\n    }\n    __syncthreads();\n    int localLargestComponentSize = 0;\n    for (int i = 0; i < N; i++) {\n        if (A[i * N + visited[i]]!= 0) {\n            localLargestComponentSize += 1;\n        }\n    }\n    atomicAdd(largestComponentSize, localLargestComponentSize);\n}",
            "// TODO\n\n}",
            "// TODO: Implement\n  int i = blockIdx.x*blockDim.x + threadIdx.x;\n  if (i < N) {\n    int componentCount = 1;\n    int adjacents[2];\n    adjacents[0] = i;\n    int numAdjacents = 1;\n    while (numAdjacents!= 0) {\n      int temp = numAdjacents;\n      numAdjacents = 0;\n      for (int j = 0; j < temp; j++) {\n        int adj = adjacents[j];\n        for (int k = 0; k < N; k++) {\n          if (A[adj*N + k] == 1) {\n            if (adj!= k && componentCount > 1) {\n              componentCount--;\n            }\n            adjacents[numAdjacents] = k;\n            numAdjacents++;\n          }\n        }\n      }\n    }\n    if (componentCount > *largestComponentSize) {\n      *largestComponentSize = componentCount;\n    }\n  }\n}",
            "// your code here\n}",
            "__shared__ int scc[BLOCKSIZE];\n\t__shared__ bool marked[BLOCKSIZE];\n\n\tint id = threadIdx.x + blockIdx.x*blockDim.x;\n\n\tif (id < N) {\n\n\t\tint componentSize = 0;\n\n\t\tif (!marked[id]) {\n\t\t\tmarked[id] = true;\n\t\t\tscc[id] = id;\n\t\t\tcomponentSize = 1;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[id*N + i]) {\n\t\t\t\t\tcomponentSize += scc[i];\n\t\t\t\t\tscc[id] = scc[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (marked[id] && scc[id] == id) {\n\t\t\tcomponentSize = 1;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[id*N + i]) {\n\t\t\t\t\tcomponentSize += scc[i];\n\t\t\t\t\tscc[id] = scc[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tatomicAdd(largestComponentSize, componentSize);\n\t}\n}",
            "const unsigned int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst unsigned int col = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst unsigned int offset = row * N + col;\n\tif (row >= N || col >= N || row == col)\n\t\treturn;\n\tif (A[offset] == 1)\n\t\tatomicMin(largestComponentSize, largestComponent(A, N, row, col));\n}",
            "int id = blockDim.x * blockIdx.y + threadIdx.x;\n\n  if (id >= N) return;\n\n  // Auxiliary variables\n  int index = id, auxIndex = id;\n  int maxSize = 0;\n  int size = 0;\n\n  do {\n    index = A[id * N + index];\n    size++;\n  } while (index!= -1 && index!= id);\n\n  if (size > maxSize) maxSize = size;\n\n  *largestComponentSize = maxSize;\n\n}",
            "// TODO: Your code here\n\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i >= N || j >= N) {\n\t\treturn;\n\t}\n\tint visited[N][N];\n\tint queue[N][N];\n\tint front = 0;\n\tint rear = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[i][j] = 0;\n\t\t}\n\t}\n\tqueue[rear++][0] = i;\n\tqueue[rear++][0] = j;\n\tvisited[i][j] = 1;\n\twhile (rear > front) {\n\t\tint top = queue[front++][0];\n\t\tint left = queue[front++][0];\n\t\tif (top < N && A[top * N + left] &&!visited[top + 1][left]) {\n\t\t\tqueue[rear++][0] = top + 1;\n\t\t\tqueue[rear++][0] = left;\n\t\t\tvisited[top + 1][left] = 1;\n\t\t}\n\t\tif (left < N && A[top * N + left] &&!visited[top][left + 1]) {\n\t\t\tqueue[rear++][0] = top;\n\t\t\tqueue[rear++][0] = left + 1;\n\t\t\tvisited[top][left + 1] = 1;\n\t\t}\n\t}\n\tatomicAdd(largestComponentSize, front - rear);\n}",
            "__shared__ bool is_visited[32];\n  __shared__ int shared_data[32];\n\n  size_t i = blockIdx.x;\n  size_t j = blockIdx.y;\n  size_t tid = threadIdx.x;\n  size_t bid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  bool is_visited[32];\n  int shared_data[32];\n\n  if (i == j)\n    is_visited[tid] = false;\n  else\n    is_visited[tid] = true;\n\n  if (A[bid]!= 0)\n    shared_data[tid] = 1;\n  else\n    shared_data[tid] = 0;\n\n  __syncthreads();\n\n  for (int s = 1; s < blockDim.x; s *= 2) {\n    int index = 2 * s * tid;\n\n    if (index < blockDim.x) {\n      shared_data[index] = shared_data[index] + shared_data[index + s];\n    }\n\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    largestComponentSize[i] = shared_data[0];\n  }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (index < N) {\n\t\tint cmp = index;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[index*N + i] > 0) {\n\t\t\t\tcmp = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[cmp*N + i] > 0 && A[cmp*N + i] > A[index*N + i]) {\n\t\t\t\tcmp = i;\n\t\t\t}\n\t\t}\n\t\tif (cmp == index) {\n\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  int s = 0;\n  if (i < N && j < N) {\n    s = A[i + j * N];\n  }\n  // Add up the edges for each vertex in the graph, which is the size of the component.\n  atomicAdd(largestComponentSize, s);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Compute the number of vertices in the largest component of the graph\n\tif (id < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[id * N + i] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t\t*largestComponentSize = max(*largestComponentSize, count);\n\t}\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x; // global thread index\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    __shared__ int sdata[16][16]; // tile shared memory\n\n    if (x >= N || y >= N) return;\n    if (A[x * N + y] == 1) { // store the result in the shared memory\n        sdata[threadIdx.y][threadIdx.x] = 1;\n    } else {\n        sdata[threadIdx.y][threadIdx.x] = 0;\n    }\n    __syncthreads();\n\n    if (threadIdx.y == 0 && threadIdx.x == 0) { // only the first thread in a tile will update the result\n        int sum = 0;\n        for (int i = 0; i < blockDim.y; i++) { // traverse the whole tile\n            for (int j = 0; j < blockDim.x; j++) {\n                sum += sdata[i][j];\n            }\n        }\n        atomicMax(largestComponentSize, sum); // update the result using atomic operations\n    }\n}",
            "// TODO\n}",
            "int row, col;\n\n    row = blockIdx.x * blockDim.x + threadIdx.x;\n    col = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row < N && col < N && row!= col) {\n        // If A[row][col] is not zero and not in the diagonal, it means that there is a connection between nodes row and col\n        if (A[row*N + col]!= 0)\n            atomicAdd(largestComponentSize, 1);\n    }\n}",
            "// TODO: Insert your code here to compute the size of the largest component.\n\n}",
            "__shared__ int sccIds[N][N];\n\t__shared__ int numSccIds;\n\tint i, j;\n\n\tif (threadIdx.x == 0 && threadIdx.y == 0)\n\t\tnumSccIds = 0;\n\n\t__syncthreads();\n\n\ti = blockIdx.x;\n\tj = blockIdx.y;\n\n\tif (i < N && j < N) {\n\t\tif (A[i * N + j] > 0) {\n\t\t\tint sccId = sccIds[i][j];\n\n\t\t\tif (sccId == 0) {\n\t\t\t\tint sccId = atomicAdd(&numSccIds, 1);\n\t\t\t\tsccIds[i][j] = sccId;\n\t\t\t\tint k;\n\n\t\t\t\tfor (k = 0; k < N; k++) {\n\t\t\t\t\tif (A[k * N + j] > 0) {\n\t\t\t\t\t\tint otherSccId = sccIds[k][j];\n\n\t\t\t\t\t\tif (otherSccId > 0) {\n\t\t\t\t\t\t\tint oldSccId;\n\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\toldSccId = atomicExch(&sccIds[i][otherSccId - 1], sccId);\n\t\t\t\t\t\t\t} while (oldSccId!= otherSccId);\n\n\t\t\t\t\t\t\tsccId = min(sccId, otherSccId);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tsccIds[k][j] = sccId;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor (k = 0; k < N; k++) {\n\t\t\t\t\tif (A[i * N + k] > 0) {\n\t\t\t\t\t\tint otherSccId = sccIds[i][k];\n\n\t\t\t\t\t\tif (otherSccId > 0) {\n\t\t\t\t\t\t\tint oldSccId;\n\n\t\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\t\toldSccId = atomicExch(&sccIds[otherSccId - 1][j], sccId);\n\t\t\t\t\t\t\t} while (oldSccId!= otherSccId);\n\n\t\t\t\t\t\t\tsccId = min(sccId, otherSccId);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tsccIds[i][k] = sccId;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t*largestComponentSize = max(*largestComponentSize, sccId);\n\t\t}\n\t}\n}",
            "// Get the id of the thread.\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// If the thread id is larger than the size of the graph, exit.\n\tif (id >= N) {\n\t\treturn;\n\t}\n\n\t// A thread only operates on a single vertex, so we need to use atomic operations to update the data.\n\tif (atomicCAS(&visited[id], false, true) == false) {\n\t\tint myComponentSize = 0;\n\n\t\t// Go over all of the neighbors and increment the number of vertices in the current component\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * id + i] == 1) {\n\t\t\t\tmyComponentSize++;\n\t\t\t}\n\t\t}\n\n\t\t// We update the largest component size only if the current component size is larger than the previously saved largest component size\n\t\tif (myComponentSize > *largestComponentSize) {\n\t\t\tatomicExch(largestComponentSize, myComponentSize);\n\t\t}\n\n\t\t// Go over all of the neighbors, and mark them as visited if they haven't been already.\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * id + i] == 1) {\n\t\t\t\tatomicCAS(&visited[i], false, true);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int r = blockDim.x * blockIdx.x + threadIdx.x;\n\tint c = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (r >= N || c >= N) {\n\t\treturn;\n\t}\n\n\tif (A[r * N + c] == 1) {\n\t\t*largestComponentSize = max(*largestComponentSize, 1 + dfs(A, N, r, c));\n\t}\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x;\n\tint y = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (x < N && y < N) {\n\t\tif (A[x + N * y])\n\t\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "__shared__ int sdata[1024];\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    if (i >= N || j >= N) return;\n\n    int isConnected = A[i * N + j];\n\n    int warpVal = 0;\n    if (isConnected) warpVal = 1;\n    warpVal = warpSum(warpVal);\n    if (threadIdx.x % 32 == 0) sdata[threadIdx.y] = warpVal;\n    __syncthreads();\n    if (threadIdx.y == 0 && threadIdx.x < 32) sdata[threadIdx.x] = sdata[threadIdx.x] + sdata[threadIdx.x + 32];\n    __syncthreads();\n    if (threadIdx.y == 0 && threadIdx.x == 0) {\n        sdata[0] = sdata[0] + sdata[1];\n        sdata[0] = sdata[0] + sdata[2];\n        sdata[0] = sdata[0] + sdata[3];\n        sdata[0] = sdata[0] + sdata[4];\n        sdata[0] = sdata[0] + sdata[5];\n        sdata[0] = sdata[0] + sdata[6];\n        sdata[0] = sdata[0] + sdata[7];\n        sdata[0] = sdata[0] + sdata[8];\n        sdata[0] = sdata[0] + sdata[9];\n        sdata[0] = sdata[0] + sdata[10];\n        sdata[0] = sdata[0] + sdata[11];\n        sdata[0] = sdata[0] + sdata[12];\n        sdata[0] = sdata[0] + sdata[13];\n        sdata[0] = sdata[0] + sdata[14];\n        sdata[0] = sdata[0] + sdata[15];\n        sdata[0] = sdata[0] + sdata[16];\n        sdata[0] = sdata[0] + sdata[17];\n        sdata[0] = sdata[0] + sdata[18];\n        sdata[0] = sdata[0] + sdata[19];\n        sdata[0] = sdata[0] + sdata[20];\n        sdata[0] = sdata[0] + sdata[21];\n        sdata[0] = sdata[0] + sdata[22];\n        sdata[0] = sdata[0] + sdata[23];\n        sdata[0] = sdata[0] + sdata[24];\n        sdata[0] = sdata[0] + sdata[25];\n        sdata[0] = sdata[0] + sdata[26];\n        sdata[0] = sdata[0] + sdata[27];\n        sdata[0] = sdata[0] + sdata[28];\n        sdata[0] = sdata[0] + sdata[29];\n        sdata[0] = sdata[0] + sdata[30];\n        sdata[0] = sdata[0] + sdata[31];\n        largestComponentSize[blockIdx.y * gridDim.x + blockIdx.x] = sdata[0];\n    }\n}",
            "// Store the thread index\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid == 0) {\n\t\t// Initialize the component sizes array\n\t\t*largestComponentSize = 0;\n\t\t// Initialize the visited array\n\t\tvisited[0] = 1;\n\t\t// Initialize the component number\n\t\tcomponent = 1;\n\t}\n\t__syncthreads();\n\t// Initialize the local component size\n\tint localComponentSize = 0;\n\t// Check if the thread index is valid\n\tif (tid < N) {\n\t\t// Check if the thread is already visited\n\t\tif (!visited[tid]) {\n\t\t\t// Initialize the current number of vertices\n\t\t\tint currentNum = 0;\n\t\t\t// Initialize the current vertex\n\t\t\tint currentVertex = tid;\n\t\t\t// Mark the current vertex as visited\n\t\t\tvisited[tid] = 1;\n\t\t\t// Initialize the number of vertices in the current component\n\t\t\tlocalComponentSize++;\n\t\t\t// Update the component number\n\t\t\tcomponent++;\n\t\t\t// Check if the current vertex has any neighbours\n\t\t\twhile (A[currentVertex + currentNum*N]) {\n\t\t\t\t// Check if the neighbour is already visited\n\t\t\t\tif (!visited[A[currentVertex + currentNum*N] - 1]) {\n\t\t\t\t\t// Mark the neighbour as visited\n\t\t\t\t\tvisited[A[currentVertex + currentNum*N] - 1] = 1;\n\t\t\t\t\t// Update the component number\n\t\t\t\t\tcomponent++;\n\t\t\t\t}\n\t\t\t\t// Go to the next neighbour\n\t\t\t\tcurrentNum++;\n\t\t\t}\n\t\t\t// Check if the local component size is larger than the global component size\n\t\t\tif (localComponentSize > *largestComponentSize) {\n\t\t\t\t// Update the global component size\n\t\t\t\t*largestComponentSize = localComponentSize;\n\t\t\t}\n\t\t}\n\t}\n}",
            "int row = blockIdx.x;\n    int col = blockIdx.y;\n    if (row == col) {\n        int sum = 0;\n        for (int i = threadIdx.x; i < N; i += blockDim.x) {\n            if (A[row * N + i] == 1)\n                sum++;\n        }\n        atomicMax(largestComponentSize, sum);\n    }\n}",
            "// Create a temporary array to record the size of the largest component\n  __shared__ int dp[TILE_SIZE][TILE_SIZE];\n\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  int largest = 0;\n  if (i < N && j < N) {\n    int size = 0;\n    if (A[i * N + j] == 1) {\n      size = 1;\n      if (i < N - 1 && A[i * N + (j + 1)] == 1) {\n        size++;\n      }\n      if (j < N - 1 && A[(i + 1) * N + j] == 1) {\n        size++;\n      }\n      if (i < N - 1 && j < N - 1 && A[(i + 1) * N + (j + 1)] == 1) {\n        size++;\n      }\n    }\n    dp[threadIdx.y][threadIdx.x] = size;\n  }\n\n  // synchronize threads within a thread block\n  __syncthreads();\n\n  // In each thread block, select the largest size of the component\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    largest = dp[0][0];\n    for (int i = 1; i < TILE_SIZE; ++i) {\n      largest = max(largest, dp[0][i]);\n      largest = max(largest, dp[i][0]);\n    }\n  }\n\n  // synchronize threads within a thread block\n  __syncthreads();\n\n  // The largest component size is stored in the first element of the temporary array dp\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    atomicMax(largestComponentSize, largest);\n  }\n}",
            "// Find the thread index (using the flattened threadId)\n\tsize_t threadIndex = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Get the row and column indices corresponding to the thread index\n\tint row = threadIndex / N;\n\tint col = threadIndex % N;\n\n\t// If this thread is part of the largest component, it will compute the size of the component\n\tint size = 1;\n\tif (A[row * N + col] == 1) {\n\t\t// Compute the size of the component\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (i == col) continue; // Don't count self-edges\n\t\t\tif (A[row * N + i] == 1) size++;\n\t\t}\n\t}\n\n\t// If this thread is not part of the largest component, ignore all the work and set size to 0\n\tif (threadIndex >= N) size = 0;\n\n\t// Determine the maximum size of all threads\n\t// NOTE: This is not the correct way to do this!\n\tif (threadIndex == 0) {\n\t\tsize_t maximumSize = size;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tsize_t curSize = 0;\n\t\t\tif (blockIdx.x * blockDim.x + i < N) curSize = size;\n\t\t\tif (curSize > maximumSize) maximumSize = curSize;\n\t\t}\n\t\t*largestComponentSize = maximumSize;\n\t}\n}",
            "extern __shared__ int shared[];\n\tsize_t my_id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint *queue = shared;\n\n\tif (my_id < N) {\n\t\tqueue[my_id] = my_id;\n\t}\n\n\t__syncthreads();\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsize_t j = queue[i];\n\t\tif (j < N) {\n\t\t\tsize_t k = j;\n\t\t\twhile (k < N && A[j * N + k] == 1) {\n\t\t\t\tqueue[i] = k;\n\t\t\t\tk = A[k * N + k];\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsize_t j = queue[i];\n\t\tif (j < N) {\n\t\t\tsize_t k = j;\n\t\t\twhile (k < N && A[j * N + k] == 1) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t}\n\n\t\t\tif (k < N) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t\twhile (k < N && A[j * N + k] == 0) {\n\t\t\t\t\tk = A[k * N + k];\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (k < N) {\n\t\t\t\tqueue[i] = k;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsize_t j = queue[i];\n\t\tif (j < N) {\n\t\t\tsize_t k = j;\n\t\t\twhile (k < N && A[j * N + k] == 1) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t}\n\t\t\tif (k < N) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t\twhile (k < N && A[j * N + k] == 0) {\n\t\t\t\t\tk = A[k * N + k];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (k < N) {\n\t\t\t\tqueue[i] = k;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsize_t j = queue[i];\n\t\tif (j < N) {\n\t\t\tsize_t k = j;\n\t\t\twhile (k < N && A[j * N + k] == 1) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t}\n\t\t\tif (k < N) {\n\t\t\t\tk = A[k * N + k];\n\t\t\t\twhile (k < N && A[j * N + k] == 0) {\n\t\t\t\t\tk = A[k * N + k];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (k < N) {\n\t\t\t\tqueue[i] = k;\n\t\t\t}\n\t\t}\n\n\t\tif (queue[i] < N) {\n\t\t\tmax++;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tatomicMax(largestComponentSize, max);\n}",
            "int largestComponentSizeLocal = 0;\n\n\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] == 1) {\n\t\t\tlargestComponentSizeLocal += 1;\n\t\t}\n\t}\n\tatomicAdd(largestComponentSize, largestComponentSizeLocal);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    __shared__ bool S[16][16]; // S is a shared memory array of size 16x16\n    __shared__ int visited[16];\n\n    for (int j = 0; j < N; ++j)\n      S[i][j] = false;\n    visited[i] = 0;\n\n    __syncthreads(); // make sure all threads have written to S and visited\n\n    int componentSize = 0;\n    int queue[16]; // queue is a shared memory array of size 16\n    queue[0] = i;\n    int front = 0; // front points to the next element to be removed\n    int rear = 1; // rear points to the next available slot in the queue\n    S[i][i] = true;\n\n    while (front < rear) {\n      int u = queue[front++];\n      visited[u] = 1;\n\n      for (int v = 0; v < N; ++v) {\n        if (A[u * N + v] == 1 && visited[v] == 0) {\n          queue[rear++] = v;\n          S[u][v] = true;\n          S[v][u] = true;\n        }\n      }\n      __syncthreads(); // make sure all threads have written to S and visited\n    }\n\n    for (int j = 0; j < N; ++j) {\n      if (S[i][j])\n        componentSize++;\n    }\n    atomicAdd(largestComponentSize, componentSize);\n  }\n}",
            "// Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n\t// Store the result in largestComponentSize[0]\n\t// Example:\n\t//\n\t// input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n\t// output: 2\n\t//\n\t// Compute the number of vertices in the largest component of the graph.\n\t// Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n\t\n\tint global_row_id = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\tint global_col_id = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;\n\t\n\tint block_row_id = hipThreadIdx_x;\n\tint block_col_id = hipThreadIdx_y;\n\t\n\t__shared__ int cache[32][32];\n\t\n\tint largest = 0;\n\tif(global_row_id == global_col_id)\n\t{\n\t\tlargest = 1;\n\t}\n\t\n\t// Read the data from the global memory to the local memory\n\tcache[block_row_id][block_col_id] = A[global_row_id * N + global_col_id];\n\t\n\t// Wait for all threads to read the data\n\t__syncthreads();\n\t\n\t// Check if the data in the local memory is connected to the local memory\n\tfor(int i = 0; i < 32; i++)\n\t{\n\t\tfor(int j = 0; j < 32; j++)\n\t\t{\n\t\t\tif(block_row_id == i && block_col_id == j) continue;\n\t\t\t\n\t\t\tif(block_row_id < 32 && block_col_id < 32)\n\t\t\t{\n\t\t\t\tif(cache[block_row_id][block_col_id] == 1 && cache[i][j] == 1)\n\t\t\t\t{\n\t\t\t\t\tlargest = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Wait for all threads to finish\n\t__syncthreads();\n\t\n\t// Write the local memory to the global memory\n\tif(block_row_id == 0 && block_col_id == 0)\n\t{\n\t\tatomicAdd(largestComponentSize, largest);\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  // The largest component size is stored in the first element of the array\n  // If this thread has the largest component size, store it in the result\n  if (id == 0) {\n    *largestComponentSize = 0;\n    for (int i = 0; i < N; ++i) {\n      if (A[i * N + i]) {\n        *largestComponentSize += 1;\n      }\n    }\n  }\n}",
            "// TODO: YOUR CODE HERE\n\n\tconst size_t gid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (gid >= N * N) return;\n\tconst size_t row = gid / N;\n\tconst size_t col = gid % N;\n\n\t// check if edge is in the matrix and it's not self-loop\n\tif (A[gid]!= 0 && row!= col) {\n\t\tatomicMin(largestComponentSize, N);\n\t\treturn;\n\t}\n\n\t// check if edge is self-loop and it's not the same vertex (1x1)\n\tif (A[gid]!= 0 && row == col && N > 1) {\n\t\tatomicMin(largestComponentSize, N - 1);\n\t\treturn;\n\t}\n}",
            "// TODO: Add code to compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n\t// The largest component size is stored in largestComponentSize.\n\n\t// This is the size of the largest component\n\tint localLargestComponentSize = 0;\n\n\t// This is the size of the current component\n\tint localCurrentComponentSize = 0;\n\n\t// This is the number of connected components\n\tint connectedComponents = 0;\n\n\t// This is the current connected component\n\tint currentComponent = 0;\n\n\t// This is the size of the largest component\n\tint globalLargestComponentSize = 0;\n\n\t// This is the index in the array\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// The value of the matrix\n\tint a = A[i];\n\n\t// If the value of the matrix is equal to the index of the thread\n\tif (a == i) {\n\t\tlocalCurrentComponentSize++;\n\n\t\t// If the size of the current component is larger than the previous largest component\n\t\tif (localCurrentComponentSize > localLargestComponentSize) {\n\t\t\tlocalLargestComponentSize = localCurrentComponentSize;\n\t\t}\n\n\t\t// Reset the current component\n\t\tcurrentComponent = 0;\n\t\tlocalCurrentComponentSize = 0;\n\t\tconnectedComponents++;\n\t} else if (a!= 0) {\n\t\tcurrentComponent++;\n\t\tlocalCurrentComponentSize++;\n\t}\n\n\t// TODO: Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n\t// This is the size of the largest component\n\t*largestComponentSize = localLargestComponentSize;\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // Only examine the upper triangle of the matrix.\n    // The (i, j) entry is stored at i * N + j.\n    if (col >= row)\n        return;\n\n    // If there is an edge between row and col, we add col to the DFS stack.\n    if (A[row * N + col] == 1) {\n        atomicAdd(largestComponentSize, 1);\n        return;\n    }\n}",
            "__shared__ int component[COMPONENT_SIZE];\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n    int cid = 0;\n    int componentSize = 0;\n    int i;\n\n    if (tid == 0) {\n        componentSize = 0;\n    }\n    __syncthreads();\n\n    // Initialize component\n    for (i = 0; i < COMPONENT_SIZE; i++) {\n        component[i] = 0;\n    }\n    __syncthreads();\n\n    // Find component\n    for (i = bid; i < N; i += gridDim.x) {\n        if (A[i*N + bid] > 0) {\n            component[componentSize++] = i;\n        }\n    }\n    __syncthreads();\n\n    if (componentSize > 0) {\n        // Mark all component nodes in the graph\n        for (i = 0; i < componentSize; i++) {\n            int cid = component[i];\n            int j;\n            for (j = 0; j < N; j++) {\n                int node = A[cid*N + j];\n                if (node > 0) {\n                    A[cid*N + j] = -1;\n                }\n            }\n            for (j = 0; j < N; j++) {\n                int node = A[j*N + cid];\n                if (node > 0) {\n                    A[j*N + cid] = -1;\n                }\n            }\n        }\n        __syncthreads();\n\n        // Check if component is largest\n        for (i = bid; i < N; i += gridDim.x) {\n            if (A[i*N + bid] == 1) {\n                atomicAdd(&cid, 1);\n            }\n        }\n        __syncthreads();\n\n        if (tid == 0) {\n            atomicAdd(largestComponentSize, cid);\n        }\n    }\n    __syncthreads();\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint compId = -1;\n\tif (id < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[id * N + i] == 1) {\n\t\t\t\tcompId = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t__shared__ int compIds[N];\n\tint tId = threadIdx.x;\n\tif (tId == 0) {\n\t\tcompIds[blockIdx.x] = compId;\n\t}\n\t__syncthreads();\n\tif (tId == 0) {\n\t\tif (blockIdx.x > 0) {\n\t\t\tfor (int i = 0; i < blockIdx.x; i++) {\n\t\t\t\tif (compIds[i]!= -1) {\n\t\t\t\t\tcompId = compIds[i];\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\tif (id < N) {\n\t\tlargestComponentSize[id] = compId;\n\t}\n}",
            "__shared__ int sharedMemory[BLOCK_SIZE][BLOCK_SIZE + 1];\n\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint bw = BLOCK_SIZE;\n\tint bh = BLOCK_SIZE;\n\tint id = (by * bw + tx);\n\n\tint sum = 0;\n\tint i = 0;\n\n\tfor (i = 0; i < N; i += bw) {\n\t\tif (id < N) {\n\t\t\tsharedMemory[ty][tx] = A[id];\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tint j = 0;\n\t\tfor (j = 0; j < bh; j++) {\n\t\t\tsum += sharedMemory[ty][j];\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tid += bh * N;\n\t}\n\n\tif (id == 0) {\n\t\tatomicAdd(largestComponentSize, sum);\n\t}\n}",
            "// TODO: Implement this.\n}",
            "// Each thread computes the number of vertices in the largest component of the subgraph defined by A\n  int threadIndex = blockIdx.x * blockDim.x + threadIdx.x;\n  if (threadIndex >= N)\n    return;\n  int c = 0;\n  for (int i = 0; i < N; i++) {\n    c += (A[threadIndex * N + i]!= 0);\n  }\n  if (c > *largestComponentSize) {\n    *largestComponentSize = c;\n  }\n}",
            "int largestComponentSizeLocal = 0;\n  int vertex = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if (vertex < N) {\n    if (A[vertex + N * vertex] > 0) {\n      largestComponentSizeLocal = 1;\n      for (int i = vertex + 1; i < N; i++) {\n        if (A[vertex + N * i] > 0) {\n          largestComponentSizeLocal++;\n        }\n      }\n    }\n  }\n\n  __shared__ int sdata[256];\n\n  // Reduce largestComponentSizeLocal values from all threads in this block.\n  int lane = threadIdx.x % warpSize;\n  int wid = threadIdx.x / warpSize;\n\n  largestComponentSizeLocal = warpReduceSum(largestComponentSizeLocal, lane, wid, sdata);\n  if (threadIdx.x == 0) {\n    atomicMax(largestComponentSize, largestComponentSizeLocal);\n  }\n}",
            "// TODO\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int idy = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (idx >= N || idy >= N || idx == idy) {\n        return;\n    }\n\n    if (A[N * idx + idy] == 1) {\n        atomicMin(largestComponentSize, 0);\n    }\n}",
            "__shared__ int componentSizes[LARGEST_COMPONENT_SHARED_SIZE];\n  // Compute the index of the vertex in the adjacency matrix of this thread\n  int vertex = blockIdx.x * blockDim.x + threadIdx.x;\n  if (vertex >= N) {\n    return;\n  }\n  // Compute the size of the component containing this vertex\n  int size = 1;\n  for (int offset = 1; offset < N; offset++) {\n    int neighbor = (vertex + offset) % N;\n    if (A[neighbor * N + vertex]!= 0) {\n      size++;\n    }\n  }\n  componentSizes[threadIdx.x] = size;\n  __syncthreads();\n  // Compute the max component size using a tree reduction\n  if (threadIdx.x == 0) {\n    *largestComponentSize = size;\n    for (int i = 1; i < LARGEST_COMPONENT_SHARED_SIZE && i < N; i++) {\n      *largestComponentSize = max(*largestComponentSize, componentSizes[i]);\n    }\n  }\n}",
            "int r = blockDim.x * blockIdx.x + threadIdx.x;\n    int c = blockDim.y * blockIdx.y + threadIdx.y;\n    __shared__ int s_A[TILE_DIM][TILE_DIM];\n    int myMax = 0;\n    int index = 0;\n    for (int i = 0; i < (N + TILE_DIM - 1) / TILE_DIM; i++) {\n        int row = i * TILE_DIM + threadIdx.y;\n        int col = i * TILE_DIM + threadIdx.x;\n        s_A[threadIdx.y][threadIdx.x] = 0;\n        if (row < N && col < N) {\n            s_A[threadIdx.y][threadIdx.x] = A[row * N + col];\n        }\n        __syncthreads();\n\n        for (int j = 0; j < TILE_DIM; j++) {\n            myMax = max(myMax, s_A[j][index]);\n        }\n        __syncthreads();\n    }\n    if (r == 0 && c == 0) {\n        *largestComponentSize = myMax;\n    }\n}",
            "int max = 0;\n   int row = blockDim.y*blockIdx.y + threadIdx.y;\n   int col = blockDim.x*blockIdx.x + threadIdx.x;\n\n   if(row >= N || col >= N) return;\n   if(A[row*N+col] > 0) max++;\n\n   __shared__ int maxPerThread[16][16];\n   __syncthreads();\n   maxPerThread[threadIdx.y][threadIdx.x] = max;\n   __syncthreads();\n\n   for(int i = 0; i < 8; i++)\n   {\n      maxPerThread[threadIdx.y][threadIdx.x] += maxPerThread[threadIdx.y][threadIdx.x + 8];\n      maxPerThread[threadIdx.y][threadIdx.x] += maxPerThread[threadIdx.y + 8][threadIdx.x];\n      maxPerThread[threadIdx.y][threadIdx.x] += maxPerThread[threadIdx.y + 8][threadIdx.x + 8];\n   }\n\n   if(threadIdx.x == 0 && threadIdx.y == 0)\n   {\n      atomicMax(largestComponentSize, maxPerThread[threadIdx.y][threadIdx.x]);\n   }\n}",
            "// The grid is NxN and the block is 1x1.\n  int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ int componentSizes[BLOCK_SIZE];\n  __shared__ int componentIDs[BLOCK_SIZE];\n\n  int currentSize = 0;\n  int currentID = 0;\n  if (threadID < N) {\n    currentID = threadID;\n    for (int i = 0; i < N; i++) {\n      if (A[IDX2C(threadID, i, N)]!= 0) {\n        currentSize++;\n      }\n    }\n  }\n  componentSizes[threadIdx.x] = currentSize;\n  componentIDs[threadIdx.x] = currentID;\n  __syncthreads();\n\n  // Perform a reduction to find the largest component.\n  int maxComponentSize = 0;\n  int maxComponentID = 0;\n  for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n    if (threadID < stride) {\n      int otherID = componentIDs[threadID + stride];\n      int otherSize = componentSizes[threadID + stride];\n      if (otherSize > maxComponentSize) {\n        maxComponentSize = otherSize;\n        maxComponentID = otherID;\n      }\n    }\n    __syncthreads();\n  }\n  if (threadID == 0) {\n    *largestComponentSize = maxComponentSize;\n  }\n}",
            "__shared__ int blockLargestComponentSize[BLOCK_SIZE];\n    __shared__ int componentSize[BLOCK_SIZE];\n    __shared__ int visited[BLOCK_SIZE];\n    __shared__ bool first;\n\n    first = true;\n    blockLargestComponentSize[threadIdx.x] = 0;\n    componentSize[threadIdx.x] = 0;\n    visited[threadIdx.x] = 0;\n\n    // Traverse all the vertices in the matrix and find the largest component\n    for(int i = 0; i < N; i++) {\n        if(threadIdx.x == 0) {\n            componentSize[threadIdx.x] = 1;\n            visited[threadIdx.x] = 1;\n        }\n\n        __syncthreads();\n\n        // The number of threads in each block is the number of vertices in the largest component\n        for(int j = 0; j < N; j++) {\n            // A vertex is adjacent to another vertex if the corresponding entry of the adjacency matrix is 1\n            if(A[i*N + j] == 1 && visited[threadIdx.x] == 0 && A[threadIdx.x*N + j] == 1) {\n                componentSize[threadIdx.x]++;\n                visited[threadIdx.x] = 1;\n            }\n        }\n\n        __syncthreads();\n\n        // Determine the largest component size\n        if(first) {\n            // Each block's component size is the sum of the vertices in its component\n            blockLargestComponentSize[threadIdx.x] = componentSize[threadIdx.x];\n            first = false;\n        } else {\n            // If the current block's component size is greater than the largest component size seen so far,\n            // update the largest component size seen so far\n            atomicMax(&blockLargestComponentSize[threadIdx.x], componentSize[threadIdx.x]);\n            first = false;\n        }\n\n        __syncthreads();\n\n        // Reduce the block component sizes to get the largest component size in the entire graph\n        while(blockLargestComponentSize[threadIdx.x] < blockLargestComponentSize[blockLargestComponentSize[threadIdx.x]]) {\n            blockLargestComponentSize[threadIdx.x] = blockLargestComponentSize[blockLargestComponentSize[threadIdx.x]];\n        }\n\n        __syncthreads();\n    }\n\n    // Find the largest component size in the entire graph\n    atomicMax(largestComponentSize, blockLargestComponentSize[threadIdx.x]);\n}",
            "// Define a variable to store the largest component size.\n  __shared__ int maxCompSize;\n\n  // Get the index of the thread in the NxN grid.\n  int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\n  // Initialize the shared maxCompSize to zero.\n  if (threadIdx.x == 0) maxCompSize = 0;\n\n  // Block synchronize threads in the block to make sure that maxCompSize is correctly initialized.\n  __syncthreads();\n\n  // Compute the number of vertices in the largest component.\n  if (tid < N) {\n    int componentSize = 0;\n    int u = tid;\n    do {\n      componentSize++;\n      u = A[u*N + u];\n    } while(u!= tid);\n\n    // Write the largest component size into shared memory.\n    if (componentSize > maxCompSize) {\n      maxCompSize = componentSize;\n    }\n  }\n\n  // Block synchronize threads in the block to make sure that maxCompSize is correctly updated.\n  __syncthreads();\n\n  // Get the largest component size from shared memory to a register.\n  int myMaxCompSize = maxCompSize;\n\n  // Block synchronize threads in the block to make sure that myMaxCompSize is correctly loaded.\n  __syncthreads();\n\n  // Write the value of myMaxCompSize into global memory.\n  if (threadIdx.x == 0) {\n    *largestComponentSize = myMaxCompSize;\n  }\n}",
            "__shared__ int A_local[BLOCK_SIZE][BLOCK_SIZE];\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint r = ty * blockDim.x + tx;\n\tint x = bx * blockDim.x + tx;\n\tint y = by * blockDim.y + ty;\n\tint size = 0;\n\tint visited[BLOCK_SIZE];\n\tbool b = false;\n\tint largest = 0;\n\t\n\tif (y >= N || x >= N) return;\n\tA_local[ty][tx] = A[y*N+x];\n\t__syncthreads();\n\t\n\tif (r < N) {\n\t\tvisited[r] = 0;\n\t}\n\t__syncthreads();\n\t\n\tif (x == r && y == r) {\n\t\tvisited[r] = 1;\n\t\tsize = 1;\n\t}\n\t__syncthreads();\n\t\n\tif (x!= r && y!= r && A_local[ty][tx]!= 0) {\n\t\tvisited[r] = 1;\n\t\tsize = 1;\n\t}\n\t__syncthreads();\n\t\n\tif (visited[r] == 1) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited[i]!= 1 && A_local[ty][i]!= 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tsize++;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\t\n\tif (size > largest) {\n\t\tlargest = size;\n\t\t*largestComponentSize = size;\n\t}\n\t\n}",
            "// Your code goes here\n}",
            "// Use CSR to store the graph.\n    // First, convert A to CSR representation.\n    //\n    // Step 1: Compute the cumulative sum of row i of A to get CSR[i].\n    //         Note that the last element of CSR is the total number of nonzeroes in the matrix.\n    //\n    // Step 2: Scan the CSR array to get CSRt.\n    //         CSRt[i] is the number of nonzeroes in rows 0 to i - 1.\n    //\n    // Step 3: Compute CSR[i] - CSRt[i] to get the index of each nonzero element of row i in A.\n    //\n    // Step 4: Copy the corresponding elements in A to the new array B.\n    //\n    // Step 5: Transpose B to get the transpose of A.\n    //\n    // Step 6: Convert the transpose of A to CSR representation.\n    //\n    // Step 7: Scan the CSR array to get CSRt.\n    //\n    // Step 8: Compute CSR[i] - CSRt[i] to get the index of each nonzero element of row i in A.\n    //\n    // Step 9: Copy the corresponding elements in A to the new array B.\n    //\n    // Step 10: Transpose B to get the transpose of A.\n\n    int myId = blockIdx.x * blockDim.x + threadIdx.x;\n    int myRow = myId / N;\n    int myCol = myId % N;\n\n    __shared__ int CSR[BLOCK_SIZE * BLOCK_SIZE];\n    __shared__ int CSRt[BLOCK_SIZE * BLOCK_SIZE];\n    __shared__ int B[BLOCK_SIZE * BLOCK_SIZE];\n\n    int rowBegin = 0, rowEnd = 0;\n    if (myRow < N && myCol < N) {\n        // Step 1: Compute the cumulative sum of row i of A to get CSR[i].\n        for (int k = myRow + 1; k < N; k++) {\n            rowBegin += A[k * N + myCol];\n        }\n        CSR[myId] = rowBegin;\n\n        // Step 2: Scan the CSR array to get CSRt.\n        if (myCol == 0) {\n            CSRt[myId] = CSR[myId];\n        }\n        if (myId < BLOCK_SIZE * BLOCK_SIZE - 1) {\n            CSRt[myId + 1] = CSRt[myId] + CSR[myId + 1];\n        }\n\n        // Step 3: Compute CSR[i] - CSRt[i] to get the index of each nonzero element of row i in A.\n        if (myRow < N) {\n            rowBegin = CSR[myId] - CSRt[myId];\n            rowEnd = CSR[myId + 1] - CSRt[myId];\n        }\n\n        // Step 4: Copy the corresponding elements in A to the new array B.\n        if (rowBegin <= rowEnd && myRow < N) {\n            for (int k = rowBegin; k < rowEnd; k++) {\n                B[k] = A[myRow * N + CSRt[myCol] + k];\n            }\n        }\n    }\n\n    __syncthreads();\n\n    // Step 5: Transpose B to get the transpose of A.\n    int rowBeginB = 0, rowEndB = 0;\n    if (myRow < N && myCol < N) {\n        // Step 6: Convert the transpose of A to CSR representation.\n        if (myCol < N) {\n            for (int k = myCol + 1; k < N; k++) {\n                rowBeginB += B[k * N + myRow];\n            }\n            CSR[myId] = rowBeginB;\n        }\n\n        if (myCol == 0) {\n            CSRt[myId] = CSR[myId];\n        }\n        if (myId < BLOCK_SIZE * BLOCK_SIZE - 1) {\n            CSRt",
            "// Initialize to -1 for each thread to indicate uninitialized\n  __shared__ int shm[1024];\n  int tid = blockDim.x * blockIdx.y * gridDim.x\n      + blockDim.x * blockIdx.x + threadIdx.x;\n\n  int comp = -1;\n  int compSize = 0;\n\n  for (int i = tid; i < N; i += blockDim.x * gridDim.x * gridDim.y) {\n    if (A[i * N + i] == 1 && comp == -1) {\n      comp = i;\n      compSize++;\n    }\n  }\n\n  // Determine if the thread is the largest vertex in its component\n  int isLargest = 0;\n  if (comp!= -1 && tid == comp) {\n    isLargest = 1;\n  }\n  __syncthreads();\n\n  // Inclusive scan to determine if the thread is the largest vertex in its component\n  shm[threadIdx.x] = isLargest;\n  for (int s = 1; s < blockDim.x; s *= 2) {\n    __syncthreads();\n    int other = shm[threadIdx.x - s];\n    if (isLargest == 1 && other == 1) {\n      // We are the largest vertex in our component\n      compSize += 1;\n    }\n    __syncthreads();\n    if (isLargest == 0) {\n      isLargest = other;\n    }\n  }\n  __syncthreads();\n\n  // Write the result to the global memory\n  if (isLargest == 1 && tid == 0) {\n    *largestComponentSize = compSize;\n  }\n}",
            "// TODO: implement this kernel\n}",
            "// Each thread handles a single vertex.\n  int vertex = blockIdx.x * blockDim.x + threadIdx.x;\n  if(vertex >= N) return;\n\n  int componentSize = 0;\n  int numVisited = 0;\n\n  while(numVisited!= N) {\n    // The stack of vertices whose neighbors have not been visited\n    __shared__ int stack[N];\n    stack[0] = vertex;\n    numVisited = 1;\n\n    while(numVisited > 0) {\n      // Pop the top vertex\n      int v = stack[numVisited - 1];\n      numVisited -= 1;\n\n      int v_begin = v * N;\n      int v_end = v_begin + N;\n\n      // Traverse the adjacency list of the popped vertex\n      for(int j = v_begin; j < v_end; j++) {\n        int u = A[j];\n        if(u > -1 && u!= vertex) {\n          if(u < N) {\n            // The vertex is a valid vertex in the graph\n            stack[numVisited] = u;\n            numVisited++;\n          }\n          // Mark the vertex as visited\n          A[j] = -1;\n        }\n      }\n    }\n\n    componentSize++;\n  }\n\n  // Compute the largest component size\n  atomicAdd(largestComponentSize, componentSize);\n}",
            "// TODO\n\n}",
            "int x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint idx = blockDim.x * blockIdx.y + blockDim.x * blockIdx.x;\n\tint size = 0;\n\n\tif (A[idx]!= 0) {\n\t\tsize = 1;\n\t\tfor (int i = 1; i < N; i++) {\n\t\t\tif (A[idx + i * N]!= 0) {\n\t\t\t\tsize++;\n\t\t\t}\n\t\t}\n\t\tatomicMax(largestComponentSize, size);\n\t}\n}",
            "// Use AMD HIP parallelism to compute the largest component of the graph.\n\t// Store the result in largestComponentSize.\n\n\tconst int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int numThreads = blockDim.x * gridDim.x;\n\n\t__shared__ int sdata[BLOCK_SIZE];\n\t__shared__ int sdata_counter[BLOCK_SIZE];\n\n\tfor(int i=0;i<BLOCK_SIZE;i++){\n\t\tsdata_counter[i]=0;\n\t}\n\n\tfor(int i=tid; i<N; i+=numThreads){\n\t\tint counter=0;\n\t\tfor(int j=0; j<N; j++){\n\t\t\tif(A[i*N+j] == 1){\n\t\t\t\tcounter++;\n\t\t\t}\n\t\t}\n\t\tsdata[tid]=counter;\n\t\t__syncthreads();\n\t\tif(tid == 0){\n\t\t\tfor(int i=0; i<BLOCK_SIZE; i++){\n\t\t\t\tint counter = sdata_counter[0];\n\t\t\t\tsdata_counter[0]+=sdata[i];\n\t\t\t\tsdata[i] = counter;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor(int i=0; i<BLOCK_SIZE; i++){\n\t\t\tsdata[tid] += sdata[i];\n\t\t}\n\t\t__syncthreads();\n\t\tsdata_counter[tid]=0;\n\t\t__syncthreads();\n\t\tif(tid == 0){\n\t\t\tfor(int i=0; i<BLOCK_SIZE; i++){\n\t\t\t\tint counter = sdata_counter[0];\n\t\t\t\tsdata_counter[0]+=sdata[i];\n\t\t\t\tsdata[i] = counter;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor(int i=0; i<BLOCK_SIZE; i++){\n\t\t\tsdata[tid] += sdata[i];\n\t\t}\n\t\t__syncthreads();\n\t\tsdata_counter[sdata[tid]]=1;\n\t\t__syncthreads();\n\t\tif(tid == 0){\n\t\t\tfor(int i=0; i<BLOCK_SIZE; i++){\n\t\t\t\tint counter = sdata_counter[0];\n\t\t\t\tsdata_counter[0]+=sdata[i];\n\t\t\t\tsdata[i] = counter;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tsdata[sdata[tid]] = sdata[sdata[tid]]-1;\n\t\tsdata[tid] = sdata[sdata[tid]];\n\t\tif(sdata[tid] == 0){\n\t\t\tlargestComponentSize[0] = sdata[tid];\n\t\t}\n\t}\n\t// Avoid race condition\n\t__syncthreads();\n\tif(tid == 0){\n\t\tint largest = largestComponentSize[0];\n\t\tfor(int i=1; i<BLOCK_SIZE; i++){\n\t\t\tif(largest < largestComponentSize[i]){\n\t\t\t\tlargest = largestComponentSize[i];\n\t\t\t}\n\t\t}\n\t\tlargestComponentSize[0] = largest;\n\t}\n}",
            "// Compute the index of the component containing this vertex\n  int index = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // Initialize the vertex\n  atomicCAS(A + index, 0, index + 1);\n\n  // Wait for all threads in the block to finish initialization\n  __syncthreads();\n\n  // Compute the index of the component containing this vertex\n  int root = findRoot(A, index);\n\n  // Merge the components of the vertices in this block\n  for (int offset = threadIdx.x; offset < N; offset += blockDim.x) {\n    int aRoot = findRoot(A, offset);\n    // If the component containing vertex offset is different from the component\n    // containing vertex index, merge them\n    if (aRoot!= root) {\n      atomicMin(largestComponentSize, atomicMin(A + aRoot, root + 1) - 1);\n    }\n  }\n\n  // Wait for all threads in the block to finish before exiting\n  __syncthreads();\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id < N) {\n    int curr_id = id;\n    bool visited[N];\n    memset(visited, false, N);\n    int stack[N];\n    int stack_top = 0;\n    int num_visited = 0;\n    int num_visited_last = 0;\n    stack[stack_top] = curr_id;\n    visited[curr_id] = true;\n    while (stack_top >= 0) {\n      int curr = stack[stack_top];\n      stack_top--;\n      for (int i = 0; i < N; i++) {\n        if (A[curr * N + i] &&!visited[i]) {\n          stack[++stack_top] = i;\n          visited[i] = true;\n          num_visited++;\n        }\n      }\n    }\n    num_visited_last = num_visited;\n    *largestComponentSize = (num_visited > *largestComponentSize? num_visited : *largestComponentSize);\n  }\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.y + threadIdx.y;\n\t\n\tif(i >= N || j >= N) return;\n\tif(A[i*N+j] == 1) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "// Each thread computes the largest component size in a\n  // bipartite graph of the subgraph defined by the rows and columns of the\n  // matrix A that it is responsible for.\n\n  // Compute the row and column of the subgraph of A that this thread\n  // is responsible for.\n  size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n  size_t col = blockIdx.y * blockDim.y + threadIdx.y;\n  int size = 0;\n  if (row < N && col < N) {\n    // Compute the size of the largest component in the bipartite graph of\n    // the rows and columns defined by the submatrix of A indexed by\n    // [row,col]\n    if (A[row * N + col] == 1) {\n      // If the matrix A has a 1 in its row and column, this thread is\n      // responsible for computing the size of the largest component in\n      // the bipartite graph defined by the rows and columns.\n      size = bipartiteLargestComponentSize(A, N, row, col);\n    }\n  }\n  // Find the largest component size across all threads.\n  atomicMax(largestComponentSize, size);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    int row = tid / N;\n    int col = tid % N;\n    if (row < N && col < N) {\n        // This thread works on the element at row row and column col of the matrix A.\n        if (A[row * N + col]) {\n            atomicMin(largestComponentSize, 1);\n            return;\n        }\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x; // compute global thread index\n\tif (i < N) { // if the global thread index is within bounds\n\t\tint compSize = 0; // current size of the component\n\t\tint compId = i; // current id of the component\n\t\tdo { // explore the component from compId\n\t\t\tcompSize++;\n\t\t\tcompId = A[compId + N * compId];\n\t\t} while (compId!= i); // continue until the component is closed\n\n\t\tif (compSize > *largestComponentSize)\n\t\t\t*largestComponentSize = compSize;\n\t}\n}",
            "// Compute the largest component size.\n\t// The largest component is defined as the maximum number of vertices that can be reached from a single vertex.\n\n\t// A is an NxN adjacency matrix stored in row-major.\n\t// N is the number of vertices in the graph.\n\n\t// Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n\t// Return the largest component size in largestComponentSize.\n}",
            "// TODO: write your code here\n}",
            "// Get thread index\n    int index = blockDim.x * blockIdx.y * gridDim.x\n               + blockDim.x * blockIdx.x\n               + threadIdx.x;\n\n    if(index < N * N) {\n        // Get the row and column of the element of interest\n        int row = index / N;\n        int col = index % N;\n\n        // Check if the element of interest is 0\n        // If it is, that means it is not connected to the rest of the graph\n        // and can be excluded from further consideration\n        if(A[index] == 0)\n            return;\n\n        // This value will be used to track the vertices in the largest component\n        // of the graph\n        int component = 1;\n\n        // Iterate over the rest of the graph\n        // If the graph element is connected to the current vertex, increment component\n        for(int i = 0; i < N; i++) {\n            if(A[row * N + i] == 1 && A[i * N + col] == 1)\n                component++;\n        }\n\n        // If this component is the largest one so far, replace the largest component size\n        // with this one\n        if(component > *largestComponentSize) {\n            *largestComponentSize = component;\n        }\n    }\n}",
            "// TODO:\n\t// 1) Allocate shared memory to store the adjacency matrix\n\t// 2) Load the A matrix into shared memory\n\t// 3) Implement a strongly connected components algorithm\n\t// 4) Use atomic functions to find the maximum size of the components in the graph\n\t// 5) Use atomic functions to find the number of vertices in the largest component\n\n\tconst int MAX_SIZE = 128;\n\t__shared__ int A_shared[MAX_SIZE][MAX_SIZE];\n\tint a[MAX_SIZE];\n\tint b[MAX_SIZE];\n\n\tint row = threadIdx.x;\n\tint col = threadIdx.y;\n\n\t// load shared memory from global memory\n\tfor (int i = row; i < N; i += blockDim.y) {\n\t\tfor (int j = col; j < N; j += blockDim.x) {\n\t\t\tA_shared[i][j] = A[i * N + j];\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (row < N && col < N) {\n\t\ta[row] = row;\n\t\tb[row] = row;\n\t}\n\t__syncthreads();\n\n\tfor (int i = row; i < N; i += blockDim.y) {\n\t\tfor (int j = col; j < N; j += blockDim.x) {\n\t\t\tif (A_shared[i][j] == 1) {\n\t\t\t\tb[i] = j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// for (int i = 0; i < N; i++) {\n\t// \tprintf(\"%d\\n\", b[i]);\n\t// }\n\t__syncthreads();\n\n\t// int *p;\n\t// p = b;\n\t// int *q;\n\t// q = a;\n\t// for (int i = 0; i < N; i++) {\n\t// \tprintf(\"%d\\n\", p[i]);\n\t// \tprintf(\"%d\\n\", q[i]);\n\t// }\n\t__syncthreads();\n\n\tint x = 0;\n\tint y = 0;\n\twhile (x < N && y < N) {\n\t\tif (a[x]!= b[y]) {\n\t\t\ta[x] = b[y];\n\t\t\tx = 0;\n\t\t\ty++;\n\t\t}\n\t\telse {\n\t\t\tx++;\n\t\t\ty = 0;\n\t\t}\n\t}\n\n\t// for (int i = 0; i < N; i++) {\n\t// \tprintf(\"%d\\n\", a[i]);\n\t// }\n\t__syncthreads();\n\n\tint size = 0;\n\tint comp = a[0];\n\tint max = 0;\n\tfor (int i = 1; i < N; i++) {\n\t\tif (a[i]!= comp) {\n\t\t\tcomp = a[i];\n\t\t\tsize++;\n\t\t\tatomicMax(largestComponentSize, size);\n\t\t\tsize = 0;\n\t\t}\n\t}\n\t__syncthreads();\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\t__shared__ int myComponent[1024];\n\tmyComponent[threadIdx.x] = A[tid*N + tid];\n\t__syncthreads();\n\tint s = blockDim.x;\n\twhile (s!= 1) {\n\t\tint old_s = s;\n\t\ts >>= 1;\n\t\tif (threadIdx.x < s)\n\t\t\tmyComponent[threadIdx.x] = myComponent[threadIdx.x] + myComponent[threadIdx.x + s];\n\t\t__syncthreads();\n\t}\n\tif (threadIdx.x == 0)\n\t\t*(largestComponentSize) = myComponent[0];\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n    if(row < N && col < N && A[row * N + col]) {\n        // Mark all vertices in the largest component\n        for(int i = 0; i < N; i++)\n            atomicOr(largestComponentSize, A[row * N + i]);\n    }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= N) return;\n  int largestComponentId = -1;\n  int largestComponentSizeSoFar = -1;\n  for (int j = 0; j < N; j++) {\n    if (A[j * N + i] && largestComponentSizeSoFar < j) {\n      largestComponentId = j;\n      largestComponentSizeSoFar = j;\n    }\n  }\n  *largestComponentSize = largestComponentSizeSoFar + 1;\n}",
            "const int row = blockIdx.y*blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (row < N && col < N)\n\t\tif (A[row*N + col] && A[col*N + row])\n\t\t\t*largestComponentSize = max(*largestComponentSize, (int)2);\n}",
            "__shared__ int componentId[32][32]; // shared memory to store the component id\n\tint *componentIdRow = componentId[threadIdx.y]; // componentIdRow is an array with length N\n\n\t// Initialize componentIdRow\n\tif(threadIdx.x < N) {\n\t\tcomponentIdRow[threadIdx.x] = 0;\n\t}\n\t__syncthreads();\n\n\t// Iterate over the graph\n\tfor(int k = 0; k < N; ++k) {\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tint row = i;\n\t\t\tint col = k;\n\t\t\t// Skip if (row, col) is not an edge\n\t\t\tif(A[row + col*N] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// Find the parent of row\n\t\t\tint parent = componentIdRow[row];\n\t\t\twhile(parent!= componentIdRow[parent]) {\n\t\t\t\tparent = componentIdRow[parent];\n\t\t\t}\n\t\t\t// If row and col are not in the same component, merge the two components\n\t\t\tif(parent!= componentIdRow[col]) {\n\t\t\t\tint colParent = componentIdRow[col];\n\t\t\t\twhile(colParent!= componentIdRow[colParent]) {\n\t\t\t\t\tcolParent = componentIdRow[colParent];\n\t\t\t\t}\n\t\t\t\tcomponentIdRow[colParent] = parent;\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\n\t// Compute the size of the largest component\n\tint size = 0;\n\tint maxComponent = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tint component = componentIdRow[i];\n\t\tif(component > maxComponent) {\n\t\t\tmaxComponent = component;\n\t\t}\n\t\tif(componentIdRow[i] == maxComponent) {\n\t\t\tsize += 1;\n\t\t}\n\t}\n\t// Store the result in largestComponentSize\n\tif(blockIdx.x == 0 && threadIdx.x == 0) {\n\t\t*largestComponentSize = size;\n\t}\n}",
            "//__shared__ int row[N]; // row buffer for a single thread\n  extern __shared__ int row[];\n  row[threadIdx.x] = A[threadIdx.x * N + blockIdx.x];\n\n  __syncthreads();\n\n  //__shared__ int result[N]; // result buffer for a single thread\n  extern __shared__ int result[];\n  result[threadIdx.x] = 0;\n\n  __syncthreads();\n\n  //__shared__ int visited[N]; // a thread should not process the same vertex twice\n  extern __shared__ int visited[];\n  visited[threadIdx.x] = 0;\n\n  __syncthreads();\n\n  for(int i = 0; i < N; i++) {\n    if(i == blockIdx.x) {\n      result[threadIdx.x] = 1;\n      break;\n    }\n  }\n\n  __syncthreads();\n\n  // traverse up the graph\n  while(true) {\n    // traverse row\n    for(int j = 0; j < N; j++) {\n      if(row[j] == 1) {\n        // check if vertex j has been visited by the current thread\n        if(visited[j] == 0) {\n          // if vertex j has not been visited by the current thread,\n          // set the number of vertices visited by the current thread to 1 + the number of vertices visited by the current thread\n          // and add the number of vertices in the component of vertex j to the number of vertices visited by the current thread\n          // and set the number of vertices in the component of vertex j to 0\n          atomicAdd(&result[threadIdx.x], 1 + result[j]);\n          visited[j] = 1;\n          row[j] = 0;\n        }\n      }\n    }\n\n    __syncthreads();\n\n    int max = 0;\n    // if no more vertex to traverse up the graph, the search is over\n    for(int i = 0; i < N; i++) {\n      if(row[i] == 1) {\n        max = 1;\n        break;\n      }\n    }\n\n    __syncthreads();\n\n    if(max == 0) {\n      break;\n    }\n  }\n\n  __syncthreads();\n\n  // store the maximum number of vertices in the largest component\n  *largestComponentSize = 0;\n  for(int i = 0; i < N; i++) {\n    *largestComponentSize = max(*largestComponentSize, result[i]);\n  }\n\n  __syncthreads();\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid >= N) return;\n\n    int largestComponentSizeLocal = 0;\n\n    if (A[tid * N + tid]!= 0) { // A[tid, tid] is 1\n        int next = tid;\n        while (next < N) {\n            if (A[next * N + tid] == 1) { // A[next, tid] is 1\n                int nextNext = next;\n                while (nextNext < N) {\n                    if (A[nextNext * N + tid] == 1) { // A[nextNext, tid] is 1\n                        int nextNextNext = nextNext;\n                        while (nextNextNext < N) {\n                            if (A[nextNextNext * N + tid] == 1) {\n                                // A[nextNextNext, tid] is 1\n                                nextNextNext++;\n                            } else {\n                                break;\n                            }\n                        }\n                        nextNext = nextNextNext;\n                    } else {\n                        break;\n                    }\n                }\n                next = nextNext;\n            } else {\n                break;\n            }\n        }\n\n        largestComponentSizeLocal = next - tid;\n    }\n\n    // Perform reduction\n    __shared__ int sdata[BLOCKSIZE];\n    int lane = threadIdx.x % WARPSIZE;\n    int wid = threadIdx.x / WARPSIZE;\n\n    sdata[tid] = largestComponentSizeLocal;\n\n    __syncthreads();\n\n    if (lane == 0) {\n        int warpVal = sdata[wid * WARPSIZE];\n        sdata[wid] = warpVal;\n    }\n\n    __syncthreads();\n\n    if (wid == 0) {\n        if (lane < 16)\n            sdata[lane] = sdata[lane] + sdata[lane + 16];\n        if (lane < 8)\n            sdata[lane] = sdata[lane] + sdata[lane + 8];\n        if (lane < 4)\n            sdata[lane] = sdata[lane] + sdata[lane + 4];\n        if (lane < 2)\n            sdata[lane] = sdata[lane] + sdata[lane + 2];\n        if (lane < 1)\n            sdata[lane] = sdata[lane] + sdata[lane + 1];\n\n        if (threadIdx.x == 0)\n            atomicMax(largestComponentSize, sdata[0]);\n    }\n}",
            "int i = blockDim.x*blockIdx.x + threadIdx.x;\n\tint j = blockDim.y*blockIdx.y + threadIdx.y;\n\n\tif(i >= N || j >= N)\n\t\treturn;\n\n\tif(A[i*N + j] == 1 && i!= j) {\n\t\tatomicMin(largestComponentSize, min(N - i, N - j));\n\t}\n}",
            "// TODO: Implement this function\n  __shared__ int row[blockDim.x];\n  __shared__ int componentSize[blockDim.x];\n\n  int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i == j) {\n    row[threadIdx.x] = 0;\n    for (int k = 0; k < N; k++) {\n      if (A[i * N + k] == 1)\n        row[threadIdx.x]++;\n    }\n  }\n  __syncthreads();\n\n  componentSize[threadIdx.x] = 0;\n  if (row[threadIdx.x] == 0) {\n    for (int k = 0; k < N; k++) {\n      if (A[threadIdx.x * N + k] == 1)\n        componentSize[threadIdx.x]++;\n    }\n  }\n  __syncthreads();\n\n  for (int d = blockDim.x / 2; d > 0; d >>= 1) {\n    if (threadIdx.x < d) {\n      if (row[threadIdx.x] == 0)\n        componentSize[threadIdx.x] += componentSize[threadIdx.x + d];\n    }\n    __syncthreads();\n  }\n\n  if (row[threadIdx.x] == 0 && threadIdx.x == 0) {\n    *largestComponentSize = componentSize[0];\n  }\n}",
            "const int TILE_WIDTH = 32;\n\t__shared__ int row[TILE_WIDTH];\n\t__shared__ int visited[TILE_WIDTH];\n\t__shared__ int componentSize;\n\n\t// get the location of the thread in the 2D grid\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\n\tint rowIndex = by * TILE_WIDTH + ty;\n\tint colIndex = bx * TILE_WIDTH + tx;\n\n\t// init\n\tcomponentSize = 0;\n\trow[ty] = 0;\n\tvisited[ty] = 0;\n\t__syncthreads();\n\n\t// set row value\n\tif (rowIndex < N) {\n\t\trow[ty] = A[rowIndex * N + colIndex];\n\t}\n\t__syncthreads();\n\n\t// check row value to see if we should increment the component size\n\tif (rowIndex < N && colIndex < N && row[ty]) {\n\t\tcomponentSize += 1;\n\t}\n\t__syncthreads();\n\n\t// parallel reduction\n\tfor (int i = TILE_WIDTH / 2; i > 0; i /= 2) {\n\t\tif (ty < i) {\n\t\t\tcomponentSize += row[ty + i];\n\t\t\tvisited[ty + i] += row[ty + i];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (ty == 0) {\n\t\tatomicAdd(largestComponentSize, componentSize);\n\t}\n}",
            "int max = 0;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      max += A[i * N + j];\n    }\n  }\n  // Find the max among all threads in the block and then the maximum in the grid.\n  __shared__ int blockMax[256];\n  blockMax[threadIdx.x] = max;\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    for (int i = 1; i < blockDim.x; i++) {\n      max = max > blockMax[i]? max : blockMax[i];\n    }\n    blockMax[0] = max;\n  }\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    *largestComponentSize = max;\n  }\n}",
            "// Get our global thread ID\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (tid < N) {\n    int visited[N];\n    int component_size = 0;\n    int queue[N];\n    int queue_head = 0;\n    int queue_tail = 0;\n\n    // Initialize the array of visited vertices to 0\n    for (int i = 0; i < N; i++) {\n      visited[i] = 0;\n    }\n\n    // Put the vertex tid on the queue\n    queue[queue_tail] = tid;\n    visited[tid] = 1;\n    queue_tail++;\n\n    while (queue_head < queue_tail) {\n      int vertex = queue[queue_head];\n      queue_head++;\n      component_size++;\n\n      // Search through all the neighbors of this vertex\n      for (int i = 0; i < N; i++) {\n        if (A[N * vertex + i] &&!visited[i]) {\n          queue[queue_tail] = i;\n          visited[i] = 1;\n          queue_tail++;\n        }\n      }\n    }\n\n    // Compare the component size to the largest component size\n    if (component_size > *largestComponentSize) {\n      *largestComponentSize = component_size;\n    }\n  }\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row >= N || col >= N) return;\n\n\t__shared__ int shared[32][32];\n\t__shared__ bool visited[32][32];\n\n\tshared[threadIdx.y][threadIdx.x] = A[row * N + col];\n\tvisited[threadIdx.y][threadIdx.x] = false;\n\n\t__syncthreads();\n\n\tif (shared[threadIdx.y][threadIdx.x] == 1) {\n\t\tint nextRow = row;\n\t\tint nextCol = col;\n\n\t\twhile (nextRow >= 0 && nextCol < N) {\n\t\t\tif (!visited[nextRow][nextCol]) {\n\t\t\t\tvisited[nextRow][nextCol] = true;\n\n\t\t\t\tif (threadIdx.x > 0 && shared[nextRow][nextCol - 1] == 1) {\n\t\t\t\t\tnextCol--;\n\t\t\t\t}\n\t\t\t\telse if (threadIdx.x < N - 1 && shared[nextRow][nextCol + 1] == 1) {\n\t\t\t\t\tnextCol++;\n\t\t\t\t}\n\t\t\t\telse if (threadIdx.y < N - 1 && shared[nextRow + 1][nextCol] == 1) {\n\t\t\t\t\tnextRow++;\n\t\t\t\t}\n\t\t\t\telse if (threadIdx.y > 0 && shared[nextRow - 1][nextCol] == 1) {\n\t\t\t\t\tnextRow--;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (visited[threadIdx.y][threadIdx.x] && threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "// Compute the size of the largest component of A\n\t// Store the size of the largest component in *largestComponentSize\n\n\tint mySize = 0;\n\tif (A[blockIdx.x*blockDim.x + threadIdx.x]!= 0)\n\t{\n\t\tmySize = 1;\n\t}\n\n\tfor (int i = threadIdx.x + blockDim.x; i < N; i += blockDim.x)\n\t{\n\t\tif (A[blockIdx.x*blockDim.x + i]!= 0)\n\t\t{\n\t\t\tmySize++;\n\t\t}\n\t}\n\n\tint myMax = mySize;\n\n\tfor (int i = 1; i < blockDim.x; i *= 2)\n\t{\n\t\tmyMax = max(myMax, __shfl_down(mySize, i));\n\t}\n\n\tif (threadIdx.x == 0)\n\t{\n\t\tatomicAdd(largestComponentSize, myMax);\n\t}\n}",
            "// TODO: implement this function\n\t// *hint*: use atomicMax() to maintain the largest component size as you traverse the graph\n\n\tint *sccs = NULL;\n\tcudaMallocManaged(&sccs, sizeof(int)*N);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tsccs[i] = i;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1 && i < j) {\n\t\t\t\tatomicMax(&sccs[i], sccs[j]);\n\t\t\t}\n\t\t}\n\t}\n\n\tint scc_size = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (sccs[i] == i) {\n\t\t\tscc_size++;\n\t\t}\n\t}\n\n\t*largestComponentSize = scc_size;\n\n\tcudaFree(sccs);\n}",
            "// TODO: Replace this line with your implementation\n\t*largestComponentSize = 1;\n}",
            "int *componentSizes;\n\tint *componentIds;\n\tint *Anew;\n\tint *AnewCopy;\n\tint *workspace;\n\tint *iwork;\n\tint *mask;\n\n\tint threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint numThreads = blockDim.x * gridDim.x;\n\n\t/* Compute the largest component size and set the componentIds to the largest componentId.\n\t   componentSizes and componentIds are parallel arrays. */\n\n\t/*\n\t   Pseudocode:\n\n\t   componentSizes[i] = 0\n\t   componentIds[i] = -1\n\n\t   // Traverse the graph (A) to find a starting vertex of the largest component\n\t   // Note: start with any valid starting vertex.\n\t   i =...\n\t   while (i < N) {\n\t       // If componentId is already assigned, skip\n\t       if (componentIds[i]!= -1)\n\t           continue;\n\n\t       // Set componentId to 0\n\t       componentIds[i] = 0;\n\n\t       // Traverse the graph (A) for the largest component\n\t       traverseComponent(i, componentIds, componentSizes);\n\t   }\n\n\t   // Find the largest component\n\t   maxComponentId = 0\n\t   for (i=0; i<N; i++) {\n\t       if (componentSizes[i] > componentSizes[maxComponentId])\n\t           maxComponentId = i;\n\t   }\n\n\t   largestComponentSize[0] = componentSizes[maxComponentId];\n\n\t   // Mark the vertices in the largest component as -1\n\t   for (i=0; i<N; i++) {\n\t       if (componentIds[i] == maxComponentId)\n\t           componentIds[i] = -1;\n\t   }\n\t*/\n\n\tint maxComponentId = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tif(threadId == 0) {\n\t\t\tcomponentSizes[i] = 0;\n\t\t\tcomponentIds[i] = -1;\n\t\t}\n\t\t__syncthreads();\n\t\tif(threadId == 0) {\n\t\t\tif(componentIds[i] == -1) {\n\t\t\t\tcomponentIds[i] = 0;\n\t\t\t\ttraverseComponent(i, componentIds, componentSizes);\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\t__syncthreads();\n\tint largestComponentSize = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tif(componentSizes[i] > largestComponentSize)\n\t\t\tlargestComponentSize = componentSizes[i];\n\t}\n\t__syncthreads();\n\tfor(int i = 0; i < N; i++) {\n\t\tif(componentIds[i] == maxComponentId)\n\t\t\tcomponentIds[i] = -1;\n\t}\n\t__syncthreads();\n\n\t/* Mark the vertices in the largest component as -1 */\n\tif(componentIds[threadId] == -1) {\n\t\tAnew[threadId] = 0;\n\t} else {\n\t\tAnew[threadId] = A[threadId];\n\t}\n\n\t/* Perform BFS on the resulting graph */\n\tif(threadId == 0) {\n\t\tAnewCopy[0] = 1;\n\t}\n\t__syncthreads();\n\tint numVisited = 1;\n\twhile(numVisited < N) {\n\t\tif(AnewCopy[threadId] == 1) {\n\t\t\tif(threadId < N) {\n\t\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\t\tif(A[threadId * N + j] == 1) {\n\t\t\t\t\t\tif(componentIds[j] == -1) {\n\t\t\t\t\t\t\tcomponentIds[j] = 0;\n\t\t\t\t\t\t\tAnewCopy[j] = 1;\n\t\t\t\t\t\t}",
            "// TODO\n}",
            "int j = blockDim.x * blockIdx.x + threadIdx.x;\n  int i = blockDim.y * blockIdx.y + threadIdx.y;\n\n  if(i == 0 && j == 0) {\n    int visited[N];\n    for(int i = 0; i < N; i++)\n      visited[i] = 0;\n\n    int nComp = 0;\n    int size;\n\n    for(int i = 0; i < N; i++) {\n      if(visited[i] == 0) {\n        size = 0;\n        dfs(A, visited, &size, i, N);\n        if(size > nComp)\n          nComp = size;\n      }\n    }\n    *largestComponentSize = nComp;\n  }\n}",
            "int blockRow = blockIdx.y;\n    int blockCol = blockIdx.x;\n    int threadRow = threadIdx.y;\n    int threadCol = threadIdx.x;\n\n\tint index = blockRow * gridDim.x * blockDim.y + blockCol * blockDim.y + threadRow;\n\tint index2 = blockRow * gridDim.x * blockDim.y + blockCol * blockDim.y + threadCol;\n\tint size = 0;\n\tint maxSize = 0;\n\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (A[index * N + i] == 1)\n\t\t{\n\t\t\tsize = 0;\n\t\t\tint *visited = (int *)malloc(sizeof(int) * N);\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tvisited[j] = 0;\n\t\t\t}\n\t\t\tvisited[index2] = 1;\n\t\t\tsize = dfs(A, N, index2, i, visited);\n\t\t\tif (size > maxSize)\n\t\t\t{\n\t\t\t\tmaxSize = size;\n\t\t\t}\n\t\t\tfree(visited);\n\t\t}\n\t}\n\n\tif (maxSize > 0)\n\t{\n\t\tatomicAdd(largestComponentSize, maxSize);\n\t}\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if(i < N) {\n    int size = 0;\n\n    for(int j = 0; j < N; j++) {\n      if(A[i * N + j]!= 0) {\n        size++;\n      }\n    }\n\n    if(*largestComponentSize < size) {\n      *largestComponentSize = size;\n    }\n  }\n}",
            "// Use the thread ID as the vertex id for which to compute the largest component\n    size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= N) {\n        return;\n    }\n    // Do the work\n\n    // 1. Initialize\n    int *visited = (int *)malloc(N * sizeof(int));\n    for (int i = 0; i < N; i++)\n        visited[i] = -1;\n\n    // 2. BFS\n    int level = 0;\n    int Q[N];\n    int front = 0, rear = -1;\n    Q[rear] = tid;\n    visited[tid] = 1;\n    while (front <= rear) {\n        int node = Q[front++];\n        for (int i = 0; i < N; i++) {\n            if (A[node * N + i] &&!visited[i]) {\n                visited[i] = 1;\n                Q[++rear] = i;\n            }\n        }\n    }\n\n    // 3. Count\n    *largestComponentSize = level + 1;\n\n    // Free\n    free(visited);\n}",
            "// Allocate a vector of bools of size N.\n  // Use atomic operations to populate this vector based on the adjacency matrix.\n  // The value at index i in this vector is true iff there is a path in the graph from vertex i to vertex 0.\n  // We use a vector because a value cannot be changed by multiple threads concurrently.\n\n  // TODO: Write your code here\n\n\n  __syncthreads();\n\n  // Find the largest component size.\n  // The largest component is the sum of all values in the above vector.\n  // Since we cannot use atomic operations to modify a single variable from multiple threads,\n  // use a vector of values to store the largest component size seen so far,\n  // and find the max across all threads.\n  // This vector should be of size 1.\n\n  // TODO: Write your code here\n\n  // Return the largest component size found.\n  // This is the value stored in the first element of the above vector.\n  // TODO: Write your code here\n\n}",
            "// Initialize the shared memory for the atomicMax operations.\n\t// There is one shared memory location per thread.\n\textern __shared__ int sharedArray[];\n\n\t// We have one thread per vertex.\n\tint vertex = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (vertex < N) {\n\t\t// Initialize the shared memory location to zero.\n\t\tsharedArray[threadIdx.x] = 0;\n\n\t\t// Each thread iterates through the neighbors of its vertex.\n\t\tfor (int neighbor = 0; neighbor < N; neighbor++) {\n\t\t\t// If the neighbor is connected to the vertex, increment the vertex's counter.\n\t\t\tif (A[N * vertex + neighbor] > 0) {\n\t\t\t\tatomicAdd(&sharedArray[threadIdx.x], 1);\n\t\t\t}\n\t\t}\n\n\t\t// Find the maximum counter for the vertex.\n\t\t// Note that since shared memory is one per thread, atomicMax will only compare the values of two threads.\n\t\t// The block-wide maximum is stored in the first thread's shared memory.\n\t\t// This reduces the parallel accesses to global memory.\n\t\tatomicMax(&sharedArray[0], sharedArray[threadIdx.x]);\n\n\t\t// Store the maximum counter in global memory.\n\t\t// Note that atomicMax does not ensure ordering between threads.\n\t\t// Therefore, we use a barrier to synchronize threads at the end of the loop.\n\t\t__syncthreads();\n\t\tif (threadIdx.x == 0) {\n\t\t\tatomicMax(largestComponentSize, sharedArray[0]);\n\t\t}\n\t}\n}",
            "const int x = blockIdx.x * blockDim.x + threadIdx.x;\n  const int y = blockIdx.y * blockDim.y + threadIdx.y;\n  if (x < N && y < N && A[x * N + y] > 0)\n    atomicMin(largestComponentSize, min(x, y) + 1);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// For each thread, store the largest component size found so far\n\tint largestComponentSizeSoFar = 0;\n\n\t// Examine the neighbors of the vertex\n\t// 1. Find the number of neighbors\n\t// 2. If the neighbor is unvisited, add it to the frontier\n\t// 3. If the neighbor is visited and not in the current largest component, then add it to the frontier\n\t// 4. If the neighbor is in the current largest component, then continue\n\t// 5. If the neighbor is already in the largest component, then do not add it to the frontier\n\tfor (int n = 0; n < N; n++) {\n\t\t// Check if the vertex is adjacent to the current vertex\n\t\tif (A[tid + n * N] == 1) {\n\t\t\t// Check if the neighbor has already been visited\n\t\t\tif (atomicCAS(&visited[n], 0, 1) == 0) {\n\t\t\t\t// If the neighbor is unvisited, add it to the frontier\n\t\t\t\tfrontier[atomicAdd(frontierSize, 1)] = n;\n\t\t\t} else {\n\t\t\t\t// If the neighbor is visited, then check if it is in the current largest component\n\t\t\t\tif (inLargestComponent[n] == 1) {\n\t\t\t\t\t// If the neighbor is in the current largest component, then add it to the frontier\n\t\t\t\t\tfrontier[atomicAdd(frontierSize, 1)] = n;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Update the largest component size if needed\n\tif (inLargestComponent[tid] == 1) {\n\t\tint largestComponentSizeSoFar = atomicAdd(largestComponentSize, 1);\n\t}\n}",
            "const int *row = A + blockIdx.x * N;\n\tconst int *col = A + blockIdx.x;\n\n\tint i = threadIdx.x;\n\tint num = 0;\n\twhile (i < N) {\n\t\tif (row[i] == 1) {\n\t\t\tnum++;\n\t\t}\n\t\ti += blockDim.x;\n\t}\n\n\tint tmp = 0;\n\tatomicAdd(&tmp, num);\n\t*largestComponentSize = max(*largestComponentSize, tmp);\n}",
            "int i = blockIdx.y;\n\tint j = blockIdx.x;\n\tint id = threadIdx.x;\n\t// shared memory for each block: 32x32\n\t__shared__ int comp[COMP_THREADS_PER_BLOCK * COMP_THREADS_PER_BLOCK];\n\t// shared memory for largest component size\n\t__shared__ int maxSize;\n\t// index in A\n\tint k;\n\t// thread id in a block\n\tint tid;\n\t// component id\n\tint cid;\n\t// largest component id\n\tint lcid = 0;\n\t// largest component size\n\tint lcsize = 0;\n\t// current component size\n\tint csize;\n\t// check if (i, j) is connected to the other threads in the block\n\tint connected;\n\t// check if a component is found\n\tint found;\n\n\t// each thread gets its own cid\n\tcid = threadIdx.y * COMP_THREADS_PER_BLOCK + threadIdx.x;\n\n\t// initialize comp[] and maxSize\n\tif (id == 0) {\n\t\tmaxSize = 0;\n\t\tfor (tid = 0; tid < COMP_THREADS_PER_BLOCK * COMP_THREADS_PER_BLOCK; tid++) {\n\t\t\tcomp[tid] = 0;\n\t\t}\n\t}\n\n\t// synchronize threads in a block\n\t__syncthreads();\n\n\t// check if (i, j) is connected to the other threads in the block\n\tk = i * N + j;\n\tconnected = (A[k] == 1);\n\tcsize = 1;\n\twhile (connected && j < N) {\n\t\t// get the next index\n\t\tj++;\n\t\tk = i * N + j;\n\t\tconnected = (A[k] == 1);\n\t\tcsize++;\n\t}\n\n\t// synchronize threads in a block\n\t__syncthreads();\n\n\t// check if a component is found\n\tfound = false;\n\n\t// the first thread in a block has the largest component id\n\tif (id == 0) {\n\t\tlcid = atomicAdd(&comp[cid], 1);\n\t\tfound = (lcid == 1);\n\t}\n\n\t// synchronize threads in a block\n\t__syncthreads();\n\n\t// the first thread in a block updates maxSize\n\tif (id == 0) {\n\t\tmaxSize = max(maxSize, csize);\n\t}\n\n\t// synchronize threads in a block\n\t__syncthreads();\n\n\t// update largestComponentSize if necessary\n\tif (found) {\n\t\tlcsize = atomicMax(largestComponentSize, maxSize);\n\t}\n\n\t// synchronize threads in a block\n\t__syncthreads();\n}",
            "// Your code here\n    int row = blockIdx.x;\n    int column = blockIdx.y;\n    int width = blockDim.x;\n    int height = gridDim.y;\n\n    if (row < N && column < N) {\n        if (A[row * N + column] == 1) {\n            atomicAdd(largestComponentSize, 1);\n            atomicAdd(&A[row * N + column], 1);\n\n            if (row - 1 >= 0 && column - 1 >= 0)\n                atomicAdd(&A[row * N + column - 1], 1);\n\n            if (row - 1 >= 0)\n                atomicAdd(&A[row * N + column - 1], 1);\n\n            if (column - 1 >= 0)\n                atomicAdd(&A[row * N + column - 1], 1);\n        }\n    }\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\t// initialize the visited array to all zeros\n\t\t__shared__ int visited[1024];\n\t\tvisited[threadIdx.x] = 0;\n\t\t__syncthreads();\n\n\t\t// depth-first traversal to find the largest component\n\t\tint visitedSize = 0;\n\t\tconst int *ptr = A + i * N;\n\t\tint v = i;\n\t\twhile (visitedSize < N) {\n\t\t\tif (ptr[v] && visited[v] == 0) {\n\t\t\t\tvisited[v] = 1;\n\t\t\t\tv = ptr[v];\n\t\t\t\tvisitedSize++;\n\t\t\t} else {\n\t\t\t\tif (visited[v] == 0) {\n\t\t\t\t\tbreak;\n\t\t\t\t} else {\n\t\t\t\t\tv = ptr[v];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// find the largest component\n\t\t*largestComponentSize = max(*largestComponentSize, visitedSize);\n\t}\n}",
            "unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;\n    unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;\n    __shared__ int sdata[BLOCK_SIZE][BLOCK_SIZE];\n    int myData = 0;\n    int myRoot = -1;\n    if (x < N && y < N) {\n        myData = A[y * N + x];\n        myRoot = findRoot(myData, sdata);\n    }\n    __syncthreads();\n    if (myRoot >= 0) {\n        atomicAdd(largestComponentSize, 1);\n    }\n}",
            "__shared__ int visited[GRID_SIZE];\n    __shared__ int largest_component_size;\n    __shared__ int largest_component_size_final;\n\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int jdx = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (idx >= N) return;\n\n    if (jdx == 0) {\n        visited[threadIdx.x] = 0;\n    }\n\n    __syncthreads();\n\n    if (idx == 0) {\n        largest_component_size = 0;\n        largest_component_size_final = 0;\n    }\n\n    __syncthreads();\n\n    if (idx >= N || jdx >= N || idx == jdx || visited[jdx] || A[idx*N+jdx] == 0) return;\n\n    visited[jdx] = 1;\n    largest_component_size += 1;\n\n    __syncthreads();\n\n    atomicMax(&largest_component_size_final, largest_component_size);\n\n    __syncthreads();\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int i = tid / N;\n  int j = tid % N;\n  if (i == j) {\n    if (A[tid] == 0) {\n      atomicMax(largestComponentSize, 0);\n    } else {\n      atomicMax(largestComponentSize, 1);\n    }\n  }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint index = tid * N;\n\n\t// Each thread will be responsible for N items\n\tint localComponentSize = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[index + i]!= 0) {\n\t\t\tlocalComponentSize++;\n\t\t}\n\t}\n\n\t// Reduce across the block and store in a shared memory\n\t__shared__ int sharedArray[BLOCK_SIZE];\n\tsharedArray[threadIdx.x] = localComponentSize;\n\t__syncthreads();\n\n\tfor (int stride = BLOCK_SIZE / 2; stride > 0; stride /= 2) {\n\t\tif (threadIdx.x < stride) {\n\t\t\tsharedArray[threadIdx.x] += sharedArray[threadIdx.x + stride];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// Block 0 will have the final result\n\tif (threadIdx.x == 0) {\n\t\tatomicMax(largestComponentSize, sharedArray[0]);\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  extern __shared__ int S[];\n\n  if (tid < N * N) {\n    S[tid] = A[tid];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    S[tid] = S[tid] + S[tid + 1] + S[tid + 2];",
            "//TODO\n}",
            "const int threadIdx = blockIdx.x * blockDim.x + threadIdx.x;\n  const int numThreads = blockDim.x * gridDim.x;\n\n  for (int v = threadIdx; v < N; v += numThreads) {\n    int component = v;\n    while (A[v * N + component] == 0) {\n      component = componentMap[component];\n      if (component == componentMap[component]) {\n        break;\n      }\n    }\n    atomicMin(componentMap + v, component);\n  }\n\n  __syncthreads();\n\n  for (int v = threadIdx; v < N; v += numThreads) {\n    if (v == componentMap[v]) {\n      atomicAdd(largestComponentSize, 1);\n    }\n  }\n}",
            "// Store the largest component size as a block-local variable to be aggregated at the end\n  int componentSize = 0;\n\n  // Get the index of the vertex in the graph that this thread is responsible for\n  int vertex = blockDim.x*blockIdx.x + threadIdx.x;\n  if(vertex < N) {\n    // Search for a vertex with no neighbors in the current component\n    bool found = true;\n    while(found) {\n      found = false;\n      for(int i = 0; i < N; ++i) {\n        if(A[vertex*N + i]) {\n          found = true;\n          break;\n        }\n      }\n      if(!found) ++componentSize;\n    }\n  }\n\n  // Sum the component size across the block\n  __shared__ int blockComponentSize[BLOCK_SIZE];\n  blockComponentSize[threadIdx.x] = componentSize;\n  __syncthreads();\n  if(threadIdx.x == 0) {\n    componentSize = 0;\n    for(int i = 0; i < blockDim.x; ++i) {\n      componentSize += blockComponentSize[i];\n    }\n    atomicAdd(largestComponentSize, componentSize);\n  }\n}",
            "__shared__ int idxs[N];\n  __shared__ int values[N];\n  __shared__ int counts[N];\n\n  for (int i = 0; i < N; i++) {\n    idxs[i] = i;\n    values[i] = A[N * idxs[i] + idxs[i]];\n    counts[i] = 1;\n  }\n\n  // Reduce all the rows, so that row i now contains the total number of edges from vertex i to other vertices.\n  for (int i = 1; i < N; i *= 2) {\n    __syncthreads();\n    if (threadIdx.x >= i) {\n      counts[threadIdx.x] += counts[threadIdx.x - i];\n    }\n  }\n\n  __syncthreads();\n\n  // Find the largest component by finding the index of the maximum value in the row.\n  int largestIdx = 0;\n  int largestValue = values[0];\n  for (int i = 1; i < N; i++) {\n    if (largestValue < values[i]) {\n      largestIdx = i;\n      largestValue = values[i];\n    }\n  }\n  __syncthreads();\n\n  // Store the result in the first element of the row.\n  values[largestIdx] = counts[largestIdx];\n\n  // Reduce the row to the first element.\n  for (int i = 1; i < N; i *= 2) {\n    __syncthreads();\n    if (threadIdx.x >= i) {\n      values[threadIdx.x] = values[threadIdx.x] + values[threadIdx.x - i];\n    }\n  }\n\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    *largestComponentSize = values[threadIdx.x];\n  }\n}",
            "// Create a local 2D grid of threads within the 2D grid of threads of the kernel\n  // Each thread on the local grid is responsible for marking a vertex as visited\n  // and exploring its neighborhood\n  __shared__ int visited[BLOCK_SIZE][BLOCK_SIZE];\n  // Compute the row and column indices of the current thread in the local 2D grid of threads\n  int row = threadIdx.y + blockIdx.y * blockDim.y;\n  int col = threadIdx.x + blockIdx.x * blockDim.x;\n  // Initialize the visited 2D grid\n  for (int i = 0; i < BLOCK_SIZE; i++)\n    visited[i][threadIdx.x] = -1;\n  if (row < N && col < N) {\n    // The first thread in each block is responsible for exploring the component starting from its vertex\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n      // Mark the vertex as visited and initialize the size of the component\n      visited[0][0] = A[N * col + row];\n      largestComponentSize[0] = 0;\n    }\n    __syncthreads();\n    // Explore the component\n    exploreComponent(A, N, visited, col, row);\n    __syncthreads();\n    // Find the size of the component\n    if (row == 0 && col == 0)\n      for (int i = 0; i < BLOCK_SIZE; i++)\n        for (int j = 0; j < BLOCK_SIZE; j++)\n          if (visited[i][j] >= 0)\n            largestComponentSize[0]++;\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n    int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n    // Check that we're in-bounds\n    if (i < N && j < N) {\n\n        // Check if the cell has been visited already\n        if (A[i * N + j] == 0) {\n            return;\n        }\n\n        // Visit all neighbours and increment the component size\n        for (int k = 0; k < N; k++) {\n            if (A[i * N + k]!= 0 && A[k * N + j]!= 0) {\n                atomicAdd(largestComponentSize, 1);\n                break;\n            }\n        }\n    }\n}",
            "// Initialize the visited vector to all zeros.\n  __shared__ int visited[MAX_NUM_VERTICES];\n  if (threadIdx.x < MAX_NUM_VERTICES) {\n    visited[threadIdx.x] = 0;\n  }\n\n  // Synchronize all threads.\n  __syncthreads();\n\n  // Compute the thread's adjacency list.\n  __shared__ int adjacencyList[MAX_NUM_VERTICES];\n  int adjacencyListLength = 0;\n  if (threadIdx.x < N) {\n    int columnIndex = threadIdx.x;\n    int rowIndex = 0;\n    while (rowIndex < N) {\n      // Check if the current row has an edge to the current column.\n      if (A[rowIndex * N + columnIndex] == 1) {\n        adjacencyList[adjacencyListLength] = rowIndex;\n        adjacencyListLength++;\n      }\n      rowIndex++;\n    }\n  }\n\n  // Synchronize all threads.\n  __syncthreads();\n\n  // Traverse the adjacency list and mark the vertices as visited.\n  for (int i = 0; i < adjacencyListLength; i++) {\n    visited[adjacencyList[i]] = 1;\n  }\n\n  // Synchronize all threads.\n  __syncthreads();\n\n  // Store the largest component size in the global memory.\n  if (threadIdx.x == 0) {\n    *largestComponentSize = 0;\n    for (int i = 0; i < N; i++) {\n      if (visited[i] == 1) {\n        (*largestComponentSize)++;\n      }\n    }\n  }\n}",
            "int blockRow = blockIdx.x;\n\tint threadRow = threadIdx.x;\n\n\tint component = 0;\n\n\tif (blockRow == 0) {\n\t\tif (threadRow == 0) {\n\t\t\tlargestComponentSize[0] = 1;\n\t\t}\n\t} else {\n\t\tif (threadRow == 0) {\n\t\t\t// Use atomicAdd to update the largestComponentSize[0] variable\n\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t}\n\t}\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t__shared__ int visited[TILE_WIDTH * TILE_WIDTH];\n\n\tif (i < N && j < N) {\n\t\tvisited[threadIdx.x * TILE_WIDTH + threadIdx.y] = 0;\n\t\t__syncthreads();\n\n\t\tint size = 0;\n\t\tif (A[i * N + j]) {\n\t\t\tsize = dfs(A, N, visited, i, j, &size);\n\t\t}\n\t\tatomicMax(largestComponentSize, size);\n\t}\n}",
            "// AMD HIP: grid size is NxN, each thread computes the size of one vertex's component\n\tconst size_t tid = threadIdx.x + blockDim.x * blockIdx.x;\n\tif (tid >= N) return;\n\tint c = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[tid * N + i] == 1) {\n\t\t\t// AMD HIP: grid size is NxN, each thread computes the size of one vertex's component\n\t\t\t// AMD HIP: this is just a way to count the size of one vertex's component\n\t\t\t// the value of c can be used to determine the size of the largest component\n\t\t\t// this is just a way to count the size of one vertex's component\n\t\t\t// the value of c can be used to determine the size of the largest component\n\t\t\tc += 1;\n\t\t}\n\t}\n\tif (c > *largestComponentSize) {\n\t\t*largestComponentSize = c;\n\t}\n}",
            "// TODO\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint col = blockIdx.y * blockDim.y + threadIdx.y;\n\tint isConnected = 0;\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] > 0) {\n\t\t\tisConnected = 1;\n\t\t}\n\t}\n\t__syncthreads();\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myLargestComponentSize = 0;\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] == 1) {\n\t\t\tint temp = 1;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[row * N + i] == 1) {\n\t\t\t\t\ttemp = temp + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tmyLargestComponentSize = myLargestComponentSize + temp;\n\t\t}\n\t}\n\t__syncthreads();\n\tatomicAdd(largestComponentSize, myLargestComponentSize);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n    if (id < N) {\n        *largestComponentSize = max(*largestComponentSize, getComponentSize(A, N, id));\n    }\n}",
            "/* Add your code here */\n\n}",
            "// Initialize a shared array with zeros\n  __shared__ int shared[MAX_N];\n  for (int i = threadIdx.x; i < N; i += blockDim.x) {\n    shared[i] = 0;\n  }\n\n  __syncthreads();\n\n  // Each thread performs a DFS search on its subgraph. Each node is visited exactly once.\n  // The DFS search is carried out by all threads in the block, and updates the same shared array.\n  // This array is used as a visited map to avoid visiting a node more than once.\n  // If a node has not been visited, all threads in the block explore its reachable nodes.\n  // During the exploration, other threads check if a node has already been visited.\n  int root = blockIdx.x;\n\n  if (shared[root] == 0) {\n    shared[root] = 1;\n\n    // Explore the reachable nodes\n    int size = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[root*N + j] > 0 && shared[j] == 0) {\n        shared[j] = 1;\n        size++;\n      }\n    }\n\n    // Update the component size\n    atomicAdd(largestComponentSize, size);\n  }\n}",
            "// Initialize the thread's global adjacency matrix row to all 0s\n    int row[N];\n    for (int i = 0; i < N; i++) {\n        row[i] = 0;\n    }\n\n    // For each element in the thread's adjacency matrix row:\n    for (int i = 0; i < N; i++) {\n        // For each neighbor of the current element:\n        for (int j = 0; j < N; j++) {\n            // If the current element has a neighbor in the adjacency matrix row:\n            if (A[j + i*N] > 0) {\n                // Add 1 to the thread's adjacency matrix row\n                atomicAdd(&row[j], 1);\n            }\n        }\n    }\n\n    // Use a shared memory array to store the row sums of each thread.\n    // Note that this only works because all of the threads in a block have the same size adjacency matrix row.\n    __shared__ int rowSum[BLOCK_SIZE];\n\n    // The row sum of the current thread is the sum of its adjacency matrix row\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n        sum += row[i];\n    }\n\n    // Store the sum in the shared memory array\n    rowSum[threadIdx.x] = sum;\n\n    // Sync to ensure all threads have written to shared memory\n    __syncthreads();\n\n    // Find the maximum row sum\n    int max = 0;\n    for (int i = 0; i < BLOCK_SIZE; i++) {\n        max = (rowSum[i] > max)? rowSum[i] : max;\n    }\n\n    // Store the result in the global memory variable largestComponentSize\n    if (threadIdx.x == 0) {\n        *largestComponentSize = max;\n    }\n}",
            "const int TILE_SIZE = 32;\n  int largestComponentSize_local[TILE_SIZE][TILE_SIZE];\n  int *A_local = A + blockIdx.x * N + threadIdx.x;\n  int *largestComponentSize_local_pointer = largestComponentSize_local[threadIdx.y][threadIdx.x];\n  int *largestComponentSize_global_pointer = largestComponentSize + blockIdx.x * N + threadIdx.x;\n  int largestComponentSize_global = 0;\n\n  __shared__ int cache[TILE_SIZE][TILE_SIZE];\n\n  /* Perform one DP iteration. */\n  for (int i = 0; i < N; i += TILE_SIZE) {\n    // Load matrix A into shared memory.\n    cache[threadIdx.y][threadIdx.x] = A_local[i * N];\n    __syncthreads();\n    // Set the size of the largest component to the diagonal element.\n    *largestComponentSize_local_pointer = A_local[i * N];\n    __syncthreads();\n    // Perform DP.\n    for (int j = 1; j < TILE_SIZE; j++) {\n      *largestComponentSize_local_pointer =\n          max(*largestComponentSize_local_pointer, cache[threadIdx.y][threadIdx.x + j]);\n      __syncthreads();\n    }\n    __syncthreads();\n    // Store the result to shared memory for the next iteration.\n    cache[threadIdx.y][threadIdx.x] = *largestComponentSize_local_pointer;\n    __syncthreads();\n  }\n\n  // Merge the results from the local arrays.\n  for (int i = TILE_SIZE / 2; i > 0; i /= 2) {\n    if (threadIdx.x < i) {\n      *largestComponentSize_local_pointer =\n          max(*largestComponentSize_local_pointer, largestComponentSize_local[threadIdx.y][threadIdx.x + i]);\n      __syncthreads();\n    }\n  }\n  // Store the result to global memory.\n  *largestComponentSize_global_pointer = *largestComponentSize_local_pointer;\n\n  // Merge the results from the global memory.\n  if (threadIdx.x == 0) {\n    for (int i = 0; i < N; i += TILE_SIZE) {\n      largestComponentSize_global = max(largestComponentSize_global, largestComponentSize[i + blockIdx.x * N]);\n    }\n    largestComponentSize[blockIdx.x * N] = largestComponentSize_global;\n  }\n}",
            "int maxIndex = 0;\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N && j < N && A[i * N + j] == 1) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (i!= k && j!= k && A[i * N + k] == 1 && A[k * N + j] == 1) {\n\t\t\t\tmaxIndex = max(maxIndex, A[i * N + k]);\n\t\t\t}\n\t\t}\n\t\tif (maxIndex > 0) {\n\t\t\tA[i * N + j] = maxIndex;\n\t\t\tA[j * N + i] = maxIndex;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (i == 0 && j == 0) {\n\t\tmaxIndex = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tmaxIndex = max(maxIndex, A[i * N + j]);\n\t\t\t}\n\t\t}\n\t\t*largestComponentSize = maxIndex;\n\t}\n}",
            "//\n  __shared__ int scc_ids[TILE_DIM][TILE_DIM]; // block size is set at 32\n  __shared__ int scc_size[TILE_DIM][TILE_DIM];\n  __shared__ int scc_size_array[TILE_DIM];\n  const int i = blockIdx.x * blockDim.x + threadIdx.x;\n  const int j = blockIdx.y * blockDim.y + threadIdx.y;\n  int component_id = -1;\n  int component_size = 0;\n\n  if (i >= N || j >= N) {\n    return;\n  }\n\n  if (A[i * N + j] == 1) {\n    component_id = 0;\n  }\n\n  scc_ids[threadIdx.y][threadIdx.x] = component_id;\n  scc_size[threadIdx.y][threadIdx.x] = 1;\n  __syncthreads();\n\n  for (int k = 0; k < blockDim.x; k++) {\n    if (scc_ids[threadIdx.y][threadIdx.x] ==\n        scc_ids[threadIdx.y][k]) // check if the component id is the same\n      scc_size[threadIdx.y][threadIdx.x] += scc_size[threadIdx.y][k];\n  }\n  __syncthreads();\n\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    component_size = 0;\n    for (int k = 0; k < blockDim.x; k++) {\n      component_size += scc_size[threadIdx.y][k];\n    }\n    scc_size_array[threadIdx.y] = component_size;\n  }\n  __syncthreads();\n\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    atomicMax(largestComponentSize, scc_size_array[threadIdx.y]);\n  }\n}",
            "// Get the index of the thread that runs this instance\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Breadth First Search using a queue\n\tif (tid == 0) {\n\t\t// Create a queue\n\t\tqueue<int> queue;\n\n\t\t// Initialize every vertex as not visited\n\t\tvector<int> visited(N, 0);\n\n\t\t// Enqueue the first vertex\n\t\tqueue.push(0);\n\n\t\t// Mark the first vertex as visited\n\t\tvisited[0] = 1;\n\n\t\twhile (!queue.empty()) {\n\t\t\t// Dequeue a vertex\n\t\t\tint deq = queue.front();\n\t\t\tqueue.pop();\n\n\t\t\t// Visit all the neighbours of the dequeued vertex\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t// If the edge exists between vertex deq and the current vertex\n\t\t\t\tif (A[deq * N + i] &&!visited[i]) {\n\t\t\t\t\t// Mark the current vertex as visited and enqueue it\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\tqueue.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Get the count of the vertices that are visited\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited[i]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\n\t\t// Store the result\n\t\t*largestComponentSize = count;\n\t}\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\tif (i < N && j < N && A[i * N + j]!= 0) {\n\t\tatomicMax(largestComponentSize, 1 + getLargestComponentSize(A, N, i, j));\n\t}\n}",
            "int row = blockIdx.x;\n    int col = threadIdx.x;\n    extern __shared__ int S[];\n    int largestSize = 0;\n    int componentSize = 0;\n    if (row < N && col < N) {\n        S[threadIdx.x] = A[row * N + col];\n        __syncthreads();\n        if (S[col] == 1) {\n            componentSize = 1;\n            while (col < N) {\n                if (S[col] == 1)\n                    componentSize++;\n                col += blockDim.x;\n            }\n            if (componentSize > largestSize)\n                largestSize = componentSize;\n        }\n    }\n    __syncthreads();\n    atomicAdd(largestComponentSize, largestSize);\n}",
            "// compute the index of the current vertex in the adjacency matrix\n\tint currentVertexIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// we have reached the end of the vertices so we do nothing\n\tif (currentVertexIdx >= N)\n\t\treturn;\n\n\t// check if vertex is part of the largest component\n\t// if it is, set the current index to 0 and return\n\tif (A[currentVertexIdx * N + currentVertexIdx] == 0)\n\t\treturn;\n\n\t// if it isn't, set it to 1 and continue\n\tA[currentVertexIdx * N + currentVertexIdx] = 1;\n\n\t// iterate through the neighbors of the current vertex\n\t// if they are 1, set them to 0\n\tfor (int neighborIdx = currentVertexIdx + 1; neighborIdx < N; neighborIdx++) {\n\t\tif (A[currentVertexIdx * N + neighborIdx] == 1) {\n\t\t\tA[currentVertexIdx * N + neighborIdx] = 0;\n\t\t\tA[neighborIdx * N + currentVertexIdx] = 0;\n\t\t}\n\t}\n}",
            "__shared__ int compSize[COMPONENT_SIZE];\n\n  int j = threadIdx.x;\n  int i = blockIdx.x;\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n\n  __shared__ int compCount;\n  __shared__ int compIndex;\n  __shared__ int index[COMPONENT_SIZE];\n\n  if (tid == 0) {\n    compCount = 0;\n    compIndex = 0;\n  }\n  __syncthreads();\n\n  int value = A[i*N + j];\n\n  if (value == 1) {\n    compSize[compIndex] = 0;\n    index[compIndex] = i;\n    compIndex++;\n  }\n  __syncthreads();\n\n  for (int k = 0; k < compIndex; k++) {\n    if (i == index[k]) {\n      for (int l = 0; l < compIndex; l++) {\n        if (l!= k) {\n          if (A[index[k]*N + index[l]] == 1) {\n            compSize[k]++;\n          }\n        }\n      }\n      break;\n    }\n  }\n  __syncthreads();\n\n  int max = 0;\n  int maxIndex = 0;\n  for (int k = 0; k < compIndex; k++) {\n    if (max < compSize[k]) {\n      max = compSize[k];\n      maxIndex = k;\n    }\n  }\n  __syncthreads();\n\n  if (i == maxIndex) {\n    *largestComponentSize = max + 1;\n  }\n}",
            "// Get the thread's id and index into the adjacency matrix.\n\tsize_t idx = threadIdx.x + blockIdx.x * blockDim.x;\n\tsize_t idy = threadIdx.y + blockIdx.y * blockDim.y;\n\n\t// Check whether the thread's id is in the range of the matrix.\n\tif (idx >= N || idy >= N) {\n\t\treturn;\n\t}\n\n\t// Get the value at the current position of the adjacency matrix.\n\tint val = A[idx * N + idy];\n\n\t// Perform a breadth-first search starting at the vertex that's currently at the top of the stack.\n\tint size = 1;\n\tint stack[10000];\n\tint top = 0;\n\tstack[top++] = idx;\n\twhile (top > 0) {\n\t\t// Pop the top element off the stack and set it to current.\n\t\tint current = stack[--top];\n\t\t// Traverse over all vertices adjacent to the current vertex.\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t// Check whether the current and adjacent vertex are connected and the current vertex has not been explored.\n\t\t\tif (A[current * N + j]!= 0 && A[current * N + j] == val && A[idx * N + j] == 0) {\n\t\t\t\tstack[top++] = j;\n\t\t\t\tA[idx * N + j] = 1;\n\t\t\t\t++size;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Write the size of the largest component to the device.\n\tatomicMax(largestComponentSize, size);\n}",
            "// Write your code here\n}",
            "__shared__ int sdata[BLOCK_SIZE];\n  __shared__ bool sdataS[BLOCK_SIZE];\n\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int cache = 0;\n  if (tid < N) {\n    for (int j = 0; j < N; j++)\n      if (A[j * N + tid] > 0)\n        cache += 1;\n    sdata[threadIdx.x] = cache;\n    sdataS[threadIdx.x] = cache > 0;\n  }\n  __syncthreads();\n\n  int i = blockDim.x / 2;\n  while (i!= 0) {\n    if (threadIdx.x < i) {\n      if (sdataS[threadIdx.x + i]) {\n        sdata[threadIdx.x] += sdata[threadIdx.x + i];\n        sdataS[threadIdx.x] = true;\n      } else {\n        sdataS[threadIdx.x] = sdataS[threadIdx.x + i];\n      }\n    }\n    __syncthreads();\n    i /= 2;\n  }\n\n  if (threadIdx.x == 0) {\n    atomicAdd(largestComponentSize, sdata[0]);\n  }\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n  int col = blockDim.y * blockIdx.y + threadIdx.y;\n\n  if (row >= N || col >= N || row >= col || A[row + col * N] == 0) return;\n  atomicMin(largestComponentSize, N - 1);\n}",
            "// your code here\n}",
            "// Your code here\n}",
            "int row = threadIdx.x;\n\tint col = blockIdx.x;\n\tint size;\n\tint val = A[row + col * N];\n\n\t// If we are not on the diagonal, compute the number of components the vertex is in.\n\tif (row!= col) {\n\t\tsize = 1;\n\t\tif (val == 1) {\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[i + col * N] == 1) {\n\t\t\t\t\tsize++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t// We are on the diagonal, so compute the size of the vertex's connected component\n\telse {\n\t\tsize = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[row + i * N] == 1) {\n\t\t\t\tsize++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(largestComponentSize, size);\n}",
            "extern __shared__ int sData[];\n\tint *sDataGlobal = sData;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint total = 0;\n\tif (tid < N) {\n\t\tint v = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[tid * N + i] == 1) {\n\t\t\t\tsData[v] = i;\n\t\t\t\tv++;\n\t\t\t}\n\t\t}\n\t\ttotal = v;\n\t}\n\t// reduce to 1 per block\n\t__syncthreads();\n\n\t// reduce within block\n\tfor (int i = 0; i < blockDim.x / 2; i++) {\n\t\tint index = threadIdx.x + i * (blockDim.x / 2);\n\t\tif (index < total) {\n\t\t\tsData[index] = sData[index] + sData[index + (blockDim.x / 2)];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// reduce to 1 per block\n\t__syncthreads();\n\n\t// reduce to 1 per grid\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = sDataGlobal[0];\n\t}\n}",
            "int rowId = blockIdx.x;\n  int columnId = blockIdx.y;\n  int myId = rowId * N + columnId;\n  extern __shared__ int myLargestComponentSize[];\n  myLargestComponentSize[myId] = 0;\n  if (A[myId]) {\n    myLargestComponentSize[myId] = 1;\n    __syncthreads();\n    for (int i = 1; i < N; i <<= 1) {\n      if (myId >= i)\n        myLargestComponentSize[myId] += myLargestComponentSize[myId - i];\n      __syncthreads();\n    }\n  }\n  if (threadIdx.x == 0) {\n    atomicAdd(largestComponentSize, myLargestComponentSize[myId]);\n  }\n}",
            "const int i = threadIdx.y * N + threadIdx.x;\n\tint index = 0;\n\tint id;\n\tint idNext;\n\tint color;\n\tint colorNext;\n\tint numVertex = 0;\n\tint *visited = (int *) malloc(sizeof(int) * N);\n\tint *visitedNext = (int *) malloc(sizeof(int) * N);\n\tint *colorA = (int *) malloc(sizeof(int) * N);\n\n\t// Init visited\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tvisitedNext[i] = 0;\n\t}\n\n\twhile (numVertex!= N) {\n\t\t// Init color\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tcolorA[i] = 0;\n\t\t}\n\n\t\t// Traverse the graph\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[index] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (visited[index] == 0) {\n\t\t\t\tid = index;\n\t\t\t\tcolor = colorA[index];\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[id] == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tidNext = id + j;\n\t\t\t\t\tif (visited[idNext] == 0) {\n\t\t\t\t\t\tvisitedNext[idNext] = 1;\n\t\t\t\t\t\tcolorA[idNext] = color + 1;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcolorNext = colorA[idNext];\n\t\t\t\t\t\tif (colorNext < color) {\n\t\t\t\t\t\t\tcolorA[idNext] = color;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tvisited[index] = 1;\n\t\t\t\tnumVertex++;\n\t\t\t}\n\t\t\tindex++;\n\t\t}\n\n\t\t// Init visited\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tvisited[i] = visitedNext[i];\n\t\t}\n\t}\n\tint max = colorA[0];\n\tfor (int i = 1; i < N; i++) {\n\t\tif (colorA[i] > max) {\n\t\t\tmax = colorA[i];\n\t\t}\n\t}\n\t*largestComponentSize = max;\n}",
            "// Set the number of threads in a thread block\n\tunsigned int numThreads = 128;\n\n\t// Obtain this thread's unique global ID\n\tint gid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// If this thread is processing an element within the bounds of the input\n\t// matrix, process it; otherwise, do not access the input matrix\n\tif (gid < N * N) {\n\n\t\t// This thread's matrix column index\n\t\tint j = gid / N;\n\n\t\t// This thread's matrix row index\n\t\tint i = gid % N;\n\n\t\t// If this thread is currently processing a non-zero element, continue;\n\t\t// otherwise, stop here\n\t\tif (A[gid] == 0) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Initialize this thread's visited list\n\t\tint visited[N];\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[j] = 0;\n\t\t}\n\n\t\t// Start with an empty set\n\t\tint set[N];\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tset[j] = 0;\n\t\t}\n\n\t\t// Set the first node in the set\n\t\tset[i] = 1;\n\n\t\t// Iterate over all the other nodes in the graph and add them to the set\n\t\t// if they are adjacent to the node being processed\n\t\tfor (int j = 0; j < N; j++) {\n\n\t\t\t// If this node has already been visited, continue\n\t\t\tif (visited[j] == 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// Determine if this node is adjacent to the node being processed\n\t\t\tint adjacent = 0;\n\t\t\tif (A[j * N + i] == 1) {\n\t\t\t\tadjacent = 1;\n\t\t\t}\n\n\t\t\t// If this node is adjacent to the node being processed, add it to\n\t\t\t// the set\n\t\t\tif (adjacent == 1) {\n\t\t\t\tset[j] = 1;\n\t\t\t}\n\n\t\t\t// If this node is not adjacent to the node being processed, add it\n\t\t\t// to the visited list and continue\n\t\t\telse {\n\t\t\t\tvisited[j] = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t// Obtain the number of elements in the set\n\t\tint setSize = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (set[j] == 1) {\n\t\t\t\tsetSize++;\n\t\t\t}\n\t\t}\n\n\t\t// If this thread's set is larger than the global largest component, store\n\t\t// this thread's set size in the global largest component\n\t\tif (setSize > *largestComponentSize) {\n\t\t\t*largestComponentSize = setSize;\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "__shared__ bool visited[BLOCK_SIZE];\n    for (int i = 0; i < BLOCK_SIZE; i++) {\n        visited[i] = false;\n    }\n\n    // Each thread processes one row of the matrix.\n    int start = N * blockIdx.x;\n    int row = threadIdx.x + start;\n    int currentVertex = -1;\n    int componentSize = 0;\n\n    // If this thread's row exists.\n    if (row < N) {\n        currentVertex = row;\n        visited[threadIdx.x] = true;\n        componentSize = 1;\n    }\n\n    // Mark all vertices in the same component as visited.\n    for (int i = 0; i < N; i++) {\n        if (A[row * N + i]!= 0 && visited[i] == false) {\n            visited[i] = true;\n            componentSize++;\n        }\n    }\n\n    // Add the size of the component to the total size of the largest component.\n    atomicAdd(largestComponentSize, componentSize);\n}",
            "int globalID = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = globalID/N;\n\tint j = globalID%N;\n\n\tif (i >= N || j >= N) return;\n\n\tif (i == j) return;\n\n\tif (A[i*N + j]!= 0) {\n\t\tatomicMin(largestComponentSize, 1);\n\t\treturn;\n\t}\n\n\tatomicAdd(largestComponentSize, 1);\n\n}",
            "int myID = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tif (myID < N * N) {\n\t\tint i = myID / N;\n\t\tint j = myID % N;\n\n\t\tif (A[myID] == 1) {\n\t\t\tatomicMax(largestComponentSize, max(N - i, N - j));\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int rid = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (tid < N && rid < N) {\n        if (A[tid * N + rid] > 0) {\n            // Note: If the graph is not fully connected,\n            //       the largest component size will be less than N.\n            //       In this case, set largestComponentSize to the largest component size found.\n            //       Otherwise, set largestComponentSize to N, the maximum component size.\n            *largestComponentSize = N;\n        }\n    }\n}",
            "// Your code here\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "mpi",
        "prompt": "#include <mpi.h>\n\n/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t/* Your solution goes here  */\n\treturn 0;\n}",
            "int num_nodes = N;\n\tint num_ranks;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\tint num_per_rank = num_nodes/num_ranks;\n\tint extra = num_nodes%num_ranks;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint start = rank * num_per_rank;\n\tint end = start + num_per_rank;\n\tif(rank == 0){\n\t\tstart = 0;\n\t}\n\tif(rank == num_ranks - 1){\n\t\tend = num_nodes;\n\t}\n\tint max_comp = 0;\n\tfor(int i = start; i < end; i++){\n\t\tint current_comp = 0;\n\t\tstd::vector<bool> visited(N, false);\n\t\tstd::queue<int> to_visit;\n\t\tto_visit.push(i);\n\t\tvisited[i] = true;\n\t\twhile(!to_visit.empty()){\n\t\t\tint node = to_visit.front();\n\t\t\tto_visit.pop();\n\t\t\tcurrent_comp++;\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(A[node*N+j] &&!visited[j]){\n\t\t\t\t\tto_visit.push(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif(current_comp > max_comp){\n\t\t\tmax_comp = current_comp;\n\t\t}\n\t}\n\tint max_comp_all = 0;\n\tMPI_Reduce(&max_comp, &max_comp_all, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn max_comp_all;\n}",
            "int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // TODO\n\n    return 0;\n}",
            "int maxSize = 1;\n\tstd::vector<int> components(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]) {\n\t\t\t\tif (components[i] == 0) {\n\t\t\t\t\tcomponents[i] = j;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tint c = components[i];\n\t\t\t\t\twhile (components[c]!= 0) {\n\t\t\t\t\t\tc = components[c];\n\t\t\t\t\t}\n\t\t\t\t\tcomponents[c] = j;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint compCount = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (components[i] == i) {\n\t\t\tcompCount++;\n\t\t}\n\t}\n\treturn compCount;\n}",
            "// TODO\n}",
            "// TODO: your code here\n\n}",
            "// TODO\n  return 1;\n}",
            "//...\n\treturn 0;\n}",
            "// TODO: implement this function\n}",
            "const int num_proc = 4;\n  int rank, my_size, i, j;\n  int start, end, proc_size, proc_start, proc_end;\n  int *my_A, *recv_A;\n  int recv_count, recv_from, total_count;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &my_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (my_size!= num_proc) {\n    std::cerr << \"Error: wrong number of processors\\n\";\n    exit(1);\n  }\n\n  start = rank * (N / my_size);\n  end = (rank + 1) * (N / my_size) - 1;\n  proc_size = end - start + 1;\n\n  proc_start = rank * proc_size;\n  proc_end = proc_start + proc_size - 1;\n\n  my_A = new int[proc_size * proc_size];\n\n  for (i = 0; i < proc_size; i++) {\n    for (j = 0; j < proc_size; j++) {\n      my_A[i * proc_size + j] = A[proc_start + i][proc_start + j];\n    }\n  }\n\n  MPI_Allreduce(&proc_size, &total_count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  recv_count = 0;\n  for (i = 0; i < num_proc; i++) {\n    if (i!= rank) {\n      MPI_Status status;\n      MPI_Probe(i, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n      if (status.MPI_TAG == 0) {\n        MPI_Get_count(&status, MPI_INT, &recv_count);\n        break;\n      }\n    }\n  }\n\n  recv_A = new int[recv_count];\n  MPI_Allgather(&proc_size, 1, MPI_INT, &recv_count, 1, MPI_INT, MPI_COMM_WORLD);\n  MPI_Gather(my_A, proc_size, MPI_INT, recv_A, proc_size, MPI_INT, 0, MPI_COMM_WORLD);\n\n  //std::cout << \"Rank: \" << rank << \", size: \" << proc_size << \", total: \" << total_count << std::endl;\n\n  int *component_sizes = new int[total_count];\n  for (i = 0; i < total_count; i++) {\n    component_sizes[i] = 1;\n  }\n\n  for (i = 0; i < total_count; i++) {\n    for (j = 0; j < total_count; j++) {\n      if (recv_A[i * total_count + j]) {\n        component_sizes[i] += component_sizes[j];\n      }\n    }\n  }\n\n  int max = 0;\n  for (i = 0; i < total_count; i++) {\n    if (component_sizes[i] > max) {\n      max = component_sizes[i];\n    }\n  }\n\n  return max;\n}",
            "/* TODO */\n    int largest = 0;\n    int component;\n\n    for (int i = 0; i < N; i++) {\n        for (int j = i + 1; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                int min_val = 0;\n                for (int k = 0; k < N; k++) {\n                    if (A[i * N + k] == 1 && A[j * N + k] == 1) {\n                        min_val++;\n                    }\n                }\n                component = (min_val >= largest)? min_val : largest;\n                largest = component;\n            }\n        }\n    }\n\n    return largest;\n}",
            "// TODO\n}",
            "// TODO: implement\n\t\n    return 0;\n}",
            "// Your code here\n}",
            "int numVertices = N;\n\tint* A_array = new int[numVertices*numVertices];\n\tfor(int i = 0; i < numVertices; i++){\n\t\tfor(int j = 0; j < numVertices; j++){\n\t\t\tA_array[i*numVertices+j] = A[i*numVertices+j];\n\t\t}\n\t}\n\tMPI_Comm comm = MPI_COMM_WORLD;\n\tint rank, size;\n\tMPI_Comm_rank(comm, &rank);\n\tMPI_Comm_size(comm, &size);\n\n\tint numVertices_rank = numVertices/size;\n\tint numVertices_rem = numVertices%size;\n\n\tif(rank < numVertices_rem){\n\t\tnumVertices_rank++;\n\t}\n\tint* A_array_rank = new int[numVertices_rank*numVertices_rank];\n\tif(rank < numVertices_rem){\n\t\tfor(int i = 0; i < numVertices_rank*numVertices_rank; i++){\n\t\t\tA_array_rank[i] = A_array[i+rank*numVertices_rank];\n\t\t}\n\t}\n\telse{\n\t\tfor(int i = 0; i < numVertices_rank*numVertices_rank; i++){\n\t\t\tA_array_rank[i] = A_array[i+(rank-numVertices_rem)*numVertices_rank];\n\t\t}\n\t}\n\n\tint* A_array_rank_new = new int[numVertices_rank*numVertices_rank];\n\n\tfor(int i = 0; i < numVertices_rank; i++){\n\t\tfor(int j = 0; j < numVertices_rank; j++){\n\t\t\tA_array_rank_new[i*numVertices_rank+j] = A_array_rank[i*numVertices_rank+j];\n\t\t}\n\t}\n\n\tint max = 0;\n\tfor(int i = 0; i < numVertices_rank; i++){\n\t\tfor(int j = 0; j < numVertices_rank; j++){\n\t\t\tif(A_array_rank_new[i*numVertices_rank+j] == 1){\n\t\t\t\tint counter = 0;\n\t\t\t\tstd::vector<int> visited;\n\t\t\t\tstd::vector<std::vector<int>> allVisited;\n\t\t\t\tfor(int k = 0; k < numVertices_rank; k++){\n\t\t\t\t\tif(A_array_rank_new[i*numVertices_rank+k] == 1){\n\t\t\t\t\t\tvisited.push_back(k);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tallVisited.push_back(visited);\n\t\t\t\tcounter++;\n\t\t\t\twhile(counter < numVertices_rank){\n\t\t\t\t\tint nextVert = -1;\n\t\t\t\t\tfor(int k = 0; k < visited.size(); k++){\n\t\t\t\t\t\tfor(int l = 0; l < numVertices_rank; l++){\n\t\t\t\t\t\t\tif(A_array_rank_new[visited[k]*numVertices_rank+l] == 1 && std::find(visited.begin(), visited.end(), l) == visited.end()){\n\t\t\t\t\t\t\t\tvisited.push_back(l);\n\t\t\t\t\t\t\t\tallVisited[counter-1].push_back(l);\n\t\t\t\t\t\t\t\tnextVert = l;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(nextVert!= -1){\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcounter++;\n\t\t\t\t\tallVisited.push_back(visited);\n\t\t\t\t}\n\t\t\t\tif(max < allVisited.size()){",
            "int num = A.size() / N;\n    std::vector<int> A_reduced(num, 0);\n\n    MPI_Reduce(A.data(), A_reduced.data(), num, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    if (A_reduced[0] == 0)\n        return 0;\n\n    return 1;\n}",
            "const int nprocs = MPI_Comm_size(MPI_COMM_WORLD);\n  const int myrank = MPI_Comm_rank(MPI_COMM_WORLD);\n  int count = 0;\n  std::vector<std::vector<bool>> components(nprocs, std::vector<bool>(N, false));\n\n  std::vector<std::vector<bool>> B;\n  MPI_Gather(A.data(), N * N, MPI_INT, &B, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // if I'm rank 0, I do all the work!\n  if (myrank == 0) {\n    std::vector<bool> seen(N, false);\n    for (int r = 0; r < nprocs; r++) {\n      for (int i = 0; i < N; i++) {\n        if (B[r][i] == 0) {\n          continue;\n        }\n        if (seen[i]) {\n          continue;\n        }\n        std::vector<bool> component(N, false);\n        component[i] = true;\n        int curr = i;\n        int next = i;\n        while (B[r][next]!= 0) {\n          component[next] = true;\n          curr = next;\n          for (int j = 0; j < N; j++) {\n            if (B[r][j] == 0) {\n              continue;\n            }\n            if (j == curr) {\n              continue;\n            }\n            if (component[j]) {\n              next = j;\n              break;\n            }\n          }\n        }\n        for (int j = 0; j < N; j++) {\n          if (B[r][j] == 0) {\n            continue;\n          }\n          if (component[j]) {\n            seen[j] = true;\n            components[r][j] = true;\n          }\n        }\n      }\n    }\n    count = 0;\n    for (int r = 0; r < nprocs; r++) {\n      for (int i = 0; i < N; i++) {\n        if (components[r][i]) {\n          count++;\n        }\n      }\n    }\n  }\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return count;\n}",
            "int const size = A.size();\n  // TODO: compute largest component using MPI\n}",
            "// TODO: replace this with your code\n    // You should use MPI calls to compute a solution.\n    // MPI_Barrier, MPI_Bcast, MPI_Reduce, and MPI_Allreduce\n    // should be used as appropriate to keep things running in parallel.\n    // Use the function `isConnected` to determine if two vertices are connected.\n    return 0;\n}",
            "// TODO: Implement this function\n  int rank, size;\n  int vertexCount = A.size();\n  int visited[vertexCount];\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int maxComponentSize = 0;\n\n  for (int i = 0; i < vertexCount; ++i)\n    visited[i] = 0;\n\n  visited[0] = 1;\n  int sizeComponent = 1;\n\n  for (int i = 0; i < vertexCount; ++i)\n  {\n    if (visited[i])\n    {\n      for (int j = 0; j < vertexCount; ++j)\n      {\n        if (A[i * vertexCount + j] &&!visited[j])\n        {\n          visited[j] = 1;\n          sizeComponent++;\n        }\n      }\n    }\n  }\n  maxComponentSize = sizeComponent;\n  int totalComponentSize = 0;\n  MPI_Reduce(&maxComponentSize, &totalComponentSize, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return totalComponentSize;\n}",
            "// COMPLETE THIS FUNCTION\n\treturn 0;\n}",
            "// TODO: Your code here.\n}",
            "int numRanks;\n    MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    std::vector<std::vector<int>> components(numRanks, std::vector<int>());\n    std::vector<std::vector<int>> reachable(numRanks, std::vector<int>());\n\n    // TODO\n\n    return 0;\n}",
            "// Your code here\n\tint size, rank;\n\tsize = A.size();\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint N = sqrt(size);\n\n\tint local_rows = N/size;\n\tint local_cols = local_rows;\n\tint local_size = local_rows*local_cols;\n\tint global_size = N*N;\n\tint start_row = rank*local_rows;\n\tint start_col = rank*local_cols;\n\n\t//Create a local copy of A\n\tstd::vector<int> localA(local_size);\n\tfor(int i = start_row; i < start_row+local_rows; i++) {\n\t\tfor(int j = start_col; j < start_col+local_cols; j++) {\n\t\t\tint index = (i-start_row)*local_cols + j-start_col;\n\t\t\tlocalA[index] = A[i*N+j];\n\t\t}\n\t}\n\t\n\t//Create a map of localA\n\tstd::map<int, std::vector<int>> map_localA;\n\tfor(int i = 0; i < local_size; i++) {\n\t\tif(localA[i] == 1) {\n\t\t\tint row = i/local_cols;\n\t\t\tint col = i%local_cols;\n\t\t\tint value = row*N + col;\n\t\t\tmap_localA[value].push_back(value);\n\t\t}\n\t}\n\n\t//Do BFS on localA\n\tstd::queue<int> q;\n\tstd::vector<int> visited(local_size, 0);\n\tfor(int i = 0; i < local_size; i++) {\n\t\tif(visited[i] == 0) {\n\t\t\tq.push(i);\n\t\t\twhile(!q.empty()) {\n\t\t\t\tint u = q.front();\n\t\t\t\tint row = u/local_cols;\n\t\t\t\tint col = u%local_cols;\n\t\t\t\tint value = row*N + col;\n\t\t\t\tq.pop();\n\t\t\t\tvisited[u] = 1;\n\t\t\t\tfor(int j = 0; j < map_localA[value].size(); j++) {\n\t\t\t\t\tif(visited[j] == 0) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t//Create a global map of A\n\tstd::map<int, std::vector<int>> map_globalA;\n\tint count = 0;\n\tfor(int i = start_row; i < start_row+local_rows; i++) {\n\t\tfor(int j = start_col; j < start_col+local_cols; j++) {\n\t\t\tint index = (i-start_row)*local_cols + j-start_col;\n\t\t\tif(visited[index] == 1) {\n\t\t\t\tmap_globalA[count].push_back(i*N + j);\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\t//Reduce to get global map\n\tint size_local = map_globalA.size();\n\tint size_global;\n\tMPI_Reduce(&size_local, &size_global, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif(rank == 0) {\n\t\tstd::vector<int> all_values(size_global);\n\t\tstd::map<int, std::vector<int>> map_global;\n\t\tMPI_Reduce(MPI_IN_PLACE, all_values.data(), size_global, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\tfor(int i = 0; i < size_global; i++) {\n\t\t\tmap_global[all_values[i]].",
            "int componentCount = 0;\n    std::vector<int> componentSize(N, 0);\n    std::vector<int> componentId(N, -1);\n    for (size_t i = 0; i < N; i++) {\n        // TODO\n    }\n    return componentCount;\n}",
            "// TODO: fill this in\n  return 0;\n}",
            "// TODO\n}",
            "// Your code here\n}",
            "// TODO: implement\n}",
            "// TODO: implement\n    int size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int out[size];\n    int *local = new int[N*N];\n    for (int i=0; i<N; i++) {\n        for (int j=0; j<N; j++) {\n            local[i*N+j] = A[i*N+j];\n        }\n    }\n    std::vector<std::vector<int>> components(size);\n    for (int i=0; i<N; i++) {\n        for (int j=0; j<N; j++) {\n            if (i!= j && local[i*N+j] == 1) {\n                local[j*N+i] = 0;\n            }\n        }\n    }\n    int tmp[N*N];\n    MPI_Barrier(MPI_COMM_WORLD);\n    for (int i=0; i<N; i++) {\n        for (int j=0; j<N; j++) {\n            tmp[i*N+j] = local[i*N+j];\n        }\n    }\n    for (int i=0; i<size; i++) {\n        for (int j=0; j<N; j++) {\n            for (int k=0; k<N; k++) {\n                if (i!= rank && tmp[j*N+k] == 1) {\n                    tmp[j*N+k] = 0;\n                }\n            }\n        }\n    }\n    for (int i=0; i<N; i++) {\n        for (int j=0; j<N; j++) {\n            local[i*N+j] = tmp[i*N+j];\n        }\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n    std::vector<int> v(N);\n    for (int i=0; i<N; i++) {\n        v[i] = 1;\n    }\n    int vv = 1;\n    int max = 0;\n    for (int i=0; i<size; i++) {\n        int count = 0;\n        for (int j=0; j<N; j++) {\n            if (local[i*N+j] == 1) {\n                count++;\n            }\n        }\n        if (count == N) {\n            vv++;\n            max = N;\n        } else if (count > 0) {\n            vv++;\n            max = N;\n        }\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n    MPI_Gather(&vv, 1, MPI_INT, &out, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    if (rank == 0) {\n        std::cout << \"",
            "assert(A.size() == N*N);\n\n\tint total = 0;\n\tMPI_Reduce(&total, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (total > 0) {\n\t\treturn 1;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "// TODO: replace this line with your solution\n  return -1;\n}",
            "// your code here\n  int root = 0;\n  int p = 0;\n  MPI_Bcast(&p, 1, MPI_INT, root, MPI_COMM_WORLD);\n  if (p == 0) {\n    int rank = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    if (rank == root) {\n      std::vector<int> visited(N, 0);\n      std::queue<int> q;\n      int n = 0;\n      for (int i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n          q.push(i);\n          while (!q.empty()) {\n            int cur = q.front();\n            q.pop();\n            if (visited[cur] == 0) {\n              ++n;\n              visited[cur] = 1;\n              for (int j = 0; j < N; ++j) {\n                if (A[cur * N + j] == 1 && visited[j] == 0) {\n                  q.push(j);\n                }\n              }\n            }\n          }\n        }\n      }\n      return n;\n    }\n  }\n  return 0;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint *count = new int[size];\n\tint *displ = new int[size];\n\tdispl[0] = 0;\n\tfor (int i = 1; i < size; i++) {\n\t\tdispl[i] = displ[i - 1] + N / size;\n\t}\n\tMPI_Gatherv(A.data(), N / size, MPI_INT, NULL, count, displ, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tint res = 0;\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tres += count[i];\n\t\t}\n\t\treturn res;\n\t}\n\treturn 0;\n}",
            "if (A.size()!= N*N) throw std::length_error(\"A must be an NxN matrix\");\n  std::vector<bool> inComponent(N, true);\n  int rank = 0, size = 1;\n  // Your code here\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  if (rank == 0) {\n    int *displs = new int[size];\n    int *recvcounts = new int[size];\n    int *sendcounts = new int[size];\n    int *sendbuf = new int[N];\n    int *recvbuf = new int[N];\n    int cnt = 0;\n    int num = 0;\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        sendbuf[cnt] = A[i*N + j];\n        cnt++;\n      }\n    }\n    int displs_cnt = 0;\n    int recvcounts_cnt = 0;\n    for (int i = 0; i < size; i++) {\n      displs[i] = displs_cnt;\n      recvcounts[i] = N;\n      displs_cnt += N;\n      recvcounts_cnt += N;\n    }\n    for (int i = 0; i < size; i++) {\n      if (i!= 0) {\n        MPI_Send(&sendbuf[i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n      }\n    }\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&recvbuf, N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      for (int j = 0; j < N; j++) {\n        if (recvbuf[j]!= 0) {\n          for (int k = 0; k < N; k++) {\n            if (A[j*N + k] == 0) {\n              if (inComponent[k]) {\n                inComponent[k] = false;\n                num++;\n              }\n            }\n          }\n        }\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      if (A[i*N + i] == 0 && inComponent[i]) {\n        inComponent[i] = false;\n        num++;\n      }\n    }\n    std::cout << \"Total: \" << num << std::endl;\n  } else {\n    int *sendbuf = new int[N];\n    int *recvbuf = new int[N];\n    int *displs = new int[1];\n    int *recvcounts = new int[1];\n    int *sendcounts = new int[1];\n    displs[0] = 0;\n    recvcounts[0] = N;\n    sendcounts[0] = N;\n    MPI_Recv(&recvbuf, N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    for (int i = 0; i < N; i++) {\n      if (recvbuf[i]!= 0) {\n        for (int j = 0; j < N; j++) {\n          if (A[i*N + j] == 0) {\n            if (inComponent[j]) {\n              inComponent[j] = false;\n            }\n          }\n        }\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      if (A[i*N + i] == 0 && inComponent[i]) {\n        inComponent[i] = false;\n      }\n    }\n  }\n  return 0;\n}",
            "int largest_comp = 1;\n\tstd::vector<int> adj_matrix(N * N);\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tadj_matrix[i * N + j] = A[i * N + j];\n\t\t}\n\t}\n\t// std::vector<int> adj_matrix = A;\n\tstd::vector<int> visited(N, 0);\n\n\tfor (int i = 0; i < N; i++) {\n\t\t// if (visited[i]) continue;\n\t\tint curr = i;\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\tint curr_size = 0;\n\t\tvisited[curr] = 1;\n\t\twhile (q.size()) {\n\t\t\tint curr = q.front();\n\t\t\tq.pop();\n\t\t\tcurr_size++;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (adj_matrix[curr * N + j] &&!visited[j]) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tlargest_comp = max(largest_comp, curr_size);\n\t}\n\treturn largest_comp;\n}",
            "int result = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &result);\n\tint rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint nproc = result;\n\n\tif (N % nproc!= 0)\n\t\tthrow std::runtime_error(\"N must be divisible by the number of processes.\");\n\n\tint n = N / nproc;\n\n\tint* p = new int[N];\n\tint* q = new int[N];\n\tint* c = new int[N];\n\tint* d = new int[N];\n\tstd::fill(p, p+N, 0);\n\tstd::fill(q, q+N, 0);\n\tstd::fill(c, c+N, 0);\n\tstd::fill(d, d+N, 0);\n\n\tfor (int i = rank*n; i < (rank+1)*n; ++i) {\n\t\tfor (int j = 0; j < n; ++j) {\n\t\t\tp[i] += A[i*N+j];\n\t\t\tq[j] += A[i*N+j];\n\t\t}\n\t}\n\n\tMPI_Allreduce(MPI_IN_PLACE, p, N, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\tMPI_Allreduce(MPI_IN_PLACE, q, N, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\tfor (int i = rank*n; i < (rank+1)*n; ++i) {\n\t\tfor (int j = 0; j < n; ++j) {\n\t\t\tc[i] += p[j];\n\t\t\td[j] += q[i];\n\t\t}\n\t}\n\n\tint lcm = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (c[i] == N && d[i] == N)\n\t\t\t++lcm;\n\t}\n\n\tdelete[] p;\n\tdelete[] q;\n\tdelete[] c;\n\tdelete[] d;\n\n\treturn lcm;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tstd::vector<int> componentSizes(size);\n\tMPI_Gather(&N, 1, MPI_INT, componentSizes.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tstd::cout << \"Gathered component sizes:\";\n\t\tfor (size_t i = 0; i < size; ++i) {\n\t\t\tstd::cout << \" \" << componentSizes[i];\n\t\t}\n\t\tstd::cout << std::endl;\n\t}\n\n\treturn 0;\n}",
            "// replace this with your code\n\treturn 0;\n}",
            "int rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint nprocs = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\t// Compute the number of rows of A that are assigned to each rank,\n\t// where each row is assigned to a rank sequentially\n\tint nrows_per_rank = N / nprocs;\n\tif (rank == 0) {\n\t\tnrows_per_rank += N % nprocs;\n\t}\n\t// The first row of A assigned to each rank\n\tint first_row = rank * nrows_per_rank;\n\t// Number of rows assigned to this rank\n\tint nrows = nrows_per_rank;\n\tif (rank == nprocs - 1) {\n\t\tnrows += N % nprocs;\n\t}\n\t// Initialize a vector of size N containing all zeros\n\tstd::vector<bool> visited(N, false);\n\t// Find the largest component\n\tint max = 0;\n\tfor (int i = 0; i < nrows; ++i) {\n\t\tint start = first_row + i;\n\t\tif (visited[start]) {\n\t\t\tcontinue;\n\t\t}\n\t\tstd::queue<int> queue;\n\t\tqueue.push(start);\n\t\twhile (!queue.empty()) {\n\t\t\tint cur = queue.front();\n\t\t\tqueue.pop();\n\t\t\tif (visited[cur]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tvisited[cur] = true;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[N*cur+j] == 1 &&!visited[j]) {\n\t\t\t\t\tqueue.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (visited.size() > max) {\n\t\t\tmax = visited.size();\n\t\t}\n\t}\n\treturn max;\n}",
            "int* adjacency_matrix = new int[N*N];\n  for (int i = 0; i < N*N; ++i) {\n    adjacency_matrix[i] = A[i];\n  }\n\n  int myrank, nprocs, root = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n  int* visited = new int[N];\n  for (int i = 0; i < N; ++i) {\n    visited[i] = 0;\n  }\n\n  int* component_sizes = new int[nprocs];\n\n  for (int i = 0; i < nprocs; ++i) {\n    component_sizes[i] = 0;\n  }\n\n  // TODO: your code here\n\n  int* final_visited = new int[N];\n  MPI_Gather(visited, N, MPI_INT, final_visited, N, MPI_INT, root, MPI_COMM_WORLD);\n\n  int max_comp = 0;\n\n  if (myrank == 0) {\n    for (int i = 0; i < N; ++i) {\n      if (final_visited[i] == 1) {\n        max_comp++;\n      }\n    }\n  }\n\n  return max_comp;\n}",
            "std::vector<int> componentSizes(N, 1);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[N * i + j]) {\n        componentSizes[i] = std::max(componentSizes[i], componentSizes[j] + 1);\n      }\n    }\n  }\n  return *std::max_element(componentSizes.begin(), componentSizes.end());\n}",
            "std::vector<int> rank(N, 0);\n\tstd::vector<int> reach(N, 0);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\t++reach[i];\n\t\t\t}\n\t\t}\n\t}\n\n\tsize_t rank_index = 0;\n\twhile (rank_index < N) {\n\t\tsize_t root = reach.front();\n\t\tsize_t reachable = reach.front();\n\t\trank.front() = rank_index;\n\t\treach.erase(reach.begin());\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j] && rank[i] < rank[j]) {\n\t\t\t\t\trank[i] = rank[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (reach[i]) {\n\t\t\t\t++reachable;\n\t\t\t}\n\t\t}\n\t\tif (reachable == 0) {\n\t\t\tbreak;\n\t\t}\n\t\t++rank_index;\n\t}\n\n\t// MPI part\n\tint rank_num;\n\tMPI_Comm_size(MPI_COMM_WORLD, &rank_num);\n\tint rank_id;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank_id);\n\n\tint root_rank = 0;\n\n\tint max_rank = 0;\n\tMPI_Reduce(&rank_index, &max_rank, 1, MPI_INT, MPI_MAX, root_rank, MPI_COMM_WORLD);\n\n\tint max_rank_out;\n\tMPI_Bcast(&max_rank, 1, MPI_INT, root_rank, MPI_COMM_WORLD);\n\treturn max_rank_out;\n}",
            "std::vector<bool> visited(N, false);\n\n    std::function<void(size_t)> dfs = [&](size_t i) {\n        visited[i] = true;\n        for (size_t j = 0; j < N; j++) {\n            if (i!= j &&!visited[j] && A[i*N + j]) {\n                dfs(j);\n            }\n        }\n    };\n\n    size_t count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            count++;\n            dfs(i);\n        }\n    }\n    return count;\n}",
            "// Replace this code with a parallel implementation\n\t// using MPI_Reduce\n\treturn 0;\n}",
            "// TODO: replace the next two lines by an MPI call to determine the rank and the number of processors.\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// TODO: replace the next two lines by an MPI call to create a communicator that includes only the other ranks.\n\tint num_procs;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\n\t// Create a local copy of the adjacency matrix.\n\tstd::vector<int> A_local;\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tA_local.push_back(A[i * N + j]);\n\n\t// TODO: replace the next two lines by an MPI call that computes the maximum vertex index of the largest component\n\t// using the algorithm from the lecture.\n\tint max_vertex = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A_local[i * N + j]) {\n\t\t\t\tint vertex_index = i > j? i : j;\n\t\t\t\tif (vertex_index > max_vertex) {\n\t\t\t\t\tmax_vertex = vertex_index;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// TODO: replace the next two lines by an MPI call that reduces the max_vertex values from all processes to the\n\t// process with rank 0.\n\tint result;\n\tMPI_Reduce(&max_vertex, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\t// TODO: replace the next line by an MPI call that returns the result from the process with rank 0 to the caller.\n\treturn result;\n}",
            "int count = 0;\n    for (int i = 0; i < N; i++) {\n        if (A[i * N + i] == 1)\n            count++;\n    }\n\n    return count;\n}",
            "int num_process = 0, rank = 0, color = 0, num_nodes = 0, num_edges = 0, sum_num_nodes = 0,\n\t\tsum_num_edges = 0, num_componnets = 0;\n\tint *send_buf = NULL, *recv_buf = NULL, *global_buf = NULL;\n\tint *adj_matrix = NULL, *global_adj_matrix = NULL;\n\tint *adj_buf = NULL;\n\tint i, j, k, c;\n\tMPI_Request request;\n\tMPI_Status status;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_process);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Get_processor_name(hostname, &len);\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_process);\n\tif (rank == 0) {\n\t\tadj_matrix = (int *)malloc(N * N * sizeof(int));\n\t\tmemcpy(adj_matrix, A.data(), N * N * sizeof(int));\n\t\tglobal_adj_matrix = (int *)malloc(N * N * sizeof(int));\n\t\tmemcpy(global_adj_matrix, A.data(), N * N * sizeof(int));\n\t} else {\n\t\tadj_matrix = (int *)malloc(N * N * sizeof(int));\n\t\tglobal_adj_matrix = (int *)malloc(N * N * sizeof(int));\n\t}\n\n\tMPI_Bcast(adj_matrix, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(global_adj_matrix, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint **list = new int*[num_process];\n\tfor (i = 0; i < num_process; i++) {\n\t\tlist[i] = new int[N];\n\t}\n\n\tif (rank == 0) {\n\t\tnum_nodes = N;\n\t}\n\n\tnum_nodes = N;\n\tnum_edges = 0;\n\n\tfor (i = 0; i < N; i++) {\n\t\tfor (j = i + 1; j < N; j++) {\n\t\t\tif (adj_matrix[i * N + j] == 1) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rank == 0) {\n\t\tsend_buf = (int *)malloc(num_process * sizeof(int));\n\t\trecv_buf = (int *)malloc(num_process * sizeof(int));\n\t}\n\n\tsend_buf[rank] = num_nodes;\n\trecv_buf[rank] = num_nodes;\n\n\tMPI_Allgather(send_buf, 1, MPI_INT, recv_buf, 1, MPI_INT, MPI_COMM_WORLD);\n\n\tfor (i = 0; i < num_process; i++) {\n\t\tfor (j = 0; j < num_process; j++) {\n\t\t\tif (i!= j) {\n\t\t\t\tglobal_buf[i * N + j] = recv_buf[j];\n\t\t\t} else {\n\t\t\t\tglobal_buf[i * N + j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tint global_num_nodes = 0, global_num_edges = 0;\n\tfor (i = 0; i < num_process; i++) {\n\t\tglobal_num_nodes += recv_buf[i];\n\t}\n\n\tfor (i = 0; i < num_process; i++) {\n\t\tglobal_num_edges += global_buf[i * num_process + i];\n\t}\n\n\tint *send_buf_adj = NULL, *recv_buf_adj = NULL, *global_adj_buf = NULL;\n\tif (rank == 0) {",
            "if (N == 0) { return 0; }\n  std::vector<int> b(N);\n  std::vector<int> c(N);\n  std::vector<int> v(N);\n  for (size_t i = 0; i < N; i++) {\n    b[i] = A[i*N];\n    c[i] = 1;\n    v[i] = 0;\n  }\n  int max = 0;\n  for (int k = 0; k < N; k++) {\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i*N + j] > 0) {\n          if (i == j) {\n            c[j] = 1;\n          } else if (v[i] == 0 && v[j] == 0) {\n            b[j] = b[i] + 1;\n            v[j] = 1;\n          } else if (b[i] > b[j] && v[i] == 1 && v[j] == 0) {\n            b[j] = b[i] + 1;\n            c[j] = c[i];\n            v[j] = 1;\n          } else if (b[i] < b[j] && v[i] == 0 && v[j] == 1) {\n            b[i] = b[j] + 1;\n            c[i] = c[j];\n            v[i] = 1;\n          } else if (b[i] == b[j] && v[i] == 0 && v[j] == 1) {\n            c[i] += c[j];\n            v[i] = 1;\n          }\n        }\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      if (b[i] > max) {\n        max = b[i];\n      }\n    }\n  }\n  return max;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint num_ranks;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n\tstd::vector<std::vector<int>> B(N);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tB[i].resize(N);\n\t}\n\tint *buffer = new int[N * N];\n\tint *displs = new int[num_ranks];\n\tint *recvcounts = new int[num_ranks];\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tbuffer[i * N + j] = A[i * N + j];\n\t\t}\n\t}\n\n\tfor (int i = 0; i < num_ranks; i++) {\n\t\tdispls[i] = i * N;\n\t\trecvcounts[i] = N;\n\t}\n\tMPI_Allgatherv(buffer, N * N, MPI_INT, B.data(), recvcounts, displs, MPI_INT, MPI_COMM_WORLD);\n\tdelete[] buffer;\n\tdelete[] displs;\n\tdelete[] recvcounts;\n\n\tint max = 0;\n\tint temp = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> queue(N);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tqueue.push_back(i);\n\t\t\tvisited[i] = 1;\n\t\t\ttemp++;\n\t\t\twhile (queue.size()!= 0) {\n\t\t\t\tsize_t index = queue.back();\n\t\t\t\tqueue.pop_back();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (B[index][j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\ttemp++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (temp > max) {\n\t\t\tmax = temp;\n\t\t}\n\t\ttemp = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tvisited[j] = 0;\n\t\t}\n\t}\n\n\tint res;\n\tMPI_Reduce(&max, &res, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn res;\n}",
            "int rank = 0;\n    int size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int sizePerRank = N / size;\n    int myStart = rank * sizePerRank;\n    int myEnd = (rank == (size - 1))? N : (rank + 1) * sizePerRank;\n    std::vector<int> myA(myEnd - myStart);\n    for (int i = 0; i < myEnd - myStart; ++i) {\n        myA[i] = A[i + myStart];\n    }\n\n    int numComponents = 0;\n    if (myStart < myEnd) {\n        numComponents = largestComponent(myA, myEnd - myStart);\n    }\n    MPI_Reduce(&numComponents, nullptr, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return numComponents;\n}",
            "// Replace this function with your own implementation\n  return 0;\n}",
            "if (N == 0) {\n        return 0;\n    }\n    else {\n        std::vector<int> A_next(A.size());\n        std::vector<int> A_curr(A.size());\n        std::copy(A.begin(), A.end(), A_curr.begin());\n        int k = 0;\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (i!= j && A_curr[i * N + j] > 0) {\n                    A_next[i * N + j] = A_curr[i * N + j];\n                    A_next[j * N + i] = A_curr[i * N + j];\n                }\n                else if (i == j && A_curr[i * N + j] > 0) {\n                    A_next[i * N + j] = A_curr[i * N + j];\n                    A_next[j * N + i] = A_curr[i * N + j];\n                    k++;\n                }\n                else {\n                    A_next[i * N + j] = 0;\n                    A_next[j * N + i] = 0;\n                }\n            }\n        }\n        std::vector<int> B_curr(A.size());\n        std::copy(A_next.begin(), A_next.end(), B_curr.begin());\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (i!= j && A_next[i * N + j] > 0) {\n                    B_curr[i * N + j] = A_next[i * N + j];\n                    B_curr[j * N + i] = A_next[i * N + j];\n                }\n                else if (i == j && A_next[i * N + j] > 0) {\n                    B_curr[i * N + j] = A_next[i * N + j];\n                    B_curr[j * N + i] = A_next[i * N + j];\n                }\n                else {\n                    B_curr[i * N + j] = 0;\n                    B_curr[j * N + i] = 0;\n                }\n            }\n        }\n        if (k == N) {\n            return largestComponent(B_curr, N);\n        }\n        else {\n            return k;\n        }\n    }\n}",
            "// Your code here.\n}",
            "int my_size = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint n = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) n++;\n\t\t}\n\t\tif (n > my_size) my_size = n;\n\t}\n\tint rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint* tmp = new int[size];\n\tint* rec = new int[size];\n\tMPI_Allgather(&my_size, 1, MPI_INT, tmp, 1, MPI_INT, MPI_COMM_WORLD);\n\tfor (int i = 0; i < size; i++) {\n\t\tif (tmp[i] > rec[i]) rec[i] = tmp[i];\n\t}\n\tint res = rec[0];\n\tfor (int i = 1; i < size; i++) {\n\t\tif (res < rec[i]) res = rec[i];\n\t}\n\treturn res;\n}",
            "// Your code here\n}",
            "int largest = 1;\n    for (size_t i = 0; i < N; i++) {\n        int count = 0;\n        for (size_t j = 0; j < N; j++) {\n            count += (A[i*N + j] == 1);\n        }\n        largest = std::max(count, largest);\n    }\n\n    // MPI-code goes here\n\n    return largest;\n}",
            "int numComponents = 0;\n    int componentSizes[N];\n    int currentComponent = 0;\n    for (int i = 0; i < N; i++) {\n        componentSizes[i] = 0;\n    }\n    for (int i = 0; i < N; i++) {\n        if (componentSizes[i] == 0) {\n            componentSizes[i] = 1;\n            currentComponent++;\n            for (int j = 0; j < N; j++) {\n                if (A[N * i + j] == 1) {\n                    componentSizes[j] = currentComponent;\n                }\n            }\n        }\n    }\n    for (int i = 0; i < N; i++) {\n        numComponents = std::max(numComponents, componentSizes[i]);\n    }\n    return numComponents;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    std::vector<std::vector<int> > adj(N, std::vector<int>(N));\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            adj[i][j] = A[i * N + j];\n\n    int comp_size = N;\n    if (rank == 0) {\n        for (size_t i = 0; i < N; ++i)\n            for (size_t j = i + 1; j < N; ++j)\n                if (adj[i][j] == 1)\n                    --comp_size;\n    }\n\n    return comp_size;\n}",
            "std::vector<int> local_A = A;\n  int count = 0;\n  std::vector<int> color(N, 0);\n  int id = 0;\n  //BFS\n  for (int i = 0; i < N; ++i) {\n    if (color[i] == 0) {\n      ++id;\n      std::queue<int> q;\n      q.push(i);\n      color[i] = id;\n      while (!q.empty()) {\n        auto c = q.front();\n        q.pop();\n        for (int j = 0; j < N; ++j) {\n          if (color[j] == 0 && local_A[c * N + j] == 1) {\n            color[j] = id;\n            q.push(j);\n          }\n        }\n      }\n    }\n  }\n  MPI_Reduce(color.data(), MPI_IN_PLACE, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  if (0 == MPI_COMM_RANK) {\n    for (int i = 0; i < N; ++i) {\n      count += color[i] == color[0];\n    }\n    return count;\n  }\n  return 0;\n}",
            "int N_proc;\n\tint rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &N_proc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t// find the largest component size on each rank\n\tint max_component_size = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint current_component_size = 0;\n\t\tstd::set<int> s;\n\t\ts.insert(i);\n\t\tint count = 0;\n\t\twhile (count!= s.size()) {\n\t\t\tint temp = s.size();\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j]!= 0 && s.find(j) == s.end()) {\n\t\t\t\t\ts.insert(j);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount = s.size();\n\t\t}\n\t\tif (s.size() > current_component_size) {\n\t\t\tcurrent_component_size = s.size();\n\t\t}\n\t\tif (current_component_size > max_component_size) {\n\t\t\tmax_component_size = current_component_size;\n\t\t}\n\t}\n\n\t// reduce the max_component_size across all ranks\n\tint max_component_size_global = 0;\n\tMPI_Reduce(&max_component_size, &max_component_size_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\treturn max_component_size_global;\n\t}\n\telse {\n\t\treturn max_component_size;\n\t}\n}",
            "// TODO\n    return 0;\n}",
            "int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    /* Your solution goes here */\n\n}",
            "// TODO\n}",
            "// TODO: YOUR CODE HERE\n  return 0;\n}",
            "// Write your code here\n}",
            "// We should check the input here\n\tassert(A.size() == N * N);\n\n\t// Initialization of variables\n\tstd::vector<int> localMatrix(A.size());\n\tint result = 0;\n\t\n\t// Initialization of local matrix\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tlocalMatrix[i * N + j] = A[i * N + j];\n\t\t}\n\t}\n\t\n\t// Checking if every row in local matrix is equal to 0\n\tfor (int i = 0; i < N; ++i) {\n\t\tbool flag = true;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (localMatrix[i * N + j]!= 0) {\n\t\t\t\tflag = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (flag) {\n\t\t\tresult = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\t// Making sure the matrix isn't empty\n\tif (result == 0) {\n\t\t// Using DFS to find if there is any path from vertex 1 to vertex 2\n\t\tint size = A.size();\n\t\t\n\t\t// Used to track the visited vertices\n\t\tstd::vector<int> visited(size);\n\t\t\n\t\t// Marking vertex 1 as visited\n\t\tvisited[0] = 1;\n\t\t\n\t\t// Used to store the next vertex to check\n\t\tstd::queue<int> queue;\n\t\tqueue.push(0);\n\t\t\n\t\t// Checking if vertex 1 can be reached from vertex 2\n\t\twhile (!queue.empty()) {\n\t\t\tint vertex = queue.front();\n\t\t\tqueue.pop();\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (localMatrix[vertex * N + i]!= 0 && visited[i]!= 1) {\n\t\t\t\t\tqueue.push(i);\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Checking if vertex 2 can be reached from vertex 1\n\t\tstd::fill(visited.begin(), visited.end(), 0);\n\t\tvisited[1] = 1;\n\t\tqueue.push(1);\n\t\twhile (!queue.empty()) {\n\t\t\tint vertex = queue.front();\n\t\t\tqueue.pop();\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (localMatrix[i * N + vertex]!= 0 && visited[i]!= 1) {\n\t\t\t\t\tqueue.push(i);\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Finding the largest component\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (visited[j] == 0 && localMatrix[i * N + j]!= 0) {\n\t\t\t\t\t\tresult = 2;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn result;\n}",
            "/* CODE GOES HERE */\n\tint size, rank;\n\tint* sendbuffer = nullptr;\n\tint* recvbuffer = nullptr;\n\tint* comp = nullptr;\n\tint* comp1 = nullptr;\n\tint* recv = nullptr;\n\tint* recv1 = nullptr;\n\tint compmax = 0;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\n\tif (rank == 0)\n\t{\n\t\tsendbuffer = new int[N * N];\n\t\tfor (int i = 0; i < N * N; i++)\n\t\t\tsendbuffer[i] = A[i];\n\t}\n\tMPI_Bcast(sendbuffer, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0)\n\t{\n\t\tcomp = new int[N];\n\t\tcomp1 = new int[N];\n\t\trecv = new int[N];\n\t\trecv1 = new int[N];\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tcomp[i] = 0;\n\t\t\tcomp1[i] = 0;\n\t\t\trecv[i] = 0;\n\t\t\trecv1[i] = 0;\n\t\t}\n\t}\n\n\tMPI_Scatter(comp, 1, MPI_INT, &compmax, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor (int i = rank; i < N * N; i += size)\n\t{\n\t\tif (sendbuffer[i]!= 0 && compmax < i / N)\n\t\t{\n\t\t\tcompmax = i / N;\n\t\t}\n\t}\n\n\tif (rank == 0)\n\t\tdelete[] comp;\n\tif (rank == 0)\n\t\tdelete[] comp1;\n\tif (rank == 0)\n\t\tdelete[] sendbuffer;\n\tif (rank == 0)\n\t\tdelete[] recv;\n\tif (rank == 0)\n\t\tdelete[] recv1;\n\n\tMPI_Gather(&compmax, 1, MPI_INT, recv, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tMPI_Reduce(&compmax, &compmax, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn compmax;\n}",
            "int n = N;\n\tint world_size, world_rank;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n\tint* A_p = &A[0];\n\n\tint* A_p_submatrix;\n\n\tif (world_size == 1) {\n\t\tA_p_submatrix = A_p;\n\t}\n\telse {\n\t\tA_p_submatrix = (int*)malloc(sizeof(int) * n * n / world_size);\n\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tfor (int j = 0; j < n; j++) {\n\t\t\t\tif (j % world_size == world_rank) {\n\t\t\t\t\tA_p_submatrix[i * n / world_size + j / world_size] = A_p[i * n + j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint* A_p_submatrix_p = A_p_submatrix;\n\tint* A_p_submatrix_p_copy;\n\tint* A_p_submatrix_p_copy_next;\n\n\tint* A_p_submatrix_p_copy_start = A_p_submatrix_p;\n\n\tint* A_p_submatrix_p_copy_submatrix = (int*)malloc(sizeof(int) * n / world_size * n / world_size);\n\tint* A_p_submatrix_p_copy_submatrix_p = A_p_submatrix_p_copy_submatrix;\n\n\tint count = 0;\n\n\tint visited[n];\n\n\tfor (int i = 0; i < n; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\twhile (count < n) {\n\t\tcount = 0;\n\t\tfor (int i = 0; i < n / world_size; i++) {\n\t\t\tfor (int j = 0; j < n / world_size; j++) {\n\t\t\t\tif (A_p_submatrix_p[i * n / world_size + j] == 1 && visited[i * n / world_size + j] == 0) {\n\t\t\t\t\tvisited[i * n / world_size + j] = 1;\n\t\t\t\t\tA_p_submatrix_p_copy = A_p_submatrix_p_copy_start;\n\t\t\t\t\twhile (A_p_submatrix_p_copy!= NULL) {\n\t\t\t\t\t\tA_p_submatrix_p_copy_next = A_p_submatrix_p_copy->next;\n\t\t\t\t\t\tfree(A_p_submatrix_p_copy);\n\t\t\t\t\t\tA_p_submatrix_p_copy = A_p_submatrix_p_copy_next;\n\t\t\t\t\t}\n\t\t\t\t\tA_p_submatrix_p_copy_submatrix_p = A_p_submatrix_p_copy_submatrix;\n\t\t\t\t\tfor (int k = 0; k < n; k++) {\n\t\t\t\t\t\tA_p_submatrix_p_copy_submatrix_p[k] = A_p_submatrix_p[k];\n\t\t\t\t\t}\n\t\t\t\t\tA_p_submatrix_p_copy_start = (int*)malloc(sizeof(int) * n / world_size * n / world_size);\n\t\t\t\t\tA_p_submatrix_p_copy_start->next = NULL;\n\t\t\t\t\tA_p_submatrix_p_copy_submatrix_p = A_p_submatrix_p_copy_start;\n\n\t\t\t\t\tfor (int k = 0; k < n; k++) {\n\t\t\t\t\t\tA_p_submatrix_p_copy_submatrix_p[k] = A_p_submatrix_p[k];\n\t\t\t\t\t}\n\t\t\t\t\tcount++;",
            "// TODO\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int n = N;\n  int c[n];\n  int a = 0;\n  int b = 0;\n  int c_global[n];\n  int count = 0;\n  int max = 0;\n  int max1 = 0;\n  if (rank == 0) {\n    for (int i = 0; i < n; i++) {\n      c[i] = 0;\n    }\n    while (a < n) {\n      if (c[a] == 0) {\n        b = a;\n        while (A[a * n + b] == 1) {\n          c[b] = 1;\n          b = b + 1;\n          count = count + 1;\n          if (b == n) {\n            a = a + 1;\n            b = a;\n          }\n        }\n        a = a + 1;\n      } else {\n        a = a + 1;\n      }\n    }\n    for (int i = 0; i < n; i++) {\n      c_global[i] = c[i];\n    }\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&c_global, n, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      for (int j = 0; j < n; j++) {\n        c_global[j] = c_global[j] + c[j];\n      }\n    }\n    for (int i = 0; i < n; i++) {\n      if (c_global[i] == 1) {\n        max = max + 1;\n      }\n    }\n  } else {\n    MPI_Send(&c, n, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n\n  if (rank == 0) {\n    MPI_Reduce(&max, &max1, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  } else {\n    MPI_Reduce(&max, &max1, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  }\n\n  if (rank == 0) {\n    return max1;\n  } else {\n    return 0;\n  }\n}",
            "// TODO: Your code here\n}",
            "std::vector<int> isConnected(N, false);\n    int numConnected = 0;\n    std::vector<int> connectedRanks(N, -1);\n    int connectedRank = -1;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &connectedRank);\n\n    for(int i = 0; i < N; i++) {\n        if(isConnected[i])\n            continue;\n\n        for(int j = 0; j < N; j++) {\n            if(A[i * N + j]!= 0) {\n                isConnected[j] = true;\n                connectedRanks[j] = connectedRank;\n                numConnected++;\n            }\n        }\n    }\n\n    int numTotal;\n    MPI_Allreduce(&numConnected, &numTotal, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n    if(connectedRank == 0) {\n        std::vector<int> maxRanks(numTotal, 0);\n        for(int i = 0; i < N; i++)\n            maxRanks[connectedRanks[i]]++;\n\n        int maxNum = maxRanks[0];\n        for(int i = 1; i < numTotal; i++) {\n            if(maxNum < maxRanks[i])\n                maxNum = maxRanks[i];\n        }\n\n        return maxNum;\n    }\n    else\n        return -1;\n}",
            "// Your code here!\n\treturn 0;\n}",
            "std::vector<int> result(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tresult[i] = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 1; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (result[j] == 0 && result[i] == 1) {\n\t\t\t\tresult[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn std::count(result.begin(), result.end(), 1);\n}",
            "}",
            "// Add your code here\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t/*\n\t * For rank i and size k, the matrix A is divided into blocks of size m x m.\n\t * m = N / k.\n\t * The (i+1)th block of A is passed to rank i.\n\t * The i-th block of A is passed to rank i+1.\n\t * If the remainder is not 0, the last rank (size - 1) gets the first\n\t * remainder rows/cols of A.\n\t */\n\tint m = N / size;\n\tint remainder = N % size;\n\tint start_row = rank * m;\n\tint end_row = rank == size - 1? N : start_row + m;\n\tint start_col = rank == 0? 0 : rank * m;\n\tint end_col = rank == size - 1? N : start_col + m;\n\tint nblocks_row = end_row - start_row;\n\tint nblocks_col = end_col - start_col;\n\tstd::vector<int> blockA(nblocks_row * nblocks_col);\n\tfor (int i = 0; i < nblocks_row; i++) {\n\t\tfor (int j = 0; j < nblocks_col; j++) {\n\t\t\tblockA[i * nblocks_col + j] = A[start_row + i][start_col + j];\n\t\t}\n\t}\n\tint max_component = -1;\n\tint recv_max_component;\n\n\tif (rank == 0) {\n\t\tMPI_Send(blockA.data(), nblocks_row * nblocks_col, MPI_INT, 1, 0, MPI_COMM_WORLD);\n\t}\n\telse if (rank == size - 1) {\n\t\tMPI_Send(blockA.data(), nblocks_row * nblocks_col, MPI_INT, rank - 1, 0, MPI_COMM_WORLD);\n\t}\n\telse {\n\t\tMPI_Send(blockA.data(), nblocks_row * nblocks_col, MPI_INT, rank - 1, 0, MPI_COMM_WORLD);\n\t\tMPI_Recv(&recv_max_component, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tmax_component = std::max(max_component, recv_max_component);\n\t\tMPI_Send(blockA.data(), nblocks_row * nblocks_col, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);\n\t}\n\n\tif (rank!= 0) {\n\t\tMPI_Recv(&recv_max_component, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tmax_component = std::max(max_component, recv_max_component);\n\t}\n\n\tint component = largestComponent(blockA, nblocks_row);\n\n\tif (rank!= 0 && rank!= size - 1) {\n\t\tMPI_Send(&component, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);\n\t}\n\n\tif (rank!= 0) {\n\t\tMPI_Recv(&recv_max_component, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tmax_component = std::max(max_component, recv_max_component);\n\t}\n\n\treturn max_component;\n}",
            "const int rank = 0;\n  const int comm_size = 1;\n  int largest_component = 0;\n  // TODO: your code goes here\n  if (rank == 0) {\n    int components[N];\n    for (int i = 0; i < N; i++) {\n      components[i] = 0;\n    }\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (i == j) {\n          continue;\n        }\n        if (A[i * N + j] == 1) {\n          components[i] = components[j];\n        }\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (components[i] == components[j]) {\n          continue;\n        }\n        if (A[i * N + j] == 1) {\n          components[j] = components[i];\n        }\n      }\n    }\n    std::map<int, int> component_map;\n    for (int i = 0; i < N; i++) {\n      if (component_map.count(components[i]) == 0) {\n        component_map[components[i]] = 1;\n      } else {\n        component_map[components[i]]++;\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      if (largest_component < component_map[components[i]]) {\n        largest_component = component_map[components[i]];\n      }\n    }\n  }\n  return largest_component;\n}",
            "}",
            "return 0;\n}",
            "std::vector<bool> visited(N, false);\n\tint nComponents = 0;\n\t\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (not visited[i]) {\n\t\t\tstd::stack<int> stack;\n\t\t\tstack.push(i);\n\t\t\twhile (not stack.empty()) {\n\t\t\t\tint const i = stack.top();\n\t\t\t\tif (not visited[i]) {\n\t\t\t\t\tvisited[i] = true;\n\t\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t\t\t\tstack.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tstack.pop();\n\t\t\t\t}\n\t\t\t}\n\t\t\t++nComponents;\n\t\t}\n\t}\n\t\n\treturn nComponents;\n}",
            "// Your code here!\n}",
            "int result = 0;\n  int myResult = 0;\n  std::vector<int> visited(N);\n  std::vector<int> nextToVisit(N);\n  int startRank = 0;\n  int nextRank = 0;\n  int nextRankToSend = 0;\n  int nextRankToSendValue = 0;\n  int nbNeighbours = 0;\n  int rank = 0;\n  int nbRanks = 0;\n  int size = 0;\n  int root = 0;\n\n  if (N > 0) {\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    nbRanks = N / size;\n  }\n  // if there are not as many ranks as needed, then assign more ranks to the first nodes\n  if (N % size!= 0 && rank < N % size) {\n    nbRanks++;\n  }\n\n  if (rank == root) {\n    if (N!= 0) {\n      myResult = 1;\n      for (int i = 0; i < N; i++) {\n        if (visited[i]!= 1) {\n          visited[i] = 1;\n          nextToVisit.push_back(i);\n        }\n      }\n    }\n  }\n\n  MPI_Bcast(&myResult, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&visited[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (N!= 0) {\n    for (int i = 0; i < N; i++) {\n      if (visited[i]!= 1) {\n        visited[i] = 1;\n        nextToVisit.push_back(i);\n      }\n    }\n  }\n\n  // if no next node is found, then stop\n  while (nextToVisit.size()!= 0) {\n    startRank = nextToVisit.front();\n    nextRank = startRank;\n    nbNeighbours = 0;\n    nextToVisit.pop_front();\n    if (rank == root) {\n      while (nextRank < N && visited[nextRank]!= 1) {\n        nextRank++;\n      }\n      nextRankToSendValue = nextRank;\n      if (nextRank < N) {\n        nextRankToSend = nextRank / nbRanks;\n      } else {\n        nextRankToSend = -1;\n      }\n    }\n    MPI_Bcast(&nextRankToSend, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (nextRankToSend!= -1) {\n      MPI_Bcast(&visited[0], N, MPI_INT, nextRankToSend, MPI_COMM_WORLD);\n      if (rank == nextRankToSend) {\n        if (visited[nextRankToSendValue]!= 1) {\n          visited[nextRankToSendValue] = 1;\n          nextToVisit.push_back(nextRankToSendValue);\n        }\n      }\n    }\n  }\n\n  MPI_Reduce(&myResult, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  if (rank == root) {\n    return result;\n  } else {\n    return 0;\n  }\n}",
            "// TODO\n}",
            "// TODO: your code here\n    return 0;\n}",
            "int mpi_size, mpi_rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n    if (mpi_rank == 0) {\n        std::vector<int> R(N * N);\n\n        for (int rank = 1; rank < mpi_size; rank++) {\n            MPI_Status status;\n            MPI_Recv(&R[0], N * N, MPI_INT, rank, 0, MPI_COMM_WORLD, &status);\n        }\n\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[N * i + j]!= 0) {\n                    for (int k = 0; k < N; k++) {\n                        R[N * i + k] |= A[N * j + k];\n                    }\n                }\n            }\n        }\n\n        int component_size = 0;\n        for (int i = 0; i < N; i++) {\n            if (R[N * i + i]!= 0) {\n                component_size++;\n            }\n        }\n\n        return component_size;\n    }\n    else {\n        MPI_Send(&A[0], N * N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    return -1;\n}",
            "// TODO\n}",
            "// TODO: implement\n    return 0;\n}",
            "int max = 0;\n\tint index = 0;\n\tint index_r = 0;\n\tint index_c = 0;\n\tstd::vector<int> new_A;\n\tstd::vector<int> new_A_r;\n\tstd::vector<int> new_A_c;\n\t\n\tstd::vector<int> index_of_A;\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tindex_of_A.push_back(i * N + j);\n\t\t}\n\t}\n\n\tstd::vector<int> index_of_A_r;\n\tfor(int i = 0; i < N; i++){\n\t\tindex_of_A_r.push_back(i * N + i);\n\t}\n\n\tstd::vector<int> index_of_A_c;\n\tfor(int i = 0; i < N; i++){\n\t\tindex_of_A_c.push_back(i + i * N);\n\t}\n\n\t//std::cout << \"index_of_A_r\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tstd::cout << index_of_A_r[i] << std::endl;\n\t//}\n\t//std::cout << \"index_of_A_c\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tstd::cout << index_of_A_c[i] << std::endl;\n\t//}\n\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tnew_A.push_back(A[i * N + j]);\n\t\t\tnew_A_r.push_back(A[i * N + i]);\n\t\t\tnew_A_c.push_back(A[i + i * N]);\n\t\t}\n\t}\n\n\t//std::cout << \"new_A\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tfor(int j = 0; j < N; j++){\n\t//\t\tstd::cout << new_A[i * N + j] << \" \";\n\t//\t}\n\t//\tstd::cout << std::endl;\n\t//}\n\n\t//std::cout << \"new_A_r\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tfor(int j = 0; j < N; j++){\n\t//\t\tstd::cout << new_A_r[i * N + j] << \" \";\n\t//\t}\n\t//\tstd::cout << std::endl;\n\t//}\n\n\t//std::cout << \"new_A_c\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tfor(int j = 0; j < N; j++){\n\t//\t\tstd::cout << new_A_c[i * N + j] << \" \";\n\t//\t}\n\t//\tstd::cout << std::endl;\n\t//}\n\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(new_A[i * N + j] == 1){\n\t\t\t\tnew_A[i * N + j] = 0;\n\t\t\t\tif(i!= j){\n\t\t\t\t\tindex_r = index_of_A_r[i];\n\t\t\t\t\tindex_c = index_of_A_c[j];\n\t\t\t\t\tnew_A[index_r] = 0;\n\t\t\t\t\tnew_A[index_c] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t//std::cout << \"new_A\" << std::endl;\n\t//for(int i = 0; i < N; i++){\n\t//\tfor(int j = 0; j",
            "int m, M;\n  std::vector<int> work;\n  int count;\n  MPI_Status status;\n\n  m = A.size();\n\n  if (N == 0) {\n    return -1;\n  }\n\n  if (N == 1) {\n    return 1;\n  }\n\n  for (int i = 1; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        work.push_back(i*N + j);\n      }\n    }\n  }\n\n  if (work.size() == 0) {\n    return 1;\n  }\n\n  MPI_Allreduce(&work.size(), &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  if (count == 0) {\n    return 1;\n  }\n\n  M = work.size();\n\n  for (int i = 1; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        work.push_back(i*N + j);\n      }\n    }\n  }\n\n  for (int k = 1; k < N; ++k) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (A[i*N + j]!= 0) {\n          work.push_back(i*N + j);\n        }\n      }\n    }\n  }\n\n  MPI_Allreduce(&work.size(), &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  if (count == 0) {\n    return 1;\n  }\n\n  M = work.size();\n\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        work.push_back(i*N + j);\n      }\n    }\n  }\n\n  for (int k = 1; k < N; ++k) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (A[i*N + j]!= 0) {\n          work.push_back(i*N + j);\n        }\n      }\n    }\n  }\n\n  MPI_Allreduce(&work.size(), &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  if (count == 0) {\n    return 1;\n  }\n\n  M = work.size();\n\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        work.push_back(i*N + j);\n      }\n    }\n  }\n\n  MPI_Allreduce(&work.size(), &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  if (count == 0) {\n    return 1;\n  }\n\n  M = work.size();\n\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        work.push_back(i*N + j);\n      }\n    }\n  }\n\n  for (int k = 1; k < N; ++k) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (A[i*N + j]!= 0) {",
            "MPI_Comm comm = MPI_COMM_WORLD;\n    const int rank = MPI_Comm_rank(comm);\n    const int nranks = MPI_Comm_size(comm);\n\n    // TODO: Use MPI to compute in parallel.\n    // Hint: Every rank has a complete copy of A.\n    //       The result is returned on rank 0.\n\n    int result;\n\n    // Return result.\n    return result;\n}",
            "// Your code goes here\n}",
            "// TODO: Your code here\n  return 0;\n}",
            "std::vector<int> B(N*N, 0);\n\n  for(size_t i=0; i<N; i++) {\n    for(size_t j=0; j<N; j++) {\n      B[i*N+j] = A[i*N+j];\n    }\n  }\n  int count = 0;\n  int max_count = 0;\n  int index = 0;\n  while(count < N){\n    index++;\n    if(B[index]==1){\n      count++;\n      B[index] = 0;\n      for(size_t j=0; j<N; j++){\n        if(B[index*N+j]==1){\n          B[index*N+j] = 0;\n        }\n      }\n    }\n    if(count > max_count){\n      max_count = count;\n    }\n  }\n\n  return max_count;\n}",
            "int n_proc, id_proc, n_vertices = 0;\n\tint color[N];\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_proc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &id_proc);\n\n\tif(id_proc == 0) {\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tcolor[i] = 0;\n\t\t}\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif(A[i*N + j] > 0) {\n\t\t\t\t\tcolor[i] = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(color[i] == 1)\n\t\t\t\tn_vertices++;\n\t\t}\n\t}\n\n\tfor(int i = 1; i < n_proc; i++) {\n\t\tMPI_Send(&color[0], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t}\n\n\tint n_vertices_loc = 0;\n\tif(id_proc!= 0) {\n\t\tMPI_Status status;\n\t\tMPI_Recv(&color[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(color[i] == 1)\n\t\t\t\tn_vertices_loc++;\n\t\t}\n\t}\n\n\tint n_vertices_rec = 0;\n\tMPI_Reduce(&n_vertices_loc, &n_vertices_rec, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif(id_proc == 0) {\n\t\treturn n_vertices_rec;\n\t}\n}",
            "/* Your solution goes here */\n\tstd::vector<int> graph(N*N, 0);\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tif (rank == 0) {\n\t\tint* graph_ptr = &graph[0];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tstd::copy(&A[i*N], &A[i*N] + N, &graph_ptr[i*N]);\n\t\t}\n\t} else {\n\t\tint* graph_ptr = &graph[0];\n\t\tstd::copy(&A[0], &A[0] + N, &graph_ptr[0]);\n\t}\n\tint p, num_vertices;\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\tnum_vertices = N / p;\n\tint* graph_ptr = &graph[0];\n\tstd::vector<int> local_graph(num_vertices*num_vertices, 0);\n\tfor (int i = 0; i < num_vertices; i++) {\n\t\tstd::copy(&graph_ptr[i*N], &graph_ptr[i*N] + num_vertices, &local_graph[i*num_vertices]);\n\t}\n\tstd::vector<int> sub_graph(num_vertices*num_vertices, 0);\n\tint num_vertices_in_local_graph = 0;\n\tfor (int i = 0; i < num_vertices; i++) {\n\t\tfor (int j = i + 1; j < num_vertices; j++) {\n\t\t\tif (local_graph[i*num_vertices + j] == 1) {\n\t\t\t\tnum_vertices_in_local_graph++;\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> visited(num_vertices, 0);\n\tint count = 0;\n\tfor (int i = 0; i < num_vertices; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tint idx = i;\n\t\t\tcount++;\n\t\t\tvisited[i] = 1;\n\t\t\tfor (int j = i + 1; j < num_vertices; j++) {\n\t\t\t\tif (local_graph[idx*num_vertices + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tint total_count = 0;\n\tMPI_Reduce(&count, &total_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn total_count;\n}",
            "assert(A.size() == N*N);\n  for (int i = 0; i < N; i++) {\n    for (int j = i + 1; j < N; j++) {\n      if (A[i*N+j] == 1) {\n        // Remove edge from graph by setting both endpoints to -1\n        A[i*N+j] = -1;\n        A[j*N+i] = -1;\n      }\n    }\n  }\n  int result = 0;\n  for (int i = 0; i < N; i++) {\n    if (A[i*N+i]!= -1) {\n      result += 1;\n    }\n  }\n  return result;\n}",
            "// Your code here\n}",
            "return 0;\n}",
            "// TODO\n  int max_size = 0;\n  std::vector<int> visited(N, 0);\n  int root = 0;\n  std::vector<int> dist(N, 0);\n  std::vector<int> parent(N, -1);\n  std::vector<int> color(N, 0);\n  MPI_Request rq;\n  int source = -1;\n  int tag = 0;\n  int value = 0;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &root);\n  MPI_Comm_size(MPI_COMM_WORLD, &value);\n  std::vector<int> send_buf;\n  std::vector<int> recv_buf;\n  send_buf.reserve(N);\n  recv_buf.reserve(N);\n\n  int num_of_neighbors = 0;\n  int max_size_per_proc = 0;\n  int max_size_per_node = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      visited[i] = 1;\n      dist[i] = 1;\n      num_of_neighbors = 0;\n      color[i] = 1;\n      for (size_t j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          visited[j] = 1;\n          num_of_neighbors++;\n          parent[j] = i;\n        }\n      }\n      max_size_per_proc = std::max(max_size_per_proc, num_of_neighbors);\n      max_size_per_node = std::max(max_size_per_node, num_of_neighbors);\n      visited[i] = 0;\n    }\n  }\n\n  if (max_size_per_node!= max_size_per_proc) {\n    MPI_Allreduce(&max_size_per_proc, &max_size_per_node, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n  }\n\n  return max_size_per_node;\n}",
            "assert(N > 0);\n\tstd::vector<bool> v(N, false);\n\tstd::vector<bool> visited(N, false);\n\tstd::queue<int> q;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tq.push(i);\n\t\t\twhile (q.size() > 0) {\n\t\t\t\tint a = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[a] = true;\n\t\t\t\tv[a] = true;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (!visited[j] && A[a * N + j] == 1) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (v[i]) {\n\t\t\tmax++;\n\t\t}\n\t}\n\treturn max;\n}",
            "// TODO: Your code here\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// YOUR CODE HERE\n\n\treturn 0;\n}",
            "// Your code here\n  int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int max = 0;\n  int l = A.size() / size;\n  int s = A.size() % size;\n  std::vector<int> Ai;\n  if (rank == 0) {\n    for (int i = 1; i < size; i++) {\n      for (int j = 0; j < l; j++) {\n        Ai.push_back(A[i*l + j]);\n      }\n      MPI_Send(Ai.data(), l, MPI_INT, i, 1, MPI_COMM_WORLD);\n      Ai.clear();\n    }\n  }\n  if (rank!= 0) {\n    MPI_Status status;\n    MPI_Recv(Ai.data(), l, MPI_INT, 0, 1, MPI_COMM_WORLD, &status);\n    for (int j = 0; j < l; j++) {\n      Ai.push_back(A[rank*l + j]);\n    }\n  }\n  for (int i = 0; i < Ai.size(); i++) {\n    for (int j = 0; j < Ai.size(); j++) {\n      if (Ai[i]!= 0 && Ai[j]!= 0) {\n        if (Ai[i] == Ai[j]) {\n          Ai[j] = 0;\n          Ai[i] = 0;\n        }\n      }\n    }\n  }\n  int count = 0;\n  for (int i = 0; i < Ai.size(); i++) {\n    if (Ai[i]!= 0) {\n      count++;\n    }\n  }\n  if (count > max) {\n    max = count;\n  }\n  if (rank == 0) {\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&count, 1, MPI_INT, i, 1, MPI_COMM_WORLD, &status);\n      if (count > max) {\n        max = count;\n      }\n    }\n  }\n  else {\n    MPI_Send(&count, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  }\n  return max;\n}",
            "// This implementation is a placeholder.\n  return 1;\n}",
            "// You may assume that the number of MPI processes is equal to the number of rows in A.\n  int nprocs;\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // Add your code here\n  // MPI_Barrier(MPI_COMM_WORLD);\n\n  // MPI_Reduce(A.data(), A.data(), A.size(), MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  int largestComp = 0;\n\n  int* A_temp = new int[A.size()];\n\n  MPI_Barrier(MPI_COMM_WORLD);\n\n  MPI_Scatter(A.data(), A.size(), MPI_INT, A_temp, A.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\n  std::vector<int> comp;\n\n  // if (rank == 0) {\n  //   std::cout << A_temp << std::endl;\n  // }\n\n  MPI_Barrier(MPI_COMM_WORLD);\n\n  for (int i = 0; i < N; i++) {\n    comp.push_back(0);\n  }\n\n  // std::cout << \"Before For Loop\" << std::endl;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A_temp[i*N + j] == 1) {\n        // std::cout << \"i: \" << i << \" j: \" << j << std::endl;\n        comp[i] += 1;\n        comp[j] += 1;\n      }\n    }\n  }\n\n  // std::cout << \"After For Loop\" << std::endl;\n\n  MPI_Barrier(MPI_COMM_WORLD);\n\n  // MPI_Gather(comp.data(), comp.size(), MPI_INT, A_temp, A.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\n  // MPI_Reduce(comp.data(), A_temp, A.size(), MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  // std::cout << \"Before Reduce\" << std::endl;\n\n  // MPI_Reduce(A.data(), A.data(), A.size(), MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  // std::cout << \"After Reduce\" << std::endl;\n\n  // int largestComp = 0;\n\n  // for (int i = 0; i < N; i++) {\n  //   if (A_temp[i] > largestComp) {\n  //     largestComp = A_temp[i];\n  //   }\n  // }\n\n  int temp = 0;\n\n  // MPI_Allreduce(MPI_IN_PLACE, &largestComp, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n  // MPI_Reduce(&largestComp, &temp, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  MPI_Reduce(comp.data(), &largestComp, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  // std::cout << \"Rank: \" << rank << \" Largest Comp: \" << largestComp << std::endl;\n\n  // MPI_Barrier(MPI_COMM_WORLD);\n\n  // std::cout << \"After Reduce\" << std::endl;\n\n  // int temp = 0;\n  // int* A_temp = new int[A.size()];\n  // for (int i = 0; i < N; i++) {\n  //   for (int j = 0; j < N; j++) {\n  //     if (A[i*N + j",
            "// TODO\n}",
            "// your code here\n}",
            "// YOUR CODE GOES HERE\n}",
            "// TODO\n    // use mpi, assume mpi is already initialized\n\n    return -1;\n}",
            "std::vector<int> B(A.begin(), A.end());\n\n\tMPI_Datatype MPI_intVector;\n\tMPI_Type_contiguous(A.size(), MPI_INT, &MPI_intVector);\n\tMPI_Type_commit(&MPI_intVector);\n\n\tint N_int = N;\n\tint rank, size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint* sendbuf = nullptr;\n\tint* recvbuf = nullptr;\n\tint* result = nullptr;\n\n\tif (rank == 0) {\n\t\tsendbuf = &B[0];\n\t\tresult = new int[N];\n\t\tstd::fill(result, result + N, 1);\n\t\tfor (int i = 1; i < size; ++i) {\n\t\t\tMPI_Recv(result, N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\t} else {\n\t\trecvbuf = new int[N];\n\t\tMPI_Send(B.data(), N, MPI_intVector, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tMPI_Type_free(&MPI_intVector);\n\n\tif (rank!= 0) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (recvbuf[i] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\trecvbuf[j] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Send(recvbuf, N, MPI_intVector, 0, 1, MPI_COMM_WORLD);\n\t\tdelete[] recvbuf;\n\t\tMPI_Type_free(&MPI_intVector);\n\t\tMPI_Finalize();\n\t\treturn 0;\n\t}\n\n\tfor (int i = 1; i < size; ++i) {\n\t\tMPI_Recv(recvbuf, N, MPI_intVector, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (recvbuf[j] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (A[j * N + k] == 1) {\n\t\t\t\t\tresult[k] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] result;\n\tMPI_Type_free(&MPI_intVector);\n\tMPI_Finalize();\n\treturn 0;\n}",
            "int my_rank;\n  int n_procs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n\n  int* counts = new int[N];\n  std::fill_n(counts, N, 0);\n  int n_components = 0;\n\n  // TODO: each rank computes the number of components of its local part\n\n  // TODO: collect the results into counts array\n\n  int* n_comps = new int[n_procs];\n  std::fill_n(n_comps, n_procs, 0);\n  MPI_Gather(n_components, 1, MPI_INT,\n             n_comps, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (my_rank == 0) {\n    int* counts_local = new int[N];\n    std::fill_n(counts_local, N, 0);\n    for (int i = 0; i < n_procs; ++i) {\n      // TODO: collect the results into counts_local array\n    }\n    int max = 0;\n    for (int i = 0; i < N; ++i) {\n      if (counts_local[i] > max) {\n        max = counts_local[i];\n      }\n    }\n    return max;\n  }\n  return -1;\n}",
            "// TODO: fill this in\n}",
            "int result = 0;\n  return result;\n}",
            "int result = 0;\n  // TODO: implement this function\n  return result;\n}",
            "int numVertices = 0;\n  int size, rank;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  std::vector<std::vector<int>> adjacencyMatrix(N, std::vector<int>(N));\n  if (rank == 0) {\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        adjacencyMatrix[i][j] = A[i * N + j];\n      }\n    }\n  }\n  MPI_Bcast(adjacencyMatrix.data(), N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (adjacencyMatrix[i][j] == 1) {\n        adjacencyMatrix[i][j] = adjacencyMatrix[j][i] = 1;\n      }\n    }\n  }\n\n  for (size_t i = 0; i < N; i++) {\n    if (adjacencyMatrix[i][i] == 1) {\n      numVertices += 1;\n      for (size_t j = 0; j < N; j++) {\n        if (adjacencyMatrix[i][j] == 1) {\n          adjacencyMatrix[i][j] = adjacencyMatrix[j][i] = 0;\n        }\n      }\n    }\n  }\n\n  MPI_Reduce(&numVertices, &numVertices, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    return numVertices;\n  }\n\n  return 0;\n}",
            "// YOUR CODE HERE\n  int result = 0;\n  int largest = 0;\n  std::vector<int> components(N, 0);\n  int component_size = 1;\n  int new_component_size;\n\n  for (int i = 0; i < N; i++)\n  {\n    for (int j = 0; j < N; j++)\n    {\n      if (A[i * N + j] == 1)\n      {\n        if (components[i] == 0)\n        {\n          new_component_size = bfs(A, i, components, N);\n          if (new_component_size > largest)\n          {\n            largest = new_component_size;\n            result = i;\n          }\n        }\n        else if (components[j] == 0)\n        {\n          new_component_size = bfs(A, j, components, N);\n          if (new_component_size > largest)\n          {\n            largest = new_component_size;\n            result = j;\n          }\n        }\n      }\n    }\n  }\n\n  return result;\n}",
            "int num_procs, rank;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\n\t// TODO: implement me\n\n\treturn 0;\n}",
            "int id;\n  int size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &id);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO: Implement this function\n  return 0;\n}",
            "// You may need to use MPI_Reduce and/or MPI_Bcast.\n    // You may assume that the adjacency matrix is square.\n    // You may assume that MPI_Reduce will be called in the same order\n    // on every rank.\n\n    // Your code here.\n\n    int my_size = N;\n    int world_size;\n\n    //find out how big the world is\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n    //get my rank in world\n    int my_rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n    //create a vector of size my_size to hold the graph\n    std::vector<int> my_graph(my_size);\n\n    //if i am rank 0 copy the adjacency matrix to my graph\n    if (my_rank == 0) {\n        for (int i = 0; i < my_size; i++) {\n            my_graph[i] = A[i];\n        }\n    }\n\n    //broadcast my_size to everyone\n    MPI_Bcast(&my_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    //broadcast my_graph to everyone\n    MPI_Bcast(my_graph.data(), my_size, MPI_INT, 0, MPI_COMM_WORLD);\n\n    //create a vector of size my_size to hold the visited nodes\n    std::vector<int> visited_nodes(my_size, 0);\n\n    //loop through my graph until no more nodes are unvisited\n    for (int i = 0; i < my_size; i++) {\n        if (visited_nodes[i] == 0) {\n            //traverse the graph, starting at node i, and mark all visited nodes as visited\n            for (int j = 0; j < my_size; j++) {\n                //if the current node is 1, and the node has not been visited, mark it as visited\n                if (my_graph[i] == 1 && visited_nodes[j] == 0) {\n                    visited_nodes[j] = 1;\n                }\n            }\n        }\n    }\n\n    //count the number of nodes that were visited\n    int my_visited = 0;\n    for (int i = 0; i < my_size; i++) {\n        if (visited_nodes[i] == 1) {\n            my_visited++;\n        }\n    }\n\n    //get the number of visited nodes from everyone and store them in visited_nodes_world\n    std::vector<int> visited_nodes_world(world_size, 0);\n    MPI_Reduce(&my_visited, visited_nodes_world.data(), world_size, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    //if i am rank 0, return the size of the largest component of the graph\n    if (my_rank == 0) {\n        int max_visited = 0;\n        for (int i = 0; i < world_size; i++) {\n            if (visited_nodes_world[i] > max_visited) {\n                max_visited = visited_nodes_world[i];\n            }\n        }\n        return max_visited;\n    }\n}",
            "std::vector<int> visited(N, 0);\n    std::queue<int> q;\n    int ans = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(visited[i] == 0) {\n            visited[i] = 1;\n            q.push(i);\n            while(!q.empty()) {\n                int u = q.front();\n                q.pop();\n                for(int v = 0; v < N; ++v) {\n                    if(A[u * N + v] == 1 && visited[v] == 0) {\n                        q.push(v);\n                        visited[v] = 1;\n                    }\n                }\n            }\n            ans = std::max(ans, (int) visited.size());\n            std::fill(visited.begin(), visited.end(), 0);\n        }\n    }\n    return ans;\n}",
            "int result = 0;\n  // Implement the algorithm here.\n  // Rank 0 will return the result.\n  return result;\n}",
            "// TODO: implement this function\n    return 0;\n}",
            "std::vector<int> A_sum(N*N);\n    std::vector<int> A_sum_loc(N*N);\n    int count_in=0;\n    int count_out=0;\n    int count_in_loc=0;\n    int count_out_loc=0;\n\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // calculate the sum of the A\n    for(size_t i=0; i<N; ++i) {\n        for(size_t j=0; j<N; ++j) {\n            A_sum_loc[i*N + j] = A[i*N + j];\n            count_in += A[i*N + j];\n        }\n    }\n\n    // sum up the elements\n    MPI_Reduce(&A_sum_loc[0], &A_sum[0], N*N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    // calculate the largest component number\n    for(size_t i=0; i<N; ++i) {\n        for(size_t j=0; j<N; ++j) {\n            if(A_sum[i*N + j] > 0) {\n                count_out++;\n            }\n        }\n    }\n\n    // calculate the largest component number on the rank 0\n    if(rank==0) {\n        for(size_t i=0; i<N; ++i) {\n            for(size_t j=0; j<N; ++j) {\n                if(A_sum[i*N + j] > 0) {\n                    count_out_loc++;\n                }\n            }\n        }\n    }\n\n    // broadcast the largest component number\n    MPI_Bcast(&count_out, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    // calculate the largest component number on all ranks\n    if(rank==0) {\n        for(size_t i=0; i<N; ++i) {\n            for(size_t j=0; j<N; ++j) {\n                if(A[i*N + j] > 0) {\n                    count_in_loc++;\n                }\n            }\n        }\n    }\n    else {\n        for(size_t i=0; i<N; ++i) {\n            for(size_t j=0; j<N; ++j) {\n                if(A_sum[i*N + j] > 0) {\n                    count_in_loc++;\n                }\n            }\n        }\n    }\n\n    // calculate the result and broadcast it\n    MPI_Bcast(&count_in_loc, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Bcast(&count_out_loc, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    return count_in_loc - count_out_loc;\n}",
            "//TODO\n}",
            "// your code here\n}",
            "// TODO\n}",
            "int mpi_rank, mpi_size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\n\tif (N == 0) {\n\t\treturn 0;\n\t} else if (N == 1) {\n\t\treturn 1;\n\t} else if (N == 2) {\n\t\treturn (A[0] && A[3]) || (A[1] && A[2])? 2 : 1;\n\t}\n\n\tint component = N;\n\tstd::vector<int> send_data(N, -1);\n\tstd::vector<int> recv_data(N, -1);\n\n\t// Create a disjoint set forest with all vertices as their own parent.\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsend_data[i] = i;\n\t}\n\n\t// Loop through all pairs of vertices and see if they are connected.\n\t// If so, union their components.\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] || A[j * N + i]) {\n\t\t\t\tsend_data[i] = j;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Use MPI_Allreduce to find the root of each component\n\tMPI_Allreduce(send_data.data(), recv_data.data(), N, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (recv_data[i] == i) {\n\t\t\tcomponent--;\n\t\t}\n\t}\n\n\treturn component;\n}",
            "return 0;\n}",
            "if (A.size()!= N*N) {\n\t\tthrow std::invalid_argument(\"A should be a square matrix\");\n\t}\n\tif (A.size() == 0) {\n\t\treturn 0;\n\t}\n\n\t// TODO: implement this function\n\treturn -1;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // number of vertices in the largest component\n  int largestComponent = 0;\n\n  // use the rank 0 process as the master\n  if (rank == 0) {\n    // TODO: implement\n  }\n\n  // broadcast the largest component to all processes\n  MPI_Bcast(&largestComponent, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return largestComponent;\n}",
            "int largestComponentSize = 0;\n\tint *graph = new int[N*N];\n\tfor (int i = 0; i < N*N; i++){\n\t\tgraph[i] = A[i];\n\t}\n\n\tint *disjointSet = new int[N];\n\tfor (int i = 0; i < N; i++){\n\t\tdisjointSet[i] = i;\n\t}\n\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (graph[i*N + j] == 1){\n\t\t\t\tint root1 = find(disjointSet, i);\n\t\t\t\tint root2 = find(disjointSet, j);\n\t\t\t\tif (root1!= root2){\n\t\t\t\t\tdisjointSet[root1] = root2;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++){\n\t\tlargestComponentSize = std::max(largestComponentSize, findSize(disjointSet, i));\n\t}\n\tdelete[] graph;\n\tdelete[] disjointSet;\n\treturn largestComponentSize;\n}",
            "int rank = 0, size = 1;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint n = N / size; // Number of vertices per rank\n\tint *vertices = new int[n];\n\tint *visited = new int[n];\n\tfor (int i = 0; i < n; ++i) {\n\t\tvertices[i] = i;\n\t\tvisited[i] = 0;\n\t}\n\n\tint *recv_buf = new int[size * n];\n\tint *send_buf = new int[size * n];\n\n\tint *result = new int[n];\n\tmemset(result, 0, sizeof(int) * n);\n\n\tMPI_Scatter(vertices, n, MPI_INT, recv_buf, n, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor (int i = 0; i < size * n; ++i) {\n\t\tint v = recv_buf[i] / n;\n\t\tint r = recv_buf[i] % n;\n\t\tfor (int j = 0; j < size; ++j) {\n\t\t\tif (A[v * n + r] == 1) {\n\t\t\t\tsend_buf[j * n + v] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Gather(send_buf, n, MPI_INT, recv_buf, n, MPI_INT, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < size * n; ++i) {\n\t\t\tint v = recv_buf[i] / n;\n\t\t\tint r = recv_buf[i] % n;\n\t\t\tif (result[v] == 0) {\n\t\t\t\tresult[v] = 1;\n\t\t\t\tresult[r] = 1;\n\t\t\t}\n\t\t\tif (result[r] == 0) {\n\t\t\t\tresult[r] = 1;\n\t\t\t\tresult[v] = 1;\n\t\t\t}\n\t\t}\n\t\tint count = 0;\n\t\tfor (int i = 0; i < size * n; ++i) {\n\t\t\tif (result[i] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}\n}",
            "std::vector<bool> visited(N);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = true;\n\t\t// Do BFS on the subgraph of A corresponding to the\n\t\t// vertices that have not been visited.\n\t\t// At the end of this loop, all vertices reachable from\n\t\t// i will have been visited.\n\t\t//\n\t\t// Note: This part is already implemented for you.\n\t\t//\n\t}\n\n\t// Return the number of visited vertices\n\treturn 0;\n}",
            "// TODO: fill this in\n    return 0;\n}",
            "MPI_Comm world = MPI_COMM_WORLD;\n  int rank, size;\n  MPI_Comm_rank(world, &rank);\n  MPI_Comm_size(world, &size);\n\n  if(rank == 0) {\n    return 0;\n  }\n\n  // TODO: fill in the code\n  int rank_largest_component = 0;\n\n  MPI_Reduce(&rank_largest_component, nullptr, 1, MPI_INT, MPI_MAX, 0, world);\n\n  return rank_largest_component;\n}",
            "// TODO: fill this in!\n\tint rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tstd::vector<int> v_rank_count(size, 0);\n\tstd::vector<int> v_rank_component_count(size, 0);\n\n\tint component_count = 0;\n\tfor(int i = 0; i < N; ++i){\n\t\tfor(int j = 0; j < N; ++j){\n\t\t\tif(A[i * N + j] > 0){\n\t\t\t\tv_rank_count[i]++;\n\t\t\t\tif(i!= j){\n\t\t\t\t\tcomponent_count++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Allreduce(MPI_IN_PLACE, &v_rank_count[0], size, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\tint max_vertex_count = *std::max_element(v_rank_count.begin(), v_rank_count.end());\n\n\tint rank_max_vertex = std::count(v_rank_count.begin(), v_rank_count.end(), max_vertex_count);\n\n\tif(rank_max_vertex > 1)\n\t{\n\t\tfor(int i = 0; i < N; ++i){\n\t\t\tfor(int j = 0; j < N; ++j){\n\t\t\t\tif(A[i * N + j] > 0){\n\t\t\t\t\tif(i!= j){\n\t\t\t\t\t\tv_rank_component_count[i]++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Allreduce(MPI_IN_PLACE, &v_rank_component_count[0], size, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\t\tint max_component_count = *std::max_element(v_rank_component_count.begin(), v_rank_component_count.end());\n\n\t\treturn max_component_count;\n\t}\n\n\treturn component_count;\n}",
            "// TODO: replace with your code.\n\treturn 0;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int num_vertices = A.size();\n  int chunk_size = num_vertices / size;\n  int rem = num_vertices % size;\n  int chunk_start = rank * chunk_size;\n  int chunk_end = chunk_start + chunk_size;\n  if (rank == size - 1)\n    chunk_end += rem;\n  int local_num_vertices = chunk_end - chunk_start;\n\n  // Create the adjacency matrix on this rank\n  std::vector<int> local_A(local_num_vertices * local_num_vertices);\n  for (int i = 0; i < local_num_vertices; i++) {\n    for (int j = 0; j < local_num_vertices; j++) {\n      local_A[i * local_num_vertices + j] = A[chunk_start + i * num_vertices + j];\n    }\n  }\n\n  std::vector<int> component_sizes(local_num_vertices);\n  std::vector<int> components(local_num_vertices, 0);\n  std::vector<int> next_components(local_num_vertices, 0);\n\n  int num_components = 0;\n  for (int i = 0; i < local_num_vertices; i++) {\n    if (components[i] == 0) {\n      num_components++;\n      int num = 1;\n      components[i] = num_components;\n      next_components[num_components - 1] = num;\n      for (int j = 0; j < local_num_vertices; j++) {\n        if (local_A[i * local_num_vertices + j]!= 0) {\n          if (components[j] == 0) {\n            components[j] = num_components;\n            num++;\n            next_components[num_components - 1] = num;\n          }\n        }\n      }\n      component_sizes[num_components - 1] = num;\n    }\n  }\n\n  // Reduce all local_component_sizes\n  int global_num_components;\n  MPI_Reduce(next_components.data(), &global_num_components, num_components, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  std::vector<int> global_component_sizes(global_num_components);\n  MPI_Reduce(component_sizes.data(), global_component_sizes.data(), num_components, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  int max_component_size = 0;\n  if (rank == 0) {\n    // Find the max component size\n    for (int i = 0; i < global_num_components; i++) {\n      if (global_component_sizes[i] > max_component_size) {\n        max_component_size = global_component_sizes[i];\n      }\n    }\n  }\n\n  MPI_Bcast(&max_component_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return max_component_size;\n}",
            "// Your code here.\n    return 0;\n}",
            "MPI_Comm newcomm;\n\n    std::vector<bool> in_subgraph(N, true);\n    std::vector<bool> visited(N, false);\n    std::vector<int> subgraph_size(N, 0);\n    int rank;\n    int size;\n\n    // Initializes subgraph_size vector\n    // First element is the number of vertices in the subgraph\n    for(int i = 0; i < N; i++)\n    {\n        for(int j = 0; j < N; j++)\n        {\n            if(A[i*N + j])\n            {\n                subgraph_size[i]++;\n            }\n        }\n    }\n\n    // Finds which rank has the largest subgraph\n    // Creates new communicator where the rank with the largest subgraph\n    // is rank 0\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    for(int i = 0; i < N; i++)\n    {\n        if(in_subgraph[i])\n        {\n            if(subgraph_size[i] > subgraph_size[rank])\n            {\n                MPI_Comm_split(MPI_COMM_WORLD, 1, i, &newcomm);\n            }\n            else\n            {\n                MPI_Comm_split(MPI_COMM_WORLD, 0, rank, &newcomm);\n            }\n        }\n    }\n\n    // Gathers all subgraphs sizes\n    // Then takes the maximum to find largest subgraph\n    MPI_Reduce(&subgraph_size[0], &subgraph_size[0], N, MPI_INT, MPI_MAX, 0, newcomm);\n    int max = subgraph_size[0];\n    for(int i = 1; i < N; i++)\n    {\n        if(subgraph_size[i] > max)\n        {\n            max = subgraph_size[i];\n        }\n    }\n\n    // If rank 0, return the size of the largest subgraph\n    // Else return -1\n    if(rank == 0)\n    {\n        return max;\n    }\n    else\n    {\n        return -1;\n    }\n}",
            "int largest = 0;\n  if (N == 1) {\n    return 1;\n  }\n  int numProcs, myRank;\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n  int *recvCounts = new int[numProcs];\n  int *disp = new int[numProcs];\n  int *recvBuffer = new int[N];\n  for (int i = 0; i < numProcs; i++) {\n    recvCounts[i] = (int)(N / numProcs);\n    if (i < N % numProcs) {\n      recvCounts[i]++;\n    }\n    disp[i] = i * (int)(N / numProcs);\n    if (i < N % numProcs) {\n      disp[i] += i;\n    }\n    if (i == 0) {\n      largest = recvCounts[i];\n    }\n  }\n\n  if (myRank == 0) {\n    MPI_Scatterv(A.data(), recvCounts, disp, MPI_INT, recvBuffer, N, MPI_INT, 0, MPI_COMM_WORLD);\n    for (int i = 0; i < N; i++) {\n      if (recvBuffer[i]) {\n        largest = std::max(largest, dfs(recvBuffer, N, i));\n      }\n    }\n    return largest;\n  }\n  else {\n    MPI_Scatterv(A.data(), recvCounts, disp, MPI_INT, recvBuffer, N, MPI_INT, 0, MPI_COMM_WORLD);\n    for (int i = 0; i < N; i++) {\n      if (recvBuffer[i]) {\n        largest = std::max(largest, dfs(recvBuffer, N, i));\n      }\n    }\n    return largest;\n  }\n  return largest;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    std::vector<int> component(N); // component[i] = index of component that contains vertex i.\n    int localSize = N / size;\n    int extra = N % size;\n    int localStart = rank * localSize;\n    std::vector<int> localA(localSize * N);\n    for (int i = 0; i < localSize; i++) {\n        for (int j = 0; j < N; j++) {\n            localA[i * N + j] = A[localStart + i][j];\n        }\n    }\n    // BFS from each vertex to fill in the component array\n    for (int v = localStart; v < localStart + localSize; v++) {\n        int queueSize = 0;\n        int queue[localSize];\n        queue[queueSize++] = v;\n        component[v] = v;\n        while (queueSize > 0) {\n            int q = queue[--queueSize];\n            for (int i = 0; i < N; i++) {\n                if (localA[q * N + i] && component[i] == -1) {\n                    component[i] = v;\n                    queue[queueSize++] = i;\n                }\n            }\n        }\n    }\n    // Combine component information from all ranks\n    int componentCount = N;\n    int maxLocalComponent = component[localStart];\n    int maxGlobalComponent = -1;\n    if (rank == 0) {\n        std::vector<int> globalComponent(N);\n        MPI_Gather(component.data(), localSize, MPI_INT, globalComponent.data(), localSize, MPI_INT, 0, MPI_COMM_WORLD);\n        for (int i = 0; i < N; i++) {\n            component[i] = globalComponent[i];\n            maxGlobalComponent = std::max(maxGlobalComponent, component[i]);\n        }\n    } else {\n        MPI_Gather(component.data(), localSize, MPI_INT, 0, localSize, MPI_INT, 0, MPI_COMM_WORLD);\n    }\n    // Count the number of vertices in the largest component.\n    for (int i = 0; i < N; i++) {\n        if (component[i] == maxGlobalComponent) {\n            componentCount--;\n        }\n    }\n    // Return the number of vertices in the largest component.\n    return componentCount;\n}",
            "const int ROOT = 0;\n    int local_answer = 0;\n    int global_answer = 0;\n\n    // Your code here!\n\n    return global_answer;\n}",
            "int result = 0;\n    return result;\n}",
            "// Use MPI to compute in parallel\n\tint rank, size, index;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint local_result = 0;\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < A.size(); i++) {\n\t\t\tfor (int j = 0; j < A.size(); j++) {\n\t\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\t\tlocal_result++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\tfor (int i = rank; i < A.size(); i += size) {\n\t\t\tfor (int j = 0; j < A.size(); j++) {\n\t\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\t\tlocal_result++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Reduce(&local_result, &local_result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn local_result;\n}",
            "// Add your code here\n}",
            "return 0;\n}",
            "// TODO: implement\n\treturn 0;\n}",
            "return 0;\n}",
            "return 0;\n}",
            "// TODO: Your code here\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if(rank == 0){\n    int compCount = 0;\n    bool* visited = new bool[N];\n    int* compSize = new int[N];\n\n    for(int i = 0; i < N; i++){\n      visited[i] = false;\n      compSize[i] = 0;\n    }\n\n    for(int i = 0; i < N; i++){\n      if(!visited[i]){\n        compCount++;\n        bfs(i, compSize, compCount, N, visited, A);\n      }\n    }\n\n    int maxCompSize = 0;\n    for(int i = 0; i < N; i++){\n      maxCompSize = std::max(maxCompSize, compSize[i]);\n    }\n\n    delete [] visited;\n    delete [] compSize;\n    return maxCompSize;\n  }\n  else{\n    int result;\n    MPI_Recv(&result, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    return result;\n  }\n\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// your code here\n\n}",
            "int mpi_rank, mpi_size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\n  if (mpi_rank == 0) {\n    std::vector<int> C;\n    C.resize(N * N);\n\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (i == j)\n          C[i * N + j] = 1;\n        else\n          C[i * N + j] = A[i * N + j];\n      }\n    }\n\n    for (int n = 1; n < mpi_size; n++) {\n      std::vector<int> R;\n      R.resize(N * N);\n\n      MPI_Recv(&R[0], N * N, MPI_INT, n, n, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n      for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n          if (i == j)\n            C[i * N + j] = 1;\n          else\n            C[i * N + j] = (C[i * N + j] == 1)? C[i * N + j] : C[i * N + j] + R[i * N + j];\n        }\n      }\n    }\n\n    int num = 0;\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (C[i * N + j] == 1)\n          num++;\n      }\n    }\n\n    return num;\n  } else {\n    std::vector<int> C;\n    C.resize(N * N);\n\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (i == j)\n          C[i * N + j] = 1;\n        else\n          C[i * N + j] = A[i * N + j];\n      }\n    }\n\n    MPI_Send(&C[0], N * N, MPI_INT, 0, mpi_rank, MPI_COMM_WORLD);\n  }\n}",
            "// TODO\n    return 0;\n}",
            "int result = 0;\n  // TODO\n  return result;\n}",
            "// Implement this function.\n\t\n\t// Your solution should be parallel.\n\t// Don't worry about race conditions.\n\t// You can assume that all the rows and columns of A are well-formed.\n\t// The solution should run in O(N + M) time, where M is the number of edges.\n\t\n\t// You may assume that MPI has been initialized.\n\t// You may assume that N is a power of 2 and N <= 1024.\n\t\n\t// We will return an MPI error code if MPI encounters an error.\n\t// If we encounter an error locally, we will return -1.\n}",
            "return 0;\n}",
            "int rank = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int numRanks = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\n    int rowsPerRank = N / numRanks;\n    int remainder = N % numRanks;\n\n    int myStartRow = rank * rowsPerRank;\n    int myNumRows = rowsPerRank + (rank < remainder);\n\n    if (rank == 0) {\n        std::vector<int> isInComponent(N, 1);\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < i; j++) {\n                if (A[i * N + j]) {\n                    isInComponent[j] = 0;\n                }\n            }\n            for (int j = 0; j < i; j++) {\n                if (A[j * N + i]) {\n                    isInComponent[i] = 0;\n                }\n            }\n        }\n        std::vector<int> isInComponentAll(N, 1);\n        MPI_Reduce(isInComponent.data(), isInComponentAll.data(), N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n        int max = 0;\n        for (int i = 0; i < N; i++) {\n            max = std::max(max, isInComponentAll[i]);\n        }\n        return max;\n    } else {\n        // We don't need this.\n        std::vector<int> isInComponent(myNumRows);\n        MPI_Reduce(isInComponent.data(), NULL, myNumRows, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n        return 0;\n    }\n}",
            "//TODO: replace this line with your solution\n\treturn 0;\n}",
            "// Your code here\n  int count = 0;\n  bool* visited = new bool[N];\n  int* result = new int[N];\n  std::fill(visited, visited + N, false);\n  std::fill(result, result + N, 0);\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      visited[i] = true;\n      result[i] = dfs(A, i, visited, result);\n      count = max(count, result[i]);\n    }\n  }\n  return count;\n}",
            "// TODO: Implement\n\tint total = 0;\n\tint mpi_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\tstd::vector<int> temp = A;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (temp[i * N + j] == 1) {\n\t\t\t\tint k;\n\t\t\t\tfor (k = 0; k < N; k++) {\n\t\t\t\t\tif (temp[j * N + k] == 1) {\n\t\t\t\t\t\ttemp[i * N + k] = 1;\n\t\t\t\t\t\ttemp[k * N + j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif (mpi_rank == 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (temp[i * N + i] == 1) {\n\t\t\t\ttotal++;\n\t\t\t}\n\t\t}\n\t}\n\treturn total;\n}",
            "int num_tasks;\n\tint my_rank;\n\t\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_tasks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\t\n\tstd::vector<int> local_A = A;\n\tint n_vertex_per_rank = N/num_tasks;\n\tint first = my_rank * n_vertex_per_rank;\n\tint last = first + n_vertex_per_rank;\n\t\n\tstd::vector<int> visited(local_A.size());\n\tstd::vector<int> components(local_A.size());\n\tint num_components = 0;\n\tint max_component = 0;\n\t\n\tfor (int i = 0; i < visited.size(); ++i) {\n\t\tif (!visited[i]) {\n\t\t\tint component_size = 0;\n\t\t\tint u = i;\n\t\t\tvisited[i] = 1;\n\t\t\tcomponents[i] = num_components;\n\t\t\twhile (!local_A[u * N + u]) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (local_A[u * N + j]) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t\tcomponents[j] = num_components;\n\t\t\t\t\t\t\t++component_size;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (components[j]!= num_components) {\n\t\t\t\t\t\t\tfor (int k = 0; k < components.size(); ++k) {\n\t\t\t\t\t\t\t\tif (components[k] == num_components) {\n\t\t\t\t\t\t\t\t\tcomponents[k] = components[j];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t++num_components;\n\t\t\tif (max_component < component_size) {\n\t\t\t\tmax_component = component_size;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint res;\n\tMPI_Reduce(&max_component, &res, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t\n\tif (my_rank == 0) {\n\t\treturn res;\n\t}\n\telse {\n\t\treturn 0;\n\t}\n}",
            "MPI_Init(NULL, NULL);\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint maxSize = 1;\n\tint localSize = 0;\n\tint* localMaxSize = new int[N];\n\tint* localSizes = new int[N];\n\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t\tif (A[i*N+j]!= 0)\n\t\t\t\t\tlocalMaxSize[i] = 1;\n\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tlocalSizes[i] = 1;\n\n\t\tfor (int k = 1; k < size; ++k) {\n\t\t\tMPI_Recv(&localMaxSize[0], N, MPI_INT, k, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tMPI_Recv(&localSizes[0], N, MPI_INT, k, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t\t\tfor (int i = 0; i < N; ++i)\n\t\t\t\tif (localMaxSize[i] == 0)\n\t\t\t\t\tcontinue;\n\t\t\t\telse if (localSizes[i] == 0)\n\t\t\t\t\tlocalMaxSize[i] = 0;\n\t\t\t\telse if (localSizes[i] > 0)\n\t\t\t\t\tlocalMaxSize[i] = 1;\n\t\t}\n\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tif (localMaxSize[i] == 1)\n\t\t\t\t++localSize;\n\n\t\tmaxSize = localSize;\n\n\t\tfor (int k = 1; k < size; ++k) {\n\t\t\tMPI_Send(&localMaxSize[0], N, MPI_INT, k, 0, MPI_COMM_WORLD);\n\t\t\tMPI_Send(&localSizes[0], N, MPI_INT, k, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\telse {\n\t\tint* localMaxSize = new int[N];\n\t\tint* localSizes = new int[N];\n\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t\tif (A[i*N+j]!= 0)\n\t\t\t\t\tlocalMaxSize[i] = 1;\n\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tlocalSizes[i] = 1;\n\n\t\tMPI_Send(&localMaxSize[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(&localSizes[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tdelete[] localMaxSize;\n\tdelete[] localSizes;\n\n\tMPI_Finalize();\n\n\treturn maxSize;\n}",
            "int totalNumber = N;\n  int maxNumber = 0;\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        totalNumber -= 1;\n      }\n    }\n\n    if (totalNumber > maxNumber) {\n      maxNumber = totalNumber;\n    }\n  }\n\n  return maxNumber;\n}",
            "const int tag = 0;\n\n\tif(N == 1){\n\t\treturn 1;\n\t}\n\n\t// Your code here.\n\t\n\tint rank, size;\n\t\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (rank == 0)\n\t{\n\t\tMPI_Send(&A[0], N*N, MPI_INT, 1, tag, MPI_COMM_WORLD);\n\t\t\n\t} else\n\t{\n\t\tstd::vector<int> A2(N*N);\n\t\tMPI_Recv(&A2[0], N*N, MPI_INT, 0, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tA2 = A;\n\t\tint result = largestComponent(A2, N);\n\t\tMPI_Send(&result, 1, MPI_INT, 0, tag, MPI_COMM_WORLD);\n\t\t\n\t}\n\n\tif (rank == 0)\n\t{\n\t\tint result = 0;\n\t\tfor (int i = 1; i < size; i++)\n\t\t{\n\t\t\tint result_i = 0;\n\t\t\tMPI_Recv(&result_i, 1, MPI_INT, i, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tresult = result > result_i? result : result_i;\n\t\t}\n\t\treturn result;\n\t} else\n\t{\n\t\treturn 0;\n\t}\n}",
            "}",
            "// TODO\n}",
            "// YOUR CODE HERE\n\treturn 0;\n}",
            "assert(N > 0);\n\n  return 0;\n}",
            "// Implemented for you\n  int result = 0;\n  return result;\n}",
            "MPI_Comm myComm;\n\tint commSize, myRank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &commSize);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n\tint* B = new int[N * N];\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tB[i * N + j] = A[i * N + j];\n\t\t}\n\t}\n\n\tif (myRank == 0) {\n\t\t// TODO\n\t}\n\n\tif (myRank!= 0) {\n\t\t// TODO\n\t}\n\n\tMPI_Gather(B, N*N, MPI_INT, B, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (myRank == 0) {\n\t\t// TODO\n\t}\n\n\tMPI_Bcast(&B, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// TODO\n}",
            "// TODO: Your code here\n\t// Note: We're going to give you some additional functions\n\t// you can use below to make your code more concise\n\t// For example, to find the number of elements that are\n\t// non-zero in an array, you can use the function\n\t// nonZeros(myArray)\n\n\treturn -1;\n}",
            "std::vector<int> compSize(N, 0);\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tcompSize[i] += 1;\n\t\t\t\tcompSize[j] += 1;\n\t\t\t}\n\t\t}\n\t}\n\tint maxCompSize = 0;\n\tfor (auto i : compSize)\n\t{\n\t\tif (i > maxCompSize)\n\t\t{\n\t\t\tmaxCompSize = i;\n\t\t}\n\t}\n\treturn maxCompSize;\n}",
            "// TODO\n    int *Aint = &(A[0]);\n    int my_rank = 0;\n    int size = 0;\n\n    int *colors = (int*)malloc(N*N*sizeof(int));\n    int *parent = (int*)malloc(N*N*sizeof(int));\n    int *sizes = (int*)malloc(N*N*sizeof(int));\n\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n    int chunk = N/size;\n    int rest = N%size;\n    int start = (my_rank*chunk)+std::min(my_rank,rest);\n    int end = ((my_rank+1)*chunk)+std::min(my_rank+1,rest);\n\n    for(int i=0;i<N*N;i++){\n        colors[i] = 0;\n        parent[i] = -1;\n        sizes[i] = 0;\n    }\n\n    for(int i=start;i<end;i++){\n        if(Aint[i]!=0){\n            colors[i] = 1;\n            sizes[i] = 1;\n            parent[i] = i;\n        }\n    }\n    for(int i=0;i<N;i++){\n        for(int j=0;j<N;j++){\n            if(colors[i*N+j]==1){\n                for(int k=0;k<N;k++){\n                    if(Aint[i*N+k]==1){\n                        if(colors[k*N+j]==0){\n                            if(parent[k*N+j]==-1){\n                                parent[k*N+j] = i*N+j;\n                                sizes[i*N+j]++;\n                            }else{\n                                while(parent[i*N+j]!= parent[k*N+j]){\n                                    if(sizes[parent[k*N+j]]>sizes[parent[i*N+j]]){\n                                        parent[i*N+j] = parent[k*N+j];\n                                        sizes[parent[i*N+j]]+=sizes[i*N+j];\n                                    }else{\n                                        parent[k*N+j] = parent[i*N+j];\n                                        sizes[parent[k*N+j]]+=sizes[k*N+j];\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n    int *sum = (int*)malloc(size*sizeof(int));\n    int global_max = 0;\n    for(int i=0;i<size;i++){\n        MPI_Recv(&(sum[i]), 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        if(sum[i]>global_max){\n            global_max = sum[i];\n        }\n    }\n    MPI_Send(&(global_max), 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    return global_max;\n}",
            "int rank, p, numRanks, source, dest;\n  int size, color;\n  int *sendBuf, *recvBuf;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (rank == 0) {\n    dest = 1;\n    color = 1;\n    size = N;\n  } else {\n    dest = 0;\n    color = 0;\n    size = 0;\n  }\n\n  // 1st step:\n  // exchange the size of the largest component in each rank\n  MPI_Bcast(&size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // 2nd step:\n  // exchange the adjacency matrix\n  if (rank!= 0) {\n    sendBuf = new int[N*N];\n    for (int i = 0; i < N*N; ++i) {\n      sendBuf[i] = A[i];\n    }\n  }\n  MPI_Bcast(sendBuf, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // 3rd step:\n  // broadcast the adjacency matrix and compute the largest component size\n  if (rank == 0) {\n    for (int i = 1; i < numRanks; ++i) {\n      if (size < i) {\n        size = i;\n      }\n    }\n    recvBuf = new int[N*N];\n    for (int i = 1; i < numRanks; ++i) {\n      MPI_Bcast(recvBuf, N*N, MPI_INT, i, MPI_COMM_WORLD);\n\n      // check if the adjacency matrix is valid\n      for (int j = 0; j < N*N; ++j) {\n        if (recvBuf[j] < 0 || recvBuf[j] > 1) {\n          // invalid matrix\n          size = 0;\n          break;\n        }\n      }\n      for (int j = 0; j < N; ++j) {\n        for (int k = 0; k < N; ++k) {\n          // find the largest component\n          if (recvBuf[k*N+j] == 1) {\n            size = std::max(size, bfs(recvBuf, N, j));\n          }\n        }\n      }\n    }\n    delete[] recvBuf;\n  }\n\n  // 4th step:\n  // broadcast the largest component size\n  MPI_Bcast(&size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank!= 0) {\n    delete[] sendBuf;\n  }\n\n  return size;\n}",
            "int myrank;\n  int nprocs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n  // TODO: Complete this function\n}",
            "int rank, size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  std::vector<int> B = A;\n  std::vector<int> C;\n  std::vector<int> D;\n  std::vector<int> E;\n  std::vector<int> F;\n  std::vector<int> G;\n  std::vector<int> H;\n  std::vector<int> I;\n  std::vector<int> J;\n  std::vector<int> K;\n  std::vector<int> L;\n  std::vector<int> M;\n  std::vector<int> NN;\n  std::vector<int> O;\n  std::vector<int> P;\n  std::vector<int> Q;\n  std::vector<int> R;\n  std::vector<int> S;\n  std::vector<int> T;\n  std::vector<int> U;\n  std::vector<int> V;\n  std::vector<int> W;\n  std::vector<int> X;\n  std::vector<int> Y;\n  std::vector<int> Z;\n  if (N % size == 0){\n    int m = N / size;\n    for (int i = 0; i < m; i++){\n      for (int j = 0; j < m; j++){\n        B[i * m + j] = 0;\n        C[i * m + j] = 0;\n        D[i * m + j] = 0;\n        E[i * m + j] = 0;\n        F[i * m + j] = 0;\n        G[i * m + j] = 0;\n        H[i * m + j] = 0;\n        I[i * m + j] = 0;\n        J[i * m + j] = 0;\n        K[i * m + j] = 0;\n        L[i * m + j] = 0;\n        M[i * m + j] = 0;\n        NN[i * m + j] = 0;\n        O[i * m + j] = 0;\n        P[i * m + j] = 0;\n        Q[i * m + j] = 0;\n        R[i * m + j] = 0;\n        S[i * m + j] = 0;\n        T[i * m + j] = 0;\n        U[i * m + j] = 0;\n        V[i * m + j] = 0;\n        W[i * m + j] = 0;\n        X[i * m + j] = 0;\n        Y[i * m + j] = 0;\n        Z[i * m + j] = 0;\n      }\n    }\n    if (rank == 0){\n      for (int i = 0; i < N; i++){\n        for (int j = 0; j < N; j++){\n          C[i * m + j] = A[i * N + j];\n          D[i * m + j] = A[i * N + j];\n          E[i * m + j] = A[i * N + j];\n          F[i * m + j] = A[i * N + j];\n          G[i * m + j] = A[i * N + j];\n          H[i * m + j] = A[i * N + j];\n          I[i * m + j] = A[i * N + j];\n          J[i * m + j] = A[i * N + j];\n          K[i * m + j] = A[i * N + j];\n          L[i * m + j] = A[i * N + j];\n          M[i * m + j] = A[i * N + j];\n          NN[i * m + j] = A[i * N + j];\n          O[i * m + j] = A[i * N + j];\n          P[i * m + j] = A[i * N + j];\n          Q[i",
            "// Your code here\n    return 0;\n}",
            "// Your code here.\n  int rank, size;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int *displs = new int[size];\n  int *counts = new int[size];\n\n  for (int i = 0; i < size; i++) {\n    displs[i] = i * N;\n    counts[i] = N;\n  }\n\n  int *A_full = new int[N * N];\n\n  MPI_Allgatherv(A.data(), N, MPI_INT, A_full, counts, displs, MPI_INT, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    int max_component_size = 0;\n    int max_component = 0;\n\n    for (int i = 0; i < N; i++) {\n      int component = 0;\n      std::vector<bool> visited(N);\n\n      for (int j = 0; j < N; j++) {\n        if (A_full[i * N + j] &&!visited[j]) {\n          visited[j] = true;\n          component++;\n\n          for (int k = 0; k < N; k++) {\n            if (A_full[j * N + k] &&!visited[k]) {\n              visited[k] = true;\n              component++;\n            }\n          }\n        }\n      }\n\n      if (component > max_component_size) {\n        max_component_size = component;\n        max_component = i;\n      }\n    }\n\n    delete[] A_full;\n    delete[] displs;\n    delete[] counts;\n\n    return max_component;\n  }\n\n  delete[] A_full;\n  delete[] displs;\n  delete[] counts;\n\n  return 0;\n}",
            "// Implement this\n}",
            "int num_components = 1;\n\tint num_vertices = 0;\n\t// Your code here\n\t\n\treturn num_components;\n}",
            "int root = 0;\n\tint num_processes, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tstd::vector<int> A_local(N*N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tA_local[i*N + j] = A[i*N + j];\n\t\t}\n\t}\n\t// BFS\n\tstd::queue<int> q;\n\tstd::vector<int> visited(N, 0);\n\tint start_vertex = 0;\n\tq.push(start_vertex);\n\tvisited[start_vertex] = 1;\n\twhile (!q.empty()) {\n\t\tint curr = q.front();\n\t\tq.pop();\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A_local[curr*N + i] == 1 && visited[i] == 0) {\n\t\t\t\tq.push(i);\n\t\t\t\tvisited[i] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tint num_of_vertices = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 1)\n\t\t\tnum_of_vertices++;\n\t}\n\tstd::vector<int> num_of_vertices_per_rank(num_processes, 0);\n\tMPI_Gather(&num_of_vertices, 1, MPI_INT, &num_of_vertices_per_rank[0], 1, MPI_INT, root, MPI_COMM_WORLD);\n\tif (rank == root) {\n\t\tint largest = 0;\n\t\tfor (size_t i = 0; i < num_of_vertices_per_rank.size(); i++) {\n\t\t\tif (num_of_vertices_per_rank[i] > largest)\n\t\t\t\tlargest = num_of_vertices_per_rank[i];\n\t\t}\n\t\treturn largest;\n\t}\n\telse {\n\t\treturn -1;\n\t}\n}",
            "MPI_Init(NULL, NULL);\n\tint numtasks, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numtasks);\n\tif (rank == 0) {\n\t\tint *s = new int[N*N];\n\t\tint *s2 = new int[N*N];\n\t\tint *s3 = new int[N*N];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\ts[i*N+j] = A[i*N+j];\n\t\t\t}\n\t\t}\n\t\tstd::vector<int> result;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tresult.push_back(i);\n\t\t}\n\t\tstd::vector<int> work;\n\t\tstd::vector<int> work2;\n\t\tstd::vector<int> work3;\n\t\twork = result;\n\t\twhile (work.size() > 0) {\n\t\t\twork2 = work;\n\t\t\tfor (int i = 0; i < work.size(); i++) {\n\t\t\t\tfor (int j = 0; j < work.size(); j++) {\n\t\t\t\t\tif (s[work2[i] * N + work2[j]] == 1) {\n\t\t\t\t\t\ts[work2[i] * N + work2[j]] = 0;\n\t\t\t\t\t\ts[work2[j] * N + work2[i]] = 0;\n\t\t\t\t\t\tfor (int k = 0; k < result.size(); k++) {\n\t\t\t\t\t\t\tif (result[k] == work2[j]) {\n\t\t\t\t\t\t\t\tresult.erase(result.begin() + k);\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor (int k = 0; k < work.size(); k++) {\n\t\t\t\t\t\t\tif (work[k] == work2[j]) {\n\t\t\t\t\t\t\t\twork.erase(work.begin() + k);\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor (int k = 0; k < work3.size(); k++) {\n\t\t\t\t\t\t\tif (work3[k] == work2[j]) {\n\t\t\t\t\t\t\t\twork3.erase(work3.begin() + k);\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\twork3 = work;\n\t\t\twork = result;\n\t\t\tresult.clear();\n\t\t\tfor (int i = 0; i < work.size(); i++) {\n\t\t\t\tresult.push_back(work[i]);\n\t\t\t}\n\t\t\tfor (int i = 0; i < work3.size(); i++) {\n\t\t\t\tif (std::find(work.begin(), work.end(), work3[i]) == work.end()) {\n\t\t\t\t\tresult.push_back(work3[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint finalResult = result.size();\n\t\tMPI_Bcast(&finalResult, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tint finalResult;\n\t\tMPI_Bcast(&finalResult, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t}\n\tMPI_Finalize();\n\treturn finalResult;\n}",
            "return 0;\n}",
            "int rank, nproc;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &nproc);\n    std::vector<int> visited(N, 0);\n    std::queue<int> queue;\n    queue.push(0);\n    visited[0] = 1;\n    int count = 1;\n    while (queue.size()) {\n        int curr = queue.front();\n        queue.pop();\n        for (int i = 0; i < N; i++) {\n            if (A[curr * N + i] &&!visited[i]) {\n                queue.push(i);\n                visited[i] = 1;\n                count++;\n            }\n        }\n    }\n    int maxcount = count;\n    for (int i = 0; i < nproc; i++) {\n        if (i!= rank) {\n            MPI_Send(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        if (i!= 0) {\n            MPI_Recv(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            if (count > maxcount) {\n                maxcount = count;\n            }\n        }\n    }\n    return maxcount;\n}",
            "if (A.size()!= N * N) {\n\t\tthrow std::runtime_error(\"Invalid matrix dimension\");\n\t}\n\n\tstd::vector<int> connected; // 0 if not connected, 1 if connected\n\tconnected.resize(N);\n\n\t// Initialize connected to all 1s\n\tfor (int i = 0; i < N; ++i) {\n\t\tconnected[i] = 1;\n\t}\n\n\t// For each edge, if the two vertices on either side are not already connected,\n\t// connect them.\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1 && connected[i]!= connected[j]) {\n\t\t\t\tconnected[j] = connected[i];\n\t\t\t}\n\t\t}\n\t}\n\n\t// Count up how many vertices are connected to a single component\n\tint numConnected = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (connected[i] == 1) {\n\t\t\tnumConnected++;\n\t\t}\n\t}\n\n\t// Send the number of connected vertices to rank 0\n\tint numConnectedTotal;\n\tMPI_Reduce(&numConnected, &numConnectedTotal, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// If rank 0, return the total number of connected vertices\n\tif (0 == MPI_Rank()) {\n\t\treturn numConnectedTotal;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "/* TODO: Your code here */\n}",
            "// TODO\n}",
            "// Your code here\n    return -1;\n}",
            "int size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// 2D matrix storage\n\tstd::vector<std::vector<int>> matrix(N, std::vector<int>(N));\n\t// matrix[i][j] is true iff there exists a edge from i to j\n\tfor(size_t i = 0; i < N; i++){\n\t\tfor(size_t j = 0; j < N; j++){\n\t\t\tmatrix[i][j] = A[N*i + j];\n\t\t}\n\t}\n\n\t// DFS traversal\n\tstd::vector<std::vector<int>> result(N, std::vector<int>(N));\n\tstd::vector<bool> visited(N, false);\n\tstd::stack<int> stack;\n\n\tint numOfVertices = 0;\n\tfor(size_t i = 0; i < N; i++){\n\t\tif(visited[i] == false){\n\t\t\tstack.push(i);\n\t\t\tvisited[i] = true;\n\t\t\tnumOfVertices++;\n\t\t\twhile(!stack.empty()){\n\t\t\t\tint top = stack.top();\n\t\t\t\tstack.pop();\n\t\t\t\tfor(size_t j = 0; j < N; j++){\n\t\t\t\t\tif(matrix[top][j] == 1 && visited[j] == false){\n\t\t\t\t\t\tstack.push(j);\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tnumOfVertices++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// return the number of vertices in the largest component\n\tint largest = numOfVertices;\n\tif(rank == 0){\n\t\tint temp = 0;\n\t\tMPI_Reduce(&numOfVertices, &temp, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t\tlargest = temp;\n\t} else {\n\t\tMPI_Reduce(&numOfVertices, NULL, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn largest;\n}",
            "// TODO: Your code here!\n  return 0;\n}",
            "int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  std::vector<int> A_all(size*N*N, 0);\n  MPI_Gather(&A[0], N*N, MPI_INT, &A_all[0], N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (A_all.size() == 0) {\n    throw std::runtime_error(\"There must be at least one row of A.\");\n  }\n\n  if (A_all.size() % (N*N)) {\n    throw std::runtime_error(\"The input matrix A must be square.\");\n  }\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (rank == 0) {\n    std::vector<int> visited(size*N, 0);\n    visited[0] = 1;\n    size_t c = 1;\n\n    for (size_t k = 0; k < size; ++k) {\n      for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n          if (A_all[k*N*N+i*N+j]!= 0) {\n            if (!visited[k*N+j]) {\n              c++;\n            }\n            visited[k*N+j] = 1;\n            visited[k*N+i] = 1;\n          }\n        }\n      }\n    }\n\n    int largest = 0;\n    for (size_t i = 0; i < visited.size(); ++i) {\n      largest = std::max(largest, visited[i]);\n    }\n\n    return largest;\n  } else {\n    return 0;\n  }\n}",
            "// A \u4e3a\u542b\u6709\u90bb\u63a5\u77e9\u9635\u7684 vector\uff0c\u9700\u8981 N*N \u4e2a\u6570\n\tassert(A.size() == N * N);\n\n\t// \u5bf9\u4e8e\u6574\u4e2a\u77e9\u9635\u4e2d\u7684\u6bcf\u4e00\u4e2a\u503c\uff0c\u5f53\u524d\u8fdb\u7a0b\u5982\u679c\u53d1\u73b0\u4e86\u5927\u4e8e 0 \u7684\u503c\uff0c\u5c31\u8bf4\u660e\n\t// \u5f53\u524d\u8fdb\u7a0b\u7684\u90bb\u63a5\u77e9\u9635\u4e2d\u6709\u65b0\u7684\u70b9\u53ef\u4ee5\u8d70\n\tstd::vector<bool> canWalk(N, false);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tcanWalk[i] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t// \u8fdb\u7a0b\u95f4\u8fdb\u884c\u901a\u4fe1\uff0c\u5c06 canWalk \u7684\u503c\u6574\u5408\u8d77\u6765\n\t// \u5148\u8fdb\u884c MPI_Allreduce\n\tint NP;\n\tMPI_Comm_size(MPI_COMM_WORLD, &NP);\n\tstd::vector<int> canWalk_reduce(N);\n\tMPI_Allreduce(canWalk.data(), canWalk_reduce.data(), N, MPI_INT, MPI_LOR, MPI_COMM_WORLD);\n\n\t// \u7528\u4e8e\u6807\u8bb0\u662f\u5426\u8d70\u8fc7\u67d0\u4e2a\u70b9\n\tstd::vector<bool> walked(N, false);\n\n\t// \u7528\u4e8e\u8bb0\u5f55\u5f53\u524d\u8fdb\u7a0b\u4e2d\u8fd8\u5b58\u5728\u591a\u5c11\u4e2a\u53ef\u8d70\u7684\u70b9\n\tsize_t numberOfWalkable = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (canWalk_reduce[i]) {\n\t\t\t++numberOfWalkable;\n\t\t}\n\t}\n\n\t// \u7528\u4e8e\u8bb0\u5f55\u5f53\u524d\u8fdb\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u70b9\u90bb\u63a5\u7684\u70b9\u8fd8\u80fd\u8d70\u5230\u7684\u70b9\u7684\u6570\u91cf\n\tstd::vector<int> numberOfNeighbor(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t// \u5982\u679c\u5f53\u524d\u70b9\u7684\u90bb\u63a5\u77e9\u9635\u7684\u503c\u4e3a 1\uff0c\u5c31\u8fdb\u884c\u4e0b\u4e00\u4e2a\u5faa\u73af\uff0c\u907f\u514d\u5728\u90bb\u63a5\u77e9\u9635\u4e2d\n\t\t\t// \u8fdb\u884c\u91cd\u590d\u7684\u8fed\u4ee3\n\t\t\tif (A[i * N + j] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// \u5982\u679c\u5f53\u524d\u8fdb\u7a0b\u7684\u90bb\u63a5\u77e9\u9635\u4e2d\u7684\u503c\u4e3a 1\uff0c\u8bf4\u660e\u5f53\u524d\u8fdb\u7a0b\u53ef\u4ee5\u904d\u5386\u5230 j\n\t\t\t// \u8fd9\u4e2a\u70b9\uff0c\u5982\u679c walked \u7684\u503c\u4e3a false\uff0c\u8bf4\u660e\u8fd8\u6ca1\u6709\u8d70\u5230\uff0c\u90a3\u4e48\u5c31\u8bb0\u5f55\u53ef\u4ee5\n\t\t\t// \u8d70\u5230\u7684\u70b9\u7684\u6570\u91cf\n\t\t\tif (canWalk[j] &&!walked[j]) {\n\t\t\t\t++numberOfNeighbor[i];\n\t\t\t}\n\t\t}\n\t}\n\n\t// \u8fdb\u7a0b\u95f4\u901a\u4fe1\uff0c\u5c06\u90bb\u63a5\u70b9\u7684\u6570\u91cf\u6574\u5408\u8d77\u6765\n\tMPI_Allreduce(numberOfNeighbor.data(), numberOfNeighbor.data(), N, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n\t// \u4f7f\u7528 MPI_Reduce \u5bf9 numberOfWalkable \u8fdb\u884c\u6574\u5408\n\tint total = 0;\n\tMPI_Reduce(&numberOfWalkable, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// \u627e\u5230\u5f53\u524d\u8fdb\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u8d70\u7684\u70b9\u7684\u6570\u91cf\u6700\u5927\u7684\u90a3\u4e2a\u70b9\uff0c\u4ee5\u53ca\u5176\u90bb\u63a5\u70b9\u7684\u6570\u91cf\n\tint max = 0;\n\tint index = 0;",
            "int result = 0;\n\tMPI_Datatype column;\n\tMPI_Type_vector(N, 1, N, MPI_INT, &column);\n\tMPI_Type_commit(&column);\n\tMPI_Status status;\n\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint numRanks;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\n\tstd::vector<int> B(N, 0);\n\tif (rank == 0)\n\t\tB = A;\n\n\tfor (int i = 0; i < numRanks; ++i) {\n\t\tif (rank == i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tB[j] = 1;\n\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\tif (j!= k && A[j * N + k] == 1)\n\t\t\t\t\t\tB[j] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Bcast(&B[0], N, column, i, MPI_COMM_WORLD);\n\t\tMPI_Reduce(MPI_IN_PLACE, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t}\n\n\tMPI_Type_free(&column);\n\n\treturn result;\n}",
            "// TODO: Fill in this function\n\n}",
            "int count = 0;\n\tint visited = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i*N + i] == 1) {\n\t\t\tvisited++;\n\t\t}\n\t}\n\n\tMPI_Allreduce(&visited, &count, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\treturn count;\n}",
            "// TODO: write code for this function\n}",
            "int largest = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tif (largest < 1) {\n\t\t\t\t\tlargest = 1;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlargest++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn largest;\n}",
            "/*\n      TODO:\n      Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n      A is an NxN adjacency matrix stored in row-major.\n      Use MPI to compute in parallel. Assume MPI has already been initialized.\n      Every rank has a complete copy of A. The result is returned on rank 0.\n\n      Example:\n\n       input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n       output: 2\n    */\n\n    /*\n       Here is some boilerplate to get you started. You will need to\n       add additional code to compute the component size.\n    */\n\n    // Initialization\n    int rank, size, tag = 1, largest_size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    if (rank == 0) {\n        for (size_t i = 0; i < N; ++i) {\n            if (A[i * N + i] == 0) {\n                throw std::invalid_argument(\"Graph not fully connected\");\n            }\n        }\n    }\n\n    // Compute the size of each component\n    int component_size = 0;\n    for (size_t i = 0; i < N; ++i) {\n        // If the current element is a vertex in the graph\n        if (A[i * N + i] == 1) {\n            // BFS from this vertex\n            std::queue<int> q;\n            std::vector<bool> visited(N);\n            q.push(i);\n            while (!q.empty()) {\n                int curr = q.front();\n                q.pop();\n                if (!visited[curr]) {\n                    visited[curr] = true;\n                    component_size++;\n                    for (size_t j = 0; j < N; ++j) {\n                        if (A[curr * N + j] == 1 &&!visited[j]) {\n                            q.push(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Reduce the size of each component\n    MPI_Reduce(&component_size, &largest_size, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    // Return result\n    if (rank == 0) {\n        return largest_size;\n    }\n    else {\n        return 0;\n    }\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "cuda",
        "prompt": "/* Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   Store the result in largestComponentSize.\n   A is an NxN adjacency matrix stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void largestComponent(const int *A, size_t N, int *largestComponentSize) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int max = 0;\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < N && col < N)\n        if (A[row * N + col]!= 0)\n            max = (col > row? col : row) + 1;\n\n    for (int i = 1; i < 32; i <<= 1)\n        max = (max >= i? max - i : max);\n\n    __shared__ int shared[32];\n    shared[threadIdx.x] = max;\n    __syncthreads();\n\n    for (int i = 16; i >= 1; i >>= 1)\n        max = (shared[threadIdx.x] >= i? shared[threadIdx.x] - i : shared[threadIdx.x]);\n\n    if (threadIdx.x == 0)\n        *largestComponentSize = max;\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n\n    __shared__ int largest[2];\n\n    // Compute the size of the largest component\n    if (id == 0) {\n        largest[0] = 0;\n        largest[1] = 0;\n    }\n\n    __syncthreads();\n\n    if (id < N*N) {\n        atomicAdd(&largest[0], A[id]);\n        atomicAdd(&largest[1], A[N*N - 1 - id]);\n    }\n\n    __syncthreads();\n\n    // Compute the size of the largest component\n    if (id == 0) {\n        largestComponentSize[0] = largest[0] > largest[1]? largest[0] : largest[1];\n    }\n}",
            "// Insert your code here\n\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= N) return;\n    int componentSize = 1;\n    for (int i = 0; i < N; ++i) {\n        if (A[tid * N + i]!= 0) {\n            int componentSize2 = 1;\n            int curr = i;\n            while (curr!= tid) {\n                for (int j = 0; j < N; ++j) {\n                    if (A[curr * N + j]!= 0) {\n                        curr = j;\n                        break;\n                    }\n                }\n                componentSize2 += 1;\n            }\n            componentSize = max(componentSize, componentSize2);\n        }\n    }\n    atomicAdd(largestComponentSize, componentSize);\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tif (i == j && A[i*N+j] == 1) atomicAdd(largestComponentSize, 1);\n}",
            "//...\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i >= N || j >= N || i == j || A[i + N*j] == 0) {\n    return;\n  }\n\n  __shared__ int componentSize[32];\n  componentSize[threadIdx.y] = 0;\n  __syncthreads();\n\n  int x = i;\n  int y = j;\n  if (A[x + N*y] == 1) {\n    componentSize[threadIdx.y] = 1;\n  }\n  __syncthreads();\n\n  for (int d = 16; d > 0; d /= 2) {\n    if (threadIdx.y < d) {\n      componentSize[threadIdx.y] += componentSize[threadIdx.y + d];\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.y == 0) {\n    atomicAdd(largestComponentSize, componentSize[threadIdx.y]);\n  }\n}",
            "__shared__ int visited[MAX_NUM_NODES];\n\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (row < N && col < N) {\n        if (A[row * N + col]!= 0) {\n            visited[row] = 1;\n            visited[col] = 1;\n            for (int i = row + 1; i < N; i++) {\n                if (A[i * N + row]!= 0)\n                    visited[i] = 1;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    if (row == 0 && col == 0) {\n        int max = 0;\n        for (int i = 0; i < N; i++) {\n            if (visited[i] == 1)\n                max += 1;\n        }\n\n        *largestComponentSize = max;\n    }\n}",
            "__shared__ int componentSizes[THREADS];\n\n\tint i = blockDim.x * blockIdx.y + threadIdx.x;\n\tint j = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// Each thread stores the size of its component in componentSizes\n\tcomponentSizes[threadIdx.x] = (A[i * N + j] == 1)? 1 : 0;\n\t__syncthreads();\n\n\t// Sum up the size of each thread's component to get the size of the largest component\n\tfor (int s = blockDim.x / 2; s > 0; s >>= 1) {\n\t\tif (threadIdx.x < s) {\n\t\t\tcomponentSizes[threadIdx.x] += componentSizes[threadIdx.x + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// First thread writes the result to the global memory\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = componentSizes[0];\n\t}\n}",
            "int myId = blockIdx.x * blockDim.x + threadIdx.x;\n  int N_ = N;\n  int componentId[N];\n  int numComponents = 0;\n  int *componentSize = (int *) malloc(sizeof(int) * N);\n  for(int i = 0; i < N; i++)\n  {\n    componentId[i] = i;\n  }\n  for(int i = 0; i < N; i++)\n  {\n    for(int j = i+1; j < N; j++)\n    {\n      if(A[i * N_ + j]!= 0)\n      {\n        if(componentId[i]!= componentId[j])\n        {\n          componentSize[componentId[j]] += componentSize[componentId[i]];\n          componentId[i] = componentId[j];\n          numComponents--;\n        }\n      }\n    }\n  }\n  for(int i = 0; i < N; i++)\n  {\n    if(componentId[i] == i)\n      numComponents++;\n  }\n  if(*largestComponentSize < componentSize[componentId[myId]])\n    *largestComponentSize = componentSize[componentId[myId]];\n}",
            "__shared__ int s_component_size;\n  int t_component_size = 0;\n\n  int i = threadIdx.x;\n  int j = blockIdx.x;\n\n  if (i == j) {\n    for (int k = 0; k < N; k++) {\n      if (A[i * N + k] || A[k * N + j]) {\n        t_component_size++;\n      }\n    }\n  }\n  atomicAdd(&s_component_size, t_component_size);\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicAdd(largestComponentSize, s_component_size);\n  }\n}",
            "// TODO\n}",
            "// Initialize our local graph.\n    __shared__ int sGraph[N][N];\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            sGraph[i][j] = A[i * N + j];\n        }\n    }\n\n    // Find the largest component by searching.\n    __shared__ bool sVisited[N];\n    __shared__ int sLargestComponentSize;\n    for (int i = threadIdx.x; i < N; i += blockDim.x) {\n        sVisited[i] = false;\n    }\n    __syncthreads();\n    int localLargestComponentSize = 0;\n    for (int i = threadIdx.x; i < N; i += blockDim.x) {\n        if (sVisited[i]) continue;\n        int localSize = 0;\n        localSize += DFS(sGraph, i, sVisited);\n        localLargestComponentSize = max(localLargestComponentSize, localSize);\n    }\n    atomicAdd(largestComponentSize, localLargestComponentSize);\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\tint size = 0;\n\tint maxSize = 0;\n\tint x = 0;\n\tint y = 0;\n\n\tif (i < N && j < N) {\n\t\tfor (int x = 0; x < N; x++) {\n\t\t\tif (A[x * N + i] == 1) {\n\t\t\t\tsize++;\n\t\t\t\tfor (int y = x + 1; y < N; y++) {\n\t\t\t\t\tif (A[y * N + i] == 1) {\n\t\t\t\t\t\tsize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (size > maxSize) {\n\t\t\t\t\tmaxSize = size;\n\t\t\t\t\t// printf(\"New max: %d\\n\", maxSize);\n\t\t\t\t}\n\t\t\t\tsize = 0;\n\t\t\t}\n\t\t}\n\t\t// printf(\"Max size: %d\\n\", maxSize);\n\t\t*largestComponentSize = maxSize;\n\t}\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n  int numThreads = blockDim.x * gridDim.x;\n  int *component = (int *)malloc(N * sizeof(int));\n  int *visited = (int *)malloc(N * sizeof(int));\n  for (int i = 0; i < N; i++) {\n    component[i] = i;\n    visited[i] = 0;\n  }\n\n  while (id < N * N) {\n    int a = id / N;\n    int b = id % N;\n    if (A[a * N + b] == 1 && a!= b) {\n      int componentA = find(component, a, visited);\n      int componentB = find(component, b, visited);\n      if (componentA!= componentB) {\n        component[componentA] = componentB;\n      }\n    }\n    id += numThreads;\n  }\n\n  int largestComponentId = 0;\n  int largestComponentSizeValue = 0;\n  for (int i = 1; i < N; i++) {\n    if (component[i] == i) {\n      if (largestComponentSizeValue < 1) {\n        largestComponentSizeValue = 1;\n        largestComponentId = i;\n      }\n    } else if (component[i] == largestComponentId) {\n      largestComponentSizeValue++;\n    }\n  }\n\n  if (largestComponentSizeValue < 1) {\n    *largestComponentSize = 1;\n  } else {\n    *largestComponentSize = largestComponentSizeValue;\n  }\n\n  free(component);\n  free(visited);\n}",
            "// TODO: Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n    // Hint: You will need to use a grid-stride loop in conjunction with atomic operations.\n    // Hint: Note that the grid-stride loop must iterate over all rows of A, not just the rows assigned to this thread.\n    __shared__ int componentSize[THREADS_PER_BLOCK];\n    __shared__ int visited[THREADS_PER_BLOCK];\n    __shared__ int minSize;\n    __shared__ int id;\n    __shared__ int total;\n\n    int globalID = blockIdx.x * blockDim.x + threadIdx.x;\n    if (globalID >= N)\n        return;\n\n    componentSize[threadIdx.x] = 0;\n    visited[threadIdx.x] = 0;\n    minSize = 0;\n    id = -1;\n    total = 0;\n    __syncthreads();\n\n    // First, count the number of vertices in the connected component that contains v\n    for (int row = 0; row < N; row++) {\n        if (A[row * N + globalID])\n            componentSize[threadIdx.x]++;\n    }\n    __syncthreads();\n\n    // Find the min size of the component\n    for (int i = 0; i < THREADS_PER_BLOCK; i++) {\n        if (i == 0)\n            minSize = componentSize[threadIdx.x];\n        else if (componentSize[i] < minSize) {\n            minSize = componentSize[i];\n            id = i;\n        }\n    }\n    __syncthreads();\n\n    // Assign each thread to a component to check\n    for (int i = 0; i < THREADS_PER_BLOCK; i++) {\n        if (i == id)\n            visited[threadIdx.x] = 1;\n        __syncthreads();\n\n        // Check if the current vertex has a connection to the component that we are checking\n        for (int row = 0; row < N; row++) {\n            if (A[row * N + globalID] && visited[row])\n                total++;\n        }\n        __syncthreads();\n    }\n    if (total == minSize)\n        atomicAdd(largestComponentSize, 1);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i = index / N;\n\tint j = index % N;\n\t// your code here\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= N) {\n    return;\n  }\n  __shared__ int component_size;\n  int comp_size = 0;\n  if (A[idx*N+idx] == 1) {\n    comp_size = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[idx*N+j] == 1) {\n        comp_size++;\n      }\n    }\n  }\n  // Reduce the results to one\n  atomicAdd(&component_size, comp_size);\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n    int j = blockDim.y * blockIdx.y + threadIdx.y;\n    extern __shared__ int cache[];\n    int cacheIndex = threadIdx.y * blockDim.x + threadIdx.x;\n    int componentSize = 0;\n    if (i < N && j < N) {\n        if (A[i * N + j] == 1) {\n            // If this node is already in the component, we don't need to do anything.\n            // Otherwise, we mark it as a part of the component and increment componentSize.\n            if (atomicOr(&cache[cacheIndex], 1) == 0) {\n                componentSize = 1;\n                // Mark this node as being in this component by setting the \n                // corresponding bit in the bitmask (i * N + j) in bitmask.\n                bitmask[i * N + j] = 1;\n                // Mark all the neighbors of this node as being in this component\n                // by setting the corresponding bit in the bitmask.\n                // Recursively visit neighbors and mark them as being in this component.\n                if (j + 1 < N && bitmask[i * N + j + 1] == 0) {\n                    markComponent(A, N, i, j + 1, componentSize);\n                }\n                if (j - 1 >= 0 && bitmask[i * N + j - 1] == 0) {\n                    markComponent(A, N, i, j - 1, componentSize);\n                }\n                if (i + 1 < N && bitmask[i * N + j] == 0) {\n                    markComponent(A, N, i + 1, j, componentSize);\n                }\n                if (i - 1 >= 0 && bitmask[i * N + j] == 0) {\n                    markComponent(A, N, i - 1, j, componentSize);\n                }\n            }\n        }\n    }\n    // Atomically increment the size of the component.\n    atomicAdd(largestComponentSize, componentSize);\n}",
            "}",
            "int row = threadIdx.y + blockIdx.y * blockDim.y;\n    int col = threadIdx.x + blockIdx.x * blockDim.x;\n\n    if (row >= N || col >= N)\n        return;\n\n    if (A[row * N + col] == 1 && (row!= col)) {\n        int rowSize = 0;\n        for (int i = 0; i < N; i++)\n            rowSize += A[row * N + i];\n        if (rowSize > *largestComponentSize)\n            *largestComponentSize = rowSize;\n    }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (index < N) {\n\t\tint temp = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[i * N + index] || A[index * N + i])\n\t\t\t\ttemp++;\n\t\t}\n\t\tatomicMax(largestComponentSize, temp);\n\t}\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    int size = 0;\n    int visited[N];\n    int i, j;\n\n    if(row < N && col < N) {\n        if(A[row * N + col] == 1) {\n            for(i = 0; i < N; i++) {\n                visited[i] = 0;\n            }\n\n            i = row;\n            size++;\n            visited[i] = 1;\n            while(size < N) {\n                for(j = 0; j < N; j++) {\n                    if(A[i * N + j] == 1 && visited[j] == 0) {\n                        size++;\n                        visited[j] = 1;\n                        i = j;\n                        break;\n                    }\n                }\n            }\n\n            atomicMin(largestComponentSize, size);\n        }\n    }\n}",
            "// TODO\n\n  __syncthreads();\n\n  // TODO\n\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tif (A[i*N + j] == 1) {\n\t\tint count = 0;\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[i*N + k] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(largestComponentSize, count);\n\t}\n}",
            "unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N) {\n\t\treturn;\n\t}\n\n\tbool marked[N];\n\tmemset(marked, false, N);\n\n\tint largestSize = 0;\n\n\tbool hasCycle = false;\n\n\tfor (int j = 0; j < N; j++) {\n\t\tif (hasCycle || marked[j]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tint currentSize = 0;\n\t\tint currentVertex = j;\n\t\tmarked[j] = true;\n\t\twhile (!hasCycle) {\n\t\t\tcurrentSize++;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (A[currentVertex * N + k] == 1 &&!marked[k]) {\n\t\t\t\t\tcurrentSize++;\n\t\t\t\t\tmarked[k] = true;\n\t\t\t\t\tcurrentVertex = k;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (currentVertex == j) {\n\t\t\t\tif (currentSize > largestSize) {\n\t\t\t\t\tlargestSize = currentSize;\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (largestSize > *largestComponentSize) {\n\t\t*largestComponentSize = largestSize;\n\t}\n}",
            "// Create a variable to store the largest component size\n    int * componentSize;\n\n    // Create a shared memory array to store the visited nodes in each thread block\n    __shared__ int shared_visited[THREAD_BLOCK_SIZE];\n\n    // Set component size to 1\n    *componentSize = 1;\n\n    // Get the index of the current thread\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // Create a variable to store the current node\n    int node = index;\n\n    // If the current thread is part of the largest component\n    if(A[node * N + node] == 1) {\n        // Mark the current node as visited\n        shared_visited[threadIdx.x] = 1;\n\n        // Loop through all the nodes in the adjacency matrix\n        for(int i = 0; i < N; i++) {\n            // If the current node is not visited and there is an edge between the current node and the node i\n            if(shared_visited[threadIdx.x] == 0 && A[node * N + i] == 1) {\n                // Mark the node i as visited\n                shared_visited[threadIdx.x] = 1;\n\n                // Increment component size\n                *componentSize += 1;\n            }\n        }\n    }\n\n    // Make sure that all the threads in the current block are done with computing their component size\n    __syncthreads();\n\n    // Create a variable to store the largest component size in the current block\n    int max_component_size;\n\n    // Find the maximum component size in the current block\n    max_component_size = *(max_element(shared_visited, shared_visited + THREAD_BLOCK_SIZE));\n\n    // Make sure that all the threads in the current block are done with computing the maximum component size\n    __syncthreads();\n\n    // If the current thread is part of the largest component\n    if(*componentSize == max_component_size) {\n        // Write the maximum component size to the global memory\n        *largestComponentSize = *componentSize;\n    }\n}",
            "int *isVisited = (int *) malloc(N * sizeof(int));\n    int *parent = (int *) malloc(N * sizeof(int));\n    for (size_t i = 0; i < N; i++) {\n        isVisited[i] = 0;\n        parent[i] = -1;\n    }\n\n    int id = threadIdx.x + blockIdx.x * blockDim.x;\n\n    if (id < N) {\n        if (A[id * N + id] == 1) {\n            isVisited[id] = 1;\n            parent[id] = id;\n            for (size_t i = 0; i < N; i++) {\n                if (i == id || A[id * N + i]!= 1) {\n                    continue;\n                }\n                if (isVisited[i] == 0) {\n                    isVisited[i] = 1;\n                    parent[i] = id;\n                }\n                while (parent[i]!= -1) {\n                    parent[i] = parent[parent[i]];\n                }\n                if (parent[i] == id) {\n                    isVisited[i] = 1;\n                    parent[i] = id;\n                }\n            }\n        }\n    }\n\n    __syncthreads();\n\n    int maxSize = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (isVisited[i]) {\n            maxSize++;\n        }\n    }\n    *largestComponentSize = maxSize;\n\n    free(isVisited);\n    free(parent);\n}",
            "// TODO: Fill this in\n}",
            "int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n    if (threadId >= N) return;\n    int *componentSize = new int[N];\n    for (int i = 0; i < N; i++) {\n        componentSize[i] = 0;\n    }\n    componentSize[threadId] = 1;\n    int i, j;\n    for (i = 0; i < N; i++) {\n        for (j = 0; j < N; j++) {\n            if (A[i * N + j] == 1 && componentSize[i] > 0) {\n                componentSize[j] = componentSize[i];\n            }\n        }\n    }\n    for (i = 0; i < N; i++) {\n        *largestComponentSize = max(componentSize[i], *largestComponentSize);\n    }\n}",
            "const int col = blockIdx.x;\n    const int row = blockIdx.y;\n\n    extern __shared__ int shared[];\n\n    // If this thread is the first thread in this block, read from global memory\n    // and store in shared memory\n    if (row == 0) {\n        shared[threadIdx.x] = A[col * N + threadIdx.x];\n    }\n\n    __syncthreads();\n\n    // If this thread is in a valid position in the adjacency matrix\n    if (row < N && col < N) {\n\n        // Mark the visited matrix\n        __shared__ int visited[MAX_THREADS_PER_BLOCK];\n        if (threadIdx.x == 0) {\n            visited[row] = 1;\n        }\n        __syncthreads();\n\n        // Determine if this cell is in the largest component\n        int maxSize = 0;\n        for (int i = 0; i < N; i++) {\n            // Check if the row is not marked as visited\n            if (visited[i] == 0) {\n                // If adjacent, increment the max size\n                if (shared[i] == 1) {\n                    maxSize++;\n                }\n            }\n        }\n\n        // Store the max size in global memory\n        if (threadIdx.x == 0) {\n            atomicMax(largestComponentSize, maxSize);\n        }\n    }\n}",
            "int row = blockIdx.x;\n\tint col = threadIdx.x;\n\n\t// TODO: replace this with your code\n\tint compSize = 1;\n\n\t// Set the value of the global variable\n\t*largestComponentSize = compSize;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) return;\n  __shared__ int visited[N];\n  for (int j = 0; j < N; j++) {\n    visited[j] = 0;\n  }\n  int count = 0;\n  count = dfs(A, N, i, visited, count);\n  if (count > *largestComponentSize) {\n    *largestComponentSize = count;\n  }\n}",
            "const int row = threadIdx.x + blockDim.x * blockIdx.x;\n\tconst int col = threadIdx.y + blockDim.y * blockIdx.y;\n\tif (row < N && col < N) {\n\t\tint val = A[row * N + col];\n\t\tif (row == col) {\n\t\t\t// diagonal values are the number of vertices in the component\n\t\t\t*largestComponentSize = val;\n\t\t}\n\t\tif (val!= 0 && row!= col) {\n\t\t\t// If a value is not 0, then it is an edge\n\t\t\tatomicMin(&A[col * N + row], 1);\n\t\t\tatomicMin(&A[row * N + col], 1);\n\t\t}\n\t}\n}",
            "// Replace this code with your solution\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n    if (id >= N) return;\n    bool visited[N];\n    memset(visited, 0, N * sizeof(bool));\n    visited[id] = true;\n    int componentSize = 1;\n    int tempSize;\n    for (int i = 0; i < N; i++) {\n        if (A[id * N + i] == 1 &&!visited[i]) {\n            tempSize = componentSize;\n            dfs(A, N, i, visited);\n            componentSize += tempSize;\n        }\n    }\n    atomicMax(largestComponentSize, componentSize);\n}",
            "// Write your code here\n}",
            "int i = threadIdx.x;\n  int j = threadIdx.y;\n  int N2 = N * N;\n  __shared__ int component[N2];\n  int count = 0;\n  int max = 0;\n\n  for (int offset = 0; offset < N2; offset += blockDim.x * blockDim.y) {\n    int i = offset + threadIdx.y * blockDim.x + threadIdx.x;\n    if (i < N2) {\n      component[i] = (A[i] > 0)? i : -1;\n    }\n  }\n\n  __syncthreads();\n\n  for (int offset = 0; offset < N2; offset += blockDim.x * blockDim.y) {\n    int i = offset + threadIdx.y * blockDim.x + threadIdx.x;\n    if (i < N2) {\n      int value = component[i];\n      if (value >= 0) {\n        int row = i / N;\n        int col = i % N;\n        int r_offset = (row + 1) * N - 1;\n        int c_offset = (col + 1) * N - 1;\n        for (int r = r_offset - 1; r >= 0; r -= N) {\n          for (int c = c_offset - 1; c >= 0; c -= N) {\n            int r_idx = row + (r - row) * N;\n            int c_idx = col + (c - col) * N;\n            if (A[r_idx * N + c_idx] && r_idx!= c_idx) {\n              value = -1;\n              break;\n            }\n          }\n          if (value == -1) break;\n        }\n\n        for (int r = r_offset + 1; r < N2; r += N) {\n          for (int c = c_offset + 1; c < N2; c += N) {\n            int r_idx = row + (r - row) * N;\n            int c_idx = col + (c - col) * N;\n            if (A[r_idx * N + c_idx] && r_idx!= c_idx) {\n              value = -1;\n              break;\n            }\n          }\n          if (value == -1) break;\n        }\n\n        for (int r = r_offset; r < N2; r += N) {\n          for (int c = c_offset; c < c_offset + (row - col); c += N) {\n            int r_idx = row + (r - row) * N;\n            int c_idx = col + (c - col) * N;\n            if (A[r_idx * N + c_idx] && r_idx!= c_idx) {\n              value = -1;\n              break;\n            }\n          }\n          if (value == -1) break;\n        }\n\n        for (int r = r_offset; r < r_offset + (col - row); r += N) {\n          for (int c = c_offset; c < c_offset + (row - col); c += N) {\n            int r_idx = row + (r - row) * N;\n            int c_idx = col + (c - col) * N;\n            if (A[r_idx * N + c_idx] && r_idx!= c_idx) {\n              value = -1;\n              break;\n            }\n          }\n          if (value == -1) break;\n        }\n      }\n      if (value >= 0) {\n        atomicAdd(&count, 1);\n        if (count > max) max = count;\n      }\n      component[i] = value;\n    }\n  }\n\n  if (blockIdx.x == 0 && blockIdx.y == 0 && threadIdx.x == 0 && threadIdx.y == 0) {\n    *largestComponentSize = max;\n  }\n}",
            "__shared__ int shared[256];\n\n    int row = threadIdx.x;\n    int col = blockIdx.x;\n    int num_vertices = blockDim.x;\n    int max_size = 0;\n    int idx = row * num_vertices + col;\n\n    // Fill in this function.\n    if (row == col) {\n        shared[row] = 1;\n    } else {\n        shared[row] = 0;\n    }\n    __syncthreads();\n    if (A[idx] == 1) {\n        shared[row] = 1;\n        shared[col] = 1;\n    }\n    __syncthreads();\n    for (int i = 0; i < num_vertices; ++i) {\n        if (i == col) continue;\n        if (shared[row] && shared[i]) {\n            shared[row] = 1;\n            shared[col] = 1;\n            shared[i] = 1;\n        }\n    }\n    __syncthreads();\n\n    if (shared[row])\n        max_size = max(max_size, shared[row]);\n\n    if (max_size > *largestComponentSize)\n        *largestComponentSize = max_size;\n}",
            "unsigned int index = threadIdx.x + blockDim.x * blockIdx.x;\n\t\n\tif (index < N) {\n\t\tint *component = (int *)malloc(N*sizeof(int));\n\t\tcomponent[0] = index;\n\t\tint size = 1;\n\t\tbool *visited = (bool *)calloc(N, sizeof(bool));\n\t\tvisited[index] = true;\n\t\twhile (size < N) {\n\t\t\tfor (int i = 0; i < size; ++i) {\n\t\t\t\tint current = component[i];\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[current*N + j] &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tcomponent[size] = j;\n\t\t\t\t\t\tsize += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t*largestComponentSize = size;\n\t}\n}",
            "//TODO: Your code here\n\tint i=blockIdx.y * blockDim.y + threadIdx.y;\n\tint j=blockIdx.x * blockDim.x + threadIdx.x;\n\t//printf(\"i: %d, j: %d\\n\",i,j);\n\tif (i < N && j < N) {\n\t\t//printf(\"%d\\n\", A[i*N + j]);\n\t\tint *ptr = (int*)malloc(N*sizeof(int));\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[i*N + k] == 1) {\n\t\t\t\tptr[k] = 1;\n\t\t\t}\n\t\t}\n\t\tint cnt = 0;\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (ptr[k] == 1) {\n\t\t\t\tfor (int kk = 0; kk < N; kk++) {\n\t\t\t\t\tif (ptr[kk] == 1) {\n\t\t\t\t\t\tcnt++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tptr[k] = 0;\n\t\t\t}\n\t\t}\n\t\tif (cnt > *largestComponentSize) {\n\t\t\t*largestComponentSize = cnt;\n\t\t}\n\t\t//printf(\"%d, \", cnt);\n\t\t//printf(\"%d, \", ptr[0]);\n\t}\n\t//printf(\"\\n\");\n}",
            "__shared__ int sccSize[N]; // array to store the size of each SCC\n  __shared__ int sccSizeFlag[N]; // array to indicate which SCC is the largest\n\n  // Calculate the id of the vertex\n  size_t i = blockIdx.y * blockDim.y + threadIdx.y;\n\n  // Initialize the size of each SCC to 0\n  if (threadIdx.y < N) {\n    sccSize[threadIdx.y] = 0;\n    sccSizeFlag[threadIdx.y] = 0;\n  }\n  __syncthreads();\n\n  // Calculate the size of the SCC containing the current vertex\n  for (size_t j = 0; j < N; ++j) {\n    // If the edge from vertex i to vertex j exists\n    if (A[i * N + j]!= 0) {\n      sccSize[i]++;\n      break;\n    }\n  }\n  __syncthreads();\n\n  // Calculate the size of the largest SCC\n  for (size_t j = 0; j < N; ++j) {\n    if (sccSize[j] > *largestComponentSize) {\n      *largestComponentSize = sccSize[j];\n      sccSizeFlag[j] = 1;\n    }\n  }\n  __syncthreads();\n\n  // If the current vertex is the largest SCC\n  if (sccSizeFlag[i] == 1) {\n    // Set the component size to the number of vertices in the largest SCC\n    *largestComponentSize = N;\n  }\n  __syncthreads();\n}",
            "}",
            "__shared__ int componentSize[GRID_SIZE];\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint max = -1;\n\tif (id < N) {\n\t\t// find largest component size for this row\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + id] == 1) {\n\t\t\t\tmax = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// determine the size of the largest component\n\tcomponentSize[threadIdx.x] = max == -1? 0 : 1;\n\t__syncthreads();\n\tfor (int s = 1; s < blockDim.x; s *= 2) {\n\t\tif (threadIdx.x % (2 * s) == 0) {\n\t\t\tif (componentSize[threadIdx.x + s] > componentSize[threadIdx.x]) {\n\t\t\t\tcomponentSize[threadIdx.x] = componentSize[threadIdx.x + s];\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = componentSize[0];\n\t}\n}",
            "int x = blockIdx.x;\n  int y = blockIdx.y;\n  __shared__ int visited[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ int largestComp;\n  int compCount = 0;\n\n  visited[threadIdx.x][threadIdx.y] = 0;\n  __syncthreads();\n\n  if (x == y && A[y*N+x] == 1) {\n    visited[threadIdx.x][threadIdx.y] = 1;\n    largestComp = 1;\n    compCount++;\n    for (int k = 0; k < N; k++) {\n      for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n          if (visited[i][j] == 1 && A[i*N+k] == 1 && A[k*N+j] == 1) {\n            visited[i][j] = 1;\n            compCount++;\n          }\n        }\n      }\n    }\n  }\n\n  if (compCount > largestComp) {\n    *largestComponentSize = compCount;\n  }\n}",
            "}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int componentSize[MAX_BLOCK_SIZE];\n\t__shared__ int componentMember[MAX_BLOCK_SIZE];\n\n\tint currentId = id;\n\tint currentComponentSize = 1;\n\tint componentId = A[id * N + id];\n\tcomponentSize[threadIdx.x] = 1;\n\tcomponentMember[threadIdx.x] = id;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[id * N + i]!= 0 && i!= id) {\n\t\t\tcomponentSize[threadIdx.x]++;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < blockDim.x; i++) {\n\t\tif (componentSize[i] > currentComponentSize) {\n\t\t\tcurrentComponentSize = componentSize[i];\n\t\t\tcurrentId = componentMember[i];\n\t\t\tcomponentId = A[currentId * N + currentId];\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint sum = 0;\n\tfor (int i = 0; i < blockDim.x; i++) {\n\t\tsum += componentSize[i];\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = sum;\n\t}\n\n\t//int threadId = threadIdx.x + blockIdx.x * blockDim.x;\n\t//int componentId = A[threadId * N + threadId];\n\t//int componentSize = 1;\n\t//for (int i = 0; i < N; i++) {\n\t//\tif (A[threadId * N + i]!= 0 && i!= threadId) {\n\t//\t\tcomponentSize++;\n\t//\t}\n\t//}\n\t//\n\t//if (threadIdx.x == 0) {\n\t//\t*largestComponentSize = componentSize;\n\t//}\n}",
            "// TODO: Implement this method\n\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint col = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (row >= N || col >= N) return;\n\n\tif (A[row * N + col] == 1) {\n\t\t*largestComponentSize = max(*largestComponentSize, floodFill(A, N, row, col));\n\t}\n}",
            "// 1. Compute the largest component size in parallel.\n\t// 2. Store the result in largestComponentSize.\n\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint i = tid;\n\tint max = 0;\n\n\tif (i < N) {\n\t\tint temp = 1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\ttemp = 0;\n\t\t\t}\n\t\t}\n\n\t\tif (temp!= 0)\n\t\t\tmax = max + 1;\n\t}\n\n\t__syncthreads();\n\n\tif (max > *largestComponentSize)\n\t\t*largestComponentSize = max;\n}",
            "}",
            "// Use grid stride loop to iterate through all components of the graph\n  // Use atomic add to keep track of largest component size\n  // Use atomic CAS to keep track of largest component index\n  int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  int index = 0;\n  int size = 0;\n  int largest = 0;\n\n  while (idx < N*N) {\n    if (A[idx] == 1) {\n      index = idx/N;\n      size = dfs(index, A, N);\n    }\n    idx += blockDim.x * gridDim.x;\n  }\n  // Use atomic add to keep track of largest component size\n  if (size > atomicAdd(largestComponentSize, 0)) {\n    atomicExch(largestComponentSize, size);\n  }\n}",
            "}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint result = 0;\n\tif (row == col && A[row * N + col] == 1) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[row * N + i] == 1)\n\t\t\t\tresult++;\n\t\t}\n\t}\n\n\tif (result > *largestComponentSize) {\n\t\t*largestComponentSize = result;\n\t}\n}",
            "// Declare the shared memory that is used for storing the number of reachable vertices\n  __shared__ int sharedReachable[THREADS_PER_BLOCK * THREADS_PER_BLOCK];\n\n  // Declare the shared memory that is used for storing the number of vertices in the largest component\n  __shared__ int sharedLargestComponentSize;\n\n  // Compute the global thread index\n  unsigned long globalThreadIdx = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // Compute the global thread index\n  unsigned long globalThreadIdy = threadIdx.y + blockIdx.y * blockDim.y;\n\n  // Compute the index of the corresponding element in the adjacency matrix A\n  unsigned long AIdx = globalThreadIdy * N + globalThreadIdx;\n\n  // Initialize the number of vertices in the largest component\n  sharedLargestComponentSize = 0;\n\n  // Initialize the number of reachable vertices\n  sharedReachable[threadIdx.x + threadIdx.y * blockDim.x] = 0;\n\n  // Make sure that the current thread is not out of bounds for the adjacency matrix\n  if (globalThreadIdx < N && globalThreadIdy < N) {\n\n    // Initialize the number of vertices in the largest component\n    sharedLargestComponentSize = 1;\n\n    // Initialize the number of reachable vertices\n    sharedReachable[threadIdx.x + threadIdx.y * blockDim.x] = 1;\n\n    // Define the number of reachable vertices for the current thread\n    int reachable = 1;\n\n    // Loop over the remaining vertices in the adjacency matrix A\n    for (unsigned long idx = AIdx + 1; idx < N * N; ++idx) {\n\n      // Compute the coordinates of the current element in the adjacency matrix A\n      unsigned long x = idx / N;\n      unsigned long y = idx % N;\n\n      // Check if the current element is adjacent to the current vertex\n      if (A[AIdx] == A[idx]) {\n\n        // Compute the index of the element in the shared memory\n        unsigned long sIdx = x + y * blockDim.x;\n\n        // Check if the vertex is reachable\n        if (sharedReachable[sIdx] == 0) {\n\n          // Mark the current vertex as reachable\n          reachable = 1;\n          sharedReachable[sIdx] = 1;\n        }\n      }\n    }\n\n    // Update the number of vertices in the largest component\n    atomicAdd(&sharedLargestComponentSize, reachable);\n  }\n\n  // Synchronize the threads\n  __syncthreads();\n\n  // Compute the index of the element in the shared memory\n  unsigned long sIdx = threadIdx.x + threadIdx.y * blockDim.x;\n\n  // Find the largest component size\n  unsigned long largestComponentSize = sharedReachable[sIdx];\n  for (unsigned long i = 1; i < blockDim.x * blockDim.y; ++i) {\n    if (sharedLargestComponentSize < sharedReachable[i]) {\n      largestComponentSize = sharedReachable[i];\n    }\n  }\n\n  // Store the largest component size\n  if (threadIdx.x + threadIdx.y * blockDim.x == 0) {\n    *largestComponentSize = largestComponentSize;\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\t\n\t// The main diagonal of the matrix is always one.\n\tif (i == j) {\n\t\tA[j * N + i] = 1;\n\t}\n\t\n\t// We cannot visit a vertex that is already visited.\n\tif (A[j * N + i] == 0) {\n\t\treturn;\n\t}\n\t\n\t// Traverse the adjacency matrix and update each vertex with the value of the largest component size it belongs to.\n\tif (A[j * N + i] == 1) {\n\t\tint count = 0;\n\t\t\n\t\t// A 2-D array of adjacency matrix is mapped to 1-D array of adjacency matrix.\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[j * N + k] == 1) {\n\t\t\t\tA[j * N + k] = count;\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Update the largest component size.\n\t\t*largestComponentSize = count;\n\t}\n}",
            "const int i = blockDim.x * blockIdx.x + threadIdx.x;\n    const int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n    __shared__ int componentSize[1024];\n    __shared__ int visited[1024];\n\n    if (i < N && j < N) {\n        if (A[j * N + i]) {\n            if (visited[j] == 0) {\n                visited[j] = 1;\n                componentSize[j] = 0;\n            }\n            if (visited[i] == 0) {\n                visited[i] = 1;\n                componentSize[i] = 0;\n            }\n\n            if (componentSize[i] < componentSize[j]) {\n                componentSize[i] = componentSize[i] + componentSize[j];\n            } else {\n                componentSize[j] = componentSize[i] + componentSize[j];\n            }\n        }\n    }\n\n    __syncthreads();\n\n    int max = 0;\n    for (int i = 0; i < N; i++) {\n        if (visited[i]) {\n            if (max < componentSize[i]) {\n                max = componentSize[i];\n            }\n        }\n    }\n\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        *largestComponentSize = max;\n    }\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    const int stride = blockDim.x * gridDim.x;\n    int scc[MAX_SCC];\n\n    for (int i = 0; i < MAX_SCC; i++) {\n        scc[i] = -1;\n    }\n\n    int v = tid;\n    if (v < N) {\n        for (int i = 0; i < N; i++) {\n            if (A[N * v + i]!= 0 && scc[i] == -1) {\n                scc[i] = 0;\n                DFS(A, N, i, scc);\n            }\n        }\n    }\n\n    __syncthreads();\n    atomicMax(largestComponentSize, scc[v]);\n}",
            "const int row = blockIdx.y*blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x*blockDim.x + threadIdx.x;\n\t__shared__ int rowData[BLOCK_SIZE][BLOCK_SIZE];\n\n\t// Copy the data to shared memory\n\tif (row < N && col < N) {\n\t\trowData[threadIdx.y][threadIdx.x] = A[row*N + col];\n\t}\n\n\t__syncthreads();\n\n\t// Do the computation\n\tif (row < N && col < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (rowData[row][i] > 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tif (count > *largestComponentSize) {\n\t\t\t*largestComponentSize = count;\n\t\t}\n\t}\n\n\t// Copy the data back to global memory\n\tif (row < N && col < N) {\n\t\tA[row*N + col] = rowData[threadIdx.y][threadIdx.x];\n\t}\n}",
            "__shared__ int sData[256];\n\n\t// get the row index of the element in A, which corresponds to the index of the thread in the NxN grid.\n\tint rIdx = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// if the thread index is larger than N, it doesn't need to execute the kernel.\n\tif (rIdx >= N) return;\n\n\t// get the column index of the element in A, which corresponds to the index of the thread in the NxN grid.\n\tint cIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// store the adjacent element's value\n\tint adjacentElement = A[rIdx * N + cIdx];\n\n\t// if the adjacent element is not zero, the value is 1\n\tint value = adjacentElement? 1 : 0;\n\n\t// the thread index in the NxN grid\n\tint tid = threadIdx.y * blockDim.x + threadIdx.x;\n\n\t// store the value in the shared memory\n\tsData[tid] = value;\n\n\t// synchronize the threads, so that every thread's value has been stored in the shared memory\n\t__syncthreads();\n\n\t// the number of threads in the NxN grid\n\tint numThreads = blockDim.x * blockDim.y;\n\n\t// if the number of threads is 1, the shared memory only contains one element,\n\t// return the value in the shared memory\n\tif (numThreads == 1) {\n\t\t*largestComponentSize = sData[0];\n\t\treturn;\n\t}\n\n\t// if the number of threads is 2, add the two elements in the shared memory\n\t// and store the result in the shared memory\n\tif (numThreads == 2) {\n\t\tsData[0] = sData[0] + sData[1];\n\t\treturn;\n\t}\n\n\t// if the number of threads is larger than 2, get the index of the first element in the shared memory\n\t// and add the first element with the second element\n\tint firstElement = sData[0];\n\n\tint secondElement = sData[1];\n\n\t// add the first element with the second element, and store the result in the first element\n\tsData[0] = firstElement + secondElement;\n\n\t// if the number of threads is not a power of 2, use the previous value in the shared memory to compute the result\n\t// and store the result in the first element\n\tfor (int stride = 1; stride < blockDim.x * blockDim.y; stride *= 2) {\n\t\t// if the thread index is odd, use the previous value in the shared memory to compute the result\n\t\t// and store the result in the first element\n\t\tif (threadIdx.y * blockDim.x + threadIdx.x > 0 && threadIdx.y * blockDim.x + threadIdx.x % (2 * stride) == stride)\n\t\t\tsData[0] = sData[0] + sData[threadIdx.y * blockDim.x + threadIdx.x - stride];\n\n\t\t// synchronize the threads\n\t\t__syncthreads();\n\t}\n\n\t// return the result\n\t*largestComponentSize = sData[0];\n}",
            "int componentSize = 1;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[threadIdx.x * N + i] == 1) {\n\t\t\tatomicAdd(&componentSize, 1);\n\t\t}\n\t}\n\n\t*largestComponentSize = componentSize;\n}",
            "// TODO: Add your code here\n}",
            "// get the index of the thread\n\tint index = blockIdx.x * blockDim.x + threadIdx.x;\n\t// check if the thread is not out of bounds\n\tif (index >= N)\n\t\treturn;\n\t\n\t// \n\t__shared__ int componentSizes[MAX_N];\n\t__shared__ int component[MAX_N];\n\t\n\tint count = 0;\n\t// iterate through the rows\n\tfor (int i = 0; i < N; i++) {\n\t\t// if the node is visited, continue\n\t\tif (component[i])\n\t\t\tcontinue;\n\t\t// if the node is not connected with other nodes, skip it\n\t\tif (A[i * N + index] == 0 && A[index * N + i] == 0)\n\t\t\tcontinue;\n\t\t// if the node is connected with other nodes\n\t\tcount++;\n\t\t// find the other nodes that are connected with it\n\t\tdfs(i, A, component, componentSizes);\n\t}\n\t// count the number of nodes in the largest component\n\tatomicAdd(largestComponentSize, count);\n}",
            "// TODO: Implement this function\n}",
            "__shared__ int isConnected[1024];\n  unsigned int tid = threadIdx.x + blockDim.x*blockIdx.x;\n  unsigned int bid = blockIdx.x;\n  if (tid < N && A[tid*N + bid] > 0) {\n    isConnected[threadIdx.x] = 1;\n  }\n  else {\n    isConnected[threadIdx.x] = 0;\n  }\n  __syncthreads();\n  unsigned int count = 0;\n  for (unsigned int i = 0; i < blockDim.x; i++) {\n    if (isConnected[i] > 0) {\n      count++;\n    }\n  }\n  if (count > *largestComponentSize) {\n    *largestComponentSize = count;\n  }\n}",
            "// TODO: Your code here\n\n\t\n\n}",
            "__shared__ int s_componentSize[MAX_N];\n    int myID = threadIdx.x + blockDim.x * blockIdx.x;\n\n    if (myID >= N) {\n        return;\n    }\n\n    // Initialize componentSize\n    s_componentSize[threadIdx.x] = 0;\n\n    __syncthreads();\n\n    if (A[myID*N + myID] > 0) {\n        int tempSize = 1;\n        int index = 0;\n        for (int i = 0; i < N; i++) {\n            if (myID!= i && A[myID*N + i] > 0) {\n                if (s_componentSize[index] > tempSize) {\n                    tempSize = s_componentSize[index];\n                }\n                index++;\n            }\n        }\n\n        if (index == 0) {\n            s_componentSize[threadIdx.x] = 1;\n        }\n        else {\n            s_componentSize[threadIdx.x] = tempSize + 1;\n        }\n    }\n\n    __syncthreads();\n\n    for (int stride = blockDim.x/2; stride > 0; stride >>= 1) {\n        if (threadIdx.x < stride) {\n            int temp = s_componentSize[threadIdx.x + stride];\n            if (s_componentSize[threadIdx.x] < temp) {\n                s_componentSize[threadIdx.x] = temp;\n            }\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n        atomicMax(largestComponentSize, s_componentSize[0]);\n    }\n}",
            "// your code here\n    __shared__ int visited[N];\n    __shared__ int level[N];\n    __shared__ int levelCount;\n\n    visited[threadIdx.x] = 0;\n    level[threadIdx.x] = 0;\n    levelCount = 0;\n    __syncthreads();\n\n    if(A[threadIdx.x * N + threadIdx.x] == 1){\n        visited[threadIdx.x] = 1;\n        level[threadIdx.x] = 1;\n        levelCount++;\n        __syncthreads();\n\n        for(int i = 0; i < N; i++){\n            if(i!= threadIdx.x && A[threadIdx.x * N + i] == 1){\n                visited[i] = 1;\n                level[i] = 1;\n                levelCount++;\n                __syncthreads();\n            }\n        }\n\n        if(levelCount == 1){\n            *largestComponentSize = 1;\n            return;\n        }\n    }\n\n    __syncthreads();\n    for(int i = 0; i < N; i++){\n        if(visited[i] == 1){\n            if(level[i] == 1){\n                int flag = 1;\n                for(int j = 0; j < N; j++){\n                    if(A[i * N + j] == 1 && level[j] == 0){\n                        level[j] = level[i] + 1;\n                        levelCount++;\n                        flag = 0;\n                        break;\n                    }\n                }\n                if(flag == 1){\n                    *largestComponentSize = *largestComponentSize + 1;\n                }\n            }\n            else if(level[i] > 1){\n                *largestComponentSize = *largestComponentSize + 1;\n            }\n        }\n    }\n}",
            "// Define and initialize a temporary array to store the depths of each vertex\n    int depth[N];\n    for(int i=0; i<N; i++) {\n        depth[i] = 0;\n    }\n    // Define and initialize a temporary array to store the parents of each vertex\n    int parent[N];\n    for(int i=0; i<N; i++) {\n        parent[i] = i;\n    }\n\n    // Get the thread index\n    int threadIdx = blockDim.x * blockIdx.x + threadIdx.x;\n\n    // Get the depth of the vertex at threadIdx\n    int depth_threadIdx = depth[threadIdx];\n\n    // Compute the index of the first vertex in the adjacency matrix row for threadIdx\n    int rowOffset = threadIdx * N;\n\n    // For each neighbor vertex j of the vertex at threadIdx\n    for(int j=0; j<N; j++) {\n        // Get the depth of the neighbor vertex j\n        int depth_j = depth[j];\n\n        // If the depth of j is greater than the depth of threadIdx, update threadIdx's parent to be j\n        if(depth_j > depth_threadIdx) {\n            parent[threadIdx] = j;\n        }\n\n        // If the depth of j is equal to the depth of threadIdx and j is not threadIdx's parent, combine threadIdx and j\n        if(depth_j == depth_threadIdx && j!= parent[threadIdx]) {\n            parent[threadIdx] = parent[j];\n        }\n    }\n\n    // Get the parent of threadIdx\n    int parent_threadIdx = parent[threadIdx];\n\n    // Update the depth of threadIdx to be 1 + the depth of its parent\n    depth[threadIdx] = 1 + depth[parent_threadIdx];\n\n    // Synchronize the threads before updating the depth of all vertices\n    __syncthreads();\n\n    // For each vertex k of the graph\n    for(int k=0; k<N; k++) {\n        // Get the depth of k\n        int depth_k = depth[k];\n\n        // If the depth of k is greater than the depth of threadIdx, update threadIdx's parent to be k\n        if(depth_k > depth_threadIdx) {\n            parent[threadIdx] = k;\n        }\n\n        // If the depth of k is equal to the depth of threadIdx and k is not threadIdx's parent, combine threadIdx and k\n        if(depth_k == depth_threadIdx && k!= parent[threadIdx]) {\n            parent[threadIdx] = parent[k];\n        }\n    }\n\n    // Synchronize the threads before updating the depth of all vertices\n    __syncthreads();\n\n    // Get the parent of threadIdx\n    int parent_threadIdx = parent[threadIdx];\n\n    // Update the depth of threadIdx to be 1 + the depth of its parent\n    depth[threadIdx] = 1 + depth[parent_threadIdx];\n\n    // Synchronize the threads before updating the depth of all vertices\n    __syncthreads();\n\n    // Compute the number of vertices in the largest component by finding the maximum depth of any vertex in the graph\n    int largestComponent = 0;\n    for(int k=0; k<N; k++) {\n        int depth_k = depth[k];\n        if(depth_k > largestComponent) {\n            largestComponent = depth_k;\n        }\n    }\n\n    // Update the output memory with the number of vertices in the largest component\n    *largestComponentSize = largestComponent;\n}",
            "int tId = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tint i = 0;\n\tint j = 0;\n\n\t__shared__ int sharedArray[BLOCKSIZE];\n\n\tint max = 0;\n\tif (tId < N * N) {\n\t\ti = tId / N;\n\t\tj = tId % N;\n\t}\n\n\tfor (int k = 0; k < N; k++) {\n\t\tif (i == k && A[tId] > 0) {\n\t\t\tsharedArray[threadIdx.x] = 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (j == k && A[tId] > 0) {\n\t\t\tsharedArray[threadIdx.x] = 1;\n\t\t\tbreak;\n\t\t}\n\t\tsharedArray[threadIdx.x] = 0;\n\t}\n\n\t__syncthreads();\n\n\tint sum = 0;\n\tfor (int k = 0; k < BLOCKSIZE; k++) {\n\t\tsum += sharedArray[k];\n\t}\n\n\tif (tId == 0) {\n\t\tatomicAdd(largestComponentSize, sum);\n\t}\n}",
            "int largest_component_size = 0;\n\n  // TODO: Compute the number of vertices in the largest component of the graph\n  // stored in the adjacency matrix A.\n  // You can use the following variables:\n  //    N: the size of the graph\n  //    A: the adjacency matrix stored in row-major\n\n  __syncthreads();\n\n  // Use atomicMax to get the largest component size\n  atomicMax(largestComponentSize, largest_component_size);\n}",
            "// YOUR CODE HERE\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n\tint col = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (row >= N || col >= N)\n\t\treturn;\n\n\tif (A[row * N + col] == 1) {\n\t\t*largestComponentSize = max(*largestComponentSize, 1);\n\t}\n}",
            "// TODO\n}",
            "const int ID = blockIdx.y*blockDim.x + threadIdx.x;\n  const int DIM = gridDim.y*blockDim.x;\n\n  if (ID >= N) return;\n\n  // Create a bitmap to store the components of the current graph\n  int *visited = (int*)malloc(sizeof(int) * N);\n  for (int i = 0; i < N; ++i) {\n    visited[i] = 0;\n  }\n\n  int size = 0;\n  // DFS\n  dfs(A, N, ID, visited);\n\n  for (int i = 0; i < N; ++i) {\n    size += visited[i];\n  }\n\n  // Atomic add to ensure that multiple threads do not overwrite\n  atomicAdd(largestComponentSize, size);\n}",
            "const int row = blockIdx.y;\n  const int col = blockIdx.x;\n  if (row == col) {\n    largestComponentSize[0] = 0;\n    for (int i = 0; i < N; ++i) {\n      if (A[row * N + i] > 0) {\n        largestComponentSize[0]++;\n      }\n    }\n  }\n}",
            "int row = blockIdx.x;\n    int col = blockIdx.y;\n\n    // if (row == col)\n    // {\n    //     *largestComponentSize = 1;\n    //     return;\n    // }\n\n    if (A[row * N + col] == 1)\n    {\n        *largestComponentSize = 1;\n    }\n    __syncthreads();\n}",
            "/*... */\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\n\tint max = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i * N + j] > max)\n\t\t\t\tmax = A[i * N + j];\n\t\t}\n\t}\n\t*largestComponentSize = max;\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n  int componentSize = 1;\n  if (col < N) {\n    for (int i = 0; i < N; i++) {\n      if (row == i) continue;\n      if (A[row * N + i] == 1) {\n        atomicAdd(largestComponentSize, 1);\n        return;\n      }\n    }\n  }\n  *largestComponentSize = componentSize;\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x;\n    int y = blockDim.y * blockIdx.y + threadIdx.y;\n\n    if (x < N && y < N) {\n        if (A[x * N + y] > 0) {\n            // TODO\n        }\n    }\n}",
            "const int myCol = threadIdx.x;\n  const int myRow = blockIdx.x;\n\n  __shared__ int componentSize[THREADS_PER_BLOCK];\n  __shared__ bool isConnectedToComponent[THREADS_PER_BLOCK];\n\n  // Initialization\n  if (myCol == 0) {\n    componentSize[myRow] = 0;\n    isConnectedToComponent[myRow] = false;\n  }\n\n  __syncthreads();\n\n  int localComponentSize = 0;\n  int row = myRow;\n  int col = myCol;\n\n  // BFS\n  while (!isConnectedToComponent[myRow] && col < N) {\n    if (A[row * N + col] == 1) {\n      isConnectedToComponent[myRow] = true;\n      localComponentSize++;\n    }\n\n    col++;\n  }\n\n  __syncthreads();\n\n  // Atomic add the size of each thread's component\n  atomicAdd(&componentSize[myCol], localComponentSize);\n\n  __syncthreads();\n\n  // Find the largest component size\n  if (myCol == 0) {\n    int maxComponentSize = 0;\n\n    for (int i = 0; i < THREADS_PER_BLOCK; i++) {\n      if (componentSize[i] > maxComponentSize) {\n        maxComponentSize = componentSize[i];\n      }\n    }\n\n    largestComponentSize[0] = maxComponentSize;\n  }\n}",
            "__shared__ int s_component[MAX_SIZE];\n\n  // Each thread handles one row in the adjacency matrix\n  int row = blockIdx.x;\n\n  // Initialize the thread's component\n  s_component[threadIdx.x] = 0;\n\n  // Iterate through the elements of the row\n  for (int i = 0; i < N; i++) {\n    // If A[row][i] == 1, then we know that the vertex at row is reachable from vertex i\n    if (A[row * N + i] == 1) {\n      // Find the maximum component size among the neighbors\n      s_component[threadIdx.x] =\n          max(s_component[threadIdx.x],\n              s_component[min(i, threadIdx.x)]);\n    }\n  }\n\n  // Wait for all threads to finish\n  __syncthreads();\n\n  // Find the largest component size of all threads\n  int maxComponent = 0;\n  for (int i = 0; i < blockDim.x; i++) {\n    maxComponent = max(maxComponent, s_component[i]);\n  }\n\n  // Each thread stores the maximum component size\n  if (threadIdx.x == 0) {\n    *largestComponentSize = maxComponent + 1;\n  }\n}",
            "/* Insert your code here */\n\n}",
            "// This is just an example implementation. You should think carefully\n    // about how you would parallelize this problem and modify this code accordingly.\n\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x < N && y < N && A[x + y * N] == 1) {\n        atomicAdd(largestComponentSize, 1);\n    }\n\n    __syncthreads();\n}",
            "// Define shared memory as a boolean array of size N.\n    // Each thread has access to this array.\n    __shared__ bool visited[N];\n    __shared__ int result;\n\n    if (blockIdx.x == 0 && threadIdx.x == 0) {\n        result = 0;\n        memset(visited, 0, N * sizeof(bool));\n    }\n    __syncthreads();\n\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row >= N) {\n        return;\n    }\n\n    if (visited[row] == 0) {\n        int counter = 0;\n        dfs(A, row, visited, N, &counter);\n        atomicAdd(largestComponentSize, counter);\n    }\n}",
            "}",
            "int n_threads = gridDim.x * blockDim.x;\n    int thread_id = blockDim.x * blockIdx.x + threadIdx.x;\n    int size = 0;\n\n    // If not in the last row, then skip over it\n    if (thread_id < N * N - N) {\n        if (A[thread_id]) {\n            size++;\n        }\n        thread_id += n_threads;\n    }\n\n    for (; thread_id < N * N; thread_id += n_threads) {\n        if (A[thread_id]) {\n            size++;\n        }\n    }\n\n    atomicMax(largestComponentSize, size);\n}",
            "// TODO: Your code here\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tsize_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\t__shared__ int largest[BLOCK_SIZE][BLOCK_SIZE];\n\tif (i < N && j < N) {\n\t\tlargest[threadIdx.y][threadIdx.x] = A[i * N + j];\n\t}\n\t__syncthreads();\n\tfor (int k = 0; k < N; k += BLOCK_SIZE) {\n\t\tif (i + k < N && j + k < N) {\n\t\t\tlargest[threadIdx.y][threadIdx.x] = max(largest[threadIdx.y][threadIdx.x], largest[threadIdx.y][threadIdx.x] + largest[threadIdx.y][k]);\n\t\t}\n\t}\n\t__syncthreads();\n\tif (i == 0 && j == 0) {\n\t\t*largestComponentSize = largest[threadIdx.y][threadIdx.x];\n\t}\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n  int j = blockDim.y * blockIdx.y + threadIdx.y;\n  int component = i == 0;\n  int size = 0;\n  if (i < N && j < N) {\n    if (A[i * N + j]) {\n      component = j == 0;\n      size = 1;\n      for (int k = j; k < N; k++) {\n        if (A[i * N + k]) {\n          size++;\n        } else {\n          break;\n        }\n      }\n    }\n  }\n  atomicMax(largestComponentSize, size);\n}",
            "// Your code here\n\n}",
            "// TODO: compute the size of the largest component in the adjacency matrix A\n\t// Hint: use atomicAdd()\n\n    // set largestComponentSize to 1 (in case no edges exist)\n    *largestComponentSize = 1;\n\n    int componentSize = 0;\n    int vertexIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // if the current vertex is an edge (there exists at least one edge going from it)\n    if(A[vertexIdx]!= 0) {\n        // traverse the graph starting at the current vertex\n        dfs(A, vertexIdx, N, &componentSize);\n\n        // check if the current component is larger than any previously found components\n        atomicMax(largestComponentSize, componentSize);\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\t// TODO\n}",
            "// Declare shared memory array of size N\n    __shared__ int isVisited[N];\n    __shared__ int sizeOfComponent[N];\n\n    int myId = threadIdx.x;\n    int mySize = 0;\n    int largestComponent = 0;\n\n    // Initializing the shared memory arrays\n    if (myId < N) {\n        isVisited[myId] = 0;\n        sizeOfComponent[myId] = 0;\n    }\n\n    __syncthreads();\n\n    // Traverse the adjacency matrix\n    for (int i = 0; i < N; i++) {\n        if (A[myId * N + i] > 0) {\n            mySize++;\n            if (myId > i) {\n                largestComponent++;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    if (myId < N) {\n        atomicAdd(&sizeOfComponent[myId], mySize);\n        atomicAdd(&largestComponent, largestComponent);\n    }\n\n    __syncthreads();\n\n    // Find the maximum size of the component\n    int maxSize = sizeOfComponent[0];\n    for (int i = 1; i < N; i++) {\n        if (sizeOfComponent[i] > maxSize) {\n            maxSize = sizeOfComponent[i];\n        }\n    }\n\n    __syncthreads();\n\n    if (myId < N && sizeOfComponent[myId] == maxSize) {\n        isVisited[myId] = 1;\n    }\n\n    __syncthreads();\n\n    largestComponent = 0;\n    for (int i = 0; i < N; i++) {\n        if (isVisited[i] == 1) {\n            largestComponent++;\n        }\n    }\n\n    __syncthreads();\n\n    // Copy the result to the output\n    if (myId == 0) {\n        *largestComponentSize = largestComponent;\n    }\n}",
            "__shared__ int s[BLOCKSIZE][BLOCKSIZE];\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int i = ty + BLOCKSIZE * by;\n    int j = tx + BLOCKSIZE * bx;\n\n    if (i < N && j < N) {\n        s[ty][tx] = A[i * N + j];\n    }\n    __syncthreads();\n    if (i < N && j < N && i < j && s[ty][tx] == 1 && s[ty][j] == 1 && s[j][ty] == 1) {\n        for (int k = 0; k < N; k++) {\n            if (s[ty][k] == 1 && s[k][tx] == 1 && s[ty][k] == 1 && s[k][j] == 1 && s[j][k] == 1 && s[k][tx] == 1) {\n                atomicAdd(largestComponentSize, 1);\n            }\n        }\n    }\n}",
            "__shared__ bool component[256];\n    __shared__ int largest;\n    int id = threadIdx.x + blockIdx.x * blockDim.x;\n    if (threadIdx.x == 0) {\n        largest = 0;\n    }\n    __syncthreads();\n    int num = 0;\n    if (id < N) {\n        if (A[id * N + id]!= 0) {\n            num++;\n            component[id] = true;\n        } else {\n            component[id] = false;\n        }\n    }\n    __syncthreads();\n    for (int i = 0; i < N; i++) {\n        int offset = i * N;\n        if (id < N && component[i] && A[offset + id]!= 0) {\n            component[id] = true;\n        }\n    }\n    __syncthreads();\n    if (id < N) {\n        if (component[id]) {\n            atomicMax(&largest, num);\n        }\n    }\n    __syncthreads();\n    if (id == 0) {\n        *largestComponentSize = largest;\n    }\n}",
            "int rowId = blockIdx.y * blockDim.y + threadIdx.y;\n  int colId = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (rowId == colId && A[rowId*N + colId]!= 0) {\n    *largestComponentSize = *largestComponentSize + 1;\n  }\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n    int col = blockDim.y * blockIdx.y + threadIdx.y;\n\n    __shared__ int s[256][256];\n\n    if (row < N && col < N) {\n        s[threadIdx.x][threadIdx.y] = A[row * N + col];\n    }\n    __syncthreads();\n\n    if (row < N && col < N) {\n        if (s[threadIdx.y][threadIdx.x] == 1) {\n            s[threadIdx.x][threadIdx.y] = 1;\n        } else {\n            s[threadIdx.x][threadIdx.y] = 0;\n        }\n    }\n    __syncthreads();\n\n    if (row < N && col < N) {\n        A[row * N + col] = s[threadIdx.x][threadIdx.y];\n    }\n    __syncthreads();\n\n    if (row == 0 && col == 0) {\n        int cnt = 0;\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    cnt++;\n                }\n            }\n        }\n        *largestComponentSize = cnt;\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i >= N || j >= N)\n        return;\n\n    __shared__ int sdata[blockSize];\n    if (A[i*N + j] == 1)\n        atomicAdd(sdata, 1);\n    __syncthreads();\n\n    if (threadIdx.x == 0)\n        atomicAdd(largestComponentSize, sdata[threadIdx.y]);\n}",
            "int row = blockIdx.x;\n\tint col = blockIdx.y;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\n\t__shared__ int s_a[BLOCK_SIZE][BLOCK_SIZE];\n\t__shared__ int s_b[BLOCK_SIZE][BLOCK_SIZE];\n\n\ts_a[ty][tx] = A[row * N + col];\n\ts_b[ty][tx] = A[col * N + row];\n\n\t__syncthreads();\n\n\t// compute the max component size\n\tfor (int k = 1; k <= ty; k++) {\n\t\tif (s_a[ty][tx] < s_a[k][tx]) {\n\t\t\ts_a[ty][tx] = s_a[k][tx];\n\t\t}\n\t}\n\n\tfor (int k = 1; k <= ty; k++) {\n\t\tif (s_b[ty][tx] < s_b[k][tx]) {\n\t\t\ts_b[ty][tx] = s_b[k][tx];\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t// write back to global memory\n\tif (row == col) {\n\t\tatomicAdd(largestComponentSize, s_a[ty][tx]);\n\t}\n}",
            "int largestComponentSizePerBlock = 0;\n  for (int i = blockIdx.x; i < N; i += gridDim.x) {\n    int componentSize = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        componentSize++;\n      }\n    }\n    largestComponentSizePerBlock = max(largestComponentSizePerBlock, componentSize);\n  }\n  atomicMax(largestComponentSize, largestComponentSizePerBlock);\n}",
            "//TODO: Write your kernel code here\n\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif(row < N && col < N && A[row * N + col]!= 0) {\n\t\tatomicMin(largestComponentSize, N);\n\t}\n}",
            "// TODO: add implementation\n}",
            "__shared__ bool visited[MAX_SIZE];\n    __shared__ int comp[MAX_SIZE];\n\n    // Initialize the visited array\n    if (threadIdx.x < MAX_SIZE)\n        visited[threadIdx.x] = false;\n    __syncthreads();\n\n    // BFS to find the largest component\n    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if (idx < N) {\n        if (!visited[idx]) {\n            int size = 0;\n            int frontier = idx;\n            comp[idx] = idx;\n            visited[idx] = true;\n            while (frontier!= -1) {\n                int neighbors[MAX_SIZE];\n                int neighborsCount = 0;\n\n                // Find all the unvisited neighbors of frontier\n                for (int j = 0; j < N; j++) {\n                    if (A[frontier * N + j] &&!visited[j]) {\n                        visited[j] = true;\n                        comp[j] = idx;\n                        neighbors[neighborsCount++] = j;\n                    }\n                }\n\n                // Move to next level\n                frontier = -1;\n                if (neighborsCount > 0) {\n                    frontier = neighbors[size % neighborsCount];\n                    size++;\n                }\n            }\n\n            if (size > *largestComponentSize)\n                *largestComponentSize = size;\n        }\n    }\n}",
            "}",
            "// TODO: YOUR CODE HERE\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n  int j = blockIdx.y*blockDim.y + threadIdx.y;\n\n  if(i < N && j < N) {\n    if(A[i*N + j] == 1) {\n      atomicMin(largestComponentSize, N-1);\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    int componentSize = 0;\n    if (i >= N || j >= N) {\n        return;\n    }\n\n    // find connected component size of vertex i\n    if (A[i*N + j]) {\n        componentSize++;\n        if (i!= j) {\n            int i_row = i*N;\n            for (int k = 0; k < N; k++) {\n                componentSize += A[i_row + k];\n            }\n        }\n    }\n\n    atomicMax(largestComponentSize, componentSize);\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint count = 0;\n\n\t// We can skip the first row since it can't have any vertices in its component.\n\tif (blockIdx.x > 0) {\n\t\t// We can skip the first column since it can't have any vertices in its component.\n\t\tfor (int j = threadIdx.x + 1; j < N; j += blockDim.x) {\n\t\t\tif (A[tid * N + j]!= 0)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\t// Write the result to shared memory\n\t__shared__ int sharedMemory[32];\n\tint s = 32;\n\tfor (int i = 0; i < 32; i += s) {\n\t\ts = s >> 1;\n\t\tif (i + s < 32 && i + s <= blockDim.x)\n\t\t\tsharedMemory[i] += sharedMemory[i + s];\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = sharedMemory[0];\n\t}\n}",
            "// get global index\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// local index\n\tint j = threadIdx.y;\n\n\t// temporary variable\n\tint tmp = 0;\n\n\tif (i < N) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i + j * N] == 1) {\n\t\t\t\ttmp = 1;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(largestComponentSize, tmp);\n\t}\n}",
            "const int i = threadIdx.x + blockIdx.x * blockDim.x;\n    const int j = threadIdx.y + blockIdx.y * blockDim.y;\n    int local_component_size = 0;\n\n    if (i < N && j < N) {\n        if (A[i * N + j]) {\n            local_component_size = 1;\n            // bfs(A, i, j, N, &local_component_size);\n        }\n    }\n\n    atomicMax(largestComponentSize, local_component_size);\n}",
            "int row = blockIdx.x;\n    int col = threadIdx.x;\n    __shared__ int blockLargestComponentSize[BLOCK_DIM][BLOCK_DIM];\n\n    if (row < N && col < N) {\n        if (A[row * N + col] == 1) {\n            if (blockLargestComponentSize[row][col] < 1)\n                blockLargestComponentSize[row][col] = 1;\n\n            __syncthreads();\n\n            for (int i = 0; i < BLOCK_DIM; i++) {\n                blockLargestComponentSize[row][col] = max(blockLargestComponentSize[row][col], blockLargestComponentSize[row][i]);\n                blockLargestComponentSize[row][col] = max(blockLargestComponentSize[row][col], blockLargestComponentSize[i][col]);\n            }\n\n            __syncthreads();\n\n            if (blockLargestComponentSize[row][col] == 1) {\n                for (int i = 0; i < BLOCK_DIM; i++) {\n                    blockLargestComponentSize[row][col] = max(blockLargestComponentSize[row][col], blockLargestComponentSize[i][col]);\n                    blockLargestComponentSize[row][col] = max(blockLargestComponentSize[row][col], blockLargestComponentSize[row][i]);\n                }\n            }\n\n            __syncthreads();\n        }\n    }\n\n    if (row == 0 && col == 0) {\n        *largestComponentSize = 0;\n        for (int i = 0; i < BLOCK_DIM; i++) {\n            *largestComponentSize = max(*largestComponentSize, blockLargestComponentSize[i][0]);\n        }\n    }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\tif (i < N && j < N)\n\t{\n\t\tif (A[i * N + j]!= 0)\n\t\t{\n\t\t\tatomicMax(largestComponentSize, 0);\n\t\t}\n\t}\n}",
            "// TODO: implement\n\t// use the CUDA grid and block indices to identify the current thread.\n\t// for example, if there are 4x4 blocks and 8x8 threads per block, then\n\t// blockIdx.x and blockIdx.y range from 0 to 3 and threadIdx.x and threadIdx.y range\n\t// from 0 to 7.\n\t//\n\t// The current thread is then at (blockIdx.x * blockDim.x) + threadIdx.x\n\t// and (blockIdx.y * blockDim.y) + threadIdx.y\n}",
            "// Thread index in the grid.\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Shared memory to store the number of vertices in the largest connected component.\n  __shared__ int componentSize;\n\n  // The size of a connected component is equal to the size of the largest component that is connected to it.\n  // Therefore, each thread can determine the size of a connected component using the adjacency matrix.\n  // Thread 0 in the grid is responsible for finding the largest connected component size.\n  if (index == 0) {\n    // Initialize the size of the largest connected component to 0.\n    componentSize = 0;\n\n    // Iterate through the adjacency matrix to find the size of the largest component.\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          componentSize = max(componentSize, 1);\n        }\n      }\n    }\n    *largestComponentSize = componentSize;\n  }\n}",
            "// TODO: Your code goes here\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\t// TODO: Fill in this function.\n\n}",
            "int x = blockIdx.x;\n  int y = blockIdx.y;\n  int id = x + N * y;\n\n  if (id >= N) {\n    return;\n  }\n\n  if (A[id] == 1) {\n    atomicMin(largestComponentSize, N - 1);\n  }\n}",
            "const int j = threadIdx.x;\n\tconst int i = blockIdx.x;\n\t__shared__ int shared[THREADS_PER_BLOCK];\n\tint value = 0;\n\tif(i < N && j < N) {\n\t\tvalue = A[i*N+j];\n\t}\n\tshared[threadIdx.x] = value;\n\t__syncthreads();\n\tif(threadIdx.x == 0) {\n\t\tint acc = 0;\n\t\tfor(int i = 0; i < THREADS_PER_BLOCK; i++) {\n\t\t\tacc += shared[i];\n\t\t}\n\t\tatomicAdd(largestComponentSize, acc);\n\t}\n}",
            "int *visited = new int[N];\n\tfor(int i = 0; i < N; i++)\n\t\tvisited[i] = 0;\n\tint size = 0;\n\n\tint x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint current = x*N + y;\n\n\tif(A[current] == 1)\n\t{\n\t\tif(visited[current] == 0)\n\t\t{\n\t\t\tvisited[current] = 1;\n\t\t\tsize++;\n\n\t\t\tif(x > 0)\n\t\t\t{\n\t\t\t\tint newx = x - 1;\n\t\t\t\tint newy = y;\n\t\t\t\tint newnode = newx*N + newy;\n\t\t\t\tif(A[newnode] == 1)\n\t\t\t\t{\n\t\t\t\t\tif(visited[newnode] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[newnode] = 1;\n\t\t\t\t\t\tsize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif(x < N - 1)\n\t\t\t{\n\t\t\t\tint newx = x + 1;\n\t\t\t\tint newy = y;\n\t\t\t\tint newnode = newx*N + newy;\n\t\t\t\tif(A[newnode] == 1)\n\t\t\t\t{\n\t\t\t\t\tif(visited[newnode] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[newnode] = 1;\n\t\t\t\t\t\tsize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif(y > 0)\n\t\t\t{\n\t\t\t\tint newx = x;\n\t\t\t\tint newy = y - 1;\n\t\t\t\tint newnode = newx*N + newy;\n\t\t\t\tif(A[newnode] == 1)\n\t\t\t\t{\n\t\t\t\t\tif(visited[newnode] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[newnode] = 1;\n\t\t\t\t\t\tsize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif(y < N - 1)\n\t\t\t{\n\t\t\t\tint newx = x;\n\t\t\t\tint newy = y + 1;\n\t\t\t\tint newnode = newx*N + newy;\n\t\t\t\tif(A[newnode] == 1)\n\t\t\t\t{\n\t\t\t\t\tif(visited[newnode] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[newnode] = 1;\n\t\t\t\t\t\tsize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif(size > *largestComponentSize)\n\t{\n\t\t*largestComponentSize = size;\n\t}\n\n\tdelete[] visited;\n}",
            "const size_t tid = threadIdx.x + blockIdx.x*blockDim.x;\n    const size_t row = tid / N;\n    const size_t col = tid % N;\n\n    if (row >= N || col >= N) return;\n    __shared__ int componentSize[N][N];\n    __shared__ int visited[N][N];\n    componentSize[row][col] = 0;\n    visited[row][col] = 0;\n    __syncthreads();\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1 && visited[i][j] == 0) {\n                bfs(i, j, A, N, componentSize, visited);\n            }\n        }\n    }\n\n    __syncthreads();\n    int maxSize = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (componentSize[i][j] > maxSize) {\n                maxSize = componentSize[i][j];\n            }\n        }\n    }\n    atomicMax(largestComponentSize, maxSize);\n}",
            "int row = blockDim.y * blockIdx.y + threadIdx.y;\n  int col = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if(row<N && col<N && row!=col)\n  {\n\t  if(A[row*N+col]>0)\n\t  {\n\t\t  atomicAdd(largestComponentSize,1);\n\t  }\n  }\n}",
            "__shared__ int shared[blockDim.x];\n\t__shared__ int count[1];\n\t__shared__ int visited[blockDim.x];\n\n\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint idy = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t//int visited[N];\n\t//int count = 0;\n\t//int largestComponentSize = 0;\n\tint largestComponentSize = 0;\n\n\tint i, j, flag = 1;\n\twhile (flag) {\n\t\tif (idx >= N) {\n\t\t\tflag = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tif (idy >= N) {\n\t\t\tflag = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (A[idx * N + idy] == 1) {\n\t\t\t//atomicAdd(visited[idx], 1);\n\t\t\tif (visited[idx] == 0) {\n\t\t\t\tvisited[idx] = 1;\n\t\t\t\tatomicAdd(count, 1);\n\t\t\t\tfor (i = 0; i < N; i++) {\n\t\t\t\t\tif (A[idx * N + i] == 1 && visited[i] == 0) {\n\t\t\t\t\t\tshared[threadIdx.x] = i;\n\t\t\t\t\t\t__syncthreads();\n\t\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\t\tatomicAdd(count, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(largestComponentSize, count[0]);\n}",
            "const int i = threadIdx.x + blockIdx.x * blockDim.x;\n\tconst int j = threadIdx.y + blockIdx.y * blockDim.y;\n\tint count = 0;\n\n\t// If i!= j, i!= 0, j!= 0, and A(i,j) == 1, increment count\n\n\tif ((i!= j) && (i!= 0) && (j!= 0) && (A[i*N+j] == 1))\n\t\tatomicAdd(largestComponentSize, 1);\n}",
            "int tx = blockIdx.x;\n    int ty = blockIdx.y;\n    int bx = blockDim.x;\n    int by = blockDim.y;\n\n    int id = ty * bx + tx;\n    if (id >= N) return;\n\n    // Initialize the array to false\n    int *visited = (int *)malloc(N * sizeof(int));\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n    // Start with vertex 0\n    int s = 0;\n    int next = 0;\n    int count = 0;\n\n    if (id == 0) {\n        visited[s] = 1;\n        count++;\n\n        while (next < N) {\n            if (visited[next] == 0) {\n                visited[next] = 1;\n                count++;\n            }\n            next = A[s * N + next];\n            s = next;\n        }\n    }\n\n    // Perform a reduction to find the size of the largest connected component\n    __shared__ int s_visited[32];\n    s_visited[threadIdx.x] = count;\n    __syncthreads();\n\n    for (unsigned int stride = 16; stride > 0; stride >>= 1) {\n        if (threadIdx.x < stride) {\n            s_visited[threadIdx.x] += s_visited[threadIdx.x + stride];\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n        atomicAdd(largestComponentSize, s_visited[0]);\n    }\n}",
            "int i = blockIdx.x;\n  int j = threadIdx.x;\n\n  __shared__ int adjacency[16][16];\n  __shared__ int component[16][16];\n\n  int id = i * blockDim.x + j;\n  if (i < N && j < N) {\n    adjacency[i][j] = A[id];\n  }\n  __syncthreads();\n\n  for (int k = 0; k < N; ++k) {\n    if (i == k || j == k) {\n      continue;\n    }\n    if (adjacency[i][k] == 1 && adjacency[j][k] == 1) {\n      if (component[i][j] == 0) {\n        component[i][j] = 1;\n      }\n      component[j][i] = 1;\n    }\n  }\n  __syncthreads();\n\n  for (int k = 0; k < N; ++k) {\n    if (component[i][k] == 1) {\n      component[i][j] = 1;\n    }\n    if (component[j][k] == 1) {\n      component[i][j] = 1;\n    }\n  }\n  __syncthreads();\n\n  if (i == j && component[i][j] == 1) {\n    atomicAdd(largestComponentSize, 1);\n  }\n}",
            "unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if (i < N && j < N) {\n    *largestComponentSize = max(*largestComponentSize, A[i*N+j]);\n  }\n}",
            "int index = blockIdx.x*blockDim.x + threadIdx.x;\n\n    if(index < N){\n        int myValue = A[index*N+index];\n        int left = -1;\n        int right = -1;\n        int up = -1;\n        int down = -1;\n\n        if (index-1 >= 0 && index-1 < N)\n            left = A[index*N + index-1];\n        if (index+1 >= 0 && index+1 < N)\n            right = A[index*N + index+1];\n        if (index-N >= 0 && index-N < N)\n            up = A[index*N + index-N];\n        if (index+N >= 0 && index+N < N)\n            down = A[index*N + index+N];\n\n        if(left == myValue || right == myValue || up == myValue || down == myValue){\n            atomicAdd(largestComponentSize, 1);\n        }\n    }\n}",
            "// TODO\n}",
            "int index = threadIdx.x;\n\n    /* YOUR CODE HERE */\n    // Find the maximum component size of the graph\n    int max_component_size = 0;\n    int max_component_index = 0;\n    for (int i = 0; i < N; i++) {\n        int component_size = 0;\n        if (A[i * N + index] == 1) {\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    component_size++;\n                }\n            }\n        }\n        if (component_size > max_component_size) {\n            max_component_size = component_size;\n            max_component_index = index;\n        }\n    }\n\n    // Update the output\n    if (index == 0) {\n        *largestComponentSize = max_component_size;\n    }\n}",
            "int x = blockIdx.x;\n    int y = blockIdx.y;\n    __shared__ int isConnected;\n    if (A[x * N + y] == 1) {\n        isConnected = 1;\n    } else {\n        isConnected = 0;\n    }\n    __syncthreads();\n\n    if (x == y) {\n        // If x == y, then we have a self loop.\n        isConnected = 1;\n    }\n\n    __syncthreads();\n    if (isConnected == 1) {\n        // If two vertices are connected, then all of the vertices in the two connected components can be \n        // represented by a single vertex x.\n        *largestComponentSize = 1;\n    }\n}",
            "// TODO: implement this. You may need to allocate shared memory if needed\n\t// see: http://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared-memory\n\n\t__shared__ int isVisited[32];\n\n\tint tid = threadIdx.x;\n\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = 0;\n\t\tfor (int i = 0; i < 32; i++) {\n\t\t\tisVisited[i] = 0;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint index = (blockIdx.x * blockDim.x + threadIdx.x) * blockDim.x + threadIdx.x;\n\n\tif (index < N * N) {\n\t\tint row = index / N;\n\t\tint col = index % N;\n\n\t\tif (row < N && col < N) {\n\t\t\tif (A[index] == 1 && isVisited[col] == 0) {\n\t\t\t\tisVisited[col] = 1;\n\t\t\t\t*largestComponentSize += 1;\n\t\t\t\tdfs(A, col, isVisited, row, *largestComponentSize, N);\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (tid == 0) {\n\t\tfor (int i = 0; i < 32; i++) {\n\t\t\tif (isVisited[i]!= 0)\n\t\t\t\t*largestComponentSize += 1;\n\t\t}\n\t}\n\n}",
            "int i, j;\n  int mySize = 0;\n  int componentSize = 0;\n  int maxSize = 0;\n  int *visited = (int *) malloc(N*sizeof(int));\n\n  for (i = 0; i < N; ++i) {\n    visited[i] = 0;\n  }\n\n  for (i = 0; i < N; ++i) {\n    for (j = 0; j < N; ++j) {\n      if (A[i*N + j] > 0) {\n        if (visited[i] == 0) {\n          componentSize = 0;\n          dfs(A, i, j, visited, &componentSize);\n          if (componentSize > maxSize) {\n            maxSize = componentSize;\n          }\n        }\n      }\n    }\n  }\n  *largestComponentSize = maxSize;\n}",
            "// TODO\n\tint index = threadIdx.x + blockDim.x * blockIdx.x;\n\tint row = index / N;\n\tint column = index % N;\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row * N + i] && A[column * N + i]) {\n\t\t\tsum++;\n\t\t}\n\t}\n\tif (sum == N - 1) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif(i >= N || j >= N || i == j || A[i*N + j] == 0) return;\n\n\tint lcs;\n\tint lc = 1;\n\n\tfor(int k = 0; k < N; k++) {\n\t\tif(A[i*N + k] && A[j*N + k])\n\t\t\tlc++;\n\t}\n\n\tatomicMax(&lcs, lc);\n\n\t*largestComponentSize = lcs;\n}",
            "//TODO: Implement this\n}",
            "__shared__ bool mark[BLOCK_SIZE][BLOCK_SIZE];\n\n    // Initialize the array to false\n    for (size_t i = 0; i < BLOCK_SIZE; i++) {\n        mark[threadIdx.x][i] = false;\n    }\n\n    __syncthreads();\n\n    // Initialize the array to false\n    for (size_t i = 0; i < BLOCK_SIZE; i++) {\n        mark[threadIdx.y][i] = false;\n    }\n\n    __syncthreads();\n\n    // If the corresponding element in A is 1\n    if (A[blockIdx.x * N + blockIdx.y] == 1) {\n        // Mark the elements in the matrix\n        for (size_t i = 0; i < BLOCK_SIZE; i++) {\n            mark[threadIdx.x][i] = true;\n        }\n\n        for (size_t i = 0; i < BLOCK_SIZE; i++) {\n            mark[i][threadIdx.y] = true;\n        }\n    }\n\n    __syncthreads();\n\n    // Iterate through the matrix and count the number of ones\n    int cnt = 0;\n\n    for (size_t i = 0; i < BLOCK_SIZE; i++) {\n        cnt += mark[threadIdx.x][i];\n    }\n\n    __syncthreads();\n\n    for (size_t i = 0; i < BLOCK_SIZE; i++) {\n        cnt += mark[i][threadIdx.y];\n    }\n\n    __syncthreads();\n\n    // Write the result to global memory\n    if (blockIdx.x == 0 && blockIdx.y == 0) {\n        *largestComponentSize = cnt;\n    }\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// If the thread is outside the bounds of A, return early.\n\tif (row >= N || col >= N) {\n\t\treturn;\n\t}\n\n\tint myComponent = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\t// We need to make sure we don't double count by only incrementing if we don't already belong to a component.\n\t\tif (A[row * N + i] && myComponent == 0) {\n\t\t\tmyComponent++;\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\t// We need to make sure we don't double count by only incrementing if we don't already belong to a component.\n\t\t\tif (A[i * N + j] && myComponent == 0) {\n\t\t\t\tmyComponent++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(largestComponentSize, myComponent);\n\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = id / N;\n  int col = id % N;\n  if (row >= N || col >= N) {\n    return;\n  }\n  // set all visited[i] to false\n  if (row == 0 && col == 0) {\n    for (int i = 0; i < N; ++i) {\n      visited[i] = false;\n    }\n  }\n  __syncthreads();\n  if (A[row * N + col] == 1 &&!visited[row] &&!visited[col]) {\n    if (row > col) {\n      visited[row] = true;\n      visited[col] = true;\n      int size = 2;\n      for (int i = 0; i < N; ++i) {\n        if (A[row * N + i] == 1 &&!visited[i]) {\n          visited[i] = true;\n          size += 1;\n        }\n      }\n      if (size > *largestComponentSize) {\n        *largestComponentSize = size;\n      }\n    } else {\n      visited[col] = true;\n      visited[row] = true;\n      int size = 2;\n      for (int i = 0; i < N; ++i) {\n        if (A[col * N + i] == 1 &&!visited[i]) {\n          visited[i] = true;\n          size += 1;\n        }\n      }\n      if (size > *largestComponentSize) {\n        *largestComponentSize = size;\n      }\n    }\n  }\n  __syncthreads();\n}",
            "// Store the number of vertices in the largest component\n\tint numberOfVertices = 0;\n\n\t// Get the index of the thread in the grid\n\tconst size_t index = (size_t) blockIdx.x * blockDim.x + threadIdx.x;\n\t\n\t// If the thread is in the valid range\n\tif (index < N) {\n\n\t\t// Store the number of vertices in the largest component\n\t\tnumberOfVertices = 1;\n\n\t\t// Define the starting index\n\t\tint startingIndex = index * N;\n\n\t\t// Define the ending index\n\t\tint endingIndex = startingIndex + N;\n\n\t\t// For each vertex that is adjacent to the current vertex\n\t\tfor (int j = startingIndex; j < endingIndex; j++) {\n\n\t\t\t// If the vertex is not adjacent to the current vertex\n\t\t\tif (A[j] == 0) {\n\n\t\t\t\t// Then increment the number of vertices in the largest component\n\t\t\t\tnumberOfVertices++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set the value of the largest component size to the largest number of vertices\n\tif (numberOfVertices > *largestComponentSize) {\n\n\t\t// Set the value of the largest component size\n\t\t*largestComponentSize = numberOfVertices;\n\t}\n}",
            "// Compute the index of the thread in the grid (i,j)\n\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\t// The kernel should not be run on any thread not in the valid range.\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\t// If i and j are connected\n\tif (A[i + j * N]!= 0) {\n\n\t\t// If i is connected to j\n\t\tif (A[i * N + j]!= 0) {\n\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t}\n\n\t\t// If j is connected to i\n\t\tif (A[j * N + i]!= 0) {\n\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t}\n\n\t}\n\n}",
            "const int row = blockIdx.y * blockDim.y + threadIdx.y;\n    const int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    extern __shared__ int s[];\n    if(row < N && col < N) s[threadIdx.y * blockDim.x + threadIdx.x] = 0;\n    __syncthreads();\n\n    for(int i = row; i < N; i += blockDim.y * gridDim.y) {\n        for(int j = col; j < N; j += blockDim.x * gridDim.x) {\n            if(i == j) continue;\n            if(A[i * N + j] == 1) {\n                s[threadIdx.y * blockDim.x + threadIdx.x] = 1;\n                break;\n            }\n        }\n    }\n    __syncthreads();\n\n    for(int i = 1; i < blockDim.x * blockDim.y; i *= 2) {\n        if(threadIdx.y * blockDim.x + threadIdx.x < i) continue;\n        s[threadIdx.y * blockDim.x + threadIdx.x] += s[threadIdx.y * blockDim.x + threadIdx.x - i];\n        __syncthreads();\n    }\n\n    int maxSize = 0;\n    if(threadIdx.y * blockDim.x + threadIdx.x == 0) {\n        for(int i = 0; i < blockDim.x * blockDim.y; i++) {\n            maxSize = max(maxSize, s[i]);\n        }\n        atomicAdd(largestComponentSize, maxSize);\n    }\n}",
            "__shared__ int s_comp[32];\n  int bid = blockIdx.x + blockIdx.y * gridDim.x;\n  int tid = threadIdx.x;\n\n  if (bid >= N) return;\n\n  s_comp[tid] = 0;\n  __syncthreads();\n\n  int componentSize = 0;\n  int startNode = bid;\n  int currNode = bid;\n  while (currNode!= -1) {\n    componentSize++;\n    for (int i = 0; i < N; i++) {\n      if (A[currNode * N + i] && i!= currNode) {\n        currNode = i;\n        break;\n      }\n    }\n    currNode = -1;\n  }\n  atomicAdd(s_comp + tid, componentSize);\n  __syncthreads();\n\n  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (tid < s) {\n      s_comp[tid] += s_comp[tid + s];\n    }\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    atomicMax(largestComponentSize, s_comp[0]);\n  }\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N && j < N) {\n    __shared__ bool matrix[BLOCK_SIZE][BLOCK_SIZE];\n    matrix[threadIdx.y][threadIdx.x] = A[i * N + j];\n    __syncthreads();\n    if (i == j) {\n      bool isLargest = true;\n      for (int k = 0; k < N; ++k) {\n        if (matrix[i][k] && matrix[k][j]) {\n          isLargest = false;\n          break;\n        }\n      }\n      if (isLargest) {\n        atomicAdd(largestComponentSize, 1);\n      }\n    }\n  }\n}",
            "const int i = blockDim.x * blockIdx.x + threadIdx.x;\n  const int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n  extern __shared__ int temp[];\n  int *visited = temp;\n\n  if (i < N && j < N && A[i * N + j]) {\n    int cnt = 0;\n    int q[N];\n    int p = 0;\n    int qsize = 0;\n    q[qsize++] = i;\n    visited[i] = 1;\n    while (qsize > 0) {\n      int v = q[p++];\n      if (v < N &&!visited[v]) {\n        visited[v] = 1;\n        q[qsize++] = v + 1;\n        q[qsize++] = v - 1;\n        for (int w = 0; w < N; w++) {\n          if (A[v * N + w]) {\n            q[qsize++] = w;\n            break;\n          }\n        }\n      }\n      cnt++;\n    }\n    atomicMax(largestComponentSize, cnt);\n  }\n}",
            "// Use blockIdx.x and blockIdx.y to index into the grid.\n\t// Use threadIdx.x and threadIdx.y to index into the thread within the block.\n\t// Use blockDim.x and blockDim.y to get the size of the block.\n\t\n\t// Compute the index into A.\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint index = j*N + i;\n\t\n\t// Check if (i, j) is a valid index of A.\n\tif (i >= N || j >= N) {\n\t\treturn;\n\t}\n\t\n\t// Check if (i, j) is part of the largest component.\n\tif (A[index] == 1) {\n\t\tatomicAdd(largestComponentSize, 1);\n\t}\n}",
            "*largestComponentSize = -1;\n\n    __shared__ int visited[THREADS_PER_BLOCK][THREADS_PER_BLOCK];\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index >= N) return;\n    visited[threadIdx.x][threadIdx.y] = 0;\n\n    __syncthreads();\n    int count = 0;\n    if (visited[threadIdx.x][threadIdx.y] == 0 && A[index*N + index]!= 0) {\n        visited[threadIdx.x][threadIdx.y] = 1;\n        count++;\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (visited[threadIdx.x][threadIdx.y] == 0) {\n            if (i == index) continue;\n            if (A[index * N + i]!= 0) {\n                visited[threadIdx.x][threadIdx.y] = 1;\n                count++;\n            }\n        }\n    }\n\n    __syncthreads();\n    if (count > *largestComponentSize) {\n        *largestComponentSize = count;\n    }\n}",
            "// TODO\n  // Use a thread-local variable to record the number of vertices in the largest component, as well as the current\n  // largest component size.\n  // Find the largest component size in the grid.\n  // Atomic add the largest component size to the result.\n\n}",
            "// TODO: Compute the number of vertices in the largest component of the graph defined by the adjacency matrix A\n\n    // TODO: Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n    // TODO: Store the result in largestComponentSize\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\t__shared__ int sA[THREADS_PER_BLOCK][THREADS_PER_BLOCK];\n\t__shared__ int sTot[THREADS_PER_BLOCK][THREADS_PER_BLOCK];\n\t\n\t// each thread is a possible node in the graph\n\tif (i < N && j < N) {\n\t\t// each thread stores the value of A(i,j) in shared memory\n\t\tsA[threadIdx.y][threadIdx.x] = A[i * N + j];\n\t\tsTot[threadIdx.y][threadIdx.x] = 0;\n\t\t\n\t\t// synchronize\n\t\t__syncthreads();\n\t\t\n\t\t// each thread looks at every node it could connect to (it's own row)\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (sA[threadIdx.y][threadIdx.x] == 1 && sA[threadIdx.y][k] == 1) {\n\t\t\t\tsTot[threadIdx.y][threadIdx.x]++;\n\t\t\t}\n\t\t\t// synchronize\n\t\t\t__syncthreads();\n\t\t}\n\t\t\n\t\t// each thread computes the largest component size by looking at the column it belongs to\n\t\t// and finding the maximum value of the column\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (sTot[threadIdx.y][threadIdx.x] < sTot[threadIdx.y][k]) {\n\t\t\t\tsTot[threadIdx.y][threadIdx.x] = sTot[threadIdx.y][k];\n\t\t\t}\n\t\t\t// synchronize\n\t\t\t__syncthreads();\n\t\t}\n\t\t\n\t\t// each thread stores its maximum component size value in shared memory\n\t\tsA[threadIdx.y][threadIdx.x] = sTot[threadIdx.y][threadIdx.x];\n\t\t\n\t\t// synchronize\n\t\t__syncthreads();\n\t\t\n\t\t// each thread finds the maximum value of the row and stores it in global memory\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (sA[threadIdx.y][threadIdx.x] < sA[k][threadIdx.x]) {\n\t\t\t\tsA[threadIdx.y][threadIdx.x] = sA[k][threadIdx.x];\n\t\t\t}\n\t\t\t// synchronize\n\t\t\t__syncthreads();\n\t\t}\n\t\t\n\t\t// each thread takes its maximum component size value and stores it in global memory\n\t\t// largestComponentSize[i] = sA[threadIdx.y][threadIdx.x];\n\t\tif (threadIdx.x == 0) {\n\t\t\tatomicAdd(largestComponentSize, sA[threadIdx.y][threadIdx.x]);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i >= N) return;\n\n    int cmp_size = 0;\n    int vertex = i;\n    while (true) {\n        cmp_size++;\n        int next = A[vertex * N + vertex];\n        if (next == -1)\n            break;\n        vertex = next;\n    }\n\n    if (cmp_size > *largestComponentSize) {\n        atomicMax(largestComponentSize, cmp_size);\n    }\n}",
            "__shared__ int componentSizes[MAX_N];\n\t__shared__ int maxComponentSize;\n\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myComponentSize = 0;\n\n\t// If I am not the root node of a component, return\n\tif (A[id * N + id] == 0) {\n\t\treturn;\n\t}\n\n\t// Mark node as visited\n\tA[id * N + id] = 0;\n\n\t// Count nodes in component\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[id * N + i] > 0) {\n\t\t\tmyComponentSize++;\n\t\t}\n\t}\n\n\t// If component size is larger than others, update shared memory\n\tif (myComponentSize > maxComponentSize) {\n\t\tmaxComponentSize = myComponentSize;\n\t\tcomponentSizes[threadIdx.x] = myComponentSize;\n\t}\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tint max = componentSizes[0];\n\n\t\t// Find largest component size from shared memory\n\t\tfor (int i = 1; i < blockDim.x; ++i) {\n\t\t\tif (componentSizes[i] > max) {\n\t\t\t\tmax = componentSizes[i];\n\t\t\t}\n\t\t}\n\n\t\t// Store largest component size in global memory\n\t\t*largestComponentSize = max;\n\t}\n}",
            "__shared__ int visited[N];\n    __shared__ int comp[N];\n\n    int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    int bid = blockIdx.x;\n    visited[tid] = 0;\n    comp[tid] = 0;\n\n    __syncthreads();\n\n    if (tid == bid) {\n        visited[bid] = 1;\n        comp[bid] = 1;\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (A[tid * N + i] == 1 &&!visited[i]) {\n            visited[i] = 1;\n            comp[i] = comp[bid] + 1;\n        }\n    }\n\n    __syncthreads();\n\n    if (comp[tid] == 0) {\n        visited[tid] = 0;\n        comp[tid] = 0;\n    }\n\n    __syncthreads();\n\n    for (int i = 0; i < N; i++) {\n        if (comp[i] > comp[tid] &&!visited[tid]) {\n            visited[tid] = 1;\n            comp[tid] = comp[i];\n        }\n    }\n\n    __syncthreads();\n\n    if (!visited[bid]) {\n        visited[bid] = 0;\n        comp[bid] = 0;\n    }\n\n    __syncthreads();\n\n    int maxComp = 0;\n    for (int i = 0; i < N; i++) {\n        if (comp[i] > maxComp) {\n            maxComp = comp[i];\n        }\n    }\n\n    __syncthreads();\n\n    *largestComponentSize = maxComp;\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n  __shared__ int sharedArray[1000];\n  __shared__ int visited[1000];\n  __shared__ int numConnected[1000];\n  __shared__ int isLeaf[1000];\n\n  int currentIndex = 0;\n  int isConnected = 0;\n  int parent = i;\n\n  if (i < N && j < N) {\n    int numNodes = N;\n    int index = i * N + j;\n\n    if (A[index] == 1) {\n      //if not visited, visit and add to queue\n      if (visited[i]!= 1) {\n        sharedArray[currentIndex] = i;\n        currentIndex++;\n        visited[i] = 1;\n        numConnected[i] = 1;\n        isLeaf[i] = 1;\n      }\n      //if visited, check if there is an edge between the current node and the parent node\n      else {\n        int current = sharedArray[0];\n        int numNodes = N;\n        int index = current * numNodes + parent;\n\n        if (A[index] == 1) {\n          numConnected[i] += numConnected[current];\n          if (isLeaf[current] == 1)\n            isLeaf[i] = 1;\n          else\n            isLeaf[i] = 0;\n        }\n        else {\n          //if not connected, add it to queue\n          sharedArray[currentIndex] = i;\n          currentIndex++;\n          visited[i] = 1;\n          numConnected[i] = 1;\n          isLeaf[i] = 1;\n        }\n\n        //if queue is empty, pop\n        if (currentIndex == 1) {\n          sharedArray[0] = sharedArray[1];\n          currentIndex--;\n        }\n        else if (currentIndex > 1) {\n          sharedArray[0] = sharedArray[1];\n          currentIndex--;\n        }\n      }\n    }\n  }\n\n  __syncthreads();\n\n  //find the largest component in the graph\n  if (isLeaf[i] == 1) {\n    if (numConnected[i] > *largestComponentSize)\n      *largestComponentSize = numConnected[i];\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id >= N) return;\n  int count = 0;\n  while (id < N) {\n    if (A[id])\n      ++count;\n    id += N;\n  }\n  *largestComponentSize = max(*largestComponentSize, count);\n}",
            "int i = threadIdx.y;\n\tint j = threadIdx.x;\n\tint largest = 0;\n\tint size = 0;\n\t__shared__ int adj[32][32];\n\n\tadj[i][j] = A[i*N+j];\n\t__syncthreads();\n\n\tif (i == j) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tsize += adj[i][k];\n\t\t}\n\t\tif (size > largest) {\n\t\t\tlargest = size;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (largest > *largestComponentSize) {\n\t\t*largestComponentSize = largest;\n\t}\n\n}",
            "// TODO: Insert your code here\n\n}",
            "int i = blockDim.x*blockIdx.x + threadIdx.x;\n    int j = blockDim.y*blockIdx.y + threadIdx.y;\n    if (i<N && j<N) {\n        atomicMax(largestComponentSize, A[i*N + j]);\n    }\n}",
            "// The index of the component the current thread is in\n    int componentIndex = 0;\n\n    // A binary array that indicates which rows of A are in the current component\n    // Note: This variable must be declared as \"volatile\" in order to guarantee thread-safety.\n    //       The kernel will not work properly otherwise.\n    __shared__ volatile int *component;\n\n    // If this is the first thread to run\n    if (threadIdx.x == 0) {\n\n        // Allocate space for the shared memory array\n        component = (int *) malloc(N * sizeof(int));\n\n        // Initialize the shared memory array to zero\n        for (int i = 0; i < N; i++) {\n            component[i] = 0;\n        }\n\n        // Mark the current thread as being in the first component\n        component[blockIdx.x] = 1;\n\n    }\n\n    // Wait until all threads in the grid have been created\n    __syncthreads();\n\n    // If this is not the first thread to run\n    if (threadIdx.x!= 0) {\n\n        // If the current row is not marked as being in the first component\n        if (component[blockIdx.x] == 0) {\n\n            // Traverse through all the rows of A\n            for (int i = 0; i < N; i++) {\n\n                // If the current row is connected to the row in the current component\n                if (A[blockIdx.x * N + i] == 1) {\n\n                    // Mark the current row as being in the current component\n                    component[blockIdx.x] = 1;\n\n                    // Break out of the loop since it is not necessary to search the rest of the rows in the current component\n                    break;\n                }\n            }\n        }\n    }\n\n    // Wait until all threads in the grid have finished executing the \"if\" block\n    __syncthreads();\n\n    // If this is not the first thread to run\n    if (threadIdx.x!= 0) {\n\n        // If the current row is marked as being in the first component\n        if (component[blockIdx.x] == 1) {\n\n            // Traverse through all the rows of A\n            for (int i = 0; i < N; i++) {\n\n                // If the current row is connected to the row in the current component\n                if (A[blockIdx.x * N + i] == 1) {\n\n                    // Mark the row as being in the current component\n                    component[i] = 1;\n\n                    // Increment the number of vertices in the current component\n                    atomicAdd(largestComponentSize, 1);\n                }\n            }\n        }\n    }\n}",
            "int i, j;\n\n\tint row = threadIdx.y;\n\tint col = threadIdx.x;\n\n\t__shared__ int myComponent;\n\t__shared__ int maxComponent;\n\t__shared__ int maxSize;\n\n\tmyComponent = 0;\n\tmaxComponent = 0;\n\tmaxSize = 0;\n\n\tfor(i = row; i < N; i+=blockDim.y) {\n\t\tfor(j = col; j < N; j+=blockDim.x) {\n\t\t\tif(A[i*N+j]!= 0) {\n\t\t\t\tmyComponent = 0;\n\t\t\t\tdfs(A, i, myComponent, N);\n\t\t\t\tif(myComponent > maxComponent) {\n\t\t\t\t\tmaxComponent = myComponent;\n\t\t\t\t\tmaxSize = 0;\n\t\t\t\t}\n\t\t\t\tif(myComponent == maxComponent)\n\t\t\t\t\tmaxSize++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(row == 0 && col == 0) {\n\t\t*largestComponentSize = maxSize;\n\t}\n}",
            "__shared__ int sharedA[BLOCK_SIZE][BLOCK_SIZE];\n\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    // Copy data from global memory to shared memory\n    if (tx < N && ty < N) {\n        sharedA[tx][ty] = A[tx * N + ty];\n    }\n    __syncthreads();\n\n    int sum = 0;\n    if (bx == by) {\n        for (int i = 0; i < N; i++) {\n            sum += sharedA[ty][i];\n        }\n    }\n    if (tx == 0 && ty == 0) {\n        atomicMax(largestComponentSize, sum);\n    }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int sdata[1024];\n\tint t = A[idx];\n\tsdata[threadIdx.x] = t;\n\t__syncthreads();\n\n\tfor (int i = blockDim.x/2; i > 0; i >>= 1)\n\t{\n\t\tif (threadIdx.x < i) {\n\t\t\tsdata[threadIdx.x] = sdata[threadIdx.x] | sdata[threadIdx.x+i];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\t*largestComponentSize = sdata[0];\n\t}\n\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(i >= N) return;\n\tint mySize = 1;\n\tif(A[i * N + i] == 0) {\n\t\tmySize = 0;\n\t}\n\tfor(size_t j = 0; j < N; j++) {\n\t\tif(j == i) continue;\n\t\tif(A[i * N + j] == 1) {\n\t\t\tmySize = max(mySize, largestComponent[j]);\n\t\t}\n\t}\n\tlargestComponent[i] = mySize;\n\t__syncthreads();\n\n\tsize_t largest = 0;\n\tfor(size_t k = 1; k < N; k++) {\n\t\tif(largestComponent[k] > largest) {\n\t\t\tlargest = largestComponent[k];\n\t\t}\n\t}\n\t*largestComponentSize = largest;\n}",
            "// Compute the largest component size for a row in the adjacency matrix A.\n    // Store the result in largestComponentSize[row].\n    // Use atomic operations for thread safety.\n    // Assume the grid is NxN.\n\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n    int *lc = (int*) malloc(N * sizeof(int));\n\n    // Initialize lc with 1\n    for (int i = 0; i < N; i++)\n        lc[i] = 1;\n\n    for (int col = 0; col < N; col++) {\n        if (A[row * N + col] == 1) {\n            // Check to see if the col is bigger than lc\n            if (lc[row] < lc[col])\n                lc[row] = lc[col];\n        }\n    }\n\n    // Copy the largest component size for a row to the output array\n    largestComponentSize[row] = lc[row];\n\n}",
            "const size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst size_t col = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (row < N && col < N && A[row * N + col] == 1) {\n\t\tfor (size_t row2 = 0; row2 < N; ++row2) {\n\t\t\tfor (size_t col2 = 0; col2 < N; ++col2) {\n\t\t\t\tif (row2 < N && col2 < N && A[row2 * N + col2] == 1) {\n\t\t\t\t\tatomicMin(largestComponentSize, min(row, col));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < N) {\n\t\t*largestComponentSize = 0;\n\t\tint visited[N];\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[j] = 0;\n\t\t}\n\n\t\t*largestComponentSize = *largestComponentSize + dfs(A, N, i, visited);\n\t}\n}",
            "__shared__ int visited[BLOCKSIZE][BLOCKSIZE];\n\t__shared__ int numVisited[BLOCKSIZE];\n\n\tint tid = threadIdx.y * blockDim.x + threadIdx.x;\n\tint blocksize = blockDim.x * blockDim.y;\n\tint bid = blockIdx.y * gridDim.x + blockIdx.x;\n\tint i, j, k;\n\tint blocknum = (N + blocksize - 1) / blocksize;\n\n\tif (tid < N && bid < N) {\n\t\tvisited[threadIdx.y][threadIdx.x] = 0;\n\t\tvisited[threadIdx.x][threadIdx.y] = 0;\n\t}\n\n\t// traverse all the vertices in the graph\n\tfor (i = 0; i < N; i++) {\n\t\t// reset number of visited vertices\n\t\tnumVisited[threadIdx.y] = 0;\n\t\t__syncthreads();\n\n\t\t// traverse all the vertices in the graph\n\t\tfor (j = 0; j < N; j++) {\n\t\t\t// each thread traverse each vertex\n\t\t\tif (visited[threadIdx.y][threadIdx.x] == 0) {\n\t\t\t\t// check whether it is adjacent to the vertex\n\t\t\t\tif (A[i*N + j] == 1 && visited[tid][j] == 0) {\n\t\t\t\t\tvisited[tid][j] = 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// the number of visited vertices\n\t\t\tnumVisited[threadIdx.y] += visited[threadIdx.y][threadIdx.x];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// find the largest component size\n\tfor (i = 0; i < blocksize; i++) {\n\t\tfor (j = 0; j < blocksize; j++) {\n\t\t\tif (numVisited[i] > numVisited[j]) {\n\t\t\t\t*largestComponentSize = numVisited[i];\n\t\t\t}\n\t\t}\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// A 1-dimensional array is used to represent an NxN matrix\n\t// A[i * N + j] represents the value of the (i, j) entry of the matrix A\n\t// Since the size of a component is determined by the number of connected vertices\n\t// We need to find the largest connected component\n\t// Then we can use the total number of vertices to determine the largest component\n\tif (idx < N * N) {\n\t\tint x = idx / N;\n\t\tint y = idx % N;\n\t\tif (A[idx] == 1 && y < x) {\n\t\t\t// mark the connection between (x, y) and (y, x)\n\t\t\tA[x * N + y] = 1;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint max = 0;\n\tint i;\n\tint j;\n\tfor (i = 0; i < N; i++) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\t*largestComponentSize = max;\n}",
            "}",
            "/*\n\t *\n\t * TODO: Compute the number of vertices in the largest component of the graph\n\t * defined by the adjacency matrix A. Store the result in *largestComponentSize.\n\t *\n\t */\n\n\t// set up the shared memory\n\t__shared__ int sdata[BLOCKSIZE * BLOCKSIZE];\n\n\t// find the index of the thread in the threadblock\n\t// each threadblock will operate on a blocksize x blocksize submatrix\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint threadIndex = BLOCKSIZE*by*BLOCKSIZE+BLOCKSIZE*bx+ty*BLOCKSIZE+tx;\n\tint threadIndexY = ty*BLOCKSIZE+tx;\n\tint x = threadIndex/BLOCKSIZE; // the row\n\tint y = threadIndex%BLOCKSIZE; // the col\n\n\tint threadIndexX = threadIndexY/BLOCKSIZE;\n\tint threadIndexY2 = threadIndexY%BLOCKSIZE;\n\tint x2 = threadIndexX/BLOCKSIZE; // the row\n\tint y2 = threadIndexX%BLOCKSIZE; // the col\n\n\n\tif (threadIndexY2 >= N || threadIndexY >= N || threadIndexX >= N || threadIndex >= N)\n\t{\n\t\t// if the thread is out of bounds, no need to do anything\n\t}\n\telse\n\t{\n\t\tif (A[threadIndexY2*N+threadIndexY] == 1)\n\t\t{\n\t\t\tsdata[threadIndexY*BLOCKSIZE+threadIndexY2] = 1;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsdata[threadIndexY*BLOCKSIZE+threadIndexY2] = 0;\n\t\t}\n\n\t\tif (A[threadIndexY2*N+threadIndexY2] == 1)\n\t\t{\n\t\t\tsdata[threadIndexY2*BLOCKSIZE+threadIndexY2] = 1;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsdata[threadIndexY2*BLOCKSIZE+threadIndexY2] = 0;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint max = 0;\n\t// for (int i = 0; i < BLOCKSIZE*BLOCKSIZE; i++)\n\t// {\n\t// \tprintf(\"shared: %d\\n\", sdata[i]);\n\t// }\n\n\tfor (int i = 0; i < BLOCKSIZE; i++)\n\t{\n\t\t// printf(\"row: %d\\n\", sdata[threadIndexY*BLOCKSIZE+i]);\n\t\tif (sdata[threadIndexY*BLOCKSIZE+i] == 1)\n\t\t{\n\t\t\tmax++;\n\t\t}\n\t}\n\n\tfor (int i = 0; i < BLOCKSIZE; i++)\n\t{\n\t\tif (sdata[threadIndexY2*BLOCKSIZE+i] == 1)\n\t\t{\n\t\t\tmax++;\n\t\t}\n\t}\n\n\t// printf(\"max: %d\\n\", max);\n\n\tif (threadIndex == 0)\n\t{\n\t\t*largestComponentSize = max;\n\t}\n}",
            "int row = blockIdx.x;\n\tint col = blockIdx.y;\n\n\t__shared__ int sdata[BLOCK_SIZE][BLOCK_SIZE];\n\tint bsize = blockDim.x;\n\n\tint tid = threadIdx.x;\n\n\tif(row < N && col < N) {\n\t\tsdata[tid][tid] = A[row*N + col];\n\t}\n\telse {\n\t\tsdata[tid][tid] = 0;\n\t}\n\t__syncthreads();\n\n\tint i = 0;\n\tfor(i = 0; i < BLOCK_SIZE; i += BLOCK_SIZE) {\n\t\tif(tid + i < N) {\n\t\t\tsdata[tid][tid + i] = A[row*N + tid + i];\n\t\t\tsdata[tid + i][tid] = A[(tid + i)*N + col];\n\t\t}\n\t\telse {\n\t\t\tsdata[tid][tid + i] = 0;\n\t\t\tsdata[tid + i][tid] = 0;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tint j = 0;\n\tfor(j = 0; j < BLOCK_SIZE; j++) {\n\t\tif(row + j < N && col + j < N) {\n\t\t\tsdata[tid][tid] = sdata[tid][tid] || sdata[tid][tid + j] || sdata[tid + j][tid] || sdata[tid + j][tid + j];\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Do reduction\n\tfor(i = bsize/2; i > 0; i /= 2) {\n\t\tif(tid < i) {\n\t\t\tsdata[tid][tid] = sdata[tid][tid] || sdata[tid][tid + i];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif(tid == 0) {\n\t\t// Write the result\n\t\t*largestComponentSize = sdata[0][0];\n\t}\n}",
            "__shared__ int S[BLOCK_SIZE][BLOCK_SIZE];\n\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\n\tint tid = BLOCK_SIZE * by + tx;\n\tS[ty][tx] = 0;\n\tif (tid < N) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tS[ty][tx] += A[tid * N + k] && A[k * N + tid];\n\t\t}\n\t}\n\t__syncthreads();\n\tint size = 0;\n\tfor (int i = 0; i < BLOCK_SIZE; i++) {\n\t\tsize += S[ty][i];\n\t}\n\tif (bx == 0 && by == 0) {\n\t\t*largestComponentSize = size;\n\t}\n}",
            "// TODO: Your code here\n    // Replace this comment with your code.\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int component_size = 1;\n    int neighbor;\n\n    if (i < N && A[i * N + i] == 0) {\n        for (int j = 0; j < N; j++) {\n            neighbor = A[i * N + j];\n            if (neighbor == 1) {\n                component_size = -1;\n                break;\n            }\n        }\n    }\n\n    if (component_size!= -1) {\n        for (int j = 0; j < N; j++) {\n            neighbor = A[i * N + j];\n            if (neighbor == 1) {\n                component_size++;\n            }\n        }\n    }\n\n    atomicMax(largestComponentSize, component_size);\n}",
            "int *S = new int[N];\n\tint *D = new int[N];\n\tint *P = new int[N];\n\tint *Dp = new int[N];\n\t\n\tint *visited = new int[N];\n\t\n\tfor (int i = 0; i < N; ++i) {\n\t\tS[i] = i;\n\t\tvisited[i] = 0;\n\t}\n\t\n\tint cmpSz = N;\n\tint cmpIdx = -1;\n\tint cmpD;\n\t\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tP[i] = -1;\n\t\t\tD[i] = -1;\n\t\t\tDp[i] = -1;\n\t\t}\n\t\t\n\t\tint x = S[k];\n\t\tint y = S[x];\n\t\tP[x] = -1;\n\t\tD[x] = 0;\n\t\twhile (y >= 0) {\n\t\t\tD[x] = max(D[x], D[y] + 1);\n\t\t\tP[y] = x;\n\t\t\tint temp = y;\n\t\t\ty = S[y];\n\t\t\tS[temp] = -1;\n\t\t}\n\t\t\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (D[j] >= 0) {\n\t\t\t\tDp[j] = D[j];\n\t\t\t}\n\t\t}\n\t\t\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (P[j] >= 0) {\n\t\t\t\tint u = j;\n\t\t\t\tint v = P[j];\n\t\t\t\twhile (v >= 0) {\n\t\t\t\t\tint temp = u;\n\t\t\t\t\tu = v;\n\t\t\t\t\tv = P[v];\n\t\t\t\t\tif (D[u] < Dp[j]) {\n\t\t\t\t\t\tDp[j] = D[u];\n\t\t\t\t\t}\n\t\t\t\t\tP[temp] = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (D[j] >= 0) {\n\t\t\t\tif (D[j] + Dp[j] > cmpD) {\n\t\t\t\t\tcmpD = D[j] + Dp[j];\n\t\t\t\t\tcmpIdx = j;\n\t\t\t\t\tcmpSz = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (visited[j] == 0) {\n\t\t\t\tif (D[j] >= 0) {\n\t\t\t\t\tcmpSz += 1;\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint finalIdx = -1;\n\t\n\tif (cmpSz > 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tif (D[i] >= 0) {\n\t\t\t\t\tfinalIdx = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t*largestComponentSize = cmpSz;\n\t}\n\telse {\n\t\t*largestComponentSize = 0;\n\t}\n\t\n\tdelete[] S;\n\tdelete[] D;\n\tdelete[] P;\n\tdelete[] Dp;\n\tdelete[] visited;\n}",
            "// TODO\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\n    // We're going to use the DFS algorithm to count the number of vertices in the largest connected component.\n    // The algorithm has the following outline:\n    // 1. Perform a DFS on the graph. Use a stack for the DFS traversal.\n    // 2. Once the DFS is complete, every vertex in the graph has a \"depth\" - the length of the path from that\n    //    vertex to the start of the DFS.\n    // 3. The depth of every vertex in the largest connected component will be the same.\n    // 4. Count the number of vertices with the same depth.\n\n    // TODO: Implement DFS\n}",
            "// Get this thread's unique ID\n\tconst int ID = threadIdx.x + blockIdx.x * blockDim.x;\n\tconst int size = N*N;\n\n\t// Create a shared memory array to store the parent of each node\n\t__shared__ int parents[MAX_N];\n\n\t// Set the default parent of all nodes to be themselves\n\tif (threadIdx.x < N) {\n\t\tparents[ID] = ID;\n\t}\n\n\t// Set all parents to be the same as their roots\n\tfor (size_t i = 0; i < size; i += blockDim.x * gridDim.x) {\n\t\tconst int node = i + threadIdx.x;\n\t\tif (node < size) {\n\t\t\tparents[node] = find(parents, node);\n\t\t}\n\t}\n\n\t// Merge components if two nodes share the same parent\n\tfor (size_t i = 0; i < size; i += blockDim.x * gridDim.x) {\n\t\tconst int node = i + threadIdx.x;\n\t\tif (node < size) {\n\t\t\tif (A[node] == 1) {\n\t\t\t\tint v1 = ID;\n\t\t\t\tint v2 = node;\n\t\t\t\tparents[v1] = parents[v2] = find(parents, v1);\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sum up the number of nodes in each component\n\tfor (size_t i = 0; i < size; i += blockDim.x * gridDim.x) {\n\t\tconst int node = i + threadIdx.x;\n\t\tif (node < size) {\n\t\t\tif (parents[ID] == find(parents, node)) {\n\t\t\t\tatomicAdd(largestComponentSize, 1);\n\t\t\t}\n\t\t}\n\t}\n\n}",
            "// You will need to add your code here\n\n\t*largestComponentSize = -1;\n\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  __shared__ bool visited[16][16];\n\n  int componentSize = 0;\n\n  if (i >= N || j >= N || A[i * N + j] == 0) {\n    return;\n  }\n\n  if (i == j) {\n    return;\n  }\n\n  if (visited[i][j]) {\n    return;\n  }\n\n  visited[i][j] = true;\n  visited[j][i] = true;\n\n  // Breadth First Search\n  queue<int> q;\n  q.push(i);\n\n  while (q.size() > 0) {\n    int cur = q.front();\n    q.pop();\n\n    for (int k = 0; k < N; k++) {\n      if (A[cur * N + k] == 1 &&!visited[cur][k]) {\n        q.push(k);\n        visited[cur][k] = true;\n        visited[k][cur] = true;\n      }\n    }\n    componentSize++;\n  }\n\n  atomicAdd(largestComponentSize, componentSize);\n}",
            "size_t i = blockIdx.y*N+blockIdx.x;\n  size_t j = threadIdx.y*N+threadIdx.x;\n  if(i==j){\n    if(j==0){\n      int max=0;\n      int index=0;\n      for(int k=0;k<N;k++){\n        if(A[k*N+k]>max){\n          max=A[k*N+k];\n          index=k;\n        }\n      }\n      largestComponentSize[0]=max;\n      largestComponentSize[1]=index;\n    }\n  }\n}",
            "// TODO: Implement me\n\n\t// You may use this variable\n\tint componentSize = 0;\n\n\t//...\n\n}",
            "const size_t row = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row < N) {\n    int component_size = 0;\n\n    // TODO\n    // The task is to compute the number of vertices in the largest connected component\n    // of the graph defined by adjacency matrix A. A is an NxN matrix stored in row-major format.\n\n    // You will need to use atomicAdd on the shared variable componentSize to ensure\n    // that component_size is set atomically.\n    //\n    // You can use any data structure you like to keep track of the vertices you have\n    // already visited. Here is one possible approach:\n    //\n    //   int visited[N];\n    //   for (int i = 0; i < N; i++) {\n    //     visited[i] = 0;\n    //   }\n    //\n    //   for (int i = 0; i < N; i++) {\n    //     if (visited[i] == 0 && A[row * N + i] == 1) {\n    //       int stack[N];\n    //       int top = -1;\n    //       stack[++top] = i;\n    //       visited[i] = 1;\n    //       while (top >= 0) {\n    //         int v = stack[top];\n    //         top--;\n    //         for (int j = 0; j < N; j++) {\n    //           if (visited[j] == 0 && A[v * N + j] == 1) {\n    //             stack[++top] = j;\n    //             visited[j] = 1;\n    //           }\n    //         }\n    //       }\n    //     }\n    //   }\n    //   component_size = 0;\n    //   for (int i = 0; i < N; i++) {\n    //     if (visited[i] == 1) {\n    //       component_size++;\n    //     }\n    //   }\n\n    atomicAdd(largestComponentSize, component_size);\n  }\n}",
            "// TODO\n}",
            "}",
            "int row = threadIdx.y * blockDim.x + threadIdx.x;\n  int col = threadIdx.y;\n  if (row >= N || col >= N)\n    return;\n  if (A[row * N + col] == 1) {\n    atomicAdd(largestComponentSize, 1);\n  }\n}",
            "// YOUR CODE HERE\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N) return;\n\n\tfor (int j = 0; j < N; j++)\n\t{\n\t\tif (i == j)\n\t\t\tcontinue;\n\n\t\tif (A[i*N + j] > 0)\n\t\t{\n\t\t\t*largestComponentSize = max(*largestComponentSize, 1 + largestComponent_recursive(A, i, j, N));\n\t\t\tbreak;\n\t\t}\n\t}\n\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n  int size = 0;\n\n  __shared__ int visited[N][N];\n  __shared__ int counts[N];\n\n  if(row == col) {\n    size = 1;\n  }\n  else if(A[row * N + col] == 1) {\n    if(visited[row][col] == 0) {\n      visited[row][col] = 1;\n      counts[row] = 1;\n    }\n    else {\n      counts[row] = 0;\n    }\n  }\n\n  __syncthreads();\n\n  for(int i = 0; i < N; i++) {\n    size += counts[i];\n  }\n\n  if(threadIdx.x == 0) {\n    *largestComponentSize = size;\n  }\n}",
            "__shared__ int components[MAX_DIM];\n    __shared__ int visited[MAX_DIM];\n    __shared__ int componentCount;\n\n    size_t id = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t size = blockDim.x * gridDim.x;\n    int index = id;\n\n    if(id < N) {\n        components[id] = id;\n        visited[id] = 0;\n    }\n\n    __syncthreads();\n\n    if(id == 0) {\n        componentCount = 0;\n    }\n    __syncthreads();\n\n    while(index < N) {\n        // find the root of index\n        while(index!= components[index]) {\n            int p = components[index];\n            components[index] = components[p];\n            index = p;\n        }\n\n        // now we have the root, check whether it is connected to any of the other components\n        for(int i = id + 1; i < N; i += size) {\n            if(A[id*N + i]!= 0) {\n                if(components[id]!= components[i]) {\n                    int p = components[i];\n                    components[i] = components[id];\n                    index = p;\n                }\n            }\n        }\n\n        __syncthreads();\n        if(id == 0) {\n            componentCount = 0;\n        }\n        __syncthreads();\n\n        // mark the vertices we have visited\n        if(id < N) {\n            visited[components[id]] = 1;\n        }\n        __syncthreads();\n\n        // increment the number of connected components\n        if(visited[id] == 1) {\n            atomicAdd(&componentCount, 1);\n        }\n        __syncthreads();\n\n        if(id < N) {\n            index = id;\n        }\n    }\n\n    __syncthreads();\n    if(id == 0) {\n        *largestComponentSize = componentCount;\n    }\n    __syncthreads();\n}",
            "}",
            "/* TODO: Your code here */\n\n\tint i = threadIdx.x + blockIdx.x * blockDim.x;\n\tint j = threadIdx.y + blockIdx.y * blockDim.y;\n\n\t__shared__ int visited[256];\n\t__shared__ int flag;\n\n\tif (i < N && j < N) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tvisited[j] = 1;\n\t\t\t__syncthreads();\n\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (visited[k] == 1) {\n\t\t\t\t\tvisited[k] = 0;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t__syncthreads();\n\t\t\tflag = 1;\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tif (i == 0 && j == 0 && flag == 1) {\n\t\t\t*largestComponentSize = N;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (visited[k] == 0) {\n\t\t\t\t\t*largestComponentSize -= 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n}",
            "int largestComponentSize_global = 0;\n    int *color = (int*)malloc(N * sizeof(int));\n    int *distance = (int*)malloc(N * sizeof(int));\n\n    /*\n    int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n    int *color = (int*)malloc(threadId * sizeof(int));\n    int *distance = (int*)malloc(threadId * sizeof(int));\n    */\n\n    int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n    if(threadId < N) {\n        if(color[threadId]!= -1) {\n            distance[threadId] = 1000;\n            color[threadId] = 0;\n        }\n    }\n\n    __syncthreads();\n\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < N; j++) {\n            int start = A[i*N + j];\n            int end = A[j*N + i];\n\n            if(start == 1 || end == 1) {\n                distance[i] = 1;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    for(int i = 0; i < N; i++) {\n        if(distance[i] == 1) {\n            for(int j = 0; j < N; j++) {\n                int start = A[i*N + j];\n                int end = A[j*N + i];\n\n                if(start == 1 || end == 1) {\n                    distance[i] = 1;\n                }\n            }\n        }\n    }\n\n    __syncthreads();\n\n    for(int i = 0; i < N; i++) {\n        int maxDistance = 0;\n        for(int j = 0; j < N; j++) {\n            if(distance[i] < distance[j]) {\n                maxDistance = distance[j];\n            }\n        }\n\n        if(maxDistance > largestComponentSize_global) {\n            largestComponentSize_global = maxDistance;\n        }\n    }\n\n    largestComponentSize[0] = largestComponentSize_global;\n}",
            "int row = threadIdx.y + blockIdx.y * blockDim.y;\n\tint col = threadIdx.x + blockIdx.x * blockDim.x;\n\tint i, j, cnt = 0;\n\tif (row < N && col < N) {\n\t\tint* visited = new int[N];\n\t\tfor (i = 0; i < N; i++)\n\t\t\tvisited[i] = 0;\n\t\tvisited[col] = 1;\n\t\tif (A[row*N+col] == 1) {\n\t\t\tcnt++;\n\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\tif (A[row*N+j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t*largestComponentSize = cnt;\n\t}\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.y + threadIdx.y;\n\tint max_component_size = 0;\n\tint max_component_index = 0;\n\tfor (int k = 0; k < N; k++) {\n\t\tif (A[i*N+k] == 1 && A[k*N+j] == 1) {\n\t\t\tmax_component_index = k;\n\t\t\tmax_component_size = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tfor (int k = 0; k < N; k++) {\n\t\tif (A[i*N+k] == 1 && A[k*N+j] == 1) {\n\t\t\tif (k!= max_component_index) {\n\t\t\t\tmax_component_size += 1;\n\t\t\t}\n\t\t}\n\t}\n\tif (i == j) {\n\t\t*largestComponentSize = max_component_size;\n\t}\n}",
            "// TODO\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i == j) {\n\t\t*largestComponentSize = *largestComponentSize + 1;\n\t}\n\n}",
            "}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    int size = 0;\n\n    if (i >= N || j >= N || i == j)\n        return;\n\n    int start = i;\n    bool visited[N];\n    for (int k = 0; k < N; k++)\n        visited[k] = false;\n\n    int current = start;\n    visited[start] = true;\n    int count = 0;\n\n    while (current < N) {\n        size++;\n        if (visited[current]) {\n            current++;\n            continue;\n        }\n\n        count++;\n        for (int k = 0; k < N; k++) {\n            if (A[i * N + k] == 1) {\n                if (!visited[k]) {\n                    current = k;\n                    break;\n                }\n            }\n        }\n        visited[current] = true;\n    }\n\n    if (count == 1)\n        atomicAdd(largestComponentSize, size);\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint largestComponentSize_private = 0;\n\tif (row < N && col < N && A[row * N + col] > 0) {\n\n\t\t// Initialize all vertices as unvisited\n\t\tbool *visited = new bool[N];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tvisited[i] = false;\n\t\t}\n\n\t\t// Check if vertex i is in the largest connected component by recursively traversing the graph\n\t\tint largestComponentSize_private = 0;\n\t\tif (col == row) {\n\t\t\tlargestComponentSize_private = findLargestComponent(A, visited, row, col, N);\n\t\t}\n\t\telse {\n\t\t\tlargestComponentSize_private = 0;\n\t\t}\n\t}\n\n\tif (row == col) {\n\t\tatomicMax(largestComponentSize, largestComponentSize_private);\n\t}\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "12_graph_largest_component",
        "parallelism_model": "mpi+omp",
        "prompt": "#include <mpi.h>\n#include <omp.h>\n\n/* Return the number of vertices in the largest component of the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint largestComponent(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// TODO\n  int max_num = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0 && i!= j) {\n        max_num++;\n      }\n    }\n  }\n  return max_num;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\n\tint local_vertex_count = 0;\n\tint local_max_vertex_count = 0;\n\n\t// Count local number of vertices\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tlocal_vertex_count += count;\n\t\tlocal_max_vertex_count = std::max(count, local_max_vertex_count);\n\t}\n\n\tint global_vertex_count = 0;\n\tint global_max_vertex_count = 0;\n\n\tMPI_Allreduce(&local_vertex_count, &global_vertex_count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\tMPI_Allreduce(&local_max_vertex_count, &global_max_vertex_count, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\treturn global_max_vertex_count;\n}",
            "/* Your solution here */\n\tint num_proc;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> largest(N, 1);\n\tstd::vector<int> count(N, 1);\n\n\tint n_blocks = (int)ceil(((double)N)/num_proc);\n\n\tint i_start = rank * n_blocks;\n\tint i_end = std::min((rank+1)*n_blocks, N);\n\n#pragma omp parallel for\n\tfor(int i=0; i<N; ++i) {\n\t\tfor(int j=0; j<N; ++j) {\n\t\t\tif(A[i*N + j]) {\n\t\t\t\tlargest[i] = std::max(largest[i], count[j]);\n\t\t\t}\n\t\t}\n\t}\n\n\t//printf(\"rank: %d, i_start: %d, i_end: %d, largest: \", rank, i_start, i_end);\n\t//for(int i=0; i<N; ++i) {\n\t//\tprintf(\"%d \", largest[i]);\n\t//}\n\t//printf(\"\\n\");\n\tMPI_Reduce(largest.data(), count.data(), N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tif(rank == 0) {\n\t\tint max = count[0];\n\t\tfor(int i=1; i<N; ++i) {\n\t\t\tmax = std::max(max, count[i]);\n\t\t}\n\t\treturn max;\n\t}\n\treturn 0;\n}",
            "// TODO: implement this function\n\n\treturn 0;\n}",
            "// TODO: your code here\n  int numVertices = N;\n  std::vector<int> vertices_found = std::vector<int>(numVertices);\n  std::vector<int> component_counter = std::vector<int>(numVertices, 0);\n  std::vector<int> adj_matrix = A;\n\n  int num_processes, process_id;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &process_id);\n\n  // Each process will be given the number of vertices to check.\n  int vertices_per_process = numVertices / num_processes;\n  int vertices_remaining = numVertices % num_processes;\n  int num_vertices_to_check = vertices_per_process;\n  if (process_id < vertices_remaining) {\n    num_vertices_to_check++;\n  }\n\n  int start_vertex = process_id * vertices_per_process;\n  if (process_id < vertices_remaining) {\n    start_vertex += process_id;\n  } else {\n    start_vertex += vertices_remaining;\n  }\n\n  for (int i = 0; i < num_vertices_to_check; i++) {\n    int vertex = start_vertex + i;\n    vertices_found[vertex] = 1;\n    component_counter[vertex] = 1;\n    for (int j = 0; j < numVertices; j++) {\n      if (adj_matrix[vertex * numVertices + j]!= 0) {\n        component_counter[vertex] += component_counter[j];\n      }\n    }\n  }\n\n  int max_component_counter = 0;\n  for (int i = 0; i < numVertices; i++) {\n    max_component_counter = std::max(max_component_counter, component_counter[i]);\n  }\n\n  int max_component_counter_global = 0;\n  MPI_Reduce(&max_component_counter, &max_component_counter_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return max_component_counter_global;\n}",
            "// TODO\n\treturn 0;\n}",
            "int numComponents = 1;\n    // TODO: Use MPI and OpenMP to compute this in parallel\n\n    return numComponents;\n}",
            "return 0;\n}",
            "// TODO\n}",
            "// TODO: Your code goes here.\n\treturn 0;\n}",
            "std::vector<int> rank_component(N, 0);\n\n    for (int i = 0; i < N; i++) {\n        int sum = 0;\n        for (int j = 0; j < N; j++) {\n            sum += A[i * N + j];\n        }\n        rank_component[i] = sum;\n    }\n\n    std::vector<int> all_components(N);\n    MPI_Gather(&rank_component[0], N, MPI_INT, &all_components[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    std::vector<int> global_max_components(N);\n\n    if (0 == rank) {\n        int global_max = 0;\n        int global_max_index = 0;\n        for (int i = 0; i < N; i++) {\n            if (all_components[i] > global_max) {\n                global_max = all_components[i];\n                global_max_index = i;\n            }\n        }\n        for (int i = 0; i < N; i++) {\n            if (all_components[i] == global_max) {\n                global_max_components[i] = 1;\n            }\n        }\n\n        for (int i = 1; i < N; i++) {\n            if (global_max_components[i]!= 1) {\n                global_max_components[global_max_index] = 0;\n                global_max = 0;\n                global_max_index = 0;\n                for (int j = 0; j < N; j++) {\n                    if (global_max_components[j] == 1) {\n                        global_max_components[j] = 0;\n                    }\n                }\n                for (int j = 0; j < N; j++) {\n                    if (all_components[j] > global_max) {\n                        global_max = all_components[j];\n                        global_max_index = j;\n                    }\n                }\n                for (int j = 0; j < N; j++) {\n                    if (all_components[j] == global_max) {\n                        global_max_components[j] = 1;\n                    }\n                }\n            }\n        }\n    }\n\n    std::vector<int> result(1);\n    if (0 == rank) {\n        int global_max = 0;\n        for (int i = 0; i < N; i++) {\n            if (global_max_components[i] == 1) {\n                global_max++;\n            }\n        }\n        result[0] = global_max;\n    }\n    MPI_Gather(&result[0], 1, MPI_INT, &result[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    return result[0];\n}",
            "// TODO\n}",
            "std::vector<int> A_copy(A);\n\t\n\tMPI_Status status;\n\tint r = 0, s = 0, world_size = 0, world_rank = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n\tint **result = new int* [world_size];\n\tfor (int i = 0; i < world_size; i++)\n\t\tresult[i] = new int[N];\n\tint **visited = new int* [world_size];\n\tfor (int i = 0; i < world_size; i++)\n\t\tvisited[i] = new int[N];\n\tint **count = new int* [world_size];\n\tfor (int i = 0; i < world_size; i++)\n\t\tcount[i] = new int[N];\n\n\tomp_set_num_threads(world_size);\n#pragma omp parallel\n\t{\n\t\tint *result = new int[N];\n\t\tint *visited = new int[N];\n\t\tint *count = new int[N];\n\t\tint tid = omp_get_thread_num();\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tresult[i] = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tvisited[i] = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tcount[i] = 0;\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tif (visited[i] == 0)\n\t\t\t{\n\t\t\t\tint j = i;\n\t\t\t\tint k = 0;\n\t\t\t\twhile (j >= 0 && j < N && visited[j] == 0)\n\t\t\t\t{\n\t\t\t\t\tresult[j] = 1;\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tj = A_copy[j];\n\t\t\t\t\tk++;\n\t\t\t\t}\n\t\t\t\tcount[tid] += k;\n\t\t\t}\n\t\t}\n\n\t\tMPI_Send(result, N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(visited, N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tfor (int i = 1; i < world_size; i++)\n\t{\n\t\tint source = i;\n\t\tMPI_Recv(result[source], N, MPI_INT, source, 0, MPI_COMM_WORLD, &status);\n\t\tMPI_Recv(visited[source], N, MPI_INT, source, 0, MPI_COMM_WORLD, &status);\n\t\tMPI_Recv(count[source], 1, MPI_INT, source, 0, MPI_COMM_WORLD, &status);\n\t}\n\n\tint m = count[0];\n\tfor (int i = 1; i < world_size; i++)\n\t{\n\t\tif (count[i] > m)\n\t\t\tm = count[i];\n\t}\n\n\tint max = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (visited[i] == 0 && max < count[0])\n\t\t{\n\t\t\tmax = count[0];\n\t\t\tr = i;\n\t\t}\n\t}\n\tfor (int i = 1; i < world_size; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (visited[j] == 0 && max < count[i])\n\t\t\t{",
            "std::vector<bool> A_bool(N*N, false);\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            A_bool[i*N+j] = A[i*N+j];\n        }\n    }\n\n    // TODO: Your code here\n    std::vector<int> visited_all_nodes(N);\n    std::fill(visited_all_nodes.begin(), visited_all_nodes.end(), 0);\n    int max_visited = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited_all_nodes[i] == 0) {\n            int visited_nodes_current = 1;\n            std::vector<int> visiting;\n            visiting.push_back(i);\n            while (visiting.size()!= 0) {\n                int current = visiting[0];\n                visited_all_nodes[current] = 1;\n                visiting.erase(visiting.begin());\n                for (int j = 0; j < N; ++j) {\n                    if (A_bool[current*N+j] == 1 && visited_all_nodes[j] == 0) {\n                        visiting.push_back(j);\n                        visited_nodes_current++;\n                    }\n                }\n            }\n            if (visited_nodes_current > max_visited) {\n                max_visited = visited_nodes_current;\n            }\n        }\n    }\n    return max_visited;\n}",
            "/* Your solution goes here */\n}",
            "}",
            "assert(A.size() == N * N);\n  //...\n  //...\n  //...\n  //...\n}",
            "// TODO: replace this line with your code\n  int a = 0;\n  return a;\n}",
            "// Your code here\n    return 0;\n}",
            "int numProc = 0, rank = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numProc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tomp_set_num_threads(numProc);\n\n\tint numVerts = N * N;\n\tint chunk = numVerts / numProc;\n\tint remainder = numVerts % numProc;\n\n\t// If there are enough vertices to give each processor at least one vertex, give each processor\n\t// the chunk of vertices.\n\t// If there are too many vertices, then the remainder of vertices need to be distributed evenly.\n\tint start, end;\n\tif (numProc <= numVerts) {\n\t\tstart = rank * chunk + std::min(rank, remainder);\n\t\tend = start + chunk + (rank < remainder? 1 : 0);\n\t}\n\telse {\n\t\tstart = rank * (numVerts / numProc) + std::min(rank, numVerts % numProc);\n\t\tend = start + (numVerts / numProc) + (rank < numVerts % numProc? 1 : 0);\n\t}\n\n\tstd::vector<int> vertices(A.begin() + start * N, A.begin() + end * N);\n\tstd::vector<int> visited(numVerts, 0);\n\tfor (int i = 0; i < numVerts; i++) {\n\t\tif (vertices[i] == 1) {\n\t\t\tint current = i;\n\t\t\tint component = 1;\n\t\t\twhile (true) {\n\t\t\t\tvertices[current] = 0;\n\t\t\t\tfor (int j = 0; j < numVerts; j++) {\n\t\t\t\t\tif (A[current * N + j] == 1 && vertices[j] == 1) {\n\t\t\t\t\t\tcomponent++;\n\t\t\t\t\t\tvertices[j] = 0;\n\t\t\t\t\t\tcurrent = j;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (current == i)\n\t\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Update the visited matrix\n\t\t\tfor (int j = start; j < end; j++) {\n\t\t\t\tif (vertices[j] == 1)\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tint result = 0;\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < numVerts; i++) {\n\t\t\tif (visited[i] == 1)\n\t\t\t\tresult++;\n\t\t}\n\t}\n\n\t// Reduce the result to rank 0\n\tMPI_Reduce(&result, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn result;\n}",
            "// TODO\n}",
            "// TODO\n\n  return 0;\n}",
            "return 0;\n}",
            "// TODO\n\treturn -1;\n}",
            "int components = 0;\n    int global_components = 0;\n    int local_components = 0;\n    int global_components_temp = 0;\n    //int *local_components;\n\n    int local_components_temp = 0;\n    int local_components_temp2 = 0;\n\n    int myrank = 0;\n    int global_components_temp2 = 0;\n\n    //int myrank = 0;\n    int myrank2 = 0;\n\n    int nranks = 0;\n\n    int i = 0;\n    int j = 0;\n\n    //int i2 = 0;\n    //int j2 = 0;\n\n    int start = 0;\n    int end = 0;\n\n    int start2 = 0;\n    int end2 = 0;\n\n    int counter = 0;\n    int counter2 = 0;\n    int counter3 = 0;\n\n    int current = 0;\n    int current2 = 0;\n    int current3 = 0;\n\n    int check = 0;\n    int check2 = 0;\n    int check3 = 0;\n\n    //int *my_local_components;\n    //int *my_local_components2;\n\n    int my_local_components;\n    int my_local_components2;\n\n    int my_local_components_temp = 0;\n    int my_local_components_temp2 = 0;\n\n    int my_local_components2_temp = 0;\n    int my_local_components2_temp2 = 0;\n\n    int my_local_components3 = 0;\n    int my_local_components3_temp = 0;\n\n    int my_local_components4 = 0;\n    int my_local_components4_temp = 0;\n\n    int local_components_temp3 = 0;\n    int local_components_temp4 = 0;\n\n    int my_local_components5 = 0;\n    int my_local_components5_temp = 0;\n\n    int local_components_temp5 = 0;\n    int local_components_temp6 = 0;\n\n    int my_local_components6 = 0;\n    int my_local_components6_temp = 0;\n\n    int local_components_temp7 = 0;\n    int local_components_temp8 = 0;\n\n    int my_local_components7 = 0;\n    int my_local_components7_temp = 0;\n\n    int my_local_components8 = 0;\n    int my_local_components8_temp = 0;\n\n    int my_local_components9 = 0;\n    int my_local_components9_temp = 0;\n\n    int local_components_temp9 = 0;\n    int local_components_temp10 = 0;\n\n    int my_local_components10 = 0;\n    int my_local_components10_temp = 0;\n\n    int local_components_temp11 = 0;\n    int local_components_temp12 = 0;\n\n    int my_local_components11 = 0;\n    int my_local_components11_temp = 0;\n\n    int my_local_components12 = 0;\n    int my_local_components12_temp = 0;\n\n    int local_components_temp13 = 0;\n    int local_components_temp14 = 0;\n\n    int my_local_components13 = 0;\n    int my_local_components13_temp = 0;\n\n    int my_local_components14 = 0;\n    int my_local_components14_temp = 0;\n\n    int local_components_temp15 = 0;\n    int local_components_temp16 = 0;\n\n    int my_local_components15 = 0;\n    int my_local_components15_temp = 0;\n\n    int my_local_components16 = 0;\n    int my_local_components16_temp = 0;\n\n    int local_components_temp17 = 0;",
            "// Use OpenMP to find the largest component of each row of A in parallel.\n  // The results are stored in a vector C.\n  // For example, if C = [0, 2, 3, 1] then the largest component for the second row of A is 2.\n  std::vector<int> C(N, 0);\n  #pragma omp parallel for schedule(static)\n  for (int i = 0; i < N; ++i) {\n    int max_component = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0 && j > max_component) {\n        max_component = j;\n      }\n    }\n    C[i] = max_component;\n  }\n\n  // Reduce the results in C to rank 0 using MPI's MPI_Reduce function.\n  int largest_component = 0;\n  MPI_Reduce(C.data(), &largest_component, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return largest_component + 1;\n}",
            "int root = 0;\n  int rank;\n  int size;\n  int tag = 0;\n\n  // get rank and size\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // get the number of vertices\n  int n = N;\n\n  // initialize the visited array\n  std::vector<int> visited(n, 0);\n\n  // initialize the component array\n  std::vector<int> component(n, -1);\n\n  // initialize the counts\n  std::vector<int> count(n, 0);\n\n  // initialize the global counts\n  std::vector<int> global_count(n, 0);\n\n  // initialize the max_count\n  int max_count = 0;\n  int global_max_count = 0;\n\n  // initialize the max_count_index\n  int max_count_index = 0;\n  int global_max_count_index = 0;\n\n  // initialize the component_count\n  int component_count = 0;\n\n  // initialize the total_count\n  int total_count = 0;\n\n  // calculate the number of vertices in the largest component on each rank\n  if (rank == root) {\n    for (int v = 0; v < n; v++) {\n      if (visited[v] == 0) {\n        component_bfs(A, v, visited, component, count, n);\n        component_count++;\n        total_count += count[v];\n        max_count = std::max(max_count, count[v]);\n        max_count_index = v;\n      }\n    }\n  }\n\n  // send the data\n  MPI_Send(&component_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD);\n  MPI_Send(&total_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD);\n  MPI_Send(&max_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD);\n  MPI_Send(&max_count_index, 1, MPI_INT, root, tag, MPI_COMM_WORLD);\n\n  // receive the data\n  if (rank!= root) {\n    MPI_Recv(&component_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    MPI_Recv(&total_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    MPI_Recv(&max_count, 1, MPI_INT, root, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    MPI_Recv(&max_count_index, 1, MPI_INT, root, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n\n  // reduce the counts\n  MPI_Reduce(&component_count, &global_count[0], size, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n  MPI_Reduce(&total_count, &global_count[1], size, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n  MPI_Reduce(&max_count, &global_max_count, size, MPI_INT, MPI_MAX, root, MPI_COMM_WORLD);\n  MPI_Reduce(&max_count_index, &global_max_count_index, size, MPI_INT, MPI_MAX, root, MPI_COMM_WORLD);\n\n  // return the number of vertices in the largest component\n  return global_max_count;\n}",
            "std::vector<int> count;\n  count.resize(N);\n\n  int i, j, p, q, k, r;\n  int size = 0;\n  int maxsize = 0;\n\n  #pragma omp parallel\n  {\n    int nthread = omp_get_num_threads();\n    int tid = omp_get_thread_num();\n    int threadN = N / nthread;\n    int start = tid * threadN;\n    int end = (tid == nthread - 1)? N : (tid + 1) * threadN;\n\n    #pragma omp for\n    for (i = 0; i < N; i++)\n      count[i] = 0;\n\n    for (i = start; i < end; i++) {\n      for (j = 0; j < N; j++)\n        if (A[i * N + j])\n          count[j]++;\n    }\n  }\n\n  for (i = 0; i < N; i++) {\n    size = count[i];\n    if (size > maxsize)\n      maxsize = size;\n  }\n\n  MPI_Reduce(&maxsize, &size, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return size;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int max_component = 1;\n\n    // TODO\n\n    return max_component;\n}",
            "auto result = 0;\n  std::vector<int> visited(N,0);\n  std::vector<int> queue;\n\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      queue.push_back(i);\n      visited[i] = 1;\n      while (queue.size() > 0) {\n        auto u = queue.back();\n        queue.pop_back();\n        for (int j = 0; j < N; j++) {\n          if (A[u*N + j] == 1 && visited[j] == 0) {\n            queue.push_back(j);\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n  }\n\n  result = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 1) {\n      result = result + 1;\n    }\n  }\n\n  return result;\n}",
            "auto const& A_data = A.data();\n\n  // TODO: Implement this function\n  return -1;\n}",
            "// Your code here.\n    std::vector<int> colors(N, -1);\n    std::queue<int> queue;\n    int color = 0;\n\n    for (int i = 0; i < N; ++i)\n    {\n        if (colors[i] == -1)\n        {\n            colors[i] = color;\n            queue.push(i);\n            while (!queue.empty())\n            {\n                int curr = queue.front();\n                queue.pop();\n                for (int j = 0; j < N; ++j)\n                {\n                    if (A[curr*N+j] == 1 && colors[j] == -1)\n                    {\n                        colors[j] = color;\n                        queue.push(j);\n                    }\n                }\n            }\n            ++color;\n        }\n    }\n\n    int max_color = -1;\n    for (int i = 0; i < N; ++i)\n    {\n        if (max_color == -1 || colors[i] > max_color)\n            max_color = colors[i];\n    }\n\n    return max_color;\n}",
            "// your code here\n\n\treturn 0;\n}",
            "std::vector<std::vector<bool>> adjacencyMatrix;\n\n    for (int i = 0; i < A.size(); i += N) {\n        adjacencyMatrix.push_back(std::vector<bool>());\n        for (int j = i; j < i + N; j++)\n            adjacencyMatrix[adjacencyMatrix.size() - 1].push_back(A[j] == 1);\n    }\n\n    std::vector<bool> visited(N);\n    std::fill(visited.begin(), visited.end(), false);\n\n    int maxComponentSize = 0;\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == false) {\n            int componentSize = 0;\n            std::vector<int> stack;\n            stack.push_back(i);\n            visited[i] = true;\n            while (stack.size()!= 0) {\n                int current = stack.back();\n                stack.pop_back();\n                componentSize++;\n                for (int j = 0; j < adjacencyMatrix[current].size(); j++) {\n                    if (adjacencyMatrix[current][j] && visited[j] == false) {\n                        stack.push_back(j);\n                        visited[j] = true;\n                    }\n                }\n            }\n            maxComponentSize = std::max(maxComponentSize, componentSize);\n        }\n    }\n\n    int result;\n    MPI_Reduce(&maxComponentSize, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> max_visited(1, 0);\n\tint max = 0;\n\tint max_size = 0;\n\n\t//omp_set_num_threads(N);\n#pragma omp parallel\n\t{\n#pragma omp for reduction(max:max_size)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tsize_t current_size = 0;\n\t\t\t\tstd::queue<size_t> queue;\n\t\t\t\tqueue.push(i);\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tcurrent_size++;\n\t\t\t\twhile (!queue.empty()) {\n\t\t\t\t\tsize_t current = queue.front();\n\t\t\t\t\tqueue.pop();\n\t\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (A[current*N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t\tcurrent_size++;\n\t\t\t\t\t\t\tqueue.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (current_size > max) {\n\t\t\t\t\tmax = current_size;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#pragma omp critical\n\t\t{\n\t\t\tif (max > max_size) {\n\t\t\t\tmax_size = max;\n\t\t\t}\n\t\t}\n\t}\n\treturn max_size;\n}",
            "int num_threads;\n    int num_procs;\n    int rank;\n    int i, j, k;\n    int num_vertices;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    std::vector<int> vertex_list[num_procs];\n    std::vector<int> local_visited(N);\n    std::vector<int> local_result(N);\n    std::vector<int> global_visited;\n    std::vector<int> global_result;\n\n    for(i = 0; i < N; i++) {\n        for(j = 0; j < N; j++) {\n            local_visited[i] = 0;\n            local_result[i] = 0;\n        }\n    }\n\n    for(i = 0; i < N; i++) {\n        local_visited[i] = 0;\n        local_result[i] = 0;\n    }\n\n    if(rank == 0) {\n        num_vertices = 0;\n        for(i = 0; i < N; i++) {\n            if(A[i]!= 0) {\n                num_vertices++;\n            }\n        }\n    }\n\n    MPI_Bcast(&num_vertices, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    for(i = 0; i < num_vertices; i++) {\n        vertex_list[rank].push_back(i);\n    }\n\n    num_threads = omp_get_num_procs();\n\n    #pragma omp parallel num_threads(num_threads)\n    {\n        int thread_id = omp_get_thread_num();\n        int my_start = (rank*num_vertices)/num_procs;\n        int my_end = (rank+1)*num_vertices/num_procs;\n        int temp;\n        int local_num;\n\n        #pragma omp for\n        for(i = my_start; i < my_end; i++) {\n            if(local_visited[vertex_list[rank][i]] == 0) {\n                temp = 1;\n                local_visited[vertex_list[rank][i]] = 1;\n                local_result[vertex_list[rank][i]] = 1;\n\n                for(k = 0; k < N; k++) {\n                    if(A[vertex_list[rank][i]] == 1 && local_visited[k] == 0) {\n                        local_visited[k] = 1;\n                        local_result[k] = 1;\n                    }\n                }\n\n                for(j = 0; j < N; j++) {\n                    if(A[j] == 1 && local_visited[j] == 0) {\n                        local_visited[j] = 1;\n                        local_result[j] = 1;\n                        for(k = 0; k < N; k++) {\n                            if(A[k] == 1 && local_visited[k] == 0) {\n                                local_visited[k] = 1;\n                                local_result[k] = 1;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n\n        #pragma omp critical\n        {\n            for(i = 0; i < N; i++) {\n                global_visited.push_back(local_visited[i]);\n                global_result.push_back(local_result[i]);\n            }\n        }\n    }\n\n    int count = 0;\n    for(i = 0; i < N; i++) {\n        if(global_visited[i] == 1) {\n            count++;\n        }\n    }\n\n    int *global_count = (int *)malloc(sizeof(int));\n\n    MPI_Gather(&count, 1, MPI_INT, global_count, 1, MPI_INT, 0, MPI_COMM_",
            "std::vector<int> A_copy(A.size());\n    std::copy(A.begin(), A.end(), A_copy.begin());\n    int result;\n    int num_of_processes, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_of_processes);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    if(num_of_processes == 1)\n    {\n        result = largestComponentSerial(A_copy, N);\n    }\n    else\n    {\n        int number_of_partitions = num_of_processes;\n        int partition_size = (int)(N / number_of_partitions + (N % number_of_partitions!= 0));\n        int num_of_threads = omp_get_max_threads();\n        int number_of_rows_each_thread;\n        if(num_of_threads < N)\n        {\n            number_of_rows_each_thread = (int)(N / num_of_threads + (N % num_of_threads!= 0));\n        }\n        else\n        {\n            number_of_rows_each_thread = 1;\n        }\n        std::vector<int> number_of_vertices_in_component_array(num_of_threads, 0);\n        int number_of_vertices_in_component = 0;\n        if(rank == 0)\n        {\n            for(int i = 0; i < number_of_partitions; i++)\n            {\n                std::vector<int> sub_A(partition_size * partition_size);\n                MPI_Recv(&sub_A[0], partition_size * partition_size, MPI_INT, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n                number_of_vertices_in_component = largestComponentSerial(sub_A, partition_size);\n                if(number_of_vertices_in_component_array.size() < (i+1)*number_of_rows_each_thread)\n                {\n                    number_of_vertices_in_component_array.resize(i+1*number_of_rows_each_thread);\n                }\n                for(int j = 0; j < number_of_rows_each_thread; j++)\n                {\n                    number_of_vertices_in_component_array[i*number_of_rows_each_thread + j] = number_of_vertices_in_component;\n                }\n            }\n            for(int i = 0; i < num_of_threads - 1; i++)\n            {\n                MPI_Send(&number_of_vertices_in_component_array[i*number_of_rows_each_thread], number_of_rows_each_thread, MPI_INT, i+1, 1, MPI_COMM_WORLD);\n            }\n            for(int i = 0; i < number_of_rows_each_thread; i++)\n            {\n                number_of_vertices_in_component_array[num_of_threads-1*number_of_rows_each_thread + i] = number_of_vertices_in_component;\n            }\n            MPI_Send(&number_of_vertices_in_component_array[num_of_threads-1*number_of_rows_each_thread], number_of_rows_each_thread, MPI_INT, num_of_threads-1, 1, MPI_COMM_WORLD);\n            for(int i = 0; i < num_of_threads; i++)\n            {\n                if(i == 0)\n                {\n                    result = *std::max_element(number_of_vertices_in_component_array.begin(), number_of_vertices_in_component_array.begin()+number_of_rows_each_thread);\n                }\n                else\n                {\n                    result = std::max(result, *std::max_element(number_of_vertices_in_component_array.begin()+i*number_of_rows_each_thread, number_of_vertices_in_component_array.begin()+(",
            "int rank = 0;\n  int numProc = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &numProc);\n\n  if (rank == 0) {\n    // do nothing\n  }\n  else {\n    // do nothing\n  }\n\n  // do nothing\n\n  // do nothing\n\n  return 0;\n}",
            "// TODO: your code here\n  return 0;\n}",
            "// TODO: YOUR CODE HERE\n\n    std::vector<int> rank_A(N*N);\n    std::vector<int> rank_B(N*N);\n    std::vector<int> temp_A(N*N);\n    std::vector<int> temp_B(N*N);\n\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < N; j++) {\n            rank_A[i*N + j] = A[i*N + j];\n        }\n    }\n\n    for(int iter = 0; iter < 100; iter++) {\n        MPI_Barrier(MPI_COMM_WORLD);\n        temp_A = rank_A;\n\n        omp_set_num_threads(4);\n        #pragma omp parallel for\n        for(int i = 0; i < N; i++) {\n            for(int j = 0; j < N; j++) {\n                rank_B[i*N + j] = 0;\n                if(rank_A[i*N + j] == 1) {\n                    for(int k = 0; k < N; k++) {\n                        rank_B[i*N + j] += rank_A[k*N + j];\n                    }\n                }\n            }\n        }\n\n        MPI_Barrier(MPI_COMM_WORLD);\n        temp_B = rank_B;\n\n        MPI_Barrier(MPI_COMM_WORLD);\n        temp_A = rank_B;\n\n        omp_set_num_threads(4);\n        #pragma omp parallel for\n        for(int i = 0; i < N; i++) {\n            for(int j = 0; j < N; j++) {\n                rank_A[i*N + j] = 0;\n                if(rank_B[i*N + j] == 1) {\n                    for(int k = 0; k < N; k++) {\n                        rank_A[i*N + j] += rank_B[k*N + j];\n                    }\n                }\n            }\n        }\n\n        MPI_Barrier(MPI_COMM_WORLD);\n        if(temp_A!= temp_B) {\n            break;\n        }\n    }\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    int rank_val;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank_val);\n    if(rank_val == 0) {\n        int max_val = 0;\n        for(int i = 0; i < N; i++) {\n            for(int j = 0; j < N; j++) {\n                if(rank_A[i*N + j] == 1) {\n                    max_val++;\n                }\n            }\n        }\n        return max_val;\n    }\n    else {\n        return 0;\n    }\n}",
            "int *local_A = new int[N * N];\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      local_A[i * N + j] = A[i * N + j];\n    }\n  }\n\n  int *num_in_comp = new int[N];\n  int *num_out_comp = new int[N];\n  int *num_verts_in_comp = new int[N];\n  int *num_verts_out_comp = new int[N];\n  int *num_verts = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    num_in_comp[i] = -1;\n    num_out_comp[i] = -1;\n    num_verts_in_comp[i] = 0;\n    num_verts_out_comp[i] = 0;\n    num_verts[i] = 0;\n  }\n\n  int *num_in_comp_sum = new int[N];\n  int *num_out_comp_sum = new int[N];\n  int *num_verts_in_comp_sum = new int[N];\n  int *num_verts_out_comp_sum = new int[N];\n  int *num_verts_sum = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    num_in_comp_sum[i] = -1;\n    num_out_comp_sum[i] = -1;\n    num_verts_in_comp_sum[i] = 0;\n    num_verts_out_comp_sum[i] = 0;\n    num_verts_sum[i] = 0;\n  }\n\n  int *num_in_comp_final = new int[N];\n  int *num_out_comp_final = new int[N];\n  int *num_verts_in_comp_final = new int[N];\n  int *num_verts_out_comp_final = new int[N];\n  int *num_verts_final = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    num_in_comp_final[i] = -1;\n    num_out_comp_final[i] = -1;\n    num_verts_in_comp_final[i] = 0;\n    num_verts_out_comp_final[i] = 0;\n    num_verts_final[i] = 0;\n  }\n\n  int *is_finished = new int[N];\n  int *is_finished_final = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    is_finished[i] = 0;\n    is_finished_final[i] = 0;\n  }\n\n  int *final_num_in_comp = new int[N];\n  int *final_num_out_comp = new int[N];\n  int *final_num_verts_in_comp = new int[N];\n  int *final_num_verts_out_comp = new int[N];\n  int *final_num_verts = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    final_num_in_comp[i] = -1;\n    final_num_out_comp[i] = -1;\n    final_num_verts_in_comp[i] = 0;\n    final_num_verts_out_comp[i] = 0;\n    final_num_verts[i] = 0;\n  }\n\n  int max_num_in_comp = 0;\n  int max_num_out_comp = 0;\n  int max_num_verts_in_comp = 0;\n  int max_num_verts_out_comp = 0;\n  int max_num_verts = 0;\n  int max_final_num_in_comp =",
            "/*... */\n    return 0;\n}",
            "// TODO: implement this function\n  int num_thread;\n  int rank, world_size;\n  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Status status;\n  std::vector<int> result;\n  int lc=0;\n  std::vector<std::vector<bool>> components(world_size);\n\n  //omp_set_num_threads(N);\n  #pragma omp parallel for shared(N,world_size)\n  for(int i=0;i<world_size;i++){\n    components[i].resize(N);\n  }\n\n  MPI_Bcast(&num_thread, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  omp_set_num_threads(num_thread);\n\n  if(rank==0){\n    result.resize(N);\n    std::fill(result.begin(), result.end(), 0);\n  }\n\n  int r=rank*N/world_size;\n  int r1=r+N/world_size;\n  if(r1>N){\n    r1=N;\n  }\n\n  #pragma omp parallel for shared(A,N,world_size)\n  for(int i=r;i<r1;i++){\n    components[rank][i]=true;\n  }\n\n  while(true){\n    bool change=false;\n    int size=components[rank].size();\n    //#pragma omp parallel for shared(A,size)\n    for(int i=0;i<size;i++){\n      if(components[rank][i]){\n        for(int j=0;j<size;j++){\n          if(A[i*size+j]&&i!=j&&!components[rank][j]){\n            components[rank][j]=true;\n            change=true;\n          }\n        }\n      }\n    }\n    if(!change){\n      break;\n    }\n  }\n\n  for(int i=0;i<world_size;i++){\n    if(i!=rank){\n      MPI_Send(&components[i][0], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n  }\n  MPI_Status status;\n  int* res;\n  res=(int*)calloc(N, sizeof(int));\n\n  for(int i=0;i<world_size;i++){\n    if(i!=rank){\n      MPI_Recv(&res[0], N, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n    }\n  }\n\n  #pragma omp parallel for shared(res,N)\n  for(int i=0;i<N;i++){\n    if(res[i]){\n      result[i]=1;\n    }\n  }\n\n  int* result_array;\n  result_array=(int*)calloc(N, sizeof(int));\n  for(int i=0;i<N;i++){\n    result_array[i]=result[i];\n  }\n  MPI_Reduce(result_array, &lc, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return lc;\n}",
            "// Your code goes here\n    int* a = new int[N*N];\n    std::copy(A.begin(), A.end(), a);\n    std::vector<int> result;\n    int max;\n    int min;\n    std::vector<int> min_val;\n    std::vector<int> max_val;\n    MPI_Status status;\n    int size;\n    int rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int number_of_process = size;\n    int number_of_row = N/size;\n    int row_start = rank*number_of_row;\n    if(rank == 0)\n    {\n        for(int i = 1; i < number_of_process; i++)\n        {\n            int row_start_i = i*number_of_row;\n            MPI_Send(&a[row_start_i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        max = 0;\n        for(int i = 0; i < number_of_row; i++)\n        {\n            if(max < a[row_start*N + i])\n                max = a[row_start*N + i];\n        }\n        for(int i = 1; i < number_of_process; i++)\n        {\n            MPI_Recv(&min, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n            if(max < min)\n                max = min;\n        }\n        result.push_back(max);\n        for(int i = 1; i < number_of_process; i++)\n        {\n            int row_start_i = i*number_of_row;\n            MPI_Send(&a[row_start_i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        max = 0;\n        for(int i = 0; i < number_of_row; i++)\n        {\n            if(max < a[row_start*N + i])\n                max = a[row_start*N + i];\n        }\n        for(int i = 1; i < number_of_process; i++)\n        {\n            MPI_Recv(&min, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n            if(max < min)\n                max = min;\n        }\n        result.push_back(max);\n        for(int i = 1; i < number_of_process; i++)\n        {\n            int row_start_i = i*number_of_row;\n            MPI_Send(&a[row_start_i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        max = 0;\n        for(int i = 0; i < number_of_row; i++)\n        {\n            if(max < a[row_start*N + i])\n                max = a[row_start*N + i];\n        }\n        for(int i = 1; i < number_of_process; i++)\n        {\n            MPI_Recv(&min, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n            if(max < min)\n                max = min;\n        }\n        result.push_back(max);\n        for(int i = 1; i < number_of_process; i++)\n        {\n            int row_start_i = i*number_of_row;\n            MPI_Send(&a[row_start_i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        max = 0;\n        for(int i = 0; i < number_of_row; i++)",
            "// -----------------------------------------------------------------------------------------\n    // -----------------------------------------------------------------------------------------\n    // YOUR CODE GOES HERE\n    // You're encouraged to make use of the provided variables to simplify your\n    // solution, but you can write your own as well.\n    // You're also encouraged to do this assignment using OMP, but you\n    // don't have to. Feel free to write the assignment any way that you\n    // want.\n\n    std::vector<bool> visited(N);\n    std::vector<int> component_count(N);\n    std::vector<int> component_idx(N, -1);\n    std::vector<int> component_size(N, 0);\n\n    // bfs to find all connected components\n    // use stack to simulate recursion\n    // find the largest component\n    for (int i = 0; i < N; ++i) {\n        if (visited[i])\n            continue;\n\n        std::stack<int> s;\n        s.push(i);\n        while (!s.empty()) {\n            int cur = s.top();\n            visited[cur] = true;\n\n            if (component_idx[cur] == -1) {\n                component_idx[cur] = component_count.size();\n                component_count.push_back(0);\n                component_size.push_back(0);\n            }\n\n            for (int j = 0; j < N; ++j) {\n                if (A[cur*N + j] &&!visited[j]) {\n                    component_count[component_idx[cur]]++;\n                    component_size[component_idx[cur]]++;\n                    s.push(j);\n                }\n            }\n            s.pop();\n        }\n    }\n\n    // find the largest component\n    int max_component_size = 0;\n    int max_component_idx = 0;\n    for (int i = 0; i < N; ++i) {\n        if (component_size[i] > max_component_size) {\n            max_component_size = component_size[i];\n            max_component_idx = i;\n        }\n    }\n\n    // count the number of vertices in the largest component\n    int component_size_sum = 0;\n    for (int i = 0; i < N; ++i) {\n        if (component_idx[i] == max_component_idx)\n            component_size_sum += component_size[i];\n    }\n\n    // -----------------------------------------------------------------------------------------\n    // -----------------------------------------------------------------------------------------\n\n    return component_size_sum;\n}",
            "// TODO: FILL THIS IN\n  return 0;\n}",
            "std::vector<bool> visited(N);\n\tint c = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tstd::queue<int> Q;\n\t\t\tQ.push(i);\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tint v = Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[v*N+j]) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tQ.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tvisited[v] = true;\n\t\t\t}\n\t\t\tc += 1;\n\t\t}\n\t}\n\treturn c;\n}",
            "int num_threads = 1;\n    int rank = 0;\n    int size = 1;\n\n    // Set number of threads to use.\n    //omp_set_num_threads(num_threads);\n\n    // Setup MPI.\n    //MPI_Comm_size(MPI_COMM_WORLD, &size);\n    //MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    //printf(\"[rank %d] Size: %d\\n\", rank, size);\n\n    // Store the number of vertices in the graph.\n    int n = N;\n\n    // Store the adjacency matrix.\n    std::vector<std::vector<int>> graph = A;\n\n    // Store the visited array.\n    std::vector<bool> visited(n, false);\n\n    // Store the component array.\n    std::vector<int> components(n, -1);\n\n    // Create a queue for BFS.\n    std::queue<int> q;\n\n    // Initialize the component counter to 0.\n    int component_count = 0;\n\n    // Traverse the graph.\n    #pragma omp parallel for schedule(dynamic, 1)\n    for (int i = 0; i < n; ++i) {\n        // Continue if the vertex has already been visited.\n        if (visited[i]) {\n            continue;\n        }\n\n        // Else, perform BFS from the vertex.\n        int component = 0;\n        q.push(i);\n        visited[i] = true;\n\n        while (!q.empty()) {\n            int index = q.front();\n            q.pop();\n            component++;\n\n            for (int j = 0; j < n; ++j) {\n                // Continue if the edge is not present.\n                if (!graph[index][j]) {\n                    continue;\n                }\n\n                // Else, add the neighbour to the queue.\n                q.push(j);\n                visited[j] = true;\n                components[j] = component;\n            }\n        }\n\n        // Store the largest component seen so far.\n        if (component > component_count) {\n            component_count = component;\n        }\n    }\n\n    // Store the largest component on rank 0.\n    int largest_component = component_count;\n\n    // Gather the results from all ranks.\n    //MPI_Reduce(&largest_component, &largest_component, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    // Return the largest component on rank 0.\n    //if (rank == 0) {\n    //    return largest_component;\n    //}\n\n    return largest_component;\n}",
            "// TODO: implement me\n\n  return 0;\n}",
            "// TODO\n}",
            "return 0;\n}",
            "const int rank = MPI_RANK;\n    const int size = MPI_SIZE;\n\n    // TODO: Your code here\n    if(rank == 0) {\n        int nbCompo = 0;\n        std::vector<int> nbCompoPerRank(size);\n        MPI_Status status;\n        MPI_Request req;\n\n        for(int i = 0; i < size; i++) {\n            if(i!= rank) {\n                MPI_Isend(A.data(), N*N, MPI_INT, i, 0, MPI_COMM_WORLD, &req);\n            }\n        }\n\n        for(int i = 0; i < size; i++) {\n            if(i!= rank) {\n                MPI_Recv(&nbCompoPerRank[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n            }\n            else {\n                nbCompoPerRank[rank] = largestComponent(A, N);\n            }\n        }\n\n        for(int i = 0; i < size; i++) {\n            nbCompo += nbCompoPerRank[i];\n        }\n        return nbCompo;\n\n    }\n    else {\n        return largestComponent(A, N);\n    }\n\n}",
            "int *counts = (int *)malloc(N * sizeof(int));\n\tmemset(counts, 0, N * sizeof(int));\n\tcounts[0] = 1;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcounts[i]++;\n\t\t\t\tcounts[j]++;\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tint max = counts[i];\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcounts[i] = max + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tint max = counts[0];\n\tfor (int i = 1; i < N; i++) {\n\t\tif (counts[i] > max)\n\t\t\tmax = counts[i];\n\t}\n\n\tfree(counts);\n\treturn max;\n}",
            "int mpi_size, mpi_rank, result = 0, size = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n  int A_start, A_end, i, j, k, cnt, idx = 0;\n  //std::vector<int> adj;\n  int* adj = new int[N*N];\n\n  int* rank_cnt = new int[mpi_size];\n  int* cnts = new int[mpi_size];\n\n  std::vector<int> visited(N, 0);\n\n  int size_chunk = N/mpi_size;\n  int remainder = N%mpi_size;\n\n  if (mpi_rank == 0) {\n    for (int i = 1; i < mpi_size; ++i) {\n      rank_cnt[i] = 0;\n    }\n  }\n\n  MPI_Barrier(MPI_COMM_WORLD);\n\n  for (int i = 0; i < mpi_size; ++i) {\n    cnts[i] = 0;\n  }\n\n  if (mpi_rank == 0) {\n    A_start = 0;\n    A_end = size_chunk + remainder;\n  } else {\n    A_start = size_chunk + remainder + (mpi_rank-1)*size_chunk;\n    A_end = A_start + size_chunk;\n  }\n\n  for (int i = 0; i < mpi_size; ++i) {\n    if (mpi_rank == i) {\n      for (int j = 0; j < N; ++j) {\n        for (int k = 0; k < N; ++k) {\n          if (A[j*N+k] == 1) {\n            adj[idx++] = j;\n          }\n        }\n      }\n      //std::cout << mpi_rank << \" \" << A_start << \" \" << A_end << std::endl;\n      //break;\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n    MPI_Bcast(&adj[0], idx, MPI_INT, i, MPI_COMM_WORLD);\n    MPI_Barrier(MPI_COMM_WORLD);\n  }\n\n  visited[A_start] = 1;\n  cnt = 1;\n  for (int i = 0; i < idx; ++i) {\n    if (visited[adj[i]] == 1) {\n      continue;\n    }\n    if (adj[i] >= A_start && adj[i] < A_end) {\n      visited[adj[i]] = 1;\n      cnt++;\n      //std::cout << \"visited \" << adj[i] << \" \" << mpi_rank << std::endl;\n    }\n  }\n\n  MPI_Reduce(&cnt, &size, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  MPI_Reduce(&size, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  //MPI_Reduce(&size, &rank_cnt[mpi_rank], 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  MPI_Gather(&size, 1, MPI_INT, &cnts[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (mpi_rank == 0) {\n    std::cout << mpi_rank << \" \" << result << std::endl;\n    for (int i = 0; i < mpi_size; ++i) {\n      std::cout << \"cnts[\" << i << \"] = \" << cnts[i] << std::endl;\n    }\n  }\n\n  MPI_Barrier(MPI_COMM_WORLD);\n\n  //std::cout << \"rank \"",
            "// TODO: Replace with your code\n    return 0;\n}",
            "/* Your code goes here! */\n\n  return -1;\n}",
            "//\n  // YOUR CODE HERE\n  //\n  // Your solution must be correct, and it must run in MPI and OpenMP.\n  //\n\n  return -1; // placeholder return\n}",
            "if (A.size()!= N*N) {\n    throw std::runtime_error(\"invalid adjacency matrix\");\n  }\n\n  // TODO: replace this with your code\n  return 0;\n}",
            "int numRank, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRank);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint vertsOnRank = N / numRank;\n\tint startIdx = vertsOnRank * rank;\n\tint endIdx = startIdx + vertsOnRank;\n\n\tint const numVerts = endIdx - startIdx;\n\tint const numEdges = numVerts * (numVerts - 1) / 2;\n\tint visited[numVerts];\n\tmemset(visited, 0, numVerts * sizeof(int));\n\n\t// We will use an OpenMP thread pool to compute the graph on a single rank in parallel\n\tomp_set_num_threads(4);\n\tstd::vector<int> visitedThreads(omp_get_max_threads());\n\tstd::vector<int> visitStack(numEdges);\n\n\tint numVisited = 0;\n\tint numVisitedThreads = 0;\n\tint numVisitedAllThreads = 0;\n\tint idxVisitedThreads = 0;\n\n\t// Start from vertex 0\n\tvisited[0] = 1;\n\tvisitStack[numVisited++] = 0;\n\tvisitedThreads[numVisitedThreads++] = 0;\n\tnumVisitedAllThreads++;\n\n\twhile (numVisitedAllThreads > 0) {\n\t\t// Find the next vertex to visit\n\t\tint vertToVisit = -1;\n\t\tint idxVertToVisit = -1;\n\t\tfor (int i = 0; i < numVisitedAllThreads; i++) {\n\t\t\tif (vertToVisit == -1 || visitedThreads[i] < vertToVisit) {\n\t\t\t\tvertToVisit = visitedThreads[i];\n\t\t\t\tidxVertToVisit = i;\n\t\t\t}\n\t\t}\n\n\t\t// Find the next edge to visit\n\t\tint edgeToVisit = -1;\n\t\tint idxEdgeToVisit = -1;\n\t\tint nextVisited = -1;\n\t\tfor (int i = 0; i < numVisited; i++) {\n\t\t\tint vert = visitStack[i];\n\t\t\tfor (int j = vert + 1; j < numVerts; j++) {\n\t\t\t\tif (A[vert + startIdx * N + j] == 1) {\n\t\t\t\t\tif (nextVisited == -1 || nextVisited > j) {\n\t\t\t\t\t\tnextVisited = j;\n\t\t\t\t\t\tedgeToVisit = i;\n\t\t\t\t\t\tidxEdgeToVisit = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (vertToVisit!= -1 && edgeToVisit!= -1) {\n\t\t\t// We found a valid vertex and edge to visit\n\t\t\tint vert = vertToVisit;\n\t\t\tint edge = edgeToVisit;\n\t\t\tint nextVert = idxEdgeToVisit;\n\t\t\tint iEdge = vert + startIdx * N + nextVert;\n\n\t\t\t// Do some work in parallel\n\t\t\t#pragma omp parallel for\n\t\t\tfor (int i = 0; i < numVisitedThreads; i++) {\n\t\t\t\tif (visited[visitedThreads[i]] == 0) {\n\t\t\t\t\tvisited[visitedThreads[i]] = 1;\n\t\t\t\t\tvisitStack[numVisited] = visitedThreads[i];\n\t\t\t\t\tvisitedThreads[numVisitedThreads++] = visitedThreads[i];\n\t\t\t\t\tnumVisitedAllThreads++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tnumVisitedThreads = 0;\n\n\t\t\tvisited[nextVert] = 1;\n\t\t\tvisitStack[numVisited] = nextVert;\n\t\t\tvisitedThreads[numVisitedThreads++] = nextVert;\n\t\t\tnumVisitedAllThread",
            "std::vector<int> visited(N, 0); // visited[i] = 1 if node i is already visited\n  std::vector<int> result(N, 0);  // result[i] = 1 if node i is in the largest component\n\n  int rank = omp_get_thread_num();\n\n  #pragma omp for\n  for (size_t node = 0; node < N; ++node) {\n    // Find all nodes in the largest component\n    std::function<void(int)> dfs = [&](int node) {\n      if (!visited[node]) {\n        visited[node] = 1;\n        result[node] = 1;\n        for (size_t otherNode = 0; otherNode < N; ++otherNode) {\n          if (A[node * N + otherNode] == 1) {\n            dfs(otherNode);\n          }\n        }\n      }\n    };\n    dfs(node);\n  }\n  MPI_Reduce(result.data(), result.data(), N, MPI_INT, MPI_LOR, 0, MPI_COMM_WORLD);\n  return std::count(result.begin(), result.end(), 1);\n}",
            "// TODO: Implement this function\n}",
            "std::vector<std::vector<int>> v(N, std::vector<int>(N));\n\tstd::vector<int> q;\n\tint num_comps;\n\tint size = A.size();\n\tfor (int i = 0; i < size; i++)\n\t{\n\t\tfor (int j = 0; j < size; j++)\n\t\t{\n\t\t\tv[i][j] = A[i * size + j];\n\t\t}\n\t}\n\t//std::vector<int> m;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (v[i][j] == 1)\n\t\t\t{\n\t\t\t\tq.push_back(j);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\twhile (!q.empty())\n\t{\n\t\tfor (int i = 0; i < q.size(); i++)\n\t\t{\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif (v[q[i]][j] == 1)\n\t\t\t\t{\n\t\t\t\t\tv[q[i]][j] = 0;\n\t\t\t\t\tfor (int k = 0; k < N; k++)\n\t\t\t\t\t{\n\t\t\t\t\t\tv[j][k] = 0;\n\t\t\t\t\t}\n\t\t\t\t\tq.push_back(j);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tnum_comps++;\n\t\tq.clear();\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif (v[i][j] == 1)\n\t\t\t\t{\n\t\t\t\t\tq.push_back(j);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn num_comps;\n}",
            "// Your code here!\n}",
            "int rank = 0;\n    int size = 1;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int* sub = new int[N * N / size];\n\n    #pragma omp parallel for\n    for(size_t i = 0; i < N * N / size; i++) {\n        sub[i] = A[i];\n    }\n\n    int num_components = 0;\n    int* visited = new int[N];\n    for(size_t i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n\n    for(size_t i = 0; i < N; i++) {\n        if(visited[i] == 0) {\n            int num_v = 0;\n            std::queue<int> q;\n            q.push(i);\n            visited[i] = 1;\n            while(!q.empty()) {\n                int tmp = q.front();\n                q.pop();\n                for(size_t j = 0; j < N; j++) {\n                    if(visited[j] == 0 && sub[tmp * N + j] == 1) {\n                        visited[j] = 1;\n                        q.push(j);\n                    }\n                }\n                num_v++;\n            }\n\n            if(num_v > num_components) {\n                num_components = num_v;\n            }\n        }\n    }\n\n    int max_components = 0;\n    MPI_Reduce(&num_components, &max_components, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    if(rank == 0) {\n        return max_components;\n    }\n\n    return -1;\n}",
            "// TODO: Implement this function.\n\tint num_ranks, my_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\tint *visited = new int[N];\n\tint *visited_temp = new int[N];\n\tint *ccomp = new int[N];\n\tint *ccomp_temp = new int[N];\n\tint *max_ccomp = new int[N];\n\tmemset(visited, 0, sizeof(int) * N);\n\tmemset(visited_temp, 0, sizeof(int) * N);\n\tmemset(ccomp, 0, sizeof(int) * N);\n\tmemset(ccomp_temp, 0, sizeof(int) * N);\n\tmemset(max_ccomp, 0, sizeof(int) * N);\n\tint start, end;\n\tint max = 0;\n\tstart = (my_rank * N) / num_ranks;\n\tend = ((my_rank + 1) * N) / num_ranks;\n\t//BFS\n\tint queue[N];\n\tint count = 0, queue_count = 0;\n\tint count_temp = 0, queue_count_temp = 0;\n\tint head = 0, tail = 0;\n\tint head_temp = 0, tail_temp = 0;\n\tint temp = 0;\n\tint max_size = 0;\n\tint max_size_temp = 0;\n\tint i, j, v;\n\tfor (i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tqueue[tail] = i;\n\t\t\tvisited[i] = 1;\n\t\t\tccomp[i] = 1;\n\t\t\ttail++;\n\t\t}\n\t}\n\twhile (head < tail) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tv = queue[head];\n\t\t\tif (A[v * N + j] &&!visited[j]) {\n\t\t\t\tqueue[tail] = j;\n\t\t\t\tvisited[j] = 1;\n\t\t\t\tccomp[j] = ccomp[v] + 1;\n\t\t\t\ttail++;\n\t\t\t}\n\t\t}\n\t\thead++;\n\t}\n\tqueue_count = tail - head;\n\tmax_size = queue_count;\n\thead = tail = 0;\n\t//max_ccomp\n\tfor (i = 0; i < N; i++) {\n\t\tif (ccomp[i] > max) {\n\t\t\tmax = ccomp[i];\n\t\t}\n\t}\n\tmax_ccomp[my_rank] = max;\n\tMPI_Reduce(max_ccomp, max_ccomp_temp, num_ranks, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif (my_rank == 0) {\n\t\tmax = max_ccomp_temp[0];\n\t\tfor (i = 1; i < num_ranks; i++) {\n\t\t\tif (max_ccomp_temp[i] > max) {\n\t\t\t\tmax = max_ccomp_temp[i];\n\t\t\t}\n\t\t}\n\t}\n\tdelete[] visited;\n\tdelete[] visited_temp;\n\tdelete[] ccomp;\n\tdelete[] ccomp_temp;\n\tdelete[] max_ccomp;\n\treturn max;\n}",
            "int compCount = 0;\n\n    std::vector<bool> visited(N*N);\n    std::vector<int> stack;\n    std::vector<int> adj(N);\n    std::vector<int> comp;\n\n    // find each connected component in the graph\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            comp.clear();\n            stack.clear();\n            stack.push_back(i);\n            while (!stack.empty()) {\n                int v = stack.back();\n                visited[v] = true;\n                comp.push_back(v);\n                for (int j = 0; j < N; ++j) {\n                    if (A[v*N + j] == 1 &&!visited[j]) {\n                        stack.push_back(j);\n                    }\n                }\n                stack.pop_back();\n            }\n            // make the component size odd\n            if (comp.size() % 2 == 0) {\n                comp.pop_back();\n            }\n\n            // if the component is large enough, add it to the list of components\n            if (comp.size() >= 2) {\n                adj.clear();\n                for (int i = 0; i < comp.size(); ++i) {\n                    for (int j = 0; j < i; ++j) {\n                        if (A[comp[i] * N + comp[j]] == 1) {\n                            adj.push_back(comp[i] * N + comp[j]);\n                        }\n                    }\n                }\n\n                // check if the component is connected\n                for (int i = 0; i < adj.size(); ++i) {\n                    int v1 = adj[i] / N;\n                    int v2 = adj[i] % N;\n                    if (comp.back()!= v1 && comp.back()!= v2) {\n                        compCount = comp.size();\n                        goto end;\n                    }\n                }\n\n                // remove the last vertex\n                comp.pop_back();\n\n                // if the component is still large enough, add it to the list of components\n                if (comp.size() >= 2) {\n                    compCount = comp.size();\n                    goto end;\n                }\n            }\n        }\n    }\n\n    end:\n    return compCount;\n}",
            "// TODO: Replace this code with a correct implementation.\n  assert(A.size() == N*N);\n  return 0;\n}",
            "auto m = A.data();\n    // BEGIN_YOUR_CODE\n    // use MPI and OpenMP to compute in parallel\n    // END_YOUR_CODE\n    return 0;\n}",
            "// TODO\n}",
            "int rank;\n    int world_size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n    int *counts = new int[world_size];\n    for(int i = 0; i < world_size; i++) {\n        counts[i] = 0;\n    }\n\n    int i, j, max_count = 0;\n    if(rank == 0) {\n        for(i = 0; i < N; i++) {\n            for(j = 0; j < N; j++) {\n                if(A[i * N + j] == 1) {\n                    counts[j / N]++;\n                    if(counts[j / N] > max_count) {\n                        max_count = counts[j / N];\n                    }\n                }\n            }\n        }\n    }\n\n    MPI_Bcast(&max_count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int num_threads;\n#pragma omp parallel\n    {\n        num_threads = omp_get_num_threads();\n    }\n\n    counts = new int[num_threads];\n    for(int i = 0; i < num_threads; i++) {\n        counts[i] = 0;\n    }\n\n#pragma omp parallel\n    {\n        int count = 0;\n        int thread_rank = omp_get_thread_num();\n\n        for(i = 0; i < N; i++) {\n            for(j = 0; j < N; j++) {\n                if(A[i * N + j] == 1) {\n                    counts[thread_rank]++;\n                    if(counts[thread_rank] > count) {\n                        count = counts[thread_rank];\n                    }\n                }\n            }\n        }\n\n        int *result = new int[num_threads];\n        MPI_Reduce(counts + thread_rank, result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n        if(rank == 0) {\n            if(result[thread_rank] > max_count) {\n                max_count = result[thread_rank];\n            }\n        }\n    }\n\n    MPI_Bcast(&max_count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    return max_count;\n}",
            "// TODO: your code here\n\t\n\tint largest_comp = 0;\n\n\tint size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0){\n\t\tlargest_comp = 0;\n\t\tfor (int i = 1; i < size; i++){\n\t\t\tint l_comp = 0;\n\t\t\tMPI_Recv(&l_comp, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tif (largest_comp < l_comp){\n\t\t\t\tlargest_comp = l_comp;\n\t\t\t}\n\t\t}\n\t}\n\telse{\n\t\tstd::vector<int> local_A;\n\t\tlocal_A.resize(N*N);\n\t\tfor (int i = rank*N; i < (rank + 1)*N; i++){\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tlocal_A[i*N + j] = A[i*N + j];\n\t\t\t}\n\t\t}\n\t\tstd::vector<int> comp(N, 0);\n\t\tint i = 0;\n\t\twhile (i < N){\n\t\t\tif (comp[i] == 0){\n\t\t\t\tint j = i;\n\t\t\t\twhile (j < N){\n\t\t\t\t\tif (local_A[i*N + j] == 1){\n\t\t\t\t\t\tcomp[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t\tj++;\n\t\t\t\t}\n\t\t\t\ti = 0;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\t\tint largest_comp = 0;\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (comp[i] == 1){\n\t\t\t\tlargest_comp++;\n\t\t\t}\n\t\t}\n\t\tif (rank == 0){\n\t\t\tMPI_Send(&largest_comp, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\treturn largest_comp;\n}",
            "// TODO: Your code here\n\n}",
            "const int P = omp_get_num_threads();\n    int *c = new int[P];\n    int *c_tmp = new int[P];\n\n    for (size_t i = 0; i < N; i++) {\n        int tmp = 0;\n        for (size_t j = 0; j < N; j++) {\n            tmp += A[i * N + j];\n        }\n        c[i % P] = tmp;\n    }\n\n    for (size_t p = 1; p < P; p++) {\n        MPI_Send(c + p, 1, MPI_INT, p, 0, MPI_COMM_WORLD);\n    }\n\n    int m = 0;\n    for (size_t p = 0; p < P; p++) {\n        MPI_Recv(c_tmp + p, 1, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        m = std::max(m, c_tmp[p]);\n    }\n\n    return m;\n}",
            "// TODO\n}",
            "// TODO: Fill this in.\n  return 0;\n}",
            "return 0;\n}",
            "int mpi_size, mpi_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n\tint rank_cnt = (int)N / mpi_size;\n\tint mod = (int)N % mpi_size;\n\tint local_cnt = rank_cnt;\n\n\tif (mod!= 0) {\n\t\tif (mpi_rank < mod) {\n\t\t\tlocal_cnt++;\n\t\t}\n\t\telse {\n\t\t\tlocal_cnt--;\n\t\t}\n\t}\n\n\t// The total number of vertices\n\tint size = local_cnt * local_cnt;\n\n\tif (mpi_rank == 0) {\n\t\tstd::vector<int> result(size, 0);\n\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < (int)A.size(); i++) {\n\t\t\tfor (int j = 0; j < (int)A.size(); j++) {\n\t\t\t\tif (i == j) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (A[i] > 0 && A[j] > 0) {\n\t\t\t\t\tint i_row = i / local_cnt;\n\t\t\t\t\tint i_col = i % local_cnt;\n\t\t\t\t\tint j_row = j / local_cnt;\n\t\t\t\t\tint j_col = j % local_cnt;\n\n\t\t\t\t\tif (i_row == j_row || i_row == j_col || i_col == j_row || i_col == j_col) {\n\t\t\t\t\t\tresult[i * local_cnt + j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tstd::vector<int> buf_send(size);\n\t\tstd::vector<int> buf_recv(size);\n\n\t\tint src = 0;\n\t\tfor (int i = 1; i < mpi_size; i++) {\n\t\t\tMPI_Send(result.data(), size, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t}\n\n\t\tfor (int i = 1; i < mpi_size; i++) {\n\t\t\tMPI_Recv(buf_recv.data(), size, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t\t\tfor (int j = 0; j < size; j++) {\n\t\t\t\tif (result[j] > 0 || buf_recv[j] > 0) {\n\t\t\t\t\tresult[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tint max_size = 0;\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tif (result[i] > 0) {\n\t\t\t\tmax_size++;\n\t\t\t}\n\t\t}\n\n\t\treturn max_size;\n\t}\n\telse {\n\t\tstd::vector<int> result(size, 0);\n\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < (int)A.size(); i++) {\n\t\t\tfor (int j = 0; j < (int)A.size(); j++) {\n\t\t\t\tif (i == j) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif (A[i] > 0 && A[j] > 0) {\n\t\t\t\t\tint i_row = i / local_cnt;\n\t\t\t\t\tint i_col = i % local_cnt;\n\t\t\t\t\tint j_row = j / local_cnt;\n\t\t\t\t\tint j_col = j % local_cnt;\n\n\t\t\t\t\tif (i_row == j_row || i_row == j_col || i_col == j_row",
            "int result;\n\n\t// TODO: Implement parallel breadth-first search.\n\t// You can assume that the graph is connected, but you should not assume that it is a tree.\n\t// Use OpenMP to parallelize the BFS algorithm on each rank.\n\t// Use MPI to combine the results from all ranks.\n\t// A hint: It may be helpful to have a function to compute the number of components in a graph.\n\n\treturn result;\n}",
            "std::vector<int> componentSize(N);\n    // your code here\n    return 0;\n}",
            "const int rank = 0;\n  const int size = 0;\n\n  // TODO: Your code here\n\n  return -1;\n}",
            "int* A_local = new int[N * N];\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      A_local[i * N + j] = A[i * N + j];\n    }\n  }\n\n  // Your code here\n\n  int* visited = new int[N];\n  int max = 0;\n  int max_count = 0;\n  int visited_count = 0;\n  int n = 0;\n\n  #pragma omp parallel\n  {\n    int private_max = 0;\n    int private_count = 0;\n    #pragma omp for schedule(static)\n    for (int i = 0; i < N; ++i) {\n      if (visited[i] == 0) {\n        int temp = DFS(i, A_local, N, visited, &private_count);\n        if (private_max < temp) {\n          private_max = temp;\n        }\n        if (max < private_max) {\n          #pragma omp critical\n          {\n            max = private_max;\n          }\n        }\n      }\n    }\n    #pragma omp atomic\n    max_count += private_count;\n  }\n\n  if (visited_count!= max_count) {\n    throw std::invalid_argument(\"not all the nodes are visited\");\n  }\n\n  return max;\n}",
            "return 0;\n}",
            "// TODO: your code here\n\tint largest = 0;\n\tint num_component = 0;\n\tint visited[N];\n\n\tomp_set_num_threads(2);\n#pragma omp parallel shared(A, visited) private(largest, num_component)\n\t{\n\t\tint i, j;\n\t\tint rank = omp_get_thread_num();\n\t\tint size = omp_get_num_threads();\n\t\tfor (i = rank; i < N; i += size) {\n\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\tvisited[j] = 0;\n\t\t\t}\n\t\t\tint count = 0;\n\t\t\tif (A[i * N + i] == 1) {\n\t\t\t\tcount = 1;\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tint q[N];\n\t\t\t\tq[0] = i;\n\t\t\t\tint front = 0;\n\t\t\t\tint rear = 0;\n\t\t\t\twhile (front <= rear) {\n\t\t\t\t\tint u = q[front];\n\t\t\t\t\tfront++;\n\t\t\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[u * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\t\tcount++;\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t\tq[++rear] = j;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (count > largest) {\n\t\t\t\tlargest = count;\n\t\t\t\tnum_component = 1;\n\t\t\t}\n\t\t\telse if (count == largest) {\n\t\t\t\tnum_component++;\n\t\t\t}\n\t\t}\n\t}\n\treturn largest;\n}",
            "// TODO: Implement this function\n  return 0;\n}",
            "std::vector<int> visited(N, 0);\n  int largest_component_size = 0;\n  for (int i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      std::queue<int> BFS;\n      int vertex = i;\n      BFS.push(i);\n      while (!BFS.empty()) {\n        int current_vertex = BFS.front();\n        BFS.pop();\n        for (int j = 0; j < N; ++j) {\n          if (A[current_vertex * N + j] == 1 && visited[j] == 0) {\n            visited[j] = 1;\n            BFS.push(j);\n          }\n        }\n      }\n    }\n  }\n  return largest_component_size;\n}",
            "int result = 0;\n  bool *visited = new bool[N];\n  std::fill_n(visited, N, false);\n  visited[0] = true;\n  result = 1;\n  #pragma omp parallel for\n  for (size_t v = 1; v < N; ++v) {\n    #pragma omp atomic update\n    if (visited[v])\n      ++result;\n    for (size_t u = 0; u < N; ++u) {\n      if (visited[u] && A[u * N + v])\n        visited[v] = true;\n    }\n  }\n  delete[] visited;\n  return result;\n}",
            "int* A_ = new int[N*N];\n\tstd::copy(A.begin(), A.end(), A_);\n\n\tint r = 0;\n\tfor (int i = 0; i < N*N; i++) {\n\t\tif (A_[i] == 1) {\n\t\t\tr = i/N;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t//#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A_[i*N+j] == 1) {\n\t\t\t\tint max = r > i? r : i;\n\t\t\t\tint min = r > i? i : r;\n\t\t\t\tmax = max > j? max : j;\n\t\t\t\tmin = min > j? min : j;\n\t\t\t\tA_[i*N+j] = A_[min*N+max];\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> const A__ = std::vector<int>(A_, A_+N*N);\n\tstd::vector<int> const A___ = std::vector<int>(A__);\n\n\tint* B = new int[N*N];\n\tstd::copy(A__.begin(), A__.end(), B);\n\n\tint* C = new int[N*N];\n\tstd::copy(A___.begin(), A___.end(), C);\n\n\tint* D = new int[N*N];\n\tstd::copy(A__.begin(), A__.end(), D);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tB[i*N+j] = 0;\n\t\t\tC[i*N+j] = 0;\n\t\t\tD[i*N+j] = 0;\n\t\t}\n\t}\n\n\tint* E = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tE[i] = 0;\n\t}\n\n\tint* F = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tF[i] = 0;\n\t}\n\n\tint* G = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tG[i] = 0;\n\t}\n\n\tint* H = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tH[i] = 0;\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A_[i*N+j] == 1) {\n\t\t\t\tint r1 = A_[i*N+j]/N;\n\t\t\t\tint c1 = A_[i*N+j]%N;\n\t\t\t\tint r2 = A_[j*N+i]/N;\n\t\t\t\tint c2 = A_[j*N+i]%N;\n\t\t\t\tB[i*N+j] = A_[r1*N+c2];\n\t\t\t\tC[i*N+j] = A_[c1*N+r2];\n\t\t\t\tD[i*N+j] = A_[c1*N+c2];\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (B[i*N+j] == 1) {\n\t\t\t\tE[i] = 1;\n\t\t\t}\n\t\t\tif (C[i*N+j] == 1) {\n\t\t\t\tF[i] = 1;\n\t\t\t}\n\t\t\tif (D[i*",
            "std::vector<std::vector<int>> A_new(N, std::vector<int>(N,0));\n    std::vector<std::vector<int>> B(N, std::vector<int>(N,0));\n    std::vector<std::vector<int>> C(N, std::vector<int>(N,0));\n    int p = omp_get_num_threads();\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    std::vector<std::vector<int>> A_rank(N, std::vector<int>(N,0));\n    for (int i=0; i<N; i++) {\n        for (int j=0; j<N; j++) {\n            A_rank[i][j] = A[i*N + j];\n        }\n    }\n    if (rank == 0) {\n        for (int i=0; i<N; i++) {\n            for (int j=0; j<N; j++) {\n                A_new[i][j] = A[i*N + j];\n            }\n        }\n    }\n    for (int k=0; k<p; k++) {\n        MPI_Bcast(A_new[0].data(), N*N, MPI_INT, 0, MPI_COMM_WORLD);\n        MPI_Barrier(MPI_COMM_WORLD);\n        for (int i=rank; i<N; i+=p) {\n            for (int j=0; j<N; j++) {\n                A_new[i][j] = 0;\n                B[i][j] = 0;\n            }\n        }\n        MPI_Barrier(MPI_COMM_WORLD);\n        #pragma omp parallel for num_threads(p)\n        for (int i=0; i<N; i++) {\n            for (int j=0; j<N; j++) {\n                C[i][j] = 0;\n                if (A_new[i][j] == 1) {\n                    B[i][j] = 1;\n                }\n            }\n        }\n        MPI_Barrier(MPI_COMM_WORLD);\n        #pragma omp parallel for num_threads(p)\n        for (int k=0; k<N; k++) {\n            for (int i=rank; i<N; i+=p) {\n                for (int j=0; j<N; j++) {\n                    if (A_rank[i][k] == 1) {\n                        C[i][j] = 1;\n                    }\n                }\n            }\n        }\n        MPI_Barrier(MPI_COMM_WORLD);\n        for (int i=rank; i<N; i+=p) {\n            for (int j=0; j<N; j++) {\n                A_new[i][j] = 0;\n            }\n        }\n        MPI_Barrier(MPI_COMM_WORLD);\n        #pragma omp parallel for num_threads(p)\n        for (int i=0; i<N; i++) {\n            for (int j=0; j<N; j++) {\n                for (int k=0; k<N; k++) {\n                    A_new[i][j] += C[i][k] * B[k][j];\n                }\n                if (A_new[i][j] == 1) {\n                    A_new[i][j] = 1;\n                } else {\n                    A_new[i][j] = 0;\n                }\n            }\n        }\n    }\n    int c=0;\n    for (int i=0; i<N; i++) {\n        if (A_new[i][i] == 1) {\n            c++;\n        }\n    }\n    return c;\n}",
            "return 0;\n}",
            "int res = 0;\n  int num_processes;\n  int rank;\n  int component_size;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  std::vector<int> component_sizes;\n  int *component_sizes_array = (int *) malloc(sizeof(int) * num_processes);\n  component_sizes_array[rank] = 0;\n  MPI_Gather(component_sizes_array + rank, 1, MPI_INT, component_sizes_array, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    for (int i = 0; i < num_processes; ++i) {\n      if (component_sizes_array[i] > component_size) {\n        component_size = component_sizes_array[i];\n      }\n    }\n  }\n  MPI_Bcast(&component_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return component_size;\n}",
            "/*\n\t *\tFor every vertex we check every other vertex, if they are in the same component\n\t *\twe merge them.\n\t */\n\n\tstd::vector<std::vector<int>> subgraphs(N, std::vector<int>(N, -1));\n\n\t// Make subgraphs and merge them\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1 && A[j * N + i] == 1) {\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (subgraphs[i][k]!= -1 && subgraphs[j][k]!= -1) {\n\t\t\t\t\t\tsubgraphs[i][k] = subgraphs[j][k];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the maximum size of all subgraphs\n\tint max_size = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint size = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (subgraphs[i][j]!= -1) {\n\t\t\t\tsize++;\n\t\t\t}\n\t\t}\n\t\tif (size > max_size) {\n\t\t\tmax_size = size;\n\t\t}\n\t}\n\n\treturn max_size;\n}",
            "int num_components = 0;\n  #pragma omp parallel for num_threads(1) reduction(max:num_components)\n  for(size_t i = 0; i < N; ++i) {\n    int component = 0;\n    for(size_t j = 0; j < N; ++j) {\n      if(A[i*N+j] == 1) {\n        ++component;\n      }\n    }\n    num_components = std::max(num_components, component);\n  }\n  return num_components;\n}",
            "// You can assume that A is an NxN adjacency matrix stored in row-major.\n\n    std::vector<bool> visited(N, false);\n    std::vector<int> component_size(N, 0);\n\n    // Do the BFS for each vertex and count the size of the component\n    for(int i = 0; i < N; ++i){\n        if(visited[i]) continue;\n\n        std::queue<int> q;\n        q.push(i);\n        visited[i] = true;\n        component_size[i] = 1;\n\n        while(!q.empty()){\n            int vertex = q.front();\n            q.pop();\n\n            for(int j = 0; j < N; ++j){\n                if(A[vertex * N + j] == 1 &&!visited[j]){\n                    q.push(j);\n                    visited[j] = true;\n                    component_size[i]++;\n                }\n            }\n        }\n    }\n\n    // Get the size of the largest component\n    int max_component_size = *std::max_element(component_size.begin(), component_size.end());\n\n    // Check if the result is the same among all ranks\n    int rank;\n    int world_size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n    std::vector<int> max_component_size_on_other_ranks(world_size, 0);\n    MPI_Gather(&max_component_size, 1, MPI_INT, max_component_size_on_other_ranks.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if(rank == 0){\n        int global_max = *std::max_element(max_component_size_on_other_ranks.begin(), max_component_size_on_other_ranks.end());\n        return global_max;\n    }\n\n    return max_component_size;\n}",
            "auto num_tasks = omp_get_num_threads();\n    auto chunk_size = N/num_tasks;\n    std::vector<int> component_sizes(num_tasks, 0);\n\n    #pragma omp parallel\n    {\n        auto tid = omp_get_thread_num();\n        auto start = tid*chunk_size;\n        auto end = start + chunk_size;\n        if (start == N) {\n            continue;\n        }\n        if (end > N) {\n            end = N;\n        }\n        std::vector<bool> visited(N, false);\n        std::queue<int> queue;\n        queue.push(start);\n        visited[start] = true;\n        while (!queue.empty()) {\n            auto v = queue.front();\n            queue.pop();\n            for (size_t w = 0; w < N; ++w) {\n                if (w == v) {\n                    continue;\n                }\n                if (A[v*N + w] &&!visited[w]) {\n                    queue.push(w);\n                    visited[w] = true;\n                }\n            }\n        }\n        component_sizes[tid] = visited.size();\n    }\n    MPI_Reduce(component_sizes.data(), component_sizes.data(), component_sizes.size(), MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return component_sizes[0];\n}",
            "int result = 0;\n    std::vector<bool> visited(N, false);\n    // Your code here\n    return result;\n}",
            "MPI_Status status;\n\tint num_procs;\n\tint my_rank;\n\t\n\t\n\t\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\t\n\tint* recvbuf = NULL;\n\t\n\tint* subgraph = NULL;\n\t\n\t\n\t\n\t\n\tint size_subgraph = N/num_procs;\n\t\n\tint start = my_rank * size_subgraph;\n\tint end = start + size_subgraph;\n\t\n\t\n\t\n\t\n\t\n\t\n\trecvbuf = (int*) malloc(size_subgraph * size_subgraph * sizeof(int));\n\tsubgraph = (int*) malloc(size_subgraph * size_subgraph * sizeof(int));\n\t\n\t\n\t\n\t\n\t\n\tfor(int i = 0; i < size_subgraph; ++i) {\n\t\tfor(int j = 0; j < size_subgraph; ++j) {\n\t\t\tsubgraph[i * size_subgraph + j] = A[start + i * N + j];\n\t\t}\n\t}\n\t\n\t\n\t\n\t\n\t\n\tMPI_Barrier(MPI_COMM_WORLD);\n\t\n\tMPI_Gather(subgraph, size_subgraph * size_subgraph, MPI_INT, recvbuf, size_subgraph * size_subgraph, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\t\n\t\n\t\n\t\n\tif(my_rank == 0) {\n\t\t\n\t\tint* visited = (int*) malloc(N * sizeof(int));\n\t\t\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tvisited[i] = 0;\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tint size = 0;\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\t\n\t\t\tif(!visited[i]) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tint j = i;\n\t\t\t\t\n\t\t\t\twhile(!visited[j]) {\n\t\t\t\t\t\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\n\t\t\t\t\tfor(int k = 0; k < N; ++k) {\n\t\t\t\t\t\t\n\t\t\t\t\t\tif(A[j * N + k] &&!visited[k]) {\n\t\t\t\t\t\t\tj = k;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t++size;\n\t\t\t}\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tfor(int i = 0; i < num_procs; ++i) {\n\t\t\t\n\t\t\tfor(int j = 0; j < size_subgraph; ++j) {\n\t\t\t\t\n\t\t\t\tfor(int k = 0; k < size_subgraph; ++k) {\n\t\t\t\t\t\n\t\t\t\t\tif(recvbuf[i * size_subgraph * size_subgraph + j * size_subgraph + k]) {\n\t\t\t\t\t\t\n\t\t\t\t\t\tint l = start + j * N + k;\n\t\t\t\t\t\t\n\t\t\t\t\t\tif(!visited[l]) {",
            "//...\n\n\treturn 0;\n}",
            "int result = 0;\n  std::vector<bool> visited(N, false);\n  int count = 0;\n  std::vector<int> queue;\n  #pragma omp parallel\n  {\n    #pragma omp for\n    for(int i=0; i<N; i++){\n      visited[i] = true;\n      count = 1;\n      queue.push_back(i);\n      while(!queue.empty()){\n        int current = queue.back();\n        queue.pop_back();\n        for(int j=0; j<N; j++){\n          if(A[current*N+j] &&!visited[j]){\n            visited[j] = true;\n            queue.push_back(j);\n            count++;\n          }\n        }\n      }\n    }\n    #pragma omp critical\n    {\n      if(count>result){\n        result = count;\n      }\n    }\n  }\n  return result;\n}",
            "// TODO: implement this function\n}",
            "std::vector<int> colors(N, -1);\n    std::vector<int> size(N, 0);\n    std::vector<int> sizeReduce(N, 0);\n    std::vector<int> parent(N, -1);\n\n    int rank, p, i, j;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // find largest connected component\n#pragma omp parallel\n    {\n        // each thread colors its part of the graph\n#pragma omp for\n        for (i = 0; i < N; ++i) {\n            if (colors[i] == -1) {\n                color(i, colors, parent, size);\n            }\n        }\n\n        // reduce color sizes\n        MPI_Reduce(size.data(), sizeReduce.data(), N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    }\n\n    // find the largest component\n    int largest = 0;\n    for (i = 0; i < N; ++i) {\n        if (sizeReduce[i] > largest)\n            largest = sizeReduce[i];\n    }\n\n    // return size\n    int result;\n    MPI_Reduce(&largest, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return result;\n}",
            "int N_procs;\n  MPI_Comm_size(MPI_COMM_WORLD, &N_procs);\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (rank == 0) {\n    // We only need one thread on rank 0\n    omp_set_num_threads(1);\n  } else {\n    // We need at least as many threads as there are processes\n    // to get the max value\n    omp_set_num_threads(N_procs);\n  }\n\n  // For each vertex, we need a \"count\" (initially 0)\n  // and a \"flag\" (initially false)\n  // to indicate whether we've been visited yet\n  std::vector<int> counts(N, 0);\n  std::vector<bool> flags(N, false);\n  int largestComponent = 0;\n\n  // Iterate over the rows of the matrix\n  for (size_t i = 0; i < N; ++i) {\n    // Don't check rows that we've already visited\n    if (!flags[i]) {\n      // Set the flag and start the count at 1\n      flags[i] = true;\n      counts[i] = 1;\n\n      // If this is rank 0, we have to do the counting\n      if (rank == 0) {\n        // Go through all the columns of the current row\n        for (size_t j = 0; j < N; ++j) {\n          // If the entry is set, visit that vertex\n          if (A[i*N+j]) {\n            // Check if we've already visited it\n            if (flags[j]) {\n              counts[i] += counts[j];\n            } else {\n              flags[j] = true;\n              counts[i]++;\n            }\n          }\n        }\n      } else {\n        // If this isn't rank 0, just send the counts\n        MPI_Send(&counts[i], 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n      }\n    }\n  }\n\n  // If this isn't rank 0, receive the counts and return\n  if (rank!= 0) {\n    MPI_Recv(&counts[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    return largestComponent;\n  }\n\n  // We're rank 0, so we need to get the largest component size\n  // and return it\n  for (size_t i = 0; i < N; ++i) {\n    largestComponent = std::max(largestComponent, counts[i]);\n  }\n\n  // Send counts to other processes\n  for (int i = 1; i < N_procs; ++i) {\n    MPI_Send(&counts[0], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n  }\n\n  // Return the largest component size\n  return largestComponent;\n}",
            "// 0. Set the number of ranks in the communicator.\n  int num_ranks;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n  // 1. Set the rank.\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // 2. Set the number of threads.\n  int num_threads = omp_get_num_procs();\n\n  // 3. Set the number of rows and columns for each rank.\n  size_t Nrows_per_rank = N / num_ranks;\n  size_t Ncols_per_rank = N / num_ranks;\n\n  // 4. Set the row offset for each rank.\n  size_t row_offset = rank * Nrows_per_rank;\n\n  // 5. Set the column offset for each rank.\n  size_t col_offset = rank * Ncols_per_rank;\n\n  // 6. Set the number of rows and columns for each thread.\n  size_t Nrows_per_thread = Nrows_per_rank / num_threads;\n  size_t Ncols_per_thread = Ncols_per_rank / num_threads;\n\n  // 7. Set the row offset for each thread.\n  size_t row_offset_thread = rank * Nrows_per_rank;\n\n  // 8. Set the column offset for each thread.\n  size_t col_offset_thread = rank * Ncols_per_rank;\n\n  // 9. Set the number of rows and columns for each thread.\n  size_t Nrows_per_thread_thread = Nrows_per_thread / num_threads;\n  size_t Ncols_per_thread_thread = Ncols_per_thread / num_threads;\n\n  // 10. Initialize the visited array.\n  std::vector<bool> visited(N, false);\n\n  // 11. Initialize the component array.\n  std::vector<int> component(N, -1);\n\n  // 12. Initialize the component counter.\n  int component_counter = 0;\n\n  // 13. Initialize the largest component counter.\n  int largest_component_counter = 0;\n\n  // 14. Initialize the connected_to array.\n  std::vector<int> connected_to(N);\n\n  // 15. Set the local component counter for each rank.\n  int local_component_counter = 0;\n\n  // 16. Set the local largest component counter for each rank.\n  int local_largest_component_counter = 0;\n\n  // 17. Set the first index of the first component for each rank.\n  int first_index_of_first_component = -1;\n\n  // 18. Loop over all threads.\n  #pragma omp parallel num_threads(num_threads)\n  {\n\n    // 19. Initialize the visited array for each thread.\n    std::vector<bool> visited_thread(N, false);\n\n    // 20. Initialize the component array for each thread.\n    std::vector<int> component_thread(N, -1);\n\n    // 21. Initialize the connected_to array for each thread.\n    std::vector<int> connected_to_thread(N);\n\n    // 22. Initialize the local component counter for each thread.\n    int local_component_counter_thread = 0;\n\n    // 23. Initialize the local largest component counter for each thread.\n    int local_largest_component_counter_thread = 0;\n\n    // 24. Initialize the first index of the first component for each thread.\n    int first_index_of_first_component_thread = -1;\n\n    // 25. Get the thread id.\n    int thread_id = omp_get_thread_num();\n\n    // 26. Loop over the matrix in chunks.\n    #pragma omp for schedule(static)\n    for (size_t i = 0; i < Nrows_per_rank; i++) {\n\n      // 27. Compute the row index of the first vertex in the current chunk.\n      size_t row_i = row_offset + i;",
            "return -1;\n}",
            "std::vector<std::vector<int>> B = A;\n\n\tint count_of_vertices = 0;\n\tint max_component = 0;\n\tint count_of_vertices_in_component = 0;\n\tint num_of_nodes = 0;\n\tint component_id = 1;\n\tint i,j;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &num_of_nodes);\n\n\tomp_set_num_threads(num_of_nodes);\n\n\t#pragma omp parallel default(shared) private(i, j, count_of_vertices, count_of_vertices_in_component, max_component)\n\t{\n\t\tint component_rank;\n\t\tint max_rank;\n\t\tMPI_Comm_rank(MPI_COMM_WORLD, &component_rank);\n\n\t\t#pragma omp for\n\t\tfor(i = 0; i < N; i++){\n\t\t\tfor(j = 0; j < N; j++){\n\t\t\t\tif(B[i][j] == 1){\n\t\t\t\t\tcount_of_vertices += 1;\n\t\t\t\t\tB[i][j] = component_id;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tmax_component = max(max_component, count_of_vertices);\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\tif(component_rank == 0){\n\t\t\t#pragma omp for\n\t\t\tfor(i = 0; i < N; i++){\n\t\t\t\tfor(j = 0; j < N; j++){\n\t\t\t\t\tB[i][j] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\tcount_of_vertices = 0;\n\t\t#pragma omp for\n\t\tfor(i = 0; i < N; i++){\n\t\t\tfor(j = 0; j < N; j++){\n\t\t\t\tif(A[i][j] == 1){\n\t\t\t\t\tcount_of_vertices += 1;\n\t\t\t\t\tB[i][j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tcount_of_vertices_in_component += count_of_vertices;\n\t\t}\n\t\t\n\t\t#pragma omp barrier\n\n\t\tif(component_rank == 0){\n\t\t\t#pragma omp for\n\t\t\tfor(i = 0; i < N; i++){\n\t\t\t\tfor(j = 0; j < N; j++){\n\t\t\t\t\tB[i][j] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&count_of_vertices_in_component, &max_component, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tif(num_of_nodes == 0){\n\t\treturn max_component;\n\t}\n\telse{\n\t\treturn 0;\n\t}\n}",
            "const int num_threads = omp_get_max_threads();\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // Compute the largest component size in parallel\n  std::vector<int> visited(N, 0);\n  int local_max = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      int max = 0;\n      // Search all neighbors of i\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i*N + j] == 1) {\n          int curr = visited[j] + 1;\n          if (curr > max) {\n            max = curr;\n          }\n        }\n      }\n      max = omp_get_thread_num() == 0? max : 0;\n      #pragma omp critical\n      {\n        visited[i] = max;\n        if (max > local_max) {\n          local_max = max;\n        }\n      }\n    }\n  }\n\n  // Compute the max in parallel\n  int global_max = 0;\n  MPI_Reduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  // Return the result on rank 0\n  int result = 0;\n  if (rank == 0) {\n    result = global_max;\n  }\n  return result;\n}",
            "// YOUR CODE GOES HERE\n\treturn 0;\n}",
            "// TODO\n}",
            "int largest = 0;\n  int rank = 0;\n  int size = 0;\n\n  // Get the MPI rank\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  // Get the number of MPI processes\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // Use OpenMP to parallelize the inner loop\n  #pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    // Count the number of elements that can be reached from vertex i\n    int count = 0;\n    for(int j = 0; j < N; j++) {\n      if(A[i * N + j]) {\n        count++;\n      }\n    }\n    // Use MPI to determine the largest component size across all ranks\n    int count_rank;\n    MPI_Allreduce(&count, &count_rank, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n    if(rank == 0) {\n      largest = count_rank;\n    }\n  }\n\n  // Return the number of vertices in the largest component on rank 0\n  return largest;\n}",
            "// Your code here\n    return -1;\n}",
            "std::vector<int> adjacencyList(N * N);\n\n    #pragma omp parallel\n    {\n        std::vector<int> visited(N, 0);\n        std::vector<int> dfsStack;\n        std::vector<int> dfsResult;\n\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; ++i) {\n            if (visited[i] == 0) {\n                dfsStack.push_back(i);\n                visited[i] = 1;\n\n                while (!dfsStack.empty()) {\n                    int current = dfsStack.back();\n                    dfsStack.pop_back();\n                    dfsResult.push_back(current);\n\n                    for (int j = 0; j < N; ++j) {\n                        if (A[current * N + j] == 1 && visited[j] == 0) {\n                            visited[j] = 1;\n                            dfsStack.push_back(j);\n                        }\n                    }\n                }\n            }\n        }\n\n        #pragma omp critical\n        {\n            for (int vertex : dfsResult) {\n                adjacencyList[vertex] = 1;\n            }\n        }\n    }\n\n    int max = 0;\n    for (int elem : adjacencyList) {\n        if (elem == 1) {\n            max++;\n        }\n    }\n\n    int result;\n\n    #pragma omp parallel\n    {\n        int localMax = 0;\n\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < adjacencyList.size(); i += N) {\n            int current = 0;\n            for (int j = i; j < i + N; ++j) {\n                if (adjacencyList[j] == 1) {\n                    current++;\n                }\n            }\n\n            if (current > localMax) {\n                localMax = current;\n            }\n        }\n\n        #pragma omp critical\n        {\n            if (localMax > max) {\n                max = localMax;\n            }\n        }\n    }\n\n    int result_local;\n\n    #pragma omp parallel\n    {\n        int localMax = 0;\n\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < adjacencyList.size(); i += N) {\n            int current = 0;\n            for (int j = i; j < i + N; ++j) {\n                if (adjacencyList[j] == 1) {\n                    current++;\n                }\n            }\n\n            if (current > localMax) {\n                localMax = current;\n            }\n        }\n\n        #pragma omp critical\n        {\n            if (localMax > max) {\n                max = localMax;\n            }\n        }\n    }\n\n    MPI_Reduce(&max, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (MPI_Comm_rank(MPI_COMM_WORLD) == 0) {\n        return result;\n    } else {\n        return 0;\n    }\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  std::vector<int> A_rank(A.begin() + rank*N, A.begin() + (rank+1)*N);\n  std::vector<int> S_rank(A.size(), 0);\n  std::vector<int> S(N, 0);\n  std::vector<std::vector<int>> C;\n\n  if (rank == 0) {\n    for (int i = 0; i < N; i++) {\n      C.push_back(std::vector<int>(N, -1));\n    }\n  }\n\n  for (int i = 0; i < N; i++) {\n    for (int j = i; j < N; j++) {\n      if (A_rank[i*N + j] == 1) {\n        S_rank[i]++;\n        S_rank[j]++;\n        S[i]++;\n        S[j]++;\n      }\n    }\n  }\n\n  MPI_Allreduce(S_rank.data(), S.data(), N, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n  int max = -1;\n  for (int i = 0; i < N; i++) {\n    if (S[i] > max) {\n      max = S[i];\n    }\n  }\n  return max;\n}",
            "// TODO: Your code here\n}",
            "// TODO\n    return 0;\n}",
            "std::vector<int> component(N);\n\tfor (size_t i = 0; i < N; i++)\n\t\tcomponent[i] = -1;\n\n\tfor (size_t k = 0; k < N; k++) {\n\t\tif (component[k] == -1) {\n\t\t\tcomponent[k] = k;\n\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\tif (A[k * N + i] == 1 && component[i] == -1)\n\t\t\t\t\tcomponent[i] = k;\n\t\t\t}\n\t\t}\n\t}\n\n\tint num_vertices = 0;\n\tint num_components = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i]!= -1) {\n\t\t\tnum_vertices++;\n\t\t\tif (component[i] == i)\n\t\t\t\tnum_components++;\n\t\t}\n\t}\n\n\treturn num_vertices;\n}",
            "// Your code goes here\n\n    // For debugging\n    // std::cout << \"N = \" << N << std::endl;\n\n    return 0;\n}",
            "// TODO\n  return 0;\n}",
            "MPI_Status status;\n\tint const rank = MPI_Comm_rank(MPI_COMM_WORLD, &status);\n\tint const size = MPI_Comm_size(MPI_COMM_WORLD, &status);\n\n\t// TODO: use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n\t// Example:\n\t//\n\t//  input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n\t//  output: 2\n\n\tstd::vector<int> graph = A;\n\n\t// Determine the start and end vertices for each rank to compute.\n\tint const startVertex = rank * N / size;\n\tint const endVertex = (rank + 1) * N / size;\n\tint numVertices = 0;\n\n\t// Mark the start vertex as visited.\n\tgraph[startVertex] = 1;\n\tnumVertices++;\n\n\t// Loop through all vertices until no more are found.\n\twhile (numVertices < N) {\n\t\tbool foundVertex = false;\n\n\t\t// Loop through all edges in the graph.\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t// Check for a connected edge.\n\t\t\t\tif (graph[i * N + j] == 1 && i < startVertex && j >= endVertex) {\n\t\t\t\t\t// Mark the vertex as visited.\n\t\t\t\t\tgraph[j] = 1;\n\t\t\t\t\tnumVertices++;\n\t\t\t\t\tfoundVertex = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (foundVertex) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sum the number of vertices.\n\tint sumVertices = 0;\n\tMPI_Reduce(&numVertices, &sumVertices, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// Return the number of vertices on rank 0.\n\tif (rank == 0) {\n\t\treturn sumVertices;\n\t}\n\n\treturn 0;\n}",
            "std::vector<int> visited(N, 0);\n    int result = 0;\n\n    // TODO\n    // use MPI to distribute the work among ranks and OpenMP to parallelize work done on each rank\n    // update the result in result\n\n    return result;\n}",
            "int my_rank, num_ranks;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n    // Your code here.\n    return 0;\n}",
            "const int numRanks = omp_get_num_threads();\n\tint maxNumNodes = 0;\n\tstd::vector<int> components(numRanks, 0);\n\tomp_set_num_threads(numRanks);\n\t#pragma omp parallel\n\t{\n\t\tint numNodes = 0;\n\t\tint startRow = N*omp_get_thread_num()/numRanks;\n\t\tint endRow = N*(omp_get_thread_num()+1)/numRanks;\n\t\t#pragma omp for\n\t\tfor (int i=startRow; i<endRow; i++) {\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\tif (A[i*N + j]) numNodes++;\n\t\t\t}\n\t\t}\n\t\tcomponents[omp_get_thread_num()] = numNodes;\n\t}\n\n\tfor (int i=1; i<numRanks; i++) {\n\t\tif (components[i]>maxNumNodes) {\n\t\t\tmaxNumNodes = components[i];\n\t\t}\n\t}\n\treturn maxNumNodes;\n}",
            "// TODO\n    return 0;\n}",
            "const int rank = 0;\n\tconst int size = 0;\n\n\tstd::vector<int> A_local(N*N);\n\tstd::vector<int> components(N);\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp single nowait\n\t\t{\n\t\t\t// TODO: find the largest component of the graph defined by the adjacency matrix A\n\t\t}\n\t}\n\n\treturn 0;\n}",
            "/* YOUR CODE HERE */\n    return 0;\n}",
            "int num_threads = omp_get_num_threads();\n\tint my_rank = omp_get_thread_num();\n\tint *visited, *comp;\n\tint maxComp = 0;\n\tvisited = new int[N];\n\tcomp = new int[N];\n\n\tomp_set_num_threads(1);\n\tomp_set_dynamic(0);\n\tomp_set_nested(0);\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tcomp[i] = i;\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tomp_set_num_threads(1);\n\t\tomp_set_dynamic(0);\n\t\tomp_set_nested(0);\n\t\tomp_set_num_threads(num_threads);\n\t\tomp_set_dynamic(1);\n\t\tomp_set_nested(1);\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]) {\n\t\t\t\tcomp[j] = i;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tomp_set_num_threads(1);\n\t\tomp_set_dynamic(0);\n\t\tomp_set_nested(0);\n\t\tomp_set_num_threads(num_threads);\n\t\tomp_set_dynamic(1);\n\t\tomp_set_nested(1);\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] && i!= j) {\n\t\t\t\tcomp[i] = comp[j];\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tomp_set_num_threads(1);\n\t\tomp_set_dynamic(0);\n\t\tomp_set_nested(0);\n\t\tomp_set_num_threads(num_threads);\n\t\tomp_set_dynamic(1);\n\t\tomp_set_nested(1);\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]) {\n\t\t\t\tmaxComp = std::max(maxComp, comp[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\tomp_set_num_threads(1);\n\tomp_set_dynamic(0);\n\tomp_set_nested(0);\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\tint *toVisit;\n\ttoVisit = new int[maxComp+1];\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < maxComp+1; i++) {\n\t\tomp_set_num_threads(1);\n\t\tomp_set_dynamic(0);\n\t\tomp_set_nested(0);\n\t\tomp_set_num_threads(num_threads);\n\t\tomp_set_dynamic(1);\n\t\tomp_set_nested(1);\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (comp[j] == i) {\n\t\t\t\ttoVisit[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < maxComp+1; i++) {\n\t\tomp_set_num_threads(1);\n\t\tomp_set_dynamic(0);\n\t\tomp_set_nested(0);\n\t\tomp_set_num_threads(num_threads);\n\t\tomp_set_dynamic(1);\n\t\tomp_set_nested(1);\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j <",
            "// Write your code here\n}",
            "// TODO: Your code here\n  std::vector<int> adj;\n  adj.resize(N);\n  int count=0;\n\n  for(int i=0; i<N;i++){\n    for(int j=0; j<N;j++){\n      adj[i]= adj[i] + A[i*N+j];\n    }\n  }\n\n  std::vector<int> adj_list;\n  adj_list.resize(N);\n  int adj_size = 0;\n\n  for(int i=0; i<N;i++){\n    if(adj[i]==N-1){\n      adj_list[adj_size] = i;\n      adj_size = adj_size + 1;\n    }\n  }\n  int new_size = 0;\n  int new_adj_list[adj_size];\n  int isvisited[adj_size];\n  int new_adj_size = 0;\n  int isvisited_size = 0;\n  int flag = 0;\n\n  for(int i=0; i<adj_size;i++){\n    isvisited[i] = 0;\n  }\n\n  while(flag==0){\n    for(int i=0; i<adj_size;i++){\n      if(isvisited[i]==0){\n        isvisited[i] = 1;\n        new_adj_list[new_size] = adj_list[i];\n        new_size = new_size + 1;\n        for(int j=0; j<N;j++){\n          if(A[adj_list[i]*N+j]==1){\n            for(int k=0; k<adj_size;k++){\n              if(adj_list[k]==j){\n                if(isvisited[k]==0){\n                  adj_list[k] = adj_list[adj_size-1];\n                  adj_size = adj_size - 1;\n                  isvisited[k] = 1;\n                  isvisited_size = isvisited_size + 1;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n    flag = 1;\n    for(int i=0; i<isvisited_size;i++){\n      if(isvisited[i]==0){\n        flag = 0;\n      }\n    }\n    new_adj_size = new_adj_size + new_size;\n    for(int i=0; i<new_size;i++){\n      adj_list[i] = new_adj_list[i];\n    }\n    new_size = 0;\n    isvisited_size = 0;\n  }\n  count = new_adj_size;\n  return count;\n}",
            "int largest = 0;\n  int my_largest = 0;\n  int rank = 0;\n  int procs = 0;\n  int my_rank = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &procs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n  // TODO\n\n  return largest;\n}",
            "// Your code goes here\n    int size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int local_count=0;\n    if(A.size()!=N*N) return -1;\n\n    if(rank==0)\n    {\n        // create an array to keep track of which node is visited\n        // initialze all the nodes as unvisited\n        bool *isVisited=(bool*)calloc(N,sizeof(bool));\n        // find the largest component by starting from each node\n        for(int i=0;i<N;i++)\n        {\n            if(!isVisited[i])\n            {\n                // start a BFS from the current node\n                std::queue<int> q;\n                q.push(i);\n                isVisited[i]=true;\n                while(!q.empty())\n                {\n                    int curr = q.front(); q.pop();\n                    for(int j=0;j<N;j++)\n                    {\n                        if(!isVisited[j] && A[curr*N+j])\n                        {\n                            q.push(j);\n                            isVisited[j]=true;\n                        }\n                    }\n                }\n            }\n        }\n        // count the number of visited node\n        for(int i=0;i<N;i++)\n        {\n            if(isVisited[i]) local_count++;\n        }\n        // free the array and return the result\n        free(isVisited);\n    }\n\n    int global_count;\n    MPI_Reduce(&local_count,&global_count,1,MPI_INT,MPI_SUM,0,MPI_COMM_WORLD);\n    return global_count;\n\n}",
            "// TODO\n}",
            "// TODO: replace this with your solution\n  int my_rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n  int num_ranks = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n  int num_threads = 0;\n  omp_set_num_threads(num_threads);\n\n  if (num_ranks == 1) {\n    // Serial case\n    return 1;\n  }\n\n  // 1. Find the components that are reachable by each rank\n  // 2. Find the largest component of the unions of those components\n  // 3. Return the largest component that each rank computed\n  int size = A.size();\n  int *A_array = &A[0];\n  int *components = new int[size];\n  int max_component = 0;\n  int max_component_size = 0;\n  int max_components = 0;\n  int max_components_size = 0;\n\n  // Set all components to 0\n  memset(components, 0, sizeof(int) * size);\n\n  for (int i = 0; i < size; i++) {\n    // Traverse the array until we find a new component or we reach the end\n    if (components[i] == 0) {\n      int component = 0;\n      std::queue<int> q;\n      q.push(i);\n\n      while (!q.empty()) {\n        int index = q.front();\n        q.pop();\n\n        component = components[index];\n\n        for (int j = 0; j < N; j++) {\n          if (A_array[index * N + j] == 1 && components[j] == 0) {\n            q.push(j);\n            components[j] = component;\n          }\n        }\n      }\n\n      if (component == 0) {\n        component = max_component;\n        max_component++;\n      }\n\n      if (component == 0) {\n        component = 1;\n      }\n\n      if (max_component_size < component) {\n        max_component_size = component;\n      }\n\n      if (max_components_size < component) {\n        max_components = component;\n        max_components_size = 1;\n      } else if (max_components_size == component) {\n        max_components_size++;\n      }\n    }\n  }\n\n  // Send the components to the 0 rank\n  int *send_components = new int[size];\n  memcpy(send_components, components, sizeof(int) * size);\n  int *recv_components = new int[size];\n  MPI_Gather(send_components, size, MPI_INT, recv_components, size, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // 0 rank gathers all the components from each rank\n  // 0 rank checks if any of the components is the largest\n  if (my_rank == 0) {\n    for (int i = 0; i < size; i++) {\n      for (int j = 0; j < N; j++) {\n        if (recv_components[i * N + j] == max_component) {\n          max_components++;\n        }\n      }\n    }\n\n    return max_components;\n  }\n\n  // Cleanup\n  delete[] components;\n  delete[] send_components;\n  delete[] recv_components;\n  return 0;\n}",
            "int myComponent = 1;\n\tstd::vector<bool> component(N,false);\n\tstd::vector<bool> visited(N,false);\n\tstd::vector<int> visitedEdge(N,0);\n\tcomponent[0] = true;\n\tvisited[0] = true;\n\tint my_id, numprocs;\n\tMPI_Comm_size(MPI_COMM_WORLD,&numprocs);\n\tMPI_Comm_rank(MPI_COMM_WORLD,&my_id);\n\n\t#pragma omp parallel for schedule(dynamic, 1)\n\tfor(int i = 0; i < N; i++) {\n\t\tif(!visited[i]) {\n\t\t\tmyComponent++;\n\t\t\tint count = 0;\n\t\t\tint stack[1000];\n\t\t\tint top = -1;\n\t\t\tstack[++top] = i;\n\t\t\twhile(top!= -1) {\n\t\t\t\tint current = stack[top];\n\t\t\t\tvisited[current] = true;\n\t\t\t\tvisitedEdge[current] = my_id;\n\t\t\t\tcomponent[current] = true;\n\t\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\t\tif(!visited[j] && A[N * current + j] == 1) {\n\t\t\t\t\t\tstack[++top] = j;\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttop--;\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxComponent = myComponent;\n\tMPI_Reduce(&maxComponent, &myComponent, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif(my_id == 0) {\n\t\tint maxRank = 0;\n\t\tMPI_Reduce(&visitedEdge, &maxRank, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t\t// MPI_Gather(visitedEdge,N,MPI_INT,visitedEdge,N,MPI_INT,0,MPI_COMM_WORLD);\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(visitedEdge[i] == maxRank) {\n\t\t\t\tif(component[i] == true) {\n\t\t\t\t\tmyComponent++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn myComponent;\n}",
            "std::vector<int> local_labels(N);\n\tstd::vector<int> global_labels(N);\n\tstd::vector<int> global_counts(N);\n\n\tstd::iota(local_labels.begin(), local_labels.end(), 0);\n\tstd::vector<std::vector<int>> local_groups(N);\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tlocal_groups[i].push_back(j);\n\t\t\t\tlocal_groups[j].push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<std::vector<int>> global_groups;\n\n\tMPI_Reduce(&local_groups[0], &global_groups[0], N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn 0;\n}",
            "int n = N;\n\tint numprocs;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n\tint myrank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n\n\tstd::vector<int> result(n);\n\tif (myrank == 0) {\n\t\tint p = 0;\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tint max = 0;\n\t\t\tfor (int j = 0; j < n; j++) {\n\t\t\t\tif (i!= j && A[i * n + j] == 1)\n\t\t\t\t\tmax = j;\n\t\t\t}\n\t\t\tresult[i] = max;\n\t\t\tif (result[i] == 0)\n\t\t\t\tp++;\n\t\t}\n\t}\n\n\tMPI_Bcast(result.data(), n, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint num_thread = omp_get_max_threads();\n\tomp_set_num_threads(numprocs);\n\n\t#pragma omp parallel\n\t{\n\t\tint id = omp_get_thread_num();\n\t\tint i = id * (n / numprocs);\n\t\tif (id == numprocs - 1) {\n\t\t\tfor (; i < n; i++) {\n\t\t\t\tif (result[i] > 0) {\n\t\t\t\t\tresult[i] = result[result[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tfor (; i < (id + 1) * (n / numprocs); i++) {\n\t\t\t\tif (result[i] > 0) {\n\t\t\t\t\tresult[i] = result[result[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint count = 0;\n\tif (myrank == 0) {\n\t\tfor (int i = 0; i < n; i++) {\n\t\t\tif (result[i] == i)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\tint res = 0;\n\tMPI_Reduce(&count, &res, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (myrank == 0)\n\t\treturn res;\n\telse\n\t\treturn 0;\n}",
            "int rank = 0;\n\tint nrank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nrank);\n\t\n\tint *num_ver = new int[nrank];\n\tint *sum_ver = new int[nrank];\n\tint *displ = new int[nrank];\n\t\n\t#pragma omp parallel for num_threads(4)\n\tfor (int i = 0; i < nrank; i++) {\n\t\tif (i == 0) {\n\t\t\tint ver_num = 0;\n\t\t\t#pragma omp parallel for num_threads(4) reduction(+:ver_num)\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[j * N + j] == 0)\n\t\t\t\t\tver_num++;\n\t\t\t}\n\t\t\tnum_ver[i] = ver_num;\n\t\t\tdispl[i] = 0;\n\t\t}\n\t\telse {\n\t\t\tint ver_num = 0;\n\t\t\t#pragma omp parallel for num_threads(4) reduction(+:ver_num)\n\t\t\tfor (int j = N / nrank * (i - 1); j < N / nrank * i; j++) {\n\t\t\t\tif (A[j * N + j] == 0)\n\t\t\t\t\tver_num++;\n\t\t\t}\n\t\t\tnum_ver[i] = ver_num;\n\t\t\tdispl[i] = displ[i - 1] + num_ver[i - 1];\n\t\t}\n\t}\n\t\n\tMPI_Gather(num_ver, 1, MPI_INT, sum_ver, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\tif (rank == 0) {\n\t\tint largest_comp = 0;\n\t\tfor (int i = 0; i < nrank; i++) {\n\t\t\tif (sum_ver[i] > largest_comp)\n\t\t\t\tlargest_comp = sum_ver[i];\n\t\t}\n\t\t\n\t\treturn largest_comp;\n\t}\n\t\n\treturn 0;\n}",
            "if (A.size()!= N * N) {\n    return -1;\n  }\n\n  // TODO: Implement me\n  return 0;\n}",
            "int myRank = 0;\n\tint nRanks = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nRanks);\n\n\tint numThreads = omp_get_max_threads();\n\tif (numThreads < nRanks) numThreads = nRanks;\n\n\tstd::vector<std::vector<int>> A_local;\n\tstd::vector<int> A_local_row;\n\tstd::vector<int> A_local_col;\n\tstd::vector<int> visited;\n\n\tstd::vector<int> comps;\n\n\tstd::vector<int> r_visited(N);\n\tstd::vector<int> r_comps(N);\n\tstd::vector<int> r_num_visited(nRanks);\n\tstd::vector<int> r_n_comps(nRanks);\n\n\tstd::queue<int> q;\n\n\tif (myRank == 0) {\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[N * i + j]) {\n\t\t\t\t\tA_local_row.push_back(i);\n\t\t\t\t\tA_local_col.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t\tA_local.push_back(A_local_row);\n\t\t\tA_local_row.clear();\n\t\t\tvisited.push_back(0);\n\t\t}\n\n\t\tint num_visited = 0;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (!visited[i]) {\n\t\t\t\tnum_visited++;\n\t\t\t\tq.push(i);\n\t\t\t\twhile (!q.empty()) {\n\t\t\t\t\tint u = q.front();\n\t\t\t\t\tq.pop();\n\t\t\t\t\tvisited[u] = 1;\n\t\t\t\t\tfor (int j = 0; j < A_local[u].size(); j++) {\n\t\t\t\t\t\tint v = A_local[u][j];\n\t\t\t\t\t\tif (!visited[v]) {\n\t\t\t\t\t\t\tq.push(v);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_num_visited[i % nRanks] = num_visited;\n\t\t\tr_n_comps[i % nRanks] = 0;\n\t\t}\n\n\t\tfor (int r = 0; r < nRanks; r++) {\n\t\t\tMPI_Send(&r_num_visited[r], 1, MPI_INT, r, 0, MPI_COMM_WORLD);\n\t\t\tMPI_Send(&r_n_comps[r], 1, MPI_INT, r, 1, MPI_COMM_WORLD);\n\t\t}\n\n\t\tfor (int r = 1; r < nRanks; r++) {\n\t\t\tMPI_Recv(&r_visited[r], N, MPI_INT, r, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tMPI_Recv(&r_comps[r], N, MPI_INT, r, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tvisited[i] = visited[i] || r_visited[r * N + i];\n\t\t\t\tcomps[i] = std::max(comps[i], r_comps[r * N + i]);\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (!visited[i]) {\n\t\t\t\tq.push(i);",
            "int p;\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\tint r;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &r);\n\tint *a = new int[N];\n\tint *d = new int[N];\n\tint *e = new int[N];\n\tint *v = new int[N];\n\tint *p_r = new int[N];\n\tint *p_c = new int[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\ta[i] = -1;\n\t\td[i] = 0;\n\t\te[i] = 0;\n\t\tv[i] = 0;\n\t\tp_r[i] = 0;\n\t\tp_c[i] = 0;\n\t}\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\te[i]++;\n\t\t\t\tp_c[j]++;\n\t\t\t}\n\t\t}\n\t}\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (e[i] == 0) {\n\t\t\ta[i] = 1;\n\t\t\tv[i] = 1;\n\t\t}\n\t}\n\tfor (int i = 0; i < p; i++) {\n\t\tif (i == r) {\n\t\t\tcontinue;\n\t\t}\n\t\t#pragma omp parallel for\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (a[j] == 0) {\n\t\t\t\tif (p_r[j] == 0) {\n\t\t\t\t\tp_r[j] = i + 1;\n\t\t\t\t}\n\t\t\t\tif (p_c[j] == 0) {\n\t\t\t\t\tp_c[j] = i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp parallel for\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (p_r[j] == i + 1) {\n\t\t\t\tif (e[j] == 0) {\n\t\t\t\t\ta[j] = 1;\n\t\t\t\t\tv[j] = 1;\n\t\t\t\t}\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (A[j * N + k]!= 0) {\n\t\t\t\t\t\tif (a[k] == 0) {\n\t\t\t\t\t\t\ta[k] = 2;\n\t\t\t\t\t\t}\n\t\t\t\t\t\td[k]++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp parallel for\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (a[j] == 2) {\n\t\t\t\tif (d[j] == 0) {\n\t\t\t\t\ta[j] = 1;\n\t\t\t\t\tv[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp parallel for\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (p_c[j] == i + 1) {\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (A[k * N + j]!= 0) {\n\t\t\t\t\t\tif (a[k] == 0) {\n\t\t\t\t\t\t\ta[k] = 2;\n\t\t\t\t\t\t}\n\t\t\t\t\t\td[k]",
            "int result = 0;\n\treturn result;\n}",
            "// Your code here.\n}",
            "int mpi_size, mpi_rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n    std::vector<bool> in_component(N, false);\n    in_component[0] = true;\n    std::vector<int> current_vertex_queue;\n    current_vertex_queue.push_back(0);\n    while (!current_vertex_queue.empty()) {\n        int vertex = current_vertex_queue.back();\n        current_vertex_queue.pop_back();\n        for (int other_vertex = 0; other_vertex < N; ++other_vertex) {\n            if (A[N*vertex + other_vertex] == 1 &&!in_component[other_vertex]) {\n                in_component[other_vertex] = true;\n                current_vertex_queue.push_back(other_vertex);\n            }\n        }\n    }\n\n    std::vector<bool> in_component_mpi(N, false);\n    for (int vertex = 0; vertex < N; ++vertex) {\n        in_component_mpi[vertex] = in_component[vertex];\n    }\n\n    std::vector<int> result_mpi(mpi_size, 0);\n    MPI_Reduce(in_component_mpi.data(), result_mpi.data(), N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    std::vector<int> result_omp;\n    if (mpi_rank == 0) {\n        #pragma omp parallel for\n        for (int i = 0; i < mpi_size; ++i) {\n            result_omp.push_back(result_mpi[i]);\n        }\n        int max = *std::max_element(result_omp.begin(), result_omp.end());\n        return max;\n    }\n\n    return 0;\n}",
            "int* colors = new int[N];\n\tint* counts = new int[N];\n\tint* counts_global = new int[N];\n\tint num_threads, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp single\n\t\t{\n\t\t\tnum_threads = omp_get_num_threads();\n\t\t}\n\t}\n\n\t#pragma omp parallel for schedule(static, N / num_threads)\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tcolors[i] = i;\n\t}\n\n\tint* adj_list = new int[N * 2];\n\n\tfor(int i = 0; i < N * 2; ++i) {\n\t\tadj_list[i] = 0;\n\t}\n\n\tint counter = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tadj_list[counter * 2] = i;\n\t\t\t\tadj_list[counter * 2 + 1] = j;\n\t\t\t\tcounter++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint start = 0;\n\tint end = counter - 1;\n\tint length = end - start + 1;\n\n\tint* send_buf = new int[length * 2];\n\n\twhile(start!= end) {\n\n\t\tif (start == end) {\n\t\t\tend++;\n\t\t\tstart++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (length < 2) {\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rank == 0) {\n\t\t\tfor(int i = 0; i < length * 2; ++i) {\n\t\t\t\tsend_buf[i] = adj_list[i + start * 2];\n\t\t\t}\n\n\t\t\tMPI_Request request[num_threads - 1];\n\t\t\tMPI_Status status[num_threads - 1];\n\n\t\t\tfor(int i = 1; i < num_threads; ++i) {\n\t\t\t\tMPI_Isend(send_buf, length * 2, MPI_INT, i, 0, MPI_COMM_WORLD, &request[i - 1]);\n\t\t\t}\n\n\t\t\tfor(int i = 1; i < num_threads; ++i) {\n\t\t\t\tMPI_Recv(send_buf, length * 2, MPI_INT, i, 0, MPI_COMM_WORLD, &status[i - 1]);\n\t\t\t}\n\n\t\t\tfor(int i = 1; i < num_threads; ++i) {\n\t\t\t\tMPI_Wait(&request[i - 1], &status[i - 1]);\n\t\t\t}\n\n\t\t\tfor(int i = 0; i < length * 2; ++i) {\n\t\t\t\tadj_list[i + start * 2] = send_buf[i];\n\t\t\t}\n\t\t} else {\n\t\t\tMPI_Recv(send_buf, length * 2, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t\t\tfor(int i = 0; i < length * 2; ++i) {\n\t\t\t\tadj_list[i + start * 2] = send_buf[i];\n\t\t\t}\n\t\t}\n\n\t\tfor(int i = start; i < end; ++i) {\n\t\t\tif(colors[adj_list[i * 2]] == colors[adj_list[i * 2 + 1]]) {\n\t\t\t\tcolors[adj_list[i * 2]] = colors[adj_list[i * 2 + 1]];\n\t\t\t}\n\n\t\t\tif(colors[adj_list[i *",
            "// TODO\n}",
            "// TODO: Your code here\n\n}",
            "int components = 0;\n    // your code here\n    return components;\n}",
            "return 0;\n}",
            "// TODO: Your code goes here\n  int num_threads;\n  int my_rank;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_threads);\n\n  //int local_component = 0;\n  int global_component = 0;\n  int global_component_size = 0;\n  int global_component_rank = 0;\n\n  std::vector<int> local_component(N, 0);\n  //omp_set_num_threads(num_threads);\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    //omp_set_num_threads(num_threads);\n    int i_component = 0;\n    int i_component_size = 0;\n    //omp_set_num_threads(num_threads);\n    #pragma omp parallel for\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j) {\n        if (A[i * N + j] > 0) {\n          if (i_component == 0) {\n            i_component = local_component[j];\n          } else if (local_component[j] > 0 && i_component!= local_component[j]) {\n            i_component = local_component[j];\n          }\n        }\n      }\n    }\n    if (i_component > 0) {\n      local_component[i] = i_component;\n    }\n    if (i_component > global_component) {\n      global_component = i_component;\n      global_component_rank = my_rank;\n    }\n  }\n\n  //printf(\"Rank %d has a component of %d\\n\", my_rank, local_component);\n\n  if (my_rank == 0) {\n    //printf(\"Rank %d has a component of %d\\n\", my_rank, local_component);\n    for (size_t i = 0; i < N; i++) {\n      if (local_component[i] == global_component) {\n        global_component_size++;\n      }\n    }\n  }\n\n  MPI_Reduce(&global_component_size, &global_component_size, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  MPI_Gather(&global_component, 1, MPI_INT, &global_component, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Gather(&global_component_rank, 1, MPI_INT, &global_component_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (my_rank == 0) {\n    int component_size = 0;\n    int component_rank = 0;\n    for (size_t i = 0; i < num_threads; i++) {\n      if (global_component[i] > component_size) {\n        component_size = global_component[i];\n        component_rank = global_component_rank[i];\n      }\n    }\n\n    if (component_rank == my_rank) {\n      return component_size;\n    }\n  }\n\n  return 0;\n}",
            "auto local_A = std::vector<int>(A.begin(), A.end());\n\tconst int rank = omp_get_thread_num();\n\tconst int size = omp_get_num_threads();\n\tint local_max = 0;\n\tstd::vector<int> local_vec(local_A.begin()+rank*N/size,local_A.begin()+(rank+1)*N/size);\n\tfor(int i = 0; i < N/size; i++){\n\t\tfor(int j = 0; j < N/size; j++){\n\t\t\tif(local_vec[i]!= 0 && local_vec[j]!= 0 && local_A[i*N+j]!= 0){\n\t\t\t\tlocal_vec[i] = 0;\n\t\t\t\tlocal_vec[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i = 0; i < local_vec.size(); i++){\n\t\tif(local_vec[i] == 1){\n\t\t\tlocal_vec[i] = 0;\n\t\t\tlocal_max++;\n\t\t}\n\t}\n\tint global_max;\n\tMPI_Reduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif(rank == 0){\n\t\treturn global_max;\n\t}\n\telse{\n\t\treturn 0;\n\t}\n}",
            "int result = -1;\n\n    // TODO: your code here\n\n    return result;\n}",
            "int ret = 0;\n  std::vector<bool> V;\n  std::vector<int> adj;\n\n  #pragma omp parallel\n  {\n    int rank = omp_get_thread_num();\n    int num_threads = omp_get_num_threads();\n\n    #pragma omp single\n    {\n      int rc = MPI_Comm_size(MPI_COMM_WORLD, &num_threads);\n      if (rc!= MPI_SUCCESS) {\n        throw std::runtime_error(\"MPI_Comm_size failed\");\n      }\n    }\n\n    size_t start = (rank*N)/num_threads;\n    size_t end = ((rank+1)*N)/num_threads;\n    V.resize(N);\n    std::fill(V.begin(), V.end(), false);\n    adj.resize(N);\n\n    #pragma omp for\n    for (size_t v = 0; v < N; ++v) {\n      adj[v] = 0;\n      if (A[v * N + v] == 1) {\n        adj[v] = 1;\n        V[v] = true;\n      }\n    }\n\n    int count = 1;\n    #pragma omp for\n    for (size_t v = start; v < end; ++v) {\n      if (!V[v]) {\n        V[v] = true;\n        count++;\n        for (size_t w = 0; w < N; ++w) {\n          if (A[v * N + w] == 1) {\n            adj[w] = 1;\n            if (!V[w]) {\n              V[w] = true;\n            }\n          }\n        }\n      }\n    }\n\n    #pragma omp single\n    {\n      int recv_counts[num_threads];\n      int displs[num_threads];\n      int local_max = count;\n      recv_counts[rank] = count;\n\n      MPI_Gather(MPI_IN_PLACE, 1, MPI_INT, recv_counts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n      if (rank == 0) {\n        displs[0] = 0;\n        for (int i = 1; i < num_threads; ++i) {\n          displs[i] = displs[i-1] + recv_counts[i-1];\n        }\n        for (int i = 0; i < num_threads; ++i) {\n          local_max = std::max(local_max, recv_counts[i]);\n        }\n        ret = local_max;\n        for (int i = 1; i < num_threads; ++i) {\n          int local_max2 = 0;\n          for (int j = displs[i]; j < displs[i] + recv_counts[i]; ++j) {\n            local_max2 = std::max(local_max2, adj[j]);\n          }\n          ret = std::max(ret, local_max2);\n        }\n      } else {\n        MPI_Gatherv(adj.data(), adj.size(), MPI_INT, NULL, recv_counts, displs, MPI_INT, 0, MPI_COMM_WORLD);\n      }\n    }\n  }\n  return ret;\n}",
            "int p, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tconst int num_threads = omp_get_max_threads();\n\tconst int num_blocks = num_threads * p;\n\tconst int block_size = N/num_blocks;\n\n\tstd::vector<std::vector<int>> visited(N, std::vector<int>(N));\n\tstd::vector<int> result(N, 0);\n\t\n\tauto visited_block = [&](int i, int j, int k, int l) {\n\t\tvisited[i][j] = 1;\n\t\tresult[i] = 1;\n\t\tif (A[i][l] == 1) {\n\t\t\tif (visited[l][k] == 0) {\n\t\t\t\tvisited_block(l, k, l, k);\n\t\t\t}\n\t\t}\n\t};\n\n\tauto visited_loop = [&](int i, int j) {\n\t\t#pragma omp parallel for num_threads(num_threads)\n\t\tfor (int k = 0; k < N; ++k) {\n\t\t\tif (A[i][k] == 1) {\n\t\t\t\tif (visited[k][j] == 0) {\n\t\t\t\t\tvisited[k][j] = 1;\n\t\t\t\t\tresult[i] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tvisited_loop(i, i);\n\t\t}\n\t}\n\n\t#pragma omp parallel for num_threads(num_threads)\n\tfor (int i = 0; i < N; i += block_size) {\n\t\tint j = i;\n\t\tint k = i;\n\t\twhile (j < N && k < N) {\n\t\t\tif (A[j][k] == 1 && visited[j][k] == 0) {\n\t\t\t\tvisited_block(j, k, j, k);\n\t\t\t}\n\t\t\t++j;\n\t\t\t++k;\n\t\t}\n\t}\n\n\tint max_result = *std::max_element(result.begin(), result.end());\n\tint max_result_count = std::count(result.begin(), result.end(), max_result);\n\tint total_max_result = 0;\n\n\tMPI_Reduce(&max_result_count, &total_max_result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn total_max_result;\n}",
            "std::vector<bool> visited(N, false);\n  int n_vertices = 0;\n\n  // First call DFS to visit all vertices\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      n_vertices++;\n      DFS(A, visited, i);\n    }\n  }\n\n  return n_vertices;\n}",
            "/* YOUR CODE GOES HERE */\n\n}",
            "const int num_of_processors = omp_get_num_procs();\n  const int rank = omp_get_thread_num();\n  const int num_of_threads = omp_get_max_threads();\n\n  int num_of_vertices = 0;\n  if (rank == 0) {\n    // MPI_Bcast(A, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n    num_of_vertices = std::count(A.begin(), A.end(), 1);\n    for (int i = 1; i < num_of_processors; ++i) {\n      MPI_Status status;\n      MPI_Recv(&num_of_vertices, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n    }\n  } else {\n    MPI_Send(&num_of_vertices, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  return num_of_vertices;\n}",
            "int count[2];\n    int result;\n    int index[2];\n    int value[2];\n    int maxval;\n    int proc_count = omp_get_num_procs();\n\n    // MPI\n    MPI_Comm_size(MPI_COMM_WORLD, &count[1]);\n    MPI_Comm_rank(MPI_COMM_WORLD, &count[0]);\n    int proc_rank = count[0];\n\n    // OpenMP\n    int thread_count = omp_get_max_threads();\n    int thread_rank = omp_get_thread_num();\n    int thread_size = omp_get_num_threads();\n\n    for (int i = 0; i < N; i++) {\n        if (A[i*N + i] == 1) {\n            for (int j = 0; j < N; j++) {\n                A[i*N + j] = 1;\n                A[j*N + i] = 1;\n            }\n        }\n    }\n\n    if (proc_rank == 0 && thread_rank == 0) {\n        for (int i = 0; i < N; i++) {\n            for (int j = i + 1; j < N; j++) {\n                if (A[i*N + j] == 1) {\n                    A[j*N + i] = 1;\n                }\n            }\n        }\n    }\n\n    MPI_Bcast(A.data(), N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    MPI_Gather(&thread_rank, 1, MPI_INT, index, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Gather(&thread_size, 1, MPI_INT, value, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    if (proc_rank == 0) {\n        maxval = 0;\n        for (int i = 0; i < count[1]; i++) {\n            if (value[i] > maxval) {\n                maxval = value[i];\n            }\n        }\n\n        int num_threads = count[1] / maxval;\n        for (int i = 0; i < N; i++) {\n            for (int j = i + 1; j < N; j++) {\n                if (A[i*N + j] == 1) {\n                    A[j*N + i] = 1;\n                }\n            }\n        }\n        MPI_Scatter(index, 1, MPI_INT, &thread_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        MPI_Scatter(value, 1, MPI_INT, &thread_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        int thread_count2 = N / maxval;\n        int start = thread_rank * thread_count2;\n        int end = (thread_rank + 1) * thread_count2;\n\n        for (int i = start; i < end; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[i*N + j] == 1) {\n                    A[j*N + i] = 1;\n                }\n            }\n        }\n\n        MPI_Scatter(index, 1, MPI_INT, &thread_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        MPI_Scatter(value, 1, MPI_INT, &thread_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    } else {\n        MPI_Scatter(index, 1, MPI_INT, &thread_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        MPI_Scatter(value, 1, MPI_INT, &thread_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    }",
            "// TODO\n}",
            "std::vector<std::vector<int>> comp(N, std::vector<int>(N, 0));\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tcomp[i][j] = (A[i*N + j]!= 0)? i : -1;\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (comp[i][j] == -1) continue;\n\t\t\tfor (size_t k = 0; k < N; ++k)\n\t\t\t{\n\t\t\t\tif (comp[i][j] == comp[i][k] && comp[i][j]!= -1)\n\t\t\t\t\tcomp[i][k] = comp[i][j];\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> v(N, 0);\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (comp[i][j]!= -1)\n\t\t\t\tv[comp[i][j]] += 1;\n\t\t}\n\t}\n\n\tint size = 0;\n\tint max_size = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tsize += v[i];\n\t\tmax_size = std::max(size, max_size);\n\t}\n\treturn max_size;\n}",
            "int component_size = -1;\n  int largest_component = -1;\n  int my_largest_component = -1;\n  int my_component_size = -1;\n  int my_component_vertex = -1;\n  int root = 0;\n  int rank = 0;\n  int size = 0;\n  std::vector<int> color(N, 0);\n  std::vector<int> parent(N, -1);\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // for each vertex in the graph\n  for (int i = 0; i < N; ++i) {\n    // if that vertex has not already been visited\n    if (color[i] == 0) {\n      // mark the vertex as being visited\n      color[i] = 1;\n      // set that vertex to be the parent of itself\n      parent[i] = i;\n      // set the size of the current component to be 1\n      my_component_size = 1;\n      // set the vertex to be the first vertex in the component\n      my_component_vertex = i;\n      // explore the graph starting from this vertex\n      for (int j = 0; j < N; ++j) {\n        // if vertex j has not already been visited\n        if (color[j] == 0 && A[i * N + j] == 1) {\n          // mark vertex j as visited\n          color[j] = 1;\n          // set the parent of vertex j to be vertex i\n          parent[j] = i;\n          // increment the size of the current component\n          my_component_size++;\n        }\n      }\n    }\n    // if the size of the component is greater than the currently known largest component size\n    if (my_component_size > my_largest_component) {\n      // set the largest component size to be the size of the current component\n      my_largest_component = my_component_size;\n      // set the largest component vertex to be the first vertex in the current component\n      largest_component = my_component_vertex;\n    }\n    // reset the color of the current vertex to 0 (not visited)\n    color[i] = 0;\n  }\n  MPI_Reduce(&my_largest_component, &component_size, 1, MPI_INT, MPI_MAX, root, MPI_COMM_WORLD);\n  if (rank == root) {\n    return component_size;\n  } else {\n    return -1;\n  }\n}",
            "// YOUR CODE HERE\n\n    // create a list of vertex sets\n    std::vector<std::vector<int>> vertex_sets;\n    vertex_sets.reserve(N);\n\n    // create a new set for each vertex\n    for (size_t i = 0; i < N; i++) {\n        std::vector<int> v{i};\n        vertex_sets.push_back(v);\n    }\n\n    // go through all edges and union sets of vertices\n    // that are connected by an edge\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                unionSets(vertex_sets, i, j);\n            }\n        }\n    }\n\n    // find the set with the largest number of vertices\n    int num_vertices_in_largest_set = 0;\n    int set_with_largest_number_of_vertices = 0;\n    for (size_t i = 0; i < vertex_sets.size(); i++) {\n        if (vertex_sets[i].size() > num_vertices_in_largest_set) {\n            num_vertices_in_largest_set = vertex_sets[i].size();\n            set_with_largest_number_of_vertices = i;\n        }\n    }\n\n    return num_vertices_in_largest_set;\n}",
            "int comm_size, rank, comm_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &comm_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> C;\n\tC.assign(N, 0);\n\tstd::vector<int> A_rank;\n\tA_rank.assign(N, 0);\n\tstd::vector<int> C_rank;\n\tC_rank.assign(N, 0);\n\t\n\t// MPI PART\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tA_rank[i] += A[i*N + j];\n\t\t}\n\t}\n\n\tMPI_Scatter(&A_rank[0], N, MPI_INT, &C_rank[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// OpenMP PART\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += C_rank[j];\n\t\t}\n\t\tC[i] = sum;\n\t}\n\tint max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (C[i] > max) {\n\t\t\tmax = C[i];\n\t\t}\n\t}\n\n\t// MPI PART\n\tMPI_Reduce(&max, &comm_rank, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\treturn comm_rank;\n\t}\n\n}",
            "std::vector<int> componentSizes(N);\n  std::vector<int> verticesToCheck(N);\n  std::vector<int> colors(N);\n  // TODO: Implement\n  return -1;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tstd::vector<int> *component = new std::vector<int>(N);\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tcomponent->at(i) = 1;\n\t}\n\n\tint numThreads = omp_get_max_threads();\n\tomp_set_num_threads(size);\n\n#pragma omp parallel\n\t{\n\t\tint rank;\n\t\tint numProcs;\n\n\t\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\tMPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\n\t\tint start = rank * (N / numProcs);\n\t\tint end = (rank + 1) * (N / numProcs);\n\t\tint temp = start;\n\n\t\twhile (temp < end)\n\t\t{\n\t\t\tfor (size_t i = 0; i < N; i++)\n\t\t\t{\n\t\t\t\tif (A.at(temp) == 1 && component->at(i) == 1)\n\t\t\t\t{\n\t\t\t\t\tcomponent->at(i) = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttemp++;\n\t\t}\n\t}\n\n\tstd::vector<int> *component_max = new std::vector<int>(N);\n\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tcomponent_max->at(i) = 0;\n\t}\n\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tif (component->at(i) == 1)\n\t\t{\n\t\t\tcomponent_max->at(i) = 1;\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tif (component_max->at(i) == 1)\n\t\t{\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tint max = 0;\n\tif (rank == 0)\n\t{\n\t\tint counts[size];\n\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tMPI_Recv(&counts[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tif (max < counts[i])\n\t\t\t{\n\t\t\t\tmax = counts[i];\n\t\t\t}\n\t\t}\n\t}\n\telse\n\t{\n\t\tMPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn max;\n}",
            "// TODO: Your code here\n\tint maxsize = 0;\n\tint compSize = 0;\n\tint currentId = 0;\n\tint finalCompSize = 0;\n\tint mpi_rank;\n\tint mpi_size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\tstd::vector<std::vector<int> > visited(A.size());\n\tstd::vector<int> visited_row(A.size());\n\tomp_set_num_threads(mpi_size);\n\t\n\t#pragma omp parallel\n\t{\n\t\tint thread_id = omp_get_thread_num();\n\t\tint comp_size = 0;\n\t\tfor (int i = thread_id; i < A.size(); i += mpi_size) {\n\t\t\tstd::vector<int> component;\n\t\t\tcomponent.push_back(i);\n\t\t\tvisited[i].push_back(currentId);\n\t\t\tvisited_row[i] = currentId;\n\t\t\tint flag = 0;\n\t\t\twhile (component.size()!= 0) {\n\t\t\t\tint cur = component.back();\n\t\t\t\tcomponent.pop_back();\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[cur * N + j] == 1 && visited_row[j]!= currentId) {\n\t\t\t\t\t\tcomponent.push_back(j);\n\t\t\t\t\t\tvisited_row[j] = currentId;\n\t\t\t\t\t\tflag = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (flag == 1)\n\t\t\t\tcomp_size++;\n\t\t}\n\t\tint* send = new int[1];\n\t\tsend[0] = comp_size;\n\t\tMPI_Send(send, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tif (mpi_rank == 0) {\n\t\tint* rec = new int[mpi_size];\n\t\tfor (int i = 1; i < mpi_size; i++) {\n\t\t\tMPI_Recv(rec + i, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\t\tfor (int i = 1; i < mpi_size; i++) {\n\t\t\tif (rec[i] > maxsize) {\n\t\t\t\tmaxsize = rec[i];\n\t\t\t}\n\t\t}\n\t\tstd::cout << maxsize << std::endl;\n\t}\n\treturn maxsize;\n}",
            "// TODO: Implement.\n  int nthreads = omp_get_max_threads();\n  int nprocs = omp_get_num_procs();\n  int rank = omp_get_thread_num();\n  int comps[nthreads][nprocs] = {0};\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i)\n    for (int j = 0; j < N; ++j)\n      if (A[i*N + j])\n        ++comps[rank][i/nthreads];\n\n  int my_comp = *std::max_element(comps[rank], comps[rank] + nprocs);\n  int comp_size = my_comp;\n\n  for (int i = 0; i < nprocs; ++i)\n    MPI_Allreduce(MPI_IN_PLACE, &my_comp, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n  return comp_size;\n}",
            "return -1;\n}",
            "// TODO\n}",
            "int res = 0;\n\n\t// TODO: compute the result here\n\n\treturn res;\n}",
            "int num_nodes;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_nodes);\n\n    /* your code here */\n\n    return -1;\n}",
            "// Your code here\n}",
            "// TODO\n}",
            "int size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // First get the size of the largest component in the current graph.\n    std::vector<int> componentSize(N, 1);\n\n#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                // If there is a connection from i to j, the components will merge.\n                // Therefore, the size of j's component is the sum of its own component's size and i's component size.\n                // We need to do this atomically, otherwise two ranks might try to modify j's component size at the same time.\n                // We can use the CAS instruction for this, but C++ doesn't have a wrapper for it, so we'll use openmp instead.\n                // This is fine since openmp is just a C++ wrapper for pthreads.\n                #pragma omp atomic capture\n                {\n                    int oldSize = componentSize[j];\n                    componentSize[j] = oldSize + componentSize[i];\n                }\n            }\n        }\n    }\n\n    std::vector<int> maxComponentSize(1, 0);\n    MPI_Reduce(componentSize.data(), maxComponentSize.data(), componentSize.size(), MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        // Rank 0 has a complete copy of the adjacency matrix and its largest component size.\n        // Now we must get the largest component size in every subgraph.\n        std::vector<int> allComponentSizes(size);\n        MPI_Gather(maxComponentSize.data(), maxComponentSize.size(), MPI_INT, allComponentSizes.data(), maxComponentSize.size(), MPI_INT, 0, MPI_COMM_WORLD);\n        // Now the largest component size for every rank is stored in the allComponentSizes vector.\n        return *std::max_element(allComponentSizes.begin(), allComponentSizes.end());\n    } else {\n        // Other ranks just return the size of their largest component.\n        // The size is returned because it's easier than sending the whole adjacency matrix back to rank 0.\n        return maxComponentSize[0];\n    }\n}",
            "// Implement this function\n}",
            "int result = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t// The number of vertices in the component starting from v\n\t\tint component[N];\n\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[v*N + v] == 1) {\n\t\t\t\tcomponent[v] = 1;\n\n\t\t\t\t// Mark every vertex that is reachable from v\n\t\t\t\tfor (int u = v + 1; u < N; ++u) {\n\t\t\t\t\tif (A[v*N + u] == 1) {\n\t\t\t\t\t\tcomponent[u] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Find the largest component size\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (result < *std::max_element(component, component + N)) {\n\t\t\t\tresult = *std::max_element(component, component + N);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "// TODO: implement\n  return -1;\n}",
            "int n_threads;\n  #pragma omp parallel\n  {\n    n_threads = omp_get_num_threads();\n  }\n\n  int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // initialize number of nodes\n  int num_nodes[size];\n  if (rank == 0) {\n    num_nodes[rank] = 1;\n  } else {\n    num_nodes[rank] = 0;\n  }\n\n  // copy A into a submatrix\n  int sub_N = N / size;\n  std::vector<int> sub_A(sub_N * sub_N);\n  for (int i = 0; i < sub_N; i++) {\n    for (int j = 0; j < sub_N; j++) {\n      sub_A[i * sub_N + j] = A[rank * sub_N + i * N + j];\n    }\n  }\n\n  // initialize visited\n  std::vector<int> visited(sub_N, 0);\n  // initialize adjacency list\n  std::vector<std::vector<int>> adj_list(sub_N);\n  // initialize parent\n  std::vector<int> parent(sub_N, -1);\n\n  for (int i = 0; i < sub_N; i++) {\n    for (int j = 0; j < sub_N; j++) {\n      if (sub_A[i * sub_N + j] == 1 && i!= j) {\n        adj_list[i].push_back(j);\n      }\n    }\n  }\n\n  // initialize current\n  int current = 0;\n\n  // initialize component\n  int component = 1;\n\n  while (current < sub_N) {\n    std::queue<int> queue;\n    queue.push(current);\n    while (!queue.empty()) {\n      int idx = queue.front();\n      queue.pop();\n      for (int j = 0; j < adj_list[idx].size(); j++) {\n        int adj = adj_list[idx][j];\n        if (visited[adj] == 0) {\n          visited[adj] = 1;\n          parent[adj] = idx;\n          queue.push(adj);\n        }\n      }\n    }\n    current = 0;\n    while (visited[current] == 1) {\n      current++;\n    }\n    component++;\n  }\n\n  MPI_Reduce(MPI_IN_PLACE, &component, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  MPI_Gather(&num_nodes[rank], 1, MPI_INT, &num_nodes[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    int max_nodes = num_nodes[0];\n    for (int i = 1; i < size; i++) {\n      if (num_nodes[i] > max_nodes) {\n        max_nodes = num_nodes[i];\n      }\n    }\n    return max_nodes;\n  } else {\n    return 0;\n  }\n}",
            "// TODO: Your code goes here\n\t// Note: You can only call omp_get_num_threads() and omp_get_thread_num() in the body of a parallel region\n\t//\t\t so you cannot use them in the body of the function itself.\n\n\tint result = 0;\n\tint threads = 0;\n\tint mythread = 0;\n\tint size = 0;\n\tint root = 0;\n\tint rank = 0;\n\tint mysize = 0;\n\tint current_thread = 0;\n\tint current_rank = 0;\n\tint local_result = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (rank == root) {\n\t\tthreads = omp_get_max_threads();\n\t\tif (N % threads!= 0) {\n\t\t\tresult = -1;\n\t\t}\n\t\telse {\n\t\t\tmysize = N / threads;\n\t\t\t#pragma omp parallel shared(A, mysize, threads, N, result) num_threads(threads)\n\t\t\t{\n\t\t\t\tmythread = omp_get_thread_num();\n\t\t\t\tcurrent_rank = rank * threads + mythread;\n\t\t\t\tlocal_result = 0;\n\t\t\t\t#pragma omp for\n\t\t\t\tfor (int i = mythread*mysize; i < mythread*mysize + mysize; i++) {\n\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\t\t\tlocal_result += 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tMPI_Send(&local_result, 1, MPI_INT, current_rank, 0, MPI_COMM_WORLD);\n\t\t\t}\n\t\t\tfor (int i = 1; i < size; i++) {\n\t\t\t\tMPI_Recv(&local_result, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\t\tif (local_result > result) {\n\t\t\t\t\tresult = local_result;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\tMPI_Recv(&local_result, 1, MPI_INT, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tMPI_Send(&local_result, 1, MPI_INT, root, 0, MPI_COMM_WORLD);\n\t}\n\t\n\treturn result;\n}",
            "// TODO: Your code goes here\n    // You will need to allocate some buffers and use MPI_Alltoall to communicate\n    // You will also need to use OpenMP to parallelize this code\n    // Note that every rank has a full copy of A\n\n    // int nprocess, processId;\n    // MPI_Comm_size(MPI_COMM_WORLD, &nprocess);\n    // MPI_Comm_rank(MPI_COMM_WORLD, &processId);\n\n    // int localN = N/nprocess;\n    // std::vector<int> localA(localN * localN);\n    // for (int i=0; i<localN*localN; i++) {\n    //     localA[i] = A[localN*processId*localN + i];\n    // }\n\n    // std::vector<int> recvA(localN * localN);\n    // std::vector<int> recvSum(localN);\n    // for (int i=0; i<localN*localN; i++) {\n    //     recvA[i] = 0;\n    // }\n\n    // for (int i=0; i<localN; i++) {\n    //     recvSum[i] = 0;\n    // }\n\n    // std::vector<int> sum(localN);\n    // for (int i=0; i<localN; i++) {\n    //     sum[i] = 0;\n    //     for (int j=0; j<localN; j++) {\n    //         sum[i] += localA[i*localN + j];\n    //     }\n    // }\n\n    // int sum_size[2] = {1, localN};\n    // MPI_Datatype type;\n    // MPI_Type_create_subarray(2, sum_size, sum_size, sum_size, MPI_ORDER_C, MPI_INT, &type);\n    // MPI_Type_commit(&type);\n\n    // MPI_Alltoall(sum.data(), 1, type, recvSum.data(), 1, type, MPI_COMM_WORLD);\n    // MPI_Type_free(&type);\n\n    // int maxSum = 0;\n    // int maxIndex = 0;\n    // for (int i=0; i<localN; i++) {\n    //     if (maxSum < recvSum[i]) {\n    //         maxSum = recvSum[i];\n    //         maxIndex = i;\n    //     }\n    // }\n    // int root = 0;\n    // int maxSum_recv;\n    // int maxIndex_recv;\n    // MPI_Reduce(&maxSum, &maxSum_recv, 1, MPI_INT, MPI_MAX, root, MPI_COMM_WORLD);\n    // MPI_Reduce(&maxIndex, &maxIndex_recv, 1, MPI_INT, MPI_MAX, root, MPI_COMM_WORLD);\n\n    // if (processId == 0) {\n    //     std::cout << \"maxsum: \" << maxSum_recv << std::endl;\n    //     std::cout << \"maxindex: \" << maxIndex_recv << std::endl;\n    // }\n\n    return 0;\n}",
            "int* visited = new int[N];\n  int* max_visited = new int[N];\n  int* tmp_visited = new int[N];\n  bool* visited_omp = new bool[N];\n\n  std::fill(visited, visited + N, 0);\n  std::fill(max_visited, max_visited + N, 0);\n  std::fill(visited_omp, visited_omp + N, 0);\n\n  int global_size, local_size;\n  int root = 0;\n  int rank = 0;\n  int tag = 0;\n  int i, j;\n  MPI_Status status;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &global_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (rank == root) {\n    MPI_Send(visited, N, MPI_INT, root, tag, MPI_COMM_WORLD);\n\n    // Use OpenMP to speed up the process\n    #pragma omp parallel for\n    for (i = 0; i < N; ++i) {\n      for (j = 0; j < N; ++j) {\n        if (i!= j && A[i * N + j] == 1) {\n          visited_omp[i] = 1;\n          break;\n        }\n      }\n    }\n\n    std::fill(visited, visited + N, 0);\n    for (i = 0; i < N; ++i) {\n      if (visited_omp[i] == 1) {\n        visited[i] = 1;\n        visited_omp[i] = 0;\n        local_size = 1;\n        for (j = 0; j < N; ++j) {\n          if (i!= j && A[i * N + j] == 1 && visited_omp[j] == 0) {\n            visited[j] = 1;\n            local_size += 1;\n            visited_omp[j] = 1;\n          }\n        }\n        if (local_size > max_visited[0]) {\n          max_visited[0] = local_size;\n        }\n      }\n    }\n\n    for (int i = 1; i < global_size; ++i) {\n      MPI_Recv(tmp_visited, N, MPI_INT, i, tag, MPI_COMM_WORLD, &status);\n      for (int j = 0; j < N; ++j) {\n        if (tmp_visited[j] == 1) {\n          visited[j] = 1;\n        }\n      }\n    }\n  }\n  else {\n    MPI_Recv(visited, N, MPI_INT, root, tag, MPI_COMM_WORLD, &status);\n    std::fill(visited_omp, visited_omp + N, 0);\n\n    for (i = 0; i < N; ++i) {\n      if (visited[i] == 1) {\n        visited_omp[i] = 1;\n        local_size = 1;\n        for (j = 0; j < N; ++j) {\n          if (i!= j && A[i * N + j] == 1 && visited_omp[j] == 0) {\n            visited[j] = 1;\n            local_size += 1;\n            visited_omp[j] = 1;\n          }\n        }\n        if (local_size > max_visited[0]) {\n          max_visited[0] = local_size;\n        }\n      }\n    }\n    MPI_Send(visited, N, MPI_INT, root, tag, MPI_COMM_WORLD);\n  }\n\n  if (rank == root) {\n    for (i = 1; i < global_size; ++i) {\n      MPI_Recv(tmp_visited, N, MPI_INT, i, tag, MPI_COMM_WORLD, &status);\n      for (int j = 0; j < N; ++j) {\n        if (tmp_visited[",
            "// TODO\n}",
            "std::vector<int> visited(N, 0);\n    int count = 0;\n\n    #pragma omp parallel for\n    for(int i = 0; i < N; i++){\n        if(visited[i] == 0){\n            std::stack<int> s;\n            s.push(i);\n            while(!s.empty()){\n                int k = s.top();\n                s.pop();\n                if(visited[k] == 0){\n                    count++;\n                    visited[k] = 1;\n                    for(int j = 0; j < N; j++){\n                        if(A[N * k + j] == 1 && visited[j] == 0){\n                            s.push(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> components(N);\n\n  // your code goes here\n\n  return 0;\n}",
            "// Your code here\n\n}",
            "return 0;\n}",
            "// TODO: implement the computation\n  return 0;\n}",
            "auto largestComponent = 0;\n\n    // TODO: implement this function\n\n    return largestComponent;\n}",
            "int numProcs, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  const int nthreads = omp_get_max_threads();\n\n  // The number of vertices in each component.\n  std::vector<int> componentSizes(nthreads, 0);\n\n  /*\n   * Initialize componentSizes.\n   *\n   * I'm not sure if this is the best way to initialize.\n   * The following seems to work, but I'm not sure it's correct.\n   *\n   *   int maxRowSize = 0;\n   *   for (int i = 0; i < N; i++) {\n   *     int rowSize = 0;\n   *     for (int j = 0; j < N; j++) {\n   *       if (A[i*N+j]) rowSize++;\n   *     }\n   *     if (rowSize > maxRowSize) maxRowSize = rowSize;\n   *   }\n   *   componentSizes.assign(nthreads, maxRowSize);\n   */\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int tid = omp_get_thread_num();\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j]) {\n        componentSizes[tid]++;\n      }\n    }\n  }\n\n  // Compute the size of the largest component.\n  std::vector<int> recvcounts(numProcs, 0);\n  MPI_Gather(&componentSizes[0], nthreads, MPI_INT, &recvcounts[0], nthreads, MPI_INT, 0, MPI_COMM_WORLD);\n  int maxComponentSize = 0;\n  if (rank == 0) {\n    for (int i = 0; i < numProcs; i++) {\n      if (recvcounts[i] > maxComponentSize) {\n        maxComponentSize = recvcounts[i];\n      }\n    }\n  }\n\n  // Broadcast the size of the largest component.\n  MPI_Bcast(&maxComponentSize, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return maxComponentSize;\n}",
            "int numProcs, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // Find the size of the largest component.\n    // You can use the following as a reference for this.\n    // It uses the fact that the number of vertices in a component is\n    // always the same as the number of vertices on a connected component.\n    // https://en.wikipedia.org/wiki/Connected_component_(graph_theory)\n\n    // Compute the number of vertices in the connected component.\n    int connectedComponentSize = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                connectedComponentSize++;\n                break;\n            }\n        }\n    }\n\n    // Find the maximum number of vertices in a connected component.\n    int maxConnectedComponentSize = 0;\n    MPI_Allreduce(&connectedComponentSize, &maxConnectedComponentSize, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n    return maxConnectedComponentSize;\n}",
            "// TODO: Implement this function\n\treturn -1;\n}",
            "std::vector<int> visited(N, 0);\n    int max_comp = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            int count = 1;\n            std::vector<int> stack;\n            stack.push_back(i);\n            visited[i] = 1;\n            while (stack.size()!= 0) {\n                int top = stack[stack.size() - 1];\n                stack.pop_back();\n                for (int j = 0; j < N; j++) {\n                    if (A[top * N + j] == 1 && visited[j] == 0) {\n                        stack.push_back(j);\n                        visited[j] = 1;\n                        count++;\n                    }\n                }\n            }\n            if (count > max_comp) max_comp = count;\n        }\n    }\n    return max_comp;\n}",
            "/* TODO: write your code here */\n  int numVerts;\n  int myId = -1;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myId);\n  std::vector<int> myA;\n  std::vector<int> myCount(N);\n  myCount[0] = 1;\n\n  if(myId == 0) {\n    numVerts = 0;\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if(A[N*i + j]!= 0) {\n          myA.push_back(i);\n          myA.push_back(j);\n          myCount[i] += 1;\n          numVerts++;\n        }\n      }\n    }\n    myCount[0] = -1;\n  }\n  MPI_Bcast(&numVerts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  if(myId!= 0) {\n    myA.resize(numVerts*2);\n    myCount.resize(N);\n  }\n  MPI_Bcast(&myA[0], numVerts*2, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&myCount[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int myNumVerts = 0;\n  if(myId!= 0) {\n    myCount[0] = -1;\n    for(int i = 0; i < myA.size(); i++) {\n      int x = myA[i];\n      if(myCount[x] > 0) {\n        myCount[x] = -1;\n        myNumVerts++;\n      }\n    }\n  }\n  MPI_Reduce(&myNumVerts, &numVerts, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return numVerts;\n}",
            "// TODO: Your code here\n    return -1;\n}",
            "// Your code goes here!\n\tint *A1 = new int[N*N];\n\tint *flag = new int[N*N];\n\tint max1=1;\n\tint max2=1;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tA1[i*N+j]=A[i*N+j];\n\t\t\tflag[i*N+j]=0;\n\t\t}\n\t}\n\t\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A[i*N+j]==1)\n\t\t\t{\n\t\t\t\tfor(int k=0;k<N;k++)\n\t\t\t\t{\n\t\t\t\t\tif(A[i*N+k]==1&&A[k*N+j]==1)\n\t\t\t\t\t{\n\t\t\t\t\t\tA1[i*N+k]=1;\n\t\t\t\t\t\tA1[k*N+j]=1;\n\t\t\t\t\t\tA1[k*N+i]=1;\n\t\t\t\t\t\tA1[i*N+j]=1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint sum=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A1[i*N+j]==1)\n\t\t\t{\n\t\t\t\tflag[i*N+j]=1;\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\tint *A2 = new int[N*N];\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tA2[i*N+j]=0;\n\t\t}\n\t}\n\tint sum1=0;\n\tint sum2=0;\n\tint sum3=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(flag[i*N+j]==1)\n\t\t\t{\n\t\t\t\tfor(int k=0;k<N;k++)\n\t\t\t\t{\n\t\t\t\t\tif(flag[i*N+k]==1&&flag[k*N+j]==1)\n\t\t\t\t\t{\n\t\t\t\t\t\tA2[i*N+k]=1;\n\t\t\t\t\t\tA2[k*N+j]=1;\n\t\t\t\t\t\tA2[k*N+i]=1;\n\t\t\t\t\t\tA2[i*N+j]=1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A2[i*N+j]==1)\n\t\t\t{\n\t\t\t\tflag[i*N+j]=1;\n\t\t\t\tsum2++;\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(flag[i*N+j]==1)\n\t\t\t{\n\t\t\t\tsum3++;\n\t\t\t}\n\t\t}\n\t}\n\tif(sum2>sum1)\n\t{\n\t\tmax1=sum2;\n\t\tmax2=sum1;\n\t}\n\telse\n\t{\n\t\tmax1=sum1;\n\t\tmax2=sum2;\n\t}\n\tif(sum3>max2)\n\t{\n\t\tmax2",
            "/* Add your code here */\n    int p, rank;\n    int largestComponent = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    std::vector<int> recv(N);\n    std::vector<int> v(N);\n    std::vector<int> adj_matrix(N*N);\n    int* A_ptr = A.data();\n    int* v_ptr = v.data();\n    int* adj_matrix_ptr = adj_matrix.data();\n    int* recv_ptr = recv.data();\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        adj_matrix[i * N + j] = A[i * N + j];\n      }\n    }\n    if (rank == 0) {\n        for (int i = 0; i < N; ++i) {\n            v_ptr[i] = 0;\n        }\n        #pragma omp parallel for\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (adj_matrix_ptr[i * N + j] == 1) {\n                    v_ptr[j] = 1;\n                }\n            }\n        }\n        int count = 0;\n        for (int i = 0; i < N; ++i) {\n            if (v_ptr[i] == 1) {\n                count++;\n            }\n        }\n        largestComponent = count;\n    }\n    if (rank == 0) {\n        MPI_Gather(v_ptr, N, MPI_INT, recv_ptr, N, MPI_INT, 0, MPI_COMM_WORLD);\n    } else {\n        MPI_Gather(v_ptr, N, MPI_INT, NULL, N, MPI_INT, 0, MPI_COMM_WORLD);\n    }\n    if (rank == 0) {\n        count = 0;\n        for (int i = 0; i < p * N; ++i) {\n            if (recv_ptr[i] == 1) {\n                count++;\n            }\n        }\n        largestComponent = count;\n    }\n    return largestComponent;\n}",
            "std::vector<int> visited(N, 0); // 0 unvisited, 1 visited\n  int n_vertices = 0;\n  std::vector<int> queue;\n  std::vector<int> local_queue;\n  int proc;\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &proc);\n  int local_n_vertices = 0;\n  int global_n_vertices = 0;\n  #pragma omp parallel\n  {\n    #pragma omp for schedule(static)\n    for (int i = 0; i < N; ++i) {\n      if (!visited[i]) {\n        queue.push_back(i);\n        while (queue.size() > 0) {\n          int v = queue.back();\n          visited[v] = 1;\n          n_vertices += 1;\n          queue.pop_back();\n          for (int j = 0; j < N; ++j) {\n            if (!visited[j] && A[v * N + j] > 0) {\n              queue.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n  MPI_Reduce(&n_vertices, &local_n_vertices, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    global_n_vertices = local_n_vertices;\n  }\n  return global_n_vertices;\n}",
            "int result = 0;\n\n\t// TODO: Compute largest component size in parallel.\n\n\treturn result;\n}",
            "//\n    int my_rank, comm_sz;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &comm_sz);\n\n    int const num_local_rows = N / comm_sz;\n\n    if (my_rank == 0) {\n        // rank 0\n        std::vector<int> a(N * N);\n        std::copy(A.begin(), A.end(), a.begin());\n\n        std::vector<int> is_visited(N, 0);\n        int count = 0;\n        // BFS\n        // OMP\n        // TODO: Add OpenMP here\n        //#pragma omp parallel for\n        for (int i = 0; i < N; i++) {\n            if (is_visited[i] == 0) {\n                std::queue<int> queue;\n                queue.push(i);\n\n                while (!queue.empty()) {\n                    int v = queue.front();\n                    queue.pop();\n\n                    for (int w = 0; w < N; w++) {\n                        if (a[N * v + w] == 1) {\n                            is_visited[w] = 1;\n                            queue.push(w);\n                        }\n                    }\n                }\n                count++;\n            }\n        }\n        // MPI\n        // TODO: Add MPI here\n        int counts[comm_sz];\n        int displs[comm_sz];\n        displs[0] = 0;\n        for (int i = 0; i < comm_sz; i++) {\n            counts[i] = num_local_rows;\n            displs[i + 1] = displs[i] + counts[i];\n        }\n        // TODO: Add MPI here\n        MPI_Reduce(is_visited.data(), is_visited.data(), N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n        int max_count = 0;\n        for (int i = 0; i < N; i++) {\n            if (is_visited[i] == 1) {\n                max_count++;\n            }\n        }\n        return max_count;\n    } else {\n        // other ranks\n        // TODO: Add MPI here\n        int counts[comm_sz];\n        int displs[comm_sz];\n        displs[0] = 0;\n        for (int i = 0; i < comm_sz; i++) {\n            counts[i] = num_local_rows;\n            displs[i + 1] = displs[i] + counts[i];\n        }\n        // TODO: Add MPI here\n        MPI_Reduce(A.data(), A.data(), N * N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n        std::vector<int> is_visited(num_local_rows, 0);\n        int count = 0;\n        // BFS\n        // OMP\n        // TODO: Add OpenMP here\n        #pragma omp parallel for\n        for (int i = 0; i < num_local_rows; i++) {\n            if (is_visited[i] == 0) {\n                std::queue<int> queue;\n                queue.push(i);\n\n                while (!queue.empty()) {\n                    int v = queue.front();\n                    queue.pop();\n\n                    for (int w = 0; w < num_local_rows; w++) {\n                        if (A[num_local_rows * v + w] == 1) {\n                            is_visited[w] = 1;\n                            queue.push(w);\n                        }\n                    }\n                }\n                count++;\n            }\n        }\n\n        return count;\n    }\n}",
            "// Implement this function\n}",
            "int nthreads = omp_get_max_threads();\n\n  #pragma omp parallel for num_threads(nthreads)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j) {\n        A[N * i + j] = A[N * i + j]? 1 : 0;\n      }\n    }\n  }\n\n  std::vector<int> visited(N);\n  int num_vertices = 0;\n  int rank = 0;\n  int mpi_size;\n  int mpi_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n  for (int i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      ++num_vertices;\n      std::queue<int> queue;\n      queue.push(i);\n\n      while (!queue.empty()) {\n        int v = queue.front();\n        visited[v] = 1;\n        queue.pop();\n\n        for (int j = 0; j < N; ++j) {\n          if (A[N * v + j] && visited[j] == 0) {\n            queue.push(j);\n          }\n        }\n      }\n    }\n  }\n\n  std::vector<int> counts(mpi_size, 0);\n  counts[mpi_rank] = num_vertices;\n\n  MPI_Gather(counts.data() + rank, 1, MPI_INT, counts.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    int max_count = num_vertices;\n    for (int i = 1; i < mpi_size; ++i) {\n      if (counts[i] > max_count) {\n        max_count = counts[i];\n      }\n    }\n    return max_count;\n  } else {\n    return 0;\n  }\n}",
            "int num_nodes = A.size();\n  //int num_nodes = (int) sqrt(A.size());\n\n  std::vector<int> comp;\n  for(int i = 0; i < N; i++){\n    comp.push_back(i);\n  }\n\n  // DFS\n  std::vector<int> stack;\n  std::vector<int> visited;\n  for(int i = 0; i < num_nodes; i++){\n    if(std::find(visited.begin(), visited.end(), i) == visited.end()){\n      stack.push_back(i);\n      visited.push_back(i);\n      while(stack.size() > 0){\n        int node = stack.back();\n        stack.pop_back();\n        for(int j = 0; j < num_nodes; j++){\n          if(A[node*num_nodes + j] == 1){\n            int comp_node = comp[node];\n            int comp_j = comp[j];\n            if(comp_node!= comp_j){\n              int max = std::max(comp_node, comp_j);\n              int min = std::min(comp_node, comp_j);\n              for(int k = 0; k < N; k++){\n                if(comp[k] == min){\n                  comp[k] = max;\n                }\n              }\n            }\n            if(std::find(visited.begin(), visited.end(), j) == visited.end()){\n              stack.push_back(j);\n              visited.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  std::vector<int> max_node;\n  std::map<int, int> comp_count;\n  for(int i = 0; i < N; i++){\n    if(comp_count.find(comp[i]) == comp_count.end()){\n      comp_count[comp[i]] = 1;\n    }\n    else{\n      comp_count[comp[i]]++;\n    }\n  }\n\n  int max_comp = 0;\n  for(std::pair<int, int> it : comp_count){\n    if(max_comp < it.second){\n      max_comp = it.second;\n    }\n  }\n  return max_comp;\n}",
            "int count = 0;\n\tint count2 = 0;\n\tstd::vector<int> A2(A.size());\n\t\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (i == j)\n\t\t\t{\n\t\t\t\tA2[i * N + j] = 0;\n\t\t\t}\n\t\t\telse if (A[i * N + j] == 0)\n\t\t\t{\n\t\t\t\tA2[i * N + j] = 0;\n\t\t\t}\n\t\t\telse if (A[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tA2[i * N + j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A2[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tA2[j * N + i] = 0;\n\t\t\t}\n\t\t\telse if (A2[i * N + j] == 0)\n\t\t\t{\n\t\t\t\tA2[j * N + i] = 0;\n\t\t\t}\n\t\t\telse if (A2[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tA2[j * N + i] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t// 1. Compute the number of connected components in the graph.\n\t// 2. Determine which component is the largest.\n\t// 3. Return the number of vertices in the largest component.\n\t\n\treturn count;\n}",
            "int *result = (int *) malloc(N*sizeof(int));\n    int *visited = (int *) malloc(N*sizeof(int));\n\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; i++){\n        result[i] = 1;\n        visited[i] = 0;\n    }\n\n    int rank, size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int *lresult = (int *) malloc(N*sizeof(int));\n    int *lvisited = (int *) malloc(N*sizeof(int));\n\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; i++){\n        lresult[i] = 1;\n        lvisited[i] = 0;\n    }\n\n    int global_res = 0;\n    int local_res = 0;\n\n    for(size_t i = 0; i < N; i++){\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            if((A[i*N + j] == 1) && (i!= j) && (visited[i] == 0) && (visited[j] == 0)){\n                visited[i] = 1;\n                visited[j] = 1;\n\n                #pragma omp parallel for\n                for(size_t k = 0; k < N; k++){\n                    if((A[i*N + k] == 1) && (lvisited[k] == 0) && (visited[k] == 0)){\n                        lvisited[k] = 1;\n                    }\n                }\n\n                #pragma omp parallel for\n                for(size_t k = 0; k < N; k++){\n                    if((A[j*N + k] == 1) && (lvisited[k] == 0) && (visited[k] == 0)){\n                        lvisited[k] = 1;\n                    }\n                }\n\n                #pragma omp parallel for\n                for(size_t k = 0; k < N; k++){\n                    if((lvisited[k] == 1) && (visited[k] == 0)){\n                        visited[k] = 1;\n                    }\n                }\n\n                #pragma omp parallel for\n                for(size_t k = 0; k < N; k++){\n                    lvisited[k] = 0;\n                }\n            }\n        }\n\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            if((lvisited[j] == 1) && (visited[j] == 0)){\n                visited[j] = 1;\n            }\n        }\n\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            if((lvisited[j] == 1) && (visited[j] == 0)){\n                visited[j] = 1;\n            }\n        }\n\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            lresult[j] = result[j];\n            lvisited[j] = visited[j];\n        }\n\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            result[j] = 1;\n            visited[j] = 0;\n        }\n\n        #pragma omp parallel for\n        for(size_t j = 0; j < N; j++){\n            lvisited[j] = 0;\n        }\n\n        local_res = 0;\n        for(size_t j = 0; j < N; j++){\n            if(lresult[j] == 1){\n                local_res++;\n            }\n        }\n\n        #pragma omp critical\n        {\n            if(local_res > global_res){\n                global_res = local_res;\n            }"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "kokkos",
        "prompt": "#include <Kokkos_Core.hpp>\n\n/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix.\n   Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(Kokkos::View<const int**> &A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Create a Kokkos view of 2D array NxN\n\t// This view will store the number of times a given node (row) has a neighbor (column)\n\t// It will be initialized to zero\n\tKokkos::View<int**> neighborCount(\"neighborCount\", N, N);\n\tKokkos::deep_copy(neighborCount, 0);\n\n\t// Create a Kokkos view of 2D array NxN\n\t// This view will store the final count of maximum neighbors per node\n\tKokkos::View<int**> finalCount(\"finalCount\", N, N);\n\tKokkos::deep_copy(finalCount, 0);\n\n\t// Compute the number of neighbors each node has in parallel\n\tKokkos::parallel_for(\n\t\t\"compute_neighbor_counts\",\n\t\tKokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n\t\tKOKKOS_LAMBDA (const int row, const int col) {\n\t\t\tint current = A(row, col);\n\t\t\tint neighborCountRow = neighborCount(row, col);\n\t\t\tint neighborCountCol = neighborCount(col, row);\n\t\t\tif (current!= 0) {\n\t\t\t\t// If node A has neighbor B, then both node A and node B have neighbor C\n\t\t\t\tneighborCountRow++;\n\t\t\t\tneighborCountCol++;\n\t\t\t}\n\t\t\tneighborCount(row, col) = neighborCountRow;\n\t\t\tneighborCount(col, row) = neighborCountCol;\n\t\t}\n\t);\n\n\t// Compute the maximum neighbor counts in parallel\n\tKokkos::parallel_for(\n\t\t\"compute_maximum_neighbor_counts\",\n\t\tKokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n\t\tKOKKOS_LAMBDA (const int row, const int col) {\n\t\t\tint neighborCountRow = neighborCount(row, col);\n\t\t\tint neighborCountCol = neighborCount(col, row);\n\t\t\tint current = Kokkos::max(neighborCountRow, neighborCountCol);\n\t\t\tfinalCount(row, col) = current;\n\t\t}\n\t);\n\n\t// Compute the maximum final count of neighbors in parallel\n\t// This will be the highest node degree in the graph\n\t// We need to initialize the maximum to a value that will always be smaller than the first value\n\tint max = 0;\n\tKokkos::parallel_reduce(\n\t\t\"find_maximum_neighbor_counts\",\n\t\tKokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n\t\tKOKKOS_LAMBDA (const int row, const int col, int &max) {\n\t\t\tint current = finalCount(row, col);\n\t\t\tif (current > max) {\n\t\t\t\tmax = current;\n\t\t\t}\n\t\t},\n\t\tmax\n\t);\n\n\treturn max;\n}",
            "auto graphDegrees = Kokkos::View<int*>(\"Graph Degrees\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j))\n\t\t\t\tdegree++;\n\t\t}\n\t\tgraphDegrees(i) = degree;\n\t});\n\tKokkos::fence();\n\n\tauto graphDegreesHost = Kokkos::create_mirror_view(graphDegrees);\n\tKokkos::deep_copy(graphDegreesHost, graphDegrees);\n\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (graphDegreesHost(i) > maxDegree)\n\t\t\tmaxDegree = graphDegreesHost(i);\n\t}\n\n\treturn maxDegree;\n}",
            "using View = Kokkos::View<int*>;\n\tusing ExecutionSpace = Kokkos::DefaultHostExecutionSpace;\n\tView degree(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"degree\"), N);\n\n\tKokkos::parallel_for(\"maxDegree\", Kokkos::RangePolicy<ExecutionSpace>(0, N), [=] (int i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t\tdegree(i) = sum;\n\t});\n\treturn Kokkos::reduce(degree, Kokkos::Max<int>(), 0);\n}",
            "int max_degree = 0;\n\n\t// Compute maximum degree\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint curr_degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcurr_degree += A(i, j);\n\t\t}\n\t\tif (curr_degree > max_degree) {\n\t\t\tmax_degree = curr_degree;\n\t\t}\n\t}\n\n\treturn max_degree;\n}",
            "using TeamPolicy = Kokkos::TeamPolicy<Kokkos::ExecutionSpace>;\n\tusing MemberType = typename TeamPolicy::member_type;\n\n\t// Set up team policy\n\tint team_size = 32;\n\tTeamPolicy policy(N, Kokkos::AUTO);\n\tKokkos::parallel_for(\n\t\tpolicy,\n\t\tKOKKOS_LAMBDA(const MemberType &member) {\n\t\t\tint i = member.league_rank();\n\n\t\t\tint local_max = 0;\n\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tlocal_max += 1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// TODO:\n\t\t\t// Use the Kokkos shared memory to reduce the local_max values\n\t\t\t// to a global maximum for the node i.\n\t\t\t// The Kokkos reduction functions are documented here:\n\t\t\t// https://kokkos.github.io/manual/reduction.html#reduction-library\n\t\t\t// The shared memory size is given by\n\t\t\t// MemberType::team_size()\n\t\t\t// The global maximum is stored in the 0-th element of the\n\t\t\t// shared memory, so for example:\n\t\t\t// Kokkos::parallel_reduce(\n\t\t\t// \t\t\tKokkos::TeamThreadRange(member, N),\n\t\t\t// \t\t\t[&](const int j, int &local_max) {\n\t\t\t// \t\t\t\tif (A(i, j) == 1) {\n\t\t\t// \t\t\t\t\tlocal_max += 1;\n\t\t\t// \t\t\t\t}\n\t\t\t// \t\t\t},\n\t\t\t// \t\t\t[&](const int &local_max_a, const int &local_max_b) {\n\t\t\t// \t\t\t\tlocal_max_a = (local_max_a > local_max_b)? local_max_a : local_max_b;\n\t\t\t// \t\t\t}\n\t\t\t// \t\t);\n\n\t\t\t// TODO:\n\t\t\t// Use Kokkos::single to write the global max to the global memory\n\t\t\t// for node i.\n\t\t\t// The global memory should be defined before the parallel_for, and\n\t\t\t// should be of type Kokkos::View<int*> and have N elements.\n\t\t\t// The global memory can be accessed like any other array in C++:\n\t\t\t// global_max(i) = local_max;\n\n\t\t}\n\t);\n\n\t// TODO:\n\t// Find the maximum of the global_max array using Kokkos::parallel_reduce.\n\t// The initial value of the maximum should be 0.\n\n\t// TODO:\n\t// Return the maximum.\n}",
            "int max_degree = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A(i, j);\n\t\t}\n\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\n\treturn max_degree;\n}",
            "int max = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                          [=] __device__(const int& i) {\n                            int max_local = 0;\n                            for (int j = 0; j < N; ++j) {\n                              max_local += A(i, j);\n                            }\n                            atomicMax(&max, max_local);\n                          },\n                          [=] __device__(int& lhs, int rhs) {\n                            atomicMax(&lhs, rhs);\n                          });\n  return max;\n}",
            "using MaxDegree = Kokkos::Max<int>;\n\tMaxDegree maxDegreeFunctor;\n\tKokkos::parallel_reduce(\"MaxDegree\", N, KOKKOS_LAMBDA(const int i, MaxDegree &md) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tsum += A(i, j);\n\t\tmd.max(sum);\n\t}, maxDegreeFunctor);\n\treturn maxDegreeFunctor.val;\n}",
            "int result = 0;\n\n  // TODO: Replace this with your Kokkos parallel code\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A(i,j)!= 0) {\n        result = i + 1;\n      }\n    }\n  }\n\n  return result;\n}",
            "Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> maxDegree(1);\n\tKokkos::deep_copy(maxDegree, 0);\n\n\tKokkos::View<int**, Kokkos::LayoutRight, Kokkos::HostSpace> workArray(\"workArray\", N, N);\n\tKokkos::parallel_for(N, [&](int i) {\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tworkArray(i,j) = A(i, j);\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_reduce(N, [&](int i, int& localMaxDegree) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (workArray(i, j) == 1)\n\t\t\t\t++localMaxDegree;\n\t\t}\n\t}, Kokkos::Min<int>(maxDegree));\n\tKokkos::fence();\n\n\treturn maxDegree();\n}",
            "Kokkos::View<int*> node_degrees(\"node_degrees\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(int i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i,j) == 1) {\n\t\t\t\tsum += 1;\n\t\t\t}\n\t\t}\n\t\tnode_degrees(i) = sum;\n\t});\n\tint max = 0;\n\tKokkos::View<int*> max_view(\"max_view\", 1);\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [=](int i, int& max_local) {\n\t\tmax_local = std::max(max_local, node_degrees(i));\n\t}, Kokkos::Max<int>(max_view));\n\tKokkos::deep_copy(max, max_view);\n\treturn max;\n}",
            "// Determine number of threads.\n\tint numThreads = omp_get_max_threads();\n\n\t// Each thread will have its own array of node degrees.\n\tKokkos::View<int*> nodeDegrees(\"node degrees\", N);\n\tKokkos::View<int*> maxDegrees(\"max degree\", numThreads);\n\tKokkos::View<int*> localIdx(\"localIdx\", numThreads);\n\n\t// Find the max degree in each subarray of nodes.\n\tKokkos::parallel_for(\n\t\t\"Max Degree\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, numThreads),\n\t\tKOKKOS_LAMBDA(const int &localId) {\n\t\t\tint myMax = 0;\n\t\t\tint myIdx = 0;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tint rowSum = 0;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\trowSum += A(i, j);\n\t\t\t\t}\n\t\t\t\tif (rowSum > myMax) {\n\t\t\t\t\tmyMax = rowSum;\n\t\t\t\t\tmyIdx = i;\n\t\t\t\t}\n\t\t\t}\n\t\t\tmaxDegrees(localId) = myMax;\n\t\t\tlocalIdx(localId) = myIdx;\n\t\t}\n\t);\n\n\t// Find the maximum degree in all of the node degrees.\n\tint maxDegree = 0;\n\tint maxIdx = 0;\n\tfor (int i = 0; i < numThreads; i++) {\n\t\tif (maxDegrees(i) > maxDegree) {\n\t\t\tmaxDegree = maxDegrees(i);\n\t\t\tmaxIdx = localIdx(i);\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int* maxDegrees = new int[N];\n  Kokkos::parallel_for(\"MaxDegrees\", N,\n    KOKKOS_LAMBDA(const int i) {\n      maxDegrees[i] = 0;\n      for(int j = 0; j < N; j++) {\n        maxDegrees[i] += A(i,j);\n      }\n    });\n  Kokkos::fence();\n  int maxDegree = 0;\n  for(int i = 0; i < N; i++) {\n    maxDegree = std::max(maxDegree, maxDegrees[i]);\n  }\n  delete[] maxDegrees;\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\t// Parallel computation using Kokkos\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\t[&](int i, int &localMaxDegree) {\n\t\t\t\tlocalMaxDegree = 0;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t\tlocalMaxDegree++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (localMaxDegree > maxDegree) {\n\t\t\t\t\tmaxDegree = localMaxDegree;\n\t\t\t\t}\n\t\t\t},\n\t\t\tKokkos::Max<int>(maxDegree));\n\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA (const int& i, int& local_max_degree) {\n\t\t\tint degree = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A(i,j)!= 0)\n\t\t\t\t\tdegree++;\n\t\t\t}\n\n\t\t\tif (degree > local_max_degree)\n\t\t\t\tlocal_max_degree = degree;\n\t\t},\n\t\tKokkos::Max<int>(max_degree)\n\t);\n\n\treturn max_degree;\n}",
            "// Your code goes here\n\n\t// You can use C++11 features.\n\t// You can use CUDA code.\n\n\t// You can initialize Kokkos views in C++11 style.\n\t// Kokkos::View<int*> maxDegree(\"maxDegree\", 1);\n\n\treturn 0;\n}",
            "using namespace Kokkos;\n\n\t// Get the maximum node degree in A.\n\tint max_degree = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint local_degree = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A(i, j) > 0) {\n\t\t\t\tlocal_degree++;\n\t\t\t}\n\t\t}\n\t\tif(local_degree > max_degree) {\n\t\t\tmax_degree = local_degree;\n\t\t}\n\t}\n\n\t// Create a Kokkos view to hold the result.\n\tView<int, LayoutLeft, Kokkos::HostSpace> result(\"result\", 1);\n\n\t// Create a parallel kernel to compute the maximum node degree in A.\n\tKokkos::parallel_reduce(\n\t\t\t\"max_degree\",\n\t\t\tPolicy2D(N, N),\n\t\t\t[&](const int& i, const int& j, int& value) {\n\t\t\t\tif(A(i, j) > 0) {\n\t\t\t\t\tvalue++;\n\t\t\t\t}\n\t\t\t},\n\t\t\t[&](const int& value1, const int& value2) {\n\t\t\t\treturn value1 > value2? value1 : value2;\n\t\t\t},\n\t\t\tresult);\n\n\t// Make sure Kokkos is done with the result.\n\tKokkos::fence();\n\n\t// Return the maximum node degree in A.\n\treturn result(0) > max_degree? result(0) : max_degree;\n}",
            "int maxDegree = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [&](size_t i, int& lMaxDegree) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) > 0) {\n        ++degree;\n      }\n    }\n    lMaxDegree = std::max(degree, lMaxDegree);\n  }, Kokkos::Max<int>(maxDegree));\n  return maxDegree;\n}",
            "int ret = 0;\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA (const int i, int& local_ret) {\n      int count = 0;\n      for (int j = 0; j < N; ++j)\n        count += A(i, j);\n      local_ret = std::max(local_ret, count);\n    },\n    Kokkos::Min",
            "// Create a Kokkos View for the result.\n  Kokkos::View<int*, Kokkos::HostSpace> maxDegree(Kokkos::ViewAllocateWithoutInitializing(\"max degree\"), 1);\n\n  // Initialize the result with a value that's definitely smaller than any\n  // valid degree.\n  Kokkos::deep_copy(maxDegree, -1);\n\n  // The kernel that will do the work.\n  Kokkos::parallel_for(\"Max degree\",\n\t\t       N,\n\t\t       KOKKOS_LAMBDA(size_t i) {\n\t\t\t int rowMax = 0;\n\t\t\t for(size_t j=0; j<N; ++j) {\n\t\t\t   rowMax += A(i, j);\n\t\t\t }\n\t\t\t if(rowMax > maxDegree(0)) {\n\t\t\t   maxDegree(0) = rowMax;\n\t\t\t }\n\t\t       });\n\n  // Copy the result back to the host.\n  int maxDegreeHost = 0;\n  Kokkos::deep_copy(maxDegreeHost, maxDegree);\n\n  // Return the result.\n  return maxDegreeHost;\n}",
            "// Declare 2 views to store the column index and value. The view size is the\n  // number of non-zeros in the matrix.\n  // The value is stored in the int type; the column index is stored in a Kokkos\n  // int64.\n  // Note that the views are declared in the parallel scope.\n  // Note that the views are declared with Kokkos::ViewAllocateWithoutInitializing.\n  // This causes the memory to be allocated but uninitialized.\n  Kokkos::View<int*> colInd(\"colInd\", N);\n  Kokkos::View<int*> val(\"val\", N);\n\n  // Compute the non-zero indices and values.\n  // The number of non-zero indices is the same as the number of rows in the\n  // matrix.\n  int numNonzeros = 0;\n  Kokkos::parallel_for(\n      \"compute_nonzeros\", N, KOKKOS_LAMBDA(int i) {\n        for (int j = 0; j < N; j++) {\n          // Skip zero elements\n          if (A(i, j) == 0)\n            continue;\n          // Store the column index\n          colInd(numNonzeros) = j;\n          // Store the value\n          val(numNonzeros) = A(i, j);\n          // Increment the number of non-zeros\n          numNonzeros++;\n        }\n      });\n\n  // Declare a view to store the column indices of each row\n  // The number of rows in the matrix is the same as the number of non-zeros\n  Kokkos::View<int*> rowInd(\"rowInd\", numNonzeros);\n\n  // Sort the column indices by their row\n  // The first argument of sort_by_row is the row index and the second argument\n  // is the column index.\n  // The third argument is the value.\n  // Note that the third argument is an integer.\n  // In the next section, the third argument is a row pointer.\n  Kokkos::sort_by_row(rowInd, colInd, val);\n\n  // Declare a view to store the number of times a row is repeated.\n  // The number of rows in the matrix is the same as the number of non-zeros.\n  Kokkos::View<int*> rowDegree(\"rowDegree\", numNonzeros);\n\n  // Compute the number of times each row is repeated in the sorted list.\n  // The last argument of unique_by_row is the number of non-zeros.\n  // The first argument is the row index and the second argument is the column\n  // index.\n  // The third argument is the value.\n  // Note that the third argument is an integer.\n  // In the next section, the third argument is a row pointer.\n  Kokkos::unique_by_row(rowDegree, rowInd, colInd, val, numNonzeros);\n\n  // Declare a view to store the number of times a row is repeated.\n  // The number of rows in the matrix is the same as the number of non-zeros.\n  Kokkos::View<int*> rowMaxDegree(\"rowMaxDegree\", numNonzeros);\n\n  // Compute the maximum degree of each row.\n  // The first argument of unique_by_row is the row index and the second\n  // argument is the column index.\n  // The third argument is the value.\n  // Note that the third argument is an integer.\n  // In the next section, the third argument is a row pointer.\n  Kokkos::unique_by_row(rowMaxDegree, rowInd, colInd, val, numNonzeros);\n\n  // Declare a view to store the maximum degree of each row.\n  // The number of rows in the matrix is the same as the number of non-zeros.\n  Kokkos::View<int*> maxDegree(\"maxDegree\", numNonzeros);\n\n  // Compute the maximum degree of each row.\n  // The first argument of reduce_by_row is the row index and the second\n  // argument is the column index.\n  // The third argument is the value.\n  // Note that the third argument is an integer.\n  // In the next section",
            "// Create a Kokkos parallel for loop.\n  // The loop will execute the given lambda expression for each element in the\n  // range.\n  Kokkos::parallel_reduce(\n      Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(int i, int& lmax) {\n        // The lambda expression takes two arguments:\n        // - i is the loop index, which goes from 0 to N\n        // - lmax is an int reference that is used to update the maximum\n        //   degree in the parallel loop\n\n        // The following statement executes the loop body N times.\n        // The loop body should update lmax with the maximum degree in the\n        // submatrix A(i, :) of the matrix A.\n\n        // Replace this statement with your code\n        lmax = 0;\n      },\n      Kokkos::Max<int>(&maxDegree));\n\n  // Return the maximum degree in A\n  return maxDegree;\n}",
            "Kokkos::View<int*> maxDegree(\"maxDegree\", N);\n  Kokkos::parallel_for(\"Max Degree\", N, KOKKOS_LAMBDA(int i) {\n\t  int maxDegreeI = 0;\n\t  for(int j = 0; j < N; ++j) {\n\t\tif(A(i, j) == 1) {\n\t\t  maxDegreeI += 1;\n\t\t}\n\t  }\n\t  maxDegree(i) = maxDegreeI;\n  });\n  int maxDegree_host = 0;\n  Kokkos::deep_copy(maxDegree_host, maxDegree);\n  int maxDegree_kokkos = *(std::max_element(maxDegree.data(), maxDegree.data() + N));\n  if(maxDegree_kokkos!= maxDegree_host) {\n\t  std::cerr << \"Warning: Kokkos and Host return different results for max degree\" << std::endl;\n  }\n  return maxDegree_kokkos;\n}",
            "using execution_space = typename Kokkos::DefaultExecutionSpace;\n  Kokkos::View<int*, execution_space> result(\"result\", N);\n  Kokkos::parallel_for(\n    \"degree\", N, KOKKOS_LAMBDA(const int i) {\n      int sum = 0;\n      for (int j = 0; j < N; j++) {\n        sum += A(i, j);\n      }\n      result(i) = sum;\n    }\n  );\n  Kokkos::fence();\n  int max = 0;\n  for (int i = 0; i < N; i++) {\n    max = std::max(max, result(i));\n  }\n  return max;\n}",
            "// Initialize Kokkos policy\n\tKokkos::RangePolicy<Kokkos::Cuda> policy(0, N);\n\n\t// Declare maxDegree variable.\n\tint maxDegree = 0;\n\n\t// Create functor.\n\tstruct Functor {\n\t\tKokkos::View<const int**> A;\n\t\tsize_t N;\n\t\tint &maxDegree;\n\t\tFunctor(Kokkos::View<const int**> A, size_t N, int &maxDegree) :\n\t\t\tA(A), N(N), maxDegree(maxDegree) { }\n\t\tKOKKOS_INLINE_FUNCTION void operator()(const size_t &i) const {\n\t\t\tint degree = 0;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t++degree;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (degree > maxDegree) {\n\t\t\t\tmaxDegree = degree;\n\t\t\t}\n\t\t}\n\t};\n\n\t// Launch functor with Kokkos\n\tKokkos::parallel_reduce(\n\t\t\"maxDegree\",\n\t\tpolicy,\n\t\tFunctor(A, N, maxDegree)\n\t);\n\n\t// Sync, then return the result.\n\tKokkos::fence();\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n\t// Set up the parallel for loop. Kokkos will partition it for us.\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(int i, int &update) {\n\t\t\tint degree = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\tdegree++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (degree > update) {\n\t\t\t\tupdate = degree;\n\t\t\t}\n\t\t},\n\t\tmaxDegree\n\t);\n\n\t// Sync and return the final result.\n\tKokkos::fence();\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\tKOKKOS_LAMBDA(const size_t i, int &lmax) {\n\t\t\tint deg = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\tdeg++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (deg > lmax) {\n\t\t\t\tlmax = deg;\n\t\t\t}\n\t\t},\n\t\tKokkos::Max<int>(maxDegree)\n\t);\n\tKokkos::fence();\n\treturn maxDegree;\n}",
            "// TODO\n\treturn 0;\n}",
            "typedef Kokkos::DefaultExecutionSpace exec_space;\n\n\t// Set the initial node degree\n\tKokkos::View<int*, exec_space> degree(\"Node degree\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\tdegree[i] = 0;\n\t});\n\n\t// Count the number of neighbors for each node\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tdegree[i]++;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Find the max node degree\n\tKokkos::View<int*, exec_space> max_degree(\"Node degree\", 1);\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(size_t i, int& update) {\n\t\tupdate = update < degree[i]? degree[i] : update;\n\t}, Kokkos::Max<int>(max_degree));\n\n\treturn max_degree[0];\n}",
            "int numThreads = 1;\n\tint maxDegree = 0;\n\n\t// Your code goes here\n\tauto degree = Kokkos::View<int*>(\"degree\", N);\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA (const int &i) {\n\t\tint degree = 0;\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif(A(i, j)) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tdegree[i] = degree;\n\t});\n\tKokkos::parallel_reduce(\"maxDegree\", N, KOKKOS_LAMBDA (const int &i, int &maxDegree) {\n\t\tif(degree[i] > maxDegree) {\n\t\t\tmaxDegree = degree[i];\n\t\t}\n\t}, Kokkos::Max<int>(maxDegree));\n\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n\n\t// Your code here\n\n\treturn max_degree;\n}",
            "// Your code goes here.\n\treturn 0;\n}",
            "Kokkos::View<int*> rowMax(Kokkos::ViewAllocateWithoutInitializing(\"rowMax\"), N);\n  Kokkos::parallel_for(\"ComputeMaxDegree\", N, KOKKOS_LAMBDA(const int& node) {\n    int maxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n      if (A(node, i)!= 0) {\n        maxDegree++;\n      }\n    }\n    rowMax(node) = maxDegree;\n  });\n\n  int finalDegree = 0;\n  Kokkos::parallel_reduce(\"ComputeMaxDegree\", N,\n                          KOKKOS_LAMBDA(const int& node, int& lmax) {\n                            int maxDegree = rowMax(node);\n                            if (maxDegree > lmax) {\n                              lmax = maxDegree;\n                            }\n                          },\n                          Kokkos::Max<int>(finalDegree));\n  return finalDegree;\n}",
            "// TODO: Your code here\n  Kokkos::View<int*> numNeighbors(\"numNeighbors\", N);\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    int num = 0;\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)) num++;\n    }\n    numNeighbors(i) = num;\n  });\n  int max_neighbor = Kokkos::reduce_max(numNeighbors);\n  Kokkos::View<int*> max_neighbor_per_thread(\"max_neighbor_per_thread\", Kokkos::DefaultExecutionSpace::concurrency());\n  Kokkos::parallel_for(\"maxDegree\", Kokkos::DefaultExecutionSpace::concurrency(), KOKKOS_LAMBDA(const int i) {\n    max_neighbor_per_thread(i) = max_neighbor;\n  });\n  Kokkos::View<int*> max_neighbor_per_node(\"max_neighbor_per_node\", 1);\n  Kokkos::parallel_for(\"maxDegree\", 1, KOKKOS_LAMBDA(const int i) {\n    max_neighbor_per_node(0) = 0;\n  });\n  Kokkos::parallel_for(\"maxDegree\", Kokkos::DefaultExecutionSpace::concurrency(), KOKKOS_LAMBDA(const int i) {\n    if (max_neighbor_per_thread(i) > max_neighbor_per_node(0)) {\n      max_neighbor_per_node(0) = max_neighbor_per_thread(i);\n    }\n  });\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    if (numNeighbors(i) == max_neighbor_per_node(0)) {\n      max_neighbor = numNeighbors(i);\n    }\n  });\n  return max_neighbor;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A(i, j);\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "Kokkos::View<int*> maxDegree(\"Maximum degree\", N);\n  Kokkos::parallel_for(\n    \"Compute maximum degree\",\n    Kokkos::RangePolicy<Kokkos::Rank<1>>(0, N),\n    KOKKOS_LAMBDA (const int& i) {\n      int max = 0;\n      for (int j = 0; j < N; ++j) {\n        max += A(i, j);\n      }\n      maxDegree(i) = max;\n  });\n  int totalMax = 0;\n  for (int i = 0; i < N; ++i) {\n    totalMax = std::max(maxDegree(i), totalMax);\n  }\n  return totalMax;\n}",
            "// TODO\n    int maxDegree = 0;\n    for (int i = 0; i < N; ++i)\n    {\n        int degree = 0;\n        for (int j = 0; j < N; ++j)\n        {\n            if (A(i, j) > 0)\n            {\n                degree++;\n            }\n        }\n        maxDegree = (maxDegree < degree)? degree : maxDegree;\n    }\n    return maxDegree;\n}",
            "Kokkos::View<int*> vout(\"vout\", 1);\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [=] (const int i, int& local_max) {\n    int n_neighbors = 0;\n    for (int j=0; j<N; ++j) {\n      n_neighbors += A(i, j);\n    }\n    if (n_neighbors > local_max) local_max = n_neighbors;\n  }, Kokkos::Max<int>(vout));\n  return vout[0];\n}",
            "int maxDegree = 0;\n\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& localMaxDegree) {\n      int sum = 0;\n      for (int j = 0; j < N; ++j) {\n        sum += A(i, j);\n      }\n      localMaxDegree = std::max(sum, localMaxDegree);\n    },\n    Kokkos::Max<int>(maxDegree));\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OMP<int>>(0, N),\n\t\t[&](int i, int& lmaxDegree) {\n\t\t\tint degree = 0;\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tif (A(i, j)!= 0)\n\t\t\t\t\tdegree++;\n\t\t\tlmaxDegree = (lmaxDegree < degree? degree : lmaxDegree);\n\t\t},\n\t\tKokkos::OMP::final_reduction_t<Kokkos::Max<int>>());\n\n\treturn maxDegree;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> degree(\"degree\", N);\n    Kokkos::parallel_for(\"maxDegree\", N, [&](int i) {\n        for (int j = 0; j < N; j++) {\n            degree(i) += A(i, j);\n        }\n    });\n    Kokkos::fence();\n    int max = 0;\n    Kokkos::parallel_reduce(\"maxDegree\", N, Kokkos::Max<int>(max), [&](int i, int &max) {\n        max = (degree(i) > max)? degree(i) : max;\n    });\n    Kokkos::fence();\n    return max;\n}",
            "auto Ahost = Kokkos::create_mirror_view(A);\n  Kokkos::deep_copy(Ahost, A);\n\n  int max_degree = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n\n    for (size_t j = 0; j < N; j++) {\n      degree += Ahost(i, j);\n    }\n\n    if (degree > max_degree) {\n      max_degree = degree;\n    }\n  }\n\n  return max_degree;\n}",
            "int maxDegree = 0;\n\n\t// Use Kokkos to compute the highest node degree in the graph\n\t// Use Kokkos parallel_reduce function to compute the max in parallel\n\n\treturn maxDegree;\n}",
            "Kokkos::View<int*,Kokkos::HostSpace> sum(\"sum\", N);\n\tKokkos::parallel_for(\"sum\", N, KOKKOS_LAMBDA(int i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t\tsum(i) = sum;\n\t});\n\tKokkos::fence();\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (sum(i) > maxDegree) {\n\t\t\tmaxDegree = sum(i);\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "Kokkos::View<int*> maxDegree(\"MaxDegree\", 1);\n\n    Kokkos::parallel_for(\"MaxDegree\", N, KOKKOS_LAMBDA(const int i) {\n        int maxDegreeValue = 0;\n        for (int j = 0; j < N; j++) {\n            if (A(i, j) > 0) {\n                maxDegreeValue++;\n            }\n        }\n        Kokkos::atomic_max(&maxDegree(0), maxDegreeValue);\n    });\n\n    Kokkos::fence();\n    return maxDegree(0);\n}",
            "using Kokkos::Max;\n\tusing Kokkos::RangePolicy;\n\tusing Kokkos::parallel_reduce;\n\n\tint maxDegree = -1;\n\n\tparallel_reduce(\"Max Degree\", RangePolicy<int>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int &localMaxDegree) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tlocalMaxDegree = Max(degree, localMaxDegree);\n\t}, Max(maxDegree));\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  Kokkos::parallel_for(N, [=] (size_t i) {\n    int degree = 0;\n    for (size_t j=0; j<N; ++j)\n      degree += A(i,j);\n    Kokkos::atomic_max(&maxDegree, degree);\n  });\n  return maxDegree;\n}",
            "Kokkos::View<int*> degree(\"Degree\", N);\n  Kokkos::deep_copy(degree, 0);\n\n  // Use Kokkos to compute the max degree\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n    for(int j = 0; j < N; j++) {\n      if (A(i, j) == 1) degree(i)++;\n    }\n  });\n\n  // Get the maximum degree\n  int maxDegree = 0;\n  Kokkos::View<int*> maxDegree_host(Kokkos::ViewAllocateWithoutInitializing(\"maxDegree\"), 1);\n  Kokkos::deep_copy(maxDegree_host, 0);\n  Kokkos::parallel_for(1, KOKKOS_LAMBDA(const int& i) {\n    for (int j = 0; j < N; j++) {\n      if (degree(j) > maxDegree_host(0)) maxDegree_host(0) = degree(j);\n    }\n  });\n  Kokkos::deep_copy(maxDegree, maxDegree_host);\n\n  return maxDegree(0);\n}",
            "// TODO: YOUR CODE HERE\n\n  // use Kokkos parallel_reduce to compute the max degree\n  // the Kokkos::View must be used in the lambda function\n  // it's easier to use a Kokkos reduction function instead of a parallel_reduce\n  // example:\n  // https://github.com/kokkos/kokkos-kernels/blob/master/src/KokkosBlas1_impl_dot.hpp\n\n  int max_degree = 0;\n\n  // you can also use other parallel constructs such as parallel_for,\n  // parallel_scan, etc...\n\n  // you can use the STL, Boost or any other library you want.\n\n  return max_degree;\n}",
            "// Define a functor that computes the max degree\n  struct MaxDegreeFunctor {\n    Kokkos::View<const int**> A;\n    int maxDegree;\n\n    MaxDegreeFunctor(Kokkos::View<const int**> A) : A(A), maxDegree(0) {}\n\n    KOKKOS_INLINE_FUNCTION\n    void operator()(const int &i) const {\n\n      int deg = 0;\n\n      for (int j = 0; j < A.extent(0); j++) {\n        if (A(i, j) > 0) {\n          deg++;\n        }\n      }\n\n      if (deg > maxDegree) {\n        maxDegree = deg;\n      }\n    }\n  };\n\n  // Instantiate the functor and execute\n  MaxDegreeFunctor functor(A);\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), functor);\n\n  // Get the result and return\n  return functor.maxDegree;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> degrees(\"degrees\", N);\n\tKokkos::parallel_for(\"degrees\", N, KOKKOS_LAMBDA (const int& i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tdegrees(i) = degree;\n\t});\n\n\tKokkos::fence();\n\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (degrees(i) > max)\n\t\t\tmax = degrees(i);\n\t}\n\n\treturn max;\n}",
            "int numThreads = 4;\n  Kokkos::parallel_reduce(\"Max degree\",\n\t\t\t  Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t\t  [&](int i, int &maxDegree) {\n\t\t\t    int count = 0;\n\t\t\t    for (int j=0; j < N; j++) {\n\t\t\t      if (A(i,j) > 0) {\n\t\t\t\tcount++;\n\t\t\t      }\n\t\t\t    }\n\t\t\t    if (count > maxDegree) {\n\t\t\t      maxDegree = count;\n\t\t\t    }\n\t\t\t  },\n\t\t\t  Kokkos::Max<int>(maxDegree));\n  Kokkos::fence();\n  return maxDegree;\n}",
            "int maxDegree = 0;\n  Kokkos::View<const int*> rowSum(\"rowSum\", N);\n  Kokkos::parallel_for(\n    \"RowSum\", N, KOKKOS_LAMBDA(const int i) {\n      rowSum(i) = 0;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j))\n          rowSum(i) += 1;\n      }\n    }\n  );\n  Kokkos::fence();\n  Kokkos::parallel_reduce(\n    \"MaxDegree\", N,\n    KOKKOS_LAMBDA(const int i, int& update) {\n      if (rowSum(i) > update)\n        update = rowSum(i);\n    },\n    Kokkos::Max<int>(maxDegree)\n  );\n  Kokkos::fence();\n  return maxDegree;\n}",
            "// Create a Kokkos view of the graph degrees.\n  Kokkos::View<int*> degrees(\"graphDegrees\", N);\n\n  // Compute the degree of each node in parallel.\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\t\t\t\tKOKKOS_LAMBDA (const int i) {\n\t\t\t\t\t\t\tint d = 0;\n\t\t\t\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t\t\t\td += A(i, j);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tdegrees(i) = d;\n\t\t\t\t\t\t});\n\n  // Make sure that all work has been completed.\n  Kokkos::fence();\n\n  // Find the highest degree of any node.\n  int maxDegree = 0;\n  for (int i = 0; i < N; ++i) {\n\t  if (degrees(i) > maxDegree) {\n\t\t  maxDegree = degrees(i);\n\t  }\n  }\n\n  return maxDegree;\n}",
            "// YOUR CODE HERE\n\treturn 0;\n}",
            "using device_exec_space = Kokkos::DefaultExecutionSpace;\n\n  /*\n  Create a Kokkos View to store the degree of each node.\n  */\n  Kokkos::View<int*, device_exec_space> deg(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"deg\"), N);\n  /*\n  Create a Kokkos View to store the maximum degree.\n  */\n  Kokkos::View<int*, device_exec_space> maxDeg(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"maxDeg\"), 1);\n\n  /*\n  Create a Kokkos parallel for to initialize the degree to 0.\n  */\n  Kokkos::parallel_for(Kokkos::RangePolicy<device_exec_space>(0, N),\n\t\t       KOKKOS_LAMBDA(const int& i) {\n\t\t\t deg(i) = 0;\n\t\t       });\n\n  /*\n  Create a Kokkos parallel for to compute the degree of each node.\n  */\n  Kokkos::parallel_for(Kokkos::RangePolicy<device_exec_space>(0, N),\n\t\t       KOKKOS_LAMBDA(const int& i) {\n\t\t\t for (int j = 0; j < N; j++)\n\t\t\t   if (A(i, j) > 0)\n\t\t\t     deg(i)++;\n\t\t       });\n\n  /*\n  Create a Kokkos parallel for to initialize the maximum degree to 0.\n  */\n  Kokkos::parallel_for(Kokkos::RangePolicy<device_exec_space>(0, 1),\n\t\t       KOKKOS_LAMBDA(const int& i) {\n\t\t\t maxDeg(i) = 0;\n\t\t       });\n\n  /*\n  Create a Kokkos parallel reduce to compute the maximum degree.\n  */\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<device_exec_space>(0, N),\n\t\t\t  KOKKOS_LAMBDA(const int& i, int& lmax) {\n\t\t\t    lmax = (lmax < deg(i))? deg(i) : lmax;\n\t\t\t  }, Kokkos::Max<int>(maxDeg(0)));\n\n  /*\n  Create a host mirror view to copy the result back to the host.\n  */\n  Kokkos::View<int*, Kokkos::HostSpace> maxDeg_host = Kokkos::create_mirror_view(maxDeg);\n  Kokkos::deep_copy(maxDeg_host, maxDeg);\n\n  int result = maxDeg_host(0);\n\n  return result;\n}",
            "// TODO\n}",
            "//TODO: Implement this function using a Kokkos parallel reduce\n  int max_degree = 0;\n\n  return max_degree;\n}",
            "int maximum = 0;\n\n  // Fill this in\n  return maximum;\n}",
            "auto a = Kokkos::subview(A, Kokkos::ALL(), 0);\n\tauto maxDegree = Kokkos::reduction_identity<int>::max();\n\tauto max = Kokkos::parallel_reduce(\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[=](const int &i, int &lmax) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tint d = 0;\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\td += A(i, j);\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlmax = (d > lmax)? d : lmax;\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tmaxDegree\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t);\n\treturn max.value;\n}",
            "Kokkos::View<int*,Kokkos::HostSpace> dmax(\"dmax\",N);\n  Kokkos::parallel_for(N,[&](const int i){\n    int max = 0;\n    for (int j=0; j<N; j++){\n      if (A(i,j)!= 0) max += 1;\n    }\n    dmax[i] = max;\n  });\n  int dmax_host = 0;\n  Kokkos::deep_copy(dmax_host,dmax);\n  for (int i=0; i<N; i++){\n    if (dmax_host[i] > dmax_host[0])\n      dmax_host[0] = dmax_host[i];\n  }\n  return dmax_host[0];\n}",
            "auto A_host = Kokkos::create_mirror_view(A);\n\tKokkos::deep_copy(A_host, A);\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tcount += A_host(i, j);\n\t\t}\n\t\tif (count > max) {\n\t\t\tmax = count;\n\t\t}\n\t}\n\treturn max;\n}",
            "int *counts = (int *)malloc(N*sizeof(int));\n\tKokkos::View<int *> count(\"counts\", N);\n\tKokkos::parallel_for(\"count_edges\", N, KOKKOS_LAMBDA (const int i) {\n\t\tcounts[i] = 0;\n\t});\n\n\tKokkos::parallel_for(\"count_edges\", N, KOKKOS_LAMBDA (const int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i,j)!= 0) {\n\t\t\t\tcounts[i]++;\n\t\t\t}\n\t\t}\n\t});\n\n\tint maxCount = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (counts[i] > maxCount) {\n\t\t\tmaxCount = counts[i];\n\t\t}\n\t}\n\n\tfree(counts);\n\treturn maxCount;\n}",
            "Kokkos::View<int*> degree(\"degree\", N);\n  Kokkos::parallel_for(\"max_degree\", N, KOKKOS_LAMBDA(const int i) {\n    int tmp = 0;\n    for(int j = 0; j < N; j++) {\n      tmp += A(i, j);\n    }\n    degree[i] = tmp;\n  });\n\n  int maxDegree = 0;\n  Kokkos::parallel_reduce(\"max_degree_reduce\", N, KOKKOS_LAMBDA(const int i, int &update) {\n    update = (degree[i] > update)? degree[i] : update;\n  }, Kokkos::Max<int>(maxDegree));\n\n  Kokkos::fence();\n  return maxDegree;\n}",
            "const int maxDegree = -1;\n\n\t// The code you write goes here\n\tKokkos::View<int*> degree(\"Degree\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [&] (int i) {\n\t\tint degree_sum = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tdegree_sum += A(i, j);\n\t\tKokkos::atomic_add(&degree(i), degree_sum);\n\t});\n\n\tint max_degree;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [&] (int i, int& max_degree_in) {\n\t\tif (degree(i) > max_degree_in)\n\t\t\tmax_degree_in = degree(i);\n\t}, Kokkos::Max<int>(max_degree));\n\n\tKokkos::fence();\n\treturn max_degree;\n}",
            "// TODO\n  //\n  // 1) Create a Kokkos::View of the maximum degree of all nodes\n  //\n  //    It should be the same size as the number of nodes in the graph, N\n  //    Initialize it to 0.\n  //\n  // 2) Create a parallel Kokkos::View with the same size as the number of nodes\n  //    This is the array that will be used for counting the degree of each node\n  //\n  //    Initialize the array to 0.\n  //\n  // 3) Kokkos::parallel_for(N)\n  //\n  //    Compute the degree of each node by looping over the rows of the adjacency matrix.\n  //    For each row, add 1 to the corresponding element of the degree array.\n  //\n  // 4) Kokkos::parallel_reduce(N)\n  //\n  //    Compute the maximum of the degrees of all nodes by finding the maximum of the elements\n  //    of the degree array\n  //\n  // 5) Return the maximum degree\n  //\n\n  int maxDegree = 0;\n  return maxDegree;\n}",
            "int maxDeg = 0;\n  int a;\n\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& lmaxDeg) {\n      int deg = 0;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) {\n          deg += 1;\n        }\n      }\n      if (deg > lmaxDeg) {\n        lmaxDeg = deg;\n      }\n    },\n    Kokkos::Max<int>(maxDeg));\n\n  return maxDeg;\n}",
            "int maxDegree = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& localMaxDegree) {\n    localMaxDegree = 0;\n    for (int j = 0; j < N; ++j) {\n      localMaxDegree += A(i, j);\n    }\n    localMaxDegree = (localMaxDegree > maxDegree)? localMaxDegree : maxDegree;\n  }, Kokkos::Max<int>(maxDegree));\n  return maxDegree;\n}",
            "/* Kokkos parallel_reduce.\n       This example is a simplified version of the parallel_reduce example in the Kokkos documentation.\n       We will only use the parallel_reduce pattern here, which is similar to a map-reduce\n       (see https://en.wikipedia.org/wiki/MapReduce).\n\n       We will use a custom struct for the parallel_reduce function.\n       The type of the struct is defined in the function signature.\n       The struct must have a function called operator() that is a function object.\n       The operator() function takes one parameter that is a tuple of Kokkos::View objects.\n       The operator() function must be marked as const.\n       The operator() function must be marked as static.\n       The operator() function must take an operator+= as the first parameter.\n       The operator() function will take the tuple of Kokkos::View objects.\n\n       The operator+= function must be marked as const.\n       The operator+= function must take a const Kokkos::View& as the first parameter.\n       The operator+= function will take the tuple of Kokkos::View objects.\n    */\n    struct MaxDegreeOp {\n        KOKKOS_INLINE_FUNCTION\n        static void operator()(int& max_degree, const int& value) const {\n            if (value > max_degree)\n                max_degree = value;\n        }\n\n        KOKKOS_INLINE_FUNCTION\n        static void operator()(const MaxDegreeOp&, const int& value, int& max_degree) const {\n            if (value > max_degree)\n                max_degree = value;\n        }\n    };\n\n    /* Kokkos parallel_reduce function.\n       The parallel_reduce function takes a Kokkos::View of the operator struct,\n       a const Kokkos::View of the input data,\n       and a const lambda function to initialize the output data.\n       The function will run in parallel.\n\n       See the example in the Kokkos documentation at:\n       https://github.com/kokkos/kokkos/blob/master/example/tutorial/parallel_reduce/parallel_reduce.cpp\n    */\n    Kokkos::parallel_reduce(\n        \"MaxDegree\",\n        Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n        MaxDegreeOp(),\n        Kokkos::View<int>(Kokkos::ViewAllocateWithoutInitializing(\"max_degree\"), 0),\n        [=] (int i) {\n            /* Kokkos reduction operator.\n               The reduction operator takes one parameter that is a tuple of Kokkos::View objects.\n               The parameter must be marked as const.\n               The parameter must be marked as static.\n               The parameter must take a const Kokkos::View& as the first parameter.\n               The parameter will take the tuple of Kokkos::View objects.\n            */\n            Kokkos::parallel_reduce(\n                Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n                [=] (int j) {\n                    if (A(i, j))\n                        MaxDegreeOp::operator()(i, 1);\n                },\n                MaxDegreeOp()\n            );\n        }\n    );\n    return max_degree;\n}",
            "// TODO\n  // implement this function\n  return 0;\n}",
            "int max_degree = 0;\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int& lmax_degree) {\n\t\t\tint sum = 0;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tsum += A(i, j);\n\t\t\t}\n\t\t\tlmax_degree = std::max(lmax_degree, sum);\n\t\t},\n\t\tKokkos::Max<int>(max_degree)\n\t);\n\n\tint max_degree_host;\n\tKokkos::deep_copy(max_degree_host, max_degree);\n\treturn max_degree_host;\n}",
            "int max_degree = 0;\n  Kokkos::parallel_reduce(\"max_degree\",\n\t\t\t  Kokkos::RangePolicy<Kokkos::Rank<2>>(0,N,0,N),\n\t\t\t  KOKKOS_LAMBDA(const int &i, const int &j, int &max_degree) {\n\t\t\t    max_degree = std::max(max_degree, A(i,j));\n\t\t\t  }, Kokkos::Max<int>(max_degree));\n  return max_degree;\n}",
            "Kokkos::View<int*> degrees(\"degrees\", N);\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n      KOKKOS_LAMBDA(const int i) {\n        int deg = 0;\n        for (int j = 0; j < N; j++) {\n          deg += A(i, j);\n        }\n        degrees(i) = deg;\n      });\n  int* h_degrees = new int[N];\n  Kokkos::deep_copy(h_degrees, degrees);\n  int maxDegree = h_degrees[0];\n  for (int i = 1; i < N; i++) {\n    if (h_degrees[i] > maxDegree) {\n      maxDegree = h_degrees[i];\n    }\n  }\n  return maxDegree;\n}",
            "using namespace Kokkos;\n\n  typedef View<int*, HostSpace> HostViewType;\n\n  HostViewType h_degrees(\"degrees\", N);\n\n  // Compute degrees on host\n  auto host_policy = Kokkos::RangePolicy<HostSpace>(0, N);\n  Kokkos::parallel_for(host_policy, KOKKOS_LAMBDA(int i) {\n    int numNeighbors = 0;\n    for (int j = 0; j < N; j++) {\n      numNeighbors += A(i, j);\n    }\n    h_degrees(i) = numNeighbors;\n  });\n\n  // Compute max degree on host\n  auto result = std::max_element(h_degrees.data(), h_degrees.data() + N);\n  return *result;\n}",
            "// TODO: Replace the code below with your solution to the exercise\n\n    // Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n    // A is an NxN adjacency matrix.\n    // Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n    // Example:\n    //\n    // input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n    // output: 3\n\n    // Get the execution space from the adjacency matrix A\n    Kokkos::View<const int**>::HostMirror A_host = Kokkos::create_mirror_view(A);\n    Kokkos::deep_copy(A_host, A);\n\n    // Check to make sure we have an adjacency matrix\n    assert(N*N == A_host.dimension(0)*A_host.dimension(1));\n\n    // Create a view on the execution space to store the highest degree\n    Kokkos::View<int, Kokkos::HostSpace> max_degree(\"Max degree\", 1);\n    max_degree() = 0;\n\n    // Create a parallel for loop to compute the maximum degree\n    Kokkos::parallel_for(\"Max degree\", N, KOKKOS_LAMBDA(const int& i) {\n        int degree = 0;\n        for(int j = 0; j < N; ++j) {\n            if(A_host(i,j)!= 0) {\n                ++degree;\n            }\n        }\n        if(degree > max_degree()) {\n            max_degree() = degree;\n        }\n    });\n    Kokkos::fence();\n\n    // Return the maximum degree\n    return max_degree();\n}",
            "Kokkos::View<int*> row_sums(\"row_sums\", N);\n  Kokkos::parallel_for(\n    \"row_sums\",\n    Kokkos::RangePolicy<Kokkos::Rank<2>>(\n      Kokkos::make_pair(0, 0),\n      Kokkos::make_pair(N, N)\n    ),\n    KOKKOS_LAMBDA(const int i, const int j) {\n      if (i!= j) {\n        row_sums[i] += A(i, j);\n      }\n    }\n  );\n  Kokkos::View<int*> row_sums_host(Kokkos::create_mirror_view(row_sums));\n  Kokkos::deep_copy(row_sums_host, row_sums);\n  int max_degree = row_sums_host(0);\n  for (int i = 0; i < N; i++) {\n    if (max_degree < row_sums_host(i)) {\n      max_degree = row_sums_host(i);\n    }\n  }\n  return max_degree;\n}",
            "/* ASSIGNMENT 1: Implement this function */\n\n\treturn 0;\n}",
            "// define local max for each thread\n    Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> localMax(Kokkos::ViewAllocateWithoutInitializing(\"\"), Kokkos::DefaultExecutionSpace::concurrency());\n    // initialize localMax to 0\n    Kokkos::parallel_for(\"initLocalMax\", Kokkos::DefaultExecutionSpace(), N, KOKKOS_LAMBDA (const int &i) {\n        localMax(i) = 0;\n    });\n    Kokkos::fence();\n\n    // find local maxes\n    Kokkos::parallel_for(\"findLocalMaxes\", Kokkos::DefaultExecutionSpace(), N, KOKKOS_LAMBDA (const int &i) {\n        int localMaxVal = 0;\n        for(int j = 0; j < N; ++j) {\n            localMaxVal += A(i, j);\n        }\n        localMax(i) = localMaxVal;\n    });\n    Kokkos::fence();\n\n    // find global max\n    int globalMaxVal = 0;\n    Kokkos::parallel_reduce(\"reduceMax\", Kokkos::DefaultExecutionSpace(), N, KOKKOS_LAMBDA (const int &i, int &lsum) {\n        lsum = std::max(lsum, localMax(i));\n    }, Kokkos::Sum<int>(globalMaxVal));\n    Kokkos::fence();\n\n    return globalMaxVal;\n}",
            "using Kokkos::ALL;\n\tusing Kokkos::RangePolicy;\n\tusing Kokkos::parallel_for;\n\n\tint* degree = (int*)malloc(sizeof(int)*N);\n\n\t// Compute the degree of each vertex\n\tKokkos::View<int*, Kokkos::HostSpace> host_degree(degree, N);\n\tKokkos::View<const int*, Kokkos::HostSpace> host_A(A.data(), N*N);\n\tKokkos::View<int*, Kokkos::HostSpace> host_A_T(A.data(), N*N);\n\n\t// Create a Kokkos copy of A for the CPU\n\tKokkos::fence();\n\tKokkos::deep_copy(host_A_T, A);\n\tKokkos::fence();\n\n\tparallel_for(RangePolicy<>(0, N), [=] (int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (host_A_T(j, i)!= 0)\n\t\t\t\thost_degree(i)++;\n\t\t}\n\t});\n\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (maxDegree < degree[i])\n\t\t\tmaxDegree = degree[i];\n\t}\n\n\tfree(degree);\n\n\treturn maxDegree;\n}",
            "Kokkos::View<int*,Kokkos::HostSpace> degree(\"Degree\", N);\n\t\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N), [=] (const int& i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1)\n\t\t\t\tsum++;\n\t\t}\n\t\tdegree[i] = sum;\n\t});\n\t\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tmaxDegree = (degree[i] > maxDegree)? degree[i] : maxDegree;\n\t}\n\t\n\treturn maxDegree;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> maxDegree(\"maxDegree\");\n  Kokkos::View<const int**, Kokkos::HostSpace> A_copy(A.data(), N, N);\n  Kokkos::parallel_for(\n    \"maxDegree\",\n    Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      int max = 0;\n      for (int j = 0; j < N; j++) {\n        if (A_copy(i, j)!= 0) {\n          max++;\n        }\n      }\n      maxDegree(i) = max;\n    }\n  );\n  Kokkos::HostSpace::execution_space().fence();\n\n  int max = 0;\n  for (int i = 0; i < N; i++) {\n    max = std::max(max, maxDegree(i));\n  }\n  return max;\n}",
            "// TODO\n  return 0;\n}",
            "Kokkos::View<int*> dmax(\"degree max\", 1);\n\n\tKokkos::parallel_for(\n\t\t\"max degree\",\n\t\tKokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::ExecutionSpace>>(0, N),\n\t\tKOKKOS_LAMBDA(const int &i) {\n\t\t\tint max = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)) max++;\n\t\t\t}\n\t\t\tKokkos::atomic_max(&(dmax(0)), max);\n\t\t}\n\t);\n\n\tint* dmax_h;\n\tKokkos::View<int*, Kokkos::HostSpace> dmax_h_view(\"dmax_h\", 1);\n\tKokkos::deep_copy(dmax_h_view, dmax);\n\tdmax_h = dmax_h_view.data();\n\treturn *dmax_h;\n}",
            "int max_degree = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A(i,j)!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmax_degree = max(max_degree, degree);\n\t}\n\treturn max_degree;\n}",
            "// Kokkos::View<int*> B(\"B\", N);\n  // Kokkos::parallel_for(\"B = A' * A\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(size_t i) {\n  // \t B(i) = 0;\n  // \t for (size_t j = 0; j < N; j++) {\n  // \t\t for (size_t k = 0; k < N; k++) {\n  // \t\t\t B(i) += A(j, k) * A(i, k);\n  // \t\t }\n  // \t }\n  // });\n  // Kokkos::fence();\n  // int maxDegree = 0;\n  // for (size_t i = 0; i < N; i++) {\n  // \t maxDegree = std::max(maxDegree, B(i));\n  // }\n  // return maxDegree;\n  Kokkos::View<int*> B(\"B\", N);\n  Kokkos::parallel_for(\"B = A' * A\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(size_t i) {\n\t  B(i) = 0;\n\t  for (size_t j = 0; j < N; j++) {\n\t\t  for (size_t k = 0; k < N; k++) {\n\t\t\t  B(i) += A(j, k) * A(i, k);\n\t\t  }\n\t  }\n  });\n  Kokkos::fence();\n  int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n\t  maxDegree = std::max(maxDegree, B(i));\n  }\n  return maxDegree;\n}",
            "// Kokkos has a max() function, but it is not used here so that the\n\t// algorithm can be compared to the sequential algorithm.\n\t// See https://github.com/kokkos/kokkos/wiki/Containers-Views#views\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n  // TODO: compute the maximum degree of the graph using parallel_reduce\n\n  return maxDegree;\n}",
            "Kokkos::View<int**> D; // node degree\n\t\n\t// TODO: allocate degree view\n\t\n\tint maxDegree = 0;\n\t\n\t// TODO: compute degrees in parallel\n\t\n\treturn maxDegree;\n}",
            "// Initialize the maximum degree to 0\n\tint maxDegree = 0;\n\n\t// Initialize the Kokkos parallelization for loops with the execution space and the loop\n\t// schedule\n\tKokkos::View<int*> maxDegreeView(\"maxDegreeView\", 1);\n\tKokkos::parallel_for(\"MaxDegree\", Kokkos::RangePolicy<>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i) {\n\n\t\t// For each node in the graph...\n\t\tint nodeDegree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tnodeDegree++;\n\t\t\t}\n\t\t}\n\n\t\t// Update the maximum degree\n\t\tKokkos::atomic_max(&maxDegreeView(0), nodeDegree);\n\t});\n\n\t// Copy the maximum degree back to the host\n\tKokkos::deep_copy(maxDegree, maxDegreeView);\n\n\treturn maxDegree;\n}",
            "using Kokkos::parallel_reduce;\n\tusing Kokkos::RangePolicy;\n\tusing Kokkos::MDRangePolicy;\n\tusing Kokkos::AUTO;\n\tusing Kokkos::ALL;\n\n\tint result = 0;\n\n\t// Compute the maximum number of neighbors in parallel using a parallel_reduce\n\tparallel_reduce(\"max_degree\", RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i, int &l_max_degree) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t\tif (sum > l_max_degree) {\n\t\t\tl_max_degree = sum;\n\t\t}\n\t}, Kokkos::Max<int>(result));\n\n\treturn result;\n}",
            "// Your code here\n    int maxDegree = 0;\n    int degree;\n    for(int i = 0; i < N; i++){\n        degree = 0;\n        for(int j = 0; j < N; j++){\n            degree += A(i,j);\n        }\n        if(degree > maxDegree)\n            maxDegree = degree;\n    }\n    return maxDegree;\n}",
            "Kokkos::View<int*> max_degree(\"max_degree\", N);\n\n\t// Set up parallel_for loop. For each node, find its degree and update the max_degree vector\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tint my_degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tmy_degree += A(i, j);\n\t\t}\n\t\tmax_degree(i) = my_degree;\n\t});\n\n\t// Find the highest degree of the node\n\tint max_degree_val = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (max_degree(i) > max_degree_val) {\n\t\t\tmax_degree_val = max_degree(i);\n\t\t}\n\t}\n\n\t// Copy back to host and return\n\tint* max_degree_val_host = (int*) malloc(sizeof(int));\n\tKokkos::deep_copy(max_degree_val_host, max_degree);\n\tint ret = max_degree_val_host[0];\n\tfree(max_degree_val_host);\n\n\treturn ret;\n}",
            "Kokkos::View<int*> nDegree(\"nDegree\", N);\n\n    auto maxDegree = Kokkos::Max<int>(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (const int &i) {\n        int deg = 0;\n\n        for (int j = 0; j < N; j++) {\n            if (A(i, j)!= 0)\n                deg++;\n        }\n\n        return deg;\n    });\n\n    Kokkos::parallel_reduce(\"maxDegree\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), maxDegree, Kokkos::Max<int>(nDegree));\n\n    int res = 0;\n    for (int i = 0; i < N; i++)\n        res = Kokkos::Max(res, nDegree(i));\n\n    return res;\n}",
            "// TODO: set max degree value\n  int max_degree = 0;\n\n  // TODO: set work array to store the number of neighbors of each vertex\n  Kokkos::View<int*> work(\"work\", N);\n\n  // TODO: initialize work array\n  // Hint: Kokkos parallel for\n\n  // TODO: find the maximum\n  // Hint: Kokkos parallel reduce\n\n  return max_degree;\n}",
            "using device_int_view_t = Kokkos::View<int*>;\n\tusing device_int_t = int;\n\n\t// Allocate a device_int_view_t with N elements\n\tdevice_int_view_t result_view(\"result_view\", N);\n\tdevice_int_t* result_view_pointer = result_view.data();\n\n\t// Reset each element in the view to 0\n\tKokkos::deep_copy(result_view, 0);\n\n\t// Compute the highest degree for each row in parallel\n\tKokkos::parallel_for(\"max_degree_per_row\", N,\n\t\tKOKKOS_LAMBDA (const int& i) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t\tresult_view_pointer[i] = count;\n\t});\n\n\t// Sum the elements of the result_view in parallel\n\tint max_degree = Kokkos::parallel_reduce(\"max_degree\", N,\n\t\tKOKKOS_LAMBDA (const int& i, int sum) {\n\t\treturn result_view_pointer[i] + sum;\n\t}, 0);\n\n\treturn max_degree;\n}",
            "int max = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),\n\t\tKOKKOS_LAMBDA (const int i, int &max) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j) > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > max) {\n\t\t\tmax = degree;\n\t\t}\n\t}, max);\n\treturn max;\n}",
            "// Create a reduction variable. We use the default value of zero\n\t// to get the maximum degree.\n\t// We need to specify a type to use for the value.\n\t// Because we are using atomic_max with ints, we need to use int,\n\t// not unsigned int.\n\tKokkos::View<int, Kokkos::LayoutLeft, Kokkos::HostSpace> maxDegree(\"maxDegree\", 1);\n\n\t// Create a functor to compute the maximum degree\n\t// The struct should be defined in the global scope\n\t// so that Kokkos can access it.\n\tstruct MaxDegree {\n\t\tKokkos::View<const int**> _A;\n\t\tKokkos::View<int, Kokkos::LayoutLeft, Kokkos::HostSpace> _maxDegree;\n\n\t\t// The operator() defines the code that is executed by the functor.\n\t\t// Here, we use a parallel_reduce algorithm to get the maximum\n\t\t// degree.\n\t\t// The range is the entire graph, and the lambda function\n\t\t// computes the degree of each node and then takes the maximum\n\t\t// over the degrees of the node.\n\t\t// The value of the reduction variable is passed to the functor.\n\t\tKOKKOS_INLINE_FUNCTION void operator()(const int &i, int &maxDegree) const {\n\t\t\tint localMaxDegree = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (_A(i, j) > 0) {\n\t\t\t\t\tlocalMaxDegree++;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Atomic update to get the maximum degree\n\t\t\tKokkos::atomic_max(&_maxDegree(0), localMaxDegree);\n\t\t}\n\t};\n\n\t// Execute the functor.\n\tKokkos::parallel_reduce(\n\t\t\"MaxDegree\",\n\t\tN,\n\t\tMaxDegree{A, maxDegree},\n\t\tmaxDegree\n\t);\n\n\t// Return the maximum degree\n\treturn maxDegree(0);\n}",
            "int maxDegree = 0;\n\tauto maxDegree_functor = KOKKOS_LAMBDA (const int &i, const int &j) {\n\t\tint degree = 0;\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A(i, k) == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t};\n\tKokkos::RangePolicy<Kokkos::ReducePolicy<Kokkos::ReduceMax<int> >, decltype(maxDegree_functor)> rangePolicy(0, N);\n\tKokkos::parallel_reduce(\"maxDegree_functor\", rangePolicy, maxDegree_functor);\n\tKokkos::fence();\n\treturn maxDegree;\n}",
            "Kokkos::View<int*> maxDegreeView(\"maxDegree\", 1);\n  Kokkos::View<int*> degreeView(\"degrees\", N);\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      if (A(i, j))\n        sum++;\n    }\n    degreeView(i) = sum;\n  });\n  int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    maxDegree = Kokkos::max(maxDegreeView(0), degreeView(i));\n  }\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    degreeView(i) = 0;\n  });\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      if (A(i, j))\n        degreeView(i)++;\n    }\n  });\n  maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    maxDegree = Kokkos::max(maxDegreeView(0), degreeView(i));\n  }\n  return maxDegree;\n}",
            "// Define a functor to count the node degrees, using a parallel_reduce\n  class CountNodeDegrees {\n    Kokkos::View<const int**> A;\n    public:\n    int *result;\n    CountNodeDegrees(Kokkos::View<const int**> A): A(A) {}\n    KOKKOS_INLINE_FUNCTION\n    void operator() (const int &i, int &count) const {\n      count = 0;\n      for (int j=0; j<A.extent(1); j++) {\n        count += A(i,j);\n      }\n    }\n    KOKKOS_INLINE_FUNCTION\n    void join (int &count, const int &value) const {\n      count += value;\n    }\n  };\n\n  // Initialize a Kokkos view to hold the max degree\n  Kokkos::View<int> degree(\"max degree\", 1);\n  // Initialize the max degree to zero\n  Kokkos::deep_copy(degree, 0);\n  // Count degrees in parallel\n  CountNodeDegrees functor(A);\n  Kokkos::parallel_reduce(\"Count node degrees\", N, functor, degree);\n  // Copy to host memory\n  int maxDegree = 0;\n  Kokkos::deep_copy(maxDegree, degree);\n  // return the max degree\n  return maxDegree;\n}",
            "/*\n  // TODO: Fill in your code here\n  */\n  return 0;\n}",
            "using namespace Kokkos;\n\n\tView<int*,HostSpace> rowDegrees(\"rowDegrees\",N);\n\tView<int*,HostSpace> colDegrees(\"colDegrees\",N);\n\t\n\t// Compute row degrees\n\tparallel_for(range<int>(0,N),[&](const int row) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tsum += A(row,i);\n\t\trowDegrees(row) = sum;\n\t});\n\n\t// Compute column degrees\n\tparallel_for(range<int>(0,N),[&](const int col) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tsum += A(j,col);\n\t\tcolDegrees(col) = sum;\n\t});\n\n\t// Find max\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (rowDegrees(i) > max)\n\t\t\tmax = rowDegrees(i);\n\t\tif (colDegrees(i) > max)\n\t\t\tmax = colDegrees(i);\n\t}\n\treturn max;\n}",
            "using namespace Kokkos;\n\n\ttypedef Kokkos::DefaultExecutionSpace execution_space;\n\ttypedef Kokkos::DefaultHostExecutionSpace host_execution_space;\n\n\ttypedef View<int*, execution_space> view_type;\n\ttypedef View<int*, host_execution_space> host_view_type;\n\n\t// Create Kokkos view of A\n\tview_type A_kok(A.data(), A.data() + N * N);\n\n\t// Compute the maximum degree\n\tview_type maxDegree_kok(\"maxDegree\", 1);\n\tKokkos::parallel_reduce(N, [&] (size_t i, int& lmax) {\n\t\tint rowSum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\trowSum += A_kok(i, j);\n\t\t}\n\t\tlmax = std::max(lmax, rowSum);\n\t}, Kokkos::Max<int>(maxDegree_kok));\n\n\t// Copy result back to host\n\thost_view_type maxDegree_host(\"maxDegree_host\", 1);\n\tKokkos::deep_copy(maxDegree_host, maxDegree_kok);\n\n\t// Return the result\n\treturn maxDegree_host(0);\n}",
            "// Create an array in Kokkos to hold the node degree values\n\tKokkos::View<int*> maxDegreeArray(\"MaxDegreeArray\", N);\n\n\t// Set all values in the array to 0\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t\tmaxDegreeArray(i) = 0;\n\t});\n\n\t// Find the maximum degree in the graph\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tmaxDegreeArray(i) += 1;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Determine the highest degree\n\tint maxDegree = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int& value) {\n\t\tvalue = std::max(value, maxDegreeArray(i));\n\t}, Kokkos::Max<int>(maxDegree));\n\n\treturn maxDegree;\n}",
            "int highestDegree = 0;\n\tKokkos::parallel_reduce(\"max_degree\", N, KOKKOS_LAMBDA(const int i, int &localHighestDegree) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tif (degree > localHighestDegree) {\n\t\t\tlocalHighestDegree = degree;\n\t\t}\n\t}, Kokkos::Max<int>(highestDegree));\n\n\treturn highestDegree;\n}",
            "// Create the execution space (parallel_for) and the data space (parallel_reduce)\n\tKokkos::View<int*> maxDegree_view(\"maxDegree\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA (const int &i) {\n\t\tint local_max = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tlocal_max = (A(i,j) > 0)? local_max + 1 : local_max;\n\t\tmaxDegree_view(i) = local_max;\n\t});\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA (const int &i, int& local_max_degree) {\n\t\tif (maxDegree_view(i) > local_max_degree)\n\t\t\tlocal_max_degree = maxDegree_view(i);\n\t}, Kokkos::Max<int>(maxDegree_view(0)));\n\tint max_degree = maxDegree_view(0);\n\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i, int &lmax) {\n\t\t\t\tint count = 0;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j)!= 0)\n\t\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t\tif (count > lmax)\n\t\t\t\t\tlmax = count;\n\t\t\t},\n\t\t\tKokkos::Max<int>(maxDegree));\n\treturn maxDegree;\n}",
            "Kokkos::View<int*> count(\"Count\", N);\n    Kokkos::parallel_for(\"MaxDegree\", N, KOKKOS_LAMBDA (const int &i) {\n        int count_i = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j)) {\n                count_i++;\n            }\n        }\n        count(i) = count_i;\n    });\n    Kokkos::View<int*> max_count(\"MaxCount\", 1);\n    Kokkos::parallel_reduce(\"MaxDegreeReduction\", N, KOKKOS_LAMBDA (const int &i, int &max_count_i) {\n        if (count(i) > max_count_i) {\n            max_count_i = count(i);\n        }\n    }, Kokkos::Max<int>(max_count(0)));\n    return max_count(0);\n}",
            "// Kokkos::View<int*> degree(\"degree\", N);\n  int maxDegree = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A(i, j) == 1) {\n        degree++;\n      }\n    }\n    // degree[i] = degree;\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n\n  return maxDegree;\n}",
            "auto maxDegree = Kokkos::View<int*>(\"maxDegree\", 1);\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), [=](int i) {\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), [=](int j) {\n      if (A(i, j) == 1) {\n        if (i == j) {\n          // diagonal\n          if (i > maxDegree(0)) {\n            maxDegree(0) = i;\n          }\n        } else {\n          // off diagonal\n          if (maxDegree(0) < 2) {\n            maxDegree(0) = 2;\n          }\n        }\n      }\n    });\n  });\n  Kokkos::fence();\n  int result;\n  Kokkos::deep_copy(result, maxDegree(0));\n  return result;\n}",
            "// TODO: Implement this.\n\t// Hint: Use Kokkos reduction to compute the highest degree in parallel.\n\t// Make sure to return the highest degree in the graph.\n\tint n = 0;\n\n\tfor(size_t i=0; i<N; i++){\n\t\tint k = 0;\n\t\tfor(size_t j=0; j<N; j++){\n\t\t\tk+= A(i,j);\n\t\t}\n\t\tif(k > n){\n\t\t\tn = k;\n\t\t}\n\t}\n\treturn n;\n\n}",
            "Kokkos::View<int*> maxDegreePerNode(\"Max degree per node\", N);\n\t// Parallelize over nodes.\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t i) {\n\t\tint maxDegree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\tmaxDegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegreePerNode(i) = maxDegree;\n\t});\n\n\tint maxDegree = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(const size_t i, int& local_maxDegree) {\n\t\tif (maxDegreePerNode(i) > local_maxDegree) {\n\t\t\tlocal_maxDegree = maxDegreePerNode(i);\n\t\t}\n\t}, Kokkos::Sum<int>(maxDegree));\n\n\treturn maxDegree;\n}",
            "// Define the Kokkos reduction operation.\n  using DegreeReduction = Kokkos::Max<Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::MemoryUnmanaged> >;\n  // Allocate a view to hold the degree of each node.\n  Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::MemoryUnmanaged> degrees(\"degrees\");\n  // Set the initial degree to 0.\n  Kokkos::parallel_for(\"init\", N, KOKKOS_LAMBDA(const int i) {\n    degrees(i) = 0;\n  });\n  // Compute the number of neighbors of each node.\n  Kokkos::parallel_for(\"compute_degrees\", N, KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)!= 0) {\n        degrees(i) += 1;\n      }\n    }\n  });\n  // Get the maximum degree.\n  int maxDegree = Kokkos::reduction_max(N, DegreeReduction(degrees));\n  return maxDegree;\n}",
            "Kokkos::View<int*> workspace(\"workspace\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(const int& i) {\n      int n = 0;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j) == 1) {\n          n++;\n        }\n      }\n      workspace(i) = n;\n    }\n  );\n  Kokkos::fence();\n  int max = 0;\n  for (int i = 0; i < N; i++) {\n    if (workspace(i) > max) {\n      max = workspace(i);\n    }\n  }\n  return max;\n}",
            "int max = 0;\n  for (int i = 0; i < N; ++i) {\n    int sum = 0;\n    for (int j = 0; j < N; ++j) {\n      sum += A(i, j);\n    }\n    max = (sum > max)? sum : max;\n  }\n  return max;\n}",
            "Kokkos::View<int*> d_maxDegree(\"maxDegree\", 1);\n  Kokkos::parallel_for(Kokkos::RangePolicy<decltype(omp_get_max_threads())>(0, omp_get_max_threads()),\n\t\t\t\t\t  [&] (int id) {\n\t\t\t\t\t\tint myMax = 0;\n\t\t\t\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\t\t\t  for (size_t j = 0; j < N; j++) {\n\t\t\t\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t\t\t  myMax++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t  }\n\t\t\t\t\t\t}\n\t\t\t\t\t\tKokkos::atomic_max(&d_maxDegree(0), myMax);\n\t\t\t\t\t  });\n\n  int maxDegree;\n  Kokkos::deep_copy(maxDegree, d_maxDegree);\n  return maxDegree;\n}",
            "Kokkos::View<int**> workspace(\"workspace\", N, N);\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tworkspace(i, j) = 0;\n\t\t}\n\t});\n\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tworkspace(i, j) = 1;\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::View<int**> workspaceT(\"workspaceT\", N, N);\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tworkspaceT(i, j) = 0;\n\t\t}\n\t});\n\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\tif (workspace(i, j) == 1 && workspace(j, k) == 1) {\n\t\t\t\t\tworkspaceT(i, k) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\tint maxDegree = 0;\n\tKokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tmaxDegree = std::max(maxDegree, workspaceT(i, j));\n\t\t}\n\t});\n\n\treturn maxDegree;\n}",
            "// Write your solution here.\n\tint max_degree = 0;\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(int i, int &local_max) {\n\t\t\tint degree = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)) {\n\t\t\t\t\tdegree++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlocal_max = Kokkos::max(local_max, degree);\n\t\t},\n\t\tmax_degree\n\t);\n\treturn max_degree;\n}",
            "auto n = N;\n\n  // Define the lambda function\n  auto maxDegreeLambda = KOKKOS_LAMBDA(const int i, int& maxDegree) {\n    int degree = 0;\n    for (int j = 0; j < n; ++j) {\n      degree += A(i, j);\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  };\n\n  // Initialize the result and run the lambda function\n  int maxDegreeResult = 0;\n  Kokkos::parallel_reduce(\n      Kokkos::RangePolicy<Kokkos::OpenMP>(0, n), maxDegreeLambda, maxDegreeResult);\n  return maxDegreeResult;\n}",
            "Kokkos::View<int**> max_degree(\"max_degree\", N, N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) {\n    for (size_t j = 0; j < N; j++) {\n      max_degree(i, j) = A(i, j);\n    }\n  });\n  Kokkos::fence();\n  int max_deg = 0;\n  for (size_t i = 0; i < N; i++) {\n    int d = 0;\n    for (size_t j = 0; j < N; j++) {\n      d += A(i, j);\n    }\n    if (d > max_deg) max_deg = d;\n  }\n  Kokkos::fence();\n  return max_deg;\n}",
            "Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> degrees(\"Degrees\", N);\n  for (int i = 0; i < N; i++) {\n    degrees(i) = 0;\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)) {\n\tdegrees(i)++;\n      }\n    }\n  }\n  int maxDegree = -1;\n  for (int i = 0; i < N; i++) {\n    if (degrees(i) > maxDegree) {\n      maxDegree = degrees(i);\n    }\n  }\n  return maxDegree;\n}",
            "Kokkos::View<int*> degrees(\"degrees\", N);\n  Kokkos::parallel_for(\"ComputeDegrees\", N, KOKKOS_LAMBDA(const int& i) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        ++degree;\n      }\n    }\n    degrees(i) = degree;\n  });\n  int result = 0;\n  Kokkos::parallel_reduce(\"FindMaxDegree\", N, KOKKOS_LAMBDA(const int& i, int& l",
            "// TODO: create view for node degrees\n    Kokkos::View<int *> nodeDegrees(\"nodeDegrees\", N);\n\n    // TODO: create functor that sets nodeDegrees\n    struct setNodeDegrees {\n        setNodeDegrees(Kokkos::View<int *> nodeDegrees) : _nodeDegrees(nodeDegrees) {}\n        KOKKOS_INLINE_FUNCTION\n        void operator()(const int i) const {\n            for (int j = 0; j < N; j++) {\n                if (A(i, j) == 1) {\n                    _nodeDegrees(i) += 1;\n                }\n            }\n        }\n        Kokkos::View<int *> _nodeDegrees;\n    } setNodeDegreesFunctor(nodeDegrees);\n\n    // TODO: run parallel_for\n    Kokkos::parallel_for(N, setNodeDegreesFunctor);\n    Kokkos::fence();\n\n    // TODO: return the maximum node degree\n    return 0;\n}",
            "int maxDeg = 0;\n  for (size_t i = 0; i < N; i++) {\n    int d = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A(i, j)!= 0) d += 1;\n    }\n    maxDeg = std::max(d, maxDeg);\n  }\n  return maxDeg;\n}",
            "Kokkos::View<int*> nodeDegrees(\"Node Degrees\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Reduce<Kokkos::ReduceMax<int> > >(0, N),\n                       KOKKOS_LAMBDA (const int& i) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A(i, j);\n    }\n    nodeDegrees(i) = degree;\n  });\n  int maxDegree = Kokkos::reduction_identity<int>();\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Reduce<Kokkos::ReduceMax<int> > >(0, N),\n                          KOKKOS_LAMBDA (const int& i, int& lmax) {\n    lmax = Kokkos::Max(lmax, nodeDegrees(i));\n  }, maxDegree);\n  return maxDegree;\n}",
            "// Declare the reduction variable and initialize it to 0\n    Kokkos::View<int, Kokkos::LayoutLeft, Kokkos::MemoryUnmanaged> maxDegree(\"maxDegree\", 1);\n    Kokkos::deep_copy(maxDegree, 0);\n\n    // Declare the functor and initialize it with the graph data\n    maxDegreeFunctor functor(A, N, maxDegree);\n\n    // Compute the maximum degree in parallel using a team policy\n    Kokkos::parallel_reduce(\"maxDegree\", Kokkos::TeamPolicy<>(N, 1), functor);\n\n    // Copy the final result to the host\n    int md;\n    Kokkos::deep_copy(md, maxDegree);\n\n    // Return the max degree\n    return md;\n}",
            "// TODO: use Kokkos to compute the maximum degree\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> maxDegree(\"maxDegree\", 1);\n\n  // Set to zero\n  Kokkos::deep_copy(maxDegree, 0);\n\n  // Set up parallel_for\n  auto policy = Kokkos::RangePolicy<Kokkos::Rank<2>>({0, 0}, {N, N});\n  auto functor = KOKKOS_LAMBDA(const int i, const int j) {\n    if (A(i, j)!= 0) {\n      // Atomic increment the value of maxDegree(0)\n      Kokkos::atomic_increment(&maxDegree(0));\n    }\n  };\n\n  Kokkos::parallel_for(\"max_degree\", policy, functor);\n  Kokkos::fence();\n\n  return maxDegree(0);\n}",
            "/* Create a Kokkos view that will hold the maximum degree */\n  Kokkos::View<int> maxDegree(\"maxDegree\", 1);\n\n  /* Declare a Kokkos reduction variable.\n   * The initial value is 0, and the operation is MAX. */\n  auto rMaxDegree = Kokkos::Max<int>(maxDegree);\n\n  /* Create a parallel for that will loop over each node in A.\n   * Use the reduction variable to find the maximum degree. */\n  Kokkos::parallel_for(\"maxDegree\", N,\n    KOKKOS_LAMBDA(size_t i) {\n      /* Count the number of edges from this node */\n      int count = 0;\n      for (int j = 0; j < N; j++) {\n        count += A(i, j);\n      }\n\n      /* Store the count as the maximum degree seen so far */\n      rMaxDegree = count;\n    }\n  );\n\n  /* Return the maximum degree */\n  return maxDegree();\n}",
            "// Kokkos's parallel_reduce takes a function as an argument.\n\t// parallel_reduce returns a Kokkos::View<T> object of type T, which can be used to retrieve the result in the host.\n\t// Here, we have a Kokkos::View<int> object max_degree_view\n\tKokkos::View<int> max_degree_view(\"max_degree_view\", 1);\n\n\t// The function passed to parallel_reduce returns the first argument, the Kokkos::View<int> max_degree_view,\n\t// after adding all the node degrees in the adjacency matrix.\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t[&] (const int &i, int &local_max) {\n\t\t\tfor (int j=0; j<N; ++j) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\tlocal_max += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tmax_degree_view\n\t);\n\n\t// return the result. max_degree_view is a Kokkos::View<int> object.\n\t// Use Kokkos::deep_copy to copy the result from the device to the host.\n\tint max_degree;\n\tKokkos::deep_copy(max_degree, max_degree_view);\n\treturn max_degree;\n}",
            "int max_degree = 0;\n\n\t// TODO: Kokkos parallel for loop over the adjacency matrix\n\n\treturn max_degree;\n}",
            "int highest = 0;\n\n\t// Use the Kokkos parallel_reduce algorithm to compute the highest node degree.\n\t// The algorithm must be instantiated with a Kokkos::RangePolicy in order to use it.\n\n\treturn highest;\n}",
            "int *maxDegree = new int[1];\n\t*maxDegree = 0;\n\n\t// Kokkos::parallel_reduce is a Kokkos parallel loop that computes the reduction\n\t// over the domain and then reduces the results\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\t[&](const int i, int &local_max) {\n\t\t\t\tint degree = 0;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tdegree++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (degree > local_max) {\n\t\t\t\t\tlocal_max = degree;\n\t\t\t\t}\n\t\t\t},\n\t\t\t*maxDegree);\n\n\treturn *maxDegree;\n}",
            "// Create a Kokkos view for the answer.\n    Kokkos::View<int*, Kokkos::HostSpace> d_ans(\"max degree\");\n\n    // Get the device id and the range of nodes to work on.\n    // For simplicity, assume that we have only one device.\n    // Use 1 thread per node to compute the degree.\n    int deviceId = 0;\n    Kokkos::RangePolicy<Kokkos::RoundRobin<1>> policy(deviceId, 0, N);\n\n    // Create a lambda that computes the max degree for a given node.\n    auto maxDegreeFunctor = KOKKOS_LAMBDA(const int& i) {\n        int maxDegree = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j)!= 0) {\n                maxDegree++;\n            }\n        }\n        d_ans(i) = maxDegree;\n    };\n\n    // Run the lambda for each node.\n    Kokkos::parallel_for(policy, maxDegreeFunctor);\n\n    // Sync and return the answer.\n    int maxDegree = 0;\n    Kokkos::deep_copy(d_ans, maxDegree);\n    return maxDegree;\n}",
            "// Your code goes here!\n  int num_max = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),[&](int i,int& lmax){\n    int local_max=0;\n    for(int j=0;j<N;j++){\n      local_max += A(i,j);\n    }\n    lmax = local_max > lmax? local_max : lmax;\n  },Kokkos::Max<int>(num_max));\n\n  return num_max;\n}",
            "Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> degree(\"degrees\", N);\n\n\t// Fill in degrees using Kokkos\n\t// for(int i = 0; i < N; i++) {\n\t// \tint row_sum = 0;\n\t// \tfor(int j = 0; j < N; j++) {\n\t// \t\trow_sum += A(i, j);\n\t// \t}\n\t// \tdegrees(i) = row_sum;\n\t// }\n\n\tint max_degree = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tif(max_degree < degree(i))\n\t\t\tmax_degree = degree(i);\n\t}\n\n\t// Find max degree using Kokkos\n\t// for(int i = 0; i < N; i++) {\n\t// \tif(max_degree < degrees(i))\n\t// \t\tmax_degree = degrees(i);\n\t// }\n\n\treturn max_degree;\n}",
            "// TODO\n  // int max_degree = 0;\n\n  // for(int i=0; i<N; i++){\n  //   int cur_degree = 0;\n  //   for(int j=0; j<N; j++){\n  //     cur_degree += A(i, j);\n  //   }\n  //   if(cur_degree > max_degree){\n  //     max_degree = cur_degree;\n  //   }\n  // }\n\n  // return max_degree;\n\n  // Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int i, int & lmax) {\n  //   int cur_degree = 0;\n  //   for(int j=0; j<N; j++){\n  //     cur_degree += A(i, j);\n  //   }\n  //   if(cur_degree > lmax){\n  //     lmax = cur_degree;\n  //   }\n  // }, Kokkos::Max<int>(max_degree));\n\n  int max_degree = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA (const int i, int & lmax) {\n    int cur_degree = 0;\n    for(int j=0; j<N; j++){\n      cur_degree += A(i, j);\n    }\n    if(cur_degree > lmax){\n      lmax = cur_degree;\n    }\n  }, Kokkos::Max<int>(max_degree));\n  return max_degree;\n}",
            "int maxDegree = 0;\n\tKokkos::parallel_reduce(\"Max degree computation\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int& i, int& lmax) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tdegree += A(i, j);\n\t\t}\n\t\tlmax = max(degree, lmax);\n\t}, Kokkos::Max<int>(maxDegree));\n\n\tKokkos::fence();\n\treturn maxDegree;\n}",
            "Kokkos::View<int*> count(\"node degrees\", N);\n\tKokkos::parallel_for(\"count degrees\", N, KOKKOS_LAMBDA(const int i) {\n\t\tint c = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A(i, j)) {\n\t\t\t\tc++;\n\t\t\t}\n\t\t}\n\t\tcount(i) = c;\n\t});\n\tKokkos::fence();\n\tint maxDegree = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tif(count(i) > maxDegree) {\n\t\t\tmaxDegree = count(i);\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int* d_maxDegree;\n\n\tKokkos::View<int*> h_maxDegree(\"h_maxDegree\", 1);\n\tKokkos::deep_copy(h_maxDegree, 0);\n\n\tKokkos::parallel_for(\"maxDegree\", Kokkos::RangePolicy<>(0, N), [&](const int i) {\n\t\tint d = 0;\n\t\tfor(int j = 0; j < N; ++j)\n\t\t\td += A(i, j);\n\n\t\tif(d > h_maxDegree[0])\n\t\t\tKokkos::atomic_compare_exchange<int>(&h_maxDegree[0], d, h_maxDegree[0]);\n\t});\n\n\tKokkos::deep_copy(d_maxDegree, h_maxDegree);\n\n\treturn d_maxDegree[0];\n}",
            "int maxDegree = 0;\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t[&](const int i, int &maxDegree) {\n\t\t\tint deg = 0;\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0)\n\t\t\t\t\tdeg++;\n\t\t\t}\n\t\t\tif (deg > maxDegree)\n\t\t\t\tmaxDegree = deg;\n\t\t},\n\t\tmaxDegree);\n\treturn maxDegree;\n}",
            "// Kokkos Views to store the degrees of each vertex\n\tKokkos::View<int*> deg(\"degrees\", N);\n\t\n\t// Set up the kernel to run over all vertices in the graph\n\tKokkos::parallel_for(\n\t\t\"maxDegree\",\n\t\tN,\n\t\t[&](int i) {\n\t\t\t// Compute the degree of this vertex\n\t\t\tint degree = 0;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tdegree++;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Store the degree\n\t\t\tdeg[i] = degree;\n\t\t}\n\t);\n\t// Copy the view back to the host\n\tKokkos::View<int*> deg_h(\"degrees_h\", N);\n\tKokkos::deep_copy(deg_h, deg);\n\n\t// Determine the maximum degree\n\tint max_degree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (deg_h[i] > max_degree) {\n\t\t\tmax_degree = deg_h[i];\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(int i, int &value) {\n\t\tint degree = 0;\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tdegree += A(i, j);\n\t\t}\n\t\tvalue = Kokkos::max(value, degree);\n\t}, maxDegree);\n\n\treturn maxDegree;\n}",
            "// TODO\n\tKokkos::View<int*> degree_vector(\"Degree Vector\", N);\n\n\tKokkos::parallel_for(\"Max degree parallel\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tdegree_vector(i) = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tdegree_vector(i)++;\n\t\t\t}\n\t\t}\n\t});\n\n\tint maxDeg = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (degree_vector(i) > maxDeg) {\n\t\t\tmaxDeg = degree_vector(i);\n\t\t}\n\t}\n\n\treturn maxDeg;\n}",
            "Kokkos::View<int*> maxDegree(\"max degree\", 1);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t  int max = 0;\n\t  for (int j = 0; j < N; ++j) {\n\t\t  if (A(i, j)!= 0) {\n\t\t\t  ++max;\n\t\t  }\n\t  }\n\t  Kokkos::atomic_max(&maxDegree(0), max);\n  });\n  return maxDegree(0);\n}",
            "int *maxDegree_h = new int(0);\n\tKokkos::View<int*> maxDegree_d(\"Maximum degree\", 1);\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i, int& lmax) {\n\t\tint local_max = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tlocal_max += 1;\n\t\t\t}\n\t\t}\n\t\tif (local_max > lmax) {\n\t\t\tlmax = local_max;\n\t\t}\n\t}, Kokkos::Max<int>(maxDegree_d));\n\tKokkos::deep_copy(maxDegree_h, maxDegree_d);\n\tint maxDegree = *maxDegree_h;\n\tdelete maxDegree_h;\n\treturn maxDegree;\n}",
            "using mem_space = Kokkos::HostSpace;\n\tusing exec_space = Kokkos::DefaultExecutionSpace;\n\n\tint num_rows = N;\n\tint num_cols = N;\n\n\t// allocate storage on host memory\n\tKokkos::View<int*, mem_space> h_row_map(\"Row map\", num_rows + 1);\n\n\t// allocate storage on device memory\n\tKokkos::View<int*, exec_space> d_row_map(\"Row map\", num_rows + 1);\n\n\t// fill in row map with the number of nonzero elements\n\t// in each row\n\tKokkos::parallel_for(\n\t\t\"Fill in row map\",\n\t\tnum_rows,\n\t\tKOKKOS_LAMBDA(int i) {\n\t\t\tint count = 0;\n\t\t\tfor (int j = 0; j < num_cols; j++) {\n\t\t\t\tif (A(i, j)) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\th_row_map(i) = count;\n\t\t}\n\t);\n\n\t// copy the row map to the device\n\tKokkos::deep_copy(d_row_map, h_row_map);\n\n\t// find the max degree\n\tint max = Kokkos::parallel_reduce(\n\t\t\"Max degree\",\n\t\tnum_rows,\n\t\tKOKKOS_LAMBDA(int i, int init) {\n\t\t\tint tmp = d_row_map(i);\n\t\t\tif (init < tmp) {\n\t\t\t\treturn tmp;\n\t\t\t} else {\n\t\t\t\treturn init;\n\t\t\t}\n\t\t},\n\t\t0\n\t);\n\n\t// copy the max degree back to host memory\n\tKokkos::deep_copy(h_row_map, d_row_map);\n\n\treturn max;\n}",
            "const int MAX_VAL = std::numeric_limits<int>::max();\n  int maxDegree = 0;\n\n  // TODO\n\n  return maxDegree;\n}",
            "// Fill this in\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmaxDegree = max(degree, maxDegree);\n\t}\n\treturn maxDegree;\n}",
            "Kokkos::View<int[1]> maxDegree(\"maxDegree\", 1);\n  Kokkos::View<int*> degree(\"degree\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n\t\t       KOKKOS_LAMBDA (const int& i) {\n\t\t\t int d = 0;\n\t\t\t for (int j = 0; j < N; j++) {\n\t\t\t   if (A(i, j)!= 0) {\n\t\t\t     d++;\n\t\t\t   }\n\t\t\t }\n\t\t\t degree(i) = d;\n\t\t       });\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(0, N),\n\t\t\t  KOKKOS_LAMBDA (const int& i, int& lmax) {\n\t\t\t    int d = degree(i);\n\t\t\t    if (d > lmax) {\n\t\t\t      lmax = d;\n\t\t\t    }\n\t\t\t  },\n\t\t\t  maxDegree(0));\n  Kokkos::fence();\n  return maxDegree(0);\n}",
            "using namespace Kokkos;\n\n\tint nMaxDegree = 0;\n\tint nDegree = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tnDegree += A(i, j);\n\t\t}\n\t\tnMaxDegree = (nDegree > nMaxDegree)? nDegree : nMaxDegree;\n\t\tnDegree = 0;\n\t}\n\n\treturn nMaxDegree;\n}",
            "// Your code here\n}",
            "// TODO: Implement this function\n\n\treturn 0;\n}",
            "// TODO: your code goes here. \n\treturn 0;\n}",
            "// Create an array of size N to store node degrees\n  Kokkos::View<int*> deg(\"node_degrees\", N);\n\n  // Create a Kokkos parallel for loop to compute degrees\n  Kokkos::parallel_for(\n      \"compute_degrees\", N, KOKKOS_LAMBDA(const int i) {\n        // Iterate over the columns of A\n        int deg_i = 0;\n        for (int j = 0; j < N; j++) {\n          // Add 1 to the degree if there is a non-zero entry in the (i, j) position\n          if (A(i, j)) {\n            deg_i++;\n          }\n        }\n        deg(i) = deg_i;\n      });\n\n  // Find the maximum node degree\n  int max_degree = 0;\n  Kokkos::parallel_reduce(\n      \"find_max_degree\", N, KOKKOS_LAMBDA(const int i, int &max_degree) {\n        max_degree = (deg(i) > max_degree)? deg(i) : max_degree;\n      },\n      max_degree);\n  return max_degree;\n}",
            "int maxDegree = 0;\n\n  Kokkos::parallel_for(\"MaxDegree\", 1, KOKKOS_LAMBDA(const int &) {\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (A(i, j) == 1) {\n          maxDegree = std::max(maxDegree, (int) i);\n          maxDegree = std::max(maxDegree, (int) j);\n        }\n      }\n    }\n  });\n  Kokkos::fence();\n\n  return maxDegree;\n}",
            "// TODO\n\treturn 0;\n}",
            "// Create array to store degree of all nodes\n\tKokkos::View<int*> degrees(\"degrees\", N);\n\n\t// Initialize each degree to 0\n\tKokkos::parallel_for(\"InitDegrees\", N, KOKKOS_LAMBDA(int i) {\n\t\tdegrees(i) = 0;\n\t});\n\n\t// Increment the degree of each node for each edge in the adjacency matrix\n\tKokkos::parallel_for(\"IncrementDegrees\", N, KOKKOS_LAMBDA(int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tKokkos::atomic_increment(degrees(i));\n\t\t\t}\n\t\t}\n\t});\n\n\t// Create and initialize maximum degree variable\n\tint max_degree = 0;\n\n\t// Loop over nodes to find the maximum degree in the graph\n\tKokkos::parallel_reduce(\"FindMaxDegree\", N, KOKKOS_LAMBDA(int i, int& max) {\n\t\t// Use atomic operation to ensure that the maximum degree variable is not being accessed by multiple threads\n\t\tKokkos::atomic_max(max, degrees(i));\n\t}, max_degree);\n\n\t// Return the maximum degree\n\treturn max_degree;\n}",
            "int* max_degree = new int[1];\n\tKokkos::View<int*, Kokkos::HostSpace> h_max_degree(\"max_degree\", 1);\n\tKokkos::View<int*, Kokkos::DefaultHostExecutionSpace> d_max_degree(\"max_degree\", 1);\n\tKokkos::parallel_for(\"max_degree\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A(i, j) == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\th_max_degree(0) = Kokkos::atomic_max(&d_max_degree(0), degree);\n\t});\n\tKokkos::deep_copy(h_max_degree, d_max_degree);\n\treturn h_max_degree(0);\n}",
            "// TODO: Use Kokkos to compute the maximum degree.\n}",
            "//\n  // TODO: create a Kokkos::View to store the number of neighbors\n  //       for each node.\n  //\n\n  //\n  // TODO: create a Kokkos::parallel_for to compute the number of\n  //       neighbors for each node\n  //\n\n  //\n  // TODO: create a Kokkos::parallel_reduce to compute the highest\n  //       degree.\n  //\n\n  return 0;\n}",
            "int result = 0;\n  Kokkos::parallel_reduce(\n\t  Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N),\n\t  KOKKOS_LAMBDA(const int& i, int& l_result) {\n\t\t  int count = 0;\n\t\t  for (int j = 0; j < N; ++j) {\n\t\t\t  if (A(i, j) == 1) {\n\t\t\t\t  ++count;\n\t\t\t  }\n\t\t  }\n\t\t  if (count > l_result) {\n\t\t\t  l_result = count;\n\t\t  }\n\t  },\n\t  result);\n  return result;\n}",
            "using Atomics = Kokkos::Atomic<int>;\n  using View = Kokkos::View<int*>;\n  View degree(\"Degree\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& node) {\n    for (int neighbor = 0; neighbor < N; neighbor++) {\n      if (A(node, neighbor) == 1) {\n        Atomics::fetch_add(&degree(node), 1);\n      }\n    }\n  });\n  Kokkos::fence();\n\n  int maxDegree = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int& node, int& localMaxDegree) {\n    if (degree(node) > localMaxDegree) {\n      localMaxDegree = degree(node);\n    }\n  }, Kokkos::RangePolicy<Kokkos::ParallelReduceTag>(0, 1));\n  Kokkos::fence();\n\n  return maxDegree;\n}",
            "int *degrees = (int *)malloc(sizeof(int) * N);\n\n\tKokkos::View<int*, Kokkos::HostSpace> kokkos_degrees(\"degrees\", N);\n\n\t// TODO: Use Kokkos to compute the degrees of the nodes.\n\t//       Use the function Kokkos::parallel_for to do this in parallel.\n\t//       Set the maximum degree in degrees[0].\n\t//       The loop below computes the degrees.\n\t\n\tfor (int n = 0; n < N; ++n) {\n\t\tint degree = 0;\n\t\tfor (int m = 0; m < N; ++m) {\n\t\t\tif (A(n, m)) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tdegrees[n] = degree;\n\t}\n\n\t// TODO: Copy the result to kokkos_degrees.\n\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (maxDegree < degrees[i]) {\n\t\t\tmaxDegree = degrees[i];\n\t\t}\n\t}\n\n\t// TODO: Use Kokkos to find the max degree in kokkos_degrees.\n\n\treturn maxDegree;\n}",
            "using atomic_type = Kokkos::atomic_t<int>;\n\n\tKokkos::View<int*, Kokkos::HostSpace> degree(\"host_view\");\n\tKokkos::parallel_for(\"MaxDegree\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tint local_max = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tlocal_max++;\n\t\t\t}\n\t\t}\n\t\tKokkos::atomic_max(&degree[i], local_max);\n\t});\n\tKokkos::fence();\n\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (degree[i] > max) {\n\t\t\tmax = degree[i];\n\t\t}\n\t}\n\n\treturn max;\n}",
            "// TODO: Your code here\n  int max_degree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A(i, j);\n    }\n    max_degree = degree > max_degree? degree : max_degree;\n  }\n  return max_degree;\n\n}",
            "auto max_degree_fun = KOKKOS_LAMBDA(const int i) {\n\t\tconst int *row = A(i, Kokkos::ALL());\n\t\tint num_neighbors = 0;\n\t\tfor (int j=0; j<N; ++j) {\n\t\t\tnum_neighbors += row[j];\n\t\t}\n\t\treturn num_neighbors;\n\t};\n\tint max_degree = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N), max_degree_fun, Kokkos::Max<int>(max_degree));\n\treturn max_degree;\n}",
            "/*\n\t* Create and initialize a Kokkos View of integers.\n\t* We want this array to be N x 1.\n\t*/\n\tKokkos::View<int*> degree(\"degree\", N);\n\tKokkos::deep_copy(degree, 0);\n\n\t/*\n\t* Create a Kokkos parallel_for loop.\n\t* Note that we use \"N\" here to create a loop from 0 to N-1.\n\t* Inside the loop, we increment the degree of each node\n\t* by using the Kokkos atomic_fetch_add function.\n\t* This is equivalent to the C++11 atomic_fetch_add function.\n\t* Note that we pass in a reference to the degree array.\n\t* This is a required Kokkos feature.\n\t*/\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tKokkos::atomic_fetch_add(&degree[i], 1);\n\t\t\t}\n\t\t}\n\t});\n\n\t/*\n\t* Create a Kokkos parallel_reduce loop.\n\t* Here, we return the highest degree of all nodes.\n\t* We use Kokkos's \"reduce\" function.\n\t* Note that the Kokkos lambda function takes in two integer arguments:\n\t* the \"value\" (the initial value, 0) and the \"sum\" (the running total).\n\t* The \"value\" is the degree of a node.\n\t* The \"sum\" is the current running total of degrees.\n\t* Here, we want to return the highest degree.\n\t* So, if the degree is greater than the current running total,\n\t* we return the degree.\n\t* Otherwise, we return the running total.\n\t*/\n\tint maxDegree = Kokkos::reduce(degree, 0, KOKKOS_LAMBDA(const int value, const int sum) {\n\t\treturn value > sum? value : sum;\n\t});\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::ReduceIdentity<int>>(0, N), KOKKOS_LAMBDA (const int i, int& lmax) {\n      int deg = 0;\n      for (size_t j = 0; j < N; j++) {\n        deg += A(i,j);\n      }\n      lmax = Kokkos::max(lmax, deg);\n    },\n    Kokkos::Max<int>(maxDegree));\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\tusing execution_space = Kokkos::DefaultExecutionSpace;\n\tusing mem_space = Kokkos::HostSpace;\n\tusing device_type = typename execution_space::device_type;\n\n\tauto h_A = Kokkos::create_mirror_view(A);\n\tKokkos::deep_copy(h_A, A);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (h_A(i, j) == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n  // For each node in the graph...\n  for (size_t i = 0; i < N; i++) {\n    // Count the number of neighbors\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A(i, j);\n    }\n\n    // Keep track of the highest degree\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n\n  return maxDegree;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n  Kokkos::View<int*, execution_space> degree(\"Degree\", N);\n  Kokkos::parallel_for(\"Degree Parallel For\", N, KOKKOS_LAMBDA(const int i) {\n    int degree_sum = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j)!= 0) {\n        ++degree_sum;\n      }\n    }\n    degree(i) = degree_sum;\n  });\n  // Wait for the kernel to finish\n  Kokkos::fence();\n\n  // Get the max degree value. Use the device to get the max.\n  int *max = Kokkos::Max<int*>(&degree(0), N);\n  int max_degree = *max;\n\n  return max_degree;\n}",
            "int max_degree = 0;\n\n    using MD_Policy = Kokkos::RangePolicy<Kokkos::Rank<1>>;\n    using MD_Reduce = Kokkos::Max<int>;\n    using MD_Functor = Kokkos::Functional::MDMaxDegree<int>;\n    Kokkos::parallel_reduce(MD_Policy(0, N), MD_Functor(A, N), MD_Reduce(max_degree));\n\n    return max_degree;\n}",
            "int max_degree = 0;\n\tKokkos::View<int*, Kokkos::HostSpace> host_view(\"host_view\", N);\n\tKokkos::parallel_for(\"max_degree\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tdegree += A(i, j);\n\t\thost_view(i) = degree;\n\t});\n\tKokkos::fence();\n\tfor (int i = 0; i < N; i++) {\n\t\tif (host_view(i) > max_degree)\n\t\t\tmax_degree = host_view(i);\n\t}\n\treturn max_degree;\n}",
            "Kokkos::View<int*> degrees(\"degrees\", N);\n\tKokkos::parallel_for(\"get degrees\", N, KOKKOS_LAMBDA (const int i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\t\tdegrees(i) = degree;\n\t});\n\tKokkos::fence();\n\tint maxDegree = degrees(0);\n\tfor (int i = 1; i < N; i++) {\n\t\tif (degrees(i) > maxDegree) {\n\t\t\tmaxDegree = degrees(i);\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// TODO\n  // Set up the variables to use in the parallel_for loop\n  // Use the maximum function to find the maximum degree\n  // Return the maximum degree\n\n  const int maxN = 1000;\n  int maximum[maxN];\n  int degree[maxN];\n  int max = 0;\n\n  for (int i = 0; i < maxN; i++) {\n    maximum[i] = 0;\n    degree[i] = 0;\n  }\n\n  Kokkos::parallel_for(\"Maximum Degree\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&](int k) {\n    for (int i = 0; i < N; i++) {\n      degree[i] = A(i, k);\n    }\n\n    for (int i = 0; i < N; i++) {\n      if (maximum[i] < degree[i]) {\n        maximum[i] = degree[i];\n      }\n    }\n\n  });\n\n  Kokkos::parallel_for(\"Maximum Degree 2\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&](int k) {\n    for (int i = 0; i < N; i++) {\n      if (max < maximum[i]) {\n        max = maximum[i];\n      }\n    }\n  });\n\n  return max;\n}",
            "Kokkos::View<int*> deg(\"max degree\", N);\n\t// TODO: use Kokkos to fill the degree view\n\n\t// Find the maximum degree\n\treturn Kokkos::parallel_reduce(\"max degree\", Kokkos::RangePolicy<Kokkos::Reduce>(0, N),\n\t                               KOKKOS_LAMBDA (const int& i, int& val) {\n\t                                   // TODO: fill the reduce function\n\t                               }, 0);\n}",
            "Kokkos::View<int*> degree(\"Degree\", N);\n\n  Kokkos::parallel_for(\n    \"Compute_Degree\",\n    Kokkos::RangePolicy<Kokkos::Rank<Kokkos::DefaultExecutionSpace>>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j) == 1) {\n          // Atomically add to the degree\n          // Note that atomicAdd(a, b) does a += b\n          // We need to do a++ for atomicity\n          Kokkos::atomic_add(&degree(i), 1);\n          Kokkos::atomic_add(&degree(j), 1);\n        }\n      }\n    }\n  );\n  Kokkos::fence();\n\n  Kokkos::View<int*>::HostMirror h_degree = Kokkos::create_mirror_view(degree);\n  Kokkos::deep_copy(h_degree, degree);\n\n  int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    if (h_degree(i) > maxDegree) {\n      maxDegree = h_degree(i);\n    }\n  }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n    Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n        KOKKOS_LAMBDA(const int i, int &lmaxDegree) {\n            int degree = 0;\n            for (int j = 0; j < N; ++j) {\n                if (A(i, j)) ++degree;\n            }\n            lmaxDegree = std::max(lmaxDegree, degree);\n        },\n        Kokkos::Max<int>(maxDegree));\n    return maxDegree;\n}",
            "Kokkos::View<int*> maxDegreePerNode(\"Maximum degree per node\", N);\n    // TODO: Implement maxDegree\n\n    // Note: You may need to use Kokkos::fence() to make sure\n    // your kernel updates the maxDegreePerNode array\n    // on the host.\n\n    // Check if all the elements of maxDegreePerNode are zero. If so, the input graph is empty.\n    // The maximum degree of an empty graph is 0.\n    if (std::all_of(maxDegreePerNode.data(), maxDegreePerNode.data() + N, [](int val) { return val == 0; })) {\n        return 0;\n    }\n\n    return *std::max_element(maxDegreePerNode.data(), maxDegreePerNode.data() + N);\n}",
            "Kokkos::View<int*> node_degrees(\"node_degrees\", N);\n\n    // TODO: initialize node_degrees\n\n    Kokkos::parallel_for(\"compute_degrees\", N, KOKKOS_LAMBDA(int i) {\n        int sum = 0;\n\n        // TODO: compute the sum of node degrees\n\n        node_degrees(i) = sum;\n    });\n    Kokkos::fence();\n\n    int max = 0;\n    for (int i = 0; i < N; i++) {\n        max = std::max(node_degrees(i), max);\n    }\n\n    return max;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> deg(\"Degree\");\n\tdeg = -1;\n\tKokkos::parallel_for(\"parallel_for\", N, KOKKOS_LAMBDA(const int& i){\n\t\tfor(int j = 0; j < N; ++j){\n\t\t\tif(A(i, j) == 1) ++deg(i);\n\t\t}\n\t});\n\n\tint maxDeg = -1;\n\tfor(int i = 0; i < N; ++i) maxDeg = Kokkos::max(maxDeg, deg(i));\n\treturn maxDeg;\n}",
            "// Use a parallel reduction to find the max degree\n\tint maxDegree = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA (const int i, int& lmax) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tlmax = std::max(lmax, degree);\n\t}, Kokkos::Max<int>(maxDegree));\n\t// Copy back to host memory\n\tKokkos::deep_copy(maxDegree, maxDegree);\n\treturn maxDegree;\n}",
            "// Fill this in\n\treturn 0;\n}",
            "// Compute number of edges for each node.\n  Kokkos::View<int*, Kokkos::HostSpace> nEdges(\"nEdges\", N);\n  Kokkos::parallel_for(\"Degree\", N, KOKKOS_LAMBDA(int i) {\n    nEdges(i) = 0;\n  });\n\n  Kokkos::parallel_for(\"Degree\", N, KOKKOS_LAMBDA(int i) {\n    for(int j = 0; j < N; j++) {\n      if (A(i,j)!= 0) {\n        nEdges(i) += 1;\n      }\n    }\n  });\n\n  // Find the max degree.\n  int maxDeg = 0;\n  Kokkos::parallel_reduce(\"Degree\", N, KOKKOS_LAMBDA(int i, int& sum) {\n    if (nEdges(i) > sum) {\n      sum = nEdges(i);\n    }\n  }, Kokkos::RangePolicy<Kokkos::ReducePolicy<Kokkos::ReduceSum<int> >, Kokkos::Schedule<Kokkos::ScheduleType::Dynamic> >(0, N));\n\n  return maxDeg;\n}",
            "using ViewType = Kokkos::View<const int**>;\n  using int_scalar_type = Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace>;\n  using int_array_type = Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace>;\n  using int_array_type_2d = Kokkos::View<int**, Kokkos::LayoutLeft, Kokkos::HostSpace>;\n  using int_array_type_3d = Kokkos::View<int***, Kokkos::LayoutLeft, Kokkos::HostSpace>;\n\n  int_scalar_type degrees(\"degrees\", N);\n  int_array_type_2d degreesPerNode(\"degreesPerNode\", N, 1);\n  int_array_type_3d dpnp(\"dpnp\", 3, N, 1);\n  int_array_type maxDegree(\"maxDegree\", 1);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        degree++;\n      }\n    }\n    degrees(i) = degree;\n    degreesPerNode(i, 0) = degree;\n  });\n\n  Kokkos::parallel_for(3, KOKKOS_LAMBDA(const int j) {\n    int maxDegreeIndex = 0;\n    int maxDegreeValue = degreesPerNode(0, 0);\n    for (int i = 0; i < N; ++i) {\n      if (degreesPerNode(i, 0) > maxDegreeValue) {\n        maxDegreeIndex = i;\n        maxDegreeValue = degreesPerNode(i, 0);\n      }\n    }\n    dpnp(j, maxDegreeIndex, 0) = 1;\n  });\n\n  int maxDegreeValue = 0;\n  for (int i = 0; i < 3; ++i) {\n    if (dpnp(i, 0, 0) == 1) {\n      maxDegreeValue = i;\n    }\n  }\n  maxDegree(0) = maxDegreeValue;\n  return maxDegree(0);\n}",
            "using namespace Kokkos;\n\n\ttypedef View<int*, Space::Host> host_view_t;\n\n\t// Create a temporary array to store the degree of each node\n\thost_view_t h_degrees(\"h_degrees\", N);\n\t// Set the degrees to zero\n\tKokkos::deep_copy(h_degrees, 0);\n\n\t// Loop through the matrix and increment the degree of each node\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\t++h_degrees(i);\n\t\t\t}\n\t\t}\n\t}\n\n\t// Create a temporary array on the device to store the degree of each node\n\thost_view_t d_degrees(\"d_degrees\", N);\n\n\t// Copy the host view into the device view\n\tdeep_copy(d_degrees, h_degrees);\n\n\t// Find the maximum value in the degrees array\n\tauto max = Kokkos::Max<int>(d_degrees);\n\n\t// Copy the maximum value back to the host\n\thost_view_t h_max(\"h_max\", 1);\n\tdeep_copy(h_max, max.value_ptr);\n\n\t// Return the highest degree\n\treturn h_max(0);\n}",
            "// Declare the node degrees.\n  Kokkos::View<int*> nodeDegrees(\"nodeDegrees\", N);\n\n  // Set the node degrees to zero.\n  Kokkos::deep_copy(nodeDegrees, 0);\n\n  // Compute the node degrees in parallel.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        // For each node i, add 1 to the node degree of each neighbor j.\n        Kokkos::atomic_add(&nodeDegrees(j), 1);\n      }\n    }\n  });\n\n  // Find the maximum node degree.\n  int maxDegree = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(size_t i, int &max) {\n    if (nodeDegrees(i) > max) {\n      max = nodeDegrees(i);\n    }\n  }, Kokkos::Max<int>(maxDegree));\n\n  return maxDegree;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> degrees(\"degrees\", N);\n\n    auto maxDegreeFunctor = KOKKOS_LAMBDA(const int i) {\n        int deg = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) > 0) {\n                deg++;\n            }\n        }\n        degrees(i) = deg;\n    };\n    Kokkos::parallel_for(N, maxDegreeFunctor);\n\n    int maxDegree = 0;\n    Kokkos::parallel_reduce(N, [&](const int i, int &value) {\n        if (degrees(i) > value) {\n            value = degrees(i);\n        }\n    }, maxDegree);\n\n    Kokkos::fence();\n    return maxDegree;\n}",
            "int* a = new int[N];\n  Kokkos::parallel_for(\"maxDegree\", N, KOKKOS_LAMBDA(const int i) {\n    int count = 0;\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)) count++;\n    }\n    a[i] = count;\n  });\n  int max_a = 0;\n  for (int i = 0; i < N; i++) {\n    max_a = max(a[i], max_a);\n  }\n  delete[] a;\n  return max_a;\n}",
            "// Kokkos::View<int**> deg (N);\n\tKokkos::View<int*> deg (\"degrees\", N);\n\tKokkos::parallel_for (\"Compute degrees\", N, KOKKOS_LAMBDA (const int i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j)!= 0) {\n\t\t\t\tsum += A(i,j);\n\t\t\t}\n\t\t}\n\t\tdeg(i) = sum;\n\t});\n\tKokkos::fence();\n\n\tint* host_degrees = (int*) malloc(N*sizeof(int));\n\tKokkos::deep_copy (host_degrees, deg);\n\n\tint max = host_degrees[0];\n\tfor (int i = 1; i < N; i++) {\n\t\tif (host_degrees[i] > max) {\n\t\t\tmax = host_degrees[i];\n\t\t}\n\t}\n\n\tfree(host_degrees);\n\treturn max;\n}",
            "int maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tdegree += A(i, j);\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "// TODO: insert code here\n\tint maxDegree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A(i,j);\n\t\t}\n\t\tmaxDegree = maxDegree < sum? sum : maxDegree;\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n\t// your code goes here\n\n\treturn maxDegree;\n}",
            "// Create a parallel_reduce to compute the maximum\n\tKokkos::View<int*> maxDegree(\"maxDegree\", 1);\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n\t\t\t\t\t\t\tKOKKOS_LAMBDA(const int i, int& lMax) {\n\t\t\t\t\t\t\t\tint thisNodeDegree = 0;\n\t\t\t\t\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\t\t\t\t\tthisNodeDegree += A(i, j);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif (thisNodeDegree > lMax) {\n\t\t\t\t\t\t\t\t\tlMax = thisNodeDegree;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\tmaxDegree);\n\n\t// Return the maximum node degree\n\tint max = Kokkos::create_mirror_view(maxDegree);\n\tKokkos::deep_copy(max, maxDegree);\n\treturn max(0);\n}",
            "using Kokkos::ALL;\n  using Kokkos::AUTO;\n\n  using CountType = int;\n  using PolicyType = Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace, AUTO>;\n  using CountsType = Kokkos::View<CountType*>;\n  using RowType = typename PolicyType::member_type;\n\n  // The number of nodes\n  int nNodes = N;\n\n  // Initialize counts array\n  CountsType counts(\"counts\", nNodes);\n  Kokkos::deep_copy(counts, 0);\n\n  // Parallel loop: increment count for each neighbor of each node\n  Kokkos::parallel_for(\"Count neighboring nodes\", PolicyType(0, nNodes), [=] (RowType i) {\n\n    int count = 0;\n    for (int j = 0; j < nNodes; j++) {\n      if (A(i, j)!= 0) {\n        count++;\n      }\n    }\n\n    counts(i) = count;\n  });\n\n  // Get the maximum degree in the graph\n  CountType maxDegree = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace, AUTO>(0, nNodes),\n    [=] (int i, CountType& lmax) {\n      lmax = Kokkos::max(lmax, counts(i));\n    },\n    Kokkos::Max<CountType>(maxDegree)\n  );\n\n  Kokkos::fence();\n\n  return maxDegree;\n}",
            "Kokkos::View<int*> deg(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"deg\"), N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Reduce>(0,N), [&] (int i) {\n\t\tint sum = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tsum += A(i,j);\n\t\t}\n\t\tdeg[i] = sum;\n\t});\n\n\tauto maxDeg = Kokkos::Max<int>(deg);\n\tKokkos::fence();\n\tint max = 0;\n\tKokkos::deep_copy(max, maxDeg);\n\n\treturn max;\n}",
            "Kokkos::View<int*> deg(\"Degree\", N);\n\n  // TODO: Fill in the Kokkos code here\n  // You may need more than one parallel_for\n\n  // return the result\n  int max_deg = 0;\n  for (int i = 0; i < N; ++i) {\n    if (deg(i) > max_deg) {\n      max_deg = deg(i);\n    }\n  }\n  return max_deg;\n}",
            "// Your code here.\n\n\treturn -1;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> sumA(\"sumA\", N);\n    auto sumA_h = Kokkos::create_mirror_view(sumA);\n\n    Kokkos::parallel_for(N, [=](size_t i) {\n        int sum = 0;\n        for (int j = 0; j < N; ++j) {\n            sum += A(i, j);\n        }\n        sumA_h(i) = sum;\n    });\n\n    Kokkos::deep_copy(sumA, sumA_h);\n\n    int maxSum = 0;\n    for (int i = 0; i < N; ++i) {\n        if (sumA(i) > maxSum) {\n            maxSum = sumA(i);\n        }\n    }\n\n    return maxSum;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "omp",
        "prompt": "#include <omp.h>\n\n/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < N; j++)\n      if (A[i*N + j] == 1)\n        maxDegree = std::max(maxDegree, int(A[i*N + j]));\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n#pragma omp parallel for reduction(max: maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tmaxDegree = std::max(maxDegree, i);\n\t\t\t\tmaxDegree = std::max(maxDegree, j);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int max = 0;\n#pragma omp parallel for\n\tfor (int i=0; i<N; i++) {\n\t\tint sum = 0;\n\t\tfor (int j=0; j<N; j++) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]!= 0) {\n                ++degree;\n            }\n        }\n        #pragma omp critical\n        if (degree > max_degree) {\n            max_degree = degree;\n        }\n    }\n    return max_degree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for\n\tfor (size_t i=0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j=0; j < N; j++) {\n\t\t\tif (A[i*N+j])\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (max_degree < degree)\n\t\t\tmax_degree = degree;\n\t}\n\treturn max_degree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for reduction(max:max_degree)\n\tfor(int i = 0; i < N; ++i){\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; ++j){\n\t\t\tif(A[i * N + j]!= 0){\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (size_t i = 0; i < N; ++i) {\n    // iterate over all elements in the adjacency matrix of the ith node\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N+j]!= 0) {\n        // count the number of neighbors in the ith node\n        // if there are neighbors, increment maxDegree\n        ++maxDegree;\n      }\n    }\n  }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n#pragma omp parallel for reduction(max: maxDegree)\n\tfor (int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] > 0) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n    std::vector<int> degree(N, 0);\n\n#pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                degree[i]++;\n                degree[j]++;\n            }\n        }\n    }\n\n    for (int k = 0; k < N; ++k) {\n        if (degree[k] > max_degree) {\n            max_degree = degree[k];\n        }\n    }\n\n    return max_degree;\n}",
            "int max_degree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint cur_degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] > 0) {\n\t\t\t\tcur_degree++;\n\t\t\t}\n\t\t}\n\t\tif (cur_degree > max_degree) {\n\t\t\tmax_degree = cur_degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int maxDeg = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j)\n      sum += A[i*N + j];\n    #pragma omp critical\n    {\n      if (sum > maxDeg) maxDeg = sum;\n    }\n  }\n  return maxDeg;\n}",
            "int max_degree = 0;\n    int degree;\n\n    // Insert your code here\n\n    return max_degree;\n}",
            "int max = 0;\n    #pragma omp parallel for schedule(dynamic) reduction(max:max)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i == j) continue;\n            if (A[i * N + j] > 0) {\n                max = std::max(max, A[i * N + j] + 1);\n            }\n        }\n    }\n\n    return max;\n}",
            "int max_degree = 0;\n\n\t//#pragma omp parallel for reduction(max:max_degree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N*i + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for schedule(static)\n    for(size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for(size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                ++degree;\n            }\n        }\n        #pragma omp critical\n        {\n            if (degree > maxDegree) {\n                maxDegree = degree;\n            }\n        }\n    }\n    return maxDegree;\n}",
            "int max = 0;\n\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > max) {\n\t\t\tmax = degree;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\n\t#pragma omp parallel for shared(A) reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for reduction(max : max_degree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\treturn max_degree;\n}",
            "int degree = 0;\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        int count = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] > 0) {\n                count++;\n            }\n        }\n        if (count > degree) {\n            degree = count;\n        }\n    }\n    return degree;\n}",
            "// TODO\n}",
            "// TODO: your code here\n\tint maxDegree = 0;\n\t#pragma omp parallel for reduction(max: maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (maxDegree < degree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++)\n  {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++)\n      if (A[i * N + j] == 1)\n        sum++;\n    if (maxDegree < sum)\n      maxDegree = sum;\n  }\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel\n    {\n        #pragma omp for reduction(max:max_degree)\n        for (size_t i=0; i < N; i++){\n            int degree = 0;\n            for (size_t j=0; j < N; j++){\n                degree += A[i*N+j];\n            }\n            max_degree = std::max(degree, max_degree);\n        }\n    }\n    return max_degree;\n}",
            "int maxDegree{0};\n#pragma omp parallel for schedule(static) reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree{0};\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "auto maxDegree = 0;\n  #pragma omp parallel for reduction(max: maxDegree)\n  for (auto i = 0u; i < N; ++i) {\n    auto sum = 0;\n    for (auto j = 0u; j < N; ++j) {\n      sum += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, sum);\n  }\n  return maxDegree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A[i*N + j];\n\t\t}\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for reduction(max:max_degree)\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n\n    return max_degree;\n}",
            "int maxDegree{0};\n\tint degree{0};\n\n\t#pragma omp parallel for num_threads(2) private(degree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\n\t\tdegree = 0;\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n\t#pragma omp parallel for reduction(max:maxDegree)\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\n\treturn maxDegree;\n}",
            "int mx = 0;\n\n\tomp_lock_t lock;\n\tomp_init_lock(&lock);\n\t\n\t//#pragma omp parallel\n\t//{\n\t\t//#pragma omp single\n\t\t//{\n\t\t\t//#pragma omp taskloop\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tint cnt = 0;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tcnt += A[i*N + j];\n\t\t\t\t}\n\t\t\t\tif (cnt > mx)\n\t\t\t\t\tmx = cnt;\n\t\t\t\t//#pragma omp task shared(mx)\n\t\t\t\t//{\n\t\t\t\t//\tomp_set_lock(&lock);\n\t\t\t\t//\tif (cnt > mx)\n\t\t\t\t//\t\tmx = cnt;\n\t\t\t\t//\tomp_unset_lock(&lock);\n\t\t\t\t//}\n\t\t\t}\n\t\t//}\n\t//}\n\t\n\tomp_destroy_lock(&lock);\n\treturn mx;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for reduction(max: maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (maxDegree < degree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "#pragma omp parallel for reduction(max: maxDegree)\n\tfor (int i = 0; i < N; i++) {\n\t\tint max = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t\tif (max > maxDegree) {\n\t\t\tmaxDegree = max;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n    for (int i = 0; i < N; i++) {\n        int local_max = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                local_max += 1;\n            }\n        }\n        max_degree = max_degree > local_max? max_degree : local_max;\n    }\n    return max_degree;\n}",
            "int max = -1;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > max) {\n\t\t\tmax = degree;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n\n        for (size_t j = 0; j < N; j++) {\n            if (A[j + i*N] == 1) {\n                degree++;\n            }\n        }\n\n        #pragma omp critical\n        if (degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for reduction(max:maxDegree)\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "std::vector<int> degree(N, 0);\n  size_t i, j;\n  #pragma omp parallel for private(i, j)\n  for (i = 0; i < N; ++i) {\n    for (j = 0; j < N; ++j) {\n      if (A[i*N+j] == 1) {\n        degree[i]++;\n      }\n    }\n  }\n  return *std::max_element(degree.begin(), degree.end());\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for reduction(max: max_degree)\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n\n    return max_degree;\n}",
            "int maxDegree = 0;\n\tint degree;\n\t#pragma omp parallel for reduction(max: maxDegree)\n\tfor (size_t i=0; i<N; ++i) {\n\t\tdegree = 0;\n\t\tfor (size_t j=0; j<N; ++j) {\n\t\t\tif (A[i*N+j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "#pragma omp parallel for reduction(max: maxDegree)\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                ++degree;\n            }\n        }\n        if (maxDegree < degree) {\n            maxDegree = degree;\n        }\n    }\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for schedule(static)\n\tfor (size_t i=0; i < N; i++) {\n\t\tint currentDegree = 0;\n\t\tfor (size_t j=0; j < N; j++) {\n\t\t\tcurrentDegree += A[i*N + j];\n\t\t}\n\t\tif (currentDegree > maxDegree)\n\t\t\tmaxDegree = currentDegree;\n\t}\n\n\treturn maxDegree;\n}",
            "int max = 0;\n\t#pragma omp parallel for reduction(max:max)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint cnt = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++cnt;\n\t\t\t}\n\t\t}\n\t\tif (cnt > max) {\n\t\t\tmax = cnt;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max_degree = 0;\n\tint thread_max_degree = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tthread_max_degree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t#pragma omp atomic\n\t\t\t\t\tthread_max_degree++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (thread_max_degree > max_degree) {\n\t\t\t\tmax_degree = thread_max_degree;\n\t\t\t}\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "return 0;\n}",
            "int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (int i = 0; i < N; ++i) {\n    int sum = 0;\n    for (int j = 0; j < N; ++j) {\n      sum += A[i*N + j];\n    }\n    if (sum > maxDegree) {\n      maxDegree = sum;\n    }\n  }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel\n  {\n    int threadMaxDegree = 0;\n    #pragma omp for\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i*N + j] == 1) {\n          threadMaxDegree += 1;\n        }\n      }\n    }\n    #pragma omp critical\n    {\n      if (threadMaxDegree > maxDegree) {\n        maxDegree = threadMaxDegree;\n      }\n    }\n  }\n  return maxDegree;\n}",
            "int* sum_A = (int*)calloc(N,sizeof(int));\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            sum_A[i] += A[i*N + j];\n        }\n    }\n    int max_degree = sum_A[0];\n    #pragma omp parallel for\n    for (int i = 1; i < N; i++) {\n        if (sum_A[i] > max_degree)\n            max_degree = sum_A[i];\n    }\n    free(sum_A);\n    return max_degree;\n}",
            "int maxDegree = 0;\n    #pragma omp parallel for reduction(max:maxDegree)\n    for (int i = 0; i < N; i++) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            degree += A[i*N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int maxDegree = 0;\n  std::vector<int> maxDegreeThread(omp_get_max_threads(), 0);\n#pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    int degree = 0;\n    for(int j = 0; j < N; j++) {\n      degree += A[N*i+j];\n    }\n    int thread_num = omp_get_thread_num();\n    if (thread_num == 0) {\n      maxDegreeThread[0] = degree;\n    }\n    else {\n      if (degree > maxDegreeThread[thread_num]) {\n        maxDegreeThread[thread_num] = degree;\n      }\n    }\n  }\n  for(int i = 0; i < omp_get_max_threads(); i++) {\n    if (maxDegreeThread[i] > maxDegree) {\n      maxDegree = maxDegreeThread[i];\n    }\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\t#pragma omp parallel for reduction(max:maxDegree)\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tmaxDegree = std::max(maxDegree, (int) (std::count(A.begin(), A.end(), 1) - 1));\n\n\treturn maxDegree;\n}",
            "int max = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint sum;\n\n\t\t#pragma omp for schedule(static) reduction(max:max)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tsum = 0;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tsum += A[i * N + j];\n\t\t\t}\n\t\t\tif (sum > max) {\n\t\t\t\tmax = sum;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int maxDeg = 0;\n\n  // your code here\n\n  // use OpenMP to parallelize this loop\n  // hint: use reduction\n#pragma omp parallel for reduction(max:maxDeg)\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0)\n        degree++;\n    }\n    maxDeg = std::max(maxDeg, degree);\n  }\n\n  return maxDeg;\n}",
            "int max = 0;\n#pragma omp parallel\n  {\n    int local_max = 0;\n#pragma omp for\n    for (size_t i = 0; i < N; ++i) {\n      int degree = 0;\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i*N + j]) {\n          degree++;\n        }\n      }\n      if (degree > local_max) {\n        local_max = degree;\n      }\n    }\n\n#pragma omp critical\n    if (local_max > max) {\n      max = local_max;\n    }\n  }\n  return max;\n}",
            "// YOUR CODE HERE\n}",
            "int max = 0;\n\tint sum = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tsum++;\n\t\t\t}\n\n\tmax = sum;\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N * i + j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(degree, maxDegree);\n\t}\n\treturn maxDegree;\n}",
            "int m = 0;\n#pragma omp parallel for reduction(max:m)\n    for (int i = 0; i < N; i++) {\n        int current = 0;\n        for (int j = 0; j < N; j++) {\n            current += A[i * N + j];\n        }\n        m = std::max(m, current);\n    }\n    return m;\n}",
            "int maxDegree = 0;\n  std::vector<int> maxDegreeThread;\n  int localMaxDegree = 0;\n  maxDegreeThread.resize(omp_get_num_threads(), 0);\n  #pragma omp parallel\n  {\n    #pragma omp for schedule(dynamic)\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (A[i * N + j]!= 0) {\n          localMaxDegree++;\n        }\n      }\n      maxDegreeThread[omp_get_thread_num()] = std::max(localMaxDegree, maxDegreeThread[omp_get_thread_num()]);\n      localMaxDegree = 0;\n    }\n  }\n  for (int i = 0; i < maxDegreeThread.size(); ++i) {\n    maxDegree = std::max(maxDegree, maxDegreeThread[i]);\n  }\n  return maxDegree;\n}",
            "int max = 0;\n    std::vector<int> count(N, 0);\n#pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                count[i]++;\n            }\n        }\n    }\n    for (size_t i = 0; i < N; i++) {\n        if (count[i] > max) {\n            max = count[i];\n        }\n    }\n    return max;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max : maxDegree)\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i*N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "// Your code goes here!\n\tint max = 0;\n\t#pragma omp parallel for shared(A) private(max) \n\tfor (int i = 0; i < N; i++) {\n\t\tint temp = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]!= 0)\n\t\t\t\ttemp++;\n\t\t}\n\t\tif (temp > max)\n\t\t\tmax = temp;\n\t}\n\n    return max;\n}",
            "std::vector<int> degrees(N);\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        degrees[i] = 0;\n        for (int j = 0; j < N; ++j) {\n            degrees[i] += A[i * N + j];\n        }\n    }\n\n    int maxDegree = *std::max_element(degrees.begin(), degrees.end());\n\n    return maxDegree;\n}",
            "int max_degree = 0;\n#pragma omp parallel for reduction(max : max_degree)\n    for (int i = 0; i < N; i++) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                degree += 1;\n            }\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "// Implement this method\n\n\tint maxDegree = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tint currentDegree = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif (A[j*N + i] == 1) {\n\t\t\t\tcurrentDegree++;\n\t\t\t}\n\t\t}\n\t\tif (maxDegree < currentDegree) {\n\t\t\tmaxDegree = currentDegree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n  // #pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    int degree = 0;\n    for(int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        degree += 1;\n      }\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int res = 0;\n\t// your code\n\n\treturn res;\n}",
            "int max_degree = 0;\n\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n#pragma omp critical\n\t\t\t\tif (max_degree < i + j + 1) {\n\t\t\t\t\tmax_degree = i + j + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "std::vector<int> degrees(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++degrees[i];\n\t\t\t}\n\t\t}\n\t}\n\tint maxDegree = 0;\n\tfor (int degree : degrees) {\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\n\treturn max_degree;\n}",
            "int maxDeg = 0;\n    std::vector<int> degrees(N);\n\n    //#pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n\n        degrees[i] = 0;\n\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                degrees[i]++;\n            }\n        }\n    }\n\n    //#pragma omp parallel for reduction(max : maxDeg)\n    for (size_t i = 0; i < N; i++) {\n        maxDeg = std::max(maxDeg, degrees[i]);\n    }\n\n    return maxDeg;\n}",
            "int max = 0;\n\t#pragma omp parallel for reduction(max:max)\n\tfor(int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t\tif(sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max = 0;\n\n#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int temp = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] > 0) {\n                temp++;\n            }\n        }\n        if (temp > max) {\n            max = temp;\n        }\n    }\n\n    return max;\n}",
            "#pragma omp parallel for reduction(max:maxDegree)\n    for (int i = 0; i < N; i++) {\n        int count = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                count++;\n            }\n        }\n        if (count > maxDegree) {\n            maxDegree = count;\n        }\n    }\n    return maxDegree;\n}",
            "// TODO: implement\n  int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n#pragma omp parallel for\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        degree += 1;\n      }\n    }\n    if (degree > maxDegree)\n      maxDegree = degree;\n  }\n\n  return maxDegree;\n}",
            "// This function requires OpenMP 4.5 or later, so we check at runtime.\n  if (omp_get_max_threads() < 2)\n    throw std::runtime_error(\n      \"Error: The number of threads should be more than 1 for OpenMP 4.5 or later.\");\n\n  // The current node degree\n  int degree = 0;\n\n  // Loop over all nodes.\n  #pragma omp parallel for reduction(max: degree)\n  for (size_t i = 0; i < N; i++) {\n\n    // The number of connections in node i\n    int connections = 0;\n\n    // Loop over all nodes.\n    for (size_t j = 0; j < N; j++) {\n\n      // If j is connected to i, increment the number of connections.\n      if (A[i * N + j] == 1)\n        connections++;\n    }\n\n    // Update the current node degree with the maximum of the node degree\n    // and the number of connections.\n    degree = std::max(degree, connections);\n  }\n\n  // Return the highest node degree.\n  return degree;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      sum += A[i*N + j];\n    }\n    maxDegree = std::max(maxDegree, sum);\n  }\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n    // use the range parallel for to compute the maximum node degree in parallel\n#pragma omp parallel for reduction(max : max_degree)\n    for(size_t i = 0; i < N; i++){\n        int max_neighbor = 0;\n\n        for(size_t j = 0; j < N; j++) {\n            if(A[i*N + j]) {\n                max_neighbor++;\n            }\n        }\n        max_degree = (max_degree > max_neighbor)? max_degree : max_neighbor;\n    }\n\n    return max_degree;\n}",
            "int maxDeg = 0;\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) degree++;\n\t\t}\n\t\tif (degree > maxDeg) maxDeg = degree;\n\t}\n\treturn maxDeg;\n}",
            "int nMax = 0;\n\n#pragma omp parallel for reduction(max:nMax)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        nMax = std::max(nMax, (int)(N - i - 1));\n      }\n    }\n  }\n\n  return nMax;\n}",
            "int max = 0;\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++)\n  {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++)\n    {\n      sum += A[i * N + j];\n    }\n    if (sum > max)\n    {\n      max = sum;\n    }\n  }\n  return max;\n}",
            "// TODO: replace this comment with the actual implementation.\n    // You can only use C++ and OpenMP constructs.\n    // You cannot use any other libraries.\n    // If your code is correct, it should return the highest node degree in the graph.\n    // The graph is defined in the adjacency matrix A. A is an NxN adjacency matrix stored in row-major.\n\n    // Add your code here.\n\n    int max = -1;\n#pragma omp parallel for\n    for(int i = 0; i < N; i++){\n        int sum = 0;\n        for(int j = 0; j < N; j++){\n            sum += A[i*N + j];\n        }\n        if(sum > max) max = sum;\n    }\n    return max;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel\n  {\n  int privateDegree = 0;\n  #pragma omp for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] > 0) privateDegree++;\n    }\n    #pragma omp critical\n    if (privateDegree > maxDegree) maxDegree = privateDegree;\n  }\n  }\n  return maxDegree;\n}",
            "int maxDeg = 0;\n# pragma omp parallel for reduction(max: maxDeg)\n  for (size_t i = 0; i < N; ++i) {\n    int nodeDegree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        nodeDegree++;\n      }\n    }\n    maxDeg = std::max(maxDeg, nodeDegree);\n  }\n  return maxDeg;\n}",
            "int max = 0;\n#pragma omp parallel for reduction(max: max)\n    for(size_t i = 0; i < N; ++i) {\n        int count = 0;\n        for(size_t j = 0; j < N; ++j) {\n            count += A[i * N + j];\n        }\n        max = std::max(max, count);\n    }\n    return max;\n}",
            "int maxDeg = 0;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tint deg = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tdeg++;\n\t\t\t}\n\t\t}\n\t\tif (deg > maxDeg) {\n\t\t\tmaxDeg = deg;\n\t\t}\n\t}\n\treturn maxDeg;\n}",
            "// YOUR CODE GOES HERE\n  // return the highest degree of the graph (number of edges)\n  int max = 0;\n  std::vector<int> degree(N, 0);\n  #pragma omp parallel for schedule(dynamic, 1) reduction(max : max)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        #pragma omp atomic\n        degree[i] += 1;\n      }\n    }\n    if (degree[i] > max) {\n      max = degree[i];\n    }\n  }\n  return max;\n}",
            "//...\n\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for shared(maxDegree)\n\tfor(int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[j * N + i] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\tif(degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// Create an empty vector to store the degrees\n  std::vector<int> degrees(N, 0);\n\n  // Compute the degrees using OpenMP\n  #pragma omp parallel for schedule(static)\n  for(size_t row = 0; row < N; ++row) {\n    for(size_t col = 0; col < N; ++col) {\n      if(A[row * N + col]!= 0) {\n        degrees[row]++;\n      }\n    }\n  }\n\n  // Find the maximum degree\n  int maxDegree = degrees[0];\n  for(size_t i = 0; i < N; ++i) {\n    if(degrees[i] > maxDegree) {\n      maxDegree = degrees[i];\n    }\n  }\n\n  return maxDegree;\n}",
            "// your code here\n    int max = 0;\n    int currMax = 0;\n#pragma omp parallel for shared(A, N, max)\n    for (int i = 0; i < N; i++) {\n        currMax = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                currMax += 1;\n            }\n        }\n        if (currMax > max) {\n            max = currMax;\n        }\n    }\n    return max;\n}",
            "int max_degree = 0;\n  #pragma omp parallel for\n  for (size_t node_id = 0; node_id < N; node_id++) {\n    int node_degree = 0;\n    for (size_t i = 0; i < N; i++) {\n      if (A[N*node_id + i] == 1) {\n        node_degree += 1;\n      }\n    }\n    if (node_degree > max_degree) {\n      max_degree = node_degree;\n    }\n  }\n  return max_degree;\n}",
            "int max = 0;\n\tint temp;\n\tfor(size_t i = 0; i < N; i++) {\n\t\ttemp = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\ttemp++;\n\t\t\t}\n\t\t}\n\t\tif (temp > max) {\n\t\t\tmax = temp;\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDeg = 0;\n#pragma omp parallel for reduction(max:maxDeg)\n  for(size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for(size_t j = 0; j < N; ++j)\n      degree += A[i * N + j];\n    if(degree > maxDeg)\n      maxDeg = degree;\n  }\n  return maxDeg;\n}",
            "int max = 0;\n\t#pragma omp parallel for reduction(max: max)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t\tmax = max > sum? max : sum;\n\t}\n\treturn max;\n}",
            "#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        #pragma omp critical\n        if (j > maxDegree)\n          maxDegree = j;\n      }\n    }\n  }\n  return maxDegree;\n}",
            "int max = -1;\n\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tint cnt = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tcnt++;\n\t\t}\n\n\t\tif (cnt > max) {\n\t\t\tmax = cnt;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int max = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for (size_t j = 0; j < N; ++j) {\n      count += A[i*N + j];\n    }\n    if (count > max) {\n      max = count;\n    }\n  }\n  return max;\n}",
            "int max_degree = 0;\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for(size_t j = 0; j < N; ++j) {\n      sum += A[i*N+j];\n    }\n    if (sum > max_degree) {\n      max_degree = sum;\n    }\n  }\n  return max_degree;\n}",
            "std::vector<int> degree(N, 0);\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\t++degree[i];\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint max_degree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tmax_degree = std::max(max_degree, degree[i]);\n\t}\n\n\treturn max_degree;\n}",
            "std::vector<int> local_max;\n\n#pragma omp parallel\n  {\n    int local_max_private = 0;\n    std::vector<int> row;\n    for(size_t i = 0; i < N; i++) {\n      row = A[i];\n      int max_in_row = *std::max_element(row.begin(), row.end());\n      if(max_in_row > local_max_private)\n        local_max_private = max_in_row;\n    }\n\n#pragma omp critical\n    local_max.push_back(local_max_private);\n\n  }\n  int max = *std::max_element(local_max.begin(), local_max.end());\n  return max;\n}",
            "int max_deg = 0;\n\t\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = i; j < N; j++) {\n\t\t\tif(A[i * N + j] > 0) {\n\t\t\t\tif(max_deg < (j - i + 1)) {\n\t\t\t\t\tmax_deg = j - i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn max_deg;\n}",
            "if (A.size()!= N * N)\n    throw std::runtime_error(\"A must be an NxN adjacency matrix\");\n\n  int maxDeg = 0;\n#pragma omp parallel for reduction(max:maxDeg)\n  for (size_t i = 0; i < N; ++i) {\n    int deg = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        deg++;\n    }\n    if (deg > maxDeg)\n      maxDeg = deg;\n  }\n  return maxDeg;\n}",
            "int max_deg = 0;\n  #pragma omp parallel for schedule(dynamic, 100) reduction(max:max_deg)\n  for (int i = 0; i < N; i++) {\n    int deg = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]) deg++;\n    }\n    max_deg = (max_deg < deg)? deg : max_deg;\n  }\n\n  return max_deg;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (maxDegree < degree) {\n\t\t\t\tmaxDegree = degree;\n\t\t\t}\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// TODO\n\tint a = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\ta = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\ta++;\n\t\t}\n\t\tif (a > 1)\n\t\t\tbreak;\n\t}\n\treturn a;\n}",
            "// YOUR CODE GOES HERE\n    return 0;\n}",
            "#pragma omp parallel for reduction(max: maxDegree)\nfor (size_t i = 0; i < N; i++) {\n\tint sum = 0;\n\tfor (size_t j = 0; j < N; j++) {\n\t\tsum += A[i*N + j];\n\t}\n\tif (sum > maxDegree) {\n\t\tmaxDegree = sum;\n\t}\n}\nreturn maxDegree;\n}",
            "int max_degree = 0;\n\n#pragma omp parallel for default(none) shared(max_degree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint local_max = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++local_max;\n\t\t\t}\n\t\t}\n\t\tlocal_max = local_max > max_degree? local_max : max_degree;\n#pragma omp critical\n\t\tmax_degree = local_max > max_degree? local_max : max_degree;\n\t}\n\n\treturn max_degree;\n}",
            "int mxDegree = 0;\n\tint * degree = new int[N];\n\tmemset(degree, 0, sizeof(int) * N);\n\n\t#pragma omp parallel for shared(degree, A)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tdegree[i]++;\n\t\t\t\t#pragma omp atomic\n\t\t\t\tdegree[j]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for reduction(max: mxDegree)\n\tfor (int i = 0; i < N; i++) {\n\t\tmxDegree = degree[i] > mxDegree? degree[i] : mxDegree;\n\t}\n\tdelete[] degree;\n\treturn mxDegree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n\n  return maxDegree;\n}",
            "int max = 0;\n  #pragma omp parallel for reduction(max:max)\n  for (size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for (size_t j = 0; j < N; ++j) {\n      count += A[i * N + j];\n    }\n    max = std::max(max, count);\n  }\n  return max;\n}",
            "int max_degree = 0;\n\n  // TODO: implement the computation of the maximum node degree\n  // You can use OpenMP to parallelize this loop.\n  // You may want to check out the omp_get_thread_num() and omp_get_num_threads() functions.\n\n  return max_degree;\n}",
            "#pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      int sum = 0;\n      for (int k = 0; k < N; k++) {\n        if (A[i * N + k] == 1)\n          sum++;\n      }\n      if (sum == 0) {\n        #pragma omp atomic update\n        i = N;\n        j = N;\n      }\n    }\n  }\n  return 0;\n}",
            "int maxDegree{};\n\n#pragma omp parallel\n\t{\n#pragma omp for reduction(max: maxDegree)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tint localMax = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tlocalMax += A[i*N + j];\n\t\t\t}\n\t\t\tmaxDegree = std::max(maxDegree, localMax);\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree{ 0 };\n  int local_max_degree{ 0 };\n  #pragma omp parallel for reduction(max: maxDegree)\n  for(size_t i = 0; i < N; i++) {\n    for(size_t j = 0; j < N; j++) {\n      if(A[i*N + j] == 1) local_max_degree++;\n    }\n    maxDegree = std::max(local_max_degree, maxDegree);\n  }\n\n  return maxDegree;\n}",
            "// TODO: YOUR CODE HERE\n  int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max:maxDegree)\n  for(size_t i = 0; i < N; ++i)\n  {\n      int deg = 0;\n      for(size_t j = 0; j < N; ++j)\n      {\n          deg += A[i*N + j];\n      }\n      if(deg > maxDegree) maxDegree = deg;\n  }\n  return maxDegree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[N * i + j];\n\t\t}\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n    int degree = 0;\n    //#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        if (degree > maxDegree)\n            maxDegree = degree;\n    }\n    return maxDegree;\n}",
            "auto max = 0;\n  #pragma omp parallel\n  {\n    auto private_max = 0;\n    #pragma omp for nowait\n    for (auto i = 0u; i < N; ++i) {\n      auto cur = 0;\n      for (auto j = 0u; j < N; ++j) {\n        cur += A[i * N + j];\n      }\n      private_max = std::max(private_max, cur);\n    }\n\n    #pragma omp critical\n    {\n      max = std::max(max, private_max);\n    }\n  }\n  return max;\n}",
            "int max_deg = -1;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\n\t\tif (degree > max_deg) {\n#pragma omp critical\n\t\t\tmax_deg = degree;\n\t\t}\n\t}\n\n\treturn max_deg;\n}",
            "int max = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\n#pragma omp parallel for\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tsum += 1;\n\t\t\t}\n\t\t}\n\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int degree = 0;\n#pragma omp parallel for reduction(max:degree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > degree) {\n\t\t\tdegree = sum;\n\t\t}\n\t}\n\treturn degree;\n}",
            "int max = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t\tif (sum > max) {\n\t\t\t#pragma omp critical\n\t\t\tmax = sum;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "// Implementation here\n}",
            "int result = 0;\n  #pragma omp parallel for schedule(dynamic) reduction(max: result)\n  for (size_t i = 0; i < N; ++i) {\n    int nodeDegree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] > 0) {\n        ++nodeDegree;\n      }\n    }\n    result = std::max(nodeDegree, result);\n  }\n  return result;\n}",
            "#pragma omp parallel for reduction(max: degree)\n  for (int i = 0; i < N; ++i) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j] > 0) {\n        degree++;\n      }\n    }\n  }\n  return degree;\n}",
            "//  std::vector<int> degrees(N, 0); // each element is the degree of that node\n  //  for (size_t i = 0; i < N; ++i) {\n  //    for (size_t j = 0; j < N; ++j) {\n  //      if (A[i * N + j])\n  //        degrees[i] += 1;\n  //    }\n  //  }\n\n  //  int maxDegree = 0;\n  //  for (size_t i = 0; i < N; ++i) {\n  //    if (degrees[i] > maxDegree)\n  //      maxDegree = degrees[i];\n  //  }\n\n  // return maxDegree;\n\n  // use OpenMP\n  // use critical section\n  int maxDegree = 0;\n\n#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j])\n        degree += 1;\n    }\n#pragma omp critical\n    {\n      if (degree > maxDegree)\n        maxDegree = degree;\n    }\n  }\n\n  return maxDegree;\n}",
            "#pragma omp parallel\n\t{\n\t\tint maxDeg = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tsize_t degree = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tdegree += A[i * N + j];\n\t\t\t}\n\t\t\tif (degree > maxDeg) {\n\t\t\t\tmaxDeg = degree;\n\t\t\t}\n\t\t}\n#pragma omp critical\n\t\t{\n\t\t\tif (maxDeg > maxDeg) {\n\t\t\t\tmaxDeg = maxDeg;\n\t\t\t}\n\t\t}\n\t}\n}",
            "int maxDegree = 0;\n\n#pragma omp parallel for reduction(max: maxDegree)\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++)\n      sum += A[i*N + j];\n    maxDegree = std::max(maxDegree, sum);\n  }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i*N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j]!= 0) degree++;\n        }\n        #pragma omp critical\n        maxDegree = std::max(maxDegree, degree);\n    }\n\n    return maxDegree;\n}",
            "int max_degree = 0;\n#pragma omp parallel\n    {\n        int max_thread_degree = 0;\n        std::vector<int> thread_degrees(N);\n#pragma omp for\n        for (int i = 0; i < N; i++) {\n            thread_degrees[i] = 0;\n            for (int j = 0; j < N; j++) {\n                thread_degrees[i] += A[i * N + j];\n            }\n            if (thread_degrees[i] > max_thread_degree) {\n                max_thread_degree = thread_degrees[i];\n            }\n        }\n#pragma omp critical\n        if (max_thread_degree > max_degree) {\n            max_degree = max_thread_degree;\n        }\n    }\n\n    return max_degree;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for reduction(max:maxDegree)\n    for (size_t i = 0; i < N; i++) {\n\n        int sum = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                sum++;\n            }\n        }\n        maxDegree = (sum > maxDegree)? sum : maxDegree;\n    }\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\n  // TODO: Compute in parallel\n#pragma omp parallel for schedule(dynamic) reduction(max:maxDegree)\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        degree++;\n      }\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; ++i) {\n\t\tint current_degree = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A[i*N + j] > 0) {\n\t\t\t\tcurrent_degree++;\n\t\t\t}\n\t\t}\n\t\tmax_degree = std::max(max_degree, current_degree);\n\t}\n\treturn max_degree;\n}",
            "// TODO: implement\n  int max_degree = 0;\n  std::vector<int> degree(N, 0);\n#pragma omp parallel for\n  for(int i = 0; i < N; i++)\n  {\n    for(int j = 0; j < N; j++)\n    {\n      if(A[i*N + j]!= 0)\n      {\n        degree[i]++;\n        break;\n      }\n    }\n  }\n\n#pragma omp parallel for\n  for(int i = 0; i < N; i++)\n  {\n    if(max_degree < degree[i])\n    {\n      max_degree = degree[i];\n    }\n  }\n\n  return max_degree;\n}",
            "//TODO: compute the highest degree in the graph defined in A\n  std::vector<int> degrees(N, 0);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N+j]) {\n        degrees[i]++;\n      }\n    }\n  }\n  return *std::max_element(degrees.begin(), degrees.end());\n}",
            "int maxDeg = 0;\n\n  // Replace this code with your solution\n  int counter = 0;\n  for(int i=0; i<N; i++){\n    int temp = 0;\n    for(int j=0; j<N; j++){\n      temp += A[counter];\n      counter++;\n    }\n    if(temp > maxDeg){\n      maxDeg = temp;\n    }\n  }\n\n  return maxDeg;\n}",
            "std::vector<int> degrees(N, 0);\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        count++;\n      }\n    }\n    #pragma omp critical\n    {\n      degrees[i] = count;\n    }\n  }\n  return *(std::max_element(degrees.begin(), degrees.end()));\n}",
            "int max = 0;\n#pragma omp parallel for reduction(max: max)\n\tfor(size_t i = 0; i < N; i++)\n\t\tfor(size_t j = 0; j < N; j++)\n\t\t\tif(A[i*N + j] == 1) max = std::max(max, 1 + A[j*N + i]);\n\treturn max;\n}",
            "// std::vector<int> const& A = graph.A;\n\tint maxDegree = 0;\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0)\n\t\t\t\t++sum;\n\t\t}\n\t\tif (sum > maxDegree)\n\t\t\tmaxDegree = sum;\n\t}\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (degree > max_degree) {\n\t\t\t\tmax_degree = degree;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn max_degree;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\tint maxDegree = 0;\n\t#pragma omp parallel for reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, sum);\n\t}\n\treturn maxDegree;\n}",
            "// You can't declare these inside the parallel region.\n\t// Otherwise each thread would have its own private copy of the variables.\n\t//int maxDegree = 0;\n\t//std::vector<int> degrees(N, 0);\n\n\tint maxDegree;\n\tstd::vector<int> degrees(N, 0);\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t//omp_atomic\n\t\t\t\t\tdegrees[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp for reduction(max:maxDegree)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (degrees[i] > maxDegree) {\n\t\t\t\tmaxDegree = degrees[i];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int max_degree = 0;\n  #pragma omp parallel for reduction(max:max_degree)\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        degree++;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "int max_degree = 0;\n\n\t#pragma omp parallel for reduction(max: max_degree)\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tdegree += A[N*i + j];\n\t\t}\n\n\t\tmax_degree = (degree > max_degree)? degree : max_degree;\n\t}\n\n\treturn max_degree;\n}",
            "if (N == 0) return 0;\n\n  int max = 0;\n  //#pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      sum += A[i*N+j];\n    }\n    if (sum > max) {\n      max = sum;\n    }\n  }\n\n  return max;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++degree;\n      }\n    }\n    // You can use atomic operations for updating the max degree,\n    // but that is not required.\n    if (maxDegree < degree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int max = 0;\n#pragma omp parallel for reduction(max:max)\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      sum += A[i * N + j];\n    }\n    max = std::max(sum, max);\n  }\n  return max;\n}",
            "int res = 0;\n\t#pragma omp parallel for reduction(max:res)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tres = std::max(res, (int)((A[i * N + j] + 1) / 2));\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max : maxDegree)\n\tfor (int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j])\n\t\t\t\tdegree++;\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "// initialize an array to store the degree of each node\n  std::vector<int> degree(N, 0);\n\n  // #pragma omp parallel for schedule(static,1)\n  #pragma omp parallel for schedule(dynamic,1)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        #pragma omp atomic\n        degree[i]++;\n\n        #pragma omp atomic\n        degree[j]++;\n      }\n    }\n  }\n\n  int max = 0;\n\n  // find the highest degree\n  for (int d : degree) {\n    if (d > max) {\n      max = d;\n    }\n  }\n\n  return max;\n}",
            "int max_degree = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[N * i + j] == 1)\n\t\t\t\t++degree;\n\t\tif (degree > max_degree)\n\t\t\tmax_degree = degree;\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\n#pragma omp parallel\n  {\n\n  // Each thread will hold its own local version of maxDegree.\n  // We have to use dynamic allocation because threads cannot share variables.\n  int* localMaxDegree = new int;\n\n#pragma omp for\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        sum += 1;\n      }\n    }\n    if (sum > *localMaxDegree) {\n      *localMaxDegree = sum;\n    }\n  }\n\n#pragma omp critical\n  if (*localMaxDegree > maxDegree) {\n    maxDegree = *localMaxDegree;\n  }\n\n  delete localMaxDegree;\n  }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n    #pragma omp parallel for reduction(max: maxDegree)\n    for (size_t n = 0; n < N; n++) {\n        int degree = 0;\n        for (size_t m = 0; m < N; m++) {\n            if (A[N*n + m]) degree++;\n        }\n        maxDegree = std::max(degree, maxDegree);\n    }\n    return maxDegree;\n}",
            "int max = 0;\n#pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) degree++;\n    }\n    #pragma omp critical\n    max = (max > degree)? max : degree;\n  }\n  return max;\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[N*i+j] == 1) {\n                degree++;\n            }\n        }\n        if (degree > max_degree) {\n            #pragma omp critical\n            max_degree = degree;\n        }\n    }\n\n    return max_degree;\n}",
            "std::vector<int> degree(N, 0);\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N+j] == 1) {\n        #pragma omp atomic\n        degree[i] += 1;\n      }\n    }\n  }\n\n  // Find the maximum degree\n  int max = 0;\n  for (int d : degree) {\n    if (d > max) {\n      max = d;\n    }\n  }\n\n  return max;\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for shared(A, max_degree)\n    for(size_t i = 0; i < N; i++)\n    {\n        int count = 0;\n        for(size_t j = 0; j < N; j++)\n        {\n            if(A[i * N + j] == 1)\n                count++;\n        }\n\n        #pragma omp critical\n        if(count > max_degree)\n            max_degree = count;\n    }\n\n    return max_degree;\n}",
            "#pragma omp parallel for\n  for (int i=0; i<N; i++) {\n    for (int j=0; j<N; j++) {\n      if(A[i*N + j] == 1) {\n        // TODO\n      }\n    }\n  }\n\n  return 0;\n}",
            "int max_degree = 0;\n# pragma omp parallel for reduction(max:max_degree)\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i*N+j];\n    }\n    max_degree = max(max_degree, degree);\n  }\n\n  return max_degree;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max: maxDegree)\n  for (size_t i = 0; i < N; i++) {\n    int rowDegree = 0;\n    for (size_t j = 0; j < N; j++) {\n      rowDegree += A[i*N + j];\n    }\n    if (rowDegree > maxDegree) {\n      maxDegree = rowDegree;\n    }\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++)\n    {\n      int sum = 0;\n      for (size_t j = 0; j < N; j++)\n        sum += A[j + i*N];\n      maxDegree = std::max(maxDegree, sum);\n    }\n\n  return maxDegree;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int max = 0;\n\n  #pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    int deg = 0;\n    for(int j = 0; j < N; j++)\n      if(A[N*i + j]) deg++;\n\n    #pragma omp critical\n    {\n      if(max < deg) max = deg;\n    }\n  }\n  return max;\n}",
            "int maxDegree = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int curDegree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N+j] == 1)\n                curDegree++;\n        }\n        if (curDegree > maxDegree) {\n            maxDegree = curDegree;\n        }\n    }\n\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\t#pragma omp atomic capture\n\t\t\t\t{\n\t\t\t\t\tint oldMaxDegree = maxDegree;\n\t\t\t\t\tif(i > j) {\n\t\t\t\t\t\tif(oldMaxDegree < 2) maxDegree = 2;\n\t\t\t\t\t} else if(oldMaxDegree < 1) maxDegree = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tdegree += A[i*N + j];\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// std::cout << \"Hello world.\" << std::endl;\n  // // Write your code here\n  // std::cout << \"Max degree: \" << maxDegree << std::endl;\n}",
            "int max = 0;\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) degree++;\n\t\t}\n\t\tif (degree > max) max = degree;\n\t}\n\treturn max;\n}",
            "std::vector<int> degrees(N);\n  int max_degree = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++degrees[i];\n      }\n    }\n  }\n\n  #pragma omp parallel\n  {\n    #pragma omp single nowait\n    for (size_t i = 0; i < N; ++i) {\n      int local_max = 0;\n      #pragma omp for nowait reduction(max:local_max)\n      for (size_t j = 0; j < N; ++j) {\n        local_max = std::max(local_max, degrees[j]);\n      }\n      #pragma omp critical\n      {\n        max_degree = std::max(max_degree, local_max);\n      }\n    }\n  }\n  return max_degree;\n}",
            "auto maxDegree = 0;\n\n  #pragma omp parallel for shared(maxDegree)\n  for (size_t i = 0; i < N; ++i) {\n    auto degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\tint degree;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (degree > maxDegree) {\n\t\t\t\tmaxDegree = degree;\n\t\t\t}\n\t\t}\n\t\tdegree = 0;\n\t}\n\n\treturn maxDegree;\n}",
            "#pragma omp parallel for reduction(max:max_degree)\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] > 0) {\n        degree++;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "// TODO: your code here\n\n  int max_degree = 0;\n\n  #pragma omp parallel for reduction(max:max_degree)\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] > 0) {\n        degree++;\n      }\n    }\n    if (degree > max_degree) {\n      max_degree = degree;\n    }\n  }\n\n  return max_degree;\n}",
            "// Initialize to 0\n  int max_degree = 0;\n\n  // Each thread should look at one row of A\n# pragma omp parallel for reduction(max: max_degree)\n  for (size_t i=0; i<N; i++) {\n\n    // Count number of ones in row i\n    int local_degree = 0;\n    for (size_t j=0; j<N; j++) {\n      if (A[i*N + j] == 1) {\n        local_degree += 1;\n      }\n    }\n\n    // Store the highest degree so far\n    if (local_degree > max_degree) {\n      max_degree = local_degree;\n    }\n  }\n\n  // Return the highest degree\n  return max_degree;\n}",
            "std::vector<int> degree(N, 0);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (degree[i] > max) {\n\t\t\tmax = degree[i];\n\t\t}\n\t}\n\treturn max;\n}",
            "int max_degree = 0;\n#pragma omp parallel for reduction(max:max_degree)\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] > 0) {\n        degree++;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "auto highestDegree = 0;\n    // TODO\n\n    return highestDegree;\n}",
            "int max = 0;\n\t#pragma omp parallel for reduction(max:max)\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[i * N + j])\n\t\t\t\tmax = std::max(max, i + 1);\n\treturn max;\n}",
            "int highestDegree{0};\n\n    //#pragma omp parallel\n    //#pragma omp for\n    for (size_t i=0; i<N; i++) {\n        int degree{0};\n        for (size_t j=0; j<N; j++) {\n            degree += A[i * N + j];\n        }\n        if (degree > highestDegree) {\n            #pragma omp critical\n            highestDegree = degree;\n        }\n    }\n\n    return highestDegree;\n}",
            "int maxDeg = 0;\n\n#pragma omp parallel for reduction(max:maxDeg)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > maxDeg)\n\t\t\tmaxDeg = sum;\n\t}\n\treturn maxDeg;\n}",
            "int maxDegree = 0;\n\n\t//#pragma omp parallel for \n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[N*i+j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for reduction(max: maxDegree)\n\tfor (int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tdegree += A[i*N + j];\n\t\tmaxDegree = (maxDegree < degree)? degree : maxDegree;\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i*N + j]!= 0)\n        ++maxDegree;\n\n  return maxDegree;\n}",
            "// TODO: compute the maximum degree in parallel\n\t//\n\t// HINT: you can use omp_get_num_threads() and omp_get_thread_num()\n\t//       to access information about the number of threads and the\n\t//       id of the current thread\n\n\tint max = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\n\t\tif (count > max) {\n\t\t\tmax = count;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "// Initialize the maxDegree\n  int maxDegree = 0;\n  // Start an OpenMP parallel region\n  #pragma omp parallel\n  {\n    // Initialize the thread local maxDegree\n    int maxDegree_thread = 0;\n    // Loop over the rows of the adjacency matrix\n    for (size_t row = 0; row < N; ++row) {\n      // Count the number of non-zero entries\n      size_t count = 0;\n      for (size_t col = 0; col < N; ++col) {\n        if (A[row * N + col]!= 0)\n          count += 1;\n      }\n      // Update the thread local maxDegree\n      if (count > maxDegree_thread)\n        maxDegree_thread = count;\n    }\n    // Update the global maxDegree\n    #pragma omp critical\n    {\n      if (maxDegree_thread > maxDegree)\n        maxDegree = maxDegree_thread;\n    }\n  }\n  // Return the maximum degree\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n\t#pragma omp parallel for reduction(max: max_degree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\n\treturn max_degree;\n}",
            "int degree = 0;\n    int numThreads = omp_get_max_threads();\n    std::vector<int> localMax(numThreads, 0);\n    int chunk = N/numThreads;\n\n    // parallelize over rows of the adjacency matrix\n    #pragma omp parallel for shared(A, localMax)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            if (A[i*N+j]!= 0) {\n                localMax[omp_get_thread_num()]++;\n            }\n        }\n    }\n\n    // find the global maximum\n    for (auto& lm : localMax) {\n        if (lm > degree) {\n            degree = lm;\n        }\n    }\n    return degree;\n}",
            "int maxDegree = 0;\n\n  #pragma omp parallel for reduction(max : maxDegree)\n  for (size_t i = 0; i < N; i++)\n  {\n    int currDegree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N+j] == 1) {\n        currDegree++;\n      }\n    }\n    if (currDegree > maxDegree) {\n      maxDegree = currDegree;\n    }\n  }\n  return maxDegree;\n}",
            "// TODO: Insert your code here\n  int maxDegree = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++)\n  {\n    int sum = 0;\n    for (int j = 0; j < N; j++)\n    {\n      sum += A[i * N + j];\n    }\n    if (sum > maxDegree)\n    {\n      maxDegree = sum;\n    }\n  }\n  return maxDegree;\n}",
            "int max = 0;\n  #pragma omp parallel for reduction(max: max)\n  for (size_t i = 0; i < N; ++i) {\n    int rowSum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      rowSum += A[i * N + j];\n    }\n    max = std::max(max, rowSum);\n  }\n  return max;\n}",
            "int result = 0;\n\t#pragma omp parallel for\n\tfor (int i=0; i<N; i++) {\n\t\tint rowSum = 0;\n\t\tfor (int j=0; j<N; j++) {\n\t\t\trowSum += A[i*N + j];\n\t\t}\n\t\tif (rowSum > result) {\n\t\t\tresult = rowSum;\n\t\t}\n\t}\n\treturn result;\n}",
            "// Your code here!\n  int maxDeg = 0;\n  #pragma omp parallel for schedule(dynamic) reduction(max: maxDeg)\n  for (size_t i = 0; i < N; i++) {\n    int currDeg = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[N*i + j] == 1) {\n        currDeg++;\n      }\n    }\n    maxDeg = (currDeg > maxDeg)? currDeg : maxDeg;\n  }\n\n  return maxDeg;\n}",
            "int max = 0;\n  #pragma omp parallel for reduction(max:max)\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j)\n      sum += A[i*N + j];\n    max = std::max(sum, max);\n  }\n  return max;\n}",
            "int maxDeg = 0;\n\n  // TODO: parallelize this loop\n  for (int i = 0; i < N; ++i) {\n    int deg = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[N * i + j]!= 0) {\n        ++deg;\n      }\n    }\n    maxDeg = std::max(maxDeg, deg);\n  }\n\n  return maxDeg;\n}",
            "int result = 0;\n    #pragma omp parallel for reduction(max:result)\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                degree++;\n            }\n        }\n        result = std::max(result, degree);\n    }\n    return result;\n}",
            "int max_degree = 0;\n#pragma omp parallel for reduction(max: max_degree)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N * i + j] == 1) degree++;\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\treturn max_degree;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "serial",
        "prompt": "/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint curr = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tcurr++;\n\t\t\t}\n\t\t}\n\t\tif (curr > max) {\n\t\t\tmax = curr;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max_degree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint current_degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j])\n\t\t\t\t++current_degree;\n\t\t}\n\t\tif (max_degree < current_degree)\n\t\t\tmax_degree = current_degree;\n\t}\n\treturn max_degree;\n}",
            "// TODO: implement this\n    return 0;\n}",
            "std::vector<int> maxDegreeNodes(N, 0);\n\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = i + 1; j < N; ++j) {\n         if (A[i * N + j] == 1) {\n            maxDegreeNodes[i]++;\n            maxDegreeNodes[j]++;\n         }\n      }\n   }\n\n   auto it = std::max_element(maxDegreeNodes.begin(), maxDegreeNodes.end());\n   return *it;\n}",
            "int max = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\n\t\tif (degree > max)\n\t\t\tmax = degree;\n\t}\n\n\treturn max;\n}",
            "// TODO: implement me\n  int maxDeg = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i*N+j];\n    }\n    if (degree > maxDeg) {\n      maxDeg = degree;\n    }\n  }\n\n  return maxDeg;\n}",
            "int max_degree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int cur_degree = 0;\n    for (size_t j = 0; j < N; ++j)\n      cur_degree += A[i*N + j];\n    max_degree = std::max(max_degree, cur_degree);\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[j * N + i] > 0) {\n        degree++;\n      }\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int mx = -1;\n  for (size_t i = 0; i < N; ++i) {\n    int cur_degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j])\n        ++cur_degree;\n    }\n    mx = std::max(mx, cur_degree);\n  }\n  return mx;\n}",
            "// Write your code here\n    int maxDegree{0};\n    int sumDegree{0};\n    int N_temp = N;\n    for (size_t i = 0; i < N; i++) {\n        sumDegree = 0;\n        for (size_t j = 0; j < N_temp; j++) {\n            if (A[i*N+j] == 1) {\n                sumDegree++;\n            }\n        }\n        if (maxDegree < sumDegree) {\n            maxDegree = sumDegree;\n        }\n        N_temp--;\n    }\n    return maxDegree;\n}",
            "// Your code here\n\n\tint max_degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint cur_degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tcur_degree += 1;\n\t\t\t}\n\t\t}\n\t\tif (cur_degree > max_degree) {\n\t\t\tmax_degree = cur_degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int maxDegree{0};\n  int currentDegree{0};\n\n  for (int i{0}; i < A.size(); ++i) {\n    for (int j{0}; j < A[i]; ++j) {\n      currentDegree++;\n    }\n    maxDegree = (maxDegree < currentDegree)? currentDegree : maxDegree;\n    currentDegree = 0;\n  }\n\n  return maxDegree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "std::vector<int> degrees(N);\n\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        ++degrees[i];\n    }\n  }\n\n  return *std::max_element(degrees.begin(), degrees.end());\n}",
            "int maxDeg = 0;\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j] > 0)\n                maxDeg = std::max(maxDeg, A[i * N + j]);\n    return maxDeg;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++)\n      degree += A[i * N + j];\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int max_degree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int nodeDegree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0)\n                nodeDegree++;\n        }\n\n        if (nodeDegree > maxDegree)\n            maxDegree = nodeDegree;\n    }\n\n    return maxDegree;\n}",
            "int degree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint curDegree = 0;\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tcurDegree += A[i * N + j];\n\t\tif (curDegree > degree)\n\t\t\tdegree = curDegree;\n\t}\n\treturn degree;\n}",
            "std::vector<int> sum;\n\tint sum_val = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsum_val = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum_val += A[i*N + j];\n\t\t}\n\t\tsum.push_back(sum_val);\n\t}\n\tint max = 0;\n\tfor (size_t i = 0; i < sum.size(); i++) {\n\t\tif (max < sum[i])\n\t\t\tmax = sum[i];\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[N * i + j]) {\n                ++degree;\n            }\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[N * i + j] > 0) {\n        ++degree;\n      }\n    }\n    max = std::max(max, degree);\n  }\n  return max;\n}",
            "if (N == 0) return 0;\n\n  std::unordered_map<int, int> degrees;\n\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        degrees[i] = degrees[i] + 1;\n      }\n    }\n  }\n\n  int max = 0;\n\n  for (auto const& [node, degree] : degrees) {\n    if (degree > max) {\n      max = degree;\n    }\n  }\n\n  return max;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmax = degree > max? degree : max;\n\t}\n\treturn max;\n}",
            "int max_degree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; i++) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[j * N + i] > 0) {\n                degree++;\n            }\n        }\n        if (maxDegree < degree) {\n            maxDegree = degree;\n        }\n    }\n    return maxDegree;\n}",
            "std::vector<int> degrees(N, 0);\n\n    for (size_t row = 0; row < N; ++row) {\n        for (size_t col = 0; col < N; ++col) {\n            if (A[row * N + col]!= 0) {\n                degrees[row]++;\n            }\n        }\n    }\n\n    int max_degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        max_degree = std::max(max_degree, degrees[i]);\n    }\n\n    return max_degree;\n}",
            "// TODO: Your code here\n    int maxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int sum = 0;\n        for (size_t j = 0; j < N; j++) {\n            sum += A[i*N+j];\n        }\n        if (sum > maxDegree)\n            maxDegree = sum;\n    }\n    return maxDegree;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; ++i) {\n    int degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[N*i + j] == 1)\n        ++degree;\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int max = 0;\n\tint x, y, sum = 0;\n\n\tfor (y = 0; y < N; ++y) {\n\t\tfor (x = 0; x < N; ++x) {\n\t\t\tif (A[y * N + x] == 1)\n\t\t\t\tsum++;\n\t\t}\n\t\tif (sum > max)\n\t\t\tmax = sum;\n\t\tsum = 0;\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++degree;\n      }\n    }\n\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = i + 1; j < N; ++j)\n            if (A[i*N + j]!= 0)\n                max_degree++;\n\n    return max_degree;\n}",
            "int max_degree = 0;\n\n  // Iterate over all the nodes in the graph.\n  for (size_t i = 0; i < N; i++) {\n    // Iterate over all the neighbors of the current node and count how many\n    // of them are connected to the same node.\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        max_degree++;\n      }\n    }\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "std::vector<int> degrees(N, 0);\n\tint maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N * i + j]!= 0) {\n\t\t\t\tdegrees[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tmaxDegree = std::max(maxDegree, degrees[i]);\n\t}\n\n\treturn maxDegree;\n}",
            "// Find the highest degree\n\tint maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1 || A[j * N + i] == 1) {\n\t\t\t\tmaxDegree++;\n\t\t\t}\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// TODO: Your code here\n\tint maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "int m = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j)\n      degree += A[i * N + j];\n    m = std::max(m, degree);\n  }\n  return m;\n}",
            "int max_degree = 0;\n    for(size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for(size_t j = 0; j < N; j++) {\n            if (A[j*N + i] == 1)\n                degree++;\n        }\n        if (degree > max_degree)\n            max_degree = degree;\n    }\n    return max_degree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[j * N + i]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "// Your code goes here!\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (max < degree) {\n\t\t\tmax = degree;\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDeg = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint nb = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tnb++;\n\t\t\t}\n\t\t}\n\t\tmaxDeg = std::max(maxDeg, nb);\n\t}\n\treturn maxDeg;\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                if (maxDegree < (i + 1)) {\n                    maxDegree = (i + 1);\n                }\n            }\n        }\n    }\n    return maxDegree;\n}",
            "int max = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tint c = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tc += A[i*N+j];\n\t\t}\n\t\tmax = std::max(max, c);\n\t}\n\treturn max;\n}",
            "int maxDeg = 0;\n    for(size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for(size_t j = 0; j < N; j++) {\n            if(A[i*N + j] == 1) {\n                degree++;\n            }\n        }\n        if(degree > maxDeg) {\n            maxDeg = degree;\n        }\n    }\n    return maxDeg;\n}",
            "std::vector<int> degree(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree[i]++;\n\t\t\t}\n\t\t}\n\t}\n\tint maxDegree = *(std::max_element(degree.begin(), degree.end()));\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        degree++;\n      }\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "if (N == 0) return 0;\n\tint max_degree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int m = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint d = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\td += A[i*N + j];\n\t\t}\n\t\tif (d > m) {\n\t\t\tm = d;\n\t\t}\n\t}\n\treturn m;\n}",
            "int degree = 0;\n  for (auto i = 0; i < N; ++i) {\n    int curr_degree = 0;\n    for (auto j = 0; j < N; ++j) {\n      curr_degree += A[i * N + j];\n    }\n    if (curr_degree > degree) degree = curr_degree;\n  }\n  return degree;\n}",
            "int res = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tres = std::max(res, A[i * N + j]);\n\t\t}\n\t}\n\treturn res;\n}",
            "int max_degree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t++degree;\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\n\treturn max_degree;\n}",
            "int degree = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j]!= 0) {\n        if (degree == 0)\n          degree = 1;\n        else\n          ++degree;\n      }\n  return degree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "//std::vector<std::vector<int>> A(N, std::vector<int>(N, 0));\n\tstd::vector<int> degrees;\n\t//int maxDegree = 0;\n\n\t//fill matrix\n\t/*for (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tA.at(i).at(j) = 0;\n\t\t}\n\t}\n\tfor (size_t i = 0; i < A.size(); i++) {\n\t\tA.at(i).at(i) = 1;\n\t}*/\n\n\t//count degrees\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A.at(i * N + j)!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tdegrees.push_back(count);\n\t}\n\t//print degrees\n\t/*std::cout << \"Degrees:\";\n\tfor (auto x : degrees) {\n\t\tstd::cout << x << \", \";\n\t}*/\n\t//return max degree\n\tint max = 0;\n\tfor (auto x : degrees) {\n\t\tif (x > max) {\n\t\t\tmax = x;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tif (max < degree) {\n\t\t\tmax = degree;\n\t\t}\n\t}\n\treturn max;\n}",
            "int max = -1;\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < N; j++)\n      if (A[i * N + j] > 0)\n        max = std::max(max, A[i * N + j]);\n  return max;\n}",
            "int result = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint cur = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) cur++;\n\t\t}\n\t\tif (cur > result) result = cur;\n\t}\n\treturn result;\n}",
            "std::vector<int> degrees;\n  degrees.reserve(N);\n\n  for (size_t row = 0; row < N; row++) {\n\n    int degree = 0;\n\n    for (size_t col = 0; col < N; col++) {\n      if (A[row * N + col] == 1) {\n        degree++;\n      }\n    }\n\n    degrees.push_back(degree);\n  }\n\n  return *std::max_element(degrees.begin(), degrees.end());\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmax = std::max(max, degree);\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int sum = 0;\n        for (size_t j = 0; j < N; ++j)\n            sum += A[i * N + j];\n        if (sum > max)\n            max = sum;\n    }\n    return max;\n}",
            "int max_deg = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        int deg = 0;\n        for (size_t j = 0; j < N; j++)\n            deg += A[i*N + j];\n        max_deg = std::max(max_deg, deg);\n    }\n\n    return max_deg;\n}",
            "int maxDegree = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(degree, maxDegree);\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree)\n      maxDegree = degree;\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                degree += 1;\n            }\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    max = std::max(max, degree);\n  }\n  return max;\n}",
            "std::vector<int> degrees(N, 0);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++degrees[i];\n      }\n    }\n  }\n\n  // We sort in reverse order to find the highest degree\n  std::sort(degrees.begin(), degrees.end(), std::greater<int>());\n  return degrees[0];\n}",
            "int maxDeg = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int d = 0;\n        for (size_t j = 0; j < N; ++j) {\n            d += A[i * N + j];\n        }\n        maxDeg = std::max(d, maxDeg);\n    }\n    return maxDeg;\n}",
            "int maxDegree = 0;\n    for (auto node : A) {\n        int degree = 0;\n        for (size_t i = 0; i < N; ++i) {\n            if (node & (1 << i)) {\n                ++degree;\n            }\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int maxDegree{ 0 };\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree{ 0 };\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = -1;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] > 0) {\n        degree++;\n      }\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint deg = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdeg += A[i*N + j];\n\t\t}\n\t\tmax = std::max(max, deg);\n\t}\n\treturn max;\n}",
            "int max = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A[i * N + j];\n\t\t}\n\n\t\tif (max < degree) {\n\t\t\tmax = degree;\n\t\t}\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++degree;\n      }\n    }\n\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n    for(size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for(size_t j = 0; j < N; j++) {\n            if (A[N*i + j] == 1) degree++;\n        }\n        max_degree = max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "if (A.size()!= N * N) {\n    throw std::invalid_argument(\"matrix must have n*n elements\");\n  }\n\n  // Find the highest degree\n  int maxDegree = 0;\n  for (size_t i = 0; i < A.size(); ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < A.size(); ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n    for (int i = 0; i < N; i++) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(degree, max_degree);\n    }\n\n    return max_degree;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i*N+j];\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "int max_degree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]) {\n        degree++;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] > 0) {\n                if (i == j) {\n                    max = std::max(max, 1);\n                } else {\n                    max = std::max(max, 2);\n                }\n            }\n        }\n    }\n\n    return max;\n}",
            "int degree = 0;\n\n\t// Fill degree vector, get max of the vector\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn degree;\n}",
            "int maxDeg = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint currentDeg = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++currentDeg;\n\t\t\t}\n\t\t}\n\t\tmaxDeg = std::max(maxDeg, currentDeg);\n\t}\n\treturn maxDeg;\n}",
            "if (N == 0) {\n    return 0;\n  }\n  std::vector<int> degrees(N);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++degrees[i];\n        ++degrees[j];\n      }\n    }\n  }\n  auto it = std::max_element(degrees.begin(), degrees.end());\n  return *it;\n}",
            "int m = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    m = std::max(m, degree);\n  }\n  return m;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[i * N + j])\n\t\t\t\tdegree++;\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "if (N <= 0)\n    return 0;\n\n  int maxDegree = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j)\n      degree += (A[N*i + j] == 1);\n\n    maxDegree = std::max(maxDegree, degree);\n  }\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n  for (int row = 0; row < N; row++) {\n    int degree = 0;\n    for (int col = 0; col < N; col++) {\n      degree += A[row * N + col];\n    }\n    if (degree > max_degree) {\n      max_degree = degree;\n    }\n  }\n\n  return max_degree;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; i++) {\n        int curr = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]!= 0) {\n                curr++;\n            }\n        }\n        max = std::max(max, curr);\n    }\n\n    return max;\n}",
            "int degree = 0;\n  for (auto v : A) {\n    int d = std::count(A.begin(), A.end(), v);\n    if (d > degree) {\n      degree = d;\n    }\n  }\n  return degree;\n}",
            "// TODO\n\treturn 0;\n}",
            "std::vector<int> degrees(N, 0);\n\tstd::vector<int> queue;\n\n\t// For each row of A\n\tfor (auto i = 0; i < N; i++) {\n\t\tfor (auto j = 0; j < N; j++) {\n\t\t\t// If the entry is 1, add j to the queue and increment degree.\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tqueue.push_back(j);\n\t\t\t\tdegrees[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// For each node in the queue, check every row of A to find the next adjacent node.\n\twhile (!queue.empty()) {\n\t\tauto i = queue.back();\n\t\tqueue.pop_back();\n\t\tfor (auto j = 0; j < N; j++) {\n\t\t\t// If the entry is 1, add j to the queue and increment degree.\n\t\t\tif (A[j*N + i]!= 0) {\n\t\t\t\tqueue.push_back(j);\n\t\t\t\tdegrees[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Compute the maximum degree in degrees.\n\tint max = 0;\n\tfor (auto i = 0; i < N; i++) {\n\t\tmax = std::max(max, degrees[i]);\n\t}\n\n\treturn max;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      sum += A[i * N + j];\n    }\n    max = std::max(max, sum);\n  }\n  return max;\n}",
            "int max = 0;\n\n    for(auto i = 0; i < N; i++)\n        max = std::max(max, countBits(A[i]));\n\n    return max;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "// TODO: Replace this code with a faster implementation\n\tint max_degree = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > max_degree)\n\t\t\tmax_degree = degree;\n\t}\n\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\t// Loop through the adjacency matrix and count the number of edges per node.\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint nodeDegree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++nodeDegree;\n\t\t\t}\n\t\t}\n\n\t\tmaxDegree = std::max(maxDegree, nodeDegree);\n\t}\n\n\treturn maxDegree;\n}",
            "int degMax = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int deg = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++deg;\n      }\n    }\n    degMax = std::max(deg, degMax);\n  }\n  return degMax;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// Write your code here\n  return 0;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i*N+j];\n    }\n    maxDegree = max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "std::vector<int> degrees(N, 0);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                degrees[i]++;\n            }\n        }\n    }\n\n    return *max_element(degrees.begin(), degrees.end());\n}",
            "int result = 0;\n    for (int i = 0; i < N; i++) {\n        int temp = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1)\n                temp++;\n        }\n        if (temp > result)\n            result = temp;\n    }\n    return result;\n}",
            "int maxDegree = 0;\n  for(size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for(size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if(degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "auto m = std::max_element(\n\t\tA.begin(),\n\t\tA.end()\n\t);\n\treturn *m;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i*N + j];\n    }\n    maxDegree = (maxDegree > degree)? maxDegree : degree;\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        if (degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n    return maxDegree;\n}",
            "// WRITE YOUR CODE HERE\n    // TODO: make a pass over the adjacency matrix, keep track of the highest degree.\n    int max_degree = 0;\n    int degree = 0;\n    for (auto i = 0; i < N; i++) {\n        for (auto j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        if (degree > max_degree) {\n            max_degree = degree;\n        }\n        degree = 0;\n    }\n    return max_degree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tdegree += A[i*N + j];\n\t\t}\n\t\tmax = std::max(max, degree);\n\t}\n\treturn max;\n}",
            "int maxDeg = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]!= 0) {\n                maxDeg++;\n            }\n        }\n    }\n    return maxDeg;\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n\n        if (degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n\n    return maxDegree;\n}",
            "std::unordered_map<int, int> degree_map;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[N*i + j] == 1) {\n\t++degree_map[i];\n\t++degree_map[j];\n      }\n    }\n  }\n\n  int max_degree = 0;\n  for (auto const& entry : degree_map) {\n    if (entry.second > max_degree) max_degree = entry.second;\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "std::vector<size_t> degrees(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegrees[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (degrees[i] > maxDegree) {\n\t\t\tmaxDegree = degrees[i];\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "auto const n = A.size();\n    assert(n == N * N);\n\n    // Calculate max degree\n    size_t max_deg = 0;\n    for (size_t i = 0; i < n; ++i) {\n        size_t curr_deg = 0;\n        for (size_t j = 0; j < n; ++j) {\n            if (A[i*N+j]) ++curr_deg;\n        }\n        max_deg = std::max(curr_deg, max_deg);\n    }\n    return max_deg;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    int d = 0;\n    for (size_t j = 0; j < N; j++) {\n      d += A[i * N + j];\n    }\n    max = std::max(max, d);\n  }\n  return max;\n}",
            "int maxDegree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1) degree++;\n\t\t}\n\n\t\tmaxDegree = degree > maxDegree? degree : maxDegree;\n\t}\n\n\treturn maxDegree;\n}",
            "std::vector<int> degrees(N, 0);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      degrees[i] += A[i * N + j];\n    }\n  }\n  int max_degree = degrees[0];\n  for (size_t i = 1; i < N; ++i) {\n    if (degrees[i] > max_degree) {\n      max_degree = degrees[i];\n    }\n  }\n  return max_degree;\n}",
            "std::vector<int> degree(N, 0);\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j]!= 0)\n                degree[i]++;\n    return *std::max_element(std::begin(degree), std::end(degree));\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = std::accumulate(A.begin() + (N * i), A.begin() + (N * (i + 1)), 0);\n    if (degree > maxDegree)\n      maxDegree = degree;\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int max_degree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++)\n      degree += (A[j * N + i] == 1);\n\n    if (degree > max_degree)\n      max_degree = degree;\n  }\n\n  return max_degree;\n}",
            "int maxDegree{0};\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree{0};\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) ++degree;\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "// Your code goes here\n    int max = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[N*i + j];\n        }\n        if (degree > max)\n            max = degree;\n    }\n    return max;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int degree = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        degree++;\n    }\n\n    if (degree > maxDegree)\n      maxDegree = degree;\n  }\n\n  return maxDegree;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int nodeDegree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] > 0) {\n        nodeDegree++;\n      }\n    }\n    max = std::max(max, nodeDegree);\n  }\n  return max;\n}",
            "int max = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[i*N + j] == 1) max = std::max(max, ++A[i*N + j]);\n\treturn max;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] > 0) {\n                ++degree;\n            }\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int maxDeg = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tif (sum > maxDeg) {\n\t\t\tmaxDeg = sum;\n\t\t}\n\t}\n\n\treturn maxDeg;\n}",
            "int maxDegree = 0;\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            if(A[i * N + j] == 1) {\n                ++maxDegree;\n            }\n        }\n    }\n    return maxDegree;\n}",
            "if (A.size()!= N*N)\n    throw std::invalid_argument(\"incorrect adjacency matrix\");\n  int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j])\n        degree++;\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++degree;\n      }\n    }\n    maxDegree = max(degree, maxDegree);\n  }\n  return maxDegree;\n}",
            "int max = -1;\n\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < N; j++)\n      if (A[i * N + j]!= 0)\n        if (j > i)\n          max = std::max(max, static_cast<int>(j - i));\n\n  return max;\n}",
            "int maxDegree = 0;\n  int degree;\n  for (size_t i = 0; i < N; i++) {\n    degree = 0;\n    for (size_t j = 0; j < N; j++)\n      degree += A[i * N + j];\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "std::vector<size_t> degrees(N, 0);\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\t++degrees[i];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn *std::max_element(degrees.begin(), degrees.end());\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tif (max < j) {\n\t\t\t\t\tmax = j;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(degree, maxDegree);\n  }\n  return maxDegree;\n}",
            "int maxDeg = 0;\n    for (size_t i = 0; i < N; i++) {\n        int sum = 0;\n        for (size_t j = 0; j < N; j++) {\n            sum += A[i * N + j];\n        }\n        maxDeg = std::max(maxDeg, sum);\n    }\n    return maxDeg;\n}",
            "int degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int sum = 0;\n        for (size_t j = 0; j < N; ++j) {\n            sum += A[i*N+j];\n        }\n        degree = std::max(degree, sum);\n    }\n    return degree;\n}",
            "std::vector<int> node_degrees(N, 0);\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            node_degrees[i] += A[i * N + j];\n        }\n    }\n    int max_degree = 0;\n    for (int i = 0; i < N; ++i) {\n        max_degree = std::max(max_degree, node_degrees[i]);\n    }\n    return max_degree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A[i * N + j];\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\treturn maxDegree;\n}",
            "int max = 0;\n\n    for(size_t i=0; i < N; ++i)\n        max = std::max(max, getRowDegree(A, i, N));\n\n    return max;\n}",
            "std::unordered_map<int, int> deg_map;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                ++deg_map[i];\n            }\n        }\n    }\n    int degree = 0;\n    for (auto const& elem : deg_map) {\n        degree = std::max(elem.second, degree);\n    }\n    return degree;\n}",
            "int max = 0;\n    for(int i = 0; i < N; ++i) {\n        int deg = 0;\n        for(int j = 0; j < N; ++j)\n            deg += A[i*N + j];\n        if(deg > max)\n            max = deg;\n    }\n    return max;\n}",
            "int max = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tmax = std::max(max, sum);\n\t}\n\treturn max;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[N * i + j] == 1) degree++;\n    }\n    if (max < degree) max = degree;\n  }\n  return max;\n}",
            "// A[i][j] == 1 if there is an edge between vertex i and vertex j\n    // Use dynamic programming to keep track of the maximum number of nodes\n    // that are reachable at each step of the graph traversal.\n\n    // TODO: Your code here\n\n    std::vector<int> reachable(N);\n    std::vector<int> max_reachable(N);\n\n    for (size_t i = 0; i < N; i++) {\n        max_reachable[i] = 1;\n    }\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            reachable[j] = (A[i][j] == 1)? max_reachable[i] + 1 : 0;\n        }\n        for (size_t j = 0; j < N; j++) {\n            max_reachable[j] = std::max(reachable[j], max_reachable[j]);\n        }\n    }\n\n    int max_degree = 0;\n    for (size_t i = 0; i < N; i++) {\n        max_degree = std::max(max_degree, max_reachable[i]);\n    }\n\n    return max_degree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (max < sum) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "// TODO: replace this with your code\n  return -1;\n}",
            "// Compute the number of vertices with degree at least 2 and at most 3\n    int num = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int deg = 0;\n        for (size_t j = 0; j < N; ++j) {\n            deg += A[N*i + j];\n        }\n        if (deg >= 2 && deg <= 3) {\n            num += 1;\n        }\n    }\n    return num;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A[i*N+j]!= 0)\n\t\t\t\t++degree;\n\t\t}\n\t\tmax = std::max(max, degree);\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int result = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int cur = 0;\n    for (size_t j = 0; j < N; ++j) {\n      cur += A[i*N + j];\n    }\n    if (result < cur)\n      result = cur;\n  }\n\n  return result;\n}",
            "std::vector<int> degrees(N, 0);\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        degrees[i] += 1;\n      }\n    }\n  }\n\n  int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (degrees[i] > maxDegree) {\n      maxDegree = degrees[i];\n    }\n  }\n\n  return maxDegree;\n}",
            "std::vector<int> degrees(N, 0);\n\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[N * i + j] == 1)\n                degrees[i]++;\n\n    int max_degree = degrees[0];\n    for (size_t i = 1; i < N; ++i)\n        max_degree = std::max(max_degree, degrees[i]);\n\n    return max_degree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[j * N + i]) {\n                degree++;\n            }\n        }\n        maxDegree = max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "if(N == 0) {\n\t\treturn 0;\n\t}\n\tint max = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tint c = 0;\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(A[i*N + j]) {\n\t\t\t\t++c;\n\t\t\t}\n\t\t}\n\t\tmax = std::max(max, c);\n\t}\n\treturn max;\n}",
            "int maxDeg = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDeg = std::max(maxDeg, degree);\n\t}\n\n\treturn maxDeg;\n}",
            "auto max = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N+j]!= 0 && i!= j) {\n                max = std::max(max, A[i*N+j]);\n            }\n        }\n    }\n    return max;\n}",
            "//...\n}",
            "int result = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] > 0) {\n        ++count;\n      }\n    }\n    result = std::max(result, count);\n  }\n\n  return result;\n}",
            "int max_degree = 0;\n  for (auto row : A) {\n    int degree = std::count(row.begin(), row.end(), 1);\n    if (degree > max_degree) {\n      max_degree = degree;\n    }\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tdegree++;\n\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\n\treturn maxDegree;\n}",
            "// Implement this function\n  int max = 0;\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] > max) {\n        max = A[i*N + j];\n      }\n    }\n  }\n  return max;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int sum = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j] > 0) {\n                sum++;\n            }\n        }\n        max = std::max(sum, max);\n    }\n    return max;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int num = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N+j] == 1)\n                num++;\n        }\n        max = std::max(max, num);\n    }\n    return max;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) degree++;\n\t\t}\n\t\tif (degree > maxDegree) maxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "int highestDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int currentDegree = 0;\n        for (size_t j = 0; j < N; j++) {\n            currentDegree += A[j * N + i];\n        }\n        if (currentDegree > highestDegree) {\n            highestDegree = currentDegree;\n        }\n    }\n    return highestDegree;\n}",
            "std::vector<int> degrees;\n\n\tdegrees.reserve(N);\n\n\t// TODO: Implement the algorithm to compute the highest node degree in the graph\n\n\treturn 0;\n}",
            "int m = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      sum += A[i*N + j];\n    }\n    m = std::max(m, sum);\n  }\n  return m;\n}",
            "int maxDegree = 0;\n  for(size_t row = 0; row < N; ++row) {\n    int degree = 0;\n    for(size_t col = 0; col < N; ++col) {\n      degree += A[row * N + col];\n    }\n    maxDegree = std::max(degree, maxDegree);\n  }\n  return maxDegree;\n}",
            "int max = 0;\n    for (size_t row = 0; row < N; row++) {\n        int degree = 0;\n        for (size_t col = 0; col < N; col++) {\n            degree += A[row*N + col];\n        }\n        if (degree > max) {\n            max = degree;\n        }\n    }\n    return max;\n}",
            "std::vector<int> degrees(N, 0);\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            degrees[i] += A[i*N + j];\n        }\n    }\n    int maxDegree = 0;\n    for (int d : degrees)\n        maxDegree = std::max(d, maxDegree);\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\t++degree;\n\t\t}\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j])\n\t\t\t\tmaxDegree = std::max(maxDegree, ++j);\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int currDegree = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j]) {\n                currDegree++;\n            }\n        }\n        if (currDegree > maxDegree) {\n            maxDegree = currDegree;\n        }\n    }\n\n    return maxDegree;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int nodeDegree = 0;\n    for (size_t j = 0; j < N; j++) {\n      nodeDegree += A[i * N + j];\n    }\n    maxDegree = std::max(nodeDegree, maxDegree);\n  }\n  return maxDegree;\n}",
            "// TODO\n  return 0;\n}",
            "size_t maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (maxDegree < sum) {\n\t\t\tmaxDegree = sum;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "std::vector<int> degree(N);\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      degree[i] += A[i * N + j];\n    }\n  }\n\n  int max = degree[0];\n  for (size_t i = 1; i < N; ++i) {\n    max = std::max(max, degree[i]);\n  }\n\n  return max;\n}",
            "int maxDegree{0};\n    for (int i{0}; i < N; ++i) {\n        int degree{0};\n        for (int j{0}; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) degree++;\n\t\t}\n\t\tif (degree > maxDegree) maxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "std::vector<int> degree;\n    for (size_t i = 0; i < N; i++) {\n        degree.push_back(0);\n        for (size_t j = 0; j < N; j++) {\n            degree[i] += A[N * i + j];\n        }\n    }\n\n    int max = 0;\n    for (int d : degree) {\n        max = std::max(max, d);\n    }\n    return max;\n}",
            "std::vector<int> degree(N, 0);\n\n    for(auto i = 0; i < N; i++)\n    {\n        for(auto j = 0; j < N; j++)\n        {\n            if(A[i * N + j]!= 0)\n            {\n                degree[i]++;\n            }\n        }\n    }\n\n    int maxDegree = 0;\n    for(auto i = 0; i < N; i++)\n    {\n        if(degree[i] > maxDegree)\n        {\n            maxDegree = degree[i];\n        }\n    }\n\n    return maxDegree;\n}",
            "int max_degree = -1;\n    int degree = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++degree;\n            }\n        }\n        max_degree = std::max(max_degree, degree);\n        degree = 0;\n    }\n\n    return max_degree;\n}",
            "std::vector<int> maxDegreeVec(N, 0);\n  for (size_t i = 0; i < A.size(); i++) {\n    int maxDegree = 0;\n    for (size_t j = 0; j < A.size(); j++) {\n      if (A[i*N + j] > 0) {\n        maxDegree += 1;\n      }\n    }\n    maxDegreeVec[i] = maxDegree;\n  }\n  return *std::max_element(maxDegreeVec.begin(), maxDegreeVec.end());\n}",
            "// TODO: implement this\n    return 0;\n}",
            "int maxDegree{ 0 };\n  for (size_t i{ 0 }; i < N; ++i) {\n    int degree{ 0 };\n    for (size_t j{ 0 }; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tint degree = 0;\n\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tdegree += A[j*N + i];\n\t\t}\n\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\n\treturn maxDegree;\n}",
            "int max = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tmax = (degree > max)? degree : max;\n\t}\n\n\treturn max;\n}",
            "int maxDegree = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      sum += A[i*N + j];\n    }\n    if (sum > max) {\n      max = sum;\n    }\n  }\n  return max;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "hip",
        "prompt": "/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. Store the result in maxDegree.\n   Use AMD HIP to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\n__global__ void maxDegree(const int *A, size_t N, int *maxDegree) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= N) {\n    return;\n  }\n  int localMaxDegree = 0;\n  for (int i = 0; i < N; ++i) {\n    if (A[idx + i * N]!= 0) {\n      localMaxDegree++;\n    }\n  }\n  atomicMax(maxDegree, localMaxDegree);\n}",
            "// TODO: Implement this kernel.\n  // Each thread computes one element of maxDegree.\n}",
            "// TODO\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index >= N) return;\n  int degree = 0;\n  for (int i = 0; i < N; ++i) {\n    degree += A[index * N + i];\n  }\n  atomicMax(maxDegree, degree);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    // shared memory to store degree of the current node\n    __shared__ int degree[THREADS_PER_BLOCK];\n    if (i < N) {\n        degree[threadIdx.x] = 0;\n        for (int j = 0; j < N; ++j) {\n            degree[threadIdx.x] += A[i * N + j];\n        }\n        // update the max degree\n        atomicMax(maxDegree, degree[threadIdx.x]);\n    }\n}",
            "int max = 0;\n\n\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row < N) {\n\t\tint sum = 0;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tsum += A[i + N * row];\n\t\t}\n\n\t\tatomicMax(&max, sum);\n\t}\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tmaxDegree[blockIdx.x] = max;\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint sum = 0;\n\t// A(i, j)!= 0 iff the edge (i, j) is present\n\tif (i < N && j < N && A[i * N + j]!= 0) {\n\t\tsum++;\n\t}\n\t*maxDegree = (sum > *maxDegree)? sum : *maxDegree;\n}",
            "int tx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tx < N) {\n    int max_deg = 0;\n    for (int i = 0; i < N; i++) {\n      max_deg += A[tx*N + i];\n    }\n    *maxDegree = max_deg;\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myMax = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tmyMax += A[N*i + id];\n\t}\n\t// TODO: Add atomics to compute maximum\n\tatomicMax(maxDegree, myMax);\n}",
            "int id = threadIdx.x;\n\tint degree = 0;\n\n\tif (id < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N*id + i] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(maxDegree, degree);\n}",
            "__shared__ int lmax[256];\n  int tid = threadIdx.x;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int max = 0;\n  if (i < N) {\n    int localMax = 0;\n    for (int j = 0; j < N; ++j) {\n      localMax += A[i * N + j];\n    }\n    lmax[tid] = localMax;\n    __syncthreads();\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n      if (tid < s) {\n        lmax[tid] = max(lmax[tid], lmax[tid + s]);\n      }\n      __syncthreads();\n    }\n    if (tid == 0) {\n      atomicMax(maxDegree, lmax[0]);\n    }\n  }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (idx < N) {\n\t\t// Get the sum of the columns for the current node\n\t\tint colSum = A[idx*N + idx];\n\t\tfor (int i = idx + 1; i < N; i++) {\n\t\t\tcolSum += A[idx*N + i];\n\t\t}\n\n\t\t// Compare the result to the current max and store if it is higher\n\t\tif (colSum > *maxDegree) {\n\t\t\t*maxDegree = colSum;\n\t\t}\n\t}\n}",
            "// get the index of the current thread\n\tsize_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// if the index is within the bounds of the array...\n\tif (i < N) {\n\n\t\t// for each row of A...\n\t\tfor (int j = 0; j < N; j++) {\n\n\t\t\t// if a value is found in the row...\n\t\t\tif (A[i * N + j]!= 0) {\n\n\t\t\t\t// store the value in the maxDegree array at the index\n\t\t\t\tatomicMax(maxDegree, A[i * N + j]);\n\n\t\t\t\t// exit this loop early\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}",
            "// Initialize the maxDegree to 0.\n  if (blockDim.x == 1) {\n    *maxDegree = 0;\n  }\n\n  // __syncthreads() causes the entire thread block to wait until the all prior \n  // global memory instructions in the thread block have been completed.\n  __syncthreads();\n\n  // Compute the max degree of each row and update the global memory location\n  // maxDegree.\n  //\n  // You can use the atomicMax function to update maxDegree.\n  //\n  // Note:\n  // If blockDim.x == 1, you don't need to compute anything.\n  if (blockDim.x > 1) {\n    // Atomically update maxDegree.\n    atomicMax(maxDegree, __popc(A[blockIdx.x * blockDim.x + threadIdx.x]));\n  }\n}",
            "unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  int degree = 0;\n  if (tid < N) {\n    for (int j = 0; j < N; j++) {\n      degree += A[j * N + tid];\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i >= N) return;\n\tint degree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i*N + j] > 0) degree++;\n\t}\n\tif (i == 0)\n\t\t*maxDegree = degree;\n\telse if (degree > *maxDegree)\n\t\t*maxDegree = degree;\n}",
            "// Implement the max degree computation\n\tint max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t\tmax = max > count? max : count;\n\t}\n\t*maxDegree = max;\n}",
            "__shared__ int sh_maxDegree[BLOCKSIZE];\n\t\n\tunsigned int i = blockDim.x*blockIdx.x + threadIdx.x;\n\t\n\tif (i < N) {\n\t\tsh_maxDegree[threadIdx.x] = 0;\n\t\t\n\t\t// count degree in row\n\t\tfor (unsigned int j = 0; j < N; j++) {\n\t\t\tsh_maxDegree[threadIdx.x] += A[i*N + j];\n\t\t}\n\t}\n\t\n\t// use atomicAdd to avoid bank conflict\n\tif (i < N) {\n\t\tatomicAdd(maxDegree, sh_maxDegree[threadIdx.x]);\n\t}\n}",
            "// compute the index of this thread\n    size_t i = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\n    // compute the number of elements in the adjacency matrix A\n    size_t NN = N * N;\n\n    // shared memory for this thread block to do a reduction\n    extern __shared__ int shm[];\n    int *shm_i = shm;\n    int *shm_o = shm + hipBlockDim_x;\n\n    // initialize shared memory to zero\n    shm_i[hipThreadIdx_x] = 0;\n    hipBarrier(0);\n\n    // check if this thread is still active\n    if (i < NN) {\n        // compute the degree of this node\n        if (A[i]) {\n            shm_i[hipThreadIdx_x] = 1;\n        }\n\n        // do a reduction to compute the maximum degree\n        int k = 0;\n        for (k = hipBlockDim_x / 2; k > 0; k /= 2) {\n            hipBarrier(0);\n            if (hipThreadIdx_x < k) {\n                shm_o[hipThreadIdx_x] = max(shm_i[hipThreadIdx_x], shm_i[hipThreadIdx_x + k]);\n            }\n        }\n        if (hipThreadIdx_x == 0) {\n            *maxDegree = shm_i[0];\n        }\n    }\n}",
            "int max = 0;\n  int tid = threadIdx.x;\n  if (tid < N) {\n    int sum = 0;\n    for (int i = 0; i < N; ++i) {\n      sum += A[i * N + tid];\n    }\n    max = max > sum? max : sum;\n  }\n  __syncthreads();\n  atomicMax(maxDegree, max);\n}",
            "// TODO: Fill in the body of this function\n}",
            "__shared__ int sData[256];\n\tint myMax = 0;\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint cacheIndex = threadIdx.x;\n\tint stepSize = blockDim.x;\n\tint temp = 0;\n\n\tfor (int i = tid; i < N; i += blockDim.x * gridDim.x) {\n\t\tmyMax = 0;\n\t\ttemp = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\ttemp = A[i * N + j];\n\t\t\tmyMax += temp;\n\t\t}\n\t\tsData[cacheIndex] = myMax;\n\t\t__syncthreads();\n\n\t\twhile (stepSize >= 1) {\n\t\t\tif (cacheIndex < stepSize) {\n\t\t\t\tsData[cacheIndex] += sData[cacheIndex + stepSize];\n\t\t\t}\n\t\t\tstepSize = stepSize / 2;\n\t\t\t__syncthreads();\n\t\t}\n\n\t\tif (cacheIndex == 0) {\n\t\t\tatomicAdd(maxDegree, sData[0]);\n\t\t}\n\t}\n}",
            "// use the first warp to find the maximum degree of a vertex\n\tint i = hipThreadIdx_x + hipBlockIdx_x * hipBlockDim_x;\n\tif (i < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i + j * N]!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\t// use atomics to get the maximum\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int max = 0;\n  for (int i = threadIdx.x; i < N * N; i += blockDim.x) {\n    if (A[i]!= 0)\n      max = max + 1;\n  }\n  atomicMax(maxDegree, max);\n}",
            "int i = blockDim.x*blockIdx.x + threadIdx.x;\n\n\tif (i < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[N*j + i] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "const int tid = threadIdx.x;\n  const int bid = blockIdx.x;\n  __shared__ int myMax[1024];\n  if (tid == 0) {\n    myMax[bid] = 0;\n  }\n  __syncthreads();\n  if (tid < N) {\n    int myRow = A[bid * N + tid];\n    myMax[bid] = max(myMax[bid], myRow);\n  }\n  __syncthreads();\n  if (tid == 0) {\n    int myMaxRow = myMax[bid];\n    for (int i = 1; i < blockDim.x; i++) {\n      myMaxRow = max(myMaxRow, myMax[i]);\n    }\n    atomicMax(maxDegree, myMaxRow);\n  }\n}",
            "int sum = 0;\n    for(int i = 0; i < N; i++) {\n        sum += A[i];\n    }\n    maxDegree[0] = max(maxDegree[0], sum);\n}",
            "int idx = threadIdx.x;\n\t__shared__ int s_maxDegree;\n\tif (idx == 0)\n\t\ts_maxDegree = 0;\n\t__syncthreads();\n\tint degree = 0;\n\tfor (size_t j = 0; j < N; ++j) {\n\t\tif (A[idx * N + j]!= 0) {\n\t\t\t++degree;\n\t\t}\n\t}\n\tatomicMax(&s_maxDegree, degree);\n\t__syncthreads();\n\tif (idx == 0)\n\t\t*maxDegree = s_maxDegree;\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (tid < N) {\n    // Compute the number of neighbors for the node with index tid\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A[tid * N + j];\n    }\n    if (sum > *maxDegree) {\n      *maxDegree = sum;\n    }\n  }\n}",
            "int max = 0;\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for (int i = tid; i < N; i += blockDim.x * gridDim.x) {\n    int s = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[N*i + j] > 0) {\n        s++;\n      }\n    }\n    if (s > max) max = s;\n  }\n  atomicMax(maxDegree, max);\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\n  if (i >= N) return;\n\n  int threadMax = 0;\n\n  for (int j = 0; j < N; ++j)\n    threadMax = A[N*i + j] > threadMax? A[N*i + j] : threadMax;\n\n  atomicMax(maxDegree, threadMax);\n}",
            "// get the thread ID\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(tid < N) {\n\t\tint max = 0;\n\t\t// compute the max degree\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[tid * N + i] > 0) {\n\t\t\t\tmax += 1;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, max);\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx < N) {\n    int degree = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[idx * N + i] > 0) {\n        degree++;\n      }\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "const size_t index = threadIdx.x;\n\tif (index >= N)\n\t\treturn;\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i * N + index] == 1) {\n\t\t\tdegree++;\n\t\t}\n\t}\n\tif (index == 0)\n\t\t*maxDegree = degree;\n}",
            "int i,j;\n\tint degree = 0;\n\n\tfor (i = blockIdx.x; i < N; i += gridDim.x) {\n\t\tfor (j = 0; j < N; j++)\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tdegree++;\n\t\tif (degree > *maxDegree) {\n\t\t\t*maxDegree = degree;\n\t\t}\n\t\tdegree = 0;\n\t}\n}",
            "int myMax = 0;\n\tfor (int i = 0; i < N; ++i)\n\t\tmyMax = (A[i * N + i] > myMax)? A[i * N + i] : myMax;\n\tatomicMax(maxDegree, myMax);\n}",
            "int *row = A + blockDim.x * blockIdx.x;\n    int *maxRow = maxDegree + blockIdx.x;\n\n    int sum = 0;\n    for (size_t i = 0; i < N; i++)\n        sum += row[i];\n\n    atomicAdd(maxRow, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint degree = 0;\n\n\tif (i >= N) return;\n\telse {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) degree++;\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int max = 0;\n    for (int i = 0; i < N; i++) {\n        int count = 0;\n        for (int j = 0; j < N; j++) {\n            count += A[i * N + j];\n        }\n        if (count > max) {\n            max = count;\n        }\n    }\n    // Write the result into global memory\n    if (threadIdx.x == 0) {\n        *maxDegree = max;\n    }\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint max = 0;\n\tint j = 0;\n\twhile (j < N) {\n\t\tif (A[i * N + j]) max++;\n\t\tj++;\n\t}\n\t*maxDegree = max;\n}",
            "int result = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      result = result + A[i*N+j];\n    }\n  }\n  *maxDegree = result;\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x; // Global thread id\n    if (i >= N) return;\n\n    __shared__ int localMax; // Shared memory to hold the local max.\n    if (threadIdx.x == 0) {\n        localMax = 0; // Initialize local max to 0\n    }\n    __syncthreads(); // Wait for all threads to read the shared memory.\n\n    int degree = 0; // Degree of the node\n    for (int j = 0; j < N; j++) {\n        if (A[i * N + j]!= 0) { // A[i,j] is a neighbor\n            degree++; // Increment the degree by 1\n        }\n    }\n    atomicMax(&localMax, degree); // Compute the max degree among all threads.\n    __syncthreads(); // Wait for all threads to read the shared memory.\n    if (threadIdx.x == 0) {\n        maxDegree[0] = localMax; // Write the local max to the global memory.\n    }\n}",
            "int i, j;\n  int *localMaxDegree = &maxDegree[blockIdx.x];\n\n  int id = threadIdx.x;\n  __shared__ int sdata[MAX_THREADS_PER_BLOCK];\n  sdata[threadIdx.x] = 0;\n\n  __syncthreads();\n\n  for (i = id; i < N; i += blockDim.x)\n    for (j = 0; j < N; j++)\n      if (A[i * N + j]!= 0)\n        sdata[threadIdx.x]++;\n\n  __syncthreads();\n\n  if (blockDim.x >= 1024) {\n    if (threadIdx.x < 512) {\n      sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + 512]);\n    }\n    __syncthreads();\n  }\n\n  if (blockDim.x >= 512) {\n    if (threadIdx.x < 256) {\n      sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + 256]);\n    }\n    __syncthreads();\n  }\n\n  if (blockDim.x >= 256) {\n    if (threadIdx.x < 128) {\n      sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + 128]);\n    }\n    __syncthreads();\n  }\n\n  if (blockDim.x >= 128) {\n    if (threadIdx.x < 64) {\n      sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + 64]);\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x < 32) {\n    warpReduce(sdata, threadIdx.x);\n  }\n\n  if (threadIdx.x == 0) {\n    atomicMax(localMaxDegree, sdata[0]);\n  }\n}",
            "// TODO\n    int maxDeg = 0;\n    int thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n    int i,j;\n    for(i=0;i<N;i++){\n        for(j=0;j<N;j++){\n            if(A[i*N+j]==1){\n                maxDeg += 1;\n            }\n        }\n    }\n    if (thread_id == 0) {\n        *maxDegree = maxDeg;\n    }\n}",
            "// Get the node id\n  const int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // The number of threads per block must be at least N\n  if(id >= N)\n    return;\n\n  // Initialize the maxDegree to 0\n  int myMaxDegree = 0;\n\n  // Loop over all nodes\n  for(int i = 0; i < N; i++) {\n    // Ignore the diagonal\n    if(i == id)\n      continue;\n\n    // Get the node degree\n    myMaxDegree += (int) A[id * N + i];\n  }\n\n  // Use atomicMax to find the maximum degree\n  atomicMax(maxDegree, myMaxDegree);\n}",
            "// TODO: add code\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index < N) {\n        int sum = 0;\n        for (int i = 0; i < N; ++i) {\n            sum += A[index + i * N];\n        }\n        atomicMax(maxDegree, sum);\n    }\n}",
            "int myMaxDegree = 0;\n\tint threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (threadID < N) {\n\t\tint rowDegree = 0;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\trowDegree += A[threadID * N + i];\n\t\t}\n\n\t\tmyMaxDegree = (rowDegree > myMaxDegree)? rowDegree : myMaxDegree;\n\t}\n\n\tatomicMax(maxDegree, myMaxDegree);\n}",
            "int node = threadIdx.x;\n\tint maxValue = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tmaxValue = A[node*N + i] > maxValue? A[node*N + i] : maxValue;\n\t}\n\tmaxDegree[node] = maxValue;\n}",
            "// The highest degree node\n    int node = blockDim.x * blockIdx.x + threadIdx.x;\n    if (node >= N)\n        return;\n\n    int nodeDegree = 0;\n    for (int i = 0; i < N; ++i) {\n        if (A[i * N + node] > 0)\n            nodeDegree++;\n    }\n\n    atomicMax(maxDegree, nodeDegree);\n}",
            "extern __shared__ int buf[];\n\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) buf[threadIdx.x] = A[i * N + i];\n\n  // Threads must sync to ensure that the buffer has been loaded\n  __syncthreads();\n\n  // Find the max degree in the buffer\n  for (int i = 1; i < blockDim.x; i *= 2) {\n    if (threadIdx.x >= i)\n      buf[threadIdx.x] = max(buf[threadIdx.x], buf[threadIdx.x - i]);\n    // Threads must sync to ensure that the buffer has been computed\n    __syncthreads();\n  }\n  // Write out the final max degree\n  if (threadIdx.x == 0) *maxDegree = buf[0];\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        int localMaxDegree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i + j * N]!= 0) {\n                localMaxDegree++;\n            }\n        }\n        atomicMax(maxDegree, localMaxDegree);\n    }\n}",
            "__shared__ int m;\n\t// set the initial value to zero\n\tif (threadIdx.x == 0) m = 0;\n\t__syncthreads();\n\n\t// compute the maximum degree\n\tfor (int i = threadIdx.x; i < N; i += blockDim.x) {\n\t\tint d = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\td += A[N * i + j];\n\t\tatomicMax(&m, d);\n\t}\n\n\t// find the maximum value in the shared memory\n\t__syncthreads();\n\tif (threadIdx.x == 0) {\n\t\tfor (int i = 1; i < blockDim.x; i++)\n\t\t\tm = max(m, __ldg(&m + i));\n\t\t*maxDegree = m;\n\t}\n}",
            "size_t threadId = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ int maxDegreeShared;\n\n  if (threadId < N) {\n    int maxDegreeThread = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[threadId * N + i] == 1)\n        maxDegreeThread++;\n    }\n    if (threadId == 0) {\n      maxDegreeShared = maxDegreeThread;\n    }\n    __syncthreads();\n\n    if (threadId == 0) {\n      atomicMax(maxDegree, maxDegreeShared);\n    }\n  }\n}",
            "const int id = blockDim.x * blockIdx.x + threadIdx.x;\n\tif(id >= N) return;\n\n\t// Fill me in\n}",
            "// TODO\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n    int maxVal = 0;\n    if(idx < N) {\n        for(int j = 0; j < N; j++) {\n            maxVal = max(maxVal, A[idx * N + j]);\n        }\n        atomicMax(maxDegree, maxVal);\n    }\n}",
            "// TODO: Implement this\n    __shared__ int sMaxDegree;\n    sMaxDegree = 0;\n    int localMax = 0;\n    int i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i >= N)\n        return;\n    for (int j = 0; j < N; j++)\n        if (A[i * N + j] == 1)\n            localMax++;\n\n    atomicMax(&sMaxDegree, localMax);\n\n    __syncthreads();\n\n    atomicMax(maxDegree, sMaxDegree);\n}",
            "size_t threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint maxD = 0;\n\n\t// TODO implement your kernel here\n\n\t// Save the result in global memory\n\tif (threadId == 0)\n\t\t*maxDegree = maxD;\n}",
            "int max = 0;\n  int j = threadIdx.x;\n  while (j < N) {\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n      sum += A[i*N + j];\n    }\n    if (sum > max) {\n      max = sum;\n    }\n    j += blockDim.x;\n  }\n  __shared__ int maxDegree_shared[1];\n  if (threadIdx.x == 0) {\n    maxDegree_shared[0] = max;\n  }\n  __syncthreads();\n  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      if (maxDegree_shared[threadIdx.x] < maxDegree_shared[threadIdx.x + s]) {\n        maxDegree_shared[threadIdx.x] = maxDegree_shared[threadIdx.x + s];\n      }\n    }\n    __syncthreads();\n  }\n  if (threadIdx.x == 0) {\n    *maxDegree = maxDegree_shared[0];\n  }\n}",
            "int max = 0;\n    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < N;\n         i += blockDim.x * gridDim.x) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                max++;\n            }\n        }\n        if (i == 0) {\n            *maxDegree = max;\n        }\n    }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int degree = 0;\n\n  if (idx < N) {\n    for (int i = 0; i < N; i++) {\n      degree += A[idx * N + i];\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (idx < N) {\n        int degree = 0;\n        for (int i = 0; i < N; ++i) {\n            if (A[idx * N + i]) {\n                degree++;\n            }\n        }\n\n        atomicMax(maxDegree, degree);\n    }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif(i >= N) return;\n\n\tint degree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[N*i + j]!= 0)\n\t\t\tdegree++;\n\t}\n\t\n\tif (atomicCAS(maxDegree, *maxDegree, max(degree, *maxDegree)) == *maxDegree) return;\n}",
            "int id = threadIdx.x;\n    int degree = 0;\n    if (id < N) {\n        int row = A[id];\n        while (row) {\n            row = __ffs(row) - 1;\n            degree++;\n        }\n    }\n    atomicMax(maxDegree, degree);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    int maxDegreeLocal = 0;\n\n    for (int i = index; i < N; i += stride) {\n        int count = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[N * i + j]!= 0)\n                count++;\n        }\n        if (count > maxDegreeLocal)\n            maxDegreeLocal = count;\n    }\n\n    atomicMax(maxDegree, maxDegreeLocal);\n}",
            "// 1. Get the global thread index\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// 2. Get the maximum degree of the graph\n\tif (tid < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + tid] > 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\t*maxDegree = max(*maxDegree, degree);\n\t}\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n\tint i;\n\tint degree = 0;\n\n\tif (row < N) {\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (A[N*row + i] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > *maxDegree)\n\t\t\t*maxDegree = degree;\n\t}\n}",
            "// TODO\n}",
            "const int row = blockIdx.x*blockDim.x + threadIdx.x;\n  if (row >= N) return;\n\n  int deg = 0;\n  for (int i = 0; i < N; ++i) {\n    deg += A[row*N+i];\n  }\n\n  atomicMax(maxDegree, deg);\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (idx >= N) return;\n\n  int deg = 0;\n  for (int i = 0; i < N; i++) {\n    deg += A[idx + i * N];\n  }\n  atomicMax(maxDegree, deg);\n}",
            "int n = blockDim.x*blockIdx.x + threadIdx.x; // global thread index\n\tint max = 0;\n\tif (n < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N*n + i] > max) {\n\t\t\t\tmax = A[N*n + i];\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, max);\n\t}\n}",
            "unsigned int t = blockDim.x * blockIdx.x + threadIdx.x;\n    int degree = 0;\n    if(t < N) {\n        for(int i = 0; i < N; i++) {\n            if(A[i*N + t]!= 0) {\n                degree++;\n            }\n        }\n    }\n    atomicMax(maxDegree, degree);\n}",
            "int maxD = 0;\n\tint id = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (id < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tcount += A[id*N + i];\n\t\t}\n\t\tif (maxD < count) {\n\t\t\tmaxD = count;\n\t\t}\n\t}\n\n\t// Reduction\n\tint tid = threadIdx.x;\n\t__shared__ int sdata[1024];\n\tsdata[tid] = maxD;\n\t__syncthreads();\n\n\tunsigned int i = blockDim.x / 2;\n\twhile (i!= 0) {\n\t\tif (tid < i) {\n\t\t\tsdata[tid] = max(sdata[tid], sdata[tid + i]);\n\t\t}\n\t\t__syncthreads();\n\t\ti /= 2;\n\t}\n\n\tif (tid == 0) {\n\t\tmaxD = sdata[0];\n\t}\n\n\tif (tid == 0) {\n\t\t*maxDegree = maxD;\n\t}\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > *maxDegree) {\n\t\t\t*maxDegree = sum;\n\t\t}\n\t}\n}",
            "const int threadNum = blockDim.x * blockIdx.x + threadIdx.x;\n  __shared__ int localMax[BLOCK_SIZE];\n  __shared__ int localRowNum[BLOCK_SIZE];\n\n  localMax[threadIdx.x] = 0;\n  localRowNum[threadIdx.x] = threadIdx.x;\n  __syncthreads();\n\n  if (threadNum < N) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      sum += A[threadNum * N + j];\n    }\n    localMax[threadIdx.x] = sum;\n  }\n\n  // Compute the maximum\n  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      if (localMax[threadIdx.x] < localMax[threadIdx.x + s]) {\n        localMax[threadIdx.x] = localMax[threadIdx.x + s];\n        localRowNum[threadIdx.x] = localRowNum[threadIdx.x + s];\n      }\n    }\n    __syncthreads();\n  }\n\n  // Store the result in maxDegree\n  if (threadIdx.x == 0) {\n    atomicMin(maxDegree, localMax[0]);\n    atomicMin(&rowNum, localRowNum[0]);\n  }\n}",
            "int maxD = 0;\n    for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {\n        int deg = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] > 0) {\n                deg++;\n            }\n        }\n        maxD = (deg > maxD)? deg : maxD;\n    }\n    atomicMax(maxDegree, maxD);\n}",
            "/* Modify this */\n  int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id < N) {\n    for (int i = 0; i < N; i++) {\n      if (A[id * N + i] == 1) {\n        atomicMax(maxDegree, i);\n      }\n    }\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint localMax = 0;\n\n\tif (id < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tlocalMax = max(localMax, A[id * N + i]);\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, localMax);\n}",
            "int tid = threadIdx.x;\n    int i, j;\n    __shared__ int max;\n\n    if (tid == 0)\n        max = 0;\n    __syncthreads();\n\n    for (i = tid; i < N; i += blockDim.x)\n        for (j = 0; j < N; j++)\n            if (A[i + j * N] == 1)\n                atomicMax(&max, A[i + j * N]);\n    __syncthreads();\n    if (tid == 0)\n        *maxDegree = max;\n}",
            "size_t gid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (gid >= N) return;\n\n    int max = 0;\n    for (int i = 0; i < N; i++) {\n        if (A[gid * N + i] > 0) {\n            max++;\n        }\n    }\n    atomicMax(maxDegree, max);\n}",
            "__shared__ int sharedMaxDegree[WARPSIZE];\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col;\n    int myMaxDegree = 0;\n    int maxSharedDegree = 0;\n    if (row < N) {\n        for (col = 0; col < N; col++) {\n            myMaxDegree += A[row*N + col];\n        }\n\n        int rowIndex = threadIdx.x % WARPSIZE;\n        int laneId = threadIdx.x % WARPSIZE;\n        myMaxDegree = warpReduceMax(myMaxDegree, laneId, sharedMaxDegree);\n        if (rowIndex == 0) {\n            sharedMaxDegree[laneId] = myMaxDegree;\n        }\n        __syncthreads();\n        if (laneId == 0) {\n            myMaxDegree = sharedMaxDegree[0];\n        }\n\n        myMaxDegree = blockReduceMax<int>(myMaxDegree);\n        if (threadIdx.x == 0) {\n            atomicMax(maxDegree, myMaxDegree);\n        }\n    }\n}",
            "// Load the adjacency matrix into shared memory\n  __shared__ int s_A[BLOCKSIZE][BLOCKSIZE];\n  int x = threadIdx.x;\n  int y = threadIdx.y;\n  int index = threadIdx.x + blockIdx.x * BLOCKSIZE;\n  if (index < N) {\n    s_A[y][x] = A[index + (y * N)];\n  }\n  __syncthreads();\n\n  // Compute the max degree of all nodes in the current block\n  int localMaxDegree = 0;\n  for (int i = 0; i < BLOCKSIZE; i++) {\n    localMaxDegree = max(localMaxDegree, s_A[i][x] + s_A[y][i]);\n  }\n  __syncthreads();\n\n  // Find the max degree in the current block\n  int blockMaxDegree = maxDegree[blockIdx.x];\n  __syncthreads();\n\n  // Update the global max degree\n  atomicMax(&blockMaxDegree, localMaxDegree);\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    maxDegree[blockIdx.x] = blockMaxDegree;\n  }\n}",
            "//__shared__ int s_maxDegree;\n\textern __shared__ int s_maxDegree[];\n\n\tint localMaxDegree = 0;\n\tint maxGlobalDegree = 0;\n\t\n\tfor (int n = 0; n < N; n++){\n\t\tfor (int m = 0; m < N; m++){\n\t\t\tif (A[n * N + m] > 0){\n\t\t\t\tlocalMaxDegree++;\n\t\t\t}\n\t\t}\n\n\t\tif (localMaxDegree > maxGlobalDegree){\n\t\t\tmaxGlobalDegree = localMaxDegree;\n\t\t}\n\t\tlocalMaxDegree = 0;\n\t}\n\n\t//threadIdx.x = 0, s_maxDegree = 3\n\t//threadIdx.x = 1, s_maxDegree = 3\n\t//threadIdx.x = 2, s_maxDegree = 3\n\t//threadIdx.x = 3, s_maxDegree = 3\n\t//s_maxDegree[threadIdx.x] = maxGlobalDegree;\n\ts_maxDegree[threadIdx.x] = maxGlobalDegree;\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tint maxDegree = 0;\n\t\tfor (int i = 0; i < blockDim.x; i++) {\n\t\t\tif (s_maxDegree[i] > maxDegree) {\n\t\t\t\tmaxDegree = s_maxDegree[i];\n\t\t\t}\n\t\t}\n\n\t\t*maxDegree = maxDegree;\n\t}\n}",
            "int idx = blockDim.x*blockIdx.x + threadIdx.x;\n\n\tint max = 0;\n\tif (idx < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tmax = max < A[idx*N + j]? A[idx*N + j] : max;\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "int index = threadIdx.x + blockIdx.x * blockDim.x;\n  int degree = 0;\n  // TODO: compute the degree for one vertex (index)\n\n  atomicMax(maxDegree, degree);\n}",
            "int tid = hipThreadIdx_x;\n    int max = 0;\n    for (size_t i = tid; i < N; i += hipBlockDim_x) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[j * N + i] == 1) {\n                degree++;\n            }\n        }\n        if (degree > max) {\n            max = degree;\n        }\n    }\n    *maxDegree = max;\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int degree;\n\n  if (tid < N) {\n    degree = 0;\n    for (int i = 0; i < N; i++) {\n      degree += A[tid * N + i];\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i >= N) return;\n\t// your code here\n}",
            "int myIdx = blockDim.x * blockIdx.x + threadIdx.x;\n  int rowStart = N * myIdx;\n  int rowEnd = N * (myIdx + 1);\n  int max = 0;\n  for (int i = rowStart; i < rowEnd; i++) {\n    if (A[i] == 1) {\n      max++;\n    }\n  }\n  atomicMax(maxDegree, max);\n}",
            "const int MAX_THREADS = 128;\n\tconst int MAX_BLOCKS = 128;\n\tconst int TOTAL_THREADS = MAX_BLOCKS * MAX_THREADS;\n\n\t// Compute a maximum degree in the subgraph that this thread is responsible for.\n\t// Each thread processes 1 row of the adjacency matrix.\n\tint max = 0;\n\tfor (int i = blockIdx.x * blockDim.x + threadIdx.x;\n\t\t\ti < N && i < (blockIdx.x + 1) * blockDim.x;\n\t\t\ti += TOTAL_THREADS) {\n\t\tint rowSum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\trowSum += A[N * i + j];\n\t\t}\n\t\tif (rowSum > max) {\n\t\t\tmax = rowSum;\n\t\t}\n\t}\n\n\t// Compute a maximum degree in the whole graph across all threads.\n\t// This requires a serial reduction.\n\tint blockMax = 0;\n\tif (max > blockMax) {\n\t\tblockMax = max;\n\t}\n\tblockMax = blockReduceMax<int, MAX_BLOCKS>(blockMax, threadIdx.x);\n\tif (threadIdx.x == 0) {\n\t\tatomicMax(maxDegree, blockMax);\n\t}\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[i * N + tid]!= 0) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int max;\n  if (row < N) {\n    max = 0;\n    for (int col = 0; col < N; col++) {\n      if (A[row * N + col]!= 0) {\n        max += 1;\n      }\n    }\n    atomicMax(maxDegree, max);\n  }\n}",
            "__shared__ int maxDegree_shared[N];\n  __shared__ int maxDegree_temp;\n\n  int max = 0;\n  int index = blockDim.x * blockIdx.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n\n  while (index < N) {\n    int degree = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[N * index + i]!= 0) {\n        degree++;\n      }\n    }\n    maxDegree_shared[threadIdx.x] = degree;\n\n    // Reduce\n    for (int offset = stride / 2; offset > 0; offset /= 2) {\n      __syncthreads();\n      if (threadIdx.x < offset) {\n        maxDegree_shared[threadIdx.x] =\n            max(maxDegree_shared[threadIdx.x], maxDegree_shared[threadIdx.x + offset]);\n      }\n    }\n\n    if (threadIdx.x == 0) {\n      maxDegree_temp = maxDegree_shared[0];\n    }\n\n    __syncthreads();\n\n    // Compute the max degree\n    if (max < maxDegree_temp) {\n      max = maxDegree_temp;\n    }\n\n    index += stride;\n  }\n\n  // Write the result for this block to global mem\n  if (threadIdx.x == 0) {\n    *maxDegree = max;\n  }\n}",
            "// Declare shared memory\n\t__shared__ int shm[BLOCKSIZE];\n\n\t// Get thread ID\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// Set local maxDegree to zero\n\tint localMaxDegree = 0;\n\n\t// Compute maxDegree\n\t// If tid is valid for matrix, compute value and update local maxDegree\n\tif (tid < N) {\n\t\tint tmp = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\ttmp += A[tid * N + i];\n\t\t}\n\t\tlocalMaxDegree = tmp;\n\t}\n\n\t// Copy localMaxDegree to shared memory\n\tshm[threadIdx.x] = localMaxDegree;\n\n\t// Sync threads\n\t__syncthreads();\n\n\t// Compute the maximum maxDegree in the shared memory\n\tint tmp = 0;\n\tif (threadIdx.x < blockDim.x / 2) {\n\t\tif (shm[threadIdx.x + blockDim.x / 2] > shm[threadIdx.x])\n\t\t\ttmp = shm[threadIdx.x + blockDim.x / 2];\n\t\telse\n\t\t\ttmp = shm[threadIdx.x];\n\t}\n\telse if (threadIdx.x == blockDim.x / 2) {\n\t\ttmp = shm[threadIdx.x];\n\t}\n\n\t// Copy tmp to shared memory\n\tshm[threadIdx.x] = tmp;\n\n\t// Sync threads\n\t__syncthreads();\n\n\t// Compute the maximum maxDegree in the shared memory\n\tif (threadIdx.x == 0) {\n\t\t*maxDegree = shm[0];\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (tid < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[tid * N + j] == 1) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tid = idx;\n\tint m = 0;\n\twhile (tid < N) {\n\t\tint tmp = A[tid];\n\t\tint k = tmp;\n\t\tfor (int j = 1; j < N; j++) {\n\t\t\tif (tmp == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttmp = tmp >> 1;\n\t\t\tif ((tmp & 0x1) == 1) {\n\t\t\t\tk++;\n\t\t\t}\n\t\t}\n\t\tif (k > m) {\n\t\t\tm = k;\n\t\t}\n\t\ttid = tid + blockDim.x * gridDim.x;\n\t}\n\tatomicMax(maxDegree, m);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tid = threadIdx.x;\n\tint stride = blockDim.x;\n\t__shared__ int sdata[256];\n\n\t// initialize shared memory\n\tsdata[tid] = 0;\n\t__syncthreads();\n\n\t// read in data and find max degree\n\tfor(int i=id; i<N; i+=stride) {\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif(A[i * N + j]!= 0) {\n\t\t\t\tsdata[tid]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// compute max degree\n\t__syncthreads();\n\tif(tid<blockDim.x/2) {\n\t\tsdata[tid] += sdata[tid + blockDim.x/2];\n\t}\n\t__syncthreads();\n\n\tif(tid==0) {\n\t\tfor(int i=blockDim.x/2; i>0; i>>=1) {\n\t\t\tif(tid < i) {\n\t\t\t\tsdata[tid] += sdata[tid + i];\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif(tid==0) {\n\t\t*maxDegree = sdata[0];\n\t}\n}",
            "// Obtain thread ID and row ID\n\tconst int tid = threadIdx.x;\n\tconst int rid = blockIdx.x;\n\n\t// Initialize degree to 0\n\tint degree = 0;\n\n\t// Loop through all elements of the row (parallel reduction)\n\tfor (int c = tid; c < N; c += blockDim.x) {\n\n\t\t// If A[rid, c] is 1, increase degree by 1\n\t\tif (A[rid * N + c] == 1) {\n\t\t\tatomicAdd(&degree, 1);\n\t\t}\n\t}\n\n\t// Find the maximum degree (parallel reduction)\n\t// https://stackoverflow.com/questions/1715150/simplest-way-to-parallelize-reduction-of-an-array-of-floats\n\t// https://stackoverflow.com/questions/30739741/reduction-in-cuda\n\t__shared__ int sdata[BLOCK_SIZE];\n\tsdata[tid] = degree;\n\t__syncthreads();\n\tif (BLOCK_SIZE >= 512) { if (tid < 256) { sdata[tid] = sdata[tid] + sdata[tid + 256]; } __syncthreads(); }\n\tif (BLOCK_SIZE >= 256) { if (tid < 128) { sdata[tid] = sdata[tid] + sdata[tid + 128]; } __syncthreads(); }\n\tif (BLOCK_SIZE >= 128) { if (tid <  64) { sdata[tid] = sdata[tid] + sdata[tid +  64]; } __syncthreads(); }\n\tif (tid < 32) {\n\t\twarpReduce(sdata, tid);\n\t}\n\tif (tid == 0) {\n\t\tatomicMax(maxDegree, sdata[0]);\n\t}\n}",
            "__shared__ int localMax;\n  // Initialize localMax to 0\n  localMax = 0;\n  // Compute the max degree of the row (i, i + N) in the A matrix\n  for (size_t j = threadIdx.x; j < N; j += blockDim.x) {\n    localMax = localMax < A[i + N]? A[i + N] : localMax;\n  }\n  // Make sure that localMax is updated across all threads\n  __syncthreads();\n  // If localMax is the max degree, update the maxDegree variable\n  if (localMax == *maxDegree) {\n    *maxDegree = localMax;\n  }\n}",
            "int m = threadIdx.x;\n\tint max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[m*N + i] > 0) {\n\t\t\tmax++;\n\t\t}\n\t}\n\tatomicMax(maxDegree, max);\n}",
            "/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n     A is an NxN adjacency matrix stored in row-major. Store the result in maxDegree.\n     Use AMD HIP to compute in parallel. The kernel is launched with at least N threads.\n     Example:\n\n\t\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n     output: 3\n  */\n\n  // TODO\n\n  // Hint:\n  // - use atomicMax to update the global maxDegree\n  // - use __ldg to load a value from global memory into the register\n  // - use atomicAdd to increment a global counter\n\n  *maxDegree = 0;\n  // int maxDegree = 0;\n  int sum = 0;\n\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int col = blockIdx.y * blockDim.y + threadIdx.y;\n  int max = 0;\n\n  if (row < N && col < N) {\n    max = __ldg(&A[row * N + col]);\n    // printf(\"(%d, %d) = %d\\n\", row, col, max);\n    // atomicAdd(&sum, max);\n    atomicMax(maxDegree, max);\n    // atomicMax(&maxDegree, max);\n  }\n\n  // printf(\"blockDim = {%d, %d}\\n\", blockDim.x, blockDim.y);\n  // printf(\"gridDim = {%d, %d}\\n\", gridDim.x, gridDim.y);\n  // printf(\"(%d, %d) = %d\\n\", row, col, sum);\n  // printf(\"maxDegree = %d\\n\", maxDegree);\n}",
            "__shared__ int shMax;\n\t__shared__ int shValue;\n\n\t// Initialize shared memory\n\tif (threadIdx.x == 0) {\n\t\tshMax = 0;\n\t\tshValue = 0;\n\t}\n\n\t__syncthreads();\n\n\t// Fill in shared memory with the degree for each node\n\tint i = threadIdx.x;\n\tint degree = 0;\n\tif (i < N) {\n\t\tint idx = i * N;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[idx + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t}\n\n\t// Find the maximum in shared memory\n\tatomicMax(&shMax, degree);\n\n\t__syncthreads();\n\n\t// Find the maximum in global memory\n\tatomicMax(maxDegree, shMax);\n}",
            "int nodeId = threadIdx.x + blockIdx.x * blockDim.x;\n   extern __shared__ int sdata[];\n   int thId = threadIdx.x;\n\n   if(nodeId < N) {\n      //initialize shared memory\n      if(thId == 0) {\n         sdata[thId] = 0;\n      }\n      __syncthreads();\n\n      //each thread computes its max degree\n      for(int i = 0; i < N; i++) {\n         if(A[nodeId*N + i] == 1) {\n            atomicAdd(&sdata[thId], 1);\n         }\n      }\n\n      //reduce shared memory to get the final max degree\n      __syncthreads();\n      if(thId == 0) {\n         for(int i = 1; i < blockDim.x; i++) {\n            if(sdata[i] > sdata[0]) {\n               sdata[0] = sdata[i];\n            }\n         }\n         atomicMax(maxDegree, sdata[0]);\n      }\n   }\n}",
            "extern __shared__ int s[];\n  int tid = threadIdx.x;\n  int blid = blockIdx.x;\n  int d = 0;\n  int max = 0;\n  if (tid < N) {\n    for (int i = 0; i < N; i++) {\n      if (A[N * i + tid] == 1) {\n        d++;\n      }\n    }\n    s[tid] = d;\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    for (int i = 0; i < N; i++) {\n      if (s[i] > max) {\n        max = s[i];\n      }\n    }\n    *maxDegree = max;\n  }\n}",
            "//TODO: Compute the highest node degree in the graph.\n}",
            "__shared__ int maxDegreeShared;\n\n  // Get the starting index for this thread.\n  int start = get_global_id(0) * N;\n\n  int localMax = 0;\n\n  for (int i = 0; i < N; i++) {\n    localMax += A[start + i];\n  }\n\n  // If this thread found a higher degree than the thread with the max so far, then update.\n  if (localMax > maxDegreeShared)\n    maxDegreeShared = localMax;\n\n  // Wait for all threads to finish.\n  __syncthreads();\n\n  // All threads will go through the if statement.\n  if (localMax == maxDegreeShared) {\n    maxDegree[0] = localMax;\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * tid + i]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row < N) {\n\t\tint degree = 0;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[row*N+i] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "// Each thread computes one element in the adjacency matrix\n\tint i = blockIdx.x*blockDim.x + threadIdx.x;\n\t// Each thread must compute at least one element\n\tif (i<N) {\n\t\t// Initialize the maxDegree to 0. It will be incremented in the loop\n\t\tint myMax = 0;\n\t\t// Iterate over all the columns in the row of the adjacency matrix\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tmyMax += A[i*N + j];\n\t\t}\n\t\t// We need to ensure that all threads have finished the loop before we can compare the maxDegrees\n\t\t__syncthreads();\n\t\t// Keep the maxDegree of the current thread. Use atomicMax to compare with the maxDegree in the memory location\n\t\tatomicMax(maxDegree, myMax);\n\t}\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N)\n\t\treturn;\n\n\tint sum = 0;\n\n\tfor (size_t j = 0; j < N; j++) {\n\t\tsum += A[i * N + j];\n\t}\n\n\tatomicMax(maxDegree, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    int localMax = 0;\n    for (int j = 0; j < N; ++j) {\n      localMax += A[i * N + j];\n    }\n    atomicMax(maxDegree, localMax);\n  }\n}",
            "// TODO: implement the kernel\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < N) {\n    int localMax = 0;\n    for (size_t i = 0; i < N; ++i) {\n      if (A[tid * N + i] == 1) {\n        localMax++;\n      }\n    }\n\n    // TODO: implement using atomicMax\n    //atomicMax(maxDegree, localMax);\n\n    // critical section\n    __shared__ int smax;\n    smax = 0;\n    __syncthreads();\n    if (localMax > smax) {\n      smax = localMax;\n    }\n    __syncthreads();\n\n    if (localMax == smax) {\n      atomicMax(maxDegree, localMax);\n    }\n  }\n}",
            "// TODO\n}",
            "int max = 0;\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (row < N) {\n    for (size_t col = 0; col < N; col++) {\n      if (A[row * N + col]!= 0) {\n        max++;\n      }\n    }\n    // Atomic operation to ensure there's no race condition\n    atomicMax(maxDegree, max);\n  }\n}",
            "int m = blockIdx.x;\n\tint n = threadIdx.x;\n\tint max = 0;\n\tfor (int i = n; i < N; i += blockDim.x) {\n\t\tint val = A[m*N + i];\n\t\tif (val > max) {\n\t\t\tmax = val;\n\t\t}\n\t}\n\tatomicMax(maxDegree, max);\n}",
            "int maxDeg = 0;\n\t\n\tint n = (int)sqrt(N);\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\t// if the vertex doesn't exist, do nothing\n\tif (i >= n || j >= n) {\n\t\treturn;\n\t}\n\t\n\tfor (int k = 0; k < n; ++k) {\n\t\tif (A[i * n + k] == 1 || A[k * n + j] == 1) {\n\t\t\tmaxDeg++;\n\t\t}\n\t}\n\t\n\tif (maxDeg > maxDegree[0]) {\n\t\tmaxDegree[0] = maxDeg;\n\t}\n\t\n}",
            "extern __shared__ int shm[];\n\n    // shm[threadIdx.x] = A[threadIdx.x]; // not a good idea to read from global memory in shared memory.\n    shm[threadIdx.x] = A[threadIdx.x * N + threadIdx.x]; // better to read from global memory in global memory.\n    __syncthreads();\n\n    if (threadIdx.x > 0)\n        shm[threadIdx.x] += shm[threadIdx.x - 1];\n    __syncthreads();\n\n    if (threadIdx.x == 0)\n        atomicMax(maxDegree, shm[blockDim.x - 1]);\n}",
            "// Insert your code here\n}",
            "int maxDeg = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (i!= j && A[i*N+j]!= 0) {\n\t\t\tmaxDeg++;\n\t\t}\n\t}\n\tmaxDegree[0] = max(maxDeg, maxDegree[0]);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int maxDegree = 0;\n    if (idx < N) {\n        for (int j = 0; j < N; j++) {\n            if (A[idx * N + j] > 0) {\n                maxDegree++;\n            }\n        }\n        atomicMax(maxDegree, maxDegree);\n    }\n}",
            "int blockIndex = blockIdx.x;\n    int blockSize  = blockDim.x;\n    int threadIndex = threadIdx.x;\n\n    // Compute a thread's portion of the array.\n    int start = N * blockIndex;\n    int end = start + N;\n\n    // Each thread manages one entry in the adjacency matrix.\n    // Initialize the maximum degree to zero.\n    int maxDegreeLocal = 0;\n    for (int i = start + threadIndex; i < end; i += blockSize) {\n\n        // Sum the number of rows with a non-zero entry.\n        for (int j = 0; j < N; j++) {\n            maxDegreeLocal += A[i + j * N];\n        }\n    }\n\n    // Perform a parallel reduction to compute the maximum degree.\n    // The maximum degree is the maximum of all partial sums.\n    int *maxDegreeShared = (int*) shared;\n    maxDegreeShared[threadIndex] = maxDegreeLocal;\n\n    // Wait for all threads to finish\n    __syncthreads();\n\n    // Reduce the partial sums to compute the maximum degree\n    for (int s = blockSize / 2; s > 0; s >>= 1) {\n        if (threadIndex < s) {\n            maxDegreeShared[threadIndex] += maxDegreeShared[threadIndex + s];\n        }\n        __syncthreads();\n    }\n\n    // Write the results to the output array.\n    if (threadIndex == 0) {\n        *maxDegree = maxDegreeShared[0];\n    }\n}",
            "int myMax = 0;\n    for (int i = 0; i < N; i++) {\n        int rowSum = 0;\n        for (int j = 0; j < N; j++) {\n            rowSum += A[i*N + j];\n        }\n        if (rowSum > myMax) {\n            myMax = rowSum;\n        }\n    }\n    atomicMax(maxDegree, myMax);\n}",
            "// TODO\n\n}",
            "size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx < N) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[N*idx + j];\n\t\t}\n\t\tatomicMax(maxDegree, sum);\n\t}\n}",
            "int myId = threadIdx.x;\n\n    __shared__ int maxDeg;\n    __shared__ int myMaxDeg;\n    if (myId == 0) {\n        maxDeg = 0;\n        myMaxDeg = 0;\n    }\n    __syncthreads();\n\n    int myDeg = 0;\n    for (int i = 0; i < N; i++) {\n        myDeg += A[N * myId + i];\n    }\n\n    atomicMax(&myMaxDeg, myDeg);\n    __syncthreads();\n\n    atomicMax(&maxDeg, myMaxDeg);\n    __syncthreads();\n\n    if (myId == 0)\n        *maxDegree = maxDeg;\n}",
            "int maxVal = -1;\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = gridDim.x * blockDim.x;\n\tint n = (N + stride - 1) / stride; // the size of each thread block\n\tfor (int i = id; i < n; i += stride) {\n\t\tint row = A[i * N + i];\n\t\tif (row > maxVal)\n\t\t\tmaxVal = row;\n\t}\n\tatomicMax(maxDegree, maxVal);\n}",
            "int i = threadIdx.x;\n\n  if (i < N) {\n    int sum = 0;\n    for (int j = 0; j < N; j++)\n      sum += A[i * N + j];\n    atomicMax(maxDegree, sum);\n  }\n}",
            "int i = threadIdx.x;\n\n\tif (i >= N) {\n\t\treturn;\n\t}\n\n\tint maxDeg = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tmaxDeg = (A[i + N * j] == 1)? maxDeg + 1 : maxDeg;\n\t}\n\tatomicMax(maxDegree, maxDeg);\n}",
            "// TODO\n}",
            "int *A_shared = (int*)shared_memory;\n    int *degree_shared = A_shared + N;\n    int maxDegreeLocal = 0;\n    size_t tid = threadIdx.x;\n\n    for(size_t i = tid; i < N; i += blockDim.x){\n        A_shared[i] = A[i*N+i];\n    }\n\n    __syncthreads();\n\n    for(size_t i = 0; i < N; i++){\n        degree_shared[i] = 0;\n        for(size_t j = 0; j < N; j++){\n            degree_shared[i] += A_shared[j*N+i];\n        }\n        maxDegreeLocal = (maxDegreeLocal > degree_shared[i])? maxDegreeLocal : degree_shared[i];\n    }\n\n    atomicMax(maxDegree, maxDegreeLocal);\n}",
            "// TODO: Implement me\n\n\t__shared__ int maxDegree_shared[32];\n\tint maxDegree_global = 0;\n\tint localMaxDegree = 0;\n\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row < N) {\n\t\tfor (int col = 0; col < N; col++) {\n\t\t\tif (A[row + col * N] == 1) {\n\t\t\t\tlocalMaxDegree++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree_shared[threadIdx.x] = localMaxDegree;\n\t}\n\t__syncthreads();\n\n\tif (row < N) {\n\t\tint localIdx = threadIdx.x;\n\t\tfor (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n\t\t\tif (localIdx < offset) {\n\t\t\t\tmaxDegree_shared[localIdx] = max(maxDegree_shared[localIdx], maxDegree_shared[localIdx + offset]);\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t\tif (localIdx == 0) {\n\t\t\tatomicMax(maxDegree, maxDegree_shared[0]);\n\t\t}\n\t}\n}",
            "// TODO\n\t__shared__ int temp[blockDim.x];\n\tint sum = 0;\n\n\tif (blockDim.x > N)\n\t{\n\t\tsum = A[blockIdx.x * blockDim.x + threadIdx.x];\n\t\tfor (int i = 1; i < blockDim.x; i++)\n\t\t{\n\t\t\tsum = sum + A[(blockIdx.x * blockDim.x + threadIdx.x) + i * blockDim.x];\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor (int i = 0; i < blockDim.x; i++)\n\t\t{\n\t\t\tsum = sum + A[(blockIdx.x * blockDim.x + threadIdx.x) + i * blockDim.x];\n\t\t}\n\t}\n\n\ttemp[threadIdx.x] = sum;\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0)\n\t{\n\t\tfor (int i = 1; i < blockDim.x; i++)\n\t\t{\n\t\t\ttemp[0] = temp[0] + temp[i];\n\t\t}\n\n\t\t*maxDegree = temp[0];\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = 0;\n    int deg = 0;\n\n    // Check if we are in the range of the matrix\n    if (i < N) {\n        for (j = 0; j < N; j++) {\n            deg = A[i * N + j];\n            atomicMax(maxDegree, deg);\n        }\n    }\n}",
            "extern __shared__ int sdata[];\n  unsigned int tid = threadIdx.x;\n  unsigned int i = blockIdx.x * (blockDim.x * 2) + threadIdx.x;\n  unsigned int gridSize = blockDim.x * 2 * gridDim.x;\n  int sum = 0;\n\n  while (i < N) {\n    sdata[tid] = A[i] + A[i + blockDim.x];\n    __syncthreads();\n\n    if (tid < blockDim.x) {\n      sum += sdata[tid];\n      sdata[tid] = 0;\n    }\n\n    i += gridSize;\n  }\n\n  __syncthreads();\n  if (blockDim.x >= 512) {\n    if (tid < 256) {\n      sdata[tid] += sdata[tid + 256];\n    }\n    __syncthreads();\n  }\n  if (blockDim.x >= 256) {\n    if (tid < 128) {\n      sdata[tid] += sdata[tid + 128];\n    }\n    __syncthreads();\n  }\n  if (blockDim.x >= 128) {\n    if (tid < 64) {\n      sdata[tid] += sdata[tid + 64];\n    }\n    __syncthreads();\n  }\n\n  if (tid < 32) {\n    warpReduce(sdata, tid);\n  }\n\n  if (tid == 0) {\n    *maxDegree = sdata[0];\n  }\n}",
            "// 1. Use a warp to process multiple elements per thread\n  // 2. Use a shared memory to cache data\n  // 3. Use a block-wide reduction to get the final result\n  // 4. Don't forget to use atomic operations to update maxDegree\n  // 5. Don't forget to use blockIdx.x, blockIdx.y, and blockIdx.z\n}",
            "// TODO: Implement this function\n\tint max = 0;\n\tint thread = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (thread < N) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tsum += A[i * N + thread];\n\t\t}\n\t\tatomicMax(&max, sum);\n\t}\n\n\t// Reduce\n\tfor (int stride = N / 2; stride > 0; stride >>= 1) {\n\t\t__syncthreads();\n\t\tif (thread < stride) {\n\t\t\tint temp = maxDegree[thread + stride];\n\t\t\tatomicMax(&maxDegree[thread], temp);\n\t\t}\n\t}\n}",
            "__shared__ int sharedMax[1];\n\tint localMax = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i < N && j < N)\n\t\tlocalMax = A[i*N + j];\n\n\t// Use atomicMin to have thread 0 find the max.\n\tif (threadIdx.x == 0 && threadIdx.y == 0)\n\t\tatomicMin(sharedMax, localMax);\n\n\t__syncthreads();\n\n\t// Use atomicMin to have thread 0 find the max.\n\tif (threadIdx.x == 0 && threadIdx.y == 0)\n\t\tatomicMin(maxDegree, sharedMax[0]);\n}",
            "// TODO\n}",
            "// **********************************************************************************************************\n\t// \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tYOUR CODE HERE\n\t// **********************************************************************************************************\n\t//\n\t// 1. Use shared memory to store A in a row-major order, and use the parallel reduction algorithm to compute\n\t//\t\tthe maximum degree.\n\t//\t2. The reduction algorithm can be found here: http://developer.download.nvidia.com/assets/cuda/files/reduction.pdf\n\t//\t3. Use a thread block size of at least N.\n\t//\t4. Atomic operations are not required.\n\t//\n\t// **********************************************************************************************************\n\n\t__shared__ int s_A[256];\n\tconst int tid = threadIdx.x;\n\tconst int bid = blockIdx.x;\n\tconst int nthreads = blockDim.x;\n\n\tint row_start = bid * nthreads;\n\tint row_end = (bid + 1) * nthreads;\n\tif (row_end > N)\n\t\trow_end = N;\n\tint degree = 0;\n\tfor (int i = row_start + tid; i < row_end; i += nthreads)\n\t{\n\t\tint row_degree = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t{\n\t\t\t\trow_degree++;\n\t\t\t}\n\t\t}\n\t\ts_A[tid] = row_degree;\n\t\t__syncthreads();\n\t\tfor (unsigned int s = 1; s < nthreads; s *= 2)\n\t\t{\n\t\t\tint index = 2 * s * tid;\n\t\t\tif (index < nthreads)\n\t\t\t\ts_A[index] += s_A[index + s];\n\t\t\t__syncthreads();\n\t\t}\n\t\tif (tid == 0)\n\t\t\tatomicMax(maxDegree, s_A[0]);\n\t}\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (row < N) {\n    int rowDegree = 0;\n    for (int i = 0; i < N; i++)\n      rowDegree += A[row*N + i];\n    atomicMax(maxDegree, rowDegree);\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint max = 0;\n\n\tif (tid < N) {\n\t\tint i = 0;\n\t\twhile (i < N && A[tid * N + i] == 0) {\n\t\t\ti++;\n\t\t}\n\t\tmax = i;\n\t\twhile (i < N) {\n\t\t\tif (A[tid * N + i]!= 0) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\t}\n\tif (tid == 0) {\n\t\tatomicMax(maxDegree, max);\n\t}\n}",
            "int index = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (index >= N) { return; }\n\n\tint temp = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\ttemp += A[index * N + i];\n\t}\n\tatomicMax(maxDegree, temp);\n}",
            "// TODO: Compute the maximum degree of the graph in parallel\n\tint degree = 0;\n\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[row * N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t}\n\n\tif (threadIdx.x == 0)\n\t\t*maxDegree = degree;\n}",
            "// TODO: Fill this in\n  __shared__ int maxDegree_local[BLOCK_SIZE];\n  __shared__ int maxDegree_tmp[BLOCK_SIZE];\n  int tid = threadIdx.x;\n  int maxDegree_global = 0;\n\n  if(tid == 0){\n    maxDegree_local[0] = 0;\n  }\n  __syncthreads();\n\n  if(tid < N){\n    int n = 0;\n    for(int i = 0; i < N; i++){\n      n += A[tid * N + i];\n    }\n    maxDegree_local[tid] = n;\n    __syncthreads();\n  }\n\n  int halfBlockDim = blockDim.x / 2;\n\n  while (halfBlockDim!= 0) {\n    if(tid < halfBlockDim){\n      maxDegree_tmp[tid] = maxDegree_local[tid + halfBlockDim] > maxDegree_local[tid]? maxDegree_local[tid + halfBlockDim] : maxDegree_local[tid];\n    }\n    __syncthreads();\n    if(tid < halfBlockDim){\n      maxDegree_local[tid] = maxDegree_tmp[tid];\n    }\n    __syncthreads();\n\n    halfBlockDim /= 2;\n  }\n\n  if(tid == 0){\n    atomicMax(&maxDegree_global, maxDegree_local[0]);\n  }\n  __syncthreads();\n\n  *maxDegree = maxDegree_global;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int max = 0;\n    // Each thread computes the number of neighbors for a vertex\n    for (int j = 0; j < N; ++j) {\n        if (A[i * N + j]) {\n            max = max + 1;\n        }\n    }\n    atomicMax(maxDegree, max);\n}",
            "size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i < N) {\n        int max = 0;\n        for (size_t j = 0; j < N; j++) {\n            max += A[i * N + j];\n        }\n        maxDegree[i] = max;\n    }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\n\tif(tid >= N)\n\t\treturn;\n\n\tint sum = 0;\n\n\tfor (int i = 0; i < N; i++)\n\t\tsum += A[tid*N+i];\n\n\tif (sum > *maxDegree)\n\t\t*maxDegree = sum;\n}",
            "// 1D block index\n  unsigned int blockId = blockIdx.x;\n  // 1D thread index\n  unsigned int threadId = blockId * blockDim.x + threadIdx.x;\n  // Threads cooperate in a block to compute the highest degree in the block\n  extern __shared__ int maxDegreeShared[];\n  int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    max = max < A[N*i + threadId]? A[N*i + threadId] : max;\n  }\n  maxDegreeShared[threadIdx.x] = max;\n  __syncthreads();\n  // Find the max degree in the block\n  // We know there are 128 threads per block (blockDim.x), so 128 threads.\n  for (int stride = 1; stride < blockDim.x; stride *= 2) {\n    if (threadIdx.x % (2*stride) == 0)\n      maxDegreeShared[threadIdx.x] = maxDegreeShared[threadIdx.x] > maxDegreeShared[threadIdx.x+stride]?\n                                      maxDegreeShared[threadIdx.x] : maxDegreeShared[threadIdx.x+stride];\n    __syncthreads();\n  }\n  // If it's the first thread in the block, write the result to the device memory\n  if (threadIdx.x == 0) {\n    atomicMax(maxDegree, maxDegreeShared[0]);\n  }\n}",
            "// Shared memory to hold max degree across threads in this work group.\n  __shared__ int sharedMax;\n\n  // Initialize sharedMax in thread 0 with 0.\n  if (threadIdx.x == 0) {\n    sharedMax = 0;\n  }\n\n  // Make sure all threads in this work group have synchronized before\n  // reading the values of A[i] in sharedMax.\n  __syncthreads();\n\n  // Loop over all rows of A.\n  for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < N;\n       i += blockDim.x * gridDim.x) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i + N * j];\n    }\n    // Reduce over all rows in this work group to get the maximum degree.\n    atomicMax(&sharedMax, degree);\n  }\n  __syncthreads();\n\n  // Write the maximum degree to global memory from sharedMax.\n  if (threadIdx.x == 0) {\n    *maxDegree = sharedMax;\n  }\n}",
            "int idx = threadIdx.x;\n  int max = 0;\n  if (idx < N) {\n    int start = idx * N;\n    int end = start + N;\n    for (int i = start; i < end; i++) {\n      if (A[i] > max) {\n        max = A[i];\n      }\n    }\n  }\n  atomicMax(maxDegree, max);\n}",
            "// Store the sum in the first element of the array\n\textern __shared__ int shared[];\n\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myMax = 0;\n\n\tif (i < N) {\n\t\tmyMax = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tmyMax += A[i*N+j];\n\t\t}\n\n\t\tshared[threadIdx.x] = myMax;\n\t\t__syncthreads();\n\n\t\tif (threadIdx.x < 32)\n\t\t{\n\t\t\tmyMax = max(myMax, shared[threadIdx.x]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 32]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 16]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 8]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 4]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 2]);\n\t\t\tmyMax = max(myMax, shared[threadIdx.x + 1]);\n\t\t}\n\n\t\tshared[threadIdx.x] = myMax;\n\t\t__syncthreads();\n\n\t\tif (threadIdx.x == 0) {\n\t\t\t*maxDegree = myMax;\n\t\t}\n\t}\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (idx >= N) return;\n\tint max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[idx * N + i] == 1) {\n\t\t\tmax++;\n\t\t}\n\t}\n\tif (max > *maxDegree) {\n\t\t*maxDegree = max;\n\t}\n}",
            "unsigned int index = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (index < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * index + i]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int i = blockDim.x*blockIdx.x + threadIdx.x;\n\tif (i >= N)\n\t\treturn;\n\n\tint degree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i*N+j] == 1)\n\t\t\tdegree++;\n\t}\n\n\tif (degree > *maxDegree) {\n\t\t*maxDegree = degree;\n\t}\n}",
            "__shared__ int sdata[BLOCK_SIZE];\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int myMax = 0;\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      myMax += A[i * N + j];\n    }\n    sdata[threadIdx.x] = myMax;\n  }\n  __syncthreads();\n\n  for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n    if (threadIdx.x < stride) {\n      sdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + stride]);\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    *maxDegree = sdata[0];\n  }\n}",
            "/* Note: A and N must be defined as constants in the kernel code using\n     the __constant__ keyword, i.e.:\n\n     __constant__ int A[N*N];\n     __constant__ int N;\n  */\n\n  // TODO: Compute the maximum degree using atomics\n  //\n  // Note: The atomic functions used in this exercise are found in the\n  // `hip/include/hip/hip_runtime.h` header file.\n  //\n  // Example usage for atomicMax(maxDegree, 42):\n  //\n  //   atomicMax(maxDegree, 42);\n  //\n  // Note that atomicMax will only write the value 42 if it is larger than\n  // the current value at `maxDegree`. See documentation for more details.\n\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n  int max_degree = 0;\n  for(int i=0; i<N; i++)\n    max_degree = max(max_degree, A[row*N + i]);\n  atomicMax(maxDegree, max_degree);\n}",
            "int thread_id = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\n  // Find the highest degree in the adjacency matrix\n  if (thread_id < N) {\n    int max = 0;\n    for (size_t i = 0; i < N; i++) {\n      if (A[thread_id * N + i]!= 0 && i!= thread_id)\n        max++;\n    }\n    atomicMax(maxDegree, max);\n  }\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) return;\n  int degree = 0;\n  for (int j = 0; j < N; ++j) {\n    degree += A[i * N + j];\n  }\n  atomicMax(maxDegree, degree);\n}",
            "__shared__ int localMaxDegree;\n\tint i = threadIdx.x;\n\tint j = blockIdx.x;\n\tint count = 0;\n\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i * N + j]) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\tlocalMaxDegree = count;\n\t}\n\n\t__syncthreads();\n\n\tatomicMax(maxDegree, localMaxDegree);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint max_degree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[tid*N + i] > max_degree)\n\t\t\tmax_degree = A[tid*N + i];\n\t}\n\n\tif (max_degree > *maxDegree)\n\t\t*maxDegree = max_degree;\n}",
            "// TODO: implement the algorithm to compute the max degree.\n\t// Use atomicCAS to update maxDegree.\n\n\t__shared__ int maxDegree_shared[256];\n\tint tid = threadIdx.x + blockIdx.x*blockDim.x;\n\tint lane = tid & 0x1f;\n\tmaxDegree_shared[tid] = 0;\n\tint lmax = 0;\n\n\tfor(int i = tid ; i < N ; i += blockDim.x*gridDim.x){\n\t\tfor(int j = 0 ; j < N ; j++){\n\t\t\tif(A[N*i + j]!= 0){\n\t\t\t\tmaxDegree_shared[tid] ++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicMax(&maxDegree[0], maxDegree_shared[tid]);\n\n}",
            "extern __shared__ int sdata[];\n\n\tunsigned int t = threadIdx.x;\n\tunsigned int blk = blockIdx.x;\n\n\tsdata[t] = 0;\n\t__syncthreads();\n\n\tfor (unsigned int i = blk * blockDim.x + t; i < N; i += blockDim.x * gridDim.x) {\n\t\tint sum = 0;\n\t\tfor (unsigned int j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tatomicAdd(sdata, sum);\n\t}\n\t__syncthreads();\n\n\tfor (unsigned int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n\t\tif (t < stride) {\n\t\t\tsdata[t] += sdata[t + stride];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (t == 0) {\n\t\t*maxDegree = sdata[0];\n\t}\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n  int temp = 0;\n\n  if(row == col) {\n    int degree = 0;\n\n    // get the number of non-zero values for this row\n    for(int i = 0; i < N; i++) {\n      if(A[row*N + i]!= 0)\n        degree++;\n    }\n\n    atomicMax(maxDegree, degree);\n  }\n}",
            "// Get the linear index of the thread that has launched the kernel\n\tint idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (idx >= N) {\n\t\treturn;\n\t}\n\n\t// Get the linear index of the thread that has launched the kernel\n\tint idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (idx >= N) {\n\t\treturn;\n\t}\n\n\tint thread_maxDegree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tthread_maxDegree += A[idx * N + i];\n\t}\n\n\tatomicMax(maxDegree, thread_maxDegree);\n\n}",
            "// Compute the global index of the thread\n\tint globalId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint ld = gridDim.x * blockDim.x;\n\n\t// Start with the first node\n\tint cur = globalId;\n\n\t// Process every node in the graph\n\twhile (cur < N) {\n\n\t\t// Find the degree of the current node\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[cur * N + i] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\n\t\t// Update the maximum degree\n\t\tatomicMax(maxDegree, degree);\n\n\t\t// Go to the next node\n\t\tcur += ld;\n\t}\n}",
            "const int row = blockDim.x*blockIdx.x + threadIdx.x;\n  const int col = blockDim.y*blockIdx.y + threadIdx.y;\n  if (row >= N || col >= N) return;\n  if (A[row*N + col]!= 0 && A[row*N + col] > maxDegree[0])\n    atomicCAS(maxDegree, maxDegree[0], A[row*N + col]);\n}",
            "const int i = blockDim.x*blockIdx.x + threadIdx.x;\n\n  if (i < N) {\n    int sum = 0;\n    for (int j = 0; j < N; ++j)\n      sum += A[i*N+j];\n    atomicMax(maxDegree, sum);\n  }\n}",
            "const int tid = blockDim.x*blockIdx.x + threadIdx.x;\n  if (tid < N) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[tid*N + j] > 0) {\n        degree++;\n      }\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (id < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + id]) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint maxA = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tint a = A[i + j * N];\n\t\t\tif (a > maxA)\n\t\t\t\tmaxA = a;\n\t\t}\n\t\tmaxDegree[i] = maxA;\n\t}\n}",
            "int sum = 0;\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N;\n       i += gridDim.x * blockDim.x) {\n    for (int j = 0; j < N; ++j) {\n      sum += A[N * i + j];\n    }\n  }\n  atomicMax(maxDegree, sum);\n}",
            "// The AMD HIP blockIdx.x is the \"threadIdx.x\" in CUDA\n\tint global_thread_index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Define a shared memory array to store the max degree\n\t__shared__ int max_degree_shared[MAX_BLOCK_SIZE];\n\n\tint my_max = 0;\n\n\tif (global_thread_index < N) {\n\t\t// The node's index in the adjacency matrix\n\t\tint i = global_thread_index;\n\t\t// Calculate the sum of the row i of the adjacency matrix\n\t\tint row_i_sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\trow_i_sum += A[j * N + i];\n\t\t}\n\t\tmy_max = row_i_sum;\n\t}\n\n\t// Atomic add to find the max degree\n\tatomicMax(max_degree_shared, my_max);\n\n\t// We need to wait until all the threads in the block have completed before we can read from\n\t// shared memory\n\t__syncthreads();\n\n\tif (global_thread_index == 0) {\n\t\t// Copy the max degree found by the block to the host\n\t\t*maxDegree = max_degree_shared[0];\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint max = 0;\n\t\n\tif (tid < N) {\n\t\tint current = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[tid * N + i] == 1) current++;\n\t\t}\n\t\tmax = (current > max)? current : max;\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "// Fill this in!\n\n}",
            "extern __shared__ int _sdata[];\n\n  int id = threadIdx.x;\n  int bid = blockIdx.x;\n  int num_threads = blockDim.x;\n  int tid = bid * num_threads + threadIdx.x;\n\n  _sdata[id] = 0;\n\n  if (tid < N) {\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n      sum += A[tid * N + i];\n    }\n    _sdata[id] = sum;\n  }\n  __syncthreads();\n\n  // Reduce\n  for (int i = num_threads / 2; i > 0; i >>= 1) {\n    if (id < i) {\n      _sdata[id] = max(_sdata[id], _sdata[id + i]);\n    }\n    __syncthreads();\n  }\n  if (id == 0) {\n    maxDegree[bid] = _sdata[0];\n  }\n}",
            "int tid = threadIdx.x;\n\n  __shared__ int sDegree[THREADS_PER_BLOCK];\n\n  // Initialize shared degree to 0\n  if (tid < THREADS_PER_BLOCK) {\n    sDegree[tid] = 0;\n  }\n  __syncthreads();\n\n  // Compute the max degree of the nodes assigned to each thread\n  if (tid < N) {\n    for (int i = tid; i < N; i += THREADS_PER_BLOCK) {\n      int degree = A[i * N + i];\n      atomicAdd(&sDegree[tid], degree);\n    }\n  }\n  __syncthreads();\n\n  // Find the max degree in shared memory\n  if (tid < THREADS_PER_BLOCK) {\n    for (int i = 1; i < THREADS_PER_BLOCK; i++) {\n      atomicMax(maxDegree, sDegree[i]);\n    }\n  }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint maxDeg = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[tid*N + i]) {\n\t\t\t\tmaxDeg++;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, maxDeg);\n\t}\n}",
            "int myMaxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint rowSum = A[i * N + i];\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\trowSum += A[i * N + j];\n\t\t}\n\t\tif (rowSum > myMaxDegree) {\n\t\t\tmyMaxDegree = rowSum;\n\t\t}\n\t}\n\n\t// Use atomic operation to ensure that only one thread is writing the maximum value.\n\tatomicMax(maxDegree, myMaxDegree);\n}",
            "int block = blockIdx.x;\n\tint thread = threadIdx.x;\n\tint stride = blockDim.x;\n\tint offset = stride * block;\n\tint localMax = 0;\n\n\t// Iterate over the sub-matrix assigned to this block to find the highest degree\n\tfor (int i = offset; i < (offset + stride) && i < N; ++i) {\n\t\tint localDegree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tlocalDegree += (int)A[i * N + j];\n\t\t}\n\t\tlocalMax = max(localDegree, localMax);\n\t}\n\n\t// Reduce the degree of the block into a single value\n\tlocalMax = blockReduce(localMax, threadIdx.x, stride);\n\n\t// Write the result for this block to global memory\n\tif (threadIdx.x == 0)\n\t\tatomicMax(maxDegree, localMax);\n}",
            "unsigned int i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i >= N) {\n        return;\n    }\n    int d = 0;\n    for (size_t j = 0; j < N; ++j) {\n        d += A[j + N*i];\n    }\n    atomicMax(maxDegree, d);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint cur = 0;\n\tif (index < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tcur += A[index * N + i];\n\t\t}\n\t\tatomicMax(maxDegree, cur);\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        int max = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i + j * N]!= 0)\n                max++;\n        }\n        atomicMax(maxDegree, max);\n    }\n}",
            "// Get my global thread ID\n  int id = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if (id < N) {\n    // Initialize local max to zero\n    int localMax = 0;\n\n    // Compute local max\n    for (int j = 0; j < N; j++) {\n      if (A[j * N + id] > 0)\n        localMax++;\n    }\n\n    // Perform parallel reduction\n    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n      __syncthreads();\n      if (threadIdx.x < stride) {\n        localMax = max(localMax, __shfl_up_sync(0xffffffff, localMax, stride));\n      }\n    }\n\n    // Store the local max\n    if (threadIdx.x == 0)\n      atomicMax(maxDegree, localMax);\n  }\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n    int max = 0;\n    int sum = 0;\n    if (id < N) {\n        for (int i = 0; i < N; i++) {\n            sum += A[id*N+i];\n        }\n        atomicMax(&max, sum);\n    }\n    __syncthreads();\n    if (threadIdx.x == 0) {\n        *maxDegree = max;\n    }\n}",
            "const int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (col >= row)\n\t\treturn;\n\n\tint counter = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row * N + i] > 0 && A[col * N + i] > 0)\n\t\t\tcounter++;\n\t}\n\n\t// Maximum degree of the current node is stored in global memory\n\tatomicMax(maxDegree, counter);\n}",
            "int tIdx = blockIdx.x*blockDim.x + threadIdx.x;\n  __shared__ int sDegree[1024];\n  if (tIdx < N) {\n    sDegree[threadIdx.x] = 0;\n    for (int i=tIdx; i < N; i += blockDim.x*gridDim.x) {\n      if (A[i*N + tIdx] == 1)\n        sDegree[threadIdx.x]++;\n    }\n  }\n  __syncthreads();\n  if (tIdx < N)\n    maxDegree[tIdx] = 0;\n  __syncthreads();\n  if (tIdx < N) {\n    for (int i=0; i < blockDim.x; i++) {\n      if (sDegree[i] > maxDegree[tIdx])\n        maxDegree[tIdx] = sDegree[i];\n    }\n  }\n  __syncthreads();\n  if (tIdx < N) {\n    for (int stride = blockDim.x/2; stride > 0; stride /= 2) {\n      if (threadIdx.x < stride) {\n        if (maxDegree[threadIdx.x] < maxDegree[threadIdx.x + stride])\n          maxDegree[threadIdx.x] = maxDegree[threadIdx.x + stride];\n      }\n      __syncthreads();\n    }\n  }\n  if (threadIdx.x == 0)\n    atomicMin(maxDegree, maxDegree[0]);\n}",
            "// Each thread computes one element of the diagonal of the adjacency matrix.\n  // Use atomicMax to avoid race conditions\n  // A is stored in row-major order: A[i * N + j] = A[i][j]\n  const int i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= N) return;\n  int sum = 0;\n  for (int j = 0; j < N; ++j) {\n    sum += A[i * N + j];\n  }\n  atomicMax(maxDegree, sum);\n}",
            "__shared__ int sData[BLOCK_SIZE];\n\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n    int i = bid * blockDim.x + tid;\n\n    int degree = 0;\n    if (i < N) {\n        for (int j = 0; j < N; j++) {\n            degree += A[i + j * N];\n        }\n        sData[tid] = degree;\n        __syncthreads();\n    }\n    // 1. Find the highest degree in the block.\n    if (N >= 64) {\n        if (tid < 32) { sData[tid] = max(sData[tid], sData[tid + 32]); }\n        __syncthreads();\n    }\n    if (N >= 32) {\n        if (tid < 16) { sData[tid] = max(sData[tid], sData[tid + 16]); }\n        __syncthreads();\n    }\n    if (N >= 16) {\n        if (tid < 8) { sData[tid] = max(sData[tid], sData[tid + 8]); }\n        __syncthreads();\n    }\n    if (N >= 8) {\n        if (tid < 4) { sData[tid] = max(sData[tid], sData[tid + 4]); }\n        __syncthreads();\n    }\n    if (N >= 4) {\n        if (tid < 2) { sData[tid] = max(sData[tid], sData[tid + 2]); }\n        __syncthreads();\n    }\n    if (N >= 2) {\n        if (tid < 1) { sData[tid] = max(sData[tid], sData[tid + 1]); }\n        __syncthreads();\n    }\n    // 2. Thread 0 finds the highest degree in the block.\n    if (tid == 0) {\n        atomicMax(maxDegree, sData[0]);\n    }\n}",
            "int tid = threadIdx.x;\n\tint row = tid / 32;\n\tint lane = tid % 32;\n\n\t__shared__ int shm[64];\n\n\tint sum = 0;\n\tif (tid < N) {\n\t\tsum = A[tid * N + tid];\n\t}\n\n\tint temp = shm[lane];\n\tshm[lane] = sum;\n\t__syncthreads();\n\n\tint newSum = shm[lane] + temp;\n\n\t__syncthreads();\n\n\tif (row == 0)\n\t\tsum = shm[lane];\n\telse\n\t\tsum = newSum;\n\n\tif (tid == 0) {\n\t\t*maxDegree = sum;\n\t}\n}",
            "const int globalId = blockDim.x * blockIdx.x + threadIdx.x;\n\tconst int stride = blockDim.x * gridDim.x;\n\tint localMax = 0;\n\tfor (int i = globalId; i < N; i += stride) {\n\t\tint nodeDegree = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[j * N + i]!= 0)\n\t\t\t\tnodeDegree++;\n\t\tlocalMax = (localMax < nodeDegree)? nodeDegree : localMax;\n\t}\n\n\textern __shared__ int sdata[];\n\tsdata[threadIdx.x] = localMax;\n\t__syncthreads();\n\n\tint i = blockDim.x / 2;\n\twhile (i!= 0) {\n\t\tif (threadIdx.x < i)\n\t\t\tsdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + i]);\n\t\t__syncthreads();\n\t\ti /= 2;\n\t}\n\n\tif (threadIdx.x == 0)\n\t\t*maxDegree = sdata[0];\n}",
            "int degree = 0;\n\tfor (size_t j = 0; j < N; ++j) {\n\t\tif (A[j*N + blockIdx.x] > 0) {\n\t\t\t++degree;\n\t\t}\n\t}\n\tatomicMax(maxDegree, degree);\n}",
            "int nodeId = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// Set initial value to zero\n\tif (threadIdx.x == 0)\n\t\tmaxDegree[blockIdx.x] = 0;\n\n\t__syncthreads();\n\n\tif (nodeId < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tif (A[nodeId * N + i]!= 0)\n\t\t\t\tdegree++;\n\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "const int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\t// TODO\n\t}\n}",
            "// TODO: implement this function\n  //int index = (blockDim.x*blockIdx.x) + threadIdx.x;\n  __shared__ int maxDegree_shared;\n  //printf(\"Thread %d starting\\n\", threadIdx.x);\n  int maxDegree_private = 0;\n  int i, j;\n  int index = (blockDim.x*blockIdx.x) + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n\n  for (i = index; i < N; i += stride) {\n    int degree = 0;\n    for (j = 0; j < N; j++) {\n      if (A[j * N + i]!= 0)\n        degree++;\n    }\n    if (maxDegree_private < degree)\n      maxDegree_private = degree;\n  }\n  //printf(\"Thread %d has degree %d\\n\", threadIdx.x, maxDegree_private);\n\n  // reduce to maximum\n  if (threadIdx.x == 0)\n    maxDegree_shared = 0;\n  __syncthreads();\n\n  atomicMax(&maxDegree_shared, maxDegree_private);\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicMax(maxDegree, maxDegree_shared);\n  }\n}",
            "size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= N)\n    return;\n\n  int curDegree = 0;\n  for (size_t j = 0; j < N; ++j) {\n    curDegree += A[i * N + j];\n  }\n  *maxDegree = max(*maxDegree, curDegree);\n}",
            "// each thread works on one row\n    int row = blockDim.x * blockIdx.x + threadIdx.x;\n    // if the thread is within bounds of the matrix\n    if (row < N) {\n        // sum the elements of the row\n        int rowSum = 0;\n        for (int i = 0; i < N; i++) {\n            rowSum += A[row * N + i];\n        }\n        // atomically assign the max degree to maxDegree\n        // if the max degree is greater than the row sum\n        if (rowSum > maxDegree[0]) {\n            atomicMax(maxDegree, rowSum);\n        }\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (tid < N) {\n    int deg = 0;\n    for (int i = 0; i < N; i++) {\n      deg += A[tid * N + i];\n    }\n    atomicMax(maxDegree, deg);\n  }\n}",
            "const int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    const int stride = gridDim.x * blockDim.x;\n    const int nodeDegree = A[tid*N + tid];\n\n    for (int j=tid+stride; j<N; j+=stride) {\n        atomicMax(maxDegree, A[tid*N+j]);\n        atomicMax(maxDegree, A[j*N+tid]);\n    }\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "mpi",
        "prompt": "#include <mpi.h>\n\n/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int my_degrees[N];\n\n    MPI_Allreduce(&A[0], &my_degrees[0], N, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n    for(int i = 0; i < N; i++)\n    {\n        if(my_degrees[i] == 0)\n        {\n            return i;\n        }\n    }\n}",
            "int max_degree = 0;\n  for(size_t i=0; i<N; ++i) {\n    for(size_t j=0; j<N; ++j) {\n      if(A[i*N+j]) {\n        max_degree = std::max(max_degree, A[i*N+j]);\n      }\n    }\n  }\n  return max_degree;\n}",
            "int N_ranks;\n    MPI_Comm_size(MPI_COMM_WORLD, &N_ranks);\n    if (N_ranks == 1) {\n        /* do not use MPI, just compute on one core */\n        int highest = 0;\n        for (size_t i = 0; i < N; i++) {\n            int n = 0;\n            for (size_t j = 0; j < N; j++) {\n                n += A[i*N+j];\n            }\n            highest = std::max(highest, n);\n        }\n        return highest;\n    }\n\n    /*\n    if (N_ranks == 2) {\n        /* use two ranks, each computes half of the graph */\n        int highest = 0;\n        if (N_ranks == 1) {\n            for (size_t i = 0; i < N; i++) {\n                int n = 0;\n                for (size_t j = 0; j < N; j++) {\n                    n += A[i*N+j];\n                }\n                highest = std::max(highest, n);\n            }\n            return highest;\n        }\n\n        if (N_ranks == 2) {\n            for (size_t i = 0; i < N; i++) {\n                int n = 0;\n                for (size_t j = 0; j < N; j++) {\n                    n += A[i*N+j];\n                }\n                highest = std::max(highest, n);\n            }\n            return highest;\n        }\n    }\n    */\n    /* use all cores available */\n    // your code goes here\n    return 0;\n}",
            "int num_neighbours = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tnum_neighbours++;\n\t\t}\n\t}\n\treturn num_neighbours;\n}",
            "}",
            "return 0;\n}",
            "int maxDeg = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tint deg = 0;\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(A[N*i + j]) {\n\t\t\t\tdeg += 1;\n\t\t\t}\n\t\t}\n\t\tmaxDeg = std::max(maxDeg, deg);\n\t}\n\treturn maxDeg;\n}",
            "// YOUR CODE HERE\n}",
            "int maxDeg = 0;\n  for (int i = 0; i < N; i++) {\n    int n = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i*N+j]) n++;\n    }\n    maxDeg = std::max(maxDeg, n);\n  }\n  return maxDeg;\n}",
            "int highest = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\thighest = std::max(highest, degree);\n\t}\n\treturn highest;\n}",
            "std::vector<int> maxs;\n\tmaxs.resize(N);\n\t\n\tMPI_Datatype dtype;\n\tMPI_Type_contiguous(N, MPI_INT, &dtype);\n\tMPI_Type_commit(&dtype);\n\t\n\tMPI_Request req;\n\tint rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\t\n\tstd::vector<int> localMaxs;\n\tlocalMaxs.resize(N);\n\tstd::fill(localMaxs.begin(), localMaxs.end(), 0);\n\t\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i * N + j]) {\n\t\t\t\tlocalMaxs[i]++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tMPI_Reduce(localMaxs.data(), maxs.data(), N, dtype, MPI_MAX, 0, MPI_COMM_WORLD);\n\tMPI_Type_free(&dtype);\n\t\n\tif(rank == 0) {\n\t\treturn *std::max_element(maxs.begin(), maxs.end());\n\t} else {\n\t\treturn -1;\n\t}\n}",
            "int rank, p;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &p);\n  int *A_ = new int[N * N];\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      A_[i * N + j] = A[i * N + j];\n    }\n  }\n  int *maxDegrees = new int[p];\n  for (size_t i = 0; i < N; i++) {\n    int maxDegree = 0;\n    for (size_t j = 0; j < N; j++) {\n      maxDegree += A_[i * N + j];\n    }\n    maxDegrees[rank] = maxDegree;\n  }\n  MPI_Allgather(MPI_IN_PLACE, 0, MPI_INT, maxDegrees, 1, MPI_INT, MPI_COMM_WORLD);\n  int result = 0;\n  for (int i = 0; i < p; i++) {\n    result = std::max(result, maxDegrees[i]);\n  }\n  delete[] maxDegrees;\n  return result;\n}",
            "assert(N > 0);\n  int max = 0;\n  for (int i = 0; i < N; ++i) {\n    int nodeDegree = 0;\n    for (int j = 0; j < N; ++j)\n      nodeDegree += A[i * N + j];\n    max = std::max(max, nodeDegree);\n  }\n  return max;\n}",
            "// TODO\n}",
            "// TODO\n}",
            "int max_degree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tdegree += A[i * N + j];\n\t\tmax_degree = std::max(degree, max_degree);\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N*i+j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > maxDegree)\n\t\t\tmaxDegree = degree;\n\t}\n\treturn maxDegree;\n}",
            "if (N == 0) {\n\t\tthrow std::invalid_argument(\"N must be greater than 0\");\n\t}\n\n\t// TODO: implement\n\treturn -1;\n}",
            "std::vector<int> degrees(N, 0);\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        degrees[i]++;\n      }\n    }\n  }\n\n  int maxDeg = degrees[0];\n  for (size_t i = 1; i < N; ++i) {\n    maxDeg = std::max(maxDeg, degrees[i]);\n  }\n\n  return maxDeg;\n}",
            "/* Your code goes here */\n}",
            "if (N == 0)\n        return 0;\n    int max = A[0];\n    for (int i = 1; i < N * N; i++) {\n        if (A[i] > max)\n            max = A[i];\n    }\n    return max;\n}",
            "int result = 0;\n\tint max_result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t\tif (count > result) {\n\t\t\tresult = count;\n\t\t}\n\t}\n\tMPI_Reduce(&result, &max_result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn max_result;\n}",
            "int max = 0;\n  // fill in the code\n  return max;\n}",
            "// TODO\n\treturn 0;\n}",
            "// TODO\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int deg = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j]!= 0) {\n        deg++;\n      }\n    }\n    maxDegree = std::max(maxDegree, deg);\n  }\n  return maxDegree;\n}",
            "// Write your code here\n  return 0;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    int row = 0;\n    for (size_t j = 0; j < N; j++) {\n      row += A[i*N+j];\n    }\n    if (row > maxDegree) {\n      maxDegree = row;\n    }\n  }\n  return maxDegree;\n}",
            "// TODO\n}",
            "// TODO: Fill this in\n  int max = 0;\n  for(int i = 0; i < A.size(); i++){\n    if (A[i] > max) {\n      max = A[i];\n    }\n  }\n  return max;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; i++) {\n        int cnt = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j]!= 0) {\n                cnt++;\n            }\n        }\n        max = std::max(cnt, max);\n    }\n    return max;\n}",
            "int myMax = 0;\n  // Fill this in\n\n  // Reduce the number of messages by using a logarithmic number of iterations\n  while (N > 1) {\n    if (N % 2 == 1) {\n      // Add the missing entries to make N even\n      A.push_back(0);\n    }\n    N /= 2;\n    // Fill this in\n  }\n\n  return myMax;\n}",
            "int my_max_degree = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] > 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tmy_max_degree = max(my_max_degree, degree);\n\t}\n\treturn my_max_degree;\n}",
            "//\n  // Your code goes here\n  //\n  return 0;\n}",
            "std::vector<int> localMaxDegree = { 0 };\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[N * i + j] == 1)\n        localMaxDegree[0]++;\n    }\n  }\n\n  return localMaxDegree[0];\n}",
            "}",
            "// Fill me in\n\treturn -1;\n}",
            "/* ************************************************************** */\n  // TODO\n  // Replace this with your code.\n  // Note: use MPI_Send and MPI_Recv to send and receive messages.\n  // Note: use MPI_Bcast to broadcast a message.\n  /* ************************************************************** */\n\n  return 0;\n}",
            "// TODO\n}",
            "// TODO: Replace this line with your implementation\n\treturn 0;\n}",
            "int max_degree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tdegree += A[i*N+j];\n\t\t}\n\t\tmax_degree = std::max(max_degree, degree);\n\t}\n\treturn max_degree;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// TODO: compute max degree in parallel\n\tint max_degree = 0;\n\n\treturn max_degree;\n}",
            "std::vector<int> localMaxDegree(N);\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t\tlocalMaxDegree[i] = sum;\n\t\tif (sum > maxDegree) {\n\t\t\tmaxDegree = sum;\n\t\t}\n\t}\n\tMPI_Reduce(localMaxDegree.data(), &maxDegree, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn maxDegree;\n}",
            "int rank = 0;\n\tint max_rank = 0;\n\n\t// compute locally\n\tmax_rank = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1)\n\t\t\t\t++degree;\n\t\t}\n\n\t\tif (degree > max_rank) {\n\t\t\tmax_rank = degree;\n\t\t}\n\t}\n\n\t// compute in parallel\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tif (rank == 0) {\n\t\tint max_rank_global = max_rank;\n\t\tfor (int r = 1; r < MPI_COMM_WORLD->local_size; ++r) {\n\t\t\tMPI_Recv(&max_rank, 1, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tif (max_rank > max_rank_global)\n\t\t\t\tmax_rank_global = max_rank;\n\t\t}\n\n\t\tmax_rank = max_rank_global;\n\t} else {\n\t\tMPI_Send(&max_rank, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tMPI_Bcast(&max_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn max_rank;\n}",
            "int max_degree = 0;\n\tint sum = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tmax_degree = std::max(max_degree, sum);\n\t\tsum = 0;\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0)\n                maxDegree = std::max(maxDegree, 1 + A[j * N + i]);\n        }\n    }\n    return maxDegree;\n}",
            "// Your code here\n\tint max_degree = -1;\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (A[N * i + j])\n\t\t\t\tdegree++;\n\t\t}\n\t\tmax_degree = degree > max_degree? degree : max_degree;\n\t}\n\treturn max_degree;\n}",
            "// TODO\n}",
            "// TODO: YOUR CODE HERE\n    std::vector<int> maxDegree_per_rank(A.size(), 0);\n    for(size_t i = 0; i < N; i++)\n    {\n        for(size_t j = 0; j < N; j++)\n        {\n            if(A[i * N + j]!= 0)\n            {\n                maxDegree_per_rank[i]++;\n            }\n        }\n    }\n    int maxDegree = 0;\n    int* p = &maxDegree;\n    MPI_Reduce(&maxDegree_per_rank[0], p, A.size(), MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return maxDegree;\n}",
            "int n = 0;\n\n\t// YOUR CODE HERE\n\t\n\treturn n;\n}",
            "/* Implement in terms of other functions */\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n\tint rank, size;\n\tMPI_Comm_rank(comm, &rank);\n\tMPI_Comm_size(comm, &size);\n\n\t// Your code goes here\n\treturn 0;\n}",
            "return 0;\n}",
            "/*\n\tThe idea is to compute the sum of degrees of nodes in the first and second half of the matrix.\n\tThen to sum up the results from all ranks. Then to find the maximum of the partial results\n\tfrom all ranks.\n\t*/\n\tint sum = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t}\n\n\tint globalSum = 0;\n\tint rank = 0;\n\tint size = 0;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tMPI_Reduce(&sum, &globalSum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tint result = 0;\n\n\tif (rank == 0) {\n\t\tresult = globalSum / 2;\n\t}\n\n\tMPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn result;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "}",
            "int result = 0;\n\n    int numRanks, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    std::vector<int> A_local(A.begin() + rank * N, A.begin() + (rank + 1) * N);\n\n    int local_max = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A_local[i] & (1 << j)) local_max++;\n        }\n    }\n\n    MPI_Reduce(&local_max, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "int max_degree{0};\n\t// TODO: Implement this function\n\n\treturn max_degree;\n}",
            "// TODO: compute the maximum degree in the graph in parallel\n    int max_degree = 0;\n    // TODO: put your code here\n    // MPI_Comm_size(MPI_COMM_WORLD, &size);\n    // MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    return max_degree;\n}",
            "int maxDegree = 0;\n\n  for(int i = 0; i < N; ++i) {\n    int numNeighbors = 0;\n    for(int j = 0; j < N; ++j) {\n      if(A[i * N + j]!= 0) {\n        ++numNeighbors;\n      }\n    }\n    maxDegree = std::max(numNeighbors, maxDegree);\n  }\n\n  return maxDegree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += A[N*i + j];\n\t\t}\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}",
            "// TODO: Implement this function.\n  int maxDegree = 0;\n  int curDegree = 0;\n  for(size_t i = 0; i < N; ++i)\n  {\n      curDegree = 0;\n      for(size_t j = 0; j < N; ++j)\n      {\n          if(A[i*N + j] == 1)\n              curDegree++;\n      }\n      if(curDegree > maxDegree)\n          maxDegree = curDegree;\n  }\n  return maxDegree;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\n\tint maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N*i+j]!= 0) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, degree);\n\t}\n\n\treturn maxDegree;\n}",
            "int result = 0;\n\n  // Compute the max degree locally on every rank.\n  for(size_t i = 0; i < A.size(); i++) {\n    int count = 0;\n    for(size_t j = 0; j < A.size(); j++) {\n      if(A[j * N + i]!= 0)\n        count++;\n    }\n    result = std::max(result, count);\n  }\n\n  // Reduce on rank 0.\n  int result_global;\n  MPI_Reduce(&result, &result_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return result_global;\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      maxDegree = maxDegree > A[N * i + j]? maxDegree : A[N * i + j];\n    }\n  }\n  return maxDegree;\n}",
            "// Your code here\n  int max = 0;\n  int tmp = 0;\n  for(int i = 0; i < N; i++)\n  {\n    for(int j = 0; j < N; j++)\n    {\n      if(A[i*N + j] == 1)\n      {\n        tmp++;\n      }\n    }\n    if(tmp > max)\n    {\n      max = tmp;\n    }\n    tmp = 0;\n  }\n  int max_global = 0;\n  MPI_Reduce(&max, &max_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return max_global;\n}",
            "int result = -1;\n\n  #ifdef PARALLEL\n    MPI_Allreduce(MPI_IN_PLACE, &result, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n  #else\n    for(size_t i=0; i<N; ++i) {\n      for(size_t j=0; j<N; ++j) {\n        if(A[i*N+j]!= 0) {\n          result = std::max(result, (int) (A[i*N+j] + A[j*N+i]));\n        }\n      }\n    }\n  #endif\n\n  return result;\n}",
            "int rank = 0;\n  int max_degree = 0;\n  int local_max_degree = 0;\n  //int global_max_degree = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Request req;\n  MPI_Status stat;\n  if(rank==0) {\n    for(size_t i=0;i<N;i++) {\n      for(size_t j=i;j<N;j++) {\n\tlocal_max_degree += A[i*N+j];\n      }\n    }\n    max_degree = local_max_degree;\n    for(int i=1;i<N;i++) {\n      MPI_Irecv(&max_degree, 1, MPI_INT, i, i, MPI_COMM_WORLD, &req);\n    }\n    for(int i=1;i<N;i++) {\n      MPI_Wait(&req, &stat);\n    }\n    return max_degree;\n  }\n  else {\n    MPI_Send(&local_max_degree, 1, MPI_INT, 0, rank, MPI_COMM_WORLD);\n    return 0;\n  }\n}",
            "// TODO: your code here\n}",
            "// replace with your code\n  int max_degree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i*N+j];\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "MPI_Datatype row;\n\tMPI_Type_vector(N, 1, N, MPI_INT, &row);\n\tMPI_Type_commit(&row);\n\n\tint max = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tint deg = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tdeg += A[i*N + j];\n\t\t}\n\t\tif (deg > max) {\n\t\t\tmax = deg;\n\t\t}\n\t}\n\n\tMPI_Type_free(&row);\n\treturn max;\n}",
            "int mx = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint nbrs = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++nbrs;\n\t\t\t}\n\t\t}\n\t\tmx = std::max(mx, nbrs);\n\t}\n\treturn mx;\n}",
            "int* in_buffer = new int[N * N];\n  int* out_buffer = new int[N * N];\n\n  for (size_t i = 0; i < N * N; i++) {\n    in_buffer[i] = A[i];\n  }\n\n  int send_count = N * N / 4;\n  int recv_count = N * N / 4;\n  int tag = 0;\n  MPI_Request* req = new MPI_Request[4];\n\n  MPI_Status* status = new MPI_Status[4];\n  MPI_Irecv(out_buffer, recv_count, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD, &req[0]);\n  MPI_Irecv(out_buffer + N * N / 4, recv_count, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD,\n            &req[1]);\n  MPI_Irecv(out_buffer + N * N / 2, recv_count, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD,\n            &req[2]);\n  MPI_Irecv(out_buffer + 3 * N * N / 4, recv_count, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD,\n            &req[3]);\n\n  MPI_Isend(in_buffer, send_count, MPI_INT, 0, tag, MPI_COMM_WORLD, &req[4]);\n  MPI_Isend(in_buffer + N * N / 4, send_count, MPI_INT, 1, tag, MPI_COMM_WORLD, &req[5]);\n  MPI_Isend(in_buffer + N * N / 2, send_count, MPI_INT, 2, tag, MPI_COMM_WORLD, &req[6]);\n  MPI_Isend(in_buffer + 3 * N * N / 4, send_count, MPI_INT, 3, tag, MPI_COMM_WORLD, &req[7]);\n\n  int degree = 0;\n  for (size_t i = 0; i < N * N; i++) {\n    for (size_t j = 0; j < N * N; j++) {\n      degree += in_buffer[i] * in_buffer[j];\n    }\n  }\n  for (size_t i = 0; i < 4; i++) {\n    MPI_Wait(&req[i], &status[i]);\n  }\n  for (size_t i = 0; i < N * N; i++) {\n    degree += out_buffer[i];\n  }\n\n  delete[] in_buffer;\n  delete[] out_buffer;\n  delete[] req;\n  delete[] status;\n\n  return degree;\n}",
            "int localMax = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j and A[N*i + j] == 1)\n        localMax++;\n    }\n  }\n  int globalMax = localMax;\n  MPI_Reduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return globalMax;\n}",
            "int degree = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        degree = std::max(degree, i + 1);\n        degree = std::max(degree, j + 1);\n      }\n    }\n  }\n\n  return degree;\n}",
            "int myMax = 0;\n  for (size_t i = 0; i < N; i++) {\n    int deg = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] > 0) {\n        deg++;\n      }\n    }\n    if (deg > myMax) {\n      myMax = deg;\n    }\n  }\n\n  int maxDegree = 0;\n  MPI_Reduce(&myMax, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree;\n}",
            "// your code here\n\treturn -1;\n}",
            "// TODO\n}",
            "int maxDegree = 0;\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\t\n\tstd::vector<int> maxDegreeVec(size, 0);\n\t\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\tmaxDegreeVec[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tMPI_Reduce(&maxDegreeVec[0], &maxDegreeVec[0], size, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < size; ++i) {\n\t\t\tif (maxDegree < maxDegreeVec[i]) {\n\t\t\t\tmaxDegree = maxDegreeVec[i];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n\n\t// Insert your code here\n\n\treturn maxDegree;\n}",
            "// Your code goes here\n  int * local_A;\n  int local_N;\n  int * max_degree_A;\n  int max_degree_A_size;\n  int max_degree;\n  int * displs;\n  int * counts;\n  MPI_Status status;\n  MPI_Comm_size(MPI_COMM_WORLD, &max_degree_A_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &local_N);\n  local_A = new int[N];\n  for(int i=0; i<N; i++){\n    local_A[i]= A[i*N + local_N];\n  }\n  max_degree_A = new int[1];\n  max_degree = 0;\n  for(int i=0; i<N; i++){\n    if(local_A[i]>max_degree){\n      max_degree = local_A[i];\n    }\n  }\n  max_degree_A[0] = max_degree;\n  displs = new int[max_degree_A_size];\n  counts = new int[max_degree_A_size];\n  for(int i=0; i<max_degree_A_size; i++){\n    displs[i]=0;\n    counts[i]=1;\n  }\n  MPI_Allgatherv(max_degree_A,1,MPI_INT,max_degree_A,counts,displs,MPI_INT,MPI_COMM_WORLD);\n  max_degree = max_degree_A[0];\n  for(int i=0; i<max_degree_A_size; i++){\n    if(max_degree_A[i]>max_degree){\n      max_degree = max_degree_A[i];\n    }\n  }\n  return max_degree;\n}",
            "int const rank = MPI::COMM_WORLD.Get_rank();\n\tint const size = MPI::COMM_WORLD.Get_size();\n\n\tint localMaxDegree = 0;\n\tif (rank == 0) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tlocalMaxDegree = std::max(localMaxDegree, 1 + A[i * N + j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[rank * N + i * N + j] == 1) {\n\t\t\t\t\tlocalMaxDegree = std::max(localMaxDegree, 1 + A[rank * N + i * N + j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxDegree;\n\tMPI::COMM_WORLD.Allreduce(&localMaxDegree, &maxDegree, 1, MPI::INT, MPI::MAX);\n\treturn maxDegree;\n}",
            "auto degree = std::vector<int>(N);\n\tfor (size_t i=0; i < N; i++) {\n\t\tfor (size_t j=0; j < N; j++) {\n\t\t\tif (A[i*N+j]!= 0) {\n\t\t\t\tdegree[i]++;\n\t\t\t}\n\t\t}\n\t}\n\t// return the highest degree for rank 0\n\tif (0 == MPI_Rank()) {\n\t\tint highestDegree = 0;\n\t\tfor (int d : degree) {\n\t\t\tif (d > highestDegree) {\n\t\t\t\thighestDegree = d;\n\t\t\t}\n\t\t}\n\t\treturn highestDegree;\n\t}\n\t// otherwise, return -1\n\treturn -1;\n}",
            "return 0;\n}",
            "int maxDegree = 0;\n    for(int i = 0; i < N; ++i) {\n        int degree = 0;\n        for(int j = 0; j < N; ++j) {\n            degree += A[N*i + j];\n        }\n        if(degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n    return maxDegree;\n}",
            "int local_max = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > local_max) {\n\t\t\tlocal_max = sum;\n\t\t}\n\t}\n\n\t// MPI magic happens here\n\n\treturn local_max;\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; i++) {\n        int d = 0;\n        for (size_t j = 0; j < N; j++) {\n            d += A[i * N + j];\n        }\n        if (d > max) {\n            max = d;\n        }\n    }\n    return max;\n}",
            "MPI_Status status;\n\tint count, rank, size, maxDegree = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint localMax = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j])\n\t\t\t\tlocalMax++;\n\t\t}\n\t\tif (rank == 0) {\n\t\t\tif (localMax > maxDegree)\n\t\t\t\tmaxDegree = localMax;\n\t\t}\n\t\telse {\n\t\t\tMPI_Send(&localMax, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\n\tif (rank!= 0) {\n\t\tMPI_Recv(&maxDegree, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n\t}\n\n\treturn maxDegree;\n}",
            "int myMaxDegree = 0;\n  for (int row = 0; row < N; row++) {\n    int myRowDegree = 0;\n    for (int column = 0; column < N; column++) {\n      myRowDegree += A[row * N + column];\n    }\n    myMaxDegree = std::max(myMaxDegree, myRowDegree);\n  }\n\n  int maxDegree = 0;\n  MPI_Reduce(&myMaxDegree, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree;\n}",
            "//TODO\n\treturn -1;\n}",
            "}",
            "// The following code assumes MPI has already been initialized.\n  // Your code should not initialize MPI.\n  // Use MPI_COMM_WORLD for inter-node communication.\n\n  // TODO: Compute the highest node degree in the graph\n\n  int n_nodes = N;\n  int n_ranks;\n  MPI_Comm_size(MPI_COMM_WORLD, &n_ranks);\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int highest_degree = 0;\n  std::vector<int> local_max;\n  local_max.push_back(0);\n\n  int node_per_rank = N / n_ranks;\n  int remainder = N % n_ranks;\n\n  // Send a message to each rank with its local maximum\n  int *local_max_data;\n  int *recv_max_data;\n  int *local_max_degree;\n  int *recv_max_degree;\n  int *local_max_node;\n  int *recv_max_node;\n  MPI_Request *max_req;\n  MPI_Request *deg_req;\n  MPI_Request *node_req;\n\n  if (rank < remainder){\n    node_per_rank += 1;\n  }\n\n  int i;\n  for (i = 1; i < n_ranks; i++){\n    if (rank == i - 1){\n      local_max_data = &(A[rank * node_per_rank * n_nodes]);\n      local_max_degree = &local_max[0];\n      local_max_node = &i;\n      MPI_Isend(local_max_data, node_per_rank * n_nodes, MPI_INT, i, 0, MPI_COMM_WORLD, &(max_req[i - 1]));\n      MPI_Isend(local_max_degree, 1, MPI_INT, i, 1, MPI_COMM_WORLD, &(deg_req[i - 1]));\n      MPI_Isend(local_max_node, 1, MPI_INT, i, 2, MPI_COMM_WORLD, &(node_req[i - 1]));\n    }\n    else if (rank > i - 1){\n      max_req = (MPI_Request *) calloc(sizeof(MPI_Request), i);\n      deg_req = (MPI_Request *) calloc(sizeof(MPI_Request), i);\n      node_req = (MPI_Request *) calloc(sizeof(MPI_Request), i);\n      recv_max_data = (int *) calloc(sizeof(int), node_per_rank * n_nodes);\n      recv_max_degree = (int *) calloc(sizeof(int), 1);\n      recv_max_node = (int *) calloc(sizeof(int), 1);\n      MPI_Irecv(recv_max_data, node_per_rank * n_nodes, MPI_INT, i - 1, 0, MPI_COMM_WORLD, &(max_req[i - 1]));\n      MPI_Irecv(recv_max_degree, 1, MPI_INT, i - 1, 1, MPI_COMM_WORLD, &(deg_req[i - 1]));\n      MPI_Irecv(recv_max_node, 1, MPI_INT, i - 1, 2, MPI_COMM_WORLD, &(node_req[i - 1]));\n    }\n  }\n\n  if (rank == 0){\n    local_max = A;\n    int max = 0;\n    for (int i = 0; i < node_per_rank; i++){\n      for (int j = 0; j < n_nodes; j++){\n        if (A[i * n_nodes + j] > max){\n          max = A[i * n_nodes + j];\n        }\n      }\n      local_max[i * n_nodes + j] = max;\n    }\n    for (int i",
            "/* Your solution goes here */\n    return 0;\n}",
            "// you code here\n}",
            "int max_degree = 0;\n\t// for every column\n\tfor (size_t j = 0; j < N; ++j) {\n\t\tint degree = 0;\n\t\t// for every row\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[N * i + j]) {\n\t\t\t\t++degree;\n\t\t\t}\n\t\t}\n\t\tif (degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "int localMax = 0;\n\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tlocalMax = std::max(localMax, A[i * N + j]);\n\t\t}\n\t}\n\n\tint globalMax;\n\n\tMPI_Reduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn globalMax;\n}",
            "int maxDegree = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tint rowSum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\trowSum += A[i*N + j];\n\t\t}\n\t\tif (rowSum > maxDegree) {\n\t\t\tmaxDegree = rowSum;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "return 0;\n}",
            "// TODO\n}",
            "if (N == 0) {\n        return 0;\n    } else {\n        int maxDegree = 0;\n        for (size_t i = 0; i < N; ++i) {\n            int degree = 0;\n            for (size_t j = 0; j < N; ++j) {\n                if (A[i * N + j]!= 0) {\n                    ++degree;\n                }\n            }\n            maxDegree = std::max(maxDegree, degree);\n        }\n        return maxDegree;\n    }\n}",
            "MPI_Barrier(MPI_COMM_WORLD);\n    //std::cout << \"N=\" << N << \" mpi_size=\" << mpi_size << \" mpi_rank=\" << mpi_rank << std::endl;\n    int max_degree = 0;\n\n    // TODO\n\n    MPI_Barrier(MPI_COMM_WORLD);\n    int degree;\n    MPI_Reduce(&max_degree, &degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    if (mpi_rank == 0) {\n        std::cout << \"rank 0 has the maximum degree \" << degree << std::endl;\n    }\n\n    return degree;\n}",
            "// This function should be implemented by you\n    return -1;\n}",
            "// Your code here\n}",
            "int maxDegree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i*N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "// Replace this code with a parallel computation of the highest degree.\n\tint highestDegree = -1;\n\tint localHighestDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tlocalHighestDegree += 1;\n\t\t\t}\n\t\t}\n\t}\n\tif (localHighestDegree > highestDegree) {\n\t\thighestDegree = localHighestDegree;\n\t}\n\treturn highestDegree;\n}",
            "std::vector<int> localMaxDegree(1, 0);\n\n  // TODO: Compute the maximum degree on each rank. Store it in localMaxDegree[0].\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j && A[i*N + j] == 1) {\n        localMaxDegree[0]++;\n      }\n    }\n  }\n\n  int mpiMaxDegree;\n  MPI_Reduce(&localMaxDegree[0], &mpiMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return mpiMaxDegree;\n}",
            "std::vector<int> localMax(N, 0);\n\n\t// TODO: Compute the local maxima for each row.\n\t\n\t// TODO: Use MPI to find the global maximum.\n\n\treturn localMax[0];\n}",
            "// TODO\n}",
            "// TODO: replace this with your code\n  return 0;\n}",
            "// TODO: Implement this function\n\n    return 0;\n}",
            "// Your code goes here\n\t\n\tint maxDegree = 0;\n\tint localMaxDegree = 0;\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A[i * N + j] == 1){\n\t\t\t\tlocalMaxDegree++;\n\t\t\t}\n\t\t}\n\t}\n\tint mpi_result;\n\tint mpi_result2;\n\tint mpi_result3;\n\tMPI_Reduce(&localMaxDegree, &mpi_result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t\n\treturn mpi_result;\n}",
            "int degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int rowDegree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                ++rowDegree;\n            }\n        }\n        degree = std::max(degree, rowDegree);\n    }\n    return degree;\n}",
            "int max_deg = 0;\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++degree;\n            }\n        }\n        max_deg = std::max(max_deg, degree);\n    }\n    return max_deg;\n}",
            "// TODO\n    return 0;\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; i++) {\n        int curSum = 0;\n        for (int j = 0; j < N; j++) {\n            curSum += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, curSum);\n    }\n    return maxDegree;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (rank == 0) {\n\t\tstd::vector<int> maxDegreePerRank(size);\n\t\tint maxDegree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tint degree = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t\tdegree++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tmaxDegree = std::max(degree, maxDegree);\n\t\t\tmaxDegreePerRank[0] = maxDegree;\n\t\t}\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Recv(&maxDegreePerRank[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tmaxDegree = std::max(maxDegreePerRank[i], maxDegree);\n\t\t}\n\t\treturn maxDegree;\n\t} else {\n\t\tint maxDegree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tint degree = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t\tdegree++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tmaxDegree = std::max(degree, maxDegree);\n\t\t}\n\t\tMPI_Send(&maxDegree, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0;\n\t}\n\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "// TODO: implement this function\n    int my_max = 0;\n    int my_rank = 0;\n    int my_size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &my_size);\n\n    int n_max = 0;\n    for(int i = 0; i < N; i++){\n        int max = 0;\n        for(int j = 0; j < N; j++){\n            if(A[i * N + j] > max){\n                max = A[i * N + j];\n            }\n        }\n        if(max > my_max){\n            my_max = max;\n        }\n    }\n\n    MPI_Reduce(&my_max, &n_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return n_max;\n\n}",
            "int my_result = 0;\n  for (size_t i = 0; i < N; i++) {\n    int count = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        count++;\n      }\n    }\n    my_result = std::max(my_result, count);\n  }\n  return my_result;\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  std::vector<int> nodeDegree(N, 0);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] > 0)\n        nodeDegree[i]++;\n    }\n  }\n\n  int maxDegree = -1;\n  if (rank == 0) {\n    for (size_t i = 0; i < N; ++i) {\n      if (nodeDegree[i] > maxDegree)\n        maxDegree = nodeDegree[i];\n    }\n  }\n\n  int localMaxDegree = -1;\n  if (rank == 0) {\n    MPI_Reduce(&maxDegree, &localMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  } else {\n    MPI_Reduce(&nodeDegree[0], &localMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  }\n\n  if (rank == 0)\n    return localMaxDegree;\n  else\n    return 0;\n}",
            "int maxDegree{0};\n  if (N == 1) return maxDegree;\n  // Add your code here\n  int count=0;\n  for(int i=0;i<N;i++)\n  {\n    for(int j=0;j<N;j++)\n    {\n      count+=A[i*N+j];\n    }\n    if(count>maxDegree)\n    {\n      maxDegree=count;\n    }\n    count=0;\n  }\n  \n\n  \n  return maxDegree;\n}",
            "// Implement me!\n  return 0;\n}",
            "auto max_degree_it = std::max_element(A.begin(), A.end());\n  int max_degree = *max_degree_it;\n  return max_degree;\n}",
            "int result = -1;\n\n\t// use a local maximum variable to keep track of the local result on each rank\n\tint local_max = 0;\n\n\t// loop over each row of A\n\tfor (size_t i = 0; i < N; i++) {\n\n\t\tint num_non_zero = 0; // number of non-zero elements in the row\n\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tnum_non_zero++;\n\t\t\t}\n\t\t}\n\n\t\t// update the local maximum if needed\n\t\tif (num_non_zero > local_max) {\n\t\t\tlocal_max = num_non_zero;\n\t\t}\n\t}\n\n\t// gather the local maximum on rank 0\n\tMPI_Reduce(&local_max, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn result;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for (size_t j = 0; j < N; ++j) {\n      count += A[i * N + j];\n    }\n    if (count > max) {\n      max = count;\n    }\n  }\n  return max;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\tint maxDegree = 0;\n\t// TODO: Your code here\n\n\treturn maxDegree;\n}",
            "// TODO: Your code here\n}",
            "int maxDegree = 0;\n    for (auto i = 0; i < N; ++i) {\n        int degree = 0;\n        for (auto j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "// Implement this function.\n  // Note: it's ok to create new arrays and to not use A at all\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO\n  return 0;\n}",
            "int max = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        int sum = 0;\n        for (size_t j = 0; j < N; j++) {\n            sum += A[i*N+j];\n        }\n        max = std::max(max, sum);\n    }\n\n    return max;\n}",
            "int numRanks, myRank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n\tstd::vector<int> localSum(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tlocalSum[i] += A[i * N + j];\n\t\t}\n\t}\n\n\tstd::vector<int> globalSum(N, 0);\n\tMPI_Reduce(localSum.data(), globalSum.data(), N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tint max = 0;\n\tfor (int v : globalSum) {\n\t\tmax = std::max(max, v);\n\t}\n\n\treturn max;\n}",
            "int localMax = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++localMax;\n\t\t\t}\n\t\t}\n\t}\n\n\tint globalMax = localMax;\n\tMPI_Reduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn globalMax;\n}",
            "int Nranks;\n  MPI_Comm_size(MPI_COMM_WORLD, &Nranks);\n\n  // TODO: Implement this function\n\n  return 0;\n}",
            "// TODO: Your code here\n\n}",
            "int max = 0;\n    for (int i = 0; i < N; i++) {\n        int count = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                count++;\n            }\n        }\n        if (count > max) {\n            max = count;\n        }\n    }\n    return max;\n}",
            "// This is a dummy implementation\n  return 1;\n}",
            "// TODO: your code here\n\tstd::vector<int> degrees(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tdegrees[i]++;\n\t\t\t}\n\t\t}\n\t}\n\tint max_degree = 0;\n\tint max_i = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (degrees[i] > max_degree) {\n\t\t\tmax_degree = degrees[i];\n\t\t\tmax_i = i;\n\t\t}\n\t}\n\tint max_degree_global;\n\tMPI_Reduce(&max_degree, &max_degree_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif (MPI_COMM_WORLD.rank == 0) {\n\t\treturn max_degree_global;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "int const rank = MPI_Comm_rank(MPI_COMM_WORLD);\n\tint const size = MPI_Comm_size(MPI_COMM_WORLD);\n\n\tint maxLocal = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tmaxLocal = std::max(maxLocal, i);\n\t\t\t\tmaxLocal = std::max(maxLocal, j);\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxGlobal;\n\tMPI_Reduce(&maxLocal, &maxGlobal, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn maxGlobal;\n}",
            "// Your code here\n\tint nrank = 0;\n\tint max = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nrank);\n\n\tstd::vector<int> A_vec(A.begin(), A.end());\n\tstd::vector<int> max_vec(nrank, 0);\n\n\tfor (int i = 0; i < nrank; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tfor (int k = 0; k < N; k++)\n\t\t\t{\n\t\t\t\tif (A_vec[j * N + k] == 1)\n\t\t\t\t{\n\t\t\t\t\tmax_vec[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(max_vec.data(), &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max;\n}",
            "// 1. Create a local variable to store the result\n\tint localResult = 0;\n\n\t// 2. Compute the local result, store it in localResult\n\t// Hint: the local degree is the number of neighbors\n\n\n\t// 3. Use MPI_Reduce to compute the global result\n\t// MPI_Reduce\n\n\treturn globalResult;\n}",
            "// TODO: Implement\n\treturn 0;\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n  int rank;\n  int size;\n  MPI_Comm_rank(comm, &rank);\n  MPI_Comm_size(comm, &size);\n\n  std::vector<int> localMax(N/size);\n  if (rank == 0) {\n    for (size_t i = 0; i < localMax.size(); i++) {\n      localMax[i] = std::accumulate(A.begin() + i*N/size, A.begin() + (i+1)*N/size, 0);\n    }\n  } else {\n    for (size_t i = 0; i < localMax.size(); i++) {\n      localMax[i] = std::accumulate(A.begin() + i*N/size, A.begin() + (i+1)*N/size, 0);\n    }\n  }\n\n  MPI_Barrier(comm);\n  std::vector<int> globalMax(N/size);\n\n  if (rank == 0) {\n    MPI_Reduce(&localMax[0], &globalMax[0], size, MPI_INT, MPI_MAX, 0, comm);\n  } else {\n    MPI_Reduce(&localMax[0], NULL, size, MPI_INT, MPI_MAX, 0, comm);\n  }\n\n  int max = 0;\n  for (size_t i = 0; i < globalMax.size(); i++) {\n    max = std::max(globalMax[i], max);\n  }\n  return max;\n}",
            "int maxDegree = 0;\n\t// YOUR CODE HERE\n\t// Replace this comment with your implementation of computing the highest degree of the\n\t// graph stored in A\n\t//\n\treturn maxDegree;\n}",
            "// TODO\n\treturn 0;\n}",
            "int maxDegree = 0;\n  int myMaxDegree = 0;\n\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = 0; j < N; ++j) {\n      if(A[i*N + j] == 1) {\n\tmyMaxDegree++;\n      }\n    }\n  }\n  if(myMaxDegree > maxDegree) {\n    maxDegree = myMaxDegree;\n  }\n  int maxDegreeOnRank0;\n  // use MPI to gather all results to rank 0\n  MPI_Reduce(&myMaxDegree, &maxDegreeOnRank0, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegreeOnRank0;\n}",
            "int maxDegree = 0;\n\tfor(size_t i=0; i<N; i++)\n\t\tfor(size_t j=i+1; j<N; j++)\n\t\t\tif(A[i*N+j])\n\t\t\t\tmaxDegree = std::max(maxDegree, (A[i*N+j]+A[j*N+i]));\n\t\n\treturn maxDegree;\n}",
            "if (N == 0) {\n        return 0;\n    }\n    std::vector<int> maxDegrees(N);\n    // Compute local max degrees\n    for (size_t i = 0; i < N; ++i) {\n        int maxDegree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            maxDegree += A[i*N + j];\n        }\n        maxDegrees[i] = maxDegree;\n    }\n\n    // Get maximum degree on rank 0\n    int maxDegree = *std::max_element(maxDegrees.begin(), maxDegrees.end());\n\n    // MPI stuff\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    std::vector<int> maxDegreesReduced(size);\n    // Gather all max degrees\n    MPI_Gather(&maxDegree, 1, MPI_INT, maxDegreesReduced.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n    if (rank == 0) {\n        maxDegree = *std::max_element(maxDegreesReduced.begin(), maxDegreesReduced.end());\n    }\n\n    return maxDegree;\n}",
            "return 0;\n}",
            "assert(N == A.size() && \"Incorrect number of rows in A\");\n    if (N == 0) return 0;\n\n    // TODO\n    int m = -1;\n    for (int i = 0; i < N; i++) {\n        int sum = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]!= 0)\n                sum++;\n        }\n        if (sum > m)\n            m = sum;\n    }\n\n    return m;\n}",
            "std::vector<int> counts(N);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] > 0) {\n\t\t\t\tcounts[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxCount = -1;\n\tfor (int count : counts) {\n\t\tif (count > maxCount) {\n\t\t\tmaxCount = count;\n\t\t}\n\t}\n\n\treturn maxCount;\n}",
            "auto const& localA = A;\n\tauto max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tsum += localA[i*N + j];\n\t\t}\n\t\tmax = std::max(max, sum);\n\t}\n\treturn max;\n}",
            "// TODO\n}",
            "/* Your code here */\n}",
            "// TODO: Replace this code with your solution\n\t\n\t// Create a vector to hold the count of outgoing edges for each node.\n\t// For example, the graph\n\t//\n\t// 0 --> 1\n\t// 0 --> 3\n\t// 1 --> 0\n\t// 1 --> 2\n\t// 2 --> 1\n\t// 2 --> 3\n\t// 3 --> 0\n\t//\n\t// would have a count of\n\t//\n\t// 0: 2\n\t// 1: 2\n\t// 2: 2\n\t// 3: 1\n\t//\n\t// Note that we do not include self-edges in the count.\n\t// A self-edge is an edge that has the same node as both the source and the destination.\n\t//\n\t// 0 --> 1\n\t// 0 --> 0\n\t// 1 --> 2\n\t// 1 --> 1\n\t// 2 --> 2\n\t// 2 --> 3\n\t// 3 --> 3\n\t//\n\t// would have a count of\n\t//\n\t// 0: 1\n\t// 1: 2\n\t// 2: 2\n\t// 3: 1\n\n\tint nprocs, proc_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &proc_rank);\n\n\tstd::vector<int> counts(N,0);\n\tfor (int i=0; i<N; i++){\n\t\tfor (int j=0; j<N; j++){\n\t\t\tif (A[i*N+j] == 1){\n\t\t\t\tcounts[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now that you have a vector of counts, you can do something with them, like find the max.\n\t// Use MPI collectives to find the maximum.\n\t// https://www.open-mpi.org/doc/v4.0/man3/MPI_Reduce.3.php\n\tint max_degree = 0;\n\tfor (int i=0; i<N; i++){\n\t\tif (counts[i] > max_degree){\n\t\t\tmax_degree = counts[i];\n\t\t}\n\t}\n\n\tMPI_Reduce(&max_degree, &max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max_degree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint cnt = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcnt += A[i*N + j];\n\t\t}\n\t\tmax = std::max(max, cnt);\n\t}\n\treturn max;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0) {\n\t\t// rank 0 computes the max degree of its submatrix\n\t\tint degree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tint d = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\td += A[i*N+j];\n\t\t\t}\n\t\t\tdegree = std::max(degree, d);\n\t\t}\n\n\t\t// ranks 1 to N-1 send their degrees to rank 0\n\t\tfor (int i = 1; i < N; i++) {\n\t\t\tint d;\n\t\t\tMPI_Recv(&d, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tdegree = std::max(degree, d);\n\t\t}\n\t\treturn degree;\n\t} else {\n\t\t// ranks 1 to N-1 send their degree to rank 0\n\t\tint degree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tint d = 0;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\td += A[i*N+j];\n\t\t\t}\n\t\t\tdegree = std::max(degree, d);\n\t\t}\n\t\tMPI_Send(&degree, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0; // not needed\n\t}\n}",
            "int localMax = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      localMax = std::max(localMax, A[i * N + j]);\n    }\n  }\n  int globalMax = 0;\n  MPI_Allreduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n  return globalMax;\n}",
            "// TODO\n}",
            "std::vector<int> localMaxDegrees;\n    std::vector<int> localMaxDegreeIndices;\n    for (size_t i = 0; i < N; i++) {\n        int localMaxDegree = 0;\n        int localMaxDegreeIndex = -1;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j] > 0 && localMaxDegree < A[i*N + j]) {\n                localMaxDegree = A[i*N + j];\n                localMaxDegreeIndex = j;\n            }\n        }\n        localMaxDegrees.push_back(localMaxDegree);\n        localMaxDegreeIndices.push_back(localMaxDegreeIndex);\n    }\n\n    // TODO: reduce maxDegrees and maxDegreeIndices with MPI\n    // TODO: compute maxDegree and maxDegreeIndex\n\n    return maxDegree;\n}",
            "// TODO\n\tMPI_Status status;\n\tint localMax = 0, max = 0;\n\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (A[N*i+j] == 1){\n\t\t\t\tlocalMax++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&localMax, &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\tif (localMax == 0) {\n\t\tMPI_Recv(&max, 1, MPI_INT, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n\t}\n\telse {\n\t\tMPI_Send(&localMax, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn max;\n}",
            "// YOUR CODE HERE\n\n\treturn 0;\n}",
            "std::vector<int> localMaxDegree(1, 0);\n    for (size_t i = 0; i < N; ++i) {\n        int sum = std::accumulate(A.begin() + N*i, A.begin() + N*(i+1), 0);\n        localMaxDegree[0] = std::max(localMaxDegree[0], sum);\n    }\n    int globalMaxDegree;\n    MPI_Reduce(&localMaxDegree[0], &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return globalMaxDegree;\n}",
            "int maxDegree = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "int max = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint cnt = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++cnt;\n\t\t\t}\n\t\t}\n\t\tif (cnt > max) {\n\t\t\tmax = cnt;\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n\t// replace this code with a correct solution\n\tfor(auto it = A.begin(); it < A.end(); ++it) {\n\t\tif(*it > maxDegree) {\n\t\t\tmaxDegree = *it;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int max = 0;\n\n  // YOUR CODE HERE\n  for (size_t i = 0; i < N; i++)\n  {\n    int count = 0;\n    for (size_t j = 0; j < N; j++)\n    {\n      if (A[i*N + j] > 0)\n      {\n        count++;\n      }\n    }\n    if (count > max)\n    {\n      max = count;\n    }\n  }\n  // YOUR CODE HERE\n\n  return max;\n}",
            "int res = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint cur = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcur += A[i*N + j];\n\t\t}\n\t\tres = std::max(res, cur);\n\t}\n\treturn res;\n}",
            "int result = 0;\n\n    // TODO: fill this in\n\n    return result;\n}",
            "int rank = 0;\n\tint worldSize = 1;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &worldSize);\n\t\n\tint maxDegree = 0;\n\tif (rank == 0) {\n\t\tint localMaxDegree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tlocalMaxDegree += A[N*i + j];\n\t\t\t}\n\t\t\tmaxDegree = std::max(maxDegree, localMaxDegree);\n\t\t\tlocalMaxDegree = 0;\n\t\t}\n\t\t\n\t\tMPI_Gather(&maxDegree, 1, MPI_INT, NULL, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\tmaxDegree = 0;\n\t\tfor (size_t i = 0; i < worldSize; i++) {\n\t\t\tmaxDegree = std::max(maxDegree, A[i]);\n\t\t}\n\t} else {\n\t\tint localMaxDegree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tlocalMaxDegree += A[N*i + j];\n\t\t\t}\n\t\t}\n\t\t\n\t\tMPI_Gather(&localMaxDegree, 1, MPI_INT, NULL, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t}\n\t\n\treturn maxDegree;\n}",
            "// TODO\n}",
            "int max = 0;\n    for(int i = 0; i < N; ++i) {\n        int sum = 0;\n        for(int j = 0; j < N; ++j) {\n            sum += A[i*N+j];\n        }\n        max = std::max(sum, max);\n    }\n    return max;\n}",
            "// Your code here\n}",
            "auto max_degree = 0;\n  for (int i = 0; i < N; ++i) {\n    auto degree = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++degree;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n  return max_degree;\n}",
            "int maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t++maxDegree;\n\treturn maxDegree;\n}",
            "// Your code here\n\n}",
            "// TODO: Your code here\n\n\treturn 0;\n}",
            "// TODO: your code here\n\tint maxDegree = 0;\n\tint degree = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i*N+j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif(maxDegree < degree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t\tdegree = 0;\n\t}\n\treturn maxDegree;\n}",
            "// TODO: Implement this function\n\tint maxDegree = 0;\n\tfor(int i = 0; i < N; ++i){\n\t\tint degree = 0;\n\t\tfor(int j = 0; j < N; ++j){\n\t\t\tdegree += A[N*i + j];\n\t\t}\n\t\tif(degree > maxDegree){\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "assert(A.size() == N*N);\n\n    // initialize\n    int maxDegree = 0;\n    int degree = 0;\n\n    for(size_t i = 0; i < N; i++) {\n        // reset the counter\n        degree = 0;\n\n        for(size_t j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                degree++;\n            }\n        }\n        // the max degree is the biggest among all node degrees\n        if(degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n    return maxDegree;\n}",
            "int localMax = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tlocalMax = std::max(localMax, degree);\n\t}\n\n\tint globalMax = 0;\n\tMPI_Reduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn globalMax;\n}",
            "// TODO: your code here\n    int max = 0;\n    for (int i = 0; i < N; i++){\n        int count = 0;\n        for (int j = 0; j < N; j++){\n            if (A[i*N + j] == 1)\n                count += 1;\n        }\n        if (count > max)\n            max = count;\n    }\n    return max;\n}",
            "if (A.empty()) {\n        return 0;\n    }\n\n    /* YOUR CODE GOES HERE */\n    auto sum = std::accumulate(A.begin(), A.end(), 0);\n    return sum;\n}",
            "MPI_Datatype rowtype;\n\tMPI_Type_contiguous(N, MPI_INT, &rowtype);\n\tMPI_Type_commit(&rowtype);\n\n\t// Initialize a vector to hold the sum of all degrees.\n\tstd::vector<int> localdegrees(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tlocaldegrees[i]++;\n\t\t}\n\t}\n\n\t// Compute the max degree.\n\tstd::vector<int> globaldegrees(N, 0);\n\tMPI_Reduce(localdegrees.data(), globaldegrees.data(), N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\t// Return the max degree.\n\tint maxDegree = 0;\n\tif (globaldegrees[0] > 0)\n\t\tmaxDegree = globaldegrees[0];\n\treturn maxDegree;\n}",
            "int max = 0;\n\tstd::vector<int> degs(N, 0);\n\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j]!= 0) {\n\t\t\t\tdegs[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&degs[0], &max, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max;\n}",
            "if (N < 1) {\n    return 0;\n  }\n  int maxDegree = 0;\n  int degree;\n  for (size_t i = 0; i < N; i++) {\n    degree = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        degree++;\n      }\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "if (A.size() == 0) {\n        return 0;\n    }\n\n    std::vector<int> numNeighbors(N, 0);\n\n    // compute number of neighbors for each node on each rank\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                numNeighbors[i]++;\n            }\n        }\n    }\n\n    // compute maximum number of neighbors\n    int max = 0;\n    for (auto n : numNeighbors) {\n        if (n > max) {\n            max = n;\n        }\n    }\n\n    return max;\n}",
            "int degree = 0;\n    for(int i = 0; i < A.size(); i++) {\n        for(int j = 0; j < A[i]; j++) {\n            if (A[i] > degree) degree = A[i];\n        }\n    }\n    return degree;\n}",
            "//TODO\n  int max=0;\n  MPI_Reduce(&A[0],&max,1,MPI_INT,MPI_MAX,0,MPI_COMM_WORLD);\n\n  return max;\n}",
            "// TODO: Add code here\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; ++i) {\n        int degree = 0;\n        for (int j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n\n    return maxDegree;\n}",
            "int maxDegree = 0;\n\n\tif (N == 0)\n\t{\n\t\treturn maxDegree;\n\t}\n\telse\n\t{\n\t\tint rank = 0;\n\t\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\tstd::vector<int> result;\n\t\tstd::vector<int> A_rank(A.begin() + rank * (N/4), A.begin() + (rank + 1) * (N/4));\n\t\tfor (size_t i = 0; i < A_rank.size(); ++i)\n\t\t{\n\t\t\tfor (size_t j = 0; j < A_rank[i].size(); ++j)\n\t\t\t{\n\t\t\t\tif (A_rank[i][j] == 1)\n\t\t\t\t{\n\t\t\t\t\tresult.push_back(1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint result_size = result.size();\n\n\t\tint maxDegree_local = 0;\n\n\t\tfor (int i = 0; i < result_size; ++i)\n\t\t{\n\t\t\tif (result[i] == 1)\n\t\t\t{\n\t\t\t\tmaxDegree_local++;\n\t\t\t}\n\t\t}\n\t\t\n\t\tint maxDegree_global = 0;\n\n\t\tif (rank == 0)\n\t\t{\n\t\t\tfor (int i = 0; i < 4; ++i)\n\t\t\t{\n\t\t\t\tint temp = 0;\n\t\t\t\tMPI_Recv(&temp, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\t\tmaxDegree_global = max(maxDegree_global, temp);\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tMPI_Send(&maxDegree_local, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\t}\n\t\treturn max(maxDegree_global, maxDegree_local);\n\t}\n}",
            "int sum = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t}\n\tint degree;\n\tMPI_Reduce(&sum, &degree, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (degree == 0) {\n\t\treturn 0;\n\t}\n\tif (rank == 0) {\n\t\tint max = A[0];\n\t\tfor(int i = 1; i < N; i++) {\n\t\t\tif (A[i] > max) {\n\t\t\t\tmax = A[i];\n\t\t\t}\n\t\t}\n\t\tint count = 0;\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif (A[i] == max) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\treturn count;\n\t}\n\treturn 0;\n}",
            "auto localDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j]) {\n        localDegree = std::max(localDegree, A[i*N + j]);\n      }\n    }\n  }\n\n  int result = localDegree;\n  MPI_Reduce(&localDegree, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return result;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Status status;\n\n\tint maxDegree = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tmaxDegree = std::max(maxDegree, A[i * N + j]);\n\t\t}\n\t}\n\n\tint globalMaxDegree = maxDegree;\n\tif (size > 1) {\n\t\tMPI_Reduce(&maxDegree, &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t}\n\n\tif (rank == 0) {\n\t\treturn globalMaxDegree;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "// TODO: implement this function\n}",
            "// TODO\n}",
            "int maxDegree = 0;\n  int myMaxDegree = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        myMaxDegree++;\n      }\n    }\n  }\n  int sum;\n  MPI_Reduce(&myMaxDegree, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (sum > maxDegree) {\n    maxDegree = sum;\n  }\n  return maxDegree;\n}",
            "int max = 0;\n    for(int i=0; i<N; i++) {\n        int sum = 0;\n        for(int j=0; j<N; j++) {\n            sum += A[i*N+j];\n        }\n        if(sum>max) {\n            max = sum;\n        }\n    }\n    return max;\n}",
            "/* Your code here. */\n  int local_max = 0;\n  for(int i = 0; i < N; i++)\n  {\n    int count = 0;\n    for(int j = 0; j < N; j++)\n    {\n      if(A[i * N + j] == 1)\n        count++;\n    }\n    local_max = std::max(count, local_max);\n  }\n  \n  int global_max;\n  MPI_Reduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return global_max;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "cuda",
        "prompt": "/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major. Store the result in maxDegree.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\n__global__ void maxDegree(const int *A, size_t N, int *maxDegree) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int j = blockIdx.x;\n    int maxi = 0;\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n        sum += A[i*N + j];\n    }\n    if (sum > maxi)\n        maxi = sum;\n    *maxDegree = maxi;\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint degree = 0;\n\tif (index < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * index + i]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t}\n\t__shared__ int mDegree[256];\n\tint localIndex = threadIdx.x;\n\tmDegree[localIndex] = degree;\n\t__syncthreads();\n\tint stride = blockDim.x / 2;\n\twhile (stride!= 0) {\n\t\tif (localIndex < stride) {\n\t\t\tmDegree[localIndex] = max(mDegree[localIndex], mDegree[localIndex + stride]);\n\t\t}\n\t\t__syncthreads();\n\t\tstride /= 2;\n\t}\n\n\tif (localIndex == 0) {\n\t\tatomicMax(maxDegree, mDegree[0]);\n\t}\n}",
            "// TODO: Compute the max degree of a graph stored in adjacency matrix A.\n\n\tint max_degree = 0;\n\n\tfor (int row = blockIdx.x * blockDim.x + threadIdx.x; row < N; row += blockDim.x * gridDim.x) {\n\t\tfor (int col = 0; col < N; col++) {\n\t\t\tif (A[row * N + col] == 1) {\n\t\t\t\tmax_degree++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max_degree);\n}",
            "//TODO: implement the function.\n\t__shared__ int maxDegree_shared;\n\tif(threadIdx.x == 0)\n\t{\n\t\tmaxDegree_shared = 0;\n\t}\n\t__syncthreads();\n\n\tif(blockIdx.x == 0)\n\t{\n\t\tfor(int i = 0; i < N; i++)\n\t\t{\n\t\t\tint count = 0;\n\t\t\tfor(int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif(A[i*N + j])\n\t\t\t\t\tcount++;\n\t\t\t}\n\n\t\t\tif(count > maxDegree_shared)\n\t\t\t\tmaxDegree_shared = count;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif(blockIdx.x == 0 && threadIdx.x == 0)\n\t{\n\t\t*maxDegree = maxDegree_shared;\n\t}\n}",
            "__shared__ int shared_max[128];\n\n  int max_deg = 0;\n  for (int row = blockIdx.x * blockDim.x + threadIdx.x;\n       row < N; row += blockDim.x * gridDim.x) {\n    int cur_deg = 0;\n    for (int col = 0; col < N; col++)\n      cur_deg += A[row * N + col];\n    if (cur_deg > max_deg)\n      max_deg = cur_deg;\n  }\n\n  int tid = threadIdx.x;\n  int temp = 0;\n  while (tid < 32) {\n    temp = max_deg;\n    __syncthreads();\n    max_deg = max_deg < shared_max[tid]? shared_max[tid] : max_deg;\n    __syncthreads();\n    if (tid < 16)\n      shared_max[tid] = max_deg;\n    __syncthreads();\n    temp = temp < shared_max[tid]? shared_max[tid] : temp;\n    __syncthreads();\n    max_deg = max_deg < shared_max[tid]? shared_max[tid] : max_deg;\n    __syncthreads();\n    if (tid < 8)\n      shared_max[tid] = max_deg;\n    __syncthreads();\n    temp = temp < shared_max[tid]? shared_max[tid] : temp;\n    __syncthreads();\n    max_deg = max_deg < shared_max[tid]? shared_max[tid] : max_deg;\n    __syncthreads();\n    if (tid < 4)\n      shared_max[tid] = max_deg;\n    __syncthreads();\n    temp = temp < shared_max[tid]? shared_max[tid] : temp;\n    __syncthreads();\n    max_deg = max_deg < shared_max[tid]? shared_max[tid] : max_deg;\n    __syncthreads();\n    if (tid < 2)\n      shared_max[tid] = max_deg;\n    __syncthreads();\n    temp = temp < shared_max[tid]? shared_max[tid] : temp;\n    __syncthreads();\n    max_deg = max_deg < shared_max[tid]? shared_max[tid] : max_deg;\n    __syncthreads();\n    if (tid < 1)\n      shared_max[tid] = max_deg;\n    __syncthreads();\n    max_deg = temp < shared_max[tid]? shared_max[tid] : max_deg;\n  }\n\n  if (threadIdx.x == 0)\n    atomicMax(maxDegree, max_deg);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n  int myMax = 0;\n  for (int i = 0; i < N; i++) {\n    myMax += A[index * N + i];\n  }\n  atomicMax(maxDegree, myMax);\n}",
            "// TODO: replace with your code\n\t//\n\t//\n\t//\n\t//\n}",
            "__shared__ int maxDeg[1];\n    maxDeg[0] = 0;\n    __syncthreads();\n    int idx = blockIdx.x;\n    int val = 0;\n    if (idx < N) {\n        for (int i = 0; i < N; i++) {\n            val += A[idx * N + i];\n        }\n    }\n    atomicMax(maxDeg, val);\n    __syncthreads();\n    *maxDegree = maxDeg[0];\n}",
            "int max = 0;\n  int row = blockDim.x * blockIdx.x + threadIdx.x;\n  if(row >= N) {\n    return;\n  }\n  for(int i = 0; i < N; i++) {\n    if(A[row * N + i] == 1) {\n      if(max < i) {\n        max = i;\n      }\n    }\n  }\n  atomicMax(maxDegree, max);\n}",
            "unsigned int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n    __shared__ int s_maxDegree;\n    if(row < N) {\n        int degree = 0;\n        for(unsigned int col = 0; col < N; ++col) {\n            if(A[row + col * N]!= 0) {\n                degree++;\n            }\n        }\n        if(degree > s_maxDegree) {\n            s_maxDegree = degree;\n        }\n    }\n    __syncthreads();\n    if(threadIdx.x == 0) {\n        *maxDegree = s_maxDegree;\n    }\n}",
            "}",
            "int i, j, max = 0;\n\n    for (i = 0; i < N; i++) {\n        for (j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                if (max < j - i) {\n                    max = j - i;\n                }\n            }\n        }\n    }\n    *maxDegree = max;\n}",
            "// TODO: compute the max degree\n    *maxDegree = 0;\n}",
            "int max = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tdegree += A[i + j * N];\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int myMax = 0;\n\n  if (tid < N) {\n    int mySum = 0;\n    for (int j = 0; j < N; j++) {\n      mySum += A[tid * N + j];\n    }\n    if (myMax < mySum) {\n      myMax = mySum;\n    }\n  }\n  atomicMax(maxDegree, myMax);\n}",
            "// TODO\n\tint myId = threadIdx.x;\n\tint myMax = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i * N + myId] > myMax) myMax = A[i * N + myId];\n\t}\n\tmaxDegree[0] = max(myMax, maxDegree[0]);\n}",
            "size_t globalId = blockDim.x * blockIdx.x + threadIdx.x;\n    if (globalId >= N) {\n        return;\n    }\n    int localMaxDegree = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (A[globalId*N + i] == 1) {\n            localMaxDegree++;\n        }\n    }\n    atomicMax(maxDegree, localMaxDegree);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    int localMaxDegree = 0;\n\n    if (tid < N) {\n        for (int i = 0; i < N; i++) {\n            localMaxDegree += A[tid * N + i];\n        }\n    }\n\n    __syncthreads();\n    atomicMax(maxDegree, localMaxDegree);\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int maxVal = 0;\n\n    if (row < N) {\n        for (int i = 0; i < N; i++) {\n            if (A[row * N + i]!= 0)\n                maxVal += 1;\n        }\n    }\n\n    if (maxVal > *maxDegree)\n        *maxDegree = maxVal;\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int sdata[BLOCK_SIZE];\n\tint val = 0;\n\n\tif (row < N) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tval += A[row * N + i];\n\t\t}\n\n\t\tsdata[threadIdx.x] = val;\n\t\t__syncthreads();\n\n\t\tint idx = 0;\n\t\tfor (int i = blockDim.x / 2; i > 0; i /= 2) {\n\t\t\tif (threadIdx.x < i) {\n\t\t\t\tsdata[threadIdx.x] = max(sdata[threadIdx.x], sdata[threadIdx.x + i]);\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\n\t\tif (threadIdx.x == 0) {\n\t\t\tatomicMax(maxDegree, sdata[threadIdx.x]);\n\t\t}\n\t}\n}",
            "}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i < N) {\n    int sum = 0;\n    for (int j = 0; j < N; j++)\n      sum += A[i*N + j];\n    atomicMax(maxDegree, sum);\n  }\n}",
            "int *localMaxDegree = (int *)malloc(sizeof(int));\n\t*localMaxDegree = 0;\n\tint threadId = threadIdx.x;\n\tif(threadId < N) {\n\t\tfor(int i=0; i < N; i++) {\n\t\t\tif(A[threadId*N + i] > 0) {\n\t\t\t\t*localMaxDegree += 1;\n\t\t\t}\n\t\t}\n\t}\n\t*maxDegree = 0;\n\tatomicMax(maxDegree, *localMaxDegree);\n}",
            "const int u = threadIdx.x;\n\tconst int v = u; // no need to check against self\n\tint count = 0;\n\n\tif (A[u*N+v]!= 0)\n\t\tatomicAdd(maxDegree, 1);\n\n}",
            "__shared__ int *Degree;\n\n\t// TODO: allocate a temporary array Degree[N] to store the node degrees.\n\tint *Degree = (int *) malloc(sizeof(int) * N);\n\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tDegree[i] = degree;\n\t}\n\n\t// TODO: Compute the maximum node degree using the array Degree\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tmaxDegree = max(maxDegree, Degree[i]);\n\t}\n\n\t// TODO: Store the maximum node degree in the variable maxDegree\n\t*maxDegree = maxDegree;\n}",
            "int max = 0;\n  int this_degree;\n  for(int i = 0; i < N; i++) {\n    this_degree = 0;\n    for(int j = 0; j < N; j++) {\n      if(A[i*N + j] == 1)\n        this_degree++;\n    }\n    if(this_degree > max)\n      max = this_degree;\n  }\n  *maxDegree = max;\n}",
            "// TODO\n    unsigned int globalID = blockDim.x*blockIdx.x + threadIdx.x;\n    __shared__ int localMax[1];\n    localMax[0] = 0;\n\n    if (globalID < N){\n        int temp = 0;\n        for (int i = 0; i < N; i++){\n            temp += A[globalID*N + i];\n        }\n        localMax[0] = temp;\n    }\n    __syncthreads();\n\n    // localMax[0] is now the max\n    if (blockDim.x > 1){\n        unsigned int offset = blockDim.x / 2;\n        while (offset!= 0){\n            __syncthreads();\n            if (threadIdx.x < offset){\n                if (localMax[threadIdx.x + offset] > localMax[threadIdx.x])\n                    localMax[threadIdx.x] = localMax[threadIdx.x + offset];\n            }\n            offset /= 2;\n        }\n    }\n\n    if (threadIdx.x == 0){\n        atomicMax(maxDegree, localMax[0]);\n    }\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) degree++;\n\t\t}\n\t\tif (degree > *maxDegree) *maxDegree = degree;\n\t}\n}",
            "}",
            "int max = 0;\n  int node = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Check if we're still in the array bounds, otherwise exit this thread\n  if (node < N) {\n    int local_max = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[node * N + i] == 1)\n        local_max++;\n    }\n    atomicMax(&max, local_max);\n  }\n  *maxDegree = max;\n}",
            "int max = 0;\n  int i, j, n = N;\n\n  if (blockDim.x > N) {\n    n = blockDim.x;\n  }\n\n  for (i = threadIdx.x; i < n; i += blockDim.x) {\n    for (j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        atomicMax(&max, __ldg(&A[i * N + j]));\n      }\n    }\n  }\n\n  atomicMax(&max, max);\n  atomicMax(maxDegree, max);\n}",
            "__shared__ int partial_maxDegree[256];\n  partial_maxDegree[threadIdx.x] = 0;\n  __syncthreads();\n\n  int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id < N) {\n    int row = id;\n    for (int col = 0; col < N; col++) {\n      if (A[row * N + col] > 0) {\n        atomicMax(&partial_maxDegree[threadIdx.x], 1);\n      }\n    }\n  }\n\n  // Reduce in shared memory\n  for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n    __syncthreads();\n    if (threadIdx.x < s)\n      atomicMax(&partial_maxDegree[threadIdx.x], partial_maxDegree[threadIdx.x + s]);\n  }\n\n  // Write result for this block to global memory\n  if (threadIdx.x == 0)\n    atomicMax(maxDegree, partial_maxDegree[0]);\n}",
            "__shared__ int sharedMem[BLOCKSIZE];\n    // Each thread in the block has a node ID, the ID of the thread is its node ID\n    int node = threadIdx.x;\n\n    // Initialize the degree of the current node to zero\n    int deg = 0;\n\n    // Traverse the elements of the row of the current node\n    for (int j = 0; j < N; j++) {\n        // Get the value of the current node's adjacency matrix\n        int value = A[node * N + j];\n        // Add the number of neighbors with a non-zero value to the current node's degree\n        deg += value;\n    }\n\n    // Get the location of the current node in the shared memory and store the current node's degree\n    sharedMem[threadIdx.x] = deg;\n\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        // Get the degree of the current node's degree in the shared memory\n        int maxDegree = sharedMem[0];\n\n        for (int i = 0; i < BLOCKSIZE; i++) {\n            if (sharedMem[i] > maxDegree) {\n                maxDegree = sharedMem[i];\n            }\n        }\n        // Write the maximum value of the current node to the global memory\n        atomicMax(maxDegree, maxDegree);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint d = 0;\n\n\tif (i < N) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\td += A[i*N + j];\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, d);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx >= N) {\n\t\treturn;\n\t}\n\n\tint degree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[idx * N + i]!= 0) {\n\t\t\tdegree++;\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, degree);\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i >= N) return;\n\n\tint degree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tdegree += A[i * N + j];\n\t}\n\tatomicMax(maxDegree, degree);\n}",
            "// TODO: Implement\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n\tif(id >= N) return;\n\tint d = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\td += A[id * N + i];\n\t}\n\tatomicMax(maxDegree, d);\n}",
            "int i = blockDim.x*blockIdx.x + threadIdx.x;\n    int max = 0;\n    if (i < N) {\n\tfor (int j = 0; j < N; j++) {\n\t    if (A[i*N + j] > max) {\n\t\tmax = A[i*N + j];\n\t    }\n\t}\n    }\n    atomicMax(maxDegree, max);\n}",
            "// TODO: compute the highest node degree in the graph.\n\n    int idx = blockDim.x * blockIdx.x + threadIdx.x;\n    int degree = 0;\n    if (idx < N)\n    {\n        for (int i = 0; i < N; i++)\n        {\n            if (A[idx*N + i] == 1)\n                degree++;\n        }\n\n        atomicMax(maxDegree, degree);\n    }\n}",
            "}",
            "__shared__ int maxDegreeShared;\n\tint thread_id = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (thread_id >= N) return;\n\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i*N + thread_id]!= 0) {\n\t\t\tdegree++;\n\t\t}\n\t}\n\n\tif (degree > maxDegreeShared) {\n\t\tmaxDegreeShared = degree;\n\t}\n\n\t__syncthreads();\n\n\tatomicMax(maxDegree, maxDegreeShared);\n}",
            "// Add code here\n\tint i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint localMaxDegree = 0;\n\tint tmp = 0;\n\tfor(int j=0; j<N; j++) {\n\t\ttmp += A[i*N+j];\n\t}\n\tif(tmp>localMaxDegree) localMaxDegree = tmp;\n\tatomicMax(maxDegree, localMaxDegree);\n}",
            "// TODO: your code here\n}",
            "int i = threadIdx.x; // which vertex to process?\n\n    // TODO\n    __shared__ int s_maxDegree;\n    int maxDegree_t = 0;\n    for (int j = 0; j < N; j++)\n        maxDegree_t += A[i * N + j];\n    maxDegree_t = max(maxDegree_t, 1);\n    if (threadIdx.x == 0) {\n        atomicMax(&s_maxDegree, maxDegree_t);\n    }\n    __syncthreads();\n    if (threadIdx.x == 0) {\n        atomicMax(maxDegree, s_maxDegree);\n    }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint max = 0;\n\t\n\tfor (int i = 0; i < N; i++) {\n\t\tmax += A[i*N + idx];\n\t}\n\t\n\tatomicMax(maxDegree, max);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(tid < N) {\n\t\tint degree = 0;\n\t\tfor(int i = 0; i < N; i++)\n\t\t\tdegree += A[tid * N + i];\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myDegree = 0;\n\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + tid] > 0) {\n\t\t\t\tmyDegree++;\n\t\t\t}\n\t\t}\n\n\t\tatomicMax(maxDegree, myDegree);\n\t}\n}",
            "// TODO\n}",
            "}",
            "// TODO\n\n}",
            "int max_degree = 0;\n  int cur_degree = 0;\n  int cur_index = 0;\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index >= N)\n    return;\n  while (cur_index < N) {\n    if (A[index * N + cur_index] == 1)\n      cur_degree++;\n    cur_index++;\n  }\n  cur_index = 0;\n  while (cur_index < N) {\n    if (A[cur_index * N + index] == 1)\n      cur_degree++;\n    cur_index++;\n  }\n  if (cur_degree > max_degree)\n    max_degree = cur_degree;\n  atomicAdd(maxDegree, max_degree);\n}",
            "int maxDegree_local = 0;\n\n\t// TODO: Your code here\n\n\t__syncthreads();\n\n\tif(threadIdx.x == 0){\n\t\tatomicMax(maxDegree, maxDegree_local);\n\t}\n}",
            "// TODO\n}",
            "// use an atomic compare-exchange to prevent data races\n  // the maximum degree of any node can be found by finding the maximum of the row-sums of A\n  // use atomicAdd to avoid a data race between the threads\n  // use a thread local value to cache the row-sum and add it to the global value when the kernel finishes\n  __shared__ int threadLocalMax;\n  int threadRowSum = 0;\n  int globalRowSum = 0;\n\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row < N) {\n    for (int col = 0; col < N; col++) {\n      threadRowSum += A[row * N + col];\n    }\n    atomicAdd(maxDegree, threadRowSum);\n    threadLocalMax = threadRowSum;\n  }\n\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicMax(maxDegree, threadLocalMax);\n  }\n}",
            "// Replace this with your implementation\n    int localMax = 0;\n    for (int i = 0; i < N; i++)\n    {\n        int rowSum = 0;\n        for (int j = 0; j < N; j++)\n        {\n            rowSum += A[i*N + j];\n        }\n        if (rowSum > localMax)\n        {\n            localMax = rowSum;\n        }\n    }\n    atomicMax(maxDegree, localMax);\n}",
            "int max = 0;\n\n\tint row_idx = threadIdx.x;\n\n\t// check whether the row_idx is valid\n\tif (row_idx < N) {\n\t\t// sum up all elements in the row\n\t\tint sum = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tsum += A[row_idx * N + i];\n\t\t}\n\t\t// if the sum is greater than the previous maximum, update\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\t// store the maximum value in the memory location pointed by maxDegree\n\tatomicMax(maxDegree, max);\n}",
            "__shared__ int localMax;\n\n\t// Set localMax to 0\n\tif (threadIdx.x == 0) {\n\t\tlocalMax = 0;\n\t}\n\n\t// Wait for all threads\n\t__syncthreads();\n\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[blockIdx.x * N + i] > 0) {\n\t\t\tdegree += 1;\n\t\t}\n\t}\n\n\t// Save the degree into localMax. If there is a tie, the last value to be stored wins\n\tif (threadIdx.x == 0) {\n\t\tatomicMax(&localMax, degree);\n\t}\n\n\t// Wait for all threads\n\t__syncthreads();\n\n\t// Set maxDegree to localMax\n\tif (threadIdx.x == 0) {\n\t\t*maxDegree = localMax;\n\t}\n}",
            "// Get the ID of the current thread.\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (tid < N) {\n        // The ID of this thread is within the range of the matrix.\n        int max_count = 0;\n        for (int i = 0; i < N; ++i) {\n            max_count = A[tid * N + i] > 0? max_count + 1 : max_count;\n        }\n        maxDegree[tid] = max_count;\n    }\n}",
            "int idx = threadIdx.x;\n\n\t__shared__ int localMaxDegree;\n\n\t// find the maximum degree in this row\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[idx * N + i]!= 0) {\n\t\t\tdegree++;\n\t\t}\n\t}\n\n\t// store the maximum degree in the shared memory\n\tif (idx == 0) {\n\t\tlocalMaxDegree = degree;\n\t}\n\t__syncthreads();\n\n\t// find the maximum degree in the shared memory\n\tif (idx == 0 && degree > localMaxDegree) {\n\t\tlocalMaxDegree = degree;\n\t}\n\t__syncthreads();\n\n\t// find the maximum degree in the block\n\tif (idx == 0) {\n\t\tatomicMax(maxDegree, localMaxDegree);\n\t}\n}",
            "int n = blockDim.x * blockIdx.x + threadIdx.x;\n\tint tmp = 0;\n\n\t//int tmp = A[n*N + n];\n\t//for(int i=0; i<N; i++){\n\t//\ttmp += A[n*N + i];\n\t//}\n\n\t// for each vertex, for each neighbor, increment by 1\n\tfor(int i=0; i<N; i++){\n\t\tif(A[n*N + i] == 1){\n\t\t\ttmp++;\n\t\t}\n\t}\n\n\t// atomic add to avoid race conditions\n\tatomicAdd(maxDegree, tmp);\n}",
            "// TODO: implement this function\n    // Use an atomicMax() to update the *maxDegree value\n    // If the value in A at position (i, j) is 1, you should increase the degree of node i by 1\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint curDegree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] > 0) {\n\t\t\t\tcurDegree++;\n\t\t\t}\n\t\t}\n\t\t*maxDegree = max(*maxDegree, curDegree);\n\t}\n}",
            "const size_t id = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (id >= N)\n\t\treturn;\n\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tdegree += A[id * N + i];\n\n\tatomicMax(maxDegree, degree);\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n\tint degree = 0;\n\n\tif (id < N) {\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[id * N + j]!= 0)\n\t\t\t\tdegree++;\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "int index = blockDim.x * blockIdx.x + threadIdx.x;\n    if (index >= N) return;\n    int degree = 0;\n    for (int i = 0; i < N; i++)\n        degree += A[index * N + i];\n    if (degree > *maxDegree)\n        *maxDegree = degree;\n}",
            "// TODO\n}",
            "// TODO: Compute the maximum degree in A and store the result in maxDegree.\n\t// You can use atomicMax to set the maxDegree in parallel\n}",
            "int maxDegree = 0;\n\n  for (int j = 0; j < N; j++) {\n    maxDegree = max(maxDegree, __popc(A[j]));\n  }\n\n  *maxDegree = maxDegree;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N) return;\n\n\tint sum = 0;\n\tfor (int j = 0; j < N; ++j) {\n\t\tsum += A[i * N + j];\n\t}\n\tint max_tmp = atomicMax(maxDegree, sum);\n}",
            "int row = blockIdx.x;\n  int max = 0;\n  for(int i = row * N; i < row * N + N; i++){\n    int degree = A[i];\n    if(max < degree){\n      max = degree;\n    }\n  }\n  if(row == 0){\n    *maxDegree = max;\n  }\n}",
            "unsigned int row = blockIdx.x * blockDim.x + threadIdx.x;\n  if(row >= N) return;\n  int degree = 0;\n  for(int col = 0; col < N; col++) {\n    degree += A[row * N + col];\n  }\n  if(threadIdx.x == 0) atomicMax(maxDegree, degree);\n}",
            "// Get the thread id\n\tint tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// Check if the thread id is valid\n\tif (tid >= N) {\n\t\treturn;\n\t}\n\n\t// Get the node degree\n\tint nodeDegree = A[tid * N + tid];\n\tint max = 0;\n\tfor (int i = tid + 1; i < N; i++) {\n\t\tint degree = A[tid * N + i];\n\t\tif (degree > nodeDegree) {\n\t\t\tmax = i;\n\t\t\tnodeDegree = degree;\n\t\t}\n\t}\n\n\t// Atomic max\n\tatomicMax(maxDegree, nodeDegree);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(id < N) {\n\t\tint deg = 0;\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(A[id*N + i] == 1) deg++;\n\t\t}\n\t\tif(deg > *maxDegree) {\n\t\t\t*maxDegree = deg;\n\t\t}\n\t}\n}",
            "int m = threadIdx.x;\n  int degree = 0;\n  for (int i = 0; i < N; i++) {\n    if (A[i * N + m] == 1) {\n      degree++;\n    }\n  }\n  atomicMax(maxDegree, degree);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = 0;\n    int temp;\n    int tempSum;\n    __shared__ int maxDegree_shared[1000];\n    maxDegree_shared[threadIdx.x] = 0;\n    __syncthreads();\n    if (i < N) {\n        tempSum = 0;\n        for (j = 0; j < N; j++) {\n            temp = A[i + N * j];\n            tempSum = tempSum + temp;\n        }\n        maxDegree_shared[threadIdx.x] = tempSum;\n        __syncthreads();\n\n        while (1) {\n            if (threadIdx.x == 0) {\n                tempSum = 0;\n                for (j = 0; j < blockDim.x; j++) {\n                    tempSum = tempSum + maxDegree_shared[j];\n                }\n                maxDegree_shared[0] = tempSum;\n            }\n            __syncthreads();\n\n            if (blockDim.x <= 1) {\n                break;\n            }\n            blockDim.x = blockDim.x / 2 + blockDim.x % 2;\n        }\n\n        if (threadIdx.x == 0) {\n            maxDegree[0] = maxDegree_shared[0];\n        }\n    }\n}",
            "size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i >= N) {\n\t\treturn;\n\t}\n\tint current = A[i];\n\n\tfor (int j = 0; j < N; j++) {\n\t\tint next = A[j*N + i];\n\t\tcurrent += next;\n\t}\n\tatomicMax(maxDegree, current);\n}",
            "int max = 0;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                max = max + 1;\n            }\n        }\n        atomicMax(maxDegree, max);\n    }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid >= N) return;\n    __shared__ int max_so_far;\n    __shared__ int temp;\n\n    if (tid == 0) max_so_far = -1;\n\n    __syncthreads();\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n        sum += A[tid * N + i];\n    }\n    temp = sum;\n\n    __syncthreads();\n    while (blockDim.x!= 1) {\n        __syncthreads();\n        int temp2 = __shfl_sync(0xffffffff, temp, 0, blockDim.x);\n        if (temp > max_so_far) {\n            max_so_far = temp;\n        }\n        if (blockDim.x > 1) {\n            temp = max_so_far;\n        }\n        blockDim.x = blockDim.x / 2;\n    }\n    if (temp > max_so_far) {\n        max_so_far = temp;\n    }\n    if (tid == 0) {\n        *maxDegree = max_so_far;\n    }\n}",
            "__shared__ int sMax[1];\n\tint i = blockIdx.x*blockDim.x+threadIdx.x;\n\tif (i<N){\n\t\tint degree = 0;\n\t\tfor (int j=0; j<N; j++) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (degree>sMax[0])\n\t\t\tsMax[0] = degree;\n\t}\n\t__syncthreads();\n\tfor (int j=blockDim.x/2; j>0; j>>=1) {\n\t\tif (threadIdx.x < j)\n\t\t\tsMax[0] = max(sMax[0], sMax[0]);\n\t\t__syncthreads();\n\t}\n\tif (threadIdx.x==0)\n\t\t*maxDegree = sMax[0];\n}",
            "int max = 0;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = i+1;\n    if (i < N && j < N) {\n        max = A[i*N + j];\n    }\n    __syncthreads();\n\n    if(i >= N || j >= N) {\n        return;\n    }\n\n    for(int k = blockDim.x/2; k > 0; k >>= 1) {\n        if(threadIdx.x < k) {\n            if(max < A[j*N + k]) {\n                max = A[j*N + k];\n            }\n        }\n        __syncthreads();\n    }\n\n    if(threadIdx.x == 0) {\n        atomicMax(maxDegree, max);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int max = 0;\n  if (i < N) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        max++;\n      }\n    }\n    atomicMax(maxDegree, max);\n  }\n}",
            "}",
            "int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n  int degree;\n\n  if(threadId < N) {\n    degree = 0;\n    for(int i = 0; i < N; i++) {\n      degree += A[threadId * N + i];\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "__shared__ int localMaxDegree;\n  __shared__ int count;\n\n  localMaxDegree = 0;\n  count = 0;\n\n  // Compute the localMaxDegree\n  for (int i = threadIdx.x; i < N; i += blockDim.x) {\n    int value = 0;\n\n    for (int j = 0; j < N; j++) {\n      value += A[i * N + j];\n    }\n\n    if (value > localMaxDegree) {\n      localMaxDegree = value;\n    }\n\n    count++;\n  }\n\n  __syncthreads();\n\n  // Find the maximum among all localMaxDegree\n  for (int s = 1; s < blockDim.x; s *= 2) {\n    if (threadIdx.x % (2 * s) == 0 && threadIdx.x + s < count) {\n      if (A[threadIdx.x + s] > localMaxDegree) {\n        localMaxDegree = A[threadIdx.x + s];\n      }\n    }\n\n    __syncthreads();\n  }\n\n  // Store the globalMaxDegree\n  if (threadIdx.x == 0) {\n    *maxDegree = localMaxDegree;\n  }\n}",
            "int myId = blockIdx.x * blockDim.x + threadIdx.x;\n    int myMax = 0;\n    for(int i = 0; i < N; i++) {\n      myMax = myMax + A[i * N + myId];\n    }\n    atomicMax(maxDegree, myMax);\n}",
            "int idx = threadIdx.x;\n    __shared__ int result[32];\n    result[idx] = 0;\n    __syncthreads();\n    for (int i = idx; i < N; i += blockDim.x)\n    {\n        int count = 0;\n        for (int j = 0; j < N; j++)\n        {\n            if (A[i*N + j] > 0) count++;\n        }\n        atomicMax(&result[idx], count);\n    }\n    __syncthreads();\n    int max = 0;\n    for (int i = 0; i < blockDim.x; i++)\n    {\n        if (result[i] > max) max = result[i];\n    }\n    __syncthreads();\n    if (idx == 0) *maxDegree = max;\n}",
            "int idx = threadIdx.x;\n    __shared__ int max;\n    if(idx == 0) {\n        max = 0;\n    }\n    __syncthreads();\n\n    int sum = 0;\n    for(int i = idx; i < N*N; i+=blockDim.x) {\n        sum += A[i];\n    }\n    atomicAdd(&max, sum);\n    __syncthreads();\n\n    if(idx == 0) {\n        *maxDegree = max;\n    }\n}",
            "int tid = threadIdx.x;\n  extern __shared__ int sData[];\n  int localMax = 0;\n\n  // Initialize the local maximum to zero for each thread.\n  sData[tid] = 0;\n  __syncthreads();\n\n  // Loop over the rows in the adjacency matrix.\n  for (int row = tid; row < N; row += blockDim.x) {\n    int sum = 0;\n\n    // Loop over the column of the adjacency matrix, and sum up the elements.\n    for (int col = 0; col < N; col++) {\n      if (A[row*N + col] == 1) {\n        sum++;\n      }\n    }\n\n    // Update the local maximum if the sum is greater than the current local maximum.\n    if (sum > localMax) {\n      localMax = sum;\n    }\n  }\n\n  // Block-Reduce to get the maximum of each thread.\n  __syncthreads();\n\n  // If this is the first thread, update maxDegree with the maximum degree.\n  if (tid == 0) {\n    atomicMax(maxDegree, localMax);\n  }\n}",
            "int max = -1;\n\tint threadId = threadIdx.x;\n\n\t// TODO: Compute the maximum degree\n\n\tif (maxDegree[0] < max) {\n\t\tmaxDegree[0] = max;\n\t}\n}",
            "__shared__ int shared_degree[1];\n\n  int i = threadIdx.x;\n  int thread_degree = 0;\n\n  while (i < N) {\n    if (A[i*N + i] == 1)\n      thread_degree += 1;\n    i += blockDim.x;\n  }\n\n  if (threadIdx.x == 0) {\n    shared_degree[0] = 0;\n  }\n\n  __syncthreads();\n  atomicAdd(shared_degree, thread_degree);\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicMax(maxDegree, shared_degree[0]);\n  }\n\n}",
            "int tid = blockDim.x*blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\t// your code here\n\t}\n}",
            "// TODO\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (tid >= N) {\n\t\treturn;\n\t}\n\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += A[tid * N + i];\n\t}\n\tatomicMax(maxDegree, sum);\n}",
            "// Your code here\n    int i = threadIdx.x;\n    __shared__ int local_max_degree;\n    local_max_degree = 0;\n    __syncthreads();\n    for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n            local_max_degree++;\n        }\n    }\n    atomicMax(&local_max_degree, local_max_degree);\n    __syncthreads();\n    *maxDegree = local_max_degree;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    int maxDeg = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[N * i + j] > 0) {\n        maxDeg++;\n      }\n    }\n    atomicMax(maxDegree, maxDeg);\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N) {\n        int deg = 0;\n        for (int i = 0; i < N; i++) {\n            deg += A[tid + i * N];\n        }\n        atomicMax(maxDegree, deg);\n    }\n}",
            "// Compute the index of the thread\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  // Compute the highest degree\n  int d = 0;\n  for (int j = 0; j < N; j++)\n    d += A[i * N + j];\n  // Save the result\n  if (d > *maxDegree)\n    *maxDegree = d;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        int rowMax = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]!= 0) {\n                rowMax++;\n            }\n        }\n        atomicMax(maxDegree, rowMax);\n    }\n}",
            "__shared__ int sDegree[BLOCK_SIZE];\n    int localMaxDegree = 0;\n\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = 0;\n\n    for (int i = 0; i < N; i++) {\n        col = i * N + row;\n        if (A[col] > 0) localMaxDegree++;\n    }\n\n    sDegree[threadIdx.x] = localMaxDegree;\n    __syncthreads();\n\n    for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n        if (threadIdx.x < stride) {\n            sDegree[threadIdx.x] = max(sDegree[threadIdx.x], sDegree[threadIdx.x + stride]);\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0)\n        atomicMax(maxDegree, sDegree[0]);\n}",
            "int maxDegree = 0;\n    for (int i = 0; i < N; i++) {\n        int nodeDegree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] > 0)\n                nodeDegree++;\n        }\n        if (nodeDegree > maxDegree)\n            maxDegree = nodeDegree;\n    }\n    *maxDegree = maxDegree;\n}",
            "/* Compute the thread index */\n  int index = threadIdx.x;\n\n  /* The maximum number of neighbors */\n  int max = 0;\n\n  /* If the thread index is valid, compute the number of neighbors */\n  if (index < N) {\n    int i, j;\n    int degree = 0;\n\n    /* Iterate over the rows of the adjacency matrix and count the neighbors */\n    for (i = 0; i < N; i++) {\n      int n = A[i * N + index];\n      if (n > 0) {\n        degree++;\n      }\n    }\n\n    /* If this vertex has the highest degree seen so far, update the maximum */\n    if (degree > max) {\n      max = degree;\n    }\n  }\n\n  /* Store the maximum degree in global memory */\n  *maxDegree = max;\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tif (A[idx * N + i]!= 0)\n\t\t\t\tdegree++;\n\t\tmaxDegree[0] = max(maxDegree[0], degree);\n\t}\n}",
            "int max = 0;\n  int i = threadIdx.x;\n  while(i < N) {\n    int sum = 0;\n    int j = 0;\n    while(j < N) {\n      sum += A[i * N + j];\n      j++;\n    }\n    if(sum > max) {\n      max = sum;\n    }\n    i++;\n  }\n  *maxDegree = max;\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i < N) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\t*maxDegree = max(*maxDegree, sum);\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint max = 0;\n\tfor (int i = tid; i < N; i += stride) {\n\t\tint cur = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tcur += A[i * N + j];\n\t\t}\n\t\tif (cur > max) {\n\t\t\tmax = cur;\n\t\t}\n\t}\n\tif (max > *maxDegree) {\n\t\t*maxDegree = max;\n\t}\n}",
            "int maxDeg = 0;\n\tint i = blockIdx.x;\n\tint rowLength = N * sizeof(int);\n\tint *row = (int *) malloc(rowLength);\n\tif(i >= N) {\n\t\treturn;\n\t}\n\tcudaMemcpy(row, A + i * N, rowLength, cudaMemcpyDeviceToHost);\n\tfor(int j = 0; j < N; j++) {\n\t\tmaxDeg = max(maxDeg, row[j]);\n\t}\n\t*maxDegree = max(*maxDegree, maxDeg);\n}",
            "int index = threadIdx.x;\n\tint degree = 0;\n\tif (index < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[index * N + j] == 1) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicMax(maxDegree, degree);\n}",
            "int max = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i*N+j]!= 0) {\n\t\t\t\tatomicMax(&max, 1);\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "int max = 0;\n    for (int i = 0; i < N; ++i) {\n        int sum = 0;\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0)\n                sum++;\n        }\n        if (sum > max)\n            max = sum;\n    }\n    *maxDegree = max;\n}",
            "// TODO\n\n\t// **********************************************************************\n\t//   YOU CODE BEGIN HERE\n\n\n\n\n\n\n\n\n\n\n\n\t//   YOU CODE END HERE\n\t// **********************************************************************\n}",
            "// TODO\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint max = 0;\n\t\n\tif(tid < N) {\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tif(A[tid*N+i] > 0) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "// TODO: Compute the highest node degree in the graph\n\t\n\tint i = blockIdx.x;\n\tint j = threadIdx.x;\n\n\tif (i == j) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[k * N + j]!= 0) {\n\t\t\t\tatomicMax(maxDegree, A[k * N + j]);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tif(i < N) {\n\t\tint cur_degree = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N+j]!= 0) {\n\t\t\t\tcur_degree++;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, cur_degree);\n\t}\n}",
            "// TODO: Implement me\n}",
            "}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint value = 0;\n\tint max = 0;\n\t\n\t// Loop through the matrix until we find the row in which the current index is located\n\tfor (int i = 0; i < N; i++) {\n\t\tvalue = A[i * N + index];\n\t\tif (value == 1)\n\t\t\tmax++;\n\t}\n\t\n\tatomicMax(maxDegree, max);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif(id < N) {\n\n\t\tint degree = 0;\n\t\tint i = id;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\n\t\tif(degree > *maxDegree) {\n\t\t\t*maxDegree = degree;\n\t\t}\n\n\t}\n\n}",
            "// TODO\n    int id = threadIdx.x;\n    __shared__ int row[MAX_N];\n    for (int i = 0; i < N; i++) {\n        row[i] = A[i*N + id];\n    }\n    __syncthreads();\n\n    int max = 0;\n    for (int i = 0; i < N; i++) {\n        if (row[i] > max)\n            max = row[i];\n    }\n    maxDegree[0] = max;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N) {\n\t\treturn;\n\t}\n\n\tint curDegree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i * N + j] > 0) {\n\t\t\tcurDegree++;\n\t\t}\n\t}\n\n\t// Use atomic functions to update maxDegree in a thread safe manner.\n\tif (atomicMax(maxDegree, curDegree) < curDegree) {\n\t\t*maxDegree = curDegree;\n\t}\n}",
            "int max = 0;\n\tint row = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (row < N){\n\t\tfor (int col=0; col < N; col++){\n\t\t\tif (A[row*N + col] == 1){\n\t\t\t\tif (max < col){\n\t\t\t\t\tmax = col;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tatomicMax(maxDegree, max);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int degree = 0;\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    atomicMax(maxDegree, degree);\n  }\n}",
            "int i = threadIdx.x;\n\tint m = 0;\n\tfor (size_t j = 0; j < N; j++) {\n\t\tm = (m > A[i + N * j])? m : A[i + N * j];\n\t}\n\n\tatomicMax(maxDegree, m);\n}",
            "int idx = threadIdx.x;\n\tint stride = blockDim.x;\n\n\tint max_degree = 0;\n\tfor (int i = idx; i < N; i += stride) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tmax_degree = max(sum, max_degree);\n\t}\n\n\tatomicMax(maxDegree, max_degree);\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  if (idx < N) {\n    int degree = 0;\n    for (int i = 0; i < N; i++)\n      degree += A[idx*N+i];\n    maxDegree[0] = max(maxDegree[0], degree);\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = 0;\n\tint max = 0;\n\tif(i < N) {\n\t\tfor(j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tmax += 1;\n\t\t\t}\n\t\t}\n\t}\n\tif (threadIdx.x == 0) {\n\t\t*maxDegree = max;\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int degree = 0;\n    for (int i = 0; i < N; i++) {\n        degree += A[id * N + i];\n    }\n    atomicMax(maxDegree, degree);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N) return;\n\n\tint degree = 0;\n\tfor (int j = 0; j < N; ++j) {\n\t\tif (A[i * N + j] > 0) {\n\t\t\t++degree;\n\t\t}\n\t}\n\n\t// TODO: Implement the kernel to compute the maximum degree\n\t// Note: This kernel should be thread safe as multiple threads may try to write the same location\n\t// Use atomicMax() to atomically write to the location\n}",
            "// TODO\n}",
            "int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (threadID < N) {\n\t\tint i = 0;\n\t\tfor (; i < N; i++) {\n\t\t\tif (A[threadID * N + i]) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (i == N) {\n\t\t\t*maxDegree = 0;\n\t\t}\n\t\t*maxDegree = max(i, *maxDegree);\n\t}\n}",
            "const int i = blockIdx.x*blockDim.x+threadIdx.x;\n\n\tint degree = 0;\n\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[j*N+i] == 1) degree++;\n\t}\n\n\tatomicMax(maxDegree, degree);\n}",
            "int id = threadIdx.x;\n  int max = 0;\n  for(int i=id;i<N;i+=blockDim.x){\n    int j = 0;\n    for(;j<N;j++){\n      if(A[i*N + j]){\n        break;\n      }\n    }\n    if(j == N){\n      max = 0;\n      break;\n    }\n    if(max < j){\n      max = j;\n    }\n  }\n  maxDegree[0] = max;\n}",
            "/* Declare shared memory for the block. */\n  __shared__ int max[THREADS_PER_BLOCK];\n\n  /* Compute the maximum of the row. */\n  int rowMax = 0;\n  for (int i = threadIdx.x; i < N; i += blockDim.x) {\n    int a = A[i * N + threadIdx.x];\n    if (a > rowMax) rowMax = a;\n  }\n\n  /* Find the maximum of the row among all threads in the block. */\n  for (int i = 0; i < blockDim.x / 2; i++) {\n    if (i == 0) {\n      max[threadIdx.x] = rowMax;\n    } else {\n      if (threadIdx.x % 2 == 0 && threadIdx.x + i < blockDim.x) {\n        if (max[threadIdx.x + i] > max[threadIdx.x]) {\n          max[threadIdx.x] = max[threadIdx.x + i];\n        }\n      }\n    }\n    __syncthreads();\n  }\n\n  /* Find the maximum of all the rows among all blocks. */\n  if (blockIdx.x == 0 && threadIdx.x == 0) {\n    for (int i = 1; i < gridDim.x; i++) {\n      if (max[i] > max[0]) {\n        max[0] = max[i];\n      }\n    }\n    *maxDegree = max[0];\n  }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index >= N) {\n        return;\n    }\n\n    // Initialize max degree to the first element in the row\n    int max_degree = A[index * N];\n    // Iterate over the row and find the max degree\n    for (int i = 1; i < N; i++) {\n        if (A[index * N + i] > max_degree) {\n            max_degree = A[index * N + i];\n        }\n    }\n\n    // Store the max degree in shared memory\n    maxDegree[0] = max_degree;\n}",
            "}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n\tint max = 0;\n\n\tif (id < N) {\n\t\tint i = 0;\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (A[i * N + id] == 1) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int localMax = 0;\n\n  // your code here.\n\n  // Update the global maximum.\n  // Use atomicAdd to avoid multiple threads updating the same location.\n  atomicMax(maxDegree, localMax);\n}",
            "int id = threadIdx.x;\n    extern __shared__ int shm[];\n    int i = id;\n    int j = 0;\n    shm[id] = 0;\n\n    while (i < N) {\n        j = 0;\n        while (j < N) {\n            if (A[i + j * N]!= 0) {\n                atomicAdd(&shm[id], 1);\n            }\n            j++;\n        }\n        i += blockDim.x;\n    }\n    __syncthreads();\n\n    int iMax = 1;\n    for (int i = 1; i < blockDim.x; i++) {\n        if (shm[i] > shm[iMax]) {\n            iMax = i;\n        }\n    }\n\n    if (id == 0) {\n        atomicMax(maxDegree, shm[iMax]);\n    }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int jdx;\n    int d = 0;\n    for (jdx = 0; jdx < N; ++jdx) {\n        if (A[idx + N * jdx]!= 0) d++;\n    }\n    atomicMax(maxDegree, d);\n}",
            "// TODO\n\tint value = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tvalue++;\n\t\t\t}\n\t\t}\n\t}\n\tif (value > maxDegree[0])\n\t\tmaxDegree[0] = value;\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint max = 0;\n\tif (id < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[id * N + i]!= 0) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicMax(maxDegree, max);\n}",
            "int max = 0;\n    int curr = 0;\n    int row = blockIdx.x*blockDim.x + threadIdx.x;\n    if (row >= N) return;\n    for (int i=0; i<N; ++i) {\n        if (A[row*N+i] == 1) {\n            curr++;\n        }\n    }\n    atomicMax(&max, curr);\n\n    // write the result\n    if (threadIdx.x == 0) {\n        *maxDegree = max;\n    }\n}",
            "// TODO: Insert your code here.\n\n    // Initialize with default value\n    int myMaxDegree = 0;\n\n    // Compute max degree in parallel\n    for(int i = 0; i < N; i++) {\n        int d = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) d++;\n        }\n\n        myMaxDegree = max(myMaxDegree, d);\n    }\n\n    // Assign to the output variable, maxDegree\n    atomicMax(maxDegree, myMaxDegree);\n}",
            "int thread_id = threadIdx.x + blockIdx.x*blockDim.x;\n  if (thread_id < N) {\n    // Implement in parallel\n    int row = 0;\n    int max = A[row * N + thread_id];\n    for(int i = 1; i < N; i++)\n      if(A[i * N + thread_id] > max)\n        max = A[i * N + thread_id];\n    maxDegree[thread_id] = max;\n  }\n}",
            "int i = threadIdx.x;\n\tint value = A[i * N + i];\n\tint rowSum = 0;\n\t\n\tfor (int j = i + 1; j < N; j++) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\trowSum++;\n\t\t}\n\t}\n\t\n\tif (rowSum > value) {\n\t\tatomicMax(maxDegree, rowSum);\n\t}\n}",
            "int max = 0;\n\tfor (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tmax++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicMax(maxDegree, max);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  if (tid < N) {\n    int current_degree = 0;\n    for (int i = 0; i < N; ++i) {\n      if (A[i * N + tid] == 1) {\n        current_degree++;\n      }\n    }\n    if (current_degree > *maxDegree) {\n      *maxDegree = current_degree;\n    }\n  }\n}",
            "const size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= N) return;\n  const int offset = idx * N;\n\n  int maxD = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (A[offset + i]!= 0)\n      maxD++;\n  }\n  atomicMax(maxDegree, maxD);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int max = 0;\n\n    if (tid < N) {\n        int sum = 0;\n        for (int i = 0; i < N; i++) {\n            sum += A[tid * N + i];\n        }\n        atomicMax(&max, sum);\n    }\n\n    __syncthreads();\n    if (threadIdx.x == 0) {\n        *maxDegree = max;\n    }\n}",
            "}",
            "int i = blockIdx.x;\n    int result = 0;\n    for (int j = 0; j < N; j++)\n    {\n        result = result + A[i*N + j];\n    }\n    atomicMax(maxDegree, result);\n}",
            "/* Your code here. */\n\n}",
            "int idx = threadIdx.x;\n    if (idx < N) {\n        int deg = 0;\n        for (int i = 0; i < N; i++) {\n            if (A[idx * N + i]!= 0) deg++;\n        }\n        if (deg > *maxDegree) *maxDegree = deg;\n    }\n}",
            "// TODO: Your code here.\n\n}",
            "// TODO:\n    // 1. Allocate shared memory\n    // 2. Determine the index of the current thread\n    // 3. Determine the adjacency matrix row\n    // 4. Compute the sum\n    // 5. Write back to global memory\n\n}",
            "// Your code here\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint max = 0;\n\tif (i < N) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > max) {\n\t\t\tmax = sum;\n\t\t}\n\t}\n\t*maxDegree = max;\n}",
            "int idx = threadIdx.x;\n    int maxDegreeVal = 0;\n    // Do the calculation\n    for (int i = 0; i < N; i++) {\n        if (A[idx*N + i] > maxDegreeVal) {\n            maxDegreeVal = A[idx*N + i];\n        }\n    }\n\n    // Write back the result to global memory\n    maxDegree[0] = maxDegreeVal;\n}",
            "/* TODO: Implement the algorithm to compute the maximum node degree in the graph.\n\t You can use the atomicMin operation to reduce the maximum degree.\n\t A is an NxN adjacency matrix stored in row-major.\n\t *maxDegree should be set to the highest node degree in the graph.\n\t*/\n\n\tint tid = blockDim.x*blockIdx.x+threadIdx.x;\n\n\tif (tid < N)\n\t{\n\t\tint maxDeg = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tif (A[tid*N+i]!= 0)\n\t\t\t{\n\t\t\t\tmaxDeg++;\n\t\t\t}\n\t\t}\n\t\tatomicMin(maxDegree, maxDeg);\n\t}\n}",
            "int myMax = 0;\n    for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {\n        int rowSum = 0;\n        for (int j = 0; j < N; j++) {\n            rowSum += A[i * N + j];\n        }\n        myMax = max(myMax, rowSum);\n    }\n\n    // Write the maximum degree to maxDegree.\n    // Use atomicMax to do this atomically.\n    atomicMax(maxDegree, myMax);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index < N) {\n    int max_degree = 0;\n    for (int i = 0; i < N; i++)\n    {\n      if (A[i * N + index] == 1)\n        max_degree++;\n    }\n    atomicMax(maxDegree, max_degree);\n  }\n}",
            "__shared__ int blockMaxDegree[512];\n    int bMaxDegree = 0;\n\n    // Calculate the max degree of the block\n    int startRow = blockIdx.x * blockDim.x;\n    int endRow = (blockIdx.x + 1) * blockDim.x;\n    for (int i = startRow + threadIdx.x; i < endRow; i += blockDim.x) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                degree++;\n            }\n        }\n        bMaxDegree = (degree > bMaxDegree)? degree : bMaxDegree;\n    }\n\n    // Block reduction\n    for (int i = blockDim.x / 2; i > 0; i /= 2) {\n        __syncthreads();\n        if (threadIdx.x < i) {\n            blockMaxDegree[threadIdx.x] = (blockMaxDegree[threadIdx.x] > blockMaxDegree[threadIdx.x + i])? blockMaxDegree[threadIdx.x] : blockMaxDegree[threadIdx.x + i];\n        }\n    }\n\n    if (threadIdx.x == 0) {\n        atomicMax(maxDegree, blockMaxDegree[0]);\n    }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tint m = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tm++;\n\t\t\t}\n\t\t}\n\t}\n\tif (tid == 0) {\n\t\tatomicMax(maxDegree, m);\n\t}\n}",
            "// TODO\n\n}",
            "}",
            "__shared__ int cache[TILE_SIZE];\n\t__shared__ int cacheSum[TILE_SIZE];\n\n\tint row = blockIdx.x*TILE_SIZE + threadIdx.x;\n\tint myMax = 0;\n\n\tfor (int i = 0; i < TILE_SIZE; i++) {\n\t\tcache[i] = 0;\n\t}\n\n\twhile (row < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[row*N + j] == 1) {\n\t\t\t\tcache[threadIdx.x]++;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tif (threadIdx.x == 0) {\n\t\t\tfor (int i = 0; i < TILE_SIZE; i++) {\n\t\t\t\tcacheSum[i] = 0;\n\t\t\t\tfor (int j = i; j < TILE_SIZE; j++) {\n\t\t\t\t\tcacheSum[i] += cache[j];\n\t\t\t\t}\n\t\t\t\tif (cacheSum[i] > myMax) {\n\t\t\t\t\tmyMax = cacheSum[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tif (threadIdx.x == 0) {\n\t\t\tfor (int i = 0; i < TILE_SIZE; i++) {\n\t\t\t\tcache[i] = 0;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\trow += TILE_SIZE*gridDim.x;\n\t}\n\n\tint sum = 0;\n\tint sumSq = 0;\n\tfor (int i = 0; i < TILE_SIZE; i++) {\n\t\tsum += cache[i];\n\t\tsumSq += cacheSum[i];\n\t}\n\tif (threadIdx.x == 0) {\n\t\tif (myMax > *maxDegree) {\n\t\t\t*maxDegree = myMax;\n\t\t}\n\t\tcacheSum[threadIdx.x] = sum;\n\t}\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tfor (int i = 1; i < TILE_SIZE; i++) {\n\t\t\tcacheSum[0] += cacheSum[i];\n\t\t}\n\t\tif (cacheSum[0] > *maxDegree) {\n\t\t\t*maxDegree = cacheSum[0];\n\t\t}\n\t}\n\t__syncthreads();\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n    int max = 0;\n\n    if (id < N) {\n        int i = 0;\n        for (i = 0; i < N; i++) {\n            if (A[i * N + id] == 1) {\n                max++;\n            }\n        }\n        atomicMax(maxDegree, max);\n    }\n}",
            "__shared__ int maxDegreeShared[BLOCK_SIZE];\n\n  int localMaxDegree = 0;\n\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N * N;\n       i += blockDim.x * gridDim.x) {\n    if (A[i]!= 0) {\n      localMaxDegree += 1;\n    }\n  }\n\n  maxDegreeShared[threadIdx.x] = localMaxDegree;\n  __syncthreads();\n\n  for (int stride = BLOCK_SIZE / 2; stride > 0; stride >>= 1) {\n    if (threadIdx.x < stride) {\n      maxDegreeShared[threadIdx.x] =\n          max(maxDegreeShared[threadIdx.x], maxDegreeShared[threadIdx.x + stride]);\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    *maxDegree = maxDegreeShared[0];\n  }\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N) {\n        int degree = 0;\n        for (int i = 0; i < N; i++) {\n            degree += A[N * tid + i];\n        }\n        atomicMax(maxDegree, degree);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (i < N) {\n        int degree = 0;\n        for (int j = 0; j < N; j++)\n            if (A[i*N + j]!= 0)\n                degree++;\n\n        atomicMax(maxDegree, degree);\n    }\n}",
            "int idx = threadIdx.x;\n\n\tif (idx < N) {\n\t\tint max = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[idx * N + i] > 0)\n\t\t\t\tmax++;\n\t\t}\n\t\t*maxDegree = max > *maxDegree? max : *maxDegree;\n\t}\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\tint max = 0;\n\tfor (int j = 0; j < N; ++j) {\n\t\tif (idx!= j)\n\t\t\tmax += A[idx * N + j];\n\t}\n\n\tif (max > *maxDegree)\n\t\t*maxDegree = max;\n}",
            "//int globalIdx = blockIdx.x * blockDim.x + threadIdx.x;\n    __shared__ int degree[BLOCKSIZE];\n    degree[threadIdx.x] = 0;\n\n    int offset = blockIdx.x * BLOCKSIZE;\n    int localIdx = threadIdx.x + offset;\n    while (localIdx < N) {\n        if (A[localIdx * N + localIdx] > 0) {\n            atomicAdd(&degree[threadIdx.x], 1);\n        }\n        localIdx += BLOCKSIZE;\n    }\n    __syncthreads();\n\n    // Reduce degree array to a single value\n    if (blockIdx.x == 0) {\n        for (int s = 1; s < BLOCKSIZE; s *= 2) {\n            if (threadIdx.x % (2 * s) == 0) {\n                atomicAdd(&degree[threadIdx.x], degree[threadIdx.x + s]);\n            }\n            __syncthreads();\n        }\n        *maxDegree = degree[0];\n    }\n}",
            "// Compute maxDegree\n\t//...\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i < N) {\n        int localMax = 0;\n        int start = i * N;\n        int end = start + N;\n        for (int j = start; j < end; j++) {\n            int value = A[j];\n            if (value > 0)\n                localMax++;\n        }\n        atomicMax(maxDegree, localMax);\n    }\n}",
            "// TODO\n}",
            "// TODO\n\t//\n\t//\n\t//\n\n}",
            "// compute the global thread index\n\tint index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// shared memory for each thread to store partial max degree\n\t__shared__ int maxDegreeBuffer[N];\n\n\t// thread 0 will store the max degree for all threads\n\tint myMax = 0;\n\n\t// if the thread is active\n\tif (index < N) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[index * N + i] == 1) {\n\t\t\t\tmyMax++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// update the max degree\n\tmaxDegreeBuffer[threadIdx.x] = myMax;\n\n\t// sync and update the max degree\n\t__syncthreads();\n\n\t// the first thread is the one that updates the max degree\n\tif (threadIdx.x == 0) {\n\t\t*maxDegree = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (maxDegreeBuffer[i] > *maxDegree) {\n\t\t\t\t*maxDegree = maxDegreeBuffer[i];\n\t\t\t}\n\t\t}\n\t}\n\n\t// sync to ensure that all threads have updated the max degree\n\t__syncthreads();\n\n}",
            "// Replace the 0s with 1s to calculate the maximum degree\n  if (A[blockIdx.x * N + threadIdx.x] == 0)\n    A[blockIdx.x * N + threadIdx.x] = 1;\n\n  __shared__ int shared[N];\n  shared[threadIdx.x] = A[blockIdx.x * N + threadIdx.x];\n  __syncthreads();\n  int max = 0;\n\n  if (N > 32)\n    for (int i = 32; i < N; i++)\n      if (shared[i] > max)\n        max = shared[i];\n\n  __syncthreads();\n\n  int lmax;\n  if (threadIdx.x < 32) {\n    lmax = max;\n\n    max = max < shared[threadIdx.x]? shared[threadIdx.x] : max;\n    if (threadIdx.x + 1 < N)\n      max = max < shared[threadIdx.x + 1]? shared[threadIdx.x + 1] : max;\n    if (threadIdx.x + 2 < N)\n      max = max < shared[threadIdx.x + 2]? shared[threadIdx.x + 2] : max;\n    if (threadIdx.x + 4 < N)\n      max = max < shared[threadIdx.x + 4]? shared[threadIdx.x + 4] : max;\n    if (threadIdx.x + 8 < N)\n      max = max < shared[threadIdx.x + 8]? shared[threadIdx.x + 8] : max;\n    if (threadIdx.x + 16 < N)\n      max = max < shared[threadIdx.x + 16]? shared[threadIdx.x + 16] : max;\n  }\n\n  __syncthreads();\n  if (threadIdx.x == 0)\n    maxDegree[blockIdx.x] = max;\n}",
            "int i = threadIdx.x;\n\tint degree = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i + j*N]!= 0) {\n\t\t\tdegree += 1;\n\t\t}\n\t}\n\tatomicMax(maxDegree, degree);\n}",
            "// TODO: Compute the max degree in A using CUDA\n  *maxDegree = 0;\n  for(int i = 0; i < N; i++) {\n    int degree = 0;\n    for(int j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    if(degree > *maxDegree) {\n      *maxDegree = degree;\n    }\n  }\n\n}",
            "// each thread should compute a node's degree\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int max = 0;\n\n  if(idx < N){\n      for(int i=0;i<N;i++)\n      {\n          if(A[idx*N+i] > 0)\n          {\n              max++;\n          }\n      }\n      atomicMax(maxDegree, max);\n  }\n\n}",
            "int id = threadIdx.x;\n    int max = 0;\n\n    if (id < N) {\n        int row = A[id * N];\n        for (int i = 1; i < N; i++) {\n            row += A[id * N + i];\n        }\n        if (row > max) {\n            max = row;\n        }\n    }\n\n    atomicMax(maxDegree, max);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    __shared__ int temp[THREADS_PER_BLOCK];\n    temp[threadIdx.x] = 0;\n    if (tid < N)\n    {\n        for (size_t i = 0; i < N; i++)\n        {\n            if (A[i*N+tid] == 1)\n            {\n                atomicAdd(&temp[threadIdx.x], 1);\n            }\n        }\n    }\n    __syncthreads();\n    for (int s=1; s<THREADS_PER_BLOCK; s*=2)\n    {\n        if (threadIdx.x % (2*s) == 0)\n        {\n            temp[threadIdx.x] += temp[threadIdx.x + s];\n        }\n        __syncthreads();\n    }\n    if (threadIdx.x == 0)\n    {\n        atomicMax(maxDegree, temp[0]);\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myMax = 0;\n\tif (tid < N) {\n\t\tint myDegree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tmyDegree += A[tid * N + i];\n\t\t}\n\t\tmyMax = myDegree > myMax? myDegree : myMax;\n\t\t*maxDegree = myMax > *maxDegree? myMax : *maxDegree;\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (id < N) {\n\t\tint degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[id + i * N] > 0) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\t\tatomicMax(maxDegree, degree);\n\t}\n}",
            "const int i = blockDim.x*blockIdx.x + threadIdx.x;\n  int sum = 0;\n  for(int j = 0; j < N; j++)\n    sum += A[j*N + i];\n  atomicAdd(maxDegree, sum);\n}",
            "// Each thread should compute the maximum degree of the sub-graph defined by a sub-matrix of A,\n\t// with one thread per row.\n\t// Use atomicMax to update the maximum degree between all threads.\n\t\n\t// Get the row index of the sub-matrix (0..N-1).\n\tint row = blockDim.x*blockIdx.x + threadIdx.x;\n\t\n\t// Initialize the maximum degree to 0.\n\tint max_degree = 0;\n\t\n\t// For each column in the row, get the value in the adjacency matrix.\n\tfor (int col = 0; col < N; ++col) {\n\t\t// Get the value in the adjacency matrix.\n\t\tint val = A[row * N + col];\n\t\t\n\t\t// If the value is 1, increment the degree.\n\t\tif (val == 1) {\n\t\t\t// Atomically increment the degree.\n\t\t\tatomicMax(&max_degree, col);\n\t\t}\n\t}\n\t\n\t// Store the maximum degree in the result array, with one element per row.\n\tmaxDegree[row] = max_degree;\n}",
            "int maxDeg = 0;\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        for (int i = 0; i < N; i++) {\n            if (A[tid * N + i] > 0) {\n                atomicMax(&maxDeg, A[tid * N + i]);\n            }\n        }\n    }\n    atomicMax(&maxDeg, maxDeg);\n\n    if (tid == 0) {\n        *maxDegree = maxDeg;\n    }\n}",
            "// TODO\n}",
            "// TODO\n  // Compute the max degree in the input graph using CUDA\n\n}",
            "// TODO\n  unsigned int index = blockIdx.x*blockDim.x+threadIdx.x;\n  if(index < N){\n    int max = 0;\n    for(int i=0; i<N; i++){\n      if(A[index*N+i]!= 0){\n        max++;\n      }\n    }\n    if(max > *maxDegree)\n    {\n      *maxDegree = max;\n    }\n  }\n}",
            "int i, j;\n  int myMaxDegree = 0;\n\n  // your code here\n\n  // Find the maximum degree of the graph.\n  int temp;\n  for(i = 0; i < N; ++i) {\n    temp = 0;\n    for(j = 0; j < N; ++j) {\n      if(A[i * N + j]!= 0)\n        temp++;\n    }\n    if(temp > myMaxDegree)\n      myMaxDegree = temp;\n  }\n\n  *maxDegree = myMaxDegree;\n\n}",
            "__shared__ int temp[N];\n\n\t// use block id as vertex id\n\tint vertex_id = blockIdx.x;\n\tint max = 0;\n\tint degree;\n\tfor (int i = threadIdx.x; i < N; i += blockDim.x) {\n\t\tif (A[vertex_id * N + i] == 1) {\n\t\t\ttemp[i] = 1;\n\t\t} else {\n\t\t\ttemp[i] = 0;\n\t\t}\n\t}\n\n\t__syncthreads();\n\tfor (int i = 0; i < N; i++) {\n\t\tmax += temp[i];\n\t}\n\n\t// only one thread per block can write to global memory\n\tif (threadIdx.x == 0) {\n\t\tatomicMax(maxDegree, max);\n\t}\n}",
            "int globalID = blockIdx.x * blockDim.x + threadIdx.x;\n    if (globalID >= N) return;\n\n    int localMax = 0;\n    for (int j = 0; j < N; j++) {\n        localMax += A[globalID * N + j];\n    }\n\n    // Reduce to a single value\n    atomicMax(maxDegree, localMax);\n}",
            "const int row = blockIdx.x;\n\tint degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row * N + i]) {\n\t\t\tdegree++;\n\t\t}\n\t}\n\tatomicMax(maxDegree, degree);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if(idx < N) {\n        int max = A[idx*N];\n        for(int i = 0; i < N; i++) {\n            if(A[idx*N+i] > max) max = A[idx*N+i];\n        }\n        *maxDegree = max;\n    }\n}",
            "// Allocate shared memory and initialize the variable.\n    extern __shared__ int shared[];\n    shared[threadIdx.x] = 0;\n\n    // Compute the maximum degree of all vertices in the graph.\n    // The first dimension of the adjacency matrix, N, is evenly divided between all the\n    // blocks that are launched. All the threads in a block will take part in the computation.\n    for (size_t i = N * blockIdx.x + threadIdx.x; i < N * (blockIdx.x + 1); i += blockDim.x) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                atomicAdd(&(shared[threadIdx.x]), 1);\n            }\n        }\n    }\n    __syncthreads();\n\n    // Reduce the maximum degree. The first thread in each block will do the reduction.\n    for (int i = blockDim.x / 2; i > 0; i >>= 1) {\n        if (threadIdx.x < i) {\n            shared[threadIdx.x] = max(shared[threadIdx.x], shared[threadIdx.x + i]);\n        }\n        __syncthreads();\n    }\n\n    // Only the first thread in the block will write the result to the global memory.\n    if (threadIdx.x == 0) {\n        maxDegree[blockIdx.x] = shared[0];\n    }\n}",
            "__shared__ int deg[BLOCK_SIZE];\n  int row = blockIdx.x;\n  int col = threadIdx.x;\n  int degree = 0;\n  if (row < N) {\n    for (int i = 0; i < N; i++) {\n      degree += A[row * N + i];\n    }\n    deg[col] = degree;\n    __syncthreads();\n\n    if (col == 0) {\n      *maxDegree = 0;\n      for (int i = 0; i < BLOCK_SIZE; i++) {\n        if (deg[i] > *maxDegree) *maxDegree = deg[i];\n      }\n    }\n  }\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "13_graph_highest_degree",
        "parallelism_model": "mpi+omp",
        "prompt": "#include <mpi.h>\n#include <omp.h>\n\n/* Compute the highest node degree in the graph. The graph is defined in the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint maxDegree(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Use an atomic integer for storing the max\n\tstd::atomic<int> max{0};\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tint thisSum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tthisSum += A[i * N + j];\n\t\t}\n\t\tif (thisSum > max) {\n\t\t\tmax = thisSum;\n\t\t}\n\t}\n\n\t// Gather the max from all MPI ranks.\n\tint allMax[MPI::COMM_WORLD.Get_size()];\n\tMPI::COMM_WORLD.Allgather(&max, 1, MPI::INT, allMax, 1, MPI::INT);\n\n\t// Return the max of all the MPI ranks.\n\tint maxMax = allMax[0];\n\tfor (int i = 1; i < MPI::COMM_WORLD.Get_size(); ++i) {\n\t\tif (allMax[i] > maxMax) {\n\t\t\tmaxMax = allMax[i];\n\t\t}\n\t}\n\n\treturn maxMax;\n}",
            "int maxDeg = 0;\n\n  // Use OpenMP to compute a local maxDegree\n  #pragma omp parallel for reduction(max:maxDeg)\n  for (size_t row = 0; row < N; row++) {\n    int rowDeg = 0;\n    for (size_t col = 0; col < N; col++) {\n      if (A[row * N + col]!= 0) {\n        rowDeg++;\n      }\n    }\n\n    maxDeg = std::max(maxDeg, rowDeg);\n  }\n\n  // Use MPI to compute a global maxDegree\n  int mpiSize;\n  MPI_Comm_size(MPI_COMM_WORLD, &mpiSize);\n\n  int mpiRank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpiRank);\n\n  std::vector<int> maxDegrees(mpiSize);\n  MPI_Gather(&maxDeg, 1, MPI_INT, maxDegrees.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (mpiRank == 0) {\n    int globalMaxDeg = maxDeg;\n    for (int i = 1; i < mpiSize; i++) {\n      globalMaxDeg = std::max(globalMaxDeg, maxDegrees[i]);\n    }\n\n    return globalMaxDeg;\n  } else {\n    return 0;\n  }\n}",
            "// TODO:\n  // Compute the max degree for one sub-matrix\n  // Compute the max degree over all sub-matrices\n  int max_degree = -1;\n  int sub_max_degree = -1;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] > 0) {\n        sub_max_degree++;\n      }\n    }\n  }\n\n  return sub_max_degree;\n}",
            "int maxDegree = 0;\n#pragma omp parallel\n#pragma omp single\n{\n\tstd::vector<int> maxDegreePerThread(omp_get_num_threads());\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tmaxDegreePerThread[omp_get_thread_num()]++;\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 1; i < omp_get_num_threads(); i++) {\n\t\tif (maxDegreePerThread[0] < maxDegreePerThread[i]) {\n\t\t\tmaxDegreePerThread[0] = maxDegreePerThread[i];\n\t\t}\n\t}\n\tmaxDegree = maxDegreePerThread[0];\n}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        degree++;\n      }\n    }\n    if (degree > maxDegree) {\n      maxDegree = degree;\n    }\n  }\n  return maxDegree;\n}",
            "assert(A.size() == N * N);\n\t// TODO\n\n\treturn 0;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                ++degree;\n            }\n        }\n        maxDegree = std::max(maxDegree, degree);\n    }\n    return maxDegree;\n}",
            "// TODO: Compute the max degree in parallel.\n\n\treturn 0;\n}",
            "int maxDegree = 0;\n\n#pragma omp parallel\n  {\n    int maxDegree_p = 0;\n\n#pragma omp for nowait\n    for (size_t i = 0; i < N; i++)\n    {\n      for (size_t j = 0; j < N; j++)\n      {\n        if (A[i*N + j] == 1)\n        {\n          maxDegree_p++;\n          break;\n        }\n      }\n    }\n\n    #pragma omp critical\n    {\n      if (maxDegree_p > maxDegree)\n        maxDegree = maxDegree_p;\n    }\n  }\n\n  return maxDegree;\n}",
            "int max = 0;\n#pragma omp parallel for reduction(max:max)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint current = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tcurrent++;\n\t\t\t}\n\t\t}\n\t\tif (current > max) {\n\t\t\tmax = current;\n\t\t}\n\t}\n\treturn max;\n}",
            "int maxDegree = 0;\n\n  // TODO: Your code goes here\n  return maxDegree;\n}",
            "int maxDegree = 0;\n  int max_threads = omp_get_max_threads();\n  int max_processes = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &max_processes);\n  int max_total_threads = max_processes * max_threads;\n  std::vector<int> A_per_thread(A.size() / max_total_threads);\n  int start = 0;\n  int end = A.size() / max_total_threads;\n  int n = 0;\n  #pragma omp parallel for schedule(dynamic, 1)\n  for (int rank = 0; rank < max_processes; ++rank) {\n    int thread_id = omp_get_thread_num();\n    int num_threads = omp_get_num_threads();\n    int rank_threads = max_threads / num_threads;\n    int thread_rank = thread_id / rank_threads;\n    int thread_in_rank = thread_id % rank_threads;\n    int n_th = n + (thread_id % num_threads);\n    int start_rank = n_th * rank_threads * end;\n    int end_rank = (n_th + 1) * rank_threads * end;\n    for (int i = start_rank; i < end_rank; ++i) {\n      A_per_thread[i] = A[i];\n    }\n  }\n  int local_max_degree = 0;\n  #pragma omp parallel for reduction(max : local_max_degree)\n  for (int i = 0; i < A_per_thread.size(); i++) {\n    int degree = 0;\n    for (int j = 0; j < N; j++) {\n      degree += A_per_thread[i * N + j];\n    }\n    local_max_degree = std::max(local_max_degree, degree);\n  }\n  MPI_Reduce(&local_max_degree, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree;\n}",
            "// TODO:\n\n  return 0;\n}",
            "int max = 0;\n  int localMax = 0;\n  int rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  for (size_t i = 0; i < N; ++i) {\n    int sum = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++sum;\n      }\n    }\n\n    if (sum > localMax) {\n      localMax = sum;\n    }\n  }\n\n  MPI_Reduce(&localMax, &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return max;\n}",
            "int maxDegree = 0;\n  // Your code here\n\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n\tif (N == 0) return 0;\n\n\t// #pragma omp parallel for reduction(max: max_degree)\n\t// for (size_t i = 0; i < N; ++i) {\n\t// \tfor (size_t j = 0; j < N; ++j) {\n\t// \t\tif (i!= j) {\n\t// \t\t\tif (A[i * N + j]!= 0) {\n\t// \t\t\t\tmax_degree = std::max(max_degree, A[i * N + j]);\n\t// \t\t\t}\n\t// \t\t}\n\t// \t}\n\t// }\n\n\tint *tmp_d = (int*)calloc(N, sizeof(int));\n\t\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\ttmp_d[i] = tmp_d[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(tmp_d, &max_degree, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tfree(tmp_d);\n\n\treturn max_degree;\n}",
            "// TODO\n  int my_ans = 0;\n\n#ifdef _OPENMP\n#pragma omp parallel\n  {\n    int my_max = 0;\n#pragma omp for\n    for (int i = 0; i < N; i++) {\n      int sum = 0;\n      for (int j = 0; j < N; j++) {\n        sum += A[i * N + j];\n      }\n      if (sum > my_max) {\n        my_max = sum;\n      }\n    }\n#pragma omp critical\n    {\n      if (my_max > my_ans) {\n        my_ans = my_max;\n      }\n    }\n  }\n#endif\n  return my_ans;\n}",
            "int max = 0;\n  for(int i = 0; i < N; ++i)\n  {\n    for(int j = 0; j < N; ++j)\n    {\n      if(A[i*N + j] == 1)\n      {\n        max = std::max(max, i);\n      }\n    }\n  }\n  return max;\n}",
            "int *incoming = new int[N];\n  int *outgoing = new int[N];\n  int *res = new int[N];\n  int local_res = 0;\n\n#pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A[i + j * N];\n    }\n    incoming[i] = sum;\n  }\n\n#pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A[j + i * N];\n    }\n    outgoing[i] = sum;\n  }\n\n#pragma omp parallel for reduction(max:local_res)\n  for (int i = 0; i < N; i++) {\n    res[i] = incoming[i] + outgoing[i];\n    local_res = std::max(local_res, res[i]);\n  }\n\n  int global_res;\n  MPI_Reduce(&local_res, &global_res, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  if (MPI_Comm_rank(MPI_COMM_WORLD) == 0)\n    return global_res;\n  else\n    return 0;\n}",
            "int maxDeg = 0;\n    if(N == 0) {\n        return 0;\n    }\n    int localMax = 0;\n    int maxThreads = omp_get_max_threads();\n    int rank = 0;\n    int numRanks = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n    std::vector<int> localMaxDegree(maxThreads, 0);\n\n    // count the max degree in parallel\n    #pragma omp parallel\n    {\n        int threadNum = omp_get_thread_num();\n        int numThreads = omp_get_num_threads();\n        int row = rank * N / numRanks;\n        int start = row;\n        int end = row + N / numRanks;\n        for(int i = start; i < end; i++) {\n            int degree = 0;\n            for(int j = 0; j < N; j++) {\n                degree += A[i * N + j];\n            }\n            localMaxDegree[threadNum] = std::max(localMaxDegree[threadNum], degree);\n        }\n    }\n    MPI_Reduce(localMaxDegree.data(), &localMax, maxThreads, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    // return the max degree\n    if(rank == 0) {\n        maxDeg = localMax;\n    }\n    return maxDeg;\n}",
            "int local_max = 0;\n  // TODO\n\n  int global_max = 0;\n  // TODO\n\n  return global_max;\n}",
            "if (N == 0) {\n        return 0;\n    }\n\n    int* degree_count = new int[N];\n    memset(degree_count, 0, sizeof(int) * N);\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                degree_count[i]++;\n                degree_count[j]++;\n            }\n        }\n    }\n\n    int rank = 0;\n    int rank_count = 0;\n    int* max_degree = new int[omp_get_num_procs()];\n\n    #pragma omp parallel num_threads(omp_get_num_procs())\n    {\n        int rank = omp_get_thread_num();\n        int max_degree = 0;\n\n        #pragma omp for\n        for (int i = 0; i < N; i++) {\n            max_degree = std::max(max_degree, degree_count[i]);\n        }\n\n        max_degree[rank] = max_degree;\n    }\n\n    // MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm)\n    // recvbuf must be large enough to hold a result from all the processes\n    MPI_Reduce(MPI_IN_PLACE, max_degree, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        int max = max_degree[0];\n        for (int i = 1; i < N; i++) {\n            max = std::max(max, max_degree[i]);\n        }\n        return max;\n    }\n\n    return 0;\n}",
            "/* TODO */\n}",
            "int rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint l_max = 0;\n\n\t#pragma omp parallel for reduction(max:l_max)\n\tfor(int i=0;i<N;i++){\n\t\tint d = 0;\n\t\tfor(int j=0;j<N;j++){\n\t\t\tif (A[i*N+j]!= 0){\n\t\t\t\td++;\n\t\t\t}\n\t\t}\n\t\tl_max = d > l_max? d : l_max;\n\t}\n\n\tint max = 0;\n\tMPI_Reduce(&l_max, &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max;\n}",
            "int nprocs, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int result = 0;\n    int local_result = 0;\n\n    // your code here\n\n    MPI_Reduce(&local_result, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "int maxDegree = 0;\n    if (A.size() == 0) {\n        return maxDegree;\n    }\n    // parallel loop with OpenMP\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        int degree = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j]!= 0) {\n                degree++;\n            }\n        }\n        if (degree > maxDegree) {\n            maxDegree = degree;\n        }\n    }\n    // return on rank 0\n    int globalMaxDegree;\n    if (getRank() == 0) {\n        globalMaxDegree = maxDegree;\n    }\n    // get global maxDegree\n    MPI_Reduce(&maxDegree, &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    if (getRank() == 0) {\n        return globalMaxDegree;\n    }\n    return 0;\n}",
            "int max_degree = 0;\n#pragma omp parallel\n  {\n#pragma omp for reduction(max:max_degree)\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        max_degree = std::max(max_degree, A[i * N + j]);\n      }\n    }\n  }\n  return max_degree;\n}",
            "// Implement me!\n}",
            "assert(A.size() == N*N);\n\tstd::vector<int> result(N);\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\t++result[i];\n\t\t\t}\n\t\t}\n\t}\n\t#pragma omp parallel for\n\tfor (size_t i = 1; i < N; ++i) {\n\t\tresult[0] = std::max(result[0], result[i]);\n\t}\n\tint maxDegree;\n\tMPI_Reduce(&result[0], &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn maxDegree;\n}",
            "int const rank = omp_get_thread_num();\n  int const numRanks = omp_get_num_threads();\n\n  // TODO: fill this in\n  return -1;\n}",
            "int maxDegree = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\t#pragma omp simd\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif (sum > maxDegree) {\n\t\t\t#pragma omp critical\n\t\t\tmaxDegree = sum;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "std::vector<int> local_max_degree;\n  int max_degree = 0;\n  int rank, num_threads;\n  int start, end, local_max_degree_temp;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_threads);\n\n  start = rank * (N/num_threads);\n  end = start + (N/num_threads);\n\n  // OMP for loop\n  #pragma omp parallel for\n  for(int i = start; i < end; i++){\n    local_max_degree_temp = 0;\n\n    for(int j = 0; j < N; j++){\n      if(A[i*N + j] == 1){\n        local_max_degree_temp++;\n      }\n    }\n\n    local_max_degree.push_back(local_max_degree_temp);\n  }\n\n  // MPI_Reduce function\n  MPI_Reduce(&local_max_degree[0], &max_degree, local_max_degree.size(), MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return max_degree;\n}",
            "// TODO\n}",
            "// your code here\n}",
            "if (A.size()!= N*N) {\n\t\tthrow std::runtime_error(\"Wrong size for A.\");\n\t}\n\t\n\t// your code here\n\tint maxDegree = 0;\n\t//#pragma omp parallel for shared(maxDegree)\n\tfor (int i = 0; i < N; i++) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tif (count > maxDegree) {\n\t\t\tmaxDegree = count;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// CODE HERE\n\t// ========\n\t//\n\t// You may use:\n\t// - omp_get_max_threads() to get the maximum number of threads\n\t// - omp_get_thread_num() to get the thread number\n\t// - omp_get_num_threads() to get the number of threads\n\t// - omp_get_num_procs() to get the number of processors\n\n\t// DO NOT ADD ANYTHING BELOW THIS LINE\n\n\treturn 0;\n}",
            "int max = 0;\n\n  #pragma omp parallel for reduction(max:max)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j]!= 0)\n        max = std::max(max, A[i * N + j] - 1);\n\n  return max;\n}",
            "// TODO: Your code here\n  int max_degree = 0;\n  int degree;\n#pragma omp parallel for\n  for(size_t i = 0; i < N; i++) {\n    degree = 0;\n    for(size_t j = 0; j < N; j++) {\n      if(A[i * N + j]) {\n        degree++;\n      }\n    }\n    if(degree > max_degree) {\n      max_degree = degree;\n    }\n  }\n  return max_degree;\n}",
            "// Your code here.\n    int result;\n    int localMaxDegree;\n\n#pragma omp parallel\n    {\n        localMaxDegree = 0;\n#pragma omp for reduction(max:localMaxDegree)\n        for (size_t i = 0; i < N; i++)\n        {\n            int sum = 0;\n            for (size_t j = 0; j < N; j++)\n            {\n                sum += A[i*N + j];\n            }\n            localMaxDegree = std::max(localMaxDegree, sum);\n        }\n    }\n\n    int globalMaxDegree;\n    MPI_Reduce(&localMaxDegree, &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    if (MPI_Comm_rank(MPI_COMM_WORLD) == 0)\n    {\n        result = globalMaxDegree;\n    }\n\n    return result;\n}",
            "/* TODO: Your code here */\n\n  int max = 0;\n  if(A.size() == 0) return 0;\n\n  #pragma omp parallel\n  {\n    int localMax = 0;\n    #pragma omp for\n    for(int i = 0; i < N; i++) {\n      int current = 0;\n      for(int j = 0; j < N; j++) {\n        current += A[i*N + j];\n      }\n      if(current > localMax) {\n        localMax = current;\n      }\n    }\n    #pragma omp critical\n    {\n      if(localMax > max) {\n        max = localMax;\n      }\n    }\n  }\n\n  return max;\n}",
            "// TODO\n}",
            "// TODO\n  int maxdeg=0;\n  std::vector<int> maxdegrees;\n\n  #pragma omp parallel\n  {\n    #pragma omp for reduction(max:maxdeg)\n    for (int i=0; i<N; ++i)\n    {\n      int mydeg = 0;\n      for (int j=0; j<N; ++j)\n      {\n        mydeg += A[i*N+j];\n      }\n      maxdeg=max(mydeg,maxdeg);\n    }\n    #pragma omp critical\n    {\n      maxdegrees.push_back(maxdeg);\n    }\n  }\n  maxdeg=0;\n  for (int i=0; i<N; ++i)\n  {\n    maxdeg=max(maxdeg,maxdegrees[i]);\n  }\n\n  return maxdeg;\n}",
            "// TODO\n}",
            "// TODO: Implement this function.\n    // It must be safe to use A from multiple threads in parallel.\n\n    // TODO: Use MPI and OpenMP to parallelize this code.\n\n    return -1;\n}",
            "std::vector<int> localMaxDegree(1);\n\tlocalMaxDegree[0] = 0;\n\tauto& localA = A;\n\tint nthreads = omp_get_max_threads();\n\tint rank = 0;\n\tint num_ranks = 1;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n\t#pragma omp parallel num_threads(nthreads)\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\tint num_threads = omp_get_num_threads();\n\t\tint localMax = 0;\n\t\tint localSize = N / num_threads;\n\t\tint localStart = tid * localSize;\n\t\tint localEnd = localStart + localSize;\n\t\tif (tid == num_threads - 1) {\n\t\t\tlocalEnd = N;\n\t\t}\n\t\tfor (int i = localStart; i < localEnd; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tlocalMax += localA[i * N + j];\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tlocalMaxDegree[0] = std::max(localMax, localMaxDegree[0]);\n\t\t}\n\t}\n\n\tMPI_Reduce(localMaxDegree.data(), NULL, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn localMaxDegree[0];\n}",
            "int maxDegree = 0;\n\n  // TODO: Implement a parallel computation of the maximum degree in the graph\n  // using MPI and OpenMP. Every rank should compute a local maximum degree\n  // before reducing the results.\n\n  return maxDegree;\n}",
            "int local_max = 0;\n  int max = 0;\n  int rank, world;\n  MPI_Comm_size(MPI_COMM_WORLD, &world);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  std::vector<int> A_row(A.begin() + rank*N, A.begin() + rank*N + N);\n  for(int i=0; i<N; ++i) {\n    int sum = 0;\n    for(int j=0; j<N; ++j) {\n      sum += A_row[j];\n    }\n    local_max = max(sum, local_max);\n  }\n  MPI_Reduce(&local_max, &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return max;\n}",
            "int maxDegree = 0;\n#pragma omp parallel\n  {\n#pragma omp for reduction(max:maxDegree)\n    for (int i=0; i < N; ++i) {\n      int degree = 0;\n      for (int j=0; j < N; ++j) {\n        degree += A[i*N + j];\n      }\n      maxDegree = std::max(maxDegree, degree);\n    }\n  }\n  return maxDegree;\n}",
            "int localMaxDegree = 0;\n  int globalMaxDegree = 0;\n\n  //TODO 1: Complete the computation\n\n  //TODO 2: Communicate localMaxDegree to all other ranks\n\n  //TODO 3: Find the globalMaxDegree on rank 0\n\n  return globalMaxDegree;\n}",
            "}",
            "// Write your code here\n\n}",
            "int degree = 0;\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; ++i)\n        for(size_t j = 0; j < N; ++j)\n            if(A[i*N + j] == 1)\n                degree = std::max(degree, (int) (i == j? 2 : 3));\n    return degree;\n}",
            "int maxDegree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tmaxDegree = std::max(maxDegree, (int)std::max(degree(A, N, i), degree(A, N, j)));\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "// TODO: Add your code here\n\n\n\n\treturn 0;\n}",
            "// TODO: Implement me!\n}",
            "// TODO: implement\n  return 0;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(degree, max_degree);\n    }\n    return max_degree;\n}",
            "// TODO\n}",
            "const int rank = 0, size = 0;\n\t// TODO\n}",
            "int max_deg = 0;\n\n\tfor (auto i = 0; i < N; ++i) {\n\t\tint deg = 0;\n\t\tfor (auto j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tdeg++;\n\t\t\t}\n\t\t}\n\t\tif (deg > max_deg) {\n\t\t\tmax_deg = deg;\n\t\t}\n\t}\n\treturn max_deg;\n}",
            "int p, rank, nprocs;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n\tint max_deg = 0;\n\tint local_max_deg = 0;\n\tint chunkSize = N / nprocs;\n\n\tomp_set_num_threads(omp_get_num_procs());\n\t#pragma omp parallel for\n\tfor (int i = rank * chunkSize; i < (rank + 1) * chunkSize; i++) {\n\t\tint local_sum = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tlocal_sum += A[i * N + j];\n\t\t}\n\t\tif (local_sum > local_max_deg) {\n\t\t\tlocal_max_deg = local_sum;\n\t\t}\n\t}\n\n\tMPI_Reduce(&local_max_deg, &max_deg, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max_deg;\n}",
            "// Your code here.\n}",
            "int rank;\n    int p;\n    int max = 0;\n    int localMax = 0;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n\n    if(rank == 0){\n        for(size_t i = 0; i < N; i++){\n            for(size_t j = 0; j < N; j++){\n                if(A[i*N + j] == 1){\n                    localMax++;\n                }\n            }\n            max = std::max(max, localMax);\n            localMax = 0;\n        }\n    }\n    else{\n        for(size_t i = rank*N/p; i < (rank+1)*N/p; i++){\n            for(size_t j = 0; j < N; j++){\n                if(A[i*N + j] == 1){\n                    localMax++;\n                }\n            }\n            MPI_Send(&localMax, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n            localMax = 0;\n        }\n    }\n\n    if(rank!= 0){\n        MPI_Recv(&max, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n\n    return max;\n}",
            "// TODO\n    return -1;\n}",
            "const int max_degree = 32768;\n    std::vector<int> out(omp_get_max_threads());\n#pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        int thread_id = omp_get_thread_num();\n        int sum = 0;\n        for (int j = 0; j < N; ++j) {\n            sum += A[i * N + j];\n        }\n        if (sum > max_degree) {\n            out[thread_id] = sum;\n        }\n    }\n    return *std::max_element(out.begin(), out.end());\n}",
            "std::vector<int> A_local(A.begin() + N * rank, A.begin() + N * (rank + 1));\n\n    // Your code goes here\n    // ...\n    // ...\n    // ...\n\n    return 0;\n}",
            "int maxDeg = 0;\n\n  // TODO:\n\n  return maxDeg;\n}",
            "// TODO: add code here\n\tint maxDegree = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j]) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tif(sum > maxDegree) {\n\t\t\tmaxDegree = sum;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "// TODO: replace this with your code\n  // Note: the values in A are 0 or 1\n  // Note: N is the number of rows in A\n  // Note: the input is a vector of length N^2\n  // Note: the input is symmetric (A[i][j] == A[j][i])\n  // Note: A is stored in row-major form,\n  //       i.e. the values in the i-th row are [A[N * i], A[N * i + 1],..., A[N * i + N - 1]]\n\n  // Get the local size of the matrix (local_size is a vector of length 2)\n  int world_size, world_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n  std::vector<int> local_size(2);\n  local_size[0] = N / world_size;\n  local_size[1] = N % world_size;\n  if(world_rank == world_size - 1)\n    local_size[0] = N / world_size + local_size[1];\n  if(world_rank == 0)\n    local_size[1] = 0;\n\n  // Compute the local maximum degrees of the matrix\n  int local_max = 0;\n  for(int i = 0; i < local_size[0]; i++) {\n    for(int j = 0; j < local_size[0]; j++) {\n      if(A[i * local_size[0] + j]!= 0) {\n        if(local_max < (i + 1))\n          local_max = i + 1;\n        if(local_max < (j + 1))\n          local_max = j + 1;\n      }\n    }\n  }\n\n  // Gather the maximum degree of the matrix to rank 0\n  std::vector<int> global_max(1);\n  if(world_rank!= 0)\n    MPI_Gather(&local_max, 1, MPI_INT, NULL, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  else {\n    MPI_Gather(&local_max, 1, MPI_INT, &global_max[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n    global_max[0] = 0;\n    for(int i = 0; i < world_size; i++) {\n      if(global_max[0] < global_max[i])\n        global_max[0] = global_max[i];\n    }\n  }\n  return global_max[0];\n}",
            "int maxDegree = 0;\n  for (int i = 0; i < N; i++) {\n    int rowDegree = 0;\n#pragma omp parallel for reduction(+:rowDegree)\n    for (int j = 0; j < N; j++) {\n      rowDegree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, rowDegree);\n  }\n  return maxDegree;\n}",
            "int highestDegree = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint localHighestDegree = 0;\n\n\t\t#pragma omp for\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tint degree = 0;\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tif(A[i * N + j] > 0) {\n\t\t\t\t\t++degree;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif(degree > localHighestDegree) {\n\t\t\t\tlocalHighestDegree = degree;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif(localHighestDegree > highestDegree) {\n\t\t\t\thighestDegree = localHighestDegree;\n\t\t\t}\n\t\t}\n\t}\n\n\tint globalHighestDegree;\n\tMPI_Allreduce(&highestDegree, &globalHighestDegree, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\treturn globalHighestDegree;\n}",
            "// YOUR CODE HERE\n\n\treturn 0;\n}",
            "int *degree, *sum_degrees;\n\tint local_max_degree = 0;\n\n\tint rank = 0, size = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0) {\n\t\tdegree = new int[size];\n\t\tsum_degrees = new int[size];\n\t}\n\t\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i*N+j];\n\t\t}\n\t\tif (rank == 0) {\n\t\t\tdegree[i] = sum;\n\t\t} else {\n\t\t\tMPI_Send(&sum, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\t\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tMPI_Recv(&sum_degrees[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\t\tlocal_max_degree = degree[0];\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tif (degree[i] > local_max_degree)\n\t\t\t\tlocal_max_degree = degree[i];\n\t\t}\n\t} else {\n\t\tMPI_Send(&local_max_degree, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\t\n\tif (rank == 0) {\n\t\tint final_max_degree = 0;\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tif (sum_degrees[i] > final_max_degree)\n\t\t\t\tfinal_max_degree = sum_degrees[i];\n\t\t}\n\t\treturn final_max_degree;\n\t}\n\n\tMPI_Finalize();\n\n\tif (rank == 0) {\n\t\tdelete[] degree;\n\t\tdelete[] sum_degrees;\n\t}\n\treturn 0;\n}",
            "// TODO: add your implementation here!\n  return 0;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[j*N + i]!= 0) {\n\t\t\t\tdegree += 1;\n\t\t\t}\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\treturn maxDegree;\n}",
            "auto A_row_begin = A.begin();\n  auto A_row_end = A.begin() + N;\n  int max_degree = 0;\n  // Replace this with your code.\n  return max_degree;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A[i*N + j];\n    }\n    maxDegree = std::max(maxDegree, sum);\n  }\n\n  return maxDegree;\n}",
            "int Nthr = omp_get_max_threads();\n\tstd::vector<int> degrees(N, 0);\n\tint mx = 0;\n\t#pragma omp parallel num_threads(Nthr)\n\t{\n\t\tint myrank = omp_get_thread_num();\n\t\tint nranks = omp_get_num_threads();\n\t\tint mx_local = 0;\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tint d = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\td += A[i*N + j];\n\t\t\t}\n\t\t\tmx_local = std::max(mx_local, d);\n\t\t\tdegrees[i] = d;\n\t\t}\n\t\t#pragma omp critical\n\t\tmx = std::max(mx, mx_local);\n\t}\n\treturn mx;\n}",
            "int maxDegree;\n  int maxDegreeLocal = 0;\n\n  #pragma omp parallel for reduction(max:maxDegreeLocal)\n  for(size_t i = 0; i < N; i++) {\n    int degree = 0;\n    for(size_t j = 0; j < N; j++) {\n      degree += A[i * N + j];\n    }\n    maxDegreeLocal = std::max(degree, maxDegreeLocal);\n  }\n\n  MPI_Reduce(&maxDegreeLocal, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return maxDegree;\n}",
            "// TODO\n}",
            "// TODO: Implement this function\n\tint rank,size;\n\tMPI_Comm_rank(MPI_COMM_WORLD,&rank);\n\tMPI_Comm_size(MPI_COMM_WORLD,&size);\n\tstd::vector<int> adjMatrix(N*N);\n\tstd::vector<int> adjMatrix_new(N*N);\n\n\tfor(int i=0;i<N*N;i++)\n\t\tadjMatrix[i]=A[i];\n\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(rank==0)\n\t\t\t{\n\t\t\t\tMPI_Send(&adjMatrix[i*N+j],1,MPI_INT,rank+1,1,MPI_COMM_WORLD);\n\t\t\t}\n\t\t\tif(rank!=0 && rank<size-1)\n\t\t\t{\n\t\t\t\tMPI_Recv(&adjMatrix_new[i*N+j],1,MPI_INT,rank-1,1,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n\t\t\t}\n\t\t}\n\t}\n\n\tint maxDegree = 0;\n\tint maxDegree_new = 0;\n\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(adjMatrix[i*N+j]==1)\n\t\t\t\tmaxDegree++;\n\t\t}\n\t}\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(adjMatrix_new[i*N+j]==1)\n\t\t\t\tmaxDegree_new++;\n\t\t}\n\t}\n\tif(rank==0)\n\t\treturn (maxDegree>maxDegree_new)?maxDegree:maxDegree_new;\n\telse\n\t\treturn maxDegree_new;\n}",
            "// Use MPI and OpenMP to compute the result in parallel\n  int degree = 0;\n  int Nrank;\n  MPI_Comm_size(MPI_COMM_WORLD, &Nrank);\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int Nthread;\n  #pragma omp parallel\n  {\n    Nthread = omp_get_num_threads();\n    if (rank == 0) {\n      std::cout << \"Using \" << Nrank << \" ranks and \" << Nthread << \" threads\" << std::endl;\n    }\n  }\n  int start, stop;\n  if (Nrank == 1) {\n    start = 0;\n    stop = N;\n  }\n  else {\n    start = rank*N/Nrank;\n    stop = (rank+1)*N/Nrank;\n  }\n  std::vector<int> local_degrees;\n  local_degrees.reserve(stop-start);\n  for (size_t i=start; i<stop; ++i) {\n    int d = std::accumulate(A.begin()+N*i, A.begin()+N*(i+1), 0);\n    local_degrees.push_back(d);\n  }\n  int* local_degree_array = &local_degrees[0];\n  int* degree_array;\n  if (rank == 0) {\n    degree_array = new int[N];\n    std::fill(degree_array, degree_array+N, 0);\n  }\n  MPI_Gather(local_degree_array, stop-start, MPI_INT, degree_array, stop-start, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    degree = *std::max_element(degree_array, degree_array+N);\n    delete[] degree_array;\n  }\n  return degree;\n}",
            "int rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint nproc = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nproc);\n\n\tif (rank == 0) {\n\t\tint max = 0;\n\t\tint* maxs = new int[nproc];\n\n#pragma omp parallel\n\t\t{\n#pragma omp for schedule(dynamic)\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tint localmax = 0;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[i*N + j] > 0) {\n\t\t\t\t\t\t++localmax;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tint m;\n\t\t\t\tMPI_Allreduce(&localmax, &m, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\t\t\t\tmaxs[i / (N / nproc)] = m;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i < nproc; ++i) {\n\t\t\tif (max < maxs[i]) {\n\t\t\t\tmax = maxs[i];\n\t\t\t}\n\t\t}\n\n\t\tdelete[] maxs;\n\t\treturn max;\n\t}\n\telse {\n\t\tint localmax = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[rank*N + j] > 0) {\n\t\t\t\t++localmax;\n\t\t\t}\n\t\t}\n\t\tint m;\n\t\tMPI_Allreduce(&localmax, &m, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\t\treturn m;\n\t}\n}",
            "// TODO\n}",
            "// TODO: implement this function\n}",
            "// TODO: Replace me\n    int result = 0;\n    return result;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                degree++;\n            }\n        }\n        max_degree = std::max(degree, max_degree);\n    }\n\n    return max_degree;\n}",
            "// replace this line with your implementation\n}",
            "int max_degree = 0;\n\n    #pragma omp parallel for reduction(max:max_degree)\n    for(size_t i = 0; i < N; i++) {\n        int degree = 0;\n        for(size_t j = 0; j < N; j++) {\n            degree += A[N*i + j];\n        }\n        if(degree > max_degree) {\n            max_degree = degree;\n        }\n    }\n    return max_degree;\n}",
            "return 0;\n}",
            "std::vector<int> localMaxDegrees(N);\n    std::fill(localMaxDegrees.begin(), localMaxDegrees.end(), 0);\n\n    // Get local max degrees in parallel\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        int max = 0;\n        for (size_t j = 0; j < N; j++) {\n            max = max < A[i * N + j]? A[i * N + j] : max;\n        }\n        localMaxDegrees[i] = max;\n    }\n\n    // Reduce to a single value on rank 0\n    int globalMax = localMaxDegrees[0];\n    for (size_t i = 1; i < N; i++) {\n        globalMax = globalMax > localMaxDegrees[i]? globalMax : localMaxDegrees[i];\n    }\n\n    return globalMax;\n}",
            "int max = 0;\n\t#pragma omp parallel for reduction(max: max)\n\tfor (size_t i=0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j=0; j < N; ++j) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tmax = std::max(max, sum);\n\t}\n\treturn max;\n}",
            "// Fill the code here\n  int maxDegree = 0;\n#pragma omp parallel for reduction(max:maxDegree)\n  for(size_t i = 0; i < N; ++i){\n    for(size_t j = i+1; j < N; ++j){\n      maxDegree = maxDegree > A[i*N + j]? maxDegree : A[i*N + j];\n    }\n  }\n\n  int globalMaxDegree = 0;\n  MPI_Reduce(&maxDegree, &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return globalMaxDegree;\n}",
            "std::vector<int> max_degree(N, 0);\n\tint max = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t#pragma omp atomic update\n\t\t\t\tmax_degree[i]++;\n\t\t\t\t#pragma omp atomic update\n\t\t\t\tmax_degree[j]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&max_degree[0], &max, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn max;\n}",
            "// TODO: replace this line with your code\n  return 0;\n}",
            "// Fill in your code here.\n\tint maxDegree = 0;\n\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint sum = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tif(sum > maxDegree) {\n\t\t\tmaxDegree = sum;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "// TODO\n\tint myMaxDegree = 0;\n\n\tomp_set_num_threads(omp_get_num_procs());\n\n\tint procNum = 0, procRank = 0;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &procNum);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &procRank);\n\n\tint local_max_degree = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tint temp = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\ttemp += A[i * N + j];\n\t\t}\n\t\tif (temp > local_max_degree) {\n\t\t\tlocal_max_degree = temp;\n\t\t}\n\t}\n\n\tint global_max_degree = 0;\n\tMPI_Reduce(&local_max_degree, &global_max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tmyMaxDegree = global_max_degree;\n\n\treturn myMaxDegree;\n}",
            "// TODO: fill this in\n}",
            "return 0;\n}",
            "int max_degree = 0;\n#pragma omp parallel\n\t{\n\t\tint local_max_degree = 0;\n#pragma omp for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tlocal_max_degree = std::max(local_max_degree, A[i * N + j]);\n\t\t\t}\n\t\t}\n#pragma omp critical\n\t\tmax_degree = std::max(max_degree, local_max_degree);\n\t}\n\treturn max_degree;\n}",
            "int maxDegree = 0;\n  std::vector<int> maxDegreeLocal(N);\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    maxDegreeLocal[i] = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++maxDegreeLocal[i];\n      }\n    }\n  }\n\n  MPI_Reduce(maxDegreeLocal.data(), &maxDegree, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree;\n}",
            "int max_degree = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree++;\n\t\t\t}\n\t\t}\n\t\tif (max_degree < degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "std::vector<int> maxDegree(N, 0);\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            maxDegree[i] += A[i * N + j];\n        }\n    }\n\n    // TODO: replace this with MPI calls\n    return *std::max_element(maxDegree.begin(), maxDegree.end());\n}",
            "// Your code here.\n    // This will be a very short function, so we don't need any comments.\n    //\n    // Some hints:\n    //   * You can use the OpenMP parallel for loop: #pragma omp parallel for\n    //   * You can use the MPI reduction operations: MPI_Reduce, MPI_MAX\n    //\n    // Also note that the size of the array is: A.size() = N * N, and the\n    // number of rows is N, and the number of columns is N, so the total number\n    // of elements is N * N.\n    //\n    // Finally, the number of threads to use for OpenMP is given by\n    // omp_get_num_threads(), and the ID of the current thread is given by\n    // omp_get_thread_num().\n    return 0;\n}",
            "int max_degree = 0;\n#pragma omp parallel\n\t{\n\t\tint max_thread_degree = 0;\n#pragma omp for\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tint cur_degree = 0;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t++cur_degree;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (cur_degree > max_thread_degree) {\n\t\t\t\tmax_thread_degree = cur_degree;\n\t\t\t}\n\t\t}\n#pragma omp critical\n\t\tif (max_thread_degree > max_degree) {\n\t\t\tmax_degree = max_thread_degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "// TODO\n    int *a = new int[N*N];\n    for (int i = 0; i < N; ++i)\n    {\n        for (int j = 0; j < N; ++j)\n        {\n            a[i * N + j] = A[i * N + j];\n        }\n    }\n    int max = 0;\n    int rank = 0;\n    int nthreads;\n    omp_set_num_threads(8);\n    #pragma omp parallel private(nthreads)\n    {\n        nthreads = omp_get_num_threads();\n        printf(\"Hello from thread %d of %d\\n\", omp_get_thread_num(), nthreads);\n        max = 0;\n        for (int i = 0; i < N; ++i)\n        {\n            int sum = 0;\n            for (int j = 0; j < N; ++j)\n            {\n                sum += a[i * N + j];\n            }\n            if (sum > max)\n            {\n                max = sum;\n            }\n        }\n    }\n\n    return max;\n}",
            "// TODO\n\n  return 0;\n}",
            "std::vector<int> localMax(N);\n\n    // find local max degrees\n    // NOTE: A is defined in row major\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; i++) {\n\n        int max = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[N * i + j]!= 0) {\n                max++;\n            }\n        }\n        localMax[i] = max;\n    }\n\n    // send data to 0\n    // NOTE: MPI_Reduce is a collective operation\n    // https://www.open-mpi.org/doc/v2.0/man3/MPI_Reduce.3.php\n    MPI_Reduce(localMax.data(), NULL, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return 0;\n}",
            "}",
            "/* Your code goes here. */\n\tint a = 0;\n\tint sum = 0;\n\tfor(int i = 0; i < A.size(); i++){\n\t\tsum = A[i];\n\t\tif (sum > a){\n\t\t\ta = sum;\n\t\t}\n\t}\n\treturn a;\n}",
            "int maxDegree = 0;\n  // Compute the highest degree in A\n  // Your code here\n\n  return maxDegree;\n}",
            "return 0;\n}",
            "int localMaxDegree = 0;\n\n  #pragma omp parallel for reduction(max: localMaxDegree)\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      sum += A[i * N + j];\n    }\n    localMaxDegree = std::max(localMaxDegree, sum);\n  }\n\n  int globalMaxDegree;\n  MPI_Reduce(&localMaxDegree, &globalMaxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return globalMaxDegree;\n}",
            "int max_degree = 0;\n\n\t// TODO: Your code here\n\n\treturn max_degree;\n}",
            "int result = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int cur_degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            cur_degree += A[i * N + j];\n        }\n        result = std::max(result, cur_degree);\n    }\n    return result;\n}",
            "const int rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// The number of elements in each chunk of A\n\tconst size_t n = N / size;\n\n\t// The number of extra elements assigned to the last rank\n\tconst size_t extra = N % size;\n\n\t// Find the maximum degree on the subarray\n\t// The extra elements assigned to the last rank will be handled by the first rank\n\tsize_t max = 0;\n\t#pragma omp parallel for reduction(max: max)\n\tfor (size_t i = rank * n; i < ((rank == size - 1)? N : rank * n + n + extra); i++) {\n\t\tsize_t degree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tdegree += A[i * N + j];\n\t\t}\n\t\tmax = std::max(max, degree);\n\t}\n\n\t// Find the maximum degree on the subarray\n\tstd::vector<size_t> maxes(size);\n\tMPI_Gather(&max, 1, MPI_SIZE_T, maxes.data(), 1, MPI_SIZE_T, 0, MPI_COMM_WORLD);\n\n\t// Return the maximum degree on rank 0\n\tif (rank == 0) {\n\t\tmax = 0;\n\t\tfor (size_t i = 0; i < size; i++) {\n\t\t\tmax = std::max(max, maxes[i]);\n\t\t}\n\t}\n\treturn max;\n}",
            "std::vector<int> max_local(N, 0);\n\n    #pragma omp parallel\n    {\n        int id = omp_get_thread_num();\n        #pragma omp for\n        for (size_t i = 0; i < N; ++i)\n            for (size_t j = 0; j < N; ++j)\n                max_local[i] = std::max(max_local[i], A[i * N + j]);\n\n        #pragma omp single\n        {\n            int max_global = 0;\n            for (int i = 0; i < N; ++i)\n                max_global = std::max(max_global, max_local[i]);\n            printf(\"Thread %d: Maximum node degree is %d\\n\", id, max_global);\n        }\n    }\n\n    // Reduce the max values from each thread using MPI.\n    int max_result = 0;\n    MPI_Allreduce(&max_local[0], &max_result, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n    printf(\"Rank 0: Maximum node degree is %d\\n\", max_result);\n    return max_result;\n}",
            "int max = 0;\n\n    #pragma omp parallel for reduction(max: max)\n    for (size_t i = 0; i < N; i++) {\n        int localMax = 0;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j])\n                localMax++;\n        }\n\n        if (localMax > max)\n            max = localMax;\n    }\n\n    return max;\n}",
            "std::vector<int> mx_degree(omp_get_max_threads(), 0);\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    int max_degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      max_degree = max_degree > A[i * N + j]? max_degree : A[i * N + j];\n    }\n    mx_degree[omp_get_thread_num()] = max_degree > mx_degree[omp_get_thread_num()]? max_degree : mx_degree[omp_get_thread_num()];\n  }\n\n  int global_mx_degree = mx_degree[0];\n  for (size_t i = 1; i < omp_get_max_threads(); ++i) {\n    global_mx_degree = global_mx_degree > mx_degree[i]? global_mx_degree : mx_degree[i];\n  }\n\n  return global_mx_degree;\n}",
            "assert(A.size() == N*N);\n  int max = 0;\n  int localMax = 0;\n  #pragma omp parallel for reduction(max:localMax)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] > 0) ++localMax;\n      if (A[j*N + i] > 0) ++localMax;\n    }\n  int globalMax = localMax;\n  MPI_Allreduce(&localMax, &globalMax, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n  return globalMax;\n}",
            "int maxDegree = 0;\n  #pragma omp parallel for reduction(max:maxDegree)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i+1; j < N; j++) {\n      maxDegree = std::max(maxDegree, A[N*i+j]);\n    }\n  }\n  return maxDegree;\n}",
            "// YOUR CODE GOES HERE\n\tint max=0;\n\tint max2=0;\n\tfor(int i=0;i<N;i++){\n\t\tfor(int j=i+1;j<N;j++){\n\t\t\tif(A[i*N+j]==1){\n\t\t\t\tmax++;\n\t\t\t}\n\t\t\tif(max2<max){\n\t\t\t\tmax2=max;\n\t\t\t}\n\t\t\tmax=0;\n\t\t}\n\t}\n\n\treturn max2;\n}",
            "int maxDegree = 0;\n\t// TODO\n\treturn maxDegree;\n}",
            "int rank, nprocs;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n    // TODO: Compute the highest degree in A\n    int max_degree = 0;\n\n    // TODO: Find the max_degree across all ranks\n\n    // Return max_degree on rank 0\n    return max_degree;\n}",
            "// TODO\n}",
            "int result = 0;\n\tint rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint thread_count = omp_get_max_threads();\n\tint block_size = N/size/thread_count;\n\tint block_start = rank * thread_count * block_size;\n\tint block_end = block_start + block_size;\n\n\t#pragma omp parallel num_threads(thread_count)\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\tint start = block_start + tid * block_size;\n\t\tint end = block_end + tid * block_size;\n\t\tint local_result = 0;\n\t\tfor (int i = start; i < end; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\t\tlocal_result++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMPI_Reduce(&local_result, &result, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn result;\n}",
            "// TODO: Your code here\n}",
            "int highest_node_degree = 0;\n\n    // TODO: implement this\n\n    return highest_node_degree;\n}",
            "const int rank = omp_get_thread_num();\n  int maxDegree = 0;\n#pragma omp parallel for schedule(static)\n  for (int i = 0; i < N; i++) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A[i*N + j];\n    }\n    if (sum > maxDegree) {\n      maxDegree = sum;\n    }\n  }\n  return maxDegree;\n}",
            "// Insert your code here\n\tint max_degree = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint local_max_degree = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = i; j < N; j++) {\n\t\t\t\tif (A[N * i + j]!= 0)\n\t\t\t\t\tlocal_max_degree++;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif (local_max_degree > max_degree)\n\t\t\t\tmax_degree = local_max_degree;\n\t\t}\n\t}\n\n\treturn max_degree;\n}",
            "int max = 0;\n  for (int i = 0; i < N; ++i) {\n    int rowSum = 0;\n    for (int j = 0; j < N; ++j) {\n      rowSum += A[i * N + j];\n    }\n    if (rowSum > max) {\n      max = rowSum;\n    }\n  }\n  return max;\n}",
            "// TODO: Implement\n}",
            "int maxDegree = 0;\n\n\tint const commSize = omp_get_num_threads();\n\tint const rank = omp_get_thread_num();\n\tint const chunk = N / commSize;\n\tint const start = rank * chunk;\n\tint const end = rank == commSize - 1? N : (rank + 1) * chunk;\n\n\tint localMaxDegree = 0;\n\tfor (int i = start; i < end; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > localMaxDegree)\n\t\t\tlocalMaxDegree = degree;\n\t}\n\tMPI_Reduce(&localMaxDegree, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn maxDegree;\n}",
            "auto max_degree_parallel = [&]() {\n        int max_degree = 0;\n        for (int i = 0; i < N; ++i)\n            for (int j = 0; j < N; ++j)\n                max_degree = std::max(max_degree, A[i * N + j]);\n        return max_degree;\n    };\n\n    int max_degree_serial = max_degree_parallel();\n\n    int max_degree_parallel_mpi = 0;\n    if (N < 1000)\n        max_degree_parallel_mpi = max_degree_parallel();\n    else {\n        int nRanks, rank;\n        MPI_Comm_size(MPI_COMM_WORLD, &nRanks);\n        MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n        int i_start = rank * N / nRanks;\n        int i_end = (rank + 1) * N / nRanks;\n\n        int max_degree_parallel_mpi_local = max_degree_parallel();\n\n        MPI_Reduce(&max_degree_parallel_mpi_local, &max_degree_parallel_mpi, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    }\n\n    if (max_degree_parallel_mpi!= max_degree_serial)\n        throw std::runtime_error(\"Your result is incorrect!\");\n\n    return max_degree_serial;\n}",
            "// TODO: implement me!\n\treturn 0;\n}",
            "std::vector<int> degree(N, 0);\n\n\t// Count the number of incoming and outgoing edges for each node\n\t// (the matrix is symmetric).\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tdegree[i] += 1;\n\t\t\t\tdegree[j] += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the maximum degree\n\tint maxDeg = 0;\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (degree[i] > maxDeg) {\n#pragma omp critical\n\t\t\t{\n\t\t\t\tif (degree[i] > maxDeg) {\n\t\t\t\t\tmaxDeg = degree[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDeg;\n}",
            "int my_max = 0;\n  std::vector<int> my_max_arr(omp_get_max_threads());\n#pragma omp parallel\n  {\n    int thread_max = 0;\n    for (int i = 0; i < N; ++i) {\n      int row_sum = 0;\n      for (int j = 0; j < N; ++j) {\n        row_sum += A[i * N + j];\n      }\n      if (row_sum > thread_max) {\n        thread_max = row_sum;\n      }\n    }\n    my_max_arr[omp_get_thread_num()] = thread_max;\n  }\n\n  for (int i = 0; i < my_max_arr.size(); ++i) {\n    if (my_max_arr[i] > my_max) {\n      my_max = my_max_arr[i];\n    }\n  }\n\n  int max = 0;\n  MPI_Reduce(&my_max, &max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return max;\n}",
            "// TODO\n}",
            "int maxDegree = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]!= 0)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif (degree > maxDegree) {\n\t\t\tmaxDegree = degree;\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree;\n\n    // TODO\n\n    return maxDegree;\n}",
            "int maxDegree_local = 0;\n  for(size_t i=0; i<N; i++) {\n    int degree_i = 0;\n    for(size_t j=0; j<N; j++) {\n      degree_i += A[i*N+j];\n    }\n    maxDegree_local = std::max(maxDegree_local, degree_i);\n  }\n\n  // use MPI to find the global maximum of maxDegree_local\n  int maxDegree_global = 0;\n  MPI_Reduce(&maxDegree_local, &maxDegree_global, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree_global;\n}",
            "// TODO\n\treturn 0;\n}",
            "int nproc, rank;\n\n    // Get the number of MPI processes (nproc) and the rank (rank)\n\n    int maxDegree = 0;\n    for (int i = 0; i < N; i++) {\n        int sum = 0;\n        for (int j = 0; j < N; j++) {\n            sum += A[i*N + j];\n        }\n        maxDegree = std::max(maxDegree, sum);\n    }\n    return maxDegree;\n}",
            "// TODO: insert your code here\n\n  int rank = 0, size = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int max_degree = -1;\n\n  if (size == 1) {\n\n    for (int i = 0; i < N; i++) {\n      int degree = 0;\n      for (int j = 0; j < N; j++) {\n        degree += A[i*N + j];\n      }\n      if (degree > max_degree) {\n        max_degree = degree;\n      }\n    }\n\n  } else {\n\n    // TODO: insert your parallel code here\n\n  }\n\n  if (rank == 0) {\n    return max_degree;\n  } else {\n    return -1;\n  }\n\n}",
            "int max_degree = -1;\n\n\tint n_threads;\n\t\n#pragma omp parallel \n\t{\n\t\tn_threads = omp_get_num_threads();\n\t}\n\t\n\tint max_degree_per_thread[n_threads];\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tmax_degree_per_thread[omp_get_thread_num()] = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t{\n\t\t\t\tmax_degree_per_thread[omp_get_thread_num()]++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < n_threads; i++)\n\t{\n\t\tif (max_degree_per_thread[i] > max_degree)\n\t\t{\n\t\t\tmax_degree = max_degree_per_thread[i];\n\t\t}\n\t}\n\t\n\treturn max_degree;\n}",
            "// Implement this function\n    return 0;\n}",
            "int const rank = omp_get_thread_num();\n\tint const size = omp_get_num_threads();\n\tif (size == 0) {\n\t\treturn 0;\n\t}\n\n\tif (rank == 0) {\n\t\t// TODO\n\t} else {\n\t\t// TODO\n\t}\n\n\treturn 0;\n}",
            "int max_degree = 0;\n#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tdegree += A[i * N + j];\n\t\t}\n\t\tif(degree > max_degree) {\n\t\t\tmax_degree = degree;\n\t\t}\n\t}\n\treturn max_degree;\n}",
            "// TODO: insert code here\n\treturn 0;\n}",
            "if (N == 0) {\n        return 0;\n    }\n\n    int result = 0;\n#pragma omp parallel\n    {\n        int localMax = 0;\n#pragma omp for\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                localMax = std::max(localMax, A[i * N + j]);\n            }\n        }\n#pragma omp critical\n        result = std::max(result, localMax);\n    }\n    return result;\n}",
            "int maxDegree = 0;\n    // TODO\n    return maxDegree;\n}",
            "return 0;\n}",
            "int max = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tmax = std::max(max, std::min(i, j) + 1);\n\t\t\t}\n\t\t}\n\t}\n\treturn max;\n}",
            "int result = 0;\n\n\t// Fill in the solution here\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tmaxDegree++;\n\t\t}\n\t\tif (maxDegree > result)\n\t\t\tresult = maxDegree;\n\t\tmaxDegree = 0;\n\t}\n\n\treturn result;\n}",
            "int rank, size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // Count the total number of edges in A (a single rank only)\n    size_t N_edges = 0;\n    if (rank == 0) {\n        for (size_t i = 0; i < N * N; ++i)\n            N_edges += A[i];\n    }\n\n    MPI_Bcast(&N_edges, 1, MPI_SIZE_T, 0, MPI_COMM_WORLD);\n\n    // TODO: Compute the highest degree in the graph\n    int max_degree = 0;\n\n    return max_degree;\n}",
            "int* localMaxDegrees = new int[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\tint localMaxDegree = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tlocalMaxDegree = std::max(localMaxDegree, A[i*N + j]);\n\t\t}\n\t\tlocalMaxDegrees[i] = localMaxDegree;\n\t}\n\n\tint globalMaxDegree = 0;\n\tMPI_Reduce(localMaxDegrees, &globalMaxDegree, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tdelete[] localMaxDegrees;\n\treturn globalMaxDegree;\n}",
            "int max_local_degree = 0;\n  int max_degree = 0;\n  int local_degree;\n\n#pragma omp parallel private(local_degree)\n{\n  local_degree = 0;\n  for (size_t i = 0; i < N; i++) {\n#pragma omp for\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        local_degree++;\n      }\n    }\n  }\n\n#pragma omp critical\n  {\n    if (local_degree > max_local_degree) {\n      max_local_degree = local_degree;\n    }\n  }\n}\n\n  MPI_Reduce(&max_local_degree, &max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return max_degree;\n}",
            "int maxDegree = 0;\n#pragma omp parallel\n  {\n    int myMaxDegree = 0;\n    for (size_t i = 0; i < N; ++i) {\n      int rowSum = 0;\n#pragma omp for nowait\n      for (size_t j = 0; j < N; ++j) {\n        rowSum += A[i * N + j];\n      }\n#pragma omp critical\n      myMaxDegree = std::max(myMaxDegree, rowSum);\n    }\n#pragma omp critical\n    maxDegree = std::max(maxDegree, myMaxDegree);\n  }\n  return maxDegree;\n}",
            "int maxDegreeLocal = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegreeLocal = std::max(maxDegreeLocal, degree);\n  }\n\n  // Use MPI to compute the global max degree\n  int maxDegreeGlobal;\n  MPI_Reduce(&maxDegreeLocal, &maxDegreeGlobal, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegreeGlobal;\n}",
            "if (N == 0) {\n    return 0;\n  }\n\n  // compute local max degree\n  int max_degree = 0;\n  for (size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++degree;\n      }\n    }\n    max_degree = std::max(max_degree, degree);\n  }\n\n  // global max degree\n  int global_max_degree = 0;\n  MPI_Reduce(&max_degree, &global_max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return global_max_degree;\n}",
            "int max_degree = 0;\n    int local_max_degree = 0;\n\n    for (int i=0; i<N; i++){\n        int row_sum = 0;\n        for (int j=0; j<N; j++){\n            row_sum += A[i*N + j];\n        }\n        local_max_degree = std::max(row_sum, local_max_degree);\n    }\n\n    int global_max_degree;\n    MPI_Reduce(&local_max_degree, &global_max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    return global_max_degree;\n}",
            "// TODO: Your code here\n}",
            "// YOUR CODE HERE\n\tint maxDegree = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tint degree = 0;\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i*N + j] == 1) degree++;\n\t\t}\n\t\tmaxDegree = (degree > maxDegree)? degree : maxDegree;\n\t}\n\n\treturn maxDegree;\n}",
            "int maxDegree = 0;\n  int maxDegreeRank;\n  #pragma omp parallel\n  {\n    int maxDegreeLocal = 0;\n    int maxDegreeRankLocal = 0;\n    #pragma omp for nowait\n    for (size_t i = 0; i < N; i++) {\n      int degreeLocal = 0;\n      for (size_t j = 0; j < N; j++) {\n        if (A[i * N + j])\n          degreeLocal++;\n      }\n      if (degreeLocal > maxDegreeLocal) {\n        maxDegreeLocal = degreeLocal;\n        maxDegreeRankLocal = i;\n      }\n    }\n    #pragma omp critical\n    {\n      if (maxDegreeLocal > maxDegree) {\n        maxDegree = maxDegreeLocal;\n        maxDegreeRank = maxDegreeRankLocal;\n      }\n    }\n  }\n  MPI_Reduce(&maxDegree, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  return maxDegree;\n}",
            "int max = 0;\n  int local_max = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N+j] > 0)\n        #pragma omp atomic update\n        local_max++;\n    }\n  }\n\n  #pragma omp critical\n  {\n    if (local_max > max)\n      max = local_max;\n  }\n\n  return max;\n}",
            "const int rank = omp_get_thread_num();\n  const int size = omp_get_num_threads();\n\n  int mx = 0;\n  int sum = 0;\n\n  #pragma omp for schedule(dynamic) reduction(max:mx) reduction(+:sum)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i+1; j < N; j++) {\n      if (A[i*N+j] > 0) {\n        sum++;\n        mx = std::max(mx, A[i*N+j]);\n      }\n    }\n  }\n  printf(\"Rank %d: max %d, sum %d\\n\", rank, mx, sum);\n\n  return mx;\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max:maxDegree)\n  for(size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for(size_t j = 0; j < N; ++j) {\n      degree += A[i * N + j];\n    }\n    maxDegree = std::max(maxDegree, degree);\n  }\n  return maxDegree;\n}",
            "int rank;\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int localMax = 0;\n  auto const n = static_cast<int>(N);\n  auto const nThreads = static_cast<int>(omp_get_max_threads());\n  auto const nRows = n / nThreads;\n  auto const begin = rank * nRows * n;\n  auto const end = (rank + 1) * nRows * n;\n  auto const APtr = A.data() + begin;\n  #pragma omp parallel for schedule(static)\n  for (auto i = begin; i < end; i += n) {\n    int nnz = 0;\n    for (auto j = 0; j < n; ++j)\n      if (APtr[i + j]!= 0)\n        nnz++;\n    localMax = std::max(localMax, nnz);\n  }\n  std::vector<int> localMaxs(size);\n  MPI_Gather(&localMax, 1, MPI_INT, localMaxs.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return *std::max_element(localMaxs.begin(), localMaxs.end());\n}",
            "// Implement this function\n    int maxDegree = 0;\n    int local_maxDegree = 0;\n    int *row = new int[N];\n#pragma omp parallel\n{\n    int local_maxDegree = 0;\n    #pragma omp for schedule(dynamic)\n    for (int i = 0; i < N; i++)\n    {\n        int row_sum = 0;\n        for (int j = 0; j < N; j++)\n        {\n            row_sum += A[i * N + j];\n        }\n        row[i] = row_sum;\n        local_maxDegree = std::max(local_maxDegree, row[i]);\n    }\n    #pragma omp critical\n    {\n        maxDegree = std::max(maxDegree, local_maxDegree);\n    }\n}\n    delete [] row;\n    return maxDegree;\n}",
            "/* Your code here! */\n}",
            "int rank, p;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tint max_degree = 0;\n\t// Add your code here...\n\n\treturn max_degree;\n}",
            "int max_degree = 0;\n    for (size_t i = 0; i < N; ++i) {\n        int degree = 0;\n        for (size_t j = 0; j < N; ++j) {\n            degree += A[i * N + j];\n        }\n        max_degree = std::max(max_degree, degree);\n    }\n    return max_degree;\n}",
            "int maxDegree = 0;\n\n\t/* *** START YOUR CODE HERE *** */\n\t// Get the number of processes\n\tint nprocs, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// Split the matrix into equal sized rows\n\tsize_t rowsPerProc = N / nprocs;\n\tsize_t startRow = rank * rowsPerProc;\n\tsize_t endRow = startRow + rowsPerProc;\n\n\t// Find the max degree of the rows in this proc\n\tint maxDegreePerProc = 0;\n\tfor(size_t i = startRow; i < endRow; i++)\n\t{\n\t\tfor(size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif(A[i*N + j] == 1)\n\t\t\t{\n\t\t\t\tif(j > maxDegreePerProc)\n\t\t\t\t\tmaxDegreePerProc = j;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the max degree from all the procs\n\tMPI_Reduce(&maxDegreePerProc, &maxDegree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\t/* *** END YOUR CODE HERE *** */\n\n\treturn maxDegree;\n}",
            "int rank = 0, size = 0;\n  int local_max = 0;\n  int global_max = 0;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int chunkSize = N / size;\n  int startIndex = rank * chunkSize;\n  int endIndex = (rank + 1) * chunkSize;\n  if (rank == size - 1) {\n    endIndex = N;\n  }\n\n  for (int i = startIndex; i < endIndex; ++i) {\n    int max = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++max;\n      }\n    }\n    local_max = max;\n  }\n\n  MPI_Reduce(&local_max, &global_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  return global_max;\n}",
            "std::vector<int> sum(N, 0);\n\t#pragma omp parallel\n\t{\n\t\tstd::vector<int> local_sum(N, 0);\n\t\t#pragma omp for\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\t\tlocal_sum[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tsum[i] += local_sum[i];\n\t\t}\n\t}\n\tint max = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (sum[i] > max) {\n\t\t\tmax = sum[i];\n\t\t}\n\t}\n\treturn max;\n}",
            "// TODO\n  int n = A.size();\n  int max_node = 0;\n\n  #pragma omp parallel shared(A, max_node)\n  {\n    int my_id = omp_get_thread_num();\n    int my_max = 0;\n\n    #pragma omp for\n    for (int i = 0; i < n; i++) {\n      int sum = 0;\n      for (int j = 0; j < n; j++) {\n        sum += A[i*n + j];\n      }\n      my_max = sum > my_max? sum : my_max;\n    }\n\n    #pragma omp critical\n    {\n      if (my_max > max_node) max_node = my_max;\n    }\n  }\n\n  return max_node;\n}",
            "// implement this\n    return 0;\n}",
            "// TODO\n}",
            "int max_degree = 0;\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++) {\n\t\tint degree = 0;\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i * N + j] == 1)\n\t\t\t\tdegree++;\n\t\t}\n\t\tif(degree > max_degree)\n\t\t\t#pragma omp critical\n\t\t\tmax_degree = degree;\n\t}\n\treturn max_degree;\n}",
            "// TODO: Implement this function\n\n\tint max = 0;\n\tint c_max = 0;\n\n\t//#pragma omp parallel for schedule(static, 1)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint counter = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++counter;\n\t\t\t}\n\t\t}\n\t\tif (counter > max) {\n\t\t\tmax = counter;\n\t\t}\n\t}\n\tMPI_Reduce(&max, &c_max, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\treturn c_max;\n}",
            "// Your code here\n}",
            "int max = 0;\n    for (size_t i = 0; i < N; i++) {\n        int degree = 0;\n        #pragma omp parallel for reduction(+:degree)\n        for (size_t j = 0; j < N; j++) {\n            degree += A[N*i + j];\n        }\n        #pragma omp critical\n        if (max < degree) max = degree;\n    }\n    return max;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int maxDegree = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                maxDegree = std::max(maxDegree, std::max(A[i * N + j], A[j * N + i]));\n            }\n        }\n    }\n\n    int maxDegreeRank = 0;\n    MPI_Reduce(&maxDegree, &maxDegreeRank, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        return maxDegreeRank;\n    }\n}",
            "std::vector<int> local_degrees(N);\n\n    // OMP pragma to parallelize the computation of the degree for each row of A\n\n    // MPI pragma to divide the computation of the degree for each row of A across the available ranks\n    // Use MPI_Reduce to obtain the global max degree on rank 0.\n    //\n    // Hint: use a local max degree variable to compute the max degree locally on each rank\n    // Then use MPI_Reduce to obtain the global max degree on rank 0\n    //\n    // Hint: MPI_Reduce requires a custom MPI datatype:\n    // https://stackoverflow.com/questions/46013124/",
            "int degree, max_degree, rank, n_ranks;\n    int max_degree_local = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &n_ranks);\n\n#pragma omp parallel\n    {\n        int my_max_degree = 0;\n        int my_rank = omp_get_thread_num();\n        int my_n_ranks = omp_get_num_threads();\n\n        // compute the max degree of the submatrix in each thread\n#pragma omp for\n        for (int i = my_rank; i < N; i += my_n_ranks) {\n            int submatrix_max_degree = 0;\n            for (int j = 0; j < N; ++j) {\n                if (A[i * N + j] == 1) {\n                    submatrix_max_degree++;\n                }\n            }\n            if (submatrix_max_degree > my_max_degree) {\n                my_max_degree = submatrix_max_degree;\n            }\n        }\n\n        // reduce the max degrees to a single value\n        MPI_Reduce(&my_max_degree, &max_degree, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    }\n\n    if (rank == 0) {\n        max_degree_local = max_degree;\n    }\n\n    return max_degree_local;\n}",
            "// TODO\n}",
            "int maxDegree = 0;\n#pragma omp parallel for reduction(max:maxDegree)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tmaxDegree = std::max(maxDegree, sum);\n\t}\n\treturn maxDegree;\n}",
            "int rank = 0;\n  int num_processes = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n\n  int max_degree = 0;\n  std::vector<int> max_degrees(num_processes);\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    int local_max = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) local_max++;\n    }\n    max_degrees[rank] = local_max;\n  }\n  // collect results\n  if (rank == 0) {\n    for (int i = 1; i < num_processes; i++) {\n      max_degrees[0] = std::max(max_degrees[0], max_degrees[i]);\n    }\n  } else {\n    MPI_Send(&max_degrees[rank], 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  if (rank == 0) {\n    for (int i = 1; i < num_processes; i++) {\n      MPI_Recv(&max_degrees[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n  } else {\n    MPI_Recv(&max_degrees[0], 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n\n  MPI_Bcast(&max_degrees[0], num_processes, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    max_degree = max_degrees[0];\n    for (int i = 1; i < num_processes; i++) {\n      max_degree = std::max(max_degree, max_degrees[i]);\n    }\n  }\n\n  return max_degree;\n}",
            "int maxDegree = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp single\n\t\t{\n\t\t\tint maxDegree_private = 0;\n\t\t\tfor (int i = 0; i < A.size(); i++)\n\t\t\t\tfor (int j = 0; j < A.size(); j++)\n\t\t\t\t\tif (A[i] == 1)\n\t\t\t\t\t\tmaxDegree_private += A[j];\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tif (maxDegree_private > maxDegree)\n\t\t\t\t\tmaxDegree = maxDegree_private;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxDegree;\n}",
            "}",
            "int maxDegree = 0;\n\n  for (auto i = 0; i < N; ++i){\n    for (auto j = i+1; j < N; ++j){\n      if (A[j * N + i] == 1)\n\tmaxDegree++;\n    }\n  }\n\n  return maxDegree;\n}",
            "assert(A.size() == N * N);\n  std::vector<int> maxDegreeLocal(N, 0);\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        #pragma omp critical\n        {\n          maxDegreeLocal[i] += 1;\n        }\n      }\n    }\n  }\n\n  return *std::max_element(maxDegreeLocal.begin(), maxDegreeLocal.end());\n}",
            "int res = 0;\n#pragma omp parallel for reduction(max:res)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tres = std::max(res, static_cast<int>(i) + static_cast<int>(j) + 1);\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}",
            "std::vector<int> maxDegreePerRank(N, 0);\n\n  // TODO: replace this with your implementation.\n  int nb_threads = omp_get_max_threads();\n  std::vector<int> maxDegreePerThread(nb_threads, 0);\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; i++){\n    for(size_t j = 0; j < N; j++){\n      if(A[i*N + j] > 0){\n        #pragma omp atomic\n        maxDegreePerThread[omp_get_thread_num()] += 1;\n      }\n    }\n  }\n\n  for(size_t i = 0; i < nb_threads; i++){\n    maxDegreePerRank[i] = maxDegreePerThread[i];\n  }\n\n  int max_degree = 0;\n  for(size_t i = 0; i < nb_threads; i++){\n    if(max_degree < maxDegreePerRank[i]){\n      max_degree = maxDegreePerRank[i];\n    }\n  }\n\n  return max_degree;\n}",
            "// your code here\n\treturn -1;\n}",
            "// Implement this.\n\treturn -1;\n}",
            "// TODO: Insert code here\n\tint n = N;\n\tint result = 0;\n\tint local_result = 0;\n\tint result_sum = 0;\n\t\n\t#pragma omp parallel\n\t{\n\t\tint local_n = n;\n\t\tint local_result = 0;\n\t\tint local_id = omp_get_thread_num();\n\t\tint num_threads = omp_get_num_threads();\n\t\tint chunk = local_n / num_threads;\n\t\tint begin = local_id * chunk;\n\t\tint end = (local_id == num_threads - 1)? local_n : begin + chunk;\n\t\t\n\t\tfor (int i = 0; i < local_n; i++) {\n\t\t\tfor (int j = 0; j < local_n; j++) {\n\t\t\t\tif (A[begin * local_n + j] == 1) {\n\t\t\t\t\tlocal_result++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t#pragma omp critical\n\t\t{\n\t\t\tresult_sum += local_result;\n\t\t}\n\t\t\n\t}\n\t\n\tMPI_Reduce(&result_sum, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn result;\n}",
            "// TODO\n    int max = 0;\n    int threadNum = 8;\n    int threadId;\n    int* maxArr = new int[threadNum];\n    int *flag = new int[threadNum];\n    for(int i = 0; i < threadNum; i++){\n        maxArr[i] = 0;\n        flag[i] = 0;\n    }\n    #pragma omp parallel private(threadId)\n    {\n        threadId = omp_get_thread_num();\n        for(int i = 0; i < N; i++){\n            for(int j = 0; j < N; j++){\n                if(A[i * N + j] == 1){\n                    maxArr[threadId] += 1;\n                }\n            }\n        }\n        if(maxArr[threadId] > max){\n            max = maxArr[threadId];\n        }\n    }\n    MPI_Allreduce(MPI_IN_PLACE, &max, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n    return max;\n}",
            "int max = 0;\n  for (size_t i = 0; i < N; i++) {\n    int sum = 0;\n    for (size_t j = 0; j < N; j++) {\n      sum += A[i * N + j];\n    }\n    max = std::max(max, sum);\n  }\n  return max;\n}",
            "// Your code here\n\tint max = 0;\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tint sum = 0;\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t{\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t{\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tif (sum > max)\n\t\t{\n\t\t\tmax = sum;\n\t\t}\n\t}\n\treturn max;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "kokkos",
        "prompt": "#include <Kokkos_Core.hpp>\n\n/* Count the number of edges in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix.\n   Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint edgeCount(Kokkos::View<const int**> &A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Initialize an empty vector to hold the total number of edges\n\t// for each cell in the adjacency matrix\n\tKokkos::View<int *> local_edges(\"local_edges\", N);\n\t\n\t// Kokkos parallel_for loop\n\tKokkos::parallel_for(N, [&] (const int &i) {\n\t\tint num_edges = 0;\n\t\t// Loop over all rows in the adjacency matrix\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\t// Count the number of neighbors in the adjacency matrix\n\t\t\tif(A(i, j) > 0) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t\t// Store the number of edges for the current cell in the local_edges vector\n\t\tlocal_edges(i) = num_edges;\n\t});\n\t\n\t// Copy the number of edges for each cell to a new vector\n\tKokkos::View<int *> global_edges(\"global_edges\", N);\n\tKokkos::deep_copy(global_edges, local_edges);\n\t\n\t// Sum the number of edges for each cell\n\tint edge_sum = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tedge_sum += global_edges(i);\n\t}\n\t\n\t// Return the total number of edges\n\treturn edge_sum;\n}",
            "//TODO: your code here.\n    int edge_count = 0;\n    for(size_t i = 0; i < N; i++){\n        for(size_t j = i; j < N; j++){\n            if(A(i, j)!= 0){\n                edge_count++;\n            }\n        }\n    }\n    return edge_count;\n\n}",
            "Kokkos::View<int**, Kokkos::LayoutLeft> adjacencyMatrix(\"adjacencyMatrix\", N, N);\n    Kokkos::deep_copy(adjacencyMatrix, A);\n\n    Kokkos::View<int*, Kokkos::LayoutLeft> nNeighbors(\"nNeighbors\", N);\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA (int i) {\n        nNeighbors(i) = 0;\n        for (int j = 0; j < N; ++j) {\n            nNeighbors(i) += adjacencyMatrix(i, j);\n        }\n    });\n\n    Kokkos::fence();\n\n    int result;\n    Kokkos::deep_copy(result, Kokkos::subview(nNeighbors, 0));\n    for (int i = 1; i < N; ++i) {\n        result += Kokkos::subview(nNeighbors, i);\n    }\n\n    return result;\n}",
            "int eCount = 0;\n    Kokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\tKOKKOS_LAMBDA (const int& i, int& eCount) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t++eCount;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\teCount\n\t);\n\n\treturn eCount;\n}",
            "// Your code here\n\tKokkos::View<int*> counts(\"counts\", N);\n\tKokkos::parallel_for(\n\t\t\"EdgeCount\",\n\t\tKokkos::RangePolicy<Kokkos::R",
            "// Create a parallel reduction view to hold the edge count.\n  // The first argument is the initial value of the reduction.\n  // The second argument is the type of the reduction view.\n  // The third argument is the type of the view.\n  // In this case, the reduction is a sum, so the view is a sum.\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::MemoryUnmanaged> edgeCount(\"edgeCount\", 1);\n\n  // Define a functor for the parallel_reduce function.\n  class EdgeCountFunctor {\n  public:\n    // A reference to the adjacency matrix.\n    Kokkos::View<const int**> _A;\n\n    // The size of the adjacency matrix.\n    size_t _N;\n\n    // A reference to the edge count.\n    Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::MemoryUnmanaged> _edgeCount;\n\n    // Constructor.\n    EdgeCountFunctor(Kokkos::View<const int**> &A, size_t N, Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::MemoryUnmanaged> &edgeCount) :\n      _A(A), _N(N), _edgeCount(edgeCount) { }\n\n    // The parallel_reduce function will call the operator() function of this class.\n    // It will give an index to each thread.\n    // The return value of this function will be added to the edge count.\n    KOKKOS_INLINE_FUNCTION\n    int operator()(int i) const {\n      int count = 0;\n      for (int j = 0; j < _N; j++) {\n        if (i!= j && _A(i, j)) {\n          count++;\n        }\n      }\n      return count;\n    }\n\n    // When the parallel_reduce function is done, we need to add the edge count values together.\n    // This function will do that.\n    KOKKOS_INLINE_FUNCTION\n    void join(volatile int& dst, volatile int& src) const {\n      dst += src;\n    }\n  };\n\n  // Compute the edge count.\n  Kokkos::parallel_reduce(N, EdgeCountFunctor(A, N, edgeCount));\n\n  // Get the edge count.\n  int value = 0;\n  Kokkos::deep_copy(value, edgeCount);\n  return value;\n}",
            "/*\n     YOUR CODE GOES HERE\n  */\n\n  int sum = 0;\n  return sum;\n}",
            "// Create the output view.\n\tKokkos::View<int*> out(\"out\", 1);\n\n\t// Create the parallel_for lambda function.\n\t// Note the use of the RAJA::strip_mined execution pattern.\n\tauto edge_count = [=] __host__ __device__ (int i) {\n\n\t\t// Loop over all rows, but only up to N to avoid going past the end of the\n\t\t// matrix.\n\t\tint n_edges = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\n\t\t\t// If i!= j and the value at i, j is 1, then there is an edge from\n\t\t\t// vertex i to vertex j.\n\t\t\tif (i!= j && A(i, j) == 1) {\n\t\t\t\tn_edges++;\n\t\t\t}\n\t\t}\n\t\tout(0) += n_edges;\n\t};\n\n\t// Run the parallel_for.\n\tKokkos::parallel_for(N, edge_count);\n\n\t// Return the number of edges.\n\treturn out(0);\n}",
            "Kokkos::View<int*> count(\"count\", 1);\n\tKokkos::deep_copy(count, 0);\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(int i) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\tKokkos::atomic_increment(&count[0]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\tint cnt;\n\tKokkos::deep_copy(cnt, count);\n\treturn cnt;\n}",
            "using MD = Kokkos::RangePolicy<Kokkos::Rank<2>>;\n  using MT = Kokkos::TeamPolicy<Kokkos::Rank<2>>;\n\n  int num_edges = 0;\n  Kokkos::View<int*, Kokkos::HostSpace> num_edges_view(\"num_edges_view\", 1);\n  Kokkos::parallel_reduce(MD(0, N), KOKKOS_LAMBDA(const int i, int& local_num_edges) {\n    local_num_edges += A(i, i);\n  }, Kokkos::Experimental::Sum<int>(num_edges_view));\n  Kokkos::deep_copy(num_edges_view, num_edges);\n  return num_edges;\n}",
            "// create a parallel reduction to sum all the entries in the graph\n\tKokkos::View<int*, Kokkos::HostSpace> edges(\"edges\", 1);\n\tKokkos::parallel_reduce(\"Edge Count Reduction\", N,\n\t\t\t\t\t\t\tKOKKOS_LAMBDA(const int& i, int& sum) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t}, Kokkos::Experimental::Sum<int>(edges));\n\n\t// return the number of edges\n\tint numEdges = 0;\n\tKokkos::deep_copy(Kokkos::HostSpace(), edges, numEdges);\n\treturn numEdges / 2;\n}",
            "// Your code goes here\n  int res = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(const int& i, int& sum) {\n    for (int j = 0; j < N; j++) {\n      if (i!= j && A(i, j))\n        sum++;\n    }\n  }, res);\n  return res;\n}",
            "// Compute the number of edges in the graph represented by A.\n\t// Hint: you can use a Kokkos reduction for this!\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> rowSums(\"rowSums\", N);\n\n  Kokkos::parallel_for(\"computeRowSums\", N, KOKKOS_LAMBDA(const int& i) {\n    int sum = 0;\n    for (int j = 0; j < N; j++)\n      sum += A(i, j);\n    rowSums(i) = sum;\n  });\n\n  // sum the row sums\n  int totalSum = 0;\n  for (int i = 0; i < N; i++) {\n    totalSum += rowSums(i);\n  }\n  return totalSum/2;\n}",
            "// Your code here\n    return -1;\n}",
            "// TODO\n  return 0;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n  Kokkos::parallel_for(\n    \"edgeCount\",\n    Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Serial>>(0, N),\n    KOKKOS_LAMBDA (int i) {\n      int count = 0;\n      for (size_t j = 0; j < N; ++j)\n\tif (A(i, j) == 1)\n\t  count++;\n      counts(i) = count;\n    });\n  int total = Kokkos::reduction_",
            "// TODO: Fill in the code here\n\tint result = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = i + 1; j < N; j++) {\n\t\t\tif(A(i,j)) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int n = N;\n\tint n_threads = 4;\n\n\tKokkos::View<int*> n_edges(\"n_edges\", n);\n\tKokkos::parallel_for(n_threads, KOKKOS_LAMBDA(int tid) {\n\t\tint start = tid * (n / n_threads);\n\t\tint end = (tid + 1) * (n / n_threads);\n\t\tif (tid == n_threads - 1)\n\t\t\tend = n;\n\n\t\tint local_edges = 0;\n\t\tfor (int i = start; i < end; i++) {\n\t\t\tfor (int j = 0; j < i; j++) {\n\t\t\t\tif (A(i, j))\n\t\t\t\t\tlocal_edges++;\n\t\t\t}\n\t\t}\n\t\tn_edges[tid] = local_edges;\n\t});\n\n\tint total_edges = 0;\n\tfor (int i = 0; i < n_threads; i++) {\n\t\ttotal_edges += n_edges(i);\n\t}\n\n\treturn total_edges;\n}",
            "using AViewType = Kokkos::View<const int**>;\n  using RViewType = Kokkos::View<int*>;\n\n  // A is an N x N matrix, where N = A.extent(0), so the extent of the outermost\n  // index is N.\n\n  // Compute the number of edges in A\n  // Increment the number of edges for each row of A\n  // Use atomic_fetch_add to handle atomic updates\n  // Invoke the execution space of Kokkos::DefaultExecutionSpace\n  auto edgeCountLambda =\n      KOKKOS_LAMBDA(const int i) {\n    int edgeCount = 0;\n    for (int j = 0; j < A.extent(1); ++j) {\n      edgeCount += (A(i, j) == 1);\n    }\n    edgeCounts(i) = edgeCount;\n  };\n\n  // Create a view to store the number of edges for each row of A\n  RViewType edgeCounts(\"edgeCounts\", A.extent(0));\n\n  Kokkos::parallel_for(\"edgeCount\", A.extent(0), edgeCountLambda);\n  Kokkos::fence();\n\n  // Compute the total number of edges in A\n  int totalEdgeCount = 0;\n  for (int i = 0; i < A.extent(0); ++i) {\n    totalEdgeCount += edgeCounts(i);\n  }\n\n  // Return the number of edges\n  return totalEdgeCount;\n}",
            "// TODO: Add code here to count the number of edges in the graph.\n  // You may find the following Kokkos functions useful:\n  // - Kokkos::Max\n  // - Kokkos::MaxLoc\n  // - Kokkos::Sum\n  // - Kokkos::SumLoc\n\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1) count++;\n    }\n  }\n\n  return count;\n}",
            "Kokkos::View<int*> row_sums(\"row_sums\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A(i, j);\n    }\n    row_sums(i) = sum;\n  });\n  Kokkos::fence();\n  int edges = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &sum) {\n    sum += row_sums(i);\n  }, Kokkos::RangePolicy<decltype(Kokkos::DefaultExecutionSpace())>(0, 1),\n     Kokkos::Experimental::Reduce::Sum<int>(edges));\n  Kokkos::fence();\n  return edges;\n}",
            "// Create a Kokkos range to iterate over the rows and columns of A.\n    // This range is defined to have the same size as A.\n    // For example, if A is a 4x4 matrix, the range will be [0,1,2,3].\n    // The type of this range is Kokkos::Range.\n    auto range = Kokkos::RangePolicy<>(0, N);\n\n    // The sum of the number of edges in each row of A.\n    // Initialize with the value 0.\n    // The type of this reducer is Kokkos::Sum.\n    // A reducer can be used as if it were an integer, but it is actually an object\n    // with a complex structure, so it must be passed by reference.\n    Kokkos::Sum<int> sum(0);\n\n    // Loop over all the rows and columns of A, and count the number of\n    // edges in each row of A.\n    // Kokkos::parallel_for() is a for loop that will execute in parallel.\n    // The loop index variable will be i and j.\n    // The range parameter is the set of values that i and j will take.\n    // The lambda is the code that will execute for each value of (i, j).\n    // The third argument is the range of parallel execution. This should\n    // be a Kokkos::Range with the same size as the adjacency matrix A.\n    // The fourth argument is the reducer.\n    Kokkos::parallel_for(\n        \"count-edges\", range, range,\n        KOKKOS_LAMBDA(const int& i, const int& j) {\n            // If the element at the ith row and jth column of A is 1,\n            // add 1 to the value of the reducer.\n            if (A(i, j) == 1) {\n                sum += 1;\n            }\n        },\n        range);\n\n    // Return the result of the reduction.\n    return sum.value;\n}",
            "int numEdges = 0;\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\tKOKKOS_LAMBDA(const int &i, int &local_edges) {\n\t\t\tfor (int j = 0; j < i; ++j) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t++local_edges;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tnumEdges\n\t);\n\n\treturn numEdges;\n}",
            "// TODO: insert your code here\n    return 0;\n}",
            "// Define functor\n    struct CountEdgesFunctor {\n        // Reference to adjacency matrix (read-only)\n        Kokkos::View<const int**> A;\n\n        // Functor constructor\n        CountEdgesFunctor(Kokkos::View<const int**> &A)\n            : A(A) { }\n\n        // Execute the functor\n        KOKKOS_INLINE_FUNCTION\n        int operator()(const int i, const int j) const {\n            // Return the number of edges\n            return A(i, j) + A(j, i);\n        }\n    };\n\n    // Create a 2D range for the adjacency matrix\n    Kokkos::RangePolicy<Kokkos::Rank<2>> policy(0, N, 0, N);\n\n    // Apply functor to each pair of vertices\n    // Use the Kokkos::parallel_reduce function\n    // See https://kokkos.readthedocs.io/en/latest/api/md_kokkos_parallel_reduce.html\n    // for details.\n    int numEdges = Kokkos::parallel_reduce(\n            \"CountEdgesFunctor\", policy, CountEdgesFunctor(A),\n            Kokkos::Sum<int>()\n    );\n\n    // Return number of edges\n    return numEdges;\n}",
            "Kokkos::View<int**> edgeCount(\"edgeCount\", N, N);\n\tKokkos::parallel_for(\"edgeCount\", Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::TeamPolicy<>::member_type>>(0, N), KOKKOS_LAMBDA(const int &i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i > j) {\n\t\t\t\tedgeCount(i, j) = A(i, j);\n\t\t\t\tedgeCount(j, i) = A(j, i);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tedgeCount(j, i) = A(j, i);\n\t\t\t\tedgeCount(i, j) = A(i, j);\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint result = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tresult += edgeCount(i, j);\n\t\t}\n\t}\n\n\treturn result;\n}",
            "// TODO\n  int num_edge = 0;\n  int* num = (int *) malloc (sizeof(int)*N);\n  int* num_local = (int *) malloc (sizeof(int)*N);\n\n  for(int i = 0; i < N; i++)\n    num[i] = 0;\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n    for(int j = 0; j < N; j++)\n      num[i] += A(i,j);\n    num_local[i] = num[i];\n    });\n\n  for(int i = 0; i < N; i++)\n    num_edge += num_local[i];\n\n  free(num);\n  free(num_local);\n\n  return num_edge;\n}",
            "Kokkos::View<int*> numEdges(\"numEdges\", N);\n\n\tKokkos::parallel_for(\"edgeCount\", N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1)\n\t\t\t\tnumEdges(i)++;\n\t\t}\n\t});\n\n\tKokkos::parallel_reduce(\"sumEdges\", N, KOKKOS_LAMBDA(const int i, int& lsum) {\n\t\tlsum += numEdges(i);\n\t}, Kokkos::Sum<int>(0));\n\n\tint* host_ptr = Kokkos::create_mirror_view(numEdges);\n\tKokkos::deep_copy(host_ptr, numEdges);\n\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tsum += host_ptr[i];\n\n\tKokkos::",
            "using Device = Kokkos::DefaultHostExecutionSpace;\n\tusing View = Kokkos::View<int*, Device>;\n\tusing Range = Kokkos::RangePolicy<Device>;\n\tusing Sum = Kokkos::Sum<int>;\n\n\tView numEdges = View(\"numEdges\", N);\n\n\t// Initialize the output\n\tKokkos::parallel_for(Range(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tnumEdges(i) = 0;\n\t});\n\t\n\t// Count the edges\n\tKokkos::parallel_for(Range(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A(i, j) > 0)\n\t\t\t\tnumEdges(i)++;\n\t\t}\n\t});\n\t\n\t// Compute the sum of the numEdges array\n\tint total = Kokkos::",
            "int sum = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Reduce, int>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& local_sum) {\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1) {\n        local_sum++;\n      }\n    }\n  },\n  Kokkos::Sum<int>(sum));\n  return sum;\n}",
            "// TODO\n}",
            "// TODO\n\tconstexpr int team_size = 32;\n\tKokkos::View<int*> num_edges(\"num_edges\", N);\n\tKokkos::parallel_for(\"edge_count\", Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic>>>(0, N, team_size),\n\t\t\tKOKKOS_LAMBDA(const Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic>>::member_type& member) {\n\t\tconst int i = member.league_rank();\n\t\tint edges = 0;\n\t\tKokkos::parallel_reduce(Kokkos::TeamThreadRange(member, N), [&](const int j, int& local_edges) {\n\t\t\t\tlocal_edges += A(i,j);\n\t\t\t}, edges);\n\t\tnum_edges[i] = edges;\n\t});\n\tKokkos::deep_copy(num_edges, num_edges);\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += num_edges[i];\n\t}\n\treturn sum;\n}",
            "int count = 0;\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            count += A(i, j);\n        }\n    }\n    return count;\n}",
            "Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> counts(\"counts\", N);\n\n    // Kokkos::parallel_for is a convenience function for performing\n    // a parallel_for loop.\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; ++j) {\n            if (A(i,j)!= 0) {\n                counts[i]++;\n            }\n        }\n    });\n\n    Kokkos::deep_copy(A, counts);\n\n    int total = 0;\n    for (int i = 0; i < N; ++i) {\n        total += counts(i);\n    }\n\n    return total;\n}",
            "// TODO: Your code goes here.\n\n}",
            "Kokkos::View<int*> counts(\"edge_counts\", N);\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)) counts(i) += 1;\n\t\t\t}\n\t\t}\n\t);\n\treturn Kokkos::reduce_sum(counts);\n}",
            "// Initialize a Kokkos view of the number of edges in the graph\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> edgeCount(\"edgeCount\", N);\n\n\t// Initialize the number of edges in each row to 0\n\tKokkos::deep_copy(edgeCount, 0);\n\n\t// Launch a Kokkos parallel_for loop to compute the number of edges in each row\n\tKokkos::parallel_for(\n\t\t\"edgeCount\",\n\t\tKokkos::RangePolicy<Kokkos::RoundRobin<Kokkos::DefaultExecutionSpace>>(0, N),\n\t\tKOKKOS_LAMBDA(const int& rowIdx) {\n\t\t\tint& edgeCountRow = edgeCount(rowIdx);\n\t\t\tfor (size_t colIdx = 0; colIdx < N; colIdx++) {\n\t\t\t\tif (A(rowIdx, colIdx)!= 0) {\n\t\t\t\t\tedgeCountRow++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\t// Use deep_copy to copy the edgeCount view to the host memory\n\tKokkos::deep_copy(edgeCount, edgeCount);\n\n\t// Loop over the number of edges in each row and sum them up\n\tint totalEdgeCount = 0;\n\tfor (size_t rowIdx = 0; rowIdx < N; rowIdx++) {\n\t\ttotalEdgeCount += edgeCount(rowIdx);\n\t}\n\n\treturn totalEdgeCount;\n}",
            "// TODO: Compute the number of edges in the graph defined by the adjacency matrix A.\n  //       A is an NxN adjacency matrix.\n  //       Use Kokkos to compute in parallel.\n  //       Assume Kokkos has already been initialized.\n\n  return 0;\n}",
            "// You should fill in your code here!\n  return 0;\n}",
            "int output;\n\n\t// TODO: implement this\n\n\treturn output;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [=] (size_t i) {\n    // TODO: replace this code with your parallel implementation\n    counts(i) = 0;\n    for (size_t j = 0; j < N; j++) {\n      if (A(i, j) == 1) {\n        counts(i)++;\n      }\n    }\n  });\n  Kokkos::fence();\n  int count = 0;\n  for (int i = 0; i < counts.size(); i++) {\n    count += counts(i);\n  }\n  return count;\n}",
            "int numEdges = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A(i, j) == 1) numEdges++;\n\treturn numEdges;\n}",
            "int sum = 0;\n  Kokkos::parallel_reduce(\n    \"EdgeCount\",\n    N,\n    KOKKOS_LAMBDA(const size_t& i, int& s) {\n      for (size_t j = 0; j < N; j++) {\n        s += (A(i, j)!= 0);\n      }\n    },\n    sum\n  );\n  return sum;\n}",
            "// Create a parallel_for lambda to compute the number of edges\n  int numEdges = 0;\n  auto edgeCounter = KOKKOS_LAMBDA (const int i, const int j) {\n    // The following line is a parallel reduction that will be executed in parallel\n    Kokkos::atomic_fetch_add(&numEdges, A(i, j));\n  };\n\n  // Run the parallel for loop\n  Kokkos::parallel_for(\"edge_count\", N*N, edgeCounter);\n  Kokkos::fence();\n\n  // Return the number of edges\n  return numEdges;\n}",
            "int *rowCounts = new int[N];\n\tfor (int i = 0; i < N; i++) rowCounts[i] = 0;\n\n\t// add up the # of edges in each row.\n\t// this is a naive O(N^2) implementation of the following\n\t// for each row i:\n\t//   for each j:\n\t//     if A[i][j] > 0:\n\t//       rowCounts[i] += 1\n\tKokkos::parallel_for(\"EdgeCount1\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\trowCounts[i] += 1;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint *rowSums = new int[N];\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\trowSums[i] = sum;\n\t\tsum += rowCounts[i];\n\t}\n\n\tint *out = new int[sum];\n\n\tKokkos::parallel_for(\"EdgeCount2\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\tout[rowSums[i]] = j;\n\t\t\t\trowSums[i] += 1;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint edgeCount = 0;\n\tfor (int i = 0; i < sum; i++) {\n\t\tif (out[i] > i) {\n\t\t\tedgeCount++;\n\t\t}\n\t}\n\n\tdelete [] rowCounts;\n\tdelete [] rowSums;\n\tdelete [] out;\n\n\treturn edgeCount;\n}",
            "// TODO: use Kokkos to compute the number of edges in the graph\n\t\n\treturn 0;\n}",
            "int sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A(i, j)!= 0) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\treturn sum;\n}",
            "int num_edges = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(int i, int &num_edges) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A(i, j)) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}, num_edges);\n\treturn num_edges;\n}",
            "/* Your solution goes here  */\n  return 0;\n}",
            "int edgeCount = 0;\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int i) {\n        for (int j = 0; j < N; j++) {\n            if (i!= j && A(i, j) == 1) {\n                Kokkos::atomic_increment(&edgeCount);\n            }\n        }\n    });\n    return edgeCount;\n}",
            "using atomic_int_type = Kokkos::atomic<int>;\n\tKokkos::View<atomic_int_type*, Kokkos::MemoryTraits<Kokkos::Unmanaged>> count(\"count\", 1);\n\tcount(0) = 0;\n\tKokkos::parallel_for(\"Edge Count\", 1, KOKKOS_LAMBDA(const int& i) {\n\t\tfor (size_t r = 0; r < N; r++) {\n\t\t\tfor (size_t c = r + 1; c < N; c++) {\n\t\t\t\tif (A(r, c)) {\n\t\t\t\t\tcount(0).fetch_add(1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\tint result;\n\tcount(0).fetch_add(0, result);\n\treturn result;\n}",
            "// Define the functor type to be executed\n  struct CountEdges {\n    const Kokkos::View<const int**> A;\n    CountEdges(const Kokkos::View<const int**> A) : A(A) {}\n\n    // Operator for the functor.\n    // It will be executed in parallel.\n    // Use Kokkos parallel_for to schedule it.\n    KOKKOS_INLINE_FUNCTION void operator() (const size_t& i) const {\n\n      // We are looping over i from 0 to N-1.\n      // We are going to count the number of neighbors of vertex i\n      // that have value 1\n\n      int count = 0;\n\n      for (size_t j = 0; j < N; j++) {\n        if (A(i, j) == 1) {\n          count++;\n        }\n      }\n\n      // The output needs to be stored in a Kokkos::View,\n      // which is a parallel vector that can be accessed by multiple threads.\n      // Use the Kokkos::atomic_add() function to add the value of count\n      // to the appropriate location in the parallel vector.\n\n      // This is a dummy assignment to make it compile.\n      // Replace this line with the appropriate Kokkos atomic operation.\n      output(i) = count;\n    }\n  };\n\n  // Create the output vector (to be stored in parallel)\n  Kokkos::View<int*> output(\"output\", N);\n\n  // The Kokkos parallel_for() function executes the CountEdges functor in parallel\n  Kokkos::parallel_for(N, CountEdges(A));\n\n  // Compute the sum of all the entries in the output vector\n  int total = 0;\n  for (int i = 0; i < N; i++) {\n    total += output(i);\n  }\n\n  // Return the total\n  return total;\n}",
            "using view_type = Kokkos::View<int**>;\n  using functor_type = Kokkos::Example::count_edges<view_type>;\n  functor_type functor(A, N);\n  Kokkos::parallel_reduce(\"Edge count\", functor);\n  return functor.count;\n}",
            "// Kokkos parallel for, loop over every row and column\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n\t\t       KOKKOS_LAMBDA(int i) {\n\tfor (int j = 0; j < N; ++j) {\n\t  // Access the element at the ith row and jth column\n\t  // Check if the element is equal to 1\n\t  // If so, we have an edge, increment the total\n\t  if (A(i, j)) {\n\t    // Use the atomic_fetch_add function from Kokkos\n\t    // Use an int[1] array to hold the value\n\t    // The first element will be the total\n\t    // Use the default execution space to synchronize\n\t    Kokkos::atomic_fetch_add(&total[0], 1);\n\t  }\n\t}\n  });\n  return total[0];\n}",
            "using T = int;\n\tusing ExecPolicy = Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>;\n\tusing Schedule = Kokkos::Schedule<Kokkos::Static>;\n\tint numEdges = 0;\n\tKokkos::parallel_reduce(ExecPolicy(0, N), [=](const int i, int &lnumEdges) {\n\t\tlnumEdges += Kokkos::parallel_reduce(ExecPolicy(0, N), [=](const int j, int &count) {\n\t\t\tif (i < j && A(i, j)!= 0)\n\t\t\t\t++count;\n\t\t\treturn count;\n\t\t}, Schedule(Schedule::Dynamic));\n\t}, Kokkos::Sum<int>(numEdges));\n\treturn numEdges;\n}",
            "int num_edges = 0;\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\tKOKKOS_LAMBDA (const int& i, int& lsum) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i,j) > 0) {\n\t\t\t\t\t++lsum;\n\t\t\t\t}\n\t\t\t}\n\t\t}, num_edges);\n\n\treturn num_edges;\n}",
            "// Put your code here!\n  int result = 0;\n  for(size_t i = 0; i < N; i++){\n\t  for(size_t j = i + 1; j < N; j++){\n\t\t  if(A(i, j) > 0) result++;\n\t  }\n  }\n  return result;\n}",
            "/* Create a parallel_reduce to add up the elements in the matrix A.\n\t   Use the default scheduling policy. */\n\treturn Kokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t[=] __host__ __device__(int i) {\n\t\t\tint localCount = 0;\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tif (A(i, j))\n\t\t\t\t\tlocalCount++;\n\t\t\treturn localCount;\n\t\t},\n\t\t[=] __host__ __device__(int lhs, int rhs) { return lhs + rhs; }\n\t);\n}",
            "// Create output array\n    Kokkos::View<int*> edgeCount(\"edgeCount\", 1);\n\n    // Set edgeCount to 0\n    Kokkos::deep_copy(edgeCount, 0);\n\n    // Compute the number of edges in the graph\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n        KOKKOS_LAMBDA(int i) {\n            for (int j = 0; j < N; j++) {\n                if (A(i, j) == 1) {\n                    Kokkos::atomic_add(edgeCount, 1);\n                }\n            }\n        });\n\n    // Copy edgeCount back to the host\n    int out_edgeCount = 0;\n    Kokkos::deep_copy(out_edgeCount, edgeCount);\n\n    return out_edgeCount;\n}",
            "// TODO\n}",
            "int sum = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i, int &mySum) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)) {\n\t\t\t\tmySum++;\n\t\t\t}\n\t\t}\n\t}, Kokkos::Sum<int>(sum));\n\treturn sum;\n}",
            "int num_edges = 0;\n\n  Kokkos::View<const int**>::HostMirror mirrorA = Kokkos::create_mirror_view(A);\n  Kokkos::deep_copy(mirrorA, A);\n\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = 0; j < N; ++j) {\n      if(mirrorA(i,j) == 1 && i < j) {\n        ++num_edges;\n      }\n    }\n  }\n\n  return num_edges;\n}",
            "// Create a Kokkos view for the result\n\t// Must be initialized to zero\n\tKokkos::View<int> edgeCount(\"edgeCount\", 1);\n\tKokkos::deep_copy(edgeCount, 0);\n\n\t// Create a Kokkos view for the local sum\n\t// Must be initialized to zero\n\tKokkos::View<int> localSum(\"localSum\", 1);\n\tKokkos::deep_copy(localSum, 0);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [&] (int i) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tint sum = 0;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tsum += A(i, k) * A(j, k);\n\t\t\t}\n\t\t\tif (sum == 1) {\n\t\t\t\tlocalSum() += 1;\n\t\t\t}\n\t\t}\n\t});\n\t\n\t// Copy the local sums to the edgeCount\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, 1), [&] (int, int &lsum) {\n\t\tlsum += localSum();\n\t}, edgeCount);\n\n\t// Copy edgeCount from the device to the host\n\tint ec[1];\n\tKokkos::deep_copy(ec, edgeCount);\n\treturn ec[0];\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> result(\"result\", 1);\n    Kokkos::parallel_reduce(\n      Kokkos::RangePolicy<Kokkos::HostSpace>(0, N),\n      KOKKOS_LAMBDA(const int i, int &sum) {\n        for (int j = 0; j < N; ++j) {\n          if (i!= j && A(i, j) == 1) {\n            sum += 1;\n          }\n        }\n      },\n      result);\n    Kokkos::fence();\n    return result[0];\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j) > 0) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "typedef Kokkos::RangePolicy<Kokkos::OpenMP> range_policy;\n\tint numEdges = 0;\n\tfor (size_t i=0; i<N; i++) {\n\t\tfor (size_t j=i; j<N; j++) {\n\t\t\tif (i!=j) {\n\t\t\t\tauto count_functor = KOKKOS_LAMBDA(const int& i, const int& j, int& numEdges) {\n\t\t\t\t\tif (A(i,j)!=0) {\n\t\t\t\t\t\tnumEdges++;\n\t\t\t\t\t}\n\t\t\t\t};\n\t\t\t\tKokkos::parallel_for(\"countEdges\", range_policy(i,j+1),\n\t\t\t\t\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t\t\t\t\t\tcount_functor(i, j, numEdges);\n\t\t\t\t\t\t});\n\t\t\t\tKokkos::fence();\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int result = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [=] (int k, int& edgeCount) {\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tif (A(i, k) == 1) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}, result);\n\treturn result;\n}",
            "int *numEdges;\n  Kokkos::View<int*> numEdgesView(\"numEdges\",1);\n  numEdges = numEdgesView.data();\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int i) {\n\t  int tmp = 0;\n\t  for (int j = 0; j < N; j++) {\n\t\t  if (A(i,j) == 1) tmp++;\n\t  }\n\t  Kokkos::atomic_add(numEdges, tmp);\n  });\n\n  Kokkos::fence();\n\n  int numEdges_h;\n  Kokkos::deep_copy(numEdges_h, numEdgesView);\n\n  return numEdges_h;\n}",
            "int numEdges = 0;\n\n    // Fill in the body of this function\n\n    return numEdges;\n}",
            "Kokkos::View<int*> result(\"Result\", 1);\n\n    // We want to sum up all elements of A. We need a parallel reduction.\n    Kokkos::parallel_reduce(\n        Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n        KOKKOS_LAMBDA(const int i, int& sum) {\n            for (int j = 0; j < N; j++) {\n                sum += A(i, j);\n            }\n        },\n        result\n    );\n\n    // Wait for the reduction to finish.\n    Kokkos::fence();\n\n    return result(0);\n}",
            "int ans = 0;\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [=] (int i, int &localCount) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A(i, j) == 1) {\n\t\t\t\tlocalCount++;\n\t\t\t}\n\t\t}\n\t}, ans);\n\n\treturn ans;\n}",
            "Kokkos::View<int*> edge_count(\"edge_count\", N);\n\tKokkos::parallel_for(\"EdgeCount\", N, KOKKOS_LAMBDA(int i) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tcount += A(i, j);\n\t\t}\n\t\tedge_count(i) = count;\n\t});\n\tint total_edges = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\ttotal_edges += edge_count(i);\n\t}\n\treturn total_edges;\n}",
            "// Create the graph to count edges for\n\tauto A_graph = KokkosGraph::create(A, KokkosGraph::DefaultHostMirror);\n\n\t// Create the functor object to compute the number of edges in the graph\n\tstruct edgeCountFunctor {\n\t\tKokkosGraph::DefaultHostMirror::Graph& G;\n\t\tedgeCountFunctor(KokkosGraph::DefaultHostMirror::Graph& G) : G(G) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tint operator()(int i) const {\n\t\t\tint numEdges = 0;\n\t\t\tfor (auto edge = G.beginEdge(i); edge!= G.endEdge(i); ++edge) {\n\t\t\t\tnumEdges++;\n\t\t\t}\n\t\t\treturn numEdges;\n\t\t}\n\t};\n\n\t// Compute the number of edges in the graph\n\tint numEdges = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), edgeCountFunctor(A_graph), numEdges);\n\n\treturn numEdges;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> C(\"C\", N);\n    Kokkos::deep_copy(C, 0);\n    Kokkos::parallel_for(\n        Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n        KOKKOS_LAMBDA (const int i) {\n            for (int j = 0; j < N; ++j) {\n                if (A(i,j)) {\n                    C[i]++;\n                }\n            }\n        });\n    int result = 0;\n    Kokkos::parallel_reduce(\n        Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n        KOKKOS_LAMBDA (const int i, int& sum) {\n            sum += C[i];\n        },\n        Kokkos::Sum<int>(result));\n    return result;\n}",
            "// TODO\n  return -1;\n}",
            "int numEdges = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A(i, j)) {\n\t\t\t\tnumEdges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int edgeCount = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i!= j && A(i, j)!= 0) {\n        edgeCount += 1;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "int sum = 0;\n\tfor(size_t i=0; i<N; i++) {\n\t\tfor(size_t j=0; j<N; j++) {\n\t\t\tif(A(i,j)) {\n\t\t\t\tsum += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn sum;\n}",
            "// Count the number of edges in the graph defined by the adjacency matrix A.\n\t// A is an NxN adjacency matrix.\n\t// Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n\t// Example:\n\t//\n\t//\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n\t//   output: 3\n\t//\n\t// Algorithm:\n\t//\n\t// 1. Create a rank-1 View (array) of N integers.\n\t//\n\t// 2. Use Kokkos::parallel_for to loop over the graph.\n\t//\n\t// 3. For each edge (row, col):\n\t//\n\t//\t  3a. If the row-col entry is 1, increment the count at row.\n\t//\n\t//\t  3b. If the col-row entry is 1, increment the count at col.\n\t//\n\t// 4. Return the sum of the counts.\n\t//\n\t// Hint:\n\t//\n\t// - You can use Kokkos::Atomic<T>::fetch_add(&value, amount) to atomically increment an integer.\n\t//\n\t// - You can use Kokkos::parallel_for(N, my_functor()) to loop over a range of integers.\n\t//   my_functor() is a functor containing a function operator()(int i) that is called for each value of i.\n\t//   You can use Kokkos::View<int*> array(\"array\", N) to create a rank-1 View (array) of N integers.\n\n\t// TODO\n\treturn -1;\n}",
            "// TODO\n\t// You must use Kokkos::View to wrap the result, and return it\n\t// You can use the Kokkos::View constructor to allocate the result\n\t//\n\t// Hints:\n\t// - Use Kokkos::parallel_reduce\n\t// - Use Kokkos::Experimental::OpenMP to use OpenMP to parallelize the loop\n\t// - Use the Kokkos::parallel_for loop to parallelize the loop\n\t// - Use the Kokkos::Experimental::UniqueToken to generate a unique token for the reduction\n\t// - Use the Kokkos::Experimental::UniqueToken::access to access the token inside the loop\n\t// - Use the Kokkos::Experimental::UniqueToken::operator++ to increment the token inside the loop\n\n\t// Declare the View for the result\n\t// (the result will be a single integer value)\n\t// You can use the View constructor to allocate the result\n\tKokkos::View<int*> result(\"edgeCount\", 1);\n\n\t// TODO: Compute the result, store it in the View\n\t// Remember, you cannot use raw pointers in a parallel_reduce\n\t// Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [=](int i) {\n\t// \tfor (int j = 0; j < N; ++j) {\n\t// \t\tif (A(i, j) > 0) {\n\t// \t\t\t++result(0);\n\t// \t\t}\n\t// \t}\n\t// });\n\n\t// TODO: Compute the result, store it in the View\n\t// Remember, you cannot use raw pointers in a parallel_reduce\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), [=](int i, int& val) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\t++val;\n\t\t\t}\n\t\t}\n\t}, result);\n\n\t// TODO: Copy the result to the host\n\t// Hint: Use Kokkos::deep_copy to copy the result\n\n\t// TODO: return the result\n\treturn result(0);\n}",
            "Kokkos::View<int*> edgeCount(\"edgeCount\", 1);\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA(const int i, int &result) {\n    result += A(i,i);\n    for (int j = i+1; j < N; ++j) {\n      if (A(i,j) == 1) {\n        result += 1;\n      }\n    }\n  }, Kokkos::Sum<int>(edgeCount));\n  return edgeCount();\n}",
            "// TODO: Replace this code with something that uses Kokkos\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i][j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n  using HostSpace      = Kokkos::DefaultHostExecutionSpace;\n  using DeviceSpace    = Kokkos::DefaultDeviceExecutionSpace;\n  using Policy         = Kokkos::RangePolicy<ExecutionSpace>;\n\n  // Create the output array.\n  Kokkos::View<int*> edges(\"edgeCount\", N);\n\n  // The work function.\n  // This is called by the range policy.\n  KOKKOS_INLINE_FUNCTION\n  void countEdges(const int& i) {\n    // Initialize the number of edges to zero.\n    edges(i) = 0;\n\n    for (int j = 0; j < N; j++) {\n      // Check if A[i][j] is 1.\n      if (A(i, j)) {\n        // If so, increment the number of edges.\n        edges(i)++;\n      }\n    }\n  }\n\n  // Create a range policy to run the work function.\n  // Execute the parallel loop.\n  Kokkos::parallel_for(\"EdgeCountParallelFor\", Policy(0, N), countEdges);\n\n  // Sum up the results from each thread.\n  // The first argument is the input.\n  // The second argument is the output.\n  // Kokkos::parallel_reduce does this by default.\n  Kokkos::parallel_reduce(\"EdgeCountReduce\", Policy(0, N), countEdges, edges);\n\n  // Create a host view to copy the results to.\n  Kokkos::View<int*> edgesHost(\"edgeCountHost\", N);\n\n  // Copy to host.\n  Kokkos::deep_copy(edgesHost, edges);\n\n  // Print the results.\n  std::cout << \"Edge Count Results:\\n\";\n  for (int i = 0; i < N; i++) {\n    std::cout << i << \"->\" << edgesHost(i) << \"\\n\";\n  }\n\n  // Sum up the results.\n  int sum = 0;\n  for (int i = 0; i < N; i++) {\n    sum += edgesHost(i);\n  }\n\n  // Return the results.\n  return sum;\n}",
            "int count = 0;\n\n  // For each row, compute the sum of each element in the row.\n  Kokkos::parallel_reduce(\n    \"edgeCount\",\n    Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& count) {\n      count += std::accumulate(A[i], A[i] + N, 0);\n    },\n    Kokkos::Sum<int>(count)\n  );\n  return count/2;\n}",
            "// Your code here\n\n\treturn 0;\n}",
            "int edgeCount = 0;\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n    [&](int i, int &local_edge_count) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j) == 1) {\n          local_edge_count += 1;\n        }\n      }\n    },\n    edgeCount\n  );\n  return edgeCount;\n}",
            "// Create a new view to hold the number of edges per row\n  Kokkos::View<int*> edgeCount(\"edgeCount\", N);\n\n  // Initialize the edgeCount view to 0\n  Kokkos::deep_copy(edgeCount, 0);\n\n  // Set up a parallel_for loop and do a reduction on edgeCount\n  Kokkos::parallel_reduce(\"edgeCountLoop\", Kokkos::RangePolicy<>(0, N),\n      [&] (const int i, int& lsum) {\n        int sum = 0;\n        for(int j = 0; j < N; j++) {\n          if (i == j) {\n            continue;\n          }\n          if (A(i, j) == 1) {\n            sum++;\n          }\n        }\n        lsum += sum;\n      },\n      [&] (int a, int b) {\n        return a + b;\n      });\n\n  // Copy the edgeCount view to a host view and print the result\n  Kokkos::View<int*, Kokkos::HostSpace> edgeCountHost(\"edgeCountHost\", N);\n  Kokkos::deep_copy(edgeCountHost, edgeCount);\n  for (int i = 0; i < N; i++) {\n    printf(\"edgeCountHost(%d) = %d\\n\", i, edgeCountHost(i));\n  }\n\n  // Finally, return the sum of all the elements in the edgeCount view\n  return Kokkos::",
            "int num_edges = 0;\n\n\t// TODO: write code here\n\n\treturn num_edges;\n}",
            "/* TODO: Replace the return statement */\n\tint NN = 0;\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A(i, j) == 1){\n\t\t\t\tNN++;\n\t\t\t}\n\t\t}\n\t}\n\treturn NN;\n}",
            "using ExecPolicy = Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>, Kokkos::IndexType<int>>;\n\tKokkos::View<int*> workspace(\"workspace\", N);\n\tKokkos::parallel_for(\"initWorkspace\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int& i) {\n\t\tworkspace(i) = 0;\n\t});\n\tKokkos::parallel_for(\"countEdges\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int& i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t++workspace(j);\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::View<int*> sum(\"sum\", 1);\n\tKokkos::parallel_reduce(\"countEdges\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int& i, int& lsum) {\n\t\tlsum += workspace(i);\n\t}, Kokkos::Sum<int>(sum));\n\tint answer = sum();\n\tKokkos::fence();\n\treturn answer;\n}",
            "// Kokkos::parallel_reduce requires a functor that implements operator() and a reduction operation\n\tstruct MyFunctor {\n\t\tKokkos::View<const int**> A;\n\t\tsize_t N;\n\t\tMyFunctor(Kokkos::View<const int**> A, size_t N) : A(A), N(N) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator()(const size_t &i, int &count) const {\n\t\t\tint my_count = 0;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tmy_count += A(i, j);\n\t\t\t}\n\t\t\tcount += my_count;\n\t\t}\n\n\t};\n\n\t// Compute the edge count on the host (CPU)\n\tMyFunctor functor(A, N);\n\tint my_edge_count = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), functor, my_edge_count);\n\n\t// Copy my_edge_count to the device and compute the edge count there\n\tKokkos::View<int, Kokkos::HostSpace> edge_count(\"edge_count\");\n\tKokkos::deep_copy(edge_count, my_edge_count);\n\tMyFunctor functor_on_device(A, N);\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), functor_on_device, edge_count);\n\n\t// Copy edge_count back to the host\n\tint device_edge_count = 0;\n\tKokkos::deep_copy(device_edge_count, edge_count);\n\n\t// Return the total number of edges\n\treturn my_edge_count + device_edge_count;\n}",
            "int *counts = new int[N];\n\tKokkos::parallel_for(\"count_edges\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tint temp = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\ttemp += A(i, j);\n\t\t}\n\t\tcounts[i] = temp;\n\t});\n\tint total = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\ttotal += counts[i];\n\t}\n\tdelete[] counts;\n\treturn total / 2;\n}",
            "int edgeCount = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      edgeCount += A(i, j);\n    }\n  }\n  return edgeCount;\n}",
            "Kokkos::View<int**> out(Kokkos::ViewAllocateWithoutInitializing(\"\"), N, N);\n\tKokkos::parallel_for(\n\t\tKokkos::MDRangePolicy<Kokkos::Rank<2>>({0, 0}, {N, N}),\n\t\tKOKKOS_LAMBDA(const int i, const int j) {\n\t\t\tif(i!= j && A(i, j) == 1) {\n\t\t\t\tout(i, j) = 1;\n\t\t\t}\n\t\t}\n\t);\n\treturn Kokkos::reduce(Kokkos::RangePolicy<Kokkos::Rank<2>>({0, 0}, {N, N}), out, 0);\n}",
            "int sum = 0;\n\n\tauto count = KOKKOS_LAMBDA(const int i, const int j) {\n\t\tif (A(i, j) == 1) {\n\t\t\tsum++;\n\t\t}\n\t};\n\n\tKokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace> rp(0, N);\n\tKokkos::parallel_for(\"edge_count\", rp, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tcount(i, j);\n\t\t}\n\t});\n\n\tKokkos::DefaultHostExecutionSpace::fence();\n\n\treturn sum;\n}",
            "// Get the default execution space type (ie, parallel_for)\n\ttypedef Kokkos::DefaultExecutionSpace execution_space;\n\t\n\t// Create a Kokkos view to hold the number of edges in the graph.\n\t// The execution space is the default execution space.\n\tKokkos::View<int, execution_space> edge_count(\"edge count\", 1);\n\n\t// Copy the value 0 to the edge_count view\n\tKokkos::deep_copy(edge_count, 0);\n\t\n\t// Invoke the parallel_for algorithm on the default execution space\n\t// and compute the number of edges in the graph.\n\t// edge_count is passed to the functor as an argument.\n\t// A is passed to the functor as an argument.\n\tKokkos::parallel_for(N, CountEdgesFunctor(edge_count, A));\n\n\t// The edge_count view is copied back from the device to the host.\n\t// The return value is the number of edges in the graph.\n\tint host_edge_count = 0;\n\tKokkos::deep_copy(host_edge_count, edge_count);\n\treturn host_edge_count;\n}",
            "// Create a Kokkos view of size N.\n  Kokkos::View<int*> counts(\"Counts\", N);\n\n  // Define a functor to be executed in parallel.\n  struct functor {\n    Kokkos::View<const int**> A;\n    Kokkos::View<int*> counts;\n    functor(Kokkos::View<const int**> A, Kokkos::View<int*> counts) : A(A), counts(counts) {}\n    KOKKOS_INLINE_FUNCTION\n    void operator()(const int& i) const {\n      counts[i] = 0;\n      for (int j = 0; j < N; j++) {\n        counts[i] += A(i, j);\n      }\n    }\n  };\n\n  // Execute the functor using Kokkos.\n  Kokkos::parallel_for(N, functor(A, counts));\n\n  // Copy the result back to the host.\n  int *h_counts = new int[N];\n  Kokkos::deep_copy(h_counts, counts);\n\n  // Compute the sum of the counts on the host.\n  int total = 0;\n  for (int i = 0; i < N; i++) {\n    total += h_counts[i];\n  }\n\n  // Clean up.\n  delete[] h_counts;\n  counts = Kokkos::View<int*>();\n\n  return total;\n}",
            "using policy_t = Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>;\n\tusing functor_t = Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace>;\n\tfunctor_t count(N);\n\tKokkos::parallel_for(\"EdgeCounter\", policy_t(0, N), [=](int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i < j && A(i, j)) {\n\t\t\t\tKokkos::atomic_increment(&count(i));\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::fence();\n\tint result = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tresult += count(i);\n\t}\n\treturn result;\n}",
            "Kokkos::View<int*> edgeCount(\"edgeCount\", 1);\n\tKokkos::parallel_for(\n\t\t\"Edge Count\",\n\t\tKokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Static> > >(0, N, 1),\n\t\tKOKKOS_LAMBDA(const Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Static> >::member_type & teamMember) {\n\t\t\tint tid = teamMember.league_rank();\n\t\t\tint& count = Kokkos::atomic_fetch_add(&edgeCount(0), 0);\n\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (tid < i && A(tid, i) == 1) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\tKokkos::fence();\n\n\tint c = 0;\n\tKokkos::parallel_reduce(\n\t\t\"Edge Count Reduce\",\n\t\tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Static> >(0, 1),\n\t\tKOKKOS_LAMBDA(const int&, int& count) {\n\t\t\tcount += edgeCount(0);\n\t\t},\n\t\tKokkos::Sum<int>(c)\n\t);\n\tKokkos::fence();\n\n\treturn c / 2;\n}",
            "Kokkos::View<int**> row_count(\"row_count\", N, N);\n  // Add an edge to the count for the row and column of the edge\n  Kokkos::parallel_for(\n    \"edgeCount_parallel_for\",\n    Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n    KOKKOS_LAMBDA(const int &i, const int &j) {\n      if (A(i, j)) {\n        row_count(i, j) += 1;\n        row_count(j, i) += 1;\n      }\n    }\n  );\n\n  Kokkos::fence();\n\n  // Sum the counts of each row\n  Kokkos::View<int*> row_sum(\"row_sum\", N);\n  Kokkos::parallel_reduce(\n    \"edgeCount_parallel_reduce\",\n    Kokkos::RangePolicy<Kokkos::Rank<1>>(0, N),\n    KOKKOS_LAMBDA(const int &i, int &update) {\n      int count = 0;\n      for (int j = 0; j < N; j++) {\n        count += row_count(i, j);\n      }\n      update += count;\n    },\n    row_sum\n  );\n\n  Kokkos::fence();\n\n  // Sum all the counts\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    count += row_sum(i);\n  }\n  return count / 2;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> count(\"Count\", N);\n\n  /* Initialize the count array */\n  for(size_t i=0; i < N; i++) count[i] = 0;\n\n  /* Count the edges */\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [&](int i) {\n    for(size_t j = 0; j < N; j++) {\n      count[i] += A(i, j);\n    }\n  });\n  Kokkos::fence();\n\n  /* Sum up the edges */\n  int numEdges = 0;\n  for(size_t i = 0; i < N; i++) numEdges += count[i];\n\n  return numEdges;\n}",
            "Kokkos::View<const int**> a(\"a\", N, N);\n\n  Kokkos::parallel_for(\"countEdges\", Kokkos::RangePolicy<>(0, N),\n                       KOKKOS_LAMBDA(const int &i) {\n    for (int j = 0; j < N; ++j) {\n      if (i < j) {\n        if (A(i, j) > 0) {\n          a(i, j) = 1;\n        } else {\n          a(i, j) = 0;\n        }\n      } else {\n        a(i, j) = a(j, i);\n      }\n    }\n  });\n\n  Kokkos::View<int**> a_host(\"a_host\", N, N);\n  Kokkos::deep_copy(a_host, a);\n\n  int edgeCount = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (i < j) {\n        edgeCount += a_host(i, j);\n      }\n    }\n  }\n\n  return edgeCount;\n}",
            "// TODO\n}",
            "// declare a Kokkos view for the number of edges\n\tint num_edges = 0;\n\tKokkos::View<int*, Kokkos::HostSpace> num_edges_view(\"num_edges_view\");\n\tnum_edges_view(0) = 0;\n\n\t// declare a Kokkos parallel_reduce lambda function to increment the number of edges\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i, int &num_edges_local) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tnum_edges_local++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\tnum_edges_view);\n\n\t// Copy the result back to the host\n\tKokkos::deep_copy(num_edges, num_edges_view);\n\n\treturn num_edges;\n}",
            "int num_edges = 0;\n    for (size_t i=0; i<N; i++) {\n        for (size_t j=0; j<N; j++) {\n            num_edges += A(i,j);\n        }\n    }\n    return num_edges;\n}",
            "// TODO: Define the edge count kernel, which is a parallel_reduce with a lambda function.\n\t// You will need to use the range execution policy with team parallel execution.\n\t// You will need to use the Kokkos::atomic_add function to add to the result counter.\n\t// Your edge count kernel should run on all the team members, and should run on the\n\t// entire matrix.\n\t// Hint:\n\t// 1) The lambda needs to return a tuple.\n\t// 2) If the size of the range is N^2, then the lambda should be declared with 2 arguments\n\t//    (i, j).\n\t// 3) Use the Kokkos::atomic_add function to increment the result counter.\n\n\t// TODO: Define and initialize the result counter.\n\n\t// TODO: Run the edge count kernel.\n\n\t// TODO: Copy the result counter back to the host.\n\n\t// TODO: Return the value of the result counter.\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> host_view(\"host_view\", N);\n\n\t// Use a Kokkos parallel_for to fill the host view with the number\n\t// of outgoing edges for each node in the graph\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [&](int i) {\n\t\tint sum = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tsum += A(i, j);\n\t\t}\n\t\thost_view(i) = sum;\n\t});\n\n\t// Copy the view to the host\n\tint *host_view_data = host_view.data();\n\n\t// Count the number of edges\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tcount += host_view_data[i];\n\t}\n\n\treturn count;\n}",
            "// Kokkos::View<int*> result = Kokkos::View<int*>(\"result\");\n\tKokkos::View<int*> result(\"result\", 1);\n\n\ttypedef Kokkos::RangePolicy<Kokkos::Reduce<Kokkos::Cuda>, int> range_policy ;\n\ttypedef Kokkos::Reduce<Kokkos::Cuda, int> ReducerType ;\n\n\tint* result_ptr = (int *)result.data();\n\tint result_val = 0;\n\t// Kokkos::View<int*> result(\"result\", 1);\n\n\t// Kokkos::parallel_reduce(range_policy(0, N), ReducerType(result_val), [&] (const int& i, int& sum) {\n\tKokkos::parallel_reduce(range_policy(0, N), ReducerType(result), [&] (const int& i, int& sum) {\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tsum++;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\tKokkos::deep_copy(result_ptr, result);\n\n\tint result_val_host = 0;\n\tKokkos::deep_copy(result_val_host, result);\n\n\treturn result_val_host;\n}\n\nint main() {\n\tint N = 4;\n\tKokkos::View<int**> A(\"A\", N, N);\n\tA(0, 3) = 1;\n\tA(1, 3) = 1;\n\tA(2, 3) = 1;\n\tA(3, 0) = 1;\n\n\tint edge_count = edgeCount(A, N);\n\tstd::cout << \"Edge count",
            "Kokkos::View<int*> count(\"count\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tcount(i) = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tcount(i) += 1;\n\t\t\t}\n\t\t}\n\t});\n\tint total = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\ttotal += count(i);\n\t}\n\treturn total;\n}",
            "Kokkos::View<int*> result(\"result\", 1);\n  int * result_h = new int[1];\n  result_h[0] = 0;\n  Kokkos::deep_copy(result, result_h);\n\n  Kokkos::parallel_for(\n\t\t  Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Serial>>(0, N),\n\t\t  KOKKOS_LAMBDA(const int& i) {\n\t\t\t  int edges = 0;\n\t\t\t  for (int j = 0; j < N; j++) {\n\t\t\t\t  if (A(i, j)!= 0) {\n\t\t\t\t\t  edges++;\n\t\t\t\t  }\n\t\t\t  }\n\t\t\t  Kokkos::atomic_add(&result[0], edges);\n\t\t  }\n  );\n\n  Kokkos::deep_copy(result_h, result);\n  int result_d = result_h[0];\n  return result_d;\n}",
            "/*\n      Implement the edgeCount algorithm here.\n\n      A is a Kokkos view representing an NxN adjacency matrix.\n      N is the number of vertices.\n\n      You may need to call Kokkos::parallel_for to run a parallel loop.\n      You may want to use the Kokkos::atomic_fetch_add function to increment\n      a counter.\n\n      Hint: The following code will create an array of size N initialized\n      to zero:\n\n      Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> count(\"count\", N);\n    */\n}",
            "using namespace Kokkos;\n\n\t// declare a view with one entry per element of A\n\t// we'll use this to keep track of whether we've seen each element of A yet\n\tView<int*, HostSpace> seen(N);\n\n\t// initialize the \"seen\" array to all zeros\n\ttypedef typename View<int*, HostSpace>::HostMirror HostSeen;\n\tHostSeen host_seen = Kokkos::create_mirror_view(seen);\n\tfor (size_t i = 0; i < N; i++) {\n\t\thost_seen[i] = 0;\n\t}\n\tKokkos::deep_copy(seen, host_seen);\n\n\t// create a parallel_reduce functor to sum up all the entries in A\n\tint total = 0;\n\tKokkos::parallel_reduce(N, [&](int i, int &val) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1 &&!seen(j)) {\n\t\t\t\tval++;\n\t\t\t\tseen(j) = 1;\n\t\t\t}\n\t\t}\n\t}, total);\n\n\treturn total;\n}",
            "using view_type = Kokkos::View<int**>;\n\tusing functor_type = Kokkos::RangePolicy<Kokkos::Reduce<view_type, Kokkos::InitializedReduce<int>>>;\n\tview_type B(\"B\", N, N);\n\tauto B_data = B.data();\n\tauto A_data = A.data();\n\tfunctor_type policy{0, N, B_data};\n\tint result = Kokkos::parallel_reduce(policy, KOKKOS_LAMBDA (int i, view_type B) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A_data[i][j] == 1) {\n\t\t\t\tB_data[i][j] = 1;\n\t\t\t}\n\t\t}\n\t}, B);\n\treturn result;\n}",
            "Kokkos::View<int*> edgeCount(\"edgeCount\", 1);\n\n  // TODO: write parallel code to compute edgeCount\n\n  Kokkos::deep_copy(edgeCount, Kokkos::ALL(), 0);\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < i; ++j) {\n      if (A(i, j) > 0) {\n        Kokkos::atomic_add(&edgeCount(0), 1);\n      }\n    }\n  }\n  Kokkos::fence();\n\n  // TODO: deep copy edgeCount to host and return result\n  int result;\n  Kokkos::deep_copy(result, edgeCount);\n  return result;\n}",
            "int numEdges = 0;\n\n  // TODO: Compute number of edges in the graph defined by adjacency matrix A.\n\n  return numEdges;\n}",
            "// TODO\n  return 0;\n}",
            "// Add your code here.\n  //...\n  //...\n  //...\n\n  // Don't edit anything below\n  // You can use Kokkos, but you may not add anything to the graph itself.\n  // Kokkos::View<const int**> A = input;\n  // int N = input.extent(0);\n\n  Kokkos::View<int*> counter(\"counter\", N);\n  // Initialize the counter to 0\n  Kokkos::parallel_for(\"init_counter\",\n                       Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n                       KOKKOS_LAMBDA(const int i) { counter(i) = 0; });\n  // Count the edges\n  Kokkos::parallel_for(\"count_edges\",\n                       Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n                       KOKKOS_LAMBDA(const int i) {\n                         for (int j = 0; j < N; ++j) {\n                           if (A(i, j) == 1) {\n                             counter(i) += 1;\n                           }\n                         }\n                       });\n  // Sum the counters\n  int counter_sum = 0;\n  Kokkos::parallel_reduce(\"sum_counters\",\n                          Kokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n                          KOKKOS_LAMBDA(const int i, int &sum) {\n                            sum += counter(i);\n                          },\n                          Kokkos::Sum<int>(counter_sum));\n  return counter_sum;\n}",
            "// Your code goes here\n\n\t// TODO: \n\t// You should create a variable total_edges that is initialized to 0.\n\t// Then you should go through each row of the matrix and, for each row,\n\t// add up the number of times the entry is 1.\n\t// Note: You can use the following code to access entries in the matrix.\n\t//     A(i, j) = A[i][j]\n\n\tint total_edges = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\ttotal_edges += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn total_edges;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n  int result;\n\n  Kokkos::parallel_for(\"edgeCount\", Kokkos::RangePolicy<>(0, N), [=](int i) {\n    int sum = 0;\n    for (int j = 0; j < N; j++) {\n      sum += A(i,j);\n    }\n    counts(i) = sum;\n  });\n  Kokkos::deep_copy(result, counts);\n\n  return result;\n}",
            "// Create a Kokkos reduction variable\n  Kokkos::View<int, Kokkos::LayoutLeft, Kokkos::MemoryTraits<Kokkos::Unmanaged> > result(\"result\", 1);\n  Kokkos::deep_copy(result, 0);\n\n  // Use a parallel_reduce to count the number of 1's in the adjacency matrix\n  // The lambda function will be called once per thread\n  Kokkos::parallel_reduce(\n    \"count_ones\",\n    Kokkos::RangePolicy<Kokkos::Threads>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& count) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, j) > 0) {\n          count += 1;\n        }\n      }\n    },\n    result\n  );\n\n  int result_host;\n  Kokkos::deep_copy(result_host, result);\n  return result_host;\n}",
            "using viewType = Kokkos::View<const int**>;\n  using functor_type = EdgeCountFunctor<viewType>;\n  using policy_type = Kokkos::RangePolicy<Kokkos::Cuda>;\n\n  functor_type edge_count_functor(A);\n\n  Kokkos::parallel_reduce(policy_type(0, N), edge_count_functor);\n  return edge_count_functor.get_total_edges();\n}",
            "using ExecPolicy = Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>;\n  using WorkTag = Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>::work_tag;\n  using MemberType = typename Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>::member_type;\n\n  Kokkos::View<int*, WorkTag> count(\"edge count\", N);\n\n  Kokkos::parallel_for(\"edgeCount\", ExecPolicy(0, N),\n    [=](const MemberType &i) {\n      int numEdges = 0;\n      for (int j = 0; j < N; j++)\n        numEdges += A(i, j);\n      count(i) = numEdges;\n    }\n  );\n\n  Kokkos::fence();\n  int sum = 0;\n  for (int i = 0; i < N; i++)\n    sum += count(i);\n  return sum;\n}",
            "// Replace this line with your code.\n\treturn -1;\n}",
            "int edgeCount = 0;\n\n\t// Loop through the rows of the adjacency matrix A.\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic>>>(0, N),\n\t\t[&](int i, int &edgeCountLocal) {\n\t\t\t// Loop through the columns of the adjacency matrix A.\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t++edgeCountLocal;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tedgeCount);\n\n\treturn edgeCount;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\tusing size_type = Kokkos::DefaultExecutionSpace::size_type;\n\n\tKokkos::View<size_type*, Kokkos::LayoutRight, execution_space> counts(\"counts\", N);\n\n\tKokkos::parallel_for(\"edge_count\", N, KOKKOS_LAMBDA(const size_type& i) {\n\t\tsize_type count = 0;\n\t\tfor (size_type j = 0; j < N; j++) {\n\t\t\tif (A(i,j)!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tcounts(i) = count;\n\t});\n\n\tsize_type total = 0;\n\tfor (size_type i = 0; i < N; i++) {\n\t\ttotal += counts(i);\n\t}\n\n\treturn total;\n}",
            "auto edgeCount_policy = Kokkos::RangePolicy<>(0, N);\n\tKokkos::View<int*, Kokkos::HostSpace> counter(Kokkos::ViewAllocateWithoutInitializing(\"counter\"), N);\n\tKokkos::parallel_for(\"EdgeCount\", edgeCount_policy, KOKKOS_LAMBDA(const int& i) {\n\t\tcounter(i) = 0;\n\t\tfor (int j = i+1; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tcounter(i)++;\n\t\t\t}\n\t\t}\n\t});\n\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += counter(i);\n\t}\n\treturn sum;\n}",
            "// 1. Define the functor\n    class edgeCountFunctor {\n    public:\n        // 2. Define the operator of the functor\n        KOKKOS_INLINE_FUNCTION int operator()(const int i, const int j) const {\n            return (A(i,j));\n        }\n        // 3. Define the operator of the functor with a reduction tag\n        KOKKOS_INLINE_FUNCTION int operator()(const int i, const int j, const int &value) const {\n            return (value + A(i,j));\n        }\n\n        Kokkos::View<const int**> _A;\n        edgeCountFunctor(Kokkos::View<const int**> &A) : _A(A) {}\n    };\n\n    // 4. Use Kokkos::parallel_reduce to compute the result\n    int edgeCount = 0;\n    Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Tag",
            "// TODO: your code goes here\n  return -1;\n}",
            "Kokkos::View<int*> edgeCount(\"edgeCount\", N);\n\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tedgeCount(i) += A(i,j);\n\t\t}\n\t});\n\n\treturn Kokkos::reduce_sum(edgeCount);\n}",
            "using view_t = Kokkos::View<const int**>;\n    using range_t = Kokkos::RangePolicy<Kokkos::Rank<2>>;\n    using host_t = Kokkos::DefaultHostExecutionSpace;\n\n    // allocate memory for counting the number of edges\n    Kokkos::View<int*, host_t> count(\"count\", 1);\n\n    Kokkos::parallel_reduce(\n        range_t({0,0}, {N,N}),\n        KOKKOS_LAMBDA (const int i, const int j, int& count) {\n            // if neighbor exists, then increment the counter\n            if (A(i, j) > 0)\n                ++count;\n        },\n        count\n    );\n\n    // copy from device to host\n    int h_count;\n    Kokkos::deep_copy(h_count, count);\n\n    return h_count / 2;\n}",
            "// Count the number of edges in the graph defined by the adjacency matrix A.\n  // A is an NxN adjacency matrix.\n  // Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n  // Example:\n\n  // input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n  // output: 3\n\n  Kokkos::View<int**> A_copy(Kokkos::ViewAllocateWithoutInitializing(\"A_copy\"), N, N);\n  Kokkos::parallel_for(\"initialize A_copy\", Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n    KOKKOS_LAMBDA(int i, int j) {\n      A_copy(i, j) = A(i, j);\n    }\n  );\n  Kokkos::fence();\n\n  int numEdges = 0;\n  Kokkos::parallel_reduce(\"count edges\", Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n    KOKKOS_LAMBDA(int i, int j, int &numEdgesLocal) {\n      if (A_copy(i, j) == 1)\n        numEdgesLocal++;\n    },\n    numEdges\n  );\n  Kokkos::fence();\n\n  return numEdges;\n}",
            "// Kokkos parallel loop:\n  // for each row\n  //   for each column\n  //     if column!= 0\n  //       increment a Kokkos View by 1\n  //\n  // The output of the loop is a Kokkos View.\n  Kokkos::View<int*, Kokkos::HostSpace> rowEdgeCount(\"rowEdgeCount\", N);\n  Kokkos::parallel_for(\"rowLoop\", N, [&](const int i) {\n    int edgeCount = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i,j)!= 0) {\n        edgeCount++;\n      }\n    }\n    rowEdgeCount(i) = edgeCount;\n  });\n\n  // Sum up all the edge counts to get the total number of edges.\n  int edgeCount = 0;\n  for (int i = 0; i < N; ++i) {\n    edgeCount += rowEdgeCount(i);\n  }\n\n  // Make the Kokkos View memory available for other uses.\n  rowEdgeCount = 0;\n\n  // Return the total number of edges.\n  return edgeCount;\n}",
            "int result;\n\tKokkos::View<int*, Kokkos::HostSpace> cnt(Kokkos::view_alloc(Kokkos::HostSpace(), \"cnt\"), N);\n\tKokkos::parallel_for(N, [=] (const int i) { cnt(i) = 0; });\n\tKokkos::parallel_for(N, [=] (const int i) {\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tcnt(i) += A(i, j);\n\t});\n\tKokkos::HostSpace().fence();\n\tresult = 0;\n\tfor (int i = 0; i < N; ++i)\n\t\tresult += cnt(i);\n\treturn result;\n}",
            "// Get the execution space from the adjacency matrix\n\tKokkos::SpaceAccessibility<Kokkos::HostSpace, Kokkos::View<const int**>>::accessible();\n\n\t// Use a C++ lambda to define a kernel that counts edges\n\tint sum = 0;\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i, int &lsum) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (i!= j && A(i, j) == 1) {\n\t\t\t\t\t\tlsum++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\tsum);\n\n\treturn sum;\n}",
            "using ViewType = Kokkos::View<const int**>;\n  using ExecutionSpace = typename ViewType::execution_space;\n  using RangePolicy = Kokkos::RangePolicy<ExecutionSpace>;\n  using MemberType = typename RangePolicy::member_type;\n  int NEdges = 0;\n  Kokkos::parallel_for(\n    RangePolicy(0, N),\n    KOKKOS_LAMBDA(const int &i, const MemberType &member) {\n      for (int j = 0; j < N; j++) {\n        if (i!= j && A(i, j)) {\n          NEdges++;\n        }\n      }\n    });\n  return NEdges;\n}",
            "typedef Kokkos::RangePolicy<Kokkos::Rank<2>, Kokkos::Schedule<Kokkos::Dynamic> > range2d_policy;\n\n\t// allocate and initialize the atomic counter.\n\t// this counter will be used to store the number of edges we've found\n\tKokkos::View<int*, Kokkos::HostSpace> counter(\"edge_counter\", 1);\n\tint *h_counter = counter.data();\n\t*h_counter = 0;\n\tKokkos::View<int*, Kokkos::HostSpace> *d_counter;\n\tKokkos::View<int*, Kokkos::HostSpace> d_counter_h(\"edge_counter_h\", 1);\n\tKokkos::deep_copy(d_counter_h, counter);\n\tKokkos::deep_copy(d_counter, d_counter_h);\n\td_counter = &d_counter_h;\n\n\tKokkos::parallel_for(range2d_policy(0, N, 0, N),\n\t\tKOKKOS_LAMBDA(int i, int j) {\n\t\t\t// check if there is an edge from i to j\n\t\t\tint val = A(i, j);\n\t\t\tif (val == 1) {\n\t\t\t\t// if there is an edge, increment the counter\n\t\t\t\tint l_val = 0;\n\t\t\t\tKokkos::atomic_increment(l_val, d_counter);\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::deep_copy(d_counter_h, *d_counter);\n\tKokkos::deep_copy(counter, d_counter_h);\n\n\treturn *h_counter;\n}",
            "// Create the counting array.\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> count(\"count\", N);\n\n  // Count the number of edges in each row.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      count(i) += A(i, j);\n    }\n  });\n\n  // Count the total number of edges in the graph.\n  // This must be done in a separate loop because of Kokkos::parallel_reduce.\n  int sum = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& local_sum) {\n    local_sum += count(i);\n  }, sum);\n\n  return sum / 2;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\tusing RP = Kokkos::RangePolicy<ExecutionSpace>;\n\tusing member_t = Kokkos::TeamPolicy<ExecutionSpace>::member_type;\n\n\tint numEdges = 0;\n\tKokkos::parallel_reduce(RP(0, N), KOKKOS_LAMBDA(const int& i, int& localNumEdges) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tKokkos::parallel_for(Kokkos::TeamThreadRange(member_t(0, N), A[i][j]), [&](int k) {\n\t\t\t\tif (A[i][j] > 0) {\n\t\t\t\t\t++localNumEdges;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}, numEdges);\n\n\treturn numEdges / 2;\n}",
            "// TODO: Implement the code here.\n    return 0;\n}",
            "int n_edges = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\t\t\t\t\tKOKKOS_LAMBDA (const int& i, int& sum) {\n\t\t\t\t\t\t\t  for (int j = 0; j < N; ++j) {\n\t\t\t\t\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t\t\t\t  sum += 1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t}, n_edges);\n\treturn n_edges;\n}",
            "Kokkos::View<int*> row_sums(\"RowSums\", N);\n\n\t// Add the entries on each row.\n\tKokkos::parallel_for(\"Add Row Sums\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(int i) {\n\t\t\tint sum = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tsum += A(i, j);\n\t\t\t}\n\t\t\trow_sums(i) = sum;\n\t\t}\n\t);\n\n\t// Add the entries on each column.\n\tKokkos::View<int*> col_sums(\"ColSums\", N);\n\tKokkos::parallel_for(\"Add Col Sums\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(int i) {\n\t\t\tint sum = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tsum += A(j, i);\n\t\t\t}\n\t\t\tcol_sums(i) = sum;\n\t\t}\n\t);\n\n\t// Compare row_sums and col_sums to find the number of edges in the graph.\n\tint edge_count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (row_sums(i) == col_sums(i)) {\n\t\t\tedge_count += row_sums(i);\n\t\t}\n\t}\n\n\treturn edge_count;\n}",
            "// Implement me!\n    return 0;\n}",
            "//TODO\n\tint edgeCount = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) edgeCount++;\n\t\t}\n\t}\n\treturn edgeCount;\n}",
            "// TODO: Your code here\n}",
            "int count = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t\t\t\t\t\tKOKKOS_LAMBDA(int i, int& lsum) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\t++lsum;\n\t\t\t}\n\t\t}\n\t}, count);\n\treturn count;\n}",
            "// Create a Kokkos view to store the results\n\tKokkos::View<int*, Kokkos::HostSpace> counts(\"edge_counts\", N);\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) continue;\n\t\t\tif (A(i, j) == 1) count++;\n\t\t}\n\t\tcounts(i) = count;\n\t});\n\tKokkos::fence();\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += counts(i);\n\t}\n\treturn sum;\n}",
            "int result = 0;\n\n  // TODO: Implement\n\n  return result;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n\tKokkos::deep_copy(counts, 0);\n\n\tauto edgeCounts = KOKKOS_LAMBDA(const int &i, const int &j, const int &val) {\n\t\tif (i!= j && val == 1) {\n\t\t\tKokkos::atomic_increment(&(counts(i)));\n\t\t}\n\t};\n\n\tKokkos::RangePolicy<Kokkos::Reduce<Kokkos::RangeTag>> policy(0, N);\n\tKokkos::parallel_for(policy, KOKKOS_LAMBDA(const int &i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tedgeCounts(i, j, A(i, j));\n\t\t}\n\t});\n\n\tint sum = 0;\n\tauto sumReduce = KOKKOS_LAMBDA(int &value, const bool final) {\n\t\tif (final) {\n\t\t\tvalue = 0;\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tvalue += counts(i);\n\t\t\t}\n\t\t}\n\t};\n\n\tKokkos::parallel_reduce(policy, sumReduce, sum);\n\n\treturn sum;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> sum(\"sum\", 1);\n\tKokkos::parallel_for( \"edge-count\", N, KOKKOS_LAMBDA(int i) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) > 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tKokkos::atomic_add(&sum(0), count);\n\t});\n\tKokkos::fence();\n\treturn sum(0);\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n  using view_type = Kokkos::View<int*, execution_space>;\n  auto edge_count_view = view_type(\"edge_count\", 1);\n  auto edge_count_host = Kokkos::create_mirror_view(edge_count_view);\n\n  Kokkos::parallel_for(\"edge_count\", N, KOKKOS_LAMBDA (const int i) {\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        Kokkos::atomic_fetch_add(edge_count_view.data(), 1);\n      }\n    }\n  });\n  Kokkos::deep_copy(edge_count_host, edge_count_view);\n  return edge_count_host(0);\n}",
            "// your code here\n}",
            "Kokkos::View<int**> B(\"B\", N, N);\n  Kokkos::deep_copy(B, A);\n\n  // TODO: insert code here\n\n  return -1;\n}",
            "Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> n(\n\t\t\"n\", N);\n\tKokkos::parallel_for(\"set\", N, KOKKOS_LAMBDA(int i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tn(i)++;\n\t\t\t}\n\t\t}\n\t});\n\n\tint sum = 0;\n\tKokkos::parallel_reduce(\"sum\", N, KOKKOS_LAMBDA(int i, int &update) {\n\t\tupdate += n(i);\n\t}, sum);\n\n\treturn sum;\n}",
            "using view_t = Kokkos::View<const int**>;\n\tusing view_t_host = typename view_t::HostMirror;\n\n\t// Create a Kokkos view from the input\n\tview_t A_device(\"A\", N, N);\n\tA_device = A;\n\n\t// Create a mirror view and copy the input to it\n\tview_t_host A_host(\"A\", N, N);\n\tKokkos::deep_copy(A_host, A_device);\n\n\t// Create a Kokkos view to store the result\n\tKokkos::View<int, Kokkos::HostSpace> result(\"result\", 1);\n\n\t// Create a Kokkos policy\n\tusing policy_t = Kokkos::TeamPolicy<Kokkos::HostSpace>;\n\tpolicy_t policy(N, Kokkos::AUTO);\n\n\t// Initialize the result to zero\n\tresult() = 0;\n\n\t// Create a functor\n\tstruct edgeCounter {\n\t\tconst view_t_host A;\n\t\tview_t_host result;\n\n\t\tedgeCounter(const view_t_host &A, view_t_host &result) :\n\t\t\tA(A), result(result) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator()(const int &i) const {\n\t\t\tfor (int j = 0; j < A.dimension_1(); ++j) {\n\t\t\t\tif (i < j) {\n\t\t\t\t\tif (A(i,j) == 1) {\n\t\t\t\t\t\tKokkos::atomic_increment(result.data());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\t// Launch the functor on the device\n\tKokkos::parallel_for(\"edgeCounter\", policy, edgeCounter(A_host, result));\n\n\t// Copy the result from device to host\n\tint result_host = 0;\n\tKokkos::deep_copy(result_host, result);\n\n\treturn result_host;\n}",
            "// You may use Kokkos::View and Kokkos::RangePolicy.\n    // You may use Kokkos::atomic_add() to update the edge count variable.\n    // You may use Kokkos::parallel_for() to launch parallel threads.\n    // You may use Kokkos::TeamPolicy to parallelize over groups of edges.\n\n    return 0;\n}",
            "// Declare a Kokkos::View to count the number of edges, then initialize to 0.\n  Kokkos::View<int> num_edges(\"num_edges\", 1);\n  Kokkos::deep_copy(num_edges, 0);\n\n  // TODO: Fill this in\n  // The Kokkos parallel_for loop will execute the code in the lambda\n  // function for each index of i from 0 to N-1.\n\n\n  // TODO: Fill this in\n  // The Kokkos parallel_for loop will execute the code in the lambda\n  // function for each index of j from 0 to N-1.\n\n\n  // TODO: Fill this in\n  // The Kokkos parallel_reduce will execute the code in the lambda\n  // function for each index of k from 0 to N-1.\n\n\n  // TODO: Fill this in\n  // Kokkos::deep_copy() copies the View into the host memory.\n\n\n  return num_edges[0];\n}",
            "int result = 0;\n\n  // TODO: replace this with a parallel Kokkos kernel\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A(i, j) == 1)\n        result += 1;\n\n  return result;\n}",
            "int numEdges = 0;\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int& numEdges) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (i!= j && A(i, j)!= 0) {\n\t\t\t\t\t++numEdges;\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\tnumEdges\n\t);\n\n\treturn numEdges;\n}",
            "// TODO\n  // count edges in the adjacency matrix\n  int numEdges = 0;\n  for(int i=0; i < N; i++){\n    for(int j=0; j < N; j++){\n      if(i!=j && A(i,j)){\n        numEdges++;\n      }\n    }\n  }\n  return numEdges;\n}",
            "// Kokkos::parallel_for to compute in parallel\n\t// Use atomic_add to safely increment the count\n\t// Atomic_add is from the Kokkos::Atomic namespace\n\t// Use Kokkos::RangePolicy to define the loop\n\t// Use Kokkos::parallel_for to compute in parallel\n\n\t// TODO: add parallel_for loop\n\n\t// return count\n}",
            "Kokkos::View<int*> edge_count(\"edge_count\", 1);\n  Kokkos::parallel_for(\n\t\t       \"edge_count\",\n\t\t       1,\n\t\t       KOKKOS_LAMBDA(const int &) {\n\n\t\t\t // Count the edges in the graph\n\t\t\t int local_count = 0;\n\t\t\t for (size_t i = 0; i < N; i++) {\n\t\t\t   for (size_t j = i + 1; j < N; j++) {\n\t\t\t     if (A(i, j)!= 0) {\n\t\t\t       local_count++;\n\t\t\t     }\n\t\t\t   }\n\t\t\t }\n\n\t\t\t // Sum the number of edges over all parallel executions\n\t\t\t Kokkos::atomic_add(&edge_count(0), local_count);\n\t\t       });\n  Kokkos::fence();\n\n  return edge_count(0);\n}",
            "// Create a 1D view with the same data as A, but with the shape (N, N) flattened into (N * N)\n    // This allows us to run an algorithm that works on a 1D view\n    auto flatA = Kokkos::subview(A, Kokkos::ALL(), Kokkos::ALL());\n\n    // Run Kokkos reduce\n    // See https://kokkos.readthedocs.io/en/latest/api/reducers.html\n    // The lambda function captures by reference the variable N, which is used to get the number of rows\n    return Kokkos::parallel_reduce(\n        Kokkos::RangePolicy<Kokkos::Cuda>(0, N * N),\n        KOKKOS_LAMBDA(const int i, int& edgeCount) {\n            // If the element of A is 1, add one to edge count\n            if (flatA(i) == 1) {\n                edgeCount++;\n            }\n        },\n        0);\n}",
            "const auto policy = Kokkos::RangePolicy<Kokkos::Reduce<Kokkos::ReduceSum<int>>, int>(0, N);\n\tKokkos::View<int, Kokkos::LayoutLeft, Kokkos::MemoryUnmanaged> count(\"count\", 1);\n\tKokkos::parallel_reduce(\n\t\tpolicy,\n\t\tKOKKOS_LAMBDA(const int i, int &local_count) {\n\t\t\tlocal_count += A(i, N) - A(i, 0);\n\t\t},\n\t\tcount);\n\tint result = 0;\n\tKokkos::deep_copy(result, count);\n\treturn result;\n}",
            "auto A_host = Kokkos::create_mirror_view(A);\n    Kokkos::deep_copy(A_host, A);\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (i < j && A_host(i, j)) ++count;\n        }\n    }\n    return count;\n}",
            "using A_t = Kokkos::View<const int**>;\n\tusing i_t = Kokkos::DefaultHostExecutionSpace::size_type;\n\tint num_edges = 0;\n\n\tKokkos::parallel_reduce(\"Edge Count\", Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n\t\tKOKKOS_LAMBDA(const i_t i, int &update) {\n\t\t\tint num_edges_i = 0;\n\t\t\tfor (i_t j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tnum_edges_i++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tupdate += num_edges_i;\n\t\t},\n\t\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>, Kokkos::Experimental::UniqueTokenScope::Global>,\n\t\tKokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>::make_topology(),\n\t\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>, Kokkos::Experimental::UniqueTokenScope::Global>(Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>::get_topology()),\n\t\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>, Kokkos::Experimental::UniqueTokenScope::Global>(Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>::get_topology()).get_max_concurrency(),\n\t\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>, Kokkos::Experimental::UniqueTokenScope::Global>(Kokkos::Experimental::HierarchicalTaskScheduler<Kokkos::DefaultHostExecutionSpace>::get_topology()).get_max_concurrency(),\n\t\tnum_edges);\n\n\treturn num_edges;\n}",
            "// Your code goes here\n\n\t// You can use the Kokkos::parallel_for and Kokkos::parallel_reduce\n\t// functions to do this work in parallel.\n\n\treturn -1;\n}",
            "const int nthreads = 16;\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::CudaUVMSpace> out(\"edgeCount_out\", 1);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Cuda>>(0, N, nthreads),\n\t\t[=](const int i) {\n\t\t\tint n = 0;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tn += A(i, j);\n\t\t\t}\n\t\t\tatomicAdd(&out(0), n);\n\t\t}\n\t);\n\tKokkos::fence();\n\tint result;\n\tKokkos::deep_copy(result, out);\n\treturn result;\n}",
            "// Kokkos::View<int*> edgeCounts(\"edgeCounts\", N);\n\t// edgeCounts = 0;\n\n\t// Kokkos::parallel_for(\"EdgeCountLoop\",\n\t// \t\t\t\t\t  Kokkos::RangePolicy<>(0, N),\n\t// \t\t\t\t\t  KOKKOS_LAMBDA(int i) {\n\t// \tfor(int j = 0; j < N; j++) {\n\t// \t\tedgeCounts(i) += A(i, j);\n\t// \t}\n\t// });\n\n\t// int* edgeCounts_h = new int[N];\n\t// Kokkos::deep_copy(edgeCounts_h, edgeCounts);\n\n\t// int totalEdgeCount = 0;\n\t// for(int i = 0; i < N; i++) {\n\t// \ttotalEdgeCount += edgeCounts_h[i];\n\t// }\n\t// delete[] edgeCounts_h;\n\t// return totalEdgeCount / 2;\n\n\tint totalEdgeCount = 0;\n\tKokkos::parallel_reduce(\"EdgeCountReduce\",\n\t\t\t\t\t\t\tKokkos::RangePolicy<>(0, N),\n\t\t\t\t\t\t\tKOKKOS_LAMBDA(int i, int& edgeCount) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tedgeCount += A(i, j);\n\t\t}\n\t},\n\ttotalEdgeCount);\n\treturn totalEdgeCount / 2;\n}",
            "using view = Kokkos::View<const int**>;\n  using range = Kokkos::RangePolicy<Kokkos::Rank<2>>;\n  using exec = Kokkos::TeamPolicy<Kokkos::Rank<2>>;\n  Kokkos::View<int*,Kokkos::HostSpace> h_result(\"h_result\");\n  Kokkos::View<int*,Kokkos::HostSpace> h_total(\"h_total\");\n\n  Kokkos::View<int*,Kokkos::HostSpace> result(\"result\");\n  Kokkos::View<int*,Kokkos::HostSpace> total(\"total\");\n  result = 0;\n  total = 0;\n\n  // This is a parallel_for loop using 2D tiles\n  Kokkos::parallel_for( \"tile_parallel_for\",\n      exec( N/2, N/2, 1 ),\n      KOKKOS_LAMBDA ( const int &i, const int &j ) {\n\n          // This is a parallel_reduce loop using 1D tiles\n          Kokkos::parallel_reduce( Kokkos::ThreadVectorRange(i,j),\n              [&] (const int &ii, int &lsum ) {\n\n              lsum += A(ii,j);\n\n          }, result(i));\n      } );\n\n  Kokkos::deep_copy(h_result, result);\n  Kokkos::deep_copy(h_total, total);\n\n  int sum = 0;\n  for (int i = 0; i < N/2; ++i) {\n    sum += h_result[i];\n  }\n\n  Kokkos::parallel_reduce(range(0,N),\n      [&] (const int& i, int& lsum) {\n      for (int j = 0; j < N; ++j) {\n        lsum += A(i,j);\n      }\n    }, total[0]);\n\n  Kokkos::deep_copy(h_total, total);\n\n  return sum + h_total[0];\n}",
            "// Create a Kokkos array of size NxN to hold the final count\n  Kokkos::View<int**> B(\"B\", N, N);\n\n  // Count the number of edges in A\n  Kokkos::parallel_for(\n      \"Edge Count Parallel For\",\n      Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n      KOKKOS_LAMBDA(int i, int j) { B(i, j) = 0; });\n\n  Kokkos::parallel_for(\n      \"Edge Count Parallel For\",\n      Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n      KOKKOS_LAMBDA(int i, int j) {\n        if (A(i, j) == 1)\n          B(i, j) = 1;\n      });\n\n  // Get the results\n  Kokkos::View<int*> C(\"C\", N);\n\n  Kokkos::parallel_for(\n      \"Edge Count Parallel For\",\n      Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n      KOKKOS_LAMBDA(int i, int j) { C(i) = B(i, j) + B(j, i); });\n\n  int count = 0;\n  Kokkos::parallel_reduce(\n      \"Edge Count Parallel Reduce\",\n      Kokkos::RangePolicy<Kokkos::Rank<1>>(0, N),\n      KOKKOS_LAMBDA(int i, int &local_count) {\n        if (C(i) > 0)\n          local_count += 1;\n      },\n      Kokkos::Sum<int>(count));\n\n  Kokkos::fence();\n\n  return count;\n}",
            "// Fill in your code here to return the number of edges in the graph\n  int count = 0;\n  for(int i=0; i<N; i++){\n  \tfor(int j=0; j<N; j++){\n\t\tif (A(i,j) == 1){\n\t\t\tcount += 1;\n\t\t}\n\t}\n  }\n  return count;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n\n\t/*\n\t  Your code here\n\t*/\n\t\n\t// Kokkos::parallel_for(\"edgeCount\", N, KOKKOS_LAMBDA(int i) {\n\t// \tfor(int j=0; j<N; j++) {\n\t// \t\tif(A(i,j) == 1) {\n\t// \t\t\tcounts(i) = counts(i)+1;\n\t// \t\t}\n\t// \t}\n\t// });\n\t// Kokkos::fence();\n\t\n\treturn counts(0);\n}",
            "// TODO: fill in the body of this function\n\n\treturn 0;\n}",
            "Kokkos::View<int**, Kokkos::LayoutLeft> C = Kokkos::View<int**, Kokkos::LayoutLeft>(\"C\", N, N);\n  Kokkos::deep_copy(C, A);\n\n  Kokkos::parallel_for(\"EdgeCount\", N, KOKKOS_LAMBDA(const int i) {\n    for (int j = i+1; j < N; j++) {\n      C(i, j) += C(j, i);\n      C(j, i) = 0;\n    }\n  });\n\n  Kokkos::fence();\n\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = i+1; j < N; j++) {\n      if (C(i, j) > 0) {\n        count++;\n      }\n    }\n  }\n\n  Kokkos::fence();\n\n  return count;\n}",
            "// Your code here!\n}",
            "using ExecSpace = Kokkos::DefaultExecutionSpace;\n\n    // Create a view for the output.\n    Kokkos::View<int*, ExecSpace> B(\"B\", 1);\n\n    // Initialize the output view to 0.\n    Kokkos::deep_copy(B, 0);\n\n    // Invoke the functor and wait for it to complete.\n    Kokkos::parallel_reduce(\n        Kokkos::RangePolicy<ExecSpace>(0, N),\n        [=] (int i, int& b) {\n            for (int j = 0; j < N; j++) {\n                if (i!= j) {\n                    // Note: the accesses to A and B are non-coherent.\n                    // Kokkos will automatically handle the synchronization.\n                    if (A(i, j) == 1) {\n                        b += 1;\n                    }\n                }\n            }\n        },\n        [=] (int& b1, int& b2) {\n            b1 += b2;\n        }\n    );\n\n    // Copy the results from the device back to the host.\n    int b = 0;\n    Kokkos::deep_copy(b, B);\n\n    return b;\n}",
            "int numEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      int value = A(i, j);\n      Kokkos::atomic_fetch_add(&numEdges, value);\n    }\n  }\n  return numEdges;\n}",
            "// TODO\n\treturn 0;\n}",
            "int result = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(0, N), [&] (const int i, int& lsum) {\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) == 1) {\n        lsum++;\n      }\n    }\n  }, result);\n  return result;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n  using Policy = Kokkos::TeamPolicy<ExecutionSpace>;\n  using MemberType = typename Policy::member_type;\n\n  struct Functor {\n    Kokkos::View<const int**> A;\n    size_t N;\n\n    KOKKOS_INLINE_FUNCTION\n    Functor(Kokkos::View<const int**> A, size_t N)\n        : A(A), N(N) {}\n\n    KOKKOS_INLINE_FUNCTION\n    void operator()(const MemberType & teamMember) const {\n      const int i = teamMember.league_rank() * teamMember.team_size() +\n        teamMember.team_rank();\n      if (i >= N) return;\n\n      int cnt = 0;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)!= 0) cnt++;\n      }\n      teamMember.team_reduce(Kokkos::Sum<int>(), cnt);\n    }\n  };\n\n  const int teamSize = 32;\n  const int numTeams = N / teamSize + (N % teamSize == 0? 0 : 1);\n  Functor functor(A, N);\n  Kokkos::parallel_for(\n      \"Edge count\", Policy(numTeams, Kokkos::AUTO), functor);\n  Kokkos::fence();\n\n  int cnt = 0;\n  Kokkos::parallel_reduce(\n      \"Edge count\", Policy(1, Kokkos::AUTO), functor, cnt);\n  Kokkos::fence();\n\n  return cnt;\n}",
            "Kokkos::View<int*> counts(\"edgeCounts\", N);\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n        int localCount = 0;\n        for (int j = 0; j < N; ++j) {\n            localCount += A(i, j);\n        }\n        counts[i] = localCount;\n    });\n    return std::accumulate(counts.data(), counts.data() + N, 0);\n}",
            "Kokkos::View<int*> count(\"count\", 1);\n\tKokkos::parallel_reduce(\"edge_count\", N, KOKKOS_LAMBDA(int i, int &lsum) {\n\t\tfor (int j=0; j < N; ++j)\n\t\t\tlsum += A(i, j);\n\t}, Kokkos::Sum<int>(count));\n\n\treturn count() / 2;\n}",
            "int count = 0;\n\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t\t[&] (int i, int& lsum) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t\tlsum++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t\tKokkos::Sum<int>(count));\n\n\treturn count;\n}",
            "// TODO\n  // Declare a variable edgeCount, and initialize to 0.\n  // Declare a Kokkos parallel_for loop with the following arguments:\n  // 1. a range policy, from 0 to N\n  // 2. a lambda function\n  // The lambda function:\n  // 1. declares a private variable edgeCount, initialized to 0\n  // 2. computes the number of edges for the row i, and adds to the private edgeCount\n  // 3. adds edgeCount to the global edgeCount variable\n  // 4. returns edgeCount\n\n  return 0;\n}",
            "int edgeCount = 0;\n\t// TODO\n\t// Count the number of edges in the adjacency matrix A, and store the result in edgeCount\n\t// Use Kokkos parallel_for\n\t// Assume Kokkos has already been initialized.\n\n\tKokkos::parallel_for( \"EdgeCount\", N, [&] (const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tedgeCount += 1;\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::fence();\n\n\treturn edgeCount;\n}",
            "Kokkos::View<int**> A_temp(\"A_temp\", N, N);\n\tKokkos::deep_copy(A_temp, A);\n\n\t// Count the number of edges\n\tint numEdges = 0;\n\n\t// TODO: Compute the number of edges using a parallel for loop\n\n\treturn numEdges;\n}",
            "// Your code here.\n  int edgeCount = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i; j < N; ++j) {\n      if (i!= j) {\n        if (A(i,j) + A(j,i)!= 0) {\n          ++edgeCount;\n        }\n      }\n    }\n  }\n  return edgeCount;\n}",
            "int edgeCount = 0;\n\n\t// TODO: parallelize\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tedgeCount += A(i,j);\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int numEdges = 0;\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(int i, int& local_numEdges) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A(i, j) == 1) {\n\t\t\t\tlocal_numEdges++;\n\t\t\t}\n\t\t}\n\t}, numEdges);\n\n\treturn numEdges;\n}",
            "int count = 0;\n\n    // TODO: Use Kokkos to fill in this function.\n\n    return count;\n}",
            "// TODO\n}",
            "// TODO: use Kokkos to compute the answer\n\t// you can access elements of A by using A(i,j)\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n\tKokkos::parallel_for(\n\t\t\tKokkos::RangePolicy<Kokkos::RoundRobin>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\t\tint count = 0;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcounts(i) = count;\n\t\t\t}\n\t);\n\tint total = 0;\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::RoundRobin>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int i, int& val) {\n\t\t\t\tval += counts(i);\n\t\t\t},\n\t\t\ttotal\n\t);\n\treturn total;\n}",
            "/* Define the number of threads per block and per kernel.\n\t   You may change these values; see the assignment for more\n\t   information about the effect of these parameters on performance.\n\t*/\n\tint threadsPerBlock = 256;\n\tint blockSize = 512;\n\n\t/* Define a variable to store the number of edges. */\n\tint numEdges = 0;\n\n\t/* TODO: Replace the return statement below with your code! */\n\treturn numEdges;\n}",
            "// Use the Kokkos view as an input argument\n  //\n  // The return value should be the number of edges in the graph\n  //\n  // You may use any Kokkos view type.\n  //\n  // Do NOT modify the input matrix.\n\n  // ==== Your code here ====\n\n  return 0;\n}",
            "Kokkos::View<int*> output(\"output\", 1);\n\tKokkos::parallel_for(\"EdgeCount\", 1, KOKKOS_LAMBDA(const int i) {\n\t\tint count = 0;\n\t\tfor (size_t row = 0; row < N; row++) {\n\t\t\tfor (size_t col = 0; col < N; col++) {\n\t\t\t\tif (A(row, col) == 1) {\n\t\t\t\t\tcount += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\toutput(0) = count;\n\t});\n\tKokkos::fence();\n\treturn output(0);\n}",
            "using namespace Kokkos;\n\n  int *result = new int[1];\n  result[0] = 0;\n\n  View<int**> A_tmp(A.data(), N, N);\n\n  View<int*> result_tmp(result, 1);\n\n  Kokkos::parallel_reduce(\"\",\n\t\t\t  1,\n\t\t\t  KOKKOS_LAMBDA(int, my_result) {\n\t\t\t    for (int i = 0; i < N; i++) {\n\t\t\t      for (int j = 0; j < N; j++) {\n\t\t\t\tif (A_tmp(i, j) > 0) {\n\t\t\t\t  my_result[0]++;\n\t\t\t\t}\n\t\t\t      }\n\t\t\t    }\n\t\t\t  },\n\t\t\t  result_tmp);\n\n  Kokkos::fence();\n\n  return result[0];\n}",
            "int* tmp = new int[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\ttmp[i] = 0;\n\t}\n\n\tKokkos::parallel_for(\n\t\t\"edgeCount\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t[A, tmp, N](const int& i) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\ttmp[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\tKokkos::fence();\n\tint result = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tresult += tmp[i];\n\t}\n\tdelete[] tmp;\n\treturn result / 2;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\n    // initialize to 0\n    Kokkos::View<int*> counts(\"counts\", N);\n    Kokkos::parallel_for(\"zeroing\", N, KOKKOS_LAMBDA(int i) {\n        counts(i) = 0;\n    });\n\n    // iterate over all elements\n    Kokkos::parallel_for(\"counting\", N*N, KOKKOS_LAMBDA(int i) {\n        const int row = i / N;\n        const int col = i % N;\n        if (A(row, col) == 1) {\n            // if edge found, increment the count\n            Kokkos::atomic_increment(&counts(row));\n        }\n    });\n\n    // compute sum of counts\n    Kokkos::View<int*> sums(\"sums\", 1);\n    Kokkos::parallel_reduce(\"summing\", N, KOKKOS_LAMBDA(int i, int &s) {\n        s += counts(i);\n    }, sums);\n\n    return sums(0);\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "omp",
        "prompt": "#include <omp.h>\n\n/* Count the number of edges in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int count = 0;\n\t\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int cnt = 0;\n#pragma omp parallel for reduction(+ : cnt)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i == j)\n\t\t\t\tcontinue;\n\t\t\tif (A[i * N + j])\n\t\t\t\t++cnt;\n\t\t}\n\t}\n\treturn cnt;\n}",
            "int edges = 0;\n  int i,j;\n  #pragma omp parallel for private(j) reduction(+:edges)\n  for (i = 0; i < N; ++i) {\n    for (j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1)\n        ++edges;\n    }\n  }\n  return edges;\n}",
            "int num_edges = 0;\n\t#pragma omp parallel for reduction(+:num_edges)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn num_edges;\n}",
            "int num_edges = 0;\n  #pragma omp parallel for schedule(dynamic, 100) reduction(+:num_edges)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        num_edges++;\n      }\n    }\n  }\n  return num_edges;\n}",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(A[i * N + j] == 1)\n\t\t\t\tresult += 1;\n\t\t}\n\t}\n\treturn result;\n}",
            "// TODO: replace this with your code\n  return 0;\n}",
            "int sum = 0;\n\t//#pragma omp parallel for reduction(+: sum)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\treturn sum / 2;\n}",
            "int numEdges{0};\n\n    //#pragma omp parallel\n    for (size_t i = 0; i < N; i++) {\n\n        for (size_t j = 0; j < N; j++) {\n\n            if (A.at(i*N + j)) {\n                numEdges++;\n            }\n        }\n    }\n\n    return numEdges;\n}",
            "int numEdges = 0;\n  // TODO: Insert your solution here\n\n  return numEdges;\n}",
            "int count = 0;\n\tint i;\n\tint j;\n\n\tfor (i = 0; i < N; i++) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count / 2;\n}",
            "#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// TODO: count the number of edges incident to node i\n\t}\n\n\t// TODO: return the total number of edges\n}",
            "int retval = 0;\n#pragma omp parallel for reduction(+: retval)\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < i; ++j)\n\t\t\tif (A[i * N + j])\n\t\t\t\t++retval;\n\treturn retval;\n}",
            "int count = 0;\n\n    #pragma omp parallel for schedule(dynamic)\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = i+1; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                #pragma omp atomic\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int numEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    #pragma omp parallel for reduction(+:numEdges)\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++numEdges;\n      }\n    }\n  }\n  return numEdges;\n}",
            "int edges{0};\n  #pragma omp parallel for reduction(+:edges)\n  for (size_t i=0; i<N; i++) {\n    for (size_t j=0; j<N; j++) {\n      if (A[i*N + j] == 1) {\n        edges++;\n      }\n    }\n  }\n  return edges;\n}",
            "int num_edges = 0;\n\n  #pragma omp parallel for reduction(+:num_edges) schedule(dynamic)\n  for (int i = 0; i < N; ++i) {\n    for (int j = i + 1; j < N; ++j) {\n      if (A[i*N+j] || A[j*N+i]) {\n        num_edges++;\n      }\n    }\n  }\n\n  return num_edges;\n}",
            "// TODO\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+ : count)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j]) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n    #pragma omp parallel for reduction(+ : count)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[i * N + j] == 1) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int sum = 0;\n\n#pragma omp parallel for reduction(+ : sum)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        sum++;\n      }\n    }\n  }\n\n  return sum;\n}",
            "int numEdges = 0;\n    size_t start = 0, end = 0;\n    if (omp_in_parallel()) {\n        start = omp_get_thread_num() * N;\n        end = (omp_get_thread_num() + 1) * N;\n    }\n    else {\n        int numThreads = omp_get_max_threads();\n        std::vector<int> sum(numThreads, 0);\n        #pragma omp parallel num_threads(numThreads)\n        {\n            start = omp_get_thread_num() * N;\n            end = (omp_get_thread_num() + 1) * N;\n            for (size_t i = start; i < end; i++) {\n                for (size_t j = i + 1; j < N; j++) {\n                    if (A[i * N + j]!= 0) {\n                        sum[omp_get_thread_num()]++;\n                    }\n                }\n            }\n        }\n        for (int i = 0; i < numThreads; i++) {\n            numEdges += sum[i];\n        }\n        return numEdges / 2;\n    }\n    for (size_t i = start; i < end; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j]!= 0) {\n                numEdges++;\n            }\n        }\n    }\n    return numEdges / 2;\n}",
            "int num_edges = 0;\n\t\n\t// TODO: Implement using OpenMP\n\t// num_edges =...\n\t\n\treturn num_edges;\n}",
            "int result = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[N*i + j]) {\n        ++result;\n      }\n    }\n  }\n  return result;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int total = 0;\n\t// #pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\ttotal++;\n\t\t\t}\n\t\t}\n\t}\n\treturn total;\n}",
            "int num_edges = 0;\n\n    #pragma omp parallel for reduction(+:num_edges)\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = 0; j < i; j++) {\n            if (A[i * N + j])\n                num_edges++;\n        }\n    }\n\n    return num_edges;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+ : count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j]!= 0)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int count{0};\n\n#pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[i*N+j] || A[j*N+i]) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j])\n                ++count;\n\n    return count;\n}",
            "int edgeCount = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        ++edgeCount;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "int count = 0;\n\tint i = 0;\n\tint j = 0;\n\tfor(i = 0; i < N; i++){\n\t\tfor(j = 0; j < N; j++){\n\t\t\tif(A[i*N+j] == 1){\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i; j < N; ++j) {\n      if (i == j) continue;\n      if (A[i * N + j]) ++count;\n    }\n  }\n  return count;\n}",
            "// Complete this function\n  int count = 0;\n  int start;\n\n  int end = N;\n\n  for (start = 0; start < N; ++start)\n  {\n    for (int i = start + 1; i < end; ++i)\n    {\n      if (A[i * N + start] == 1) {\n        count++;\n      }\n    }\n    end = start + 1;\n  }\n\n  return count;\n}",
            "int count = 0;\n    #pragma omp parallel for schedule(dynamic)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                #pragma omp atomic\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int sum = 0;\n  #pragma omp parallel for reduction(+:sum)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        sum++;\n      }\n    }\n  }\n  return sum;\n}",
            "int count = 0;\n#pragma omp parallel for\n    for(size_t i = 0; i < N; i++)\n    {\n        for(size_t j = 0; j < N; j++)\n        {\n            if(A[i*N + j] == 1)\n            {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int edgeCount = 0;\n  std::vector<bool> visited(N, false);\n\n  // Start parallel region.\n  // #pragma omp parallel for num_threads(4) default(none) shared(edgeCount, visited, A) firstprivate(N) schedule(static)\n  #pragma omp parallel for num_threads(4) default(none) shared(edgeCount, visited, A) firstprivate(N) schedule(dynamic)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i*N + j]) {\n        visited[j] = true;\n      }\n    }\n  }\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i]) {\n      edgeCount++;\n    }\n  }\n\n  return edgeCount;\n}",
            "size_t numEdges = 0;\n\n  // Iterate over the matrix to get the number of edges\n#pragma omp parallel for reduction(+:numEdges)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i; j < N; j++) {\n      if (A[i * N + j] == 1)\n        numEdges += 1;\n    }\n  }\n\n  return numEdges;\n}",
            "int sum = 0;\n#pragma omp parallel for reduction(+ : sum)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t}\n\n\treturn sum;\n}",
            "int count = 0;\n\n    // #pragma omp parallel for schedule(guided)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            if (A[N * i + j] == 1) {\n                ++count;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n#pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < i; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "#pragma omp parallel for\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i * N + j] == 1) {\n\t\t\t\tstd::cout << \"(\" << i << \", \" << j << \")\" << std::endl;\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}",
            "int sum = 0;\n  #pragma omp parallel for reduction(+:sum)\n  for (int i = 0; i < N; i++)\n    for (int j = 0; j < N; j++)\n      if (A[i * N + j])\n        sum++;\n  return sum;\n}",
            "int count = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n\n        for (size_t j = 0; j < N; j++) {\n\n            if (i!= j) {\n\n                if (A[i*N + j]) {\n                    count++;\n                }\n\n            }\n\n        }\n\n    }\n\n    return count;\n\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                count += 1;\n            }\n        }\n    }\n    return count;\n}",
            "int res = 0;\n#pragma omp parallel for num_threads(4)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < i; ++j) {\n      if (A[N * i + j] == 1)\n        ++res;\n    }\n  return res;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+ : count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i+1; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n  #pragma omp parallel for schedule(static, 1) reduction(+: count)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]) {\n        count += 1;\n      }\n    }\n  }\n\n  return count;\n}",
            "// Replace this with your code\n  return 0;\n}",
            "int count = 0;\n  size_t N2 = N * N;\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N2; ++i) {\n    if (A[i] == 1)\n      ++count;\n  }\n  return count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      count += A[i * N + j];\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n    //#pragma omp parallel for reduction(+:count)\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            if(i!= j && A[i * N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int edgeCount = 0;\n\n\t#pragma omp parallel for reduction(+: edgeCount)\n\tfor(int i = 0; i < N; ++i)\n\t\tfor(int j = 0; j < N; ++j)\n\t\t\tif(A[i*N + j])\n\t\t\t\t++edgeCount;\n\n\treturn edgeCount;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+ : count)\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (i < j && A[i*N + j]!= 0)\n\t\t\t\tcount++;\n\treturn count;\n}",
            "int count = 0;\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i*N+j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> edge_count(N, 0);\n\tint count = 0;\n\n\t// #pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tedge_count[i] += 1;\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (edge_count[i] > 1) {\n\t\t\t#pragma omp atomic\n\t\t\tcount -= 1;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int n=N;\n    int count=0;\n    \n    int Ai, Aj;\n    Ai=0;\n    Aj=0;\n\n    #pragma omp parallel for shared(A, n) private(Ai,Aj) reduction(+:count)\n    for(Ai=0; Ai<n; Ai++){\n    \tfor(Aj=0; Aj<n; Aj++){\n    \t\tif(A[Ai*n+Aj]==1)\n    \t\t\tcount++;\n    \t}\n    }\n    \n    return count;\n}",
            "// TODO: Your code goes here!\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tcount++;\n\treturn count;\n}",
            "// TODO: implement\n  return 0;\n}",
            "int res = 0;\n\t#pragma omp parallel for reduction(+:res)\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tres++;\n\treturn res;\n}",
            "int numEdges = 0;\n\t#pragma omp parallel for reduction(+:numEdges)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tnumEdges += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int count = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int numEdges = 0;\n\t#pragma omp parallel for schedule(dynamic) reduction(+:numEdges)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tnumEdges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int edge_count = 0;\n    #pragma omp parallel for reduction(+: edge_count)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                edge_count++;\n            }\n        }\n    }\n    return edge_count;\n}",
            "// TODO: Implement this\n    int edgeCount = 0;\n    #pragma omp parallel for reduction(+:edgeCount)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1 && A[j * N + i] == 1) {\n                edgeCount++;\n            }\n        }\n    }\n    return edgeCount;\n}",
            "int numEdges = 0;\n\t#pragma omp parallel for num_threads(N) reduction(+: numEdges)\n\tfor (int i=0; i<N; ++i) {\n\t\tfor (int j=i; j<N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tnumEdges += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int num_edges = 0;\n\n\t#pragma omp parallel for reduction(+: num_edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j])\n\t\t\t\tnum_edges++;\n\t\t}\n\t}\n\n\treturn num_edges;\n}",
            "int edge_count = 0;\n\t#pragma omp parallel for reduction(+ : edge_count)\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = i + 1; j < N; j++) {\n\t\t\tedge_count += A[i * N + j];\n\t\t}\n\t}\n\treturn edge_count;\n}",
            "int count = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i+1; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int edgeCount = 0;\n\n\t#pragma omp parallel for reduction(+:edgeCount) schedule(dynamic)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t++edgeCount;\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int nbEdges = 0;\n\t#pragma omp parallel for reduction(+ : nbEdges)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++nbEdges;\n\t\t\t}\n\t\t}\n\t}\n\treturn nbEdges;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      count += (i!= j) && A[i * N + j];\n    }\n  }\n  return count;\n}",
            "int num_threads = omp_get_num_threads();\n\tint num_edges = 0;\n\n\t#pragma omp parallel for reduction(+:num_edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn num_edges;\n}",
            "int numEdges = 0;\n  #pragma omp parallel for reduction(+: numEdges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < i; ++j) { // skip half\n      if (A[i * N + j]) {\n        ++numEdges;\n      }\n    }\n  }\n  return numEdges;\n}",
            "int num_edges = 0;\n\n  #pragma omp parallel for reduction(+:num_edges)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        num_edges += 1;\n      }\n    }\n  }\n\n  return num_edges;\n}",
            "int edgeCount = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edgeCount;\n}",
            "int sum = 0;\n\n#pragma omp parallel\n\t{\n\t\tint sum_private = 0;\n\n\t\t// add the number of edges for the submatrix of A that each thread computes\n#pragma omp for collapse(2)\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = i; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\tsum_private++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n#pragma omp critical\n\t\tsum += sum_private;\n\t}\n\treturn sum;\n}",
            "// TODO: your code here\n\tint count = 0;\n\t#pragma omp parallel for reduction(+:count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int nE = 0;\n  #pragma omp parallel for schedule(static)\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = i; j < N; j++) {\n      if (A[i*N + j]) {\n        #pragma omp atomic\n        nE++;\n      }\n    }\n  return nE;\n}",
            "int e = 0;\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = i+1; j < N; j++) {\n            e += A[i * N + j];\n        }\n    }\n    return e;\n}",
            "int sum = 0;\n\n\t#pragma omp parallel for reduction(+: sum)\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = i+1; j < N; j++)\n\t\t\tif (A[i * N + j])\n\t\t\t\tsum++;\n\n\treturn sum;\n}",
            "// TODO\n\treturn -1;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+: count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int n_threads = omp_get_max_threads();\n  std::cout << \"Number of threads used: \" << n_threads << std::endl;\n\n  size_t i, j;\n\n  int sum = 0;\n  //#pragma omp parallel for shared(A,sum)\n  for (i = 0; i < N; i++)\n  {\n    for (j = 0; j < N; j++)\n    {\n      if(i!= j && A[i * N + j] == 1)\n      {\n        sum++;\n      }\n    }\n  }\n  return sum;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+: count)\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (i!= j && A[i * N + j]) count++;\n\treturn count;\n}",
            "std::vector<int> counts(N, 0);\n#pragma omp parallel for schedule(static)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++counts[i];\n      }\n    }\n  }\n\n  int total = 0;\n  for (int c : counts) {\n    total += c;\n  }\n  return total;\n}",
            "int n_edges = 0;\n\t#pragma omp parallel for reduction(+: n_edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tn_edges += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn n_edges;\n}",
            "int n = N;\n  int *A1 = new int[n * n];\n  for (size_t i = 0; i < A.size(); i++) {\n    A1[i] = A[i];\n  }\n\n  int ret = 0;\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < n; i++) {\n    for (size_t j = 0; j < n; j++) {\n      if (i == j) continue;\n      if (A1[i * n + j]) ret++;\n    }\n  }\n\n  delete[] A1;\n  return ret;\n}",
            "int edgeCount = 0;\n\t\n\t#pragma omp parallel for reduction(+:edgeCount)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn edgeCount;\n}",
            "int count = 0;\n#pragma omp parallel for schedule(static) reduction(+: count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i+1; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int num_edges = 0;\n  #pragma omp parallel for reduction(+:num_edges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        ++num_edges;\n    }\n  }\n  return num_edges;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[N * i + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] > 0)\n        ++count;\n    }\n  }\n  return count;\n}",
            "int count = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        #pragma omp atomic update\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n#pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i < j && A[i + j * N] > 0) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int e = 0;\n\n\t// Fill code here\n\n\treturn e;\n}",
            "int edgeCount = 0;\n\tint numThreads;\n\n\t#pragma omp parallel num_threads(4) shared(A, N, edgeCount)\n\t{\n\t\tnumThreads = omp_get_num_threads();\n\t\tstd::cout << \"Thread #\" << omp_get_thread_num() << \" of \" << numThreads << \" created\" << std::endl;\n\t\tfor (size_t i = 0; i < N; ++i)\n\t\t{\n\t\t\tfor (size_t j = 0; j < i; ++j)\n\t\t\t{\n\t\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t{\n\t\t\t\t\t#pragma omp atomic\n\t\t\t\t\tedgeCount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int count = 0;\n\n    // TODO: Add parallel for loop\n    // for each row in the matrix\n    // for each column in the row\n    // if matrix[row][column] is true\n    // add 1 to the count\n\n    return count;\n}",
            "int numEdges = 0;\n\t\n\t#pragma omp parallel for reduction(+: numEdges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tnumEdges++;\n\t\t}\n\t}\n\t\n\treturn numEdges;\n}",
            "int result = 0;\n\t// TODO: Implement me!\n\treturn result;\n}",
            "int num_edges = 0;\n\n#pragma omp parallel for reduction(+: num_edges)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++num_edges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn num_edges;\n}",
            "int count = 0;\n\n    #pragma omp parallel for reduction(+:count)\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = i + 1; j < N; j++) {\n            if(A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int ans = 0;\n    // Your code goes here!\n    return ans;\n}",
            "int count = 0;\n  int const nThreads = omp_get_num_threads();\n  int const threadID = omp_get_thread_num();\n  int const chunkSize = N / nThreads;\n  int const start = threadID * chunkSize;\n  int const end = (threadID + 1 == nThreads)? N : start + chunkSize;\n\n  #pragma omp parallel for\n  for (int i = start; i < end; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int numEdges = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tnumEdges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int nEdges = 0;\n\t#pragma omp parallel for num_threads(N) reduction(+:nEdges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tnEdges++;\n\t\t}\n\t}\n\treturn nEdges;\n}",
            "int result = 0;\n\n#pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j] == 1) {\n        ++result;\n      }\n    }\n  }\n\n  return result;\n}",
            "int count = 0;\n#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j]) count++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int nEdge = 0;\n\t#pragma omp parallel for\n\tfor (size_t row = 0; row < N; row++) {\n\t\tfor (size_t col = 0; col < N; col++) {\n\t\t\tif (A[row*N + col] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tnEdge++;\n\t\t\t}\n\t\t}\n\t}\n\treturn nEdge;\n}",
            "// TODO: Implement me\n  return 0;\n}",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i < j && A[i * N + j]) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < i; j++) {\n      if (A[i*N + j] == 1) {\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n  #pragma omp parallel for schedule(dynamic) reduction(+ : count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int edges = 0;\n\t#pragma omp parallel for reduction(+:edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edges;\n}",
            "int sum = 0;\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < N; j++)\n      if (i!= j)\n        if (A[i * N + j])\n          sum += 1;\n\n  return sum;\n}",
            "std::vector<int> counter(N, 0);\n    // std::vector<int> counter(N, 0);\n    // #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                counter[i] += 1;\n            }\n        }\n    }\n    int count = 0;\n    for (auto& c : counter) {\n        count += c;\n    }\n    return count;\n}",
            "int sum = 0;\n#pragma omp parallel for reduction(+:sum)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i*N + j]!= 0) {\n\t\t\t\t++sum;\n\t\t\t}\n\t\t}\n\t}\n\treturn sum;\n}",
            "if (N <= 0) {\n\t\treturn 0;\n\t}\n\n\tint num_threads = 0;\n\tint total_edges = 0;\n\t#pragma omp parallel shared(total_edges) num_threads(4)\n\t{\n\t\tint thread_id = omp_get_thread_num();\n\t\tint num_threads = omp_get_num_threads();\n\t\tif (thread_id == 0) {\n\t\t\tprintf(\"Number of threads: %d\\n\", num_threads);\n\t\t}\n\n\t\tint chunk_size = (N + num_threads - 1) / num_threads;\n\t\tint start_index = chunk_size * thread_id;\n\t\tint end_index = std::min(start_index + chunk_size, N);\n\t\tfor (size_t i = start_index; i < end_index; i++) {\n\t\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t#pragma omp atomic\n\t\t\t\t\ttotal_edges++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn total_edges;\n}",
            "int c = 0;\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i*N + j]!= 0) ++c;\n\t\t}\n\t}\n\treturn c;\n}",
            "// TODO\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "#pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        #pragma omp atomic\n        ++count;\n    }\n\n    return count;\n}",
            "int numEdges = 0;\n#pragma omp parallel for reduction(+:numEdges)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "/* YOUR CODE GOES HERE */\n}",
            "std::vector<int> rowSums(N, 0);\n\n#ifdef OMP\n\t#pragma omp parallel for schedule(dynamic)\n#endif\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\trowSums[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tresult += rowSums[i];\n\t}\n\n\treturn result / 2;\n}",
            "int result = 0;\n\n\tfor(int i = 0; i < N; i++) {\n\t\t#pragma omp parallel for reduction(+:result)\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[N*i + j] == 1) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n\n#pragma omp parallel for shared(A, count)\n\tfor (int i = 0; i < N; ++i) {\n\n\t\tfor (int j = 0; j < N; ++j) {\n\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int ans = 0;\n  #pragma omp parallel for reduction(+: ans)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      ans += A[i * N + j];\n  return ans;\n}",
            "// Check the size of A matches NxN\n  if (A.size()!= N*N) {\n    throw std::runtime_error(\"input must be a NxN matrix\");\n  }\n\n  int count = 0;\n\n  #pragma omp parallel for reduction(+: count)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i == j) continue;\n      if (A[i*N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int sum = 0;\n  // TODO\n  return sum;\n}",
            "int count = 0;\n#pragma omp parallel for reduction(+ : count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO: use OpenMP to count the edges in A in parallel\n\n  int edges = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i > j) {\n        if (A[i * N + j])\n          edges++;\n      } else if (A[i * N + j]!= A[j * N + i]) {\n        edges++;\n      }\n    }\n  }\n\n  return edges;\n}",
            "int nEdges = 0;\n    #pragma omp parallel for num_threads(4)\n    for (int i = 0; i < N; ++i) {\n        for (int j = i+1; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                #pragma omp atomic\n                nEdges++;\n            }\n        }\n    }\n    return nEdges;\n}",
            "int sum = 0;\n    #pragma omp parallel for reduction(+:sum)\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = i + 1; j < N; j++) {\n            if(A[i * N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n    return sum;\n}",
            "int count = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i)\n  {\n    for (size_t j = 0; j < N; ++j)\n    {\n      if (A[N*i+j])\n      {\n        #pragma omp atomic\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n    #pragma omp parallel for reduction(+:count)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                count += 1;\n            }\n        }\n    }\n\n    return count;\n}",
            "int numEdges = 0;\n\n\t// Use OpenMP here\n\n\treturn numEdges;\n}",
            "int edgeCount = 0;\n  #pragma omp parallel for schedule(dynamic) reduction(+:edgeCount)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        edgeCount++;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "size_t count = 0;\n#pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i; j < N; ++j) {\n      count += A[i * N + j];\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\t#pragma omp parallel for num_threads(4) reduction(+:count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[N*i + j] == 1) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int n = 0;\n    #pragma omp parallel for reduction(+ : n)\n    for (size_t i = 0; i < N; ++i)\n    {\n        for (size_t j = 0; j < N; ++j)\n        {\n            if (A[i * N + j]) {\n                n++;\n            }\n        }\n    }\n    return n;\n}",
            "// TODO\n}",
            "// TO DO: your code goes here\n  //  You should parallelize the loop using OpenMP.\n  //  You should use the reduction clause to sum the number of edges.\n  //  https://software.intel.com/en-us/articles/openmp-loop-reduction\n\n\n}",
            "// TODO\n\n  return 0;\n}",
            "int res=0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i+1; j < N; j++) {\n      if (A[i*N+j]!= 0) {\n        res += 1;\n      }\n    }\n  }\n  return res;\n}",
            "int num_threads = omp_get_max_threads();\n  std::vector<int> thread_edge_count(num_threads, 0);\n  std::vector<int> thread_num_processed(num_threads, 0);\n  std::vector<int> thread_start(num_threads);\n\n  for (int i = 0; i < num_threads; i++) {\n    thread_start[i] = i * (N/num_threads);\n  }\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n\n    int t_id = omp_get_thread_num();\n    int a_offset = thread_start[t_id];\n\n    for (int j = a_offset; j < N; j++) {\n      if (i!= j && A[i * N + j] == 1) {\n        thread_edge_count[t_id] += 1;\n      }\n    }\n\n    thread_num_processed[t_id] = i;\n  }\n\n  int total_edge_count = 0;\n  for (int i = 0; i < num_threads; i++) {\n    total_edge_count += thread_edge_count[i];\n    printf(\"thread %d edge count: %d, num processed: %d\\n\", i, thread_edge_count[i], thread_num_processed[i]);\n  }\n\n  return total_edge_count;\n}",
            "int result = 0;\n    std::vector<int> row_sum(N, 0);\n    std::vector<int> col_sum(N, 0);\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            row_sum[i] += A[i * N + j];\n            col_sum[j] += A[i * N + j];\n        }\n    }\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                if (row_sum[i] > 1 && col_sum[j] > 1) {\n                    result += 1;\n                }\n            }\n        }\n    }\n\n    return result;\n}",
            "int nbEdges = 0;\n#pragma omp parallel for reduction(+ : nbEdges)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j] == 1) {\n        ++nbEdges;\n      }\n    }\n  }\n\n  return nbEdges;\n}",
            "int sum{0};\n#pragma omp parallel for reduction(+ : sum)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = i + 1; j < N; ++j)\n      if (A[i*N + j] == 1)\n        sum += 1;\n\n  return sum;\n}",
            "int counter = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i+1; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                counter++;\n            }\n        }\n    }\n    return counter;\n}",
            "int n = 0;\n\tint i = 0;\n\tint j = 0;\n\n\t#pragma omp parallel for shared(A, N) reduction(+:n) private(i, j)\n\tfor (i = 0; i < N; ++i) {\n\t\tfor (j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\tn++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn n;\n}",
            "int sum = 0;\n\n    #pragma omp parallel for reduction(+:sum)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n\n    return sum;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+: count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "size_t sum = 0;\n\t#pragma omp parallel for reduction(+:sum)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < i; ++j) {\n\t\t\tif (A[i * N + j] > 0)\n\t\t\t\tsum++;\n\t\t}\n\t}\n\treturn sum;\n}",
            "int count = 0;\n  for(int i = 0; i < N; i++){\n    for(int j = 0; j < N; j++){\n      if(A[N*i + j] == 1){\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int edges = 0;\n    #pragma omp parallel for reduction(+: edges)\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++edges;\n            }\n        }\n    }\n    return edges;\n}",
            "int num_edges = 0;\n  #pragma omp parallel for reduction(+ : num_edges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++num_edges;\n      }\n    }\n  }\n  return num_edges;\n}",
            "// TODO: Your code here\n    int count = 0;\n    for(int i = 0; i < N; ++i)\n    {\n        for(int j = 0; j < N; ++j)\n        {\n            if(A[N*i + j]!= 0)\n                ++count;\n        }\n    }\n    return count;\n}",
            "int sum = 0;\n\n\t#pragma omp parallel for reduction(+:sum)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < i; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tsum += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn sum;\n}",
            "// TODO: fill in the missing code\n\tint count = 0;\n\tint i = 0;\n\tint j = 0;\n\tint n = 0;\n\tint N1 = N - 1;\n\tint p = 0;\n\tint q = 0;\n\tint r = 0;\n\tint s = 0;\n\tint sum = 0;\n\tint threadNum = 0;\n\n\t// Loop through the matrix diagonally\n\t#pragma omp parallel for private(i, j, n, p, q, r, s, sum) reduction(+:count)\n\tfor (n = 0; n < N; n++) {\n\t\tp = n;\n\t\tq = n;\n\t\tr = n;\n\t\ts = n;\n\n\t\t// Check diagonally up\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (A[p] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tp += N1;\n\t\t}\n\n\t\t// Check diagonally down\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[q] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tq -= N1;\n\t\t}\n\n\t\t// Check diagonally left\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (A[r] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tr += 1;\n\t\t}\n\n\t\t// Check diagonally right\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[s] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\ts -= 1;\n\t\t}\n\t}\n\n\t// Return the number of edges\n\treturn count;\n}",
            "int edges = 0;\n#pragma omp parallel for reduction(+: edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edges;\n}",
            "// TODO: Fill this in!\n  int sum = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      sum += A[i*N + j];\n    }\n  }\n  return sum;\n\n}",
            "// TODO: Your code here\n  int numEdges = 0;\n  int const chunkSize = N/4;\n#pragma omp parallel for shared(A, N) private(numEdges)\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i == j) continue;\n      if (A[i*N + j] == 1) {\n#pragma omp atomic\n        numEdges++;\n      }\n    }\n  }\n  return numEdges;\n}",
            "// count edges\n  int count = 0;\n  // do it in parallel\n#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for num_threads(4) reduction(+: count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "if (A.size()!= N*N) throw \"Incorrect matrix size\";\n  int count = 0;\n  int i;\n  int j;\n  int x;\n  int a_ij;\n\n  int i_begin, i_end;\n  int j_begin, j_end;\n\n  #pragma omp parallel\n  {\n    int thid = omp_get_thread_num();\n    int num_threads = omp_get_num_threads();\n    int rows_per_thread = N / num_threads;\n    int rem = N % num_threads;\n\n    if (thid < rem)\n    {\n      i_begin = (thid + 1) * (rows_per_thread + 1);\n      i_end = (thid + 2) * (rows_per_thread + 1);\n    }\n    else\n    {\n      i_begin = thid * rows_per_thread + rem;\n      i_end = (thid + 1) * rows_per_thread + rem;\n    }\n\n    j_begin = 0;\n    j_end = N;\n\n    for (i = i_begin; i < i_end; i++)\n    {\n      for (j = j_begin; j < j_end; j++)\n      {\n        x = i * N + j;\n        a_ij = A[x];\n        if (a_ij == 1) count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n#pragma omp parallel for reduction(+: count)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i+1; j < N; ++j) {\n            count += A[i*N+j];\n        }\n    }\n    return count / 2;\n}",
            "if (N < 1)\n\t\treturn 0;\n\tint count = 0;\n\n\t#pragma omp parallel for reduction(+: count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int numOfEdges = 0;\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for reduction(+:numOfEdges)\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tfor (int j=i+1; j<N; j++) {\n\t\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t\tnumOfEdges++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numOfEdges;\n}",
            "int edgeCount = 0;\n    #pragma omp parallel for reduction(+ : edgeCount)\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i * N + j]) edgeCount += 1;\n    return edgeCount;\n}",
            "int count = 0;\n    #pragma omp parallel for\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < i; j++) {\n            if(A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+ : count)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j] == 1)\n        count += 1;\n  return count;\n}",
            "size_t sum = 0;\n\t#pragma omp parallel for reduction(+:sum)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j])\n\t\t\t\tsum += 1;\n\t\t}\n\t}\n\treturn sum;\n}",
            "int result = 0;\n\n\t#pragma omp parallel for reduction(+: result)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "std::vector<int> E(N);\n\n  #pragma omp parallel for\n  for (size_t i=0; i<N; i++) {\n    E[i] = std::accumulate(A.begin()+i*N, A.begin()+i*N+N, 0);\n  }\n\n  return std::accumulate(E.begin(), E.end(), 0);\n}",
            "int count = 0;\n\tint i, j;\n#pragma omp parallel for default(none) shared(A, count, N) private(i, j)\n\tfor (i = 0; i < N; ++i) {\n\t\tfor (j = i + 1; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int sum = 0;\n  size_t n = N;\n  size_t NTHREADS = 4;\n  size_t i = 0;\n  int lsum[NTHREADS] = {};\n\n#pragma omp parallel for num_threads(NTHREADS) shared(n, A) reduction(+ : sum)\n  for (i = 0; i < n * n; i++) {\n    int row = i / n;\n    int col = i % n;\n    if (row!= col && A[i] == 1) {\n      lsum[omp_get_thread_num()]++;\n    }\n  }\n\n#pragma omp parallel for num_threads(NTHREADS)\n  for (int i = 0; i < NTHREADS; i++) {\n    sum += lsum[i];\n  }\n  return sum;\n}",
            "int numEdges = 0;\n    int const numThreads = omp_get_max_threads();\n    std::vector<int> counts(numThreads, 0);\n\n    #pragma omp parallel num_threads(numThreads)\n    {\n        int const threadId = omp_get_thread_num();\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (A[i * N + j] == 1) {\n                    #pragma omp atomic\n                    counts[threadId]++;\n                }\n            }\n        }\n    }\n\n    for (int count : counts) {\n        numEdges += count;\n    }\n\n    return numEdges / 2;\n}",
            "int count = 0;\n#pragma omp parallel for num_threads(4)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      count += A[i*N + j];\n    }\n  }\n  return count;\n}",
            "int num_threads = omp_get_max_threads();\n\tint num_edges = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i*N+j] > 0) {\n\t\t\t\t++num_edges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn num_edges;\n}",
            "int numEdges = 0;\n\tint count = 0;\n\t#pragma omp parallel for shared(A, count) private(numEdges)\n\tfor (int i = 0; i < N; ++i) {\n\t\tnumEdges = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tnumEdges += A[i * N + j];\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tcount += numEdges;\n\t\t}\n\t}\n\treturn count;\n}",
            "int result;\n\t#pragma omp parallel for reduction(+:result)\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = i+1; j < N; j++) {\n\t\t\tif(A[i*N+j] == 1) result++;\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+ : count)\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t++count;\n\treturn count;\n}",
            "// TODO: Your code here\n\n\tint ret = 0;\n\n\t// Parallel\n\t#pragma omp parallel for reduction(+:ret)\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tret++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ret;\n}",
            "size_t cnt = 0;\n\t#pragma omp parallel for reduction(+:cnt)\n\tfor (int i = 0; i < N; ++i)\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tcnt += A[i*N + j];\n\treturn cnt;\n}",
            "auto NThreads = omp_get_max_threads();\n  auto NRows = (N + NThreads - 1) / NThreads;\n\n  auto n = 0;\n  for (auto i = 0; i < N; i++) {\n    #pragma omp parallel for reduction(+:n) schedule(static, NRows)\n    for (auto j = i+1; j < N; j++) {\n      n += A[i * N + j] * A[j * N + i];\n    }\n  }\n  return n / 2;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A[N*i + j] == 1){\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\n    #pragma omp parallel for reduction(+ : count)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int res = 0;\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < i; ++j) {\n\t\t\tif (A[N*i + j] > 0)\n\t\t\t\t++res;\n\t\t}\n\t}\n\treturn res;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i+1; j < N; j++) {\n      count += A[i*N+j];\n    }\n  }\n  return count;\n}",
            "int result = 0;\n\n  #pragma omp parallel for reduction(+ : result)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      result += A[i*N+j];\n    }\n  }\n  return result;\n}",
            "int sum = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint local_sum = 0;\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\t++local_sum;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\tsum += local_sum;\n\t}\n\n\treturn sum;\n}",
            "int numEdges = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i*N + j] == 1) {\n        #pragma omp atomic\n        numEdges++;\n      }\n    }\n  }\n  return numEdges;\n}",
            "int sum = 0;\n\n#pragma omp parallel for reduction(+:sum)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n\n    return sum;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "serial",
        "prompt": "/* Count the number of edges in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int e{0};\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i; j < N; ++j) {\n\t\t\te += A[i*N + j];\n\t\t}\n\t}\n\treturn e;\n}",
            "auto const N2 = N * N;\n  auto const A_data = A.data();\n\n  int e = 0;\n  for (size_t i = 0; i < N2 - N; i++) {\n    if (A_data[i] == 1) {\n      e++;\n    }\n  }\n\n  return e;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = i + 1; j < N; ++j)\n\t\t{\n\t\t\tif (A[i * N + j])\n\t\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "auto count = 0;\n  for (size_t row = 0; row < N; ++row)\n    for (size_t col = 0; col < N; ++col)\n      if (A[row * N + col])\n        ++count;\n  return count;\n}",
            "int total = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\ttotal += (A[i * N + j] == 1);\n\t\t}\n\t}\n\treturn total;\n}",
            "int result = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tresult++;\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int edgeCount = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int total = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]!= 0) {\n                total++;\n            }\n        }\n    }\n    return total;\n}",
            "int cnt{0};\n  for(auto& row : A)\n    cnt += std::bitset<32>(row).count();\n\n  return cnt;\n}",
            "int count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[N * i + j])\n                count++;\n        }\n    }\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int sum = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tsum += A[N*i+j];\n\treturn sum;\n}",
            "int nEdges = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (i!= j) {\n            if (A[N * i + j] == 1) {\n               ++nEdges;\n            }\n         }\n      }\n   }\n   return nEdges;\n}",
            "int edgeCount = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int cnt = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\t++cnt;\n\t\t\t}\n\t\t}\n\t}\n\treturn cnt;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (A[i*N + j]) {\n            ++count;\n         }\n      }\n   }\n   return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "if (A.size()!= N * N) {\n    throw std::runtime_error(\"Invalid input size.\");\n  }\n\n  int nEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++nEdges;\n      }\n    }\n  }\n\n  return nEdges;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            count += A[i * N + j]? 1 : 0;\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] > 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[N*i + j]!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tcount += A[i*N + j];\n\t\t}\n\t}\n\n\treturn count / 2;\n}",
            "// Write your solution here\n\tint count = 0;\n\n\tfor(size_t i = 0; i < N; i++){\n\t\tfor(size_t j = 0; j < N; j++){\n\t\t\tif(A[i * N + j] == 1){\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "size_t count{0};\n\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            if(A[i * N + j] == 1) {\n                count++;\n            }\n        }\n    }\n\n    return static_cast<int>(count);\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i!= j && A[i * N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "if (A.size()!= N*N) {\n\t\tthrow std::length_error(\"The size of the vector A must be equal to N*N.\");\n\t}\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tcount += A[i*N + j];\n\t\t}\n\t}\n\n\t// For undirected graph, we have to divide the count by 2 because for each edge we have a corresponding reverse edge.\n\tcount /= 2;\n\n\treturn count;\n}",
            "int numEdges = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j])\n        ++numEdges;\n  return numEdges;\n}",
            "int result{};\n  for (size_t i{0}; i < N; ++i) {\n    for (size_t j{i + 1}; j < N; ++j) {\n      result += A[i + j * N]? 1 : 0;\n    }\n  }\n  return result;\n}",
            "int count{0};\n\n\tfor (size_t i{0}; i < N; ++i) {\n\t\tfor (size_t j{0}; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = i + 1; j < N; ++j)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "// TODO: Implement\n\n    return 0;\n}",
            "int count = 0;\n\t\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tcount++;\n\t\t\t\n\treturn count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = i; j < N; j++) {\n            if(A[i * N + j]!= 0) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[N*i + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++)\n        for (size_t j = 0; j < N; j++)\n            if (A[i * N + j] == 1)\n                count++;\n    return count;\n}",
            "int totalEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1 || A[j * N + i] == 1)\n        ++totalEdges;\n    }\n  }\n  return totalEdges;\n}",
            "int count = 0;\n\n    for (size_t i = 0; i < N; ++i)\n        for (size_t j = 0; j < N; ++j)\n            if (A[i*N + j])\n                ++count;\n\n    return count;\n}",
            "int count{};\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (A[i*N + j])\n\t\t\t\tcount++;\n\treturn count;\n}",
            "int count{};\n\tfor (auto& row : A) {\n\t\tfor (auto& cell : row) {\n\t\t\tif (cell == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tcount += (A[i * N + j]!= 0);\n\n\treturn count;\n}",
            "int edge_count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j]) {\n        ++edge_count;\n      }\n    }\n  }\n  return edge_count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int e = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = i; j < N; j++)\n\t\t\te += A[i * N + j];\n\treturn e;\n}",
            "// Count edges and store them in a vector, then return vector.size()\n  int n = 0;\n  std::vector<int> edges;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        n += 1;\n        edges.push_back(i * N + j);\n      }\n    }\n  }\n  return n;\n}",
            "int result = 0;\n  for (size_t i = 0; i < N - 1; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j]) {\n        result += 1;\n      }\n    }\n  }\n  return result;\n}",
            "auto count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tcount += A[i*N + j];\n\t\t}\n\t}\n\n\treturn count;\n}",
            "size_t count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1)\n                count++;\n        }\n    }\n    return count / 2;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; i++) {\n      for (size_t j = i; j < N; j++) {\n         if (A[i * N + j] == 1) {\n            count++;\n         }\n      }\n   }\n   return count / 2;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "if (N < 1)\n    throw std::invalid_argument(\"N must be positive\");\n  if (A.size()!= N * N)\n    throw std::invalid_argument(\"Invalid matrix size\");\n\n  int count = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j])\n        ++count;\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            count += (A[i * N + j]!= 0);\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count{};\n  for (auto const& i : A)\n    count += i;\n\n  return count - N;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      count += A[i * N + j];\n    }\n  }\n\n  return count / 2;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "assert(N * N == A.size());\n  auto it = std::find(A.cbegin(), A.cend(), 1);\n  size_t numEdges = 0;\n  while (it!= A.cend()) {\n    auto prev = it;\n    it = std::find(it + 1, A.cend(), 1);\n    numEdges += std::distance(prev, it);\n  }\n  return numEdges;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[N * i + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "auto ret = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++ret;\n\t\t\t}\n\t\t}\n\t}\n\treturn ret;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n   for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n         if (i == j) {\n            continue;\n         }\n\n         if (A[i * N + j]) {\n            count++;\n         }\n      }\n   }\n\n   return count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      count += A[i * N + j];\n    }\n  }\n  return count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j]) count++;\n    }\n  }\n  return count / 2;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (i!= j && A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "// write your solution here\n   int count = 0;\n   for (size_t i = 0; i < N; ++i)\n      for (size_t j = i + 1; j < N; ++j)\n         if (A[i * N + j] || A[j * N + i])\n            ++count;\n   return count;\n}",
            "assert(A.size() == N * N);\n\tint total = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++total;\n\t\t\t}\n\t\t}\n\t}\n\treturn total;\n}",
            "size_t count = 0;\n\tfor (size_t r = 0; r < N; r++) {\n\t\tfor (size_t c = r + 1; c < N; c++) {\n\t\t\tcount += (A[r * N + c] == 1);\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n  // Check if N is not zero\n  if (N!= 0) {\n\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i * N + j]!= 0) {\n          count++;\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count{0};\n\tfor(size_t i{0}; i < N; ++i) {\n\t\tfor(size_t j{0}; j < N; ++j) {\n\t\t\tif(i!= j && A[i*N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int total = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            total += A[i * N + j];\n        }\n    }\n    return total;\n}",
            "int numEdges = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(A[i * N + j]) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "int count = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[N * i + j] == 1)\n        ++count;\n    }\n  }\n  return count;\n}",
            "int count{};\n\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n\tfor (size_t row = 0; row < N; ++row) {\n\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\tif (A[row * N + col]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int sum = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = i + 1; j < N; j++) {\n\t\t\tif(A[i * N + j])\n\t\t\t\tsum++;\n\t\t}\n\t}\n\treturn sum;\n}",
            "int nEdges = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i+1; j < N; ++j) {\n\t\t\tif (A[N*i + j] == 1) {\n\t\t\t\t++nEdges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nEdges;\n}",
            "int result = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tresult += A[i * N + j] + A[j * N + i];\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        for(size_t j = i+1; j < N; ++j) {\n            if(A[i*N+j]!= 0)\n                ++count;\n        }\n    }\n    return count;\n}",
            "int result = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tresult += A[i*N + j];\n\t\t}\n\t}\n\treturn result;\n}",
            "int edges = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tedges += A[i*N + j] == 1? 1 : 0;\n\t\t}\n\t}\n\treturn edges;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0 && i < j) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tfor (size_t j = i + 1; j < N; ++j)\n\t\t{\n\t\t\tif (A[i*N+j]!= 0 || A[j*N+i]!= 0)\n\t\t\t{\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int edges{ 0 };\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j]) {\n        edges++;\n      }\n    }\n  }\n  return edges;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (A[i * N + j] == 1) {\n            ++count;\n         }\n      }\n   }\n   return count;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      count += A[i * N + j];\n    }\n  }\n  return count / 2;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for(int i = 0; i < N; ++i) {\n        for(int j = 0; j < N; ++j) {\n            if(A[i * N + j] == 1) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n  for (int row = 0; row < N; row++) {\n    for (int col = 0; col < N; col++) {\n      if (row!= col && A[row * N + col] == 1)\n        count++;\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i < j && A[i + j * N] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int count{0};\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      count += (A[i * N + j] && i!= j);\n    }\n  }\n  return count;\n}",
            "assert(N * N == A.size());\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t}\n\treturn count;\n}",
            "int counter = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++counter;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn counter;\n}",
            "int num = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i+1; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tnum++;\n\t\t}\n\t}\n\treturn num;\n}",
            "if (N < 1) return 0;\n  if (N == 1) return A[0];\n  if (N == 2) return A[0] + A[1];\n  if (N == 3) return A[0] + A[1] + A[2];\n  if (N == 4) return A[0] + A[1] + A[2] + A[3];\n\n  int result = 0;\n\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = i + 1; j < N; j++)\n      if (A[i * N + j] == 1) result += 1;\n\n  return result;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (i!= j && A[i * N + j]!= 0)\n\t\t\t\tcount++;\n\n\treturn count;\n}",
            "// Write your code here\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int edges = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i < j && A[i * N + j] == 1) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edges;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i * N + j])\n\t\t\t\t++count;\n\n\treturn count;\n}",
            "int count{0};\n    for (size_t i{0}; i < N; ++i)\n        for (size_t j{i + 1}; j < N; ++j)\n            if (A[i * N + j] == 1)\n                ++count;\n    return count;\n}",
            "int sum = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn sum;\n}",
            "int edgeCount = 0;\n  for (size_t row = 0; row < N; ++row) {\n    for (size_t col = 0; col < N; ++col) {\n      if (A[row * N + col] == 1) {\n        ++edgeCount;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "int num_of_edges = 0;\n\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = i; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tnum_of_edges++;\n\t\t}\n\t}\n\treturn num_of_edges;\n}",
            "// Your code here!\n    int count{0};\n    for(int i = 0; i < A.size(); ++i) {\n        for(int j = 0; j < A[i]; ++j) {\n            count++;\n        }\n    }\n    return count;\n}",
            "// Write your code here.\n   return std::count(std::begin(A), std::end(A), 1);\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\t\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (i!= j && A[i * N + j])\n            ++count;\n      }\n   }\n   return count;\n}",
            "auto it = std::find(A.cbegin(), A.cend(), 1);\n   if (it == A.cend()) {\n      return 0;\n   }\n   auto const begin = std::distance(A.cbegin(), it);\n   auto const row = begin / N;\n   auto const col = begin % N;\n   std::vector<bool> visited(N, false);\n   std::vector<int> stack;\n   stack.push_back(row);\n   visited[row] = true;\n   int count = 1;\n   while (!stack.empty()) {\n      auto const idx = stack.back();\n      stack.pop_back();\n      for (auto i = 0u; i < N; i++) {\n         auto const idx2 = idx * N + i;\n         if (A[idx2] == 1 &&!visited[i]) {\n            visited[i] = true;\n            count += 1;\n            stack.push_back(i);\n         }\n      }\n   }\n   return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int edges{0};\n  for (auto const& row : A) {\n    auto i = 0;\n    while (i < N) {\n      if (row & (1 << i++))\n        ++edges;\n    }\n  }\n  return edges;\n}",
            "size_t count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N+j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int edge_count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tedge_count += (A[i * N + j]!= 0);\n\t\t}\n\t}\n\treturn edge_count;\n}",
            "int count{};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count{};\n\tfor(size_t row=0; row<N-1; ++row) {\n\t\tfor(size_t col=row+1; col<N; ++col) {\n\t\t\tcount += A[col*N + row];\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> degrees;\n  degrees.reserve(N);\n  for(size_t i = 0; i < N; ++i) {\n    int degree = 0;\n    for(size_t j = 0; j < N; ++j)\n      if(A[i*N+j] == 1)\n        degree++;\n    degrees.push_back(degree);\n  }\n\n  return std::accumulate(degrees.begin(), degrees.end(), 0,\n                         [&A,N](int x, int degree) {\n                           return x + degree*(degree-1)/2;\n                         });\n}",
            "int count = 0;\n\tfor (int row = 0; row < N; ++row) {\n\t\tfor (int col = 0; col < N; ++col) {\n\t\t\tif (A[row * N + col] == 1) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// The number of edges in the graph.\n\tint numEdges = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numEdges;\n}",
            "int numEdges = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                numEdges++;\n            }\n        }\n    }\n\n    return numEdges;\n}",
            "int count = 0;\n\n\tfor (size_t row = 0; row < N; row++) {\n\t\tfor (size_t col = row + 1; col < N; col++) {\n\t\t\tif (A[row * N + col] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int edges = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++edges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edges;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[N * i + j] == 1) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (size_t row = 0; row < N; ++row) {\n\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\tif (row!= col && A[row * N + col]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int edgeCount = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++edgeCount;\n            }\n        }\n    }\n\n    return edgeCount;\n}",
            "if(N < 1) return 0;\n\tint e = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < i; ++j) {\n\t\t\tif(A[i * N + j]) ++e;\n\t\t}\n\t}\n\treturn e;\n}",
            "// This function counts the number of edges in the adjacency matrix.\n    int count{};\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j] == 1) ++count;\n        }\n    }\n    return count;\n}",
            "int total{0};\n\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (A[i * N + j]) {\n            total += 1;\n         }\n      }\n   }\n\n   return total;\n}",
            "int edges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        edges++;\n    }\n  }\n  return edges;\n}",
            "int total = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i; j < N; j++) {\n            if (A[i*N + j] == 1)\n                total++;\n        }\n    }\n    return total;\n}",
            "int edges = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (i!= j && A[i * N + j]) {\n            edges++;\n         }\n      }\n   }\n   return edges;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int cnt = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++cnt;\n\t\t\t}\n\t\t}\n\t}\n\treturn cnt;\n}",
            "int count = 0;\n\t\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i == j)\n\t\t\t\tcontinue;\n\t\t\t\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int edgeCount{0};\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++edgeCount;\n      }\n    }\n  }\n\n  return edgeCount;\n}",
            "int edges = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1)\n                ++edges;\n        }\n    }\n\n    return edges;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < i; ++j) {\n            if (A[i * N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int numEdges{};\n\n\tfor (size_t i{}; i < N; ++i) {\n\t\tfor (size_t j{}; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1 && i < j) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numEdges;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int sum = 0;\n  for(int i=0; i<N; ++i){\n    for(int j=0; j<N; ++j){\n      if(A[i*N+j] == 1) {\n        ++sum;\n      }\n    }\n  }\n  return sum;\n}",
            "int count = 0;\n\tfor (size_t row = 0; row < N; ++row) {\n\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\tif (row < col && A[row * N + col]) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (A[i*N + j] == 1) {\n            ++count;\n         }\n      }\n   }\n   return count;\n}",
            "int count = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = i + 1; j < N; ++j) {\n\t\t\tif(A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int edgeCount = 0;\n\n\tfor(size_t i=0; i < N; i++) {\n\t\tfor(size_t j=0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edgeCount;\n}",
            "int count = 0;\n   for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n         if (A[i * N + j] == 1) {\n            count += 1;\n         }\n      }\n   }\n   return count;\n}",
            "if (A.empty())\n        return 0;\n\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i)\n    {\n        for (size_t j = 0; j < N; ++j)\n        {\n            if (A[i * N + j])\n                ++count;\n        }\n    }\n\n    return count;\n}",
            "// Count the number of edges in the graph defined by the adjacency matrix A.\n\tint counter = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcounter += A[i*N + j];\n\t\t}\n\t}\n\n\treturn counter / 2;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i*N + j] == 1 || A[j*N + i] == 1) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int edgeCount = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i < j && A[i * N + j]!= 0) {\n        edgeCount++;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = i + 1; j < N; ++j)\n      if (A[N * i + j])\n        ++count;\n  return count;\n}",
            "if (A.size()!= N*N) {\n    throw std::invalid_argument(\"Invalid adjacency matrix.\");\n  }\n\n  // Count the number of edges in the graph defined by the adjacency matrix A.\n  // A is an NxN adjacency matrix stored in row-major.\n  // Example:\n\n  // input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n  // output: 3\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i+1; j < N; j++) {\n      if (A[i*N+j] == 1 || A[j*N+i] == 1) {\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int numEdges{0};\n\n    for (size_t row{0}; row < N; ++row) {\n        for (size_t col{row+1}; col < N; ++col) {\n            if (A[row * N + col]) {\n                numEdges++;\n            }\n        }\n    }\n\n    return numEdges;\n}",
            "int num_edges = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[i * N + j] == 1) {\n                num_edges++;\n            }\n        }\n    }\n    return num_edges;\n}",
            "int count = 0;\n\n  for (size_t row = 0; row < N; ++row)\n    for (size_t col = 0; col < N; ++col)\n      if (A[row * N + col] == 1)\n        ++count;\n\n  return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "size_t count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j] == 1 || A[j * N + i] == 1) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// Your code here.\n\tint e = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t{\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t{\n\t\t\tif (i!= j && A[i*N + j] == 1)\n\t\t\t{\n\t\t\t\te++;\n\t\t\t}\n\t\t}\n\t}\n\treturn e;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = i + 1; j < N; j++) {\n            if (A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n\n    return count;\n}",
            "int result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n    for(size_t i = 0; i < N; i++) {\n        for(size_t j = i + 1; j < N; j++) {\n            if(A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                ++count;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++)\n    {\n        for (size_t j = 0; j < N; j++)\n        {\n            if (A[i * N + j])\n            {\n                count += 1;\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = i + 1; j < N; ++j) {\n      count += A[i * N + j];\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "size_t count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j]) ++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = i + 1; j < N; ++j) {\n            if (A[i*N + j] == 1)\n                count++;\n        }\n    }\n    return count;\n}",
            "// Replace this with your code\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i)\n        for (int j = 0; j < N; ++j)\n            if (A[i*N + j])\n                count++;\n    return count;\n}",
            "int edge_count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++edge_count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edge_count;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "hip",
        "prompt": "/* Count the number of edges in the graph defined by the adjacency matrix A.\n   Store the result in numEdges.\n   A is an NxN adjacency matrix stored in row-major.\n   Use AMD HIP to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\n__global__ void edgeCount(const int *A, size_t N, int *numEdges) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int sum = 0;\n\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (col < N) {\n\t\tfor (int row = 0; row < N; row++) {\n\t\t\tif (A[row + col * N]!= 0)\n\t\t\t\tsum++;\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "int myIdx = threadIdx.x;\n\tint nEdges = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tnEdges += A[i * N + myIdx];\n\t}\n\tatomicAdd(numEdges, nEdges);\n}",
            "int idx = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\tif (idx < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[idx * N + i]!= 0) count++;\n\t\t}\n\t\tnumEdges[idx] = count;\n\t}\n}",
            "int threadId = threadIdx.x;\n    if (threadId < N) {\n        int sum = 0;\n        for (int i = 0; i < N; i++) {\n            if (A[threadId * N + i] == 1) {\n                sum++;\n            }\n        }\n        atomicAdd(numEdges, sum);\n    }\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n    if (i < N) {\n        int num = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                num++;\n            }\n        }\n        *numEdges = *numEdges + num;\n    }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row < N) {\n    for (int col = 0; col < N; col++) {\n      if (A[row * N + col] > 0) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "// Store the global index in threadIdx.x\n\tint tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint n = N;\n\tif (tid < n * n) {\n\t\tint row = tid / n;\n\t\tint col = tid % n;\n\t\tint val = A[tid];\n\t\tint sum = 0;\n\t\tfor (int i = row; i < n; i++) {\n\t\t\tfor (int j = col; j < n; j++) {\n\t\t\t\tif (i!= j && A[i * n + j] > 0) {\n\t\t\t\t\tsum++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tnumEdges[0] += sum;\n\t}\n}",
            "int i, j, myNumEdges = 0;\n\n\ti = threadIdx.x;\n\tj = blockIdx.x;\n\tif (j < N && A[i + j * N] == 1) myNumEdges++;\n\n\t__shared__ int myNumEdges_s[32];\n\tmyNumEdges_s[threadIdx.x] = myNumEdges;\n\n\t__syncthreads();\n\n\tif (threadIdx.x < 16)\n\t\tmyNumEdges_s[threadIdx.x] += myNumEdges_s[threadIdx.x + 16];\n\n\t__syncthreads();\n\n\tif (threadIdx.x < 8)\n\t\tmyNumEdges_s[threadIdx.x] += myNumEdges_s[threadIdx.x + 8];\n\n\t__syncthreads();\n\n\tif (threadIdx.x < 4)\n\t\tmyNumEdges_s[threadIdx.x] += myNumEdges_s[threadIdx.x + 4];\n\n\t__syncthreads();\n\n\tif (threadIdx.x < 2)\n\t\tmyNumEdges_s[threadIdx.x] += myNumEdges_s[threadIdx.x + 2];\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0)\n\t\tatomicAdd(numEdges, myNumEdges_s[0] + myNumEdges_s[1]);\n}",
            "int i = threadIdx.x;\n    int myCount = 0;\n    if (i < N) {\n        for (int j = 0; j < N; j++) {\n            myCount += A[i * N + j];\n        }\n        numEdges[i] = myCount;\n    }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid >= N) return;\n\n\tint edgeCount = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tif (A[tid * N + i] == 1) edgeCount++;\n\tif (tid == 0) *numEdges = edgeCount;\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (tid < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tif (A[tid * N + i] == 1)\n\t\t\t\tcount++;\n\t\tnumEdges[tid] = count;\n\t}\n}",
            "// TODO: Implement this.\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (x < N) {\n\t\tint s = 0;\n\t\tfor (int y = 0; y < N; y++) {\n\t\t\tif (A[x * N + y] == 1)\n\t\t\t\ts += 1;\n\t\t}\n\t\tatomicAdd(numEdges, s);\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid >= N) {\n\t\treturn;\n\t}\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[tid * N + i]!= 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\n\tint count = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i*N + j] == 1) {\n\t\t\tcount++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "// Fill this in.\n}",
            "int i = threadIdx.x;\n  int sum = 0;\n  for (int j = 0; j < N; ++j) {\n    sum += A[N*i + j];\n  }\n  atomicAdd(numEdges, sum);\n}",
            "const size_t globalThreadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (globalThreadID >= N) {\n\t\treturn;\n\t}\n\n\tint myNumEdges = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (A[globalThreadID * N + i] == 1) {\n\t\t\tmyNumEdges++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, myNumEdges);\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (i < N && j < N && i < j) {\n\t\tatomicAdd(numEdges, (A[i*N+j] || A[j*N+i])? 1 : 0);\n\t}\n}",
            "__shared__ int edges[BLOCK_SIZE];\n\tedges[threadIdx.x] = 0;\n\t__syncthreads();\n\n\tfor(size_t row=0; row < N; row++) {\n\t\tfor(size_t col=0; col < N; col++) {\n\t\t\tif(A[row*N + col]!= 0) {\n\t\t\t\tedges[threadIdx.x]++;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tint sum = 0;\n\t\tint *tmp = edges + threadIdx.x;\n\t\tfor(int i=0; i<BLOCK_SIZE; i++) {\n\t\t\tsum += *tmp;\n\t\t\ttmp += BLOCK_SIZE;\n\t\t}\n\t\t__syncthreads();\n\n\t\tif(threadIdx.x == 0) {\n\t\t\tatomicAdd(numEdges, sum);\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "const int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tmp = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[row * N + j]) {\n\t\t\ttmp++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, tmp);\n}",
            "int sum = 0;\n\tfor(int i = threadIdx.x; i < N*N; i += blockDim.x) {\n\t\tif(A[i] == 1) {\n\t\t\tsum++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.y + threadIdx.y;\n\tif (i >= N || j >= N)\n\t\treturn;\n\tint m = (A[i*N + j] == 1);\n\tatomicAdd(numEdges, m);\n}",
            "//TODO: Implement\n\n}",
            "int sum = 0;\n    for (size_t i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++sum;\n            }\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "const int numThreads = gridDim.x * blockDim.x;\n\tconst int threadNum = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myEdges = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1 && i!= j) {\n\t\t\t\tmyEdges++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, myEdges);\n}",
            "const int id = blockDim.x*blockIdx.x + threadIdx.x;\n\tint i;\n\tint count = 0;\n\n\tfor(i=0; i<N; i++) {\n\t\tif(A[id*N+i]==1) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, count);\n}",
            "// Add your code here\n}",
            "const int ID = blockDim.x * blockIdx.x + threadIdx.x;\n  if (ID < N) {\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[ID * N + i] == 1)\n        count++;\n    }\n    numEdges[ID] = count;\n  }\n}",
            "int row = threadIdx.x;\n    int sum = 0;\n    for (int i = 0; i < N; ++i) {\n        if (i!= row)\n            sum += A[row*N + i];\n    }\n    atomicAdd(numEdges, sum);\n}",
            "// Compute the sum of all the elements in the\n    // adjacency matrix\n    // A is an NxN matrix stored in row-major\n    // A[i][j] = A[i * N + j]\n\n    int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n    // use a shared memory to store the sum of all the threads\n    extern __shared__ int smem[];\n\n    int sm_tid = hipThreadIdx_x;\n    int sum = 0;\n\n    for (int i = tid; i < N * N; i += hipGridDim_x * hipBlockDim_x) {\n        sum += A[i];\n    }\n\n    // reduce the thread sum in each thread using shared memory\n    smem[sm_tid] = sum;\n    __syncthreads();\n\n    for (int i = (hipBlockDim_x / 2); i > 0; i >>= 1) {\n        if (sm_tid < i) {\n            smem[sm_tid] = smem[sm_tid] + smem[sm_tid + i];\n        }\n        __syncthreads();\n    }\n\n    // The first thread in the block stores the block sum\n    // in the global memory\n    if (sm_tid == 0) {\n        atomicAdd(numEdges, smem[0]);\n    }\n}",
            "int sum = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint count = 0;\n\tfor (int i = tid; i < N * N; i += blockDim.x * gridDim.x) {\n\t\tint j = i % N;\n\t\tint k = i / N;\n\t\tif (j == k)\n\t\t\tcontinue;\n\t\tcount += A[i];\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "// Get global thread index.\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Return if i is out of bounds.\n  if (i >= N)\n    return;\n\n  int numLocalEdges = 0;\n\n  // Loop over the rest of the row in A.\n  for (int j = i + 1; j < N; ++j) {\n\n    // If there is an edge (i,j) in A, increment local edge count.\n    if (A[i * N + j] == 1) {\n      numLocalEdges++;\n    }\n  }\n\n  // Use atomicAdd to add to the global counter.\n  atomicAdd(numEdges, numLocalEdges);\n}",
            "/*\n      AMD-optimized code.\n      Uses 32 threads (blockDim.x = 32), where each thread\n      processes one edge.\n      AMD-optimized code should run in 32 threads\n      per edge, so this code should be able to handle\n      N <= 65536 edges.\n      If N > 65536, you may want to adjust the code to\n      use more threads, or process multiple edges per\n      thread.\n      */\n    __shared__ int partial_counts[32];\n    unsigned int start = threadIdx.x;\n    unsigned int stride = blockDim.x;\n    unsigned int t;\n    int sum = 0;\n    for (t = start; t < N; t += stride) {\n        int edge = A[t];\n        if (edge!= 0) {\n            sum++;\n        }\n    }\n    partial_counts[threadIdx.x] = sum;\n    __syncthreads();\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (threadIdx.x < s) {\n            partial_counts[threadIdx.x] += partial_counts[threadIdx.x + s];\n        }\n        __syncthreads();\n    }\n    if (threadIdx.x == 0) {\n        atomicAdd(numEdges, partial_counts[0]);\n    }\n}",
            "__shared__ int edgeCounts[256];\n\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n\n  // If this thread's vertex does not have any outgoing edges, then it does\n  // not contribute to the edge count.\n  if(A[bid * N + tid] == 0)\n    return;\n\n  // Count the number of nonzero entries in the vertex's row.\n  edgeCounts[tid] = __popc(A[bid * N + tid]);\n\n  __syncthreads();\n\n  // Sum up the values in edgeCounts using warp-level reduction.\n  // Note that we assume blockDim.x is a power of 2.\n  for(int offset = 1; offset < blockDim.x; offset *= 2) {\n    if(tid % (offset * 2) == 0)\n      edgeCounts[tid] += edgeCounts[tid + offset];\n\n    __syncthreads();\n  }\n\n  // Only one thread in the block will write to numEdges, because there is a\n  // __syncthreads() call between the warp-level reductions.\n  if(tid == 0)\n    atomicAdd(numEdges, edgeCounts[0]);\n}",
            "// A is an NxN adjacency matrix stored in row-major.\n\t// The kernel is launched with at least N threads.\n\t// Each thread processes one row of A.\n\t// The thread's row index is given by row.\n\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row < N) {\n\t\t// Count the number of adjacent nodes for the current row.\n\t\t// The number of adjacent nodes is equal to the number of\n\t\t// set bits in the binary representation of A[row].\n\t\tint adj = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[row * N + i]!= 0) {\n\t\t\t\tadj += 1;\n\t\t\t}\n\t\t}\n\t\t// Each thread atomically increments numEdges by adj.\n\t\tatomicAdd(numEdges, adj);\n\t}\n}",
            "int myRow = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (myRow < N) {\n    int myOffset = myRow * N;\n    for (int j = 0; j < N; ++j) {\n      if (A[myOffset + j]!= 0) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "int gid = blockIdx.x * blockDim.x + threadIdx.x;\n    int tid = threadIdx.x;\n    extern __shared__ int temp[];\n    int threadId = threadIdx.x;\n    int laneId = threadId & 31;\n    int wid = threadIdx.x / 32;\n    int bid = blockIdx.x;\n    int i = gid;\n    int sum = 0;\n    int j;\n\n    /*\n\t   At this point, the threads have been launched in parallel and can process the\n       elements in A in parallel\n    */\n\n    temp[threadId] = 0;\n    __syncthreads();\n\n    for (j = 0; j < N; j++) {\n        if (i < N && j < N)\n            temp[threadId] += A[i + j * N];\n    }\n    __syncthreads();\n\n    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            temp[threadId] += temp[threadId + s];\n        }\n        __syncthreads();\n    }\n\n    if (threadIdx.x == 0) {\n        atomicAdd(numEdges, temp[threadId]);\n    }\n}",
            "int threadIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (threadIdx < N) {\n    // Compute the number of edges in this row.\n    int localNumEdges = 0;\n    for (int i = 0; i < N; i++)\n      if (A[threadIdx * N + i]!= 0)\n        localNumEdges++;\n    atomicAdd(numEdges, localNumEdges);\n  }\n}",
            "// TODO: replace with your code\n  __shared__ int sum[BLOCKSIZE];\n  int i, j;\n  int k = threadIdx.x;\n\n  if (k == 0)\n    sum[0] = 0;\n  __syncthreads();\n\n  while (k < N) {\n    i = blockIdx.x;\n    j = k;\n    if (i < N && A[i * N + j] == 1)\n      atomicAdd(sum, 1);\n\n    k += blockDim.x;\n  }\n\n  __syncthreads();\n  int idx = threadIdx.x;\n  while (idx < blockDim.x) {\n    atomicAdd(numEdges, sum[idx]);\n    idx += blockDim.x;\n  }\n}",
            "__shared__ int tmp[64];\n  int tid = threadIdx.x;\n  tmp[tid] = 0;\n  __syncthreads();\n  int i = blockDim.x * blockIdx.x + threadIdx.x;\n  while (i < N*N) {\n    if (A[i] == 1) {\n      atomicAdd(&(tmp[tid]), 1);\n    }\n    i += blockDim.x * gridDim.x;\n  }\n  __syncthreads();\n  for (int i = 16; i > 0; i >>= 1) {\n    if (tid < i) {\n      atomicAdd(&(tmp[tid]), tmp[tid + i]);\n    }\n    __syncthreads();\n  }\n  if (tid == 0) {\n    atomicAdd(numEdges, tmp[0]);\n  }\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (id < N) {\n\t\tint i = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i + j * N]!= 0) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int index = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n    if (index >= N * N) {\n        return;\n    }\n\n    // Calculate the number of edges by finding the number of ones in the upper triangle\n    int i = index / N;\n    int j = index % N;\n    if (i >= j) {\n        atomicAdd(numEdges, A[index]);\n    }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint count = 0;\n\tif(idx < N) {\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tcount += A[i * N + idx];\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "// TODO: add code here\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N) return;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (i < j) {\n\t\t\tnumEdges[0] += A[i + j * N];\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < N * N) {\n\t\tint col = i % N;\n\t\tint row = i / N;\n\n\t\tif (row < N && col < N) {\n\t\t\tif (A[row*N + col] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int edgeCount = 0;\n  for (size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n       i < N;\n       i += gridDim.x * blockDim.x) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        atomicAdd(&edgeCount, 1);\n      }\n    }\n  }\n  atomicAdd(numEdges, edgeCount);\n}",
            "int i = threadIdx.x;\n\n\t__shared__ int numEdgesLocal[256];\n\tnumEdgesLocal[i] = 0;\n\n\t__syncthreads();\n\n\tif(i < N) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[j * N + i]!= 0) {\n\t\t\t\tnumEdgesLocal[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif(i < 128)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 128];\n\t__syncthreads();\n\tif(i < 64)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 64];\n\t__syncthreads();\n\tif(i < 32)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 32];\n\t__syncthreads();\n\tif(i < 16)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 16];\n\t__syncthreads();\n\tif(i < 8)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 8];\n\t__syncthreads();\n\tif(i < 4)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 4];\n\t__syncthreads();\n\tif(i < 2)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 2];\n\t__syncthreads();\n\tif(i < 1)\n\t\tnumEdgesLocal[i] += numEdgesLocal[i + 1];\n\n\t__syncthreads();\n\n\tif(i == 0) {\n\t\t*numEdges = numEdgesLocal[0];\n\t}\n}",
            "int sum = 0;\n  for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += gridDim.x * blockDim.x) {\n    for (int j = 0; j < N; ++j) {\n      if (i == j) {\n        continue;\n      }\n      if (A[i * N + j] == 1) {\n        sum++;\n      }\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "int count = 0;\n  int start = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  for (int i = start; i < N; i += stride) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  atomicAdd(numEdges, count);\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  if (tid >= N) return;\n  int rowSum = 0;\n  for (size_t j = 0; j < N; j++) {\n    rowSum += A[tid * N + j];\n  }\n  atomicAdd(numEdges, rowSum);\n}",
            "int i = threadIdx.x;\n  int j;\n  int cnt = 0;\n  for(j = 0; j < N; j++) {\n    if(i < N && j < N) {\n      if (A[j * N + i] == 1) {\n        cnt++;\n      }\n    }\n  }\n  atomicAdd(numEdges, cnt);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        int edges = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[N * tid + j]!= 0) {\n                edges++;\n            }\n        }\n        atomicAdd(numEdges, edges);\n    }\n}",
            "int count = 0;\n\n  for (int j = blockIdx.x * blockDim.x + threadIdx.x; j < N * N;\n       j += gridDim.x * blockDim.x) {\n    if (A[j] == 1) {\n      atomicAdd(numEdges, 1);\n    }\n  }\n\n  if (blockDim.x * blockIdx.x + threadIdx.x == 0) {\n    atomicAdd(numEdges, 0);\n  }\n}",
            "unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif(tid < N*N) {\n\t\tint row = tid / N;\n\t\tint col = tid % N;\n\t\tif(row!= col && A[row * N + col] > 0) {\n\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "size_t i = blockDim.x*blockIdx.x + threadIdx.x;\n\n  // Compute the number of edges in the sub-graph defined by this row of A\n  int local_numEdges = 0;\n  for (size_t j = 0; j < N; ++j) {\n    if (i!= j)\n      local_numEdges += A[i*N+j];\n  }\n\n  // Add this local count to the global count\n  atomicAdd(numEdges, local_numEdges);\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\n  if (tid < N) {\n    int rowOffset = tid * N;\n    int i;\n    for (i = 0; i < N; i++) {\n      if (A[rowOffset + i] == 1)\n        atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "// Fetch the thread id.\n\tconst int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// Make sure we don't access out of bounds memory.\n\tif (tid < N) {\n\t\tint count = 0;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[tid * N + i] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "__shared__ int sdata[BLOCK_DIM]; // Shared memory array for block-wide reduction\n\n\t// Compute a thread's element of the answer\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint count = 0;\n\tfor (int j = i; j < N * N; j += stride) {\n\t\tcount += (int) (A[j]!= 0);\n\t}\n\n\t// Reduce the sum of the counts to a single value for the entire block\n\tsdata[threadIdx.x] = count;\n\t__syncthreads();\n\tfor (unsigned int s = BLOCK_DIM / 2; s > 0; s >>= 1) {\n\t\tif (threadIdx.x < s) {\n\t\t\tsdata[threadIdx.x] += sdata[threadIdx.x + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// Write the result to the global memory\n\tif (threadIdx.x == 0) {\n\t\tnumEdges[blockIdx.x] = sdata[0];\n\t}\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      if (i == j)\n        continue;\n      if (A[i * N + j] > 0) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "int sum = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t}\n\t*numEdges = sum;\n}",
            "unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int stride = blockDim.x * gridDim.x;\n  unsigned int offset = 0;\n\n  if (idx < N) {\n    int row[N];\n\n    // read the matrix row into shared memory\n    for (int i = 0; i < N; i++) {\n      row[i] = A[i*N + idx];\n    }\n    // count the number of edges in the row\n    for (int i = 0; i < N; i++) {\n      if (i == idx) {\n        continue;\n      }\n      if (row[i]!= 0) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "const int thread = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (thread < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i*N + thread] == 1)\n\t\t\t\tcount++;\n\t\t}\n\t\tnumEdges[thread] = count;\n\t}\n}",
            "int *global_sum = numEdges;\n\tint sum = 0;\n\n\tconst int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tconst int gsize = gridDim.x*blockDim.x;\n\tint j;\n\n\tfor (int i = tid; i < N; i += gsize) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(global_sum, sum);\n}",
            "int sum = 0;\n  int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (tid < N) {\n    for (int j = 0; j < N; j++) {\n      sum += (A[j * N + tid] == 1);\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "const int x = blockIdx.x * blockDim.x + threadIdx.x;\n    const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (x == y)\n        atomicAdd(numEdges, A[y * N + x]);\n}",
            "__shared__ int sData[THREADS_PER_BLOCK];\n  int gData = 0;\n  int row = blockIdx.x;\n  int col = threadIdx.x;\n\n  if (row < N && col < N) {\n    if (A[row*N + col] == 1) {\n      atomicAdd(&gData, 1);\n    }\n  }\n\n  // Reduce within the block.\n  for (int i = 16; i > 0; i /= 2) {\n    __syncthreads();\n    int index = 2 * threadIdx.x - (i & (i - 1));\n    if (index < i && index < blockDim.x) {\n      atomicAdd(&sData[threadIdx.x], sData[index]);\n    }\n  }\n\n  // Write result for this block to global memory.\n  if (threadIdx.x == 0) {\n    atomicAdd(numEdges, sData[0]);\n  }\n}",
            "int index = blockDim.x * blockIdx.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  int count = 0;\n  for(size_t i = index; i < N; i += stride) {\n    for(size_t j = i + 1; j < N; j++) {\n      if(A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  atomicAdd(numEdges, count);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int numT = gridDim.x * blockDim.x;\n  int myEdges = 0;\n  // each thread iterates over its column of the matrix\n  for (size_t i = tid; i < N; i += numT) {\n    for (size_t j = 0; j < N; j++) {\n      // add the edge if the entry is 1\n      myEdges += A[i*N+j];\n    }\n  }\n  // atomicAdd to avoid race conditions\n  atomicAdd(numEdges, myEdges);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int sum = 0;\n    if (tid < N) {\n        for (size_t i = 0; i < N; i++) {\n            sum += A[tid * N + i];\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i >= N || j >= N) {\n        return;\n    }\n    __shared__ int sum;\n    if (A[i*N+j]) {\n        atomicAdd(&sum, 1);\n    }\n    __syncthreads();\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        atomicAdd(numEdges, sum);\n    }\n}",
            "__shared__ int sData[BLOCK_SIZE];\n  int threadId = blockDim.x*blockIdx.x + threadIdx.x;\n  int numThreads = blockDim.x*gridDim.x;\n  int count = 0;\n\n  for (int i=threadId; i < N; i+=numThreads) {\n    for (int j=0; j < N; ++j) {\n      count += A[N*i+j];\n    }\n  }\n\n  sData[threadIdx.x] = count;\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    for (int i=1; i < blockDim.x; ++i) {\n      count += sData[i];\n    }\n    *numEdges = count;\n  }\n}",
            "const int myID = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (myID < N) {\n\t\tint myRow[N];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tmyRow[i] = A[myID + i*N];\n\t\t}\n\t\tint myCount = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < i; j++) {\n\t\t\t\tif (myRow[i] == 1 && myRow[j] == 1) {\n\t\t\t\t\tmyCount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, myCount);\n\t}\n}",
            "__shared__ int thread_sums[256];\n  unsigned int tid = threadIdx.x;\n  unsigned int idx = blockDim.x * blockIdx.x + tid;\n\n  // We need 2 threads per edge\n  int local_sum = 0;\n  if (idx < N * (N - 1)) {\n    if (A[idx] > 0) {\n      local_sum = 2;\n    }\n  }\n\n  // Accumulate each thread's sum into a private array\n  thread_sums[tid] = local_sum;\n  __syncthreads();\n\n  // Accumulate the values in the private array back into threadIdx.x\n  // The reduction is performed in log2(blockDim.x) iterations\n  unsigned int i = blockDim.x / 2;\n  while (i!= 0) {\n    if (tid < i) {\n      thread_sums[tid] += thread_sums[tid + i];\n    }\n    __syncthreads();\n    i /= 2;\n  }\n\n  // Final sum stored in threadIdx.x\n  if (tid == 0) {\n    atomicAdd(numEdges, thread_sums[0]);\n  }\n}",
            "int myId = threadIdx.x; // my Id\n\n\t__shared__ int nBlocks;\n\tif (threadIdx.x == 0) {\n\t\tnBlocks = blockDim.x;\n\t}\n\t__syncthreads();\n\n\t// Each thread will take care of the lower triangular part of the submatrix\n\t// with the matrix Id as the diagonal\n\n\tint id = myId * nBlocks + myId;\n\tint start = id * N;\n\n\tint n = N * N;\n\tint count = 0;\n\twhile (id < n) {\n\t\tif (A[id] > 0) {\n\t\t\tcount++;\n\t\t}\n\t\tid += nBlocks * nBlocks;\n\t}\n\n\t// Add the counts from all the threads in the block\n\n\textern __shared__ int sdata[];\n\tsdata[myId] = count;\n\t__syncthreads();\n\n\tint i = blockDim.x / 2;\n\twhile (i!= 0) {\n\t\tif (myId < i) {\n\t\t\tsdata[myId] += sdata[myId + i];\n\t\t}\n\t\t__syncthreads();\n\t\ti /= 2;\n\t}\n\n\tif (myId == 0) {\n\t\tatomicAdd(numEdges, sdata[0]);\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t__shared__ int s_count[MAX_THREADS_PER_BLOCK];\n\n\tint count = 0;\n\tfor(int i = tid; i < N; i += blockDim.x * gridDim.x) {\n\t\tint rowIdx = i * N;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif (A[rowIdx + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\ts_count[tid] = count;\n\t__syncthreads();\n\tint i = blockDim.x/2;\n\twhile(i > 0) {\n\t\tif(tid < i) {\n\t\t\ts_count[tid] += s_count[tid+i];\n\t\t}\n\t\t__syncthreads();\n\t\ti = i/2;\n\t}\n\tif(tid == 0) {\n\t\tatomicAdd(numEdges, s_count[0]);\n\t}\n}",
            "// compute edge count\n    int tid = blockIdx.x*blockDim.x + threadIdx.x;\n    int ecount = 0;\n\n    for (size_t i=tid; i < N*N; i+=blockDim.x*gridDim.x) {\n        int row = i/N;\n        int col = i%N;\n        ecount += A[row*N + col];\n    }\n\n    // sum edge counts\n    atomicAdd(numEdges, ecount);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  int stride = gridDim.x * blockDim.x;\n\n  int e = 0;\n  for (size_t i = tid; i < N; i += stride) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        e += 1;\n      }\n    }\n  }\n\n  atomicAdd(numEdges, e);\n}",
            "// Thread ID\n\tconst int tid = threadIdx.x + blockDim.x * blockIdx.x;\n\n\t// Get the row number for the current thread\n\tconst int row = tid / N;\n\t// Get the column number for the current thread\n\tconst int col = tid % N;\n\n\tif (A[row * N + col] == 1) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "int sum = 0;\n\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (i < N) {\n\t\tfor (int j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\n\t*numEdges = sum;\n}",
            "// The grid is mapped to A\n\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// The block size is 1\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\t\n\t// Each thread reads one element from the matrix A\n\tint a = A[row * N + col];\n\t\n\t// Compute the total number of edges by computing the sum over all elements in A\n\t// in parallel\n\tint sum = 0;\n\t#pragma unroll\n\tfor (int i = 0; i < N / 1024; ++i) {\n\t\tsum += A[row * N + N * 1024 + i * 1024 + tx];\n\t}\n\t\n\t// Each thread stores its local sum to shared memory\n\t__shared__ int s_sum[1024];\n\ts_sum[tx] = sum;\n\t__syncthreads();\n\t\n\t// Add up values in shared memory to compute the total sum\n\tsum = s_sum[tx];\n\t#pragma unroll\n\tfor (int i = 1; i < 1024; i <<= 1) {\n\t\tsum += s_sum[tx + i];\n\t}\n\t\n\t// The value of the sum is stored in a register\n\tint totalSum = sum;\n\t\n\t// All threads in a block write to the same location\n\tif (tx == 0) {\n\t\tatomicAdd(numEdges, totalSum);\n\t}\n}",
            "int threadIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (threadIdx < N) {\n\t\tint i, sum = 0;\n\t\tfor (i = 0; i < N; ++i) {\n\t\t\tsum += A[i * N + threadIdx];\n\t\t}\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "__shared__ int numEdgesShared[THREADS_PER_BLOCK];\n\tint n = threadIdx.x;\n\tint m = blockIdx.x;\n\tif (m == n) {\n\t\tint edges = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tedges += A[m*N + i] + A[i*N + n];\n\t\t}\n\t\tnumEdgesShared[threadIdx.x] = edges;\n\t} else {\n\t\tnumEdgesShared[threadIdx.x] = 0;\n\t}\n\t__syncthreads();\n\n\tfor (int s = THREADS_PER_BLOCK / 2; s > 0; s /= 2) {\n\t\tif (n < s) {\n\t\t\tnumEdgesShared[n] += numEdgesShared[n + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (n == 0) {\n\t\tatomicAdd(numEdges, numEdgesShared[0]);\n\t}\n}",
            "int gid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (gid < N) {\n\t\tint start = gid * N;\n\t\tint count = 0;\n\n\t\tfor (int i = start; i < start + N; i++) {\n\t\t\tif (A[i]!= 0)\n\t\t\t\tcount++;\n\t\t}\n\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (tid >= N) return;\n\n\tint sum = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += A[N * i + tid];\n\t}\n\tnumEdges[tid] = sum;\n}",
            "// shared memory for computing histogram\n\t__shared__ int sharedMem[BLOCK_SIZE];\n\n\tconst int myID = threadIdx.x;\n\tconst int myRow = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int myCol = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myCount = 0;\n\n\tif (myRow < N && myCol < N) {\n\t\tmyCount = (A[myRow * N + myCol])? 1 : 0;\n\t}\n\n\t// Use atomicAdd to avoid race conditions.\n\tatomicAdd(sharedMem + myID, myCount);\n\n\t// wait until all threads in this block have completed the above step\n\t__syncthreads();\n\n\t// Now, a single thread from each block does the summation of the counts from\n\t// shared memory.\n\t// Note: thread 0 is assigned the value of threadIdx.x == 0.\n\t//       We are using a for loop because this is a simple example of reduction.\n\tif (myID == 0) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < BLOCK_SIZE; i++) {\n\t\t\tsum += sharedMem[i];\n\t\t}\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "int i = threadIdx.x;\n\n  int j, val = 0;\n\n  for (j = 0; j < N; j++) {\n    if (A[i * N + j] == 1) {\n      val++;\n    }\n  }\n\n  atomicAdd(numEdges, val);\n}",
            "const int row = blockDim.x * blockIdx.x + threadIdx.x;\n  int sum = 0;\n  if (row < N) {\n    for (int col = 0; col < N; col++) {\n      if (A[row * N + col] == 1) {\n        sum++;\n      }\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "// The thread ID\n  size_t id = blockDim.x * blockIdx.x + threadIdx.x;\n  // The number of threads in the block\n  size_t stride = gridDim.x * blockDim.x;\n\n  // Compute the sum of the adjacency matrix\n  int sum = 0;\n  for (size_t i = id; i < N * N; i += stride) {\n    sum += A[i];\n  }\n\n  // Accumulate the results across the block\n  __shared__ int sumTemp[256];\n  sumTemp[threadIdx.x] = sum;\n  __syncthreads();\n\n  for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n    if (threadIdx.x < stride) {\n      sumTemp[threadIdx.x] += sumTemp[threadIdx.x + stride];\n    }\n    __syncthreads();\n  }\n\n  // Write the sum out to global memory\n  if (threadIdx.x == 0) {\n    *numEdges = sumTemp[0];\n  }\n}",
            "// Add code here to count the number of edges.\n}",
            "int thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    for (int idx = thread_id; idx < N; idx += stride) {\n        int count = 0;\n\n        for (int jdx = 0; jdx < N; jdx++) {\n            if (A[idx * N + jdx] > 0) {\n                count++;\n            }\n        }\n\n        atomicAdd(numEdges, count);\n    }\n}",
            "// The number of edges is the same as the number of elements that are non-zero in the adjacency matrix\n\tconst int n = threadIdx.x;\n\n\tint sum = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += (A[i * N + j] == 1)? 1 : 0;\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "const int tid = threadIdx.x;\n\tconst int bid = blockIdx.x;\n\tconst int bsize = blockDim.x;\n\tint tmp = 0;\n\tfor (int i = bid * bsize + tid; i < N; i += bsize * gridDim.x)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\ttmp += A[i * N + j];\n\n\t// __syncthreads();\n\textern __shared__ int numEdgesSh[];\n\tint num = numEdgesSh[threadIdx.x];\n\tfor (int i = 1; i < bsize; i *= 2)\n\t\tnum += __shfl_down_sync(0xffffffff, num, i);\n\tif (threadIdx.x == 0)\n\t\tnumEdgesSh[0] = num;\n\t__syncthreads();\n\tnum = numEdgesSh[0];\n\n\tif (threadIdx.x == 0)\n\t\tatomicAdd(numEdges, tmp);\n}",
            "__shared__ int sdata[MAX_THREADS];\n    int tid = threadIdx.x;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int offset = blockDim.x * gridDim.x;\n    sdata[tid] = 0;\n    while (i < N) {\n        sdata[tid] += A[i];\n        i += offset;\n    }\n    __syncthreads();\n\n    // Parallel sum reduction\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sdata[tid] += sdata[tid + s];\n        }\n        __syncthreads();\n    }\n    if (tid == 0) {\n        numEdges[blockIdx.x] = sdata[0];\n    }\n}",
            "int sum = 0;\n  for (int j = 0; j < N; j++) {\n    for (int i = 0; i < N; i++) {\n      if (A[i + j * N] > 0) {\n        sum += 1;\n      }\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "// TODO implement\n}",
            "__shared__ int sA[BLOCK_SIZE][BLOCK_SIZE];\n\tint sum = 0;\n\tfor (int i = threadIdx.x; i < N; i += blockDim.x) {\n\t\tif (threadIdx.y == 0) {\n\t\t\tsA[threadIdx.x][threadIdx.y] = A[threadIdx.x*N + i];\n\t\t}\n\t}\n\t__syncthreads();\n\tfor (int i = 0; i < N; i++) {\n\t\tif (threadIdx.x > i) {\n\t\t\tsum += sA[threadIdx.x][i];\n\t\t} else if (threadIdx.x < i) {\n\t\t\tsum += sA[i][threadIdx.x];\n\t\t}\n\t}\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "int tid = blockIdx.x*blockDim.x+threadIdx.x;\n\tint count = 0;\n\tif(tid < N) {\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(A[tid*N+i] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "const int tid = threadIdx.x;\n\tif(tid < N) {\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(A[tid*N + i] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO: Compute the number of edges in the graph defined by adjacency matrix A.\n  //   A is an NxN adjacency matrix stored in row-major.\n  //   The kernel is launched with at least N threads.\n  //   numEdges is a pointer to a single integer set by this function to the number of edges.\n  //   Assume 0-based indexing.\n\n  // For now, just set numEdges to the total number of non-zero values in A.\n  //   This is the correct answer, but not the most efficient way to do it.\n  //   We should use AMD HIP intrinsics to find the correct value.\n  *numEdges = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0)\n        ++(*numEdges);\n    }\n  }\n\n  // TODO: Use an atomic operation to update numEdges correctly.\n}",
            "int myCount = 0;\n\tint myRow = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (myRow >= N) {\n\t\treturn;\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (i!= myRow && A[i * N + myRow] > 0) {\n\t\t\tmyCount++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, myCount);\n}",
            "__shared__ int sum[BLOCK_SIZE];\n    int offset = blockIdx.x * blockDim.x;\n    int id = threadIdx.x + offset;\n    int num = 0;\n    for (int i = id; i < N; i += blockDim.x * gridDim.x) {\n        for (int j = 0; j < N; j++) {\n            num += A[i*N+j];\n        }\n    }\n    sum[threadIdx.x] = num;\n    __syncthreads();\n    int len = blockDim.x;\n    while (len!= 1) {\n        int half = len / 2;\n        if (threadIdx.x < half) {\n            sum[threadIdx.x] += sum[threadIdx.x + half];\n        }\n        __syncthreads();\n        len = half;\n    }\n    if (threadIdx.x == 0) {\n        numEdges[blockIdx.x] = sum[0];\n    }\n}",
            "const int i = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif(i >= N) {\n\t\treturn;\n\t}\n\n\tint result = 0;\n\n\tfor(int j = 0; j < N; ++j) {\n\t\tresult += A[j * N + i];\n\t}\n\n\tatomicAdd(numEdges, result);\n}",
            "// Fill in your code here\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  if (tid >= N)\n    return;\n\n  int myEdges = 0;\n  int i,j;\n  for (i=0; i<N; i++)\n    for (j=0; j<N; j++)\n      myEdges += (A[i*N + j] && (i!=j));\n\n  atomicAdd(numEdges, myEdges);\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tconst int stride = blockDim.x * gridDim.x;\n\tint sum = 0;\n\tfor (int i = tid; i < N; i += stride) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  if (tid >= N) return;\n  int rowSum = 0;\n  for (int i = 0; i < N; i++) {\n    if (A[tid * N + i] == 1) rowSum++;\n  }\n  atomicAdd(numEdges, rowSum);\n}",
            "// Thread IDs in a one-dimensional grid\n\tconst int tid = blockDim.x*blockIdx.y*gridDim.x\n\t\t\t\t  + blockDim.x*blockIdx.x\n\t\t\t\t  + threadIdx.x;\n\n\t// Iterate over all the columns of the adjacency matrix\n\tint count = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\t// If a non-zero entry is found, the edge is present\n\t\tif (A[tid*N + j] > 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\t// Store the count in global memory\n\tatomicAdd(numEdges, count);\n}",
            "// This is the id of the thread.\n\tsize_t tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[tid * N + j] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int row = blockIdx.x*blockDim.x + threadIdx.x;\n\tint col = blockIdx.y*blockDim.y + threadIdx.y;\n\n\tif(row < N && col < N) {\n\t\t//printf(\"%d %d %d\\n\", row, col, A[row*N+col]);\n\t\tif(A[row*N+col] == 1) {\n\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  int count = 0;\n\n  for (int i = tid; i < N; i += stride) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n\n  atomicAdd(numEdges, count);\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (i >= N || j >= N)\n    return;\n\n  atomicAdd(numEdges, (A[i * N + j] == 1));\n}",
            "// threadID is an integer in [0, numThreads), where numThreads is the total number of\n    // threads in the kernel. We can obtain this from blockDim.x * gridDim.x.\n    int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n    if (threadID >= N) return; // exit if threadID is not in [0, N).\n\n    int cnt = 0;\n    for (int i = 0; i < N; i++) {\n        // If A[threadID][i] is 1, then A[i][threadID] is also 1.\n        // Only count one of the two, in order to avoid double counting.\n        if (threadID < i && A[i * N + threadID] == 1) cnt++;\n    }\n    atomicAdd(numEdges, cnt);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  int stride = gridDim.x * blockDim.x;\n\n  int i;\n  int *row;\n\n  for (i = tid; i < N; i += stride) {\n    row = &A[N * i];\n    int j;\n\n    for (j = 0; j < N; ++j) {\n      if (row[j]) {\n        atomicAdd(numEdges, 1);\n        break;\n      }\n    }\n  }\n}",
            "extern __shared__ int temp[];\n\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n\n  int index = bid * blockDim.x + tid;\n\n  temp[tid] = (index < N)? A[index * N + bid] : 0;\n\n  __syncthreads();\n\n  int sum = 0;\n\n  for (int offset = blockDim.x / 2; offset > 0; offset >>= 1) {\n    if (tid < offset) {\n      temp[tid] += temp[tid + offset];\n    }\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    atomicAdd(numEdges, temp[0]);\n  }\n}",
            "/* Get the index of this thread */\n  int tid = threadIdx.x;\n\n  /*\n   * Compute the number of edges on each thread.\n   * Each thread computes a different column of the matrix.\n   * Use the atomicAdd() function to add to the global value safely.\n   */\n  int i = 0;\n  int nEdges = 0;\n  for (i = 0; i < N; i++) {\n    if (A[tid + i * N]) {\n      nEdges++;\n    }\n  }\n\n  /* Store the number of edges found by this thread */\n  atomicAdd(numEdges, nEdges);\n}",
            "// This is how many adjacent blocks (in the adjacency matrix) this thread will count\n\tconst int countPerThread = 2;\n\n\t// This is the range of blocks to count (relative to this thread's starting block)\n\tconst int startBlock = threadIdx.x * countPerThread;\n\tconst int endBlock = startBlock + countPerThread;\n\n\t// This is the index of the thread in the block\n\tconst int threadIdxInBlock = threadIdx.x % countPerThread;\n\n\t// Count the number of edges in the adjacent blocks\n\tint count = 0;\n\tfor (int block = startBlock; block < endBlock; block++) {\n\t\tconst int row = block * blockDim.x + threadIdx.x;\n\t\tif (row < N) {\n\t\t\tconst int col = row + blockDim.x;\n\t\t\tif (col < N) {\n\t\t\t\tif (A[row * N + col] == 1) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sum the counts for each thread in this block\n\tint blockCount = blockReduceSum(count);\n\n\t// Write out our count to global memory\n\tif (threadIdx.x % countPerThread == 0) {\n\t\tatomicAdd(numEdges, blockCount);\n\t}\n}",
            "int sum = 0;\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  if (x < N) {\n    for (int y = 0; y < N; y++) {\n      if (A[x * N + y] > 0) {\n        sum++;\n      }\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "const int col = blockDim.x*blockIdx.x + threadIdx.x;\n\tif (col >= N) return;\n\tint sum = 0;\n\tfor (int row = 0; row < N; row++) {\n\t\tsum += A[row * N + col];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n    if (idx < N) {\n        int sum = 0;\n        for (int i = 0; i < N; i++) {\n            sum += A[idx * N + i];\n        }\n        atomicAdd(numEdges, sum);\n    }\n}",
            "//TODO: implement the kernel\n  *numEdges = 0;\n  int myRow = blockDim.y * blockIdx.y + threadIdx.y;\n  int myCol = blockDim.x * blockIdx.x + threadIdx.x;\n  int ind = myCol * N + myRow;\n  if (myCol < N && myRow < N && A[ind]!= 0) {\n    atomicAdd(numEdges, 1);\n  }\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N)\n\t\treturn;\n\tint count = 0;\n\tfor (int j = 0; j < N; j++)\n\t\tcount += A[i * N + j];\n\tnumEdges[i] = count;\n}",
            "int row = blockIdx.x;\n    int thread = threadIdx.x;\n\n    if (thread == 0) {\n        int c = 0;\n        for (int col = 0; col < N; col++) {\n            if (A[row * N + col]!= 0) {\n                c++;\n            }\n        }\n        atomicAdd(numEdges, c);\n    }\n}",
            "int tx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tx < N) {\n    for (int i = 0; i < N; ++i) {\n      if (A[tx * N + i] == 1)\n        atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n    if (idx >= N) return;\n\n    // Count the number of non-zero values.\n    int cnt = 0;\n    for (int i = 0; i < N; i++) {\n        if (A[idx + i * N]) cnt++;\n    }\n    atomicAdd(numEdges, cnt);\n}",
            "// Get this block's thread ID\n  unsigned int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  // Do nothing if this thread exceeds the number of rows\n  if (tid >= N) return;\n  // Calculate the index for this thread's row of the adjacency matrix\n  size_t ai = tid * N;\n  // Accumulate the number of edges in the adjacency matrix for this thread\n  int sum = 0;\n  for (int j = 0; j < N; j++)\n    if (A[ai + j] == 1) sum++;\n  // Add this thread's result to the global sum\n  atomicAdd(numEdges, sum);\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  if (tid < N) {\n    for (int i = 0; i < N; i++) {\n      if (A[tid * N + i]) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  // Iterate over the non-zero elements of the input array\n  for (int j = i; j < N * N; j += blockDim.x * gridDim.x) {\n    // Check if the element is non-zero\n    if (A[j]!= 0) {\n      atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid < N) {\n        atomicAdd(numEdges, countEdges(A, tid, N));\n    }\n}",
            "// TODO: Implement this function.\n  // You may need to launch extra threads to handle boundary conditions.\n  // You may find AMD's vector_type<T, N> useful.\n  // For more information about vector_type: https://developer.amd.com/amd-gpu-opencl-vectors-in-c/\n  // See the example below.\n\n  int tid = hipThreadIdx_x; // thread ID in the global address space.\n  int bid = hipBlockIdx_x; // block ID in the global address space.\n  int xid = tid % N; // thread ID in the global address space.\n  int yid = tid / N; // block ID in the global address space.\n\n  int cnt = 0;\n\n  if(A[bid * N + tid] == 1)\n    cnt = 1;\n\n  if(xid == 0 || xid == N - 1) {\n    if(A[bid * N + xid] == 1)\n      cnt = 1;\n  }\n\n  if(yid == 0 || yid == N - 1) {\n    if(A[bid * N + yid] == 1)\n      cnt = 1;\n  }\n\n  if(tid < N) {\n    for(int j = 0; j < N; j++) {\n      if(A[bid * N + tid] == 1 && A[bid * N + j] == 1)\n        cnt = 1;\n    }\n  }\n\n  __shared__ int sh_cnt[512];\n  sh_cnt[tid] = cnt;\n\n  __syncthreads();\n\n  for(int i = 0; i < 16; i++) {\n    cnt = 0;\n    for(int j = 0; j < 16; j++)\n      cnt += sh_cnt[j];\n    sh_cnt[tid] = cnt;\n    __syncthreads();\n  }\n\n  if(tid == 0) {\n    atomicAdd(numEdges, sh_cnt[tid]);\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // TODO: implement in parallel\n  // hint: you will need to use atomic operations\n  // use a shared memory atomic to count edges\n  atomicAdd(numEdges, 0);\n}",
            "// Get thread ID\n\tint tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// Do some work\n\tif (tid < N) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tsum += A[tid * N + i];\n\t\t}\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i < N && j < N && A[i*N + j] > 0) {\n        atomicAdd(numEdges, 1);\n    }\n}",
            "// Use a block-wide barrier to synchronize the block\n  __syncthreads();\n  // Initialize the block's shared memory\n  __shared__ int blockCounts[16];\n  blockCounts[threadIdx.x] = 0;\n  __syncthreads();\n\n  // Compute the number of edges in the block-sized submatrix\n  int col = blockDim.x * blockIdx.x + threadIdx.x;\n  for (int row = blockIdx.x * blockDim.x; row < N && row + threadIdx.x < N; row += blockDim.x) {\n    int offset = row + col * N;\n    if (A[offset] > 0) {\n      atomicAdd(&blockCounts[threadIdx.x], 1);\n    }\n  }\n  // Use a block-wide barrier to synchronize the block\n  __syncthreads();\n  // Compute the total number of edges in the matrix by using a parallel sum reduction\n  int sum = 0;\n  for (int i = 0; i < blockDim.x; i++) {\n    sum += blockCounts[i];\n  }\n  // Write the block's total to global memory\n  if (threadIdx.x == 0) {\n    atomicAdd(numEdges, sum);\n  }\n}",
            "size_t x = blockIdx.x * blockDim.x + threadIdx.x;\n  if (x < N) {\n    for (size_t y = 0; y < N; y++) {\n      if (x < N) {\n        if (A[x * N + y] == 1)\n          atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint count = 0;\n\n\t// Use AMD HIP to count the number of non-zero elements\n\t// Note: This is a serial operation.\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tcount += A[tid + i * N];\n\t}\n\n\t// Sum up the counts\n\t// Note: This is a serial operation.\n\tatomicAdd(numEdges, count);\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tint myEdges = 0;\n\tif (i < N) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[j + i*N] == 1) {\n\t\t\t\tmyEdges++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, myEdges);\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor (int i = tid; i < N; i += stride) {\n\t\tfor (int j = i; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (i!= tid && A[tid + N * i]) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "__shared__ int cache[256];\n\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i < N) {\n\t\tint localNumEdges = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i + j * N] == 1) {\n\t\t\t\tlocalNumEdges++;\n\t\t\t}\n\t\t}\n\n\t\t// Use first warp to do reduction\n\t\tint lane = threadIdx.x & 31;\n\t\tif (lane < 32) {\n\t\t\tcache[lane] = localNumEdges;\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor (int offset = 16; offset > 0; offset /= 2) {\n\t\t\tif (lane < offset) {\n\t\t\t\tcache[lane] += cache[lane + offset];\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\n\t\t// Store result to shared memory\n\t\tif (lane == 0) {\n\t\t\tcache[0] = cache[0] / 2;\n\t\t\tatomicAdd(numEdges, cache[0]);\n\t\t}\n\t}\n}",
            "int i = threadIdx.x;\n\tint stride = blockDim.x;\n\tint tid = i + blockIdx.x * blockDim.x;\n\tint count = 0;\n\n\tif (tid < N) {\n\t\tfor (int j = 0; j < N; j += stride) {\n\t\t\tif (i < N && j <= i) {\n\t\t\t\tif (A[i*N + j] || A[j*N + i]) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (i == 0) {\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "int myCount = 0;\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n  if (i < N) {\n    for (int j = 0; j < N; j++)\n      if (A[i * N + j])\n        myCount++;\n  }\n  atomicAdd(numEdges, myCount);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N) return;\n\tint n = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (i < j && A[i*N+j] == 1) n++;\n\t}\n\tatomicAdd(numEdges, n);\n}",
            "// Use atomicAdd to increment the counter numEdges.\n\t// This is the only way to write to the device memory from a kernel.\n\t// https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions\n\tatomicAdd(numEdges, __popc(A[blockIdx.x * N + blockIdx.x]));\n}",
            "// Thread index in block\n    int tid = hipThreadIdx_x;\n\n    // Number of threads in block\n    int nthreads = hipBlockDim_x;\n\n    // Number of threads in grid\n    int nblocks = hipGridDim_x;\n\n    // Block index\n    int bid = hipBlockIdx_x;\n\n    // Get the current vertex for the thread\n    int vertex = tid + bid*nthreads;\n\n    // We only want to do valid iterations of this loop\n    int end = N - nblocks*nthreads + bid*nthreads;\n\n    // The number of edges is 0 initially\n    int count = 0;\n\n    // Iterate over all edges in the adjacency matrix\n    for (int i = vertex; i < end; i += nthreads) {\n\n        // Iterate over the row of the vertex\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                count++;\n            }\n        }\n    }\n\n    // Atomically add the count from the thread to the shared memory\n    atomicAdd(numEdges, count);\n}",
            "int j, k;\n\tint nThreads = blockDim.x;\n\tint nBlocks = gridDim.x;\n\tint threadID = threadIdx.x;\n\tint blockID = blockIdx.x;\n\t__shared__ int rowCounts[BLOCK_SIZE];\n\n\tif (blockID == 0) {\n\t\t// block 0 finds the number of edges for a given row\n\t\trowCounts[threadID] = 0;\n\n\t\t// count all edges for this row\n\t\tfor (k = 0; k < N; ++k) {\n\t\t\trowCounts[threadID] += A[threadID*N+k];\n\t\t}\n\n\t\t// count all edges for the rest of the rows\n\t\tfor (j = 1; j < nBlocks; ++j) {\n\t\t\tif (threadID < nThreads) {\n\t\t\t\tfor (k = 0; k < N; ++k) {\n\t\t\t\t\trowCounts[threadID] += A[blockID*N+k];\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\n\t\t// sum all row counts\n\t\tint sum = 0;\n\t\tfor (j = 0; j < nThreads; ++j) {\n\t\t\tsum += rowCounts[j];\n\t\t}\n\t\t*numEdges = sum;\n\t} else {\n\t\t// find the number of edges for each row and store in the global mem\n\t\tfor (k = 0; k < N; ++k) {\n\t\t\tatomicAdd(numEdges, A[blockID*N+k]);\n\t\t}\n\t}\n}",
            "int idx = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tif (idx >= N)\n\t\treturn;\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[idx + N * i] == 1)\n\t\t\tcount++;\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint lane = threadIdx.x & (WARP_SIZE - 1);\n\tint warpId = tid / WARP_SIZE;\n\n\tint sum = 0;\n\tif (tid < N) {\n\t\tfor (int i = lane; i < N; i += WARP_SIZE) {\n\t\t\tsum += A[tid * N + i];\n\t\t}\n\t}\n\n\tsum = warpReduce(sum);\n\n\tif (lane == 0) {\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "int sum = 0;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (col < N) {\n        for (int i = 0; i < N; i++) {\n            sum += A[i * N + col];\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int tid = threadIdx.x;\n  extern __shared__ int sData[];\n  int sum = 0;\n  for (int i = tid; i < N; i += blockDim.x) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        sum += 1;\n      }\n    }\n  }\n\n  sData[tid] = sum;\n  __syncthreads();\n  int halfN = N / 2;\n  int step = blockDim.x;\n\n  while (step > 0) {\n    if (tid < step) {\n      sData[tid] += sData[tid + step];\n    }\n    __syncthreads();\n    step = step / 2;\n  }\n\n  if (tid == 0) {\n    *numEdges = sData[0];\n  }\n}",
            "// thread index in global (flat) array\n\tint idx = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// global (flat) array index\n\tint a = idx / N;\n\tint b = idx % N;\n\n\tif(a!= b && A[idx]!= 0) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "__shared__ int sdata[BLOCKSIZE];\n  // The row to be processed by the current thread\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int count = 0;\n\n  if (row < N) {\n    for (int col = 0; col < N; col++) {\n      // If there is an edge between the current row and the current column,\n      // then the current thread increments the counter.\n      if (A[row * N + col]!= 0) {\n        count++;\n      }\n    }\n    sdata[threadIdx.x] = count;\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n      // The first thread in the block writes the result to global memory\n      atomicAdd(numEdges, sdata[0]);\n    }\n  }\n}",
            "// This value is not thread safe (i.e. if two threads execute this line at the same time,\n\t// they will both get a pointer to the same memory location), but since the array is\n\t// filled in by one thread, we are not modifying it here, so it is thread safe.\n\tint *myNumEdges = numEdges + blockIdx.x;\n\n\t// Count the number of non-zero elements in this row\n\tint myEdges = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tmyEdges += A[blockIdx.x * N + i];\n\t}\n\n\t// Store the result\n\t*myNumEdges = myEdges;\n}",
            "int i = threadIdx.x;\n    int j = blockIdx.x;\n\n    int sum = 0;\n\n    if (A[i + j * N] == 1) {\n        atomicAdd(numEdges, 1);\n    }\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n\tint start = id * N;\n\tint end = start + N;\n\tint count = 0;\n\n\tfor (int i = start; i < end; ++i)\n\t\tif (A[i])\n\t\t\t++count;\n\n\tatomicAdd(numEdges, count);\n}",
            "int j, i = blockDim.x * blockIdx.x + threadIdx.x;\n  int *count = &(numEdges[i]);\n\n  if (i < N) {\n    for (j = 0; j < N; j++)\n      *count += A[i * N + j];\n  }\n}",
            "const int tid = threadIdx.x;\n\tint sum = 0;\n\tint i = blockIdx.x*blockDim.x + tid;\n\n\twhile(i<N*N) {\n\t\tif(A[i]!= 0) {\n\t\t\tsum++;\n\t\t}\n\t\ti+=gridDim.x*blockDim.x;\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "int *local_numEdges = (int *)malloc(sizeof(int));\n  *local_numEdges = 0;\n\n  int local_id = hipThreadIdx_x + hipBlockIdx_x * hipBlockDim_x;\n  int global_id = hipThreadIdx_x + hipBlockIdx_x * hipBlockDim_x;\n  int nthreads = hipBlockDim_x * hipGridDim_x;\n\n  // Loop over the rows of A\n  for (int i = 0; i < N; ++i) {\n    // Loop over the columns of A\n    for (int j = 0; j < N; ++j) {\n      // For the element A[i,j], check if it's a 1.\n      if (A[i * N + j] == 1) {\n        // If so, increment the local number of edges.\n        atomicAdd(local_numEdges, 1);\n        // If the edge count is odd, then there is an odd cycle.\n        if (*local_numEdges % 2 == 1) {\n          // Set the global number of edges to be odd\n          atomicAdd(numEdges, 1);\n          // We found an odd cycle.\n          return;\n        }\n      }\n    }\n  }\n  // We have found an even number of edges.\n  atomicAdd(numEdges, 0);\n}",
            "// TODO: Replace this with your code\n\t*numEdges = 0;\n}",
            "// Implement this kernel\n}",
            "size_t i = threadIdx.x;\n\tsize_t j = threadIdx.y;\n\n\tif (A[i + j * N]!= 0) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "int sum = 0;\n\tint tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tfor (int i = tid; i < N * N; i += blockDim.x * gridDim.x) {\n\t\tsum += A[i];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "// Compute the index in the array\n    size_t i = (blockIdx.x * blockDim.x) + threadIdx.x;\n    // Compute the row\n    int row = i / N;\n    // Compute the column\n    int col = i % N;\n\n    if (i < N * N) {\n        // Count the number of edges\n        if (A[i]!= 0) {\n            atomicAdd(numEdges, 1);\n        }\n    }\n}",
            "__shared__ int sum[BLOCK_SIZE];\n\n\tsum[threadIdx.x] = 0;\n\tfor (int i = threadIdx.x; i < N * N; i += blockDim.x) {\n\t\tsum[threadIdx.x] += A[i];\n\t}\n\n\t// sum\n\tint index = threadIdx.x;\n\tint step = blockDim.x / 2;\n\n\twhile (step!= 0) {\n\t\tif (index < step) {\n\t\t\tsum[index] += sum[index + step];\n\t\t}\n\n\t\t// Synchronize within a warp\n\t\t__syncthreads();\n\n\t\t// Move to the next level of the reduction tree\n\t\tstep /= 2;\n\t}\n\n\t// sum[0] contains the result\n\tif (threadIdx.x == 0) {\n\t\t*numEdges = sum[0];\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        int sum = 0;\n        int j = tid;\n        for (int i = 0; i < N; i++) {\n            if (A[i * N + j]) {\n                sum++;\n            }\n        }\n        *numEdges += sum;\n    }\n}",
            "// Implementation here\n}",
            "__shared__ int localSum;\n  localSum = 0;\n  for (size_t i = threadIdx.x; i < N; i += blockDim.x) {\n    if (A[blockIdx.x*N+i] + A[i*N+blockIdx.x] > 0) {\n      localSum++;\n    }\n  }\n  atomicAdd(numEdges, localSum);\n}",
            "int tId = blockDim.x*blockIdx.x+threadIdx.x;\n\tint start = tId*N;\n\tint end = (tId+1)*N;\n\tint count = 0;\n\tfor (int i = start; i < end; i++) {\n\t\tcount += A[i];\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int row = blockIdx.x;\n    int col = threadIdx.x;\n    int idx = row * N + col;\n    int num_edges = 0;\n    int num_threads = N;\n\n    // Calculate the number of edges\n    if (col < N && A[idx]!= 0) {\n        num_edges++;\n    }\n\n    __shared__ int edge_counts[THREADS_PER_BLOCK];\n    edge_counts[threadIdx.x] = num_edges;\n    __syncthreads();\n\n    // Reduce across threads in a warp\n    if (threadIdx.x < 16) {\n        edge_counts[threadIdx.x] += edge_counts[threadIdx.x + 16];\n    }\n    if (threadIdx.x < 8) {\n        edge_counts[threadIdx.x] += edge_counts[threadIdx.x + 8];\n    }\n    if (threadIdx.x < 4) {\n        edge_counts[threadIdx.x] += edge_counts[threadIdx.x + 4];\n    }\n    if (threadIdx.x < 2) {\n        edge_counts[threadIdx.x] += edge_counts[threadIdx.x + 2];\n    }\n    if (threadIdx.x < 1) {\n        edge_counts[threadIdx.x] += edge_counts[threadIdx.x + 1];\n    }\n\n    // Write result for this block to global mem\n    if (threadIdx.x == 0) {\n        atomicAdd(numEdges, edge_counts[0]);\n    }\n}",
            "// TODO: your code here\n}",
            "int tID = blockDim.x * blockIdx.x + threadIdx.x;\n  int tid = tID;\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (tID == 0) {\n        if (A[i * N + j] == 1)\n          count++;\n      }\n      tID += gridDim.x * blockDim.x;\n    }\n  }\n\n  // Use atomics to prevent race conditions when incrementing numEdges\n  atomicAdd(numEdges, count);\n}",
            "const int gid = blockIdx.x*blockDim.x+threadIdx.x;\n\n    if (gid >= N)\n        return;\n\n    int count = 0;\n    for (int j = 0; j < N; j++) {\n        count += A[N*gid + j];\n    }\n\n    atomicAdd(numEdges, count);\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  if (tid < N) {\n    int numEdgesLocal = 0;\n    for (size_t i = 0; i < N; ++i) {\n      if (A[tid + i*N] > 0) ++numEdgesLocal;\n    }\n    atomicAdd(numEdges, numEdgesLocal);\n  }\n}",
            "int sum = 0;\n  for (int i = 0; i < N * N; i++) {\n    if (A[i]) {\n      sum++;\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "__shared__ int sdata[BLOCK_DIM];\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int threadNumEdges = 0;\n  if (tid < N) {\n    for (int i = 0; i < N; i++) {\n      if (i!= tid) {\n        threadNumEdges += A[tid + i * N];\n      }\n    }\n  }\n  sdata[threadIdx.x] = threadNumEdges;\n  __syncthreads();\n  for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      sdata[threadIdx.x] += sdata[threadIdx.x + s];\n    }\n    __syncthreads();\n  }\n  if (threadIdx.x == 0) {\n    atomicAdd(numEdges, sdata[0]);\n  }\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (i >= N) {\n\t\treturn;\n\t}\n\tint count = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[j * N + i]!= 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int total = 0;\n  int *row = A + N * blockIdx.x;\n  for (int i = 0; i < N; i++) {\n    total += row[i];\n  }\n  *numEdges = total;\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n  int col = blockDim.y * blockIdx.y + threadIdx.y;\n  if (row < N && col < N) {\n    if (A[row * N + col] == 1) {\n      atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "int id = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n    if (id < N) {\n        for (int i = 0; i < N; i++) {\n            if (A[N * id + i] == 1) {\n                atomicAdd(numEdges, 1);\n            }\n        }\n    }\n}",
            "int threadIdx = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (threadIdx >= N) return;\n\n\tint rowIdx = threadIdx;\n\tint i;\n\tint sum = 0;\n\tfor (i=0; i<N; i++) {\n\t\tsum += A[i*N+rowIdx];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = i;\n    int count = 0;\n    if (i < N) {\n        for (j = 0; j < N; j++) {\n            if (A[i*N + j] > 0) {\n                count++;\n            }\n        }\n        numEdges[i] = count;\n    }\n}",
            "__shared__ int sharedSum[512];\n\n\tint tid = threadIdx.x;\n\tint bid = blockIdx.x;\n\n\tint sum = 0;\n\n\t// Each thread computes the sum of the elements in a row of A.\n\tfor (int i = bid * 512 + tid; i < N; i += 512 * gridDim.x) {\n\t\tsum += A[i];\n\t}\n\n\t// Sum the partial sums per thread in the block.\n\tfor (unsigned int stride = 256; stride > 0; stride >>= 1) {\n\t\t__syncthreads();\n\t\tif (tid < stride)\n\t\t\tsharedSum[tid] += sharedSum[tid + stride];\n\t}\n\n\t// The partial sum is in sharedSum[0].\n\t// Every thread in the block writes to the corresponding location in\n\t// numEdges\n\tif (tid == 0)\n\t\tnumEdges[bid] = sharedSum[0];\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    int sum = 0;\n    for (int i = idx; i < N * N; i += stride) {\n        sum += A[i];\n    }\n    atomicAdd(numEdges, sum);\n}",
            "// compute id of this thread\n  unsigned int id = threadIdx.x + blockIdx.x*blockDim.x;\n  unsigned int i;\n  unsigned int j;\n  // compute edges\n  for (i = 0; i < N; ++i) {\n    for (j = i+1; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "// Get a handle to the AMD HIP accelerator\n\tconst int gpuDeviceId = 0;\n\tamd::host_device_vector<int> dev_A(N*N, gpuDeviceId);\n\tdev_A.data()[threadIdx.x] = A[threadIdx.x];\n\n\t// Compute edgeCount for each row of the adjacency matrix\n\tint rowCount = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\t// Only one thread per row.\n\t\t// If threadIdx.x!= i, skip.\n\t\tif(threadIdx.x!= i) continue;\n\t\t// Otherwise, compute edgeCount.\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\trowCount += dev_A.data()[i*N + j];\n\t\t}\n\t}\n\n\t// Reduce the rowsCount vector, using atomicAdd\n\t// to get the final sum.\n\tint *d_rowsCount = dev_A.data();\n\tint sum = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tsum += d_rowsCount[i];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int t_id = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = gridDim.x * blockDim.x;\n\n\tint count = 0;\n\tfor (int i = t_id; i < N; i += stride) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, count);\n}",
            "unsigned tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid >= N) return;\n\n  int n = 0;\n  for (int j = 0; j < N; ++j) {\n    if (A[tid * N + j] == 1) n++;\n  }\n  numEdges[tid] = n;\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int cnt = 0;\n  for (int i = tid; i < N; i += blockDim.x * gridDim.x) {\n    for (int j = 0; j < N; j++) {\n      cnt += A[i * N + j];\n    }\n  }\n  atomicAdd(numEdges, cnt);\n}",
            "// TODO\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) return;\n  for (int j = i + 1; j < N; ++j) {\n    if (A[i * N + j]!= 0) atomicAdd(numEdges, 1);\n  }\n}",
            "// Get the thread index\n  int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Use the thread index to access the adjacency matrix.\n  // If A[index] is 1, the corresponding matrix element is 1.\n  // If A[index] is 0, the corresponding matrix element is 0.\n  if (A[index] == 1) {\n    atomicAdd(numEdges, 1);\n  }\n}",
            "// TODO:\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < N) {\n        int sum = 0;\n        for (int col = 0; col < N; col++) {\n            if (A[row + col * N])\n                sum++;\n        }\n        if (sum) {\n            atomicAdd(numEdges, sum);\n        }\n    }\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint threadNumEdges = 0;\n\t\tint rowStart = tid * N;\n\t\tfor (int i = rowStart; i < rowStart + N; i++) {\n\t\t\tif (A[i] == 1) {\n\t\t\t\tthreadNumEdges++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, threadNumEdges);\n\t}\n}",
            "// Initialize to zero\n  *numEdges = 0;\n\n  int myId = blockIdx.x * blockDim.x + threadIdx.x;\n  if (myId < N) {\n    int row = myId;\n    for (int col = 0; col < N; col++) {\n      if (A[row*N + col]!= 0) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "int edgeCount = 0;\n  const int TID = threadIdx.x + blockIdx.x * blockDim.x;\n  const int stride = blockDim.x * gridDim.x;\n  for (int i = TID; i < N; i += stride) {\n    for (int j = 0; j < N; ++j) {\n      if (i < N && j < N) {\n        if (A[i * N + j] == 1) {\n          ++edgeCount;\n        }\n      }\n    }\n  }\n  *numEdges = edgeCount;\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (index >= N * N)\n\t\treturn;\n\tint i = index / N, j = index % N;\n\tif (A[i * N + j] == 1)\n\t\tatomicAdd(numEdges, 1);\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "mpi",
        "prompt": "#include <mpi.h>\n\n/* Count the number of edges in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "MPI_Request request;\n  int sendrank, recvrank;\n  MPI_Status status;\n  int edgecount = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        edgecount++;\n      }\n    }\n  }\n  return edgecount;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    /*... */\n}",
            "int worldSize;\n\tint worldRank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &worldSize);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &worldRank);\n\n\tint* localResult = new int[worldSize];\n\tlocalResult[worldRank] = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tlocalResult[worldRank]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint* globalResult = new int[worldSize];\n\tMPI_Allgather(localResult, 1, MPI_INT, globalResult, 1, MPI_INT, MPI_COMM_WORLD);\n\n\tif (worldRank == 0) {\n\t\tint result = 0;\n\t\tfor (int i = 0; i < worldSize; i++) {\n\t\t\tresult += globalResult[i];\n\t\t}\n\t\treturn result;\n\t}\n\telse {\n\t\treturn 0;\n\t}\n}",
            "// YOUR CODE HERE\n    int count = 0;\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int start = rank * (int)N / size;\n    int end = (rank + 1) * (int)N / size;\n\n    for (size_t i = start; i < end; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j]!= 0)\n                ++count;\n        }\n    }\n\n    std::vector<int> recvbuf(size);\n    MPI_Allgather(&count, 1, MPI_INT, recvbuf.data(), 1, MPI_INT, MPI_COMM_WORLD);\n    int sum = 0;\n    for (int val : recvbuf) {\n        sum += val;\n    }\n    return sum;\n}",
            "int rank, p, size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int* result = (int*)malloc(size*sizeof(int));\n\n  int num_edges = 0;\n  int count = 0;\n\n  // for each row\n  for (int i = rank; i < N; i+=size) {\n\n    // for each column\n    for (int j = 0; j < N; j++) {\n\n      // if the element is a 1\n      if (A[i*N + j] == 1) {\n\n        // increment the number of edges\n        num_edges++;\n\n        // count number of edges in each row\n        count++;\n      }\n    }\n  }\n\n  // send row counts to rank 0\n  MPI_Gather(&count, 1, MPI_INT, result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // sum the row counts\n  if (rank == 0) {\n    num_edges = 0;\n    for (int i = 0; i < size; i++) {\n      num_edges += result[i];\n    }\n  }\n\n  // cleanup\n  free(result);\n\n  return num_edges;\n}",
            "int sum = 0;\n    int n = N;\n    int my_rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Status stat;\n\n    for (int i = my_rank; i < N; i += N){\n        int i2 = i + 1;\n        while (i2 < N){\n            for (int j = 0; j < N; j++){\n                if (A[i * N + j] == 1 && A[i2 * N + j] == 1){\n                    sum++;\n                }\n            }\n            i2++;\n        }\n    }\n\n    // sum up results\n    int local_sum;\n    MPI_Reduce(&sum, &local_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return local_sum;\n}",
            "int n = A.size();\n    int local_count = 0;\n    for(int i = 0; i < n; i++)\n    {\n        for(int j = 0; j < n; j++)\n        {\n            if(A[i * n + j])\n            {\n                local_count++;\n            }\n        }\n    }\n\n    int global_count = 0;\n    MPI_Allreduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n    return global_count;\n}",
            "/* YOUR CODE HERE */\n    int m = N*N;\n    int count = 0;\n    for(int i = 0; i < N; ++i){\n        for(int j = 0; j < N; ++j){\n            if(A[i*N + j] > 0){\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "// TODO: your code here\n    int c = 0;\n    int rank = 0;\n    int size = 0;\n    int myrow = 0;\n    int mycol = 0;\n    int globalcol = 0;\n    int mystart = 0;\n    int myend = 0;\n    int globalstart = 0;\n    int globalend = 0;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    myrow = rank;\n    mycol = 0;\n    globalcol = 0;\n    mystart = myrow * N;\n    myend = mystart + N;\n    globalstart = 0;\n    globalend = N;\n\n    // MPI_Type_vector(int count, int blocklength, int stride, MPI_Datatype oldtype, MPI_Datatype *newtype);\n    // MPI_Type_commit(MPI_Datatype *type);\n    // MPI_Type_free(MPI_Datatype *type);\n\n    MPI_Datatype vec_t;\n\n    MPI_Type_vector(N, 1, N, MPI_INT, &vec_t);\n    MPI_Type_commit(&vec_t);\n\n    std::vector<int> myvec(N);\n\n    MPI_Scatter(&A[0], 1, vec_t, &myvec[0], 1, vec_t, 0, MPI_COMM_WORLD);\n\n    int i = 0;\n    for (i = 0; i < N; i++) {\n        c += myvec[i];\n    }\n\n    MPI_Reduce(&c, &c, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        c = c/2;\n    }\n\n    MPI_Type_free(&vec_t);\n\n    return c;\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // TODO: use MPI to sum up the number of edges.\n\n  return 0;\n}",
            "int sum = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        sum++;\n      }\n    }\n  }\n  return sum;\n}",
            "int myCount = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tmyCount += (A[i*N + j] > 0) + (A[j*N + i] > 0);\n\t\t}\n\t}\n\treturn myCount;\n}",
            "int edges = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i+1; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                ++edges;\n            }\n        }\n    }\n    return edges;\n}",
            "int my_rank, p;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tint n = N / p;\n\n\tint *arr = new int[n * n];\n\n\tMPI_Scatter(&A[0], n * n, MPI_INT, arr, n * n, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint my_edges = 0;\n\tfor (int i = 0; i < n; ++i)\n\t\tfor (int j = 0; j < n; ++j)\n\t\t\tif (arr[i * n + j]!= 0)\n\t\t\t\tmy_edges++;\n\n\tint *my_edges_arr = new int[p];\n\tmy_edges_arr[my_rank] = my_edges;\n\tMPI_Gather(my_edges_arr, 1, MPI_INT, my_edges_arr, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint result = 0;\n\tif (my_rank == 0)\n\t\tfor (int i = 0; i < p; ++i)\n\t\t\tresult += my_edges_arr[i];\n\n\tdelete[] arr;\n\tdelete[] my_edges_arr;\n\n\treturn result;\n}",
            "// TODO:\n\t//   1. Create a local counter and initialize to zero\n\t//   2. Loop over A[i][j] for i = 0..N-1, j = i..N-1, add one to the counter for each 1 element in A\n\t//   3. Use MPI_Reduce to sum the local counter across all MPI ranks into the global counter\n\t//   4. Return the global counter\n\n\tint counter = 0;\n\tint local_counter = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tlocal_counter += 1;\n\t\t}\n\t}\n\n\tMPI_Reduce(&local_counter, &counter, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn counter;\n}",
            "int mySum = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < i; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++mySum;\n\t\t\t}\n\t\t}\n\t}\n\tint totalSum = 0;\n\tMPI_Reduce(&mySum, &totalSum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn totalSum;\n}",
            "// Add your code here\n}",
            "int rank = -1, size = -1;\n  int result = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // your code here\n  int num_elements = N * N;\n  int my_num_elements = num_elements / size;\n  int my_start = rank * my_num_elements;\n  int my_end = my_start + my_num_elements;\n  int temp = 0;\n  for (int i = my_start; i < my_end; i++) {\n    if (A[i] == 1) {\n      temp++;\n    }\n  }\n\n  // reduction\n  MPI_Reduce(&temp, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return result;\n}",
            "int sum = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            sum += (A[i * N + j] + A[j * N + i]);\n        }\n    }\n    return sum;\n}",
            "// Compute the result on rank 0.\n  if (N == 0) return 0;\n  if (N == 1) return A[0];\n\n  // Compute the result on rank 0.\n  if (N == 2) {\n    int result = 0;\n    if (A[0] == 1) ++result;\n    if (A[1] == 1) ++result;\n    if (A[2] == 1) ++result;\n    if (A[3] == 1) ++result;\n    return result;\n  }\n\n  // Send the first half of the matrix to rank 1.\n  MPI_Send(A.data(), N / 2, MPI_INT, 1, 0, MPI_COMM_WORLD);\n\n  // Compute the first half of the result on rank 0.\n  int firstHalf = edgeCount(A, N / 2);\n\n  // Recieve the second half of the matrix from rank 1.\n  std::vector<int> secondHalf(N / 2);\n  MPI_Recv(secondHalf.data(), N / 2, MPI_INT, 1, 0, MPI_COMM_WORLD,\n           MPI_STATUS_IGNORE);\n\n  // Compute the second half of the result on rank 0.\n  int secondHalfCount = edgeCount(secondHalf, N / 2);\n\n  // Compute the result on rank 0.\n  return firstHalf + secondHalfCount;\n}",
            "if (A.size()!= N * N) {\n    return 0;\n  }\n\n  int sum = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j && A[i * N + j] == 1) {\n        sum++;\n      }\n    }\n  }\n  return sum;\n}",
            "// TODO: your code here\n    int edges = 0;\n    for (size_t i = 0; i < N; i++){\n        for (size_t j = 0; j < N; j++){\n            if (A[i * N + j]!= 0 && i!= j)\n                edges += 1;\n        }\n    }\n    return edges;\n}",
            "int rank, numranks;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numranks);\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint count_total;\n\tif (numranks > 1) {\n\t\tint sendcount = count;\n\t\tMPI_Reduce(&sendcount, &count_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tcount_total = count;\n\t}\n\n\treturn count_total;\n}",
            "int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int result = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[i * N + j] == 1)\n                result++;\n        }\n    }\n\n    int all_results;\n    MPI_Reduce(&result, &all_results, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return all_results;\n}",
            "/*\n\t\tYour code goes here.\n\n\t\tYou should first find how many edges are in the subgraph on rank 0.\n\t\tThen use MPI_Reduce to find how many edges are in the subgraph across all ranks.\n\t*/\n    return 0;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int num_edges = 0;\n\n    /*\n      BEGIN_YOUR_CODE\n    */\n    num_edges = 0;\n\n    for (int i = 0; i < N; i++) {\n        for (int j = i; j < N; j++) {\n            if (A[i * N + j]) {\n                num_edges++;\n            }\n        }\n    }\n\n    /*\n      END_YOUR_CODE\n    */\n\n    return num_edges;\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n  int rank, size;\n  MPI_Comm_rank(comm, &rank);\n  MPI_Comm_size(comm, &size);\n\n  const int count = static_cast<int>(A.size());\n  const int count_per_proc = count / size;\n\n  int edges = 0;\n\n  // The following is your task.\n  // You may need to use MPI_Send and MPI_Recv to communicate.\n  // You may need to use MPI_Scatter and MPI_Gather to distribute and collect data.\n\n  return edges;\n}",
            "return 0;\n}",
            "// TODO: implement\n}",
            "int edges = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edges;\n}",
            "int mpi_rank;\n\tint mpi_size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\n\tint count = 0;\n\tif (mpi_rank == 0) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = i; j < N; j++) {\n\t\t\t\tcount += A[N * i + j];\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor (size_t i = mpi_rank; i < N; i += mpi_size) {\n\t\t\tfor (size_t j = i; j < N; j++) {\n\t\t\t\tcount += A[N * i + j];\n\t\t\t}\n\t\t}\n\t}\n\n\tint all_count;\n\tMPI_Reduce(&count, &all_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn all_count;\n}",
            "int numEdges = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\treturn numEdges;\n}",
            "// YOUR CODE HERE\n  return 0;\n}",
            "// Your code goes here!\n}",
            "int rc = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j])\n        ++rc;\n    }\n  }\n  return rc;\n}",
            "// TODO: implement\n  return 0;\n}",
            "int n_count = 0;\n    // TODO: Fill this in\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++n_count;\n            }\n        }\n    }\n    return n_count;\n}",
            "int result = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i + 1; j < N; ++j) {\n\t\t\tresult += A[i * N + j];\n\t\t}\n\t}\n\treturn result;\n}",
            "/* YOUR CODE HERE */\n    return 0;\n}",
            "}",
            "int sum = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i == j) {\n                continue;\n            }\n\n            sum += A[N * i + j];\n        }\n    }\n\n    return sum;\n}",
            "if (N == 0) {\n        throw \"Invalid N\";\n    }\n\n    int local_sum = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            if (A[i * N + j]) {\n                ++local_sum;\n            }\n        }\n    }\n\n    int sum = 0;\n    MPI_Reduce(&local_sum, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return sum;\n}",
            "int result = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[N * i + j]!= 0) {\n\t\t\t\tresult += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int rank;\n\tint size;\n\tint sum = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint* localSum = new int[N];\n\tfor(size_t i = 0; i < N; i++){\n\t\tlocalSum[i] = 0;\n\t\tfor(size_t j = 0; j < N; j++){\n\t\t\tif(i!= j && A[i*N + j] == 1){\n\t\t\t\tlocalSum[i]++;\n\t\t\t}\n\t\t}\n\t}\n\tint* globalSum = new int[N];\n\tif(rank == 0){\n\t\tfor(size_t i = 1; i < size; i++){\n\t\t\tMPI_Recv(&globalSum, N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tfor(size_t j = 0; j < N; j++){\n\t\t\t\tsum += globalSum[j];\n\t\t\t}\n\t\t}\n\t} else {\n\t\tMPI_Send(&localSum, N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\tdelete[] localSum;\n\tdelete[] globalSum;\n\treturn sum;\n}",
            "/* YOUR CODE HERE */\n}",
            "int num_local_edges = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = i; j < N; j++) {\n      if (i == j) {\n        continue;\n      }\n      num_local_edges += (A[i * N + j] == 1);\n    }\n  }\n  // Sum over all ranks.\n  int global_num_edges;\n  MPI_Reduce(&num_local_edges, &global_num_edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  // Only rank 0 returns the result.\n  if (MPI_COMM_WORLD->rank!= 0) {\n    global_num_edges = 0;\n  }\n  return global_num_edges;\n}",
            "int rank = 0;\n\tint size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint sizeRow = N / size;\n\tint rest = N % size;\n\n\tint result = 0;\n\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tresult += countEdges(A, i, 0, sizeRow, 0, 0);\n\t\t}\n\t}\n\telse {\n\t\tfor (int i = (rank - 1) * sizeRow; i < rank * sizeRow; ++i) {\n\t\t\tresult += countEdges(A, i, 0, sizeRow, 0, 0);\n\t\t}\n\t}\n\n\tif (rest!= 0) {\n\t\tfor (int i = 0; i < rest; ++i) {\n\t\t\tresult += countEdges(A, i + size * sizeRow, 0, sizeRow, 0, 0);\n\t\t}\n\t}\n\n\tint final = 0;\n\tMPI_Reduce(&result, &final, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn final;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i*N+j] > 0) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "// Implement this function!\n  return -1;\n}",
            "int rank, size, count;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  count = 0;\n  for (size_t i = rank; i < N; i += size) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        count += 1;\n      }\n    }\n  }\n  if (rank == 0) {\n    int allCount[size];\n    for (int i = 0; i < size; ++i) {\n      MPI_Recv(&allCount[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n    for (int i = 0; i < size; ++i) {\n      count += allCount[i];\n    }\n  } else {\n    MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  return count;\n}",
            "// Replace this with your code\n  int n_edges = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        n_edges++;\n      }\n    }\n  }\n  return n_edges;\n}",
            "// TODO: implement this\n  return 0;\n}",
            "// TODO: implement\n    return 0;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int n = static_cast<int>(N);\n  // Count the edges on this rank\n  int edgeCount = 0;\n  for (int r = 0; r < n; ++r) {\n    for (int c = 0; c < n; ++c) {\n      if (r!= c && A[r * n + c]) {\n        ++edgeCount;\n      }\n    }\n  }\n  // Aggregate the counts\n  int counts[size];\n  counts[rank] = edgeCount;\n  MPI_Allgather(MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, counts, 1, MPI_INT,\n                MPI_COMM_WORLD);\n  // Sum the counts\n  int result = 0;\n  for (int i = 0; i < size; ++i) {\n    result += counts[i];\n  }\n  return result;\n}",
            "// Your code here\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i; j < N; j++) {\n      if (A[i*N + j]!= 0) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // calculate number of blocks\n  int nBlock = N / size;\n\n  // calculate number of extra blocks\n  int nExtra = N % size;\n\n  // number of elements to be sent to the next rank\n  int nSend = nBlock;\n\n  // number of elements to be received from the previous rank\n  int nRecv;\n  if (rank < N % size)\n    nRecv = nBlock + 1;\n  else\n    nRecv = nBlock;\n\n  int start = rank * nBlock;\n  int end = start + nSend;\n\n  // send and recieve buffers\n  std::vector<int> sendBuf(nSend);\n  std::vector<int> recvBuf(nRecv);\n\n  // loop to count edges\n  int sum = 0;\n  for (int i = 0; i < nSend; i++) {\n    for (int j = 0; j < nSend; j++) {\n      if (i!= j) {\n        sum += A[start + i] * A[start + j];\n      }\n    }\n  }\n\n  // MPI operations\n  MPI_Send(sendBuf.data(), nSend, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);\n  MPI_Recv(recvBuf.data(), nRecv, MPI_INT, rank - 1, 0, MPI_COMM_WORLD,\n           MPI_STATUS_IGNORE);\n\n  int result;\n  if (rank == 0) {\n    result = 0;\n    for (int i = 0; i < nRecv; i++) {\n      for (int j = 0; j < nSend; j++) {\n        if (i!= j) {\n          result += A[i] * A[j];\n        }\n      }\n    }\n  }\n  MPI_Reduce(&sum, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // Your code here...\n}",
            "std::vector<int> localResult(N * N, 0);\n    for (int i = 0; i < N; ++i) {\n        for (int j = i + 1; j < N; ++j) {\n            if (A[i * N + j] > 0) {\n                localResult[i * N + j] = 1;\n            }\n        }\n    }\n    int localCount = 0;\n    for (int i = 0; i < N * N; ++i) {\n        localCount += localResult[i];\n    }\n\n    // TODO: Your code here\n    int worldCount;\n    MPI_Reduce(&localCount, &worldCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (worldRank == 0) {\n        return worldCount;\n    } else {\n        return 0;\n    }\n}",
            "int r = 0; // the result\n  for (int i = 0; i < N; ++i) {\n    for (int j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        // increment result by 1\n        //\n        //  - If you do not have a good understanding of how MPI works,\n        //    replace this line with r += 1;\n        //\n        //  - If you understand how MPI works, this line will be easy to\n        //    understand.\n        //\n        //  - If you know more about MPI, there is an even better way to\n        //    implement this program, and we will talk about that in the next\n        //    tutorial.\n        //\n        //  - If you are a C++ expert, you might recognize this line as a\n        //    common idiom for parallel computing.\n        MPI_ADD(&r, &r, 1, MPI_INT, MPI_COMM_WORLD);\n      }\n    }\n  }\n\n  // collect result\n  MPI_Gather(&r, 1, MPI_INT, &r, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return r;\n}",
            "// TODO: compute the number of edges in the graph defined by the\n\t// adjacency matrix A.\n\n\treturn 0;\n}",
            "if (A.size()!= N * N) {\n    throw std::invalid_argument(\"Size mismatch\");\n  }\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  size_t row_begin = rank * N / size;\n  size_t row_end = (rank + 1) * N / size;\n  int count = 0;\n  for (size_t i = row_begin; i < row_end; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[i * N + j] || A[j * N + i]) {\n        ++count;\n      }\n    }\n  }\n  int total_count;\n  MPI_Reduce(&count, &total_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return total_count;\n}",
            "// TODO\n\tint edges = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i < j and A[i * N + j] == 1) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edges;\n}",
            "int count = 0;\n  int myRank;\n  int numProcs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\n  // TODO: Add code here\n\n  return count;\n}",
            "return 0;\n}",
            "int numEdge = 0;\n  for (size_t i = 0; i < N; i++)\n    for (size_t j = 0; j < N; j++)\n      if (i!= j && A[i * N + j]) numEdge++;\n  return numEdge;\n}",
            "// your code here\n  return 0;\n}",
            "if (N == 0) {\n    return 0;\n  }\n\n  int result;\n  int left;\n  int right;\n\n  // TODO\n\n  return result;\n}",
            "// TODO: Implement this\n\n\treturn 0;\n}",
            "int edges = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn edges;\n}",
            "int numEdges{0};\n\tint *B = new int[N*N];\n\tMPI_Bcast(&A[0], N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\tfor (int i=0; i<N; i++){\n\t\tfor (int j=0; j<N; j++){\n\t\t\tif (j>i)\n\t\t\t\tB[i*N+j] = B[j*N+i];\n\t\t\telse\n\t\t\t\tB[i*N+j] = A[i*N+j];\n\t\t}\n\t}\n\tfor (int i=0; i<N; i++){\n\t\tfor (int j=0; j<N; j++){\n\t\t\tif (B[i*N+j])\n\t\t\t\tnumEdges++;\n\t\t}\n\t}\n\tdelete[] B;\n\treturn numEdges;\n}",
            "// TODO\n}",
            "int num_procs;\n  int proc_num;\n  int i;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &proc_num);\n  int part_size = A.size() / num_procs;\n\n  int edges = 0;\n  for (i = proc_num * part_size; i < (proc_num + 1) * part_size; i++) {\n    if (A[i]) edges++;\n  }\n\n  int total = 0;\n  MPI_Reduce(&edges, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  if (proc_num == 0)\n    return total;\n  else\n    return 0;\n}",
            "int mpi_result = 0;\n\tint local_result = 0;\n\tint recv_count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1 && i < j) {\n\t\t\t\tlocal_result++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&local_result, &mpi_result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn mpi_result;\n}",
            "int worldSize;\n    int worldRank;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &worldSize);\n    MPI_Comm_rank(MPI_COMM_WORLD, &worldRank);\n\n    int total = 0;\n\n    int *send = new int[N];\n    int *recv = new int[N];\n\n    if (worldRank == 0) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (A[i * N + j] == 1) {\n                    send[i]++;\n                }\n            }\n        }\n    }\n\n    MPI_Bcast(send, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    for (int i = 0; i < N; ++i) {\n        total += send[i];\n    }\n\n    return total;\n}",
            "// Your code here\n    int sum = 0;\n    for (int i = 0; i < N; i++)\n    {\n        for (int j = i + 1; j < N; j++)\n        {\n            if (A[i * N + j] == 1 || A[j * N + i] == 1)\n            {\n                sum++;\n            }\n        }\n    }\n    return sum;\n}",
            "int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  if (N % size) {\n    if (rank == 0) {\n      std::cerr << \"Warning: N not divisible by number of ranks. Ignoring excess rows.\" << std::endl;\n    }\n    N = N - N % size;\n  }\n\n  int sum = 0;\n  if (rank == 0) {\n    std::vector<int> A_padded(N * N, 0);\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        A_padded[i * N + j] = A[i * N + j];\n      }\n    }\n    A = A_padded;\n  }\n\n  MPI_Bcast(&N, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  int start = rank * N / size;\n  int end = (rank + 1) * N / size;\n\n  for (int i = start; i < end; ++i) {\n    for (int j = start; j < end; ++j) {\n      if (i!= j && A[i * N + j]!= 0) {\n        sum++;\n      }\n    }\n  }\n\n  int result = sum;\n  MPI_Reduce(&sum, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "int count = 0;\n  for(size_t i=0; i<N; i++) {\n    for(size_t j=i+1; j<N; j++) {\n      if(A[i*N+j]) count++;\n    }\n  }\n  return count;\n}",
            "return 0;\n}",
            "MPI_Status status;\n    int result;\n    int rank;\n    int size;\n    int neighbor = -1;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    if (rank == 0) {\n        int recv = 0;\n        int send = 0;\n        for (int i = 1; i < size; i++) {\n            MPI_Recv(&recv, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n            result += recv;\n        }\n        result += edgeCount(A, N);\n        for (int i = 1; i < size; i++) {\n            MPI_Send(&send, 1, MPI_INT, i, 0, MPI_COMM_WORLD);\n        }\n        return result;\n    } else {\n        neighbor = (rank + size - 1) % size;\n        MPI_Send(&result, 1, MPI_INT, neighbor, 0, MPI_COMM_WORLD);\n        MPI_Recv(&result, 1, MPI_INT, neighbor, 0, MPI_COMM_WORLD, &status);\n        return result;\n    }\n\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  std::vector<std::vector<int>> adj(N, std::vector<int>(N));\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      adj[i][j] = A[i*N + j];\n    }\n  }\n  int a;\n  int num;\n  if (rank == 0) {\n    std::vector<int> b(N);\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&b[0], N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      for (int j = 0; j < N; j++) {\n        adj[i][j] = b[j];\n      }\n    }\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (adj[i][j] == 1 && i < j) {\n          num++;\n        }\n      }\n    }\n    MPI_Send(&num, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  else {\n    std::vector<int> c(N);\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (adj[i][j] == 1 && i < j) {\n          num++;\n        }\n      }\n    }\n    MPI_Send(&num, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    MPI_Recv(&a, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n  return a;\n}",
            "int count = 0;\n    int left, right;\n    for (int i = 0; i < N; ++i) {\n        for (int j = i + 1; j < N; ++j) {\n            left = A[i * N + j];\n            right = A[j * N + i];\n            if (left > 0 && right > 0) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "return 0;\n}",
            "// TODO\n}",
            "int my_count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < i; j++) {\n      my_count += A[i*N + j];\n    }\n  }\n  return my_count;\n}",
            "// Write your solution here.\n}",
            "int myrank;\n  int numprocs;\n  int rcount;\n  int rdisp;\n  int myedges;\n  int result;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n\n  rcount = N / numprocs;\n  rdisp = rcount * myrank;\n\n  std::vector<int> localA(A.begin() + rdisp * N,\n                          A.begin() + rdisp * N + rcount * N);\n  myedges = 0;\n  for (size_t i = 0; i < rcount; i++)\n    for (size_t j = i; j < rcount; j++)\n      myedges += localA[i * rcount + j];\n\n  MPI_Reduce(&myedges, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return result;\n}",
            "int n_procs, my_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n  int start = my_rank * N / n_procs;\n  int end = start + N / n_procs;\n  int sum = 0;\n  for (size_t i = start; i < end; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[i * N + j]) {\n        ++sum;\n      }\n    }\n  }\n  int sum_total;\n  MPI_Reduce(&sum, &sum_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (my_rank == 0) {\n    return sum_total;\n  }\n  return sum;\n}",
            "int numEdges = 0;\n\n    int numProcessors, processorID;\n    MPI_Comm_size(MPI_COMM_WORLD, &numProcessors);\n    MPI_Comm_rank(MPI_COMM_WORLD, &processorID);\n\n    int* blocksize = new int[numProcessors];\n    int* displs = new int[numProcessors];\n    int* count = new int[numProcessors];\n\n    int total = 0;\n    int index = 0;\n    int localSize = N / numProcessors;\n    int lastProcessSize = N % numProcessors;\n\n    for (int i = 0; i < numProcessors; i++)\n    {\n        if (i < lastProcessSize)\n        {\n            blocksize[i] = localSize + 1;\n            count[i] = blocksize[i] - 1;\n            displs[i] = index;\n            index += blocksize[i] - 1;\n        }\n        else\n        {\n            blocksize[i] = localSize;\n            count[i] = blocksize[i];\n            displs[i] = index;\n            index += blocksize[i];\n        }\n        total += blocksize[i];\n    }\n\n    int* data = new int[total];\n\n    MPI_Gatherv(&A[displs[processorID]], blocksize[processorID], MPI_INT, data, count, displs, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (processorID == 0)\n    {\n        for (int i = 0; i < total; i += 2)\n        {\n            if (data[i] == 1)\n            {\n                numEdges++;\n            }\n        }\n    }\n\n    MPI_Bcast(&numEdges, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    delete[] blocksize;\n    delete[] displs;\n    delete[] count;\n    delete[] data;\n\n    return numEdges;\n}",
            "// TODO: Your code here\n\treturn -1;\n}",
            "int count = 0;\n  for (size_t row = 0; row < N; row++) {\n    for (size_t col = 0; col < N; col++) {\n      if (row!= col && A[row * N + col] == 1) {\n        count++;\n      }\n    }\n  }\n\n  int count_local = count;\n  int count_global;\n\n  MPI_Reduce(&count_local, &count_global, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return count_global;\n}",
            "int numEdges = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tnumEdges++;\n\t\t}\n\t}\n\n\treturn numEdges;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // TODO\n}",
            "// Add your code here.\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N+j]) {\n\t++count;\n      }\n    }\n  }\n  return count;\n}",
            "if (A.size()!= N*N) {\n    std::cerr << \"Error: input is not a square matrix!\" << std::endl;\n    exit(EXIT_FAILURE);\n  }\n\n  int local_edges = 0;\n\n  // Compute the number of edges on each rank\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        local_edges++;\n      }\n    }\n  }\n\n  int global_edges = 0;\n  MPI_Reduce(&local_edges, &global_edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return global_edges;\n}",
            "// TODO: Fill in the body\n  int edgecount = 0;\n  int size, rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int x, y;\n  for (x = 0; x < N; x++) {\n    for (y = 0; y < N; y++) {\n      if (A[x * N + y] == 1) {\n        edgecount++;\n      }\n    }\n  }\n  int *result;\n  MPI_Status status;\n  if (rank == 0) {\n    result = new int[size];\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(result + i, 1, MPI_INT, i, 1, MPI_COMM_WORLD, &status);\n    }\n  }\n  if (rank > 0) {\n    MPI_Send(&edgecount, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  }\n  if (rank == 0) {\n    for (int i = 1; i < size; i++) {\n      result[0] += result[i];\n    }\n    return result[0];\n  }\n  else {\n    return 0;\n  }\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  if (rank == 0) {\n    // Compute the number of rows and columns that each rank has\n    int rowsPerRank = N / size;\n    int colsPerRank = N / size;\n    if (rowsPerRank * size < N) rowsPerRank++;\n    if (colsPerRank * size < N) colsPerRank++;\n    // Send rows to the other ranks\n    for (int i = 1; i < size; i++) {\n      MPI_Send(A.data() + rowsPerRank * i, rowsPerRank * N, MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n    // Store the local result on rank 0\n    int result = 0;\n    // Loop over each row\n    for (int row = 0; row < rowsPerRank; row++) {\n      // Loop over each column\n      for (int col = 0; col < colsPerRank; col++) {\n        // Add the result of each row/column pair\n        result += A[row * N + col];\n      }\n    }\n    // Add the values from the other ranks\n    for (int i = 1; i < size; i++) {\n      int value;\n      MPI_Recv(&value, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      result += value;\n    }\n    return result;\n  } else {\n    // Receive the rows from rank 0\n    int rowsPerRank = N / size;\n    int colsPerRank = N / size;\n    if (rowsPerRank * size < N) rowsPerRank++;\n    if (colsPerRank * size < N) colsPerRank++;\n    std::vector<int> localA(rowsPerRank * N);\n    MPI_Recv(localA.data(), rowsPerRank * N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    // Compute the local result\n    int result = 0;\n    for (int row = 0; row < rowsPerRank; row++) {\n      for (int col = 0; col < colsPerRank; col++) {\n        result += localA[row * N + col];\n      }\n    }\n    // Send the result to rank 0\n    MPI_Send(&result, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    return -1; // Dummy value to stop compilation warning\n  }\n}",
            "int rank, size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint start = rank * N / size;\n\tint end = (rank + 1) * N / size;\n\n\tint count = 0;\n\n\tfor (size_t i = start; i < end; ++i)\n\t\tfor (size_t j = i + 1; j < N; ++j)\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\t++count;\n\n\tint totalCount = 0;\n\n\tMPI_Reduce(&count, &totalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn totalCount;\n}",
            "int local_count = 0;\n\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[i * N + j])\n\t\t\t\t++local_count;\n\n\tint global_count = 0;\n\tMPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn global_count;\n}",
            "const int RANK = MPI::COMM_WORLD.Get_rank();\n\tconst int SIZE = MPI::COMM_WORLD.Get_size();\n\n\tint count = 0;\n\n\tif (RANK == 0) {\n\t\t// Rank 0 is the master process that distributes work to the slaves\n\n\t\tfor (int i = 1; i < SIZE; ++i) {\n\t\t\t// Send A to slave rank i\n\t\t\tint source = 0;\n\t\t\tint tag = 0;\n\t\t\tMPI::COMM_WORLD.Send(&A[0], N*N, MPI::INT, i, tag);\n\t\t}\n\t} else {\n\t\t// Rank i is a slave process that processes its part of A\n\n\t\tint partSize = (N / SIZE) * N;\n\t\tstd::vector<int> A_part(partSize, 0);\n\n\t\t// Receive part of A\n\t\tint source = 0;\n\t\tint tag = 0;\n\t\tMPI::COMM_WORLD.Recv(&A_part[0], partSize, MPI::INT, source, tag);\n\n\t\t// Count the number of edges\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < i; ++j) {\n\t\t\t\tif (A_part[i * N + j]!= 0) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (RANK == 0) {\n\t\t// Rank 0 is the master process that collects the results from the slaves\n\n\t\tfor (int i = 1; i < SIZE; ++i) {\n\t\t\t// Receive count from slave rank i\n\t\t\tint source = i;\n\t\t\tint tag = 0;\n\t\t\tMPI::COMM_WORLD.Recv(&count, 1, MPI::INT, source, tag);\n\t\t}\n\t} else {\n\t\t// Rank i is a slave process that sends the result to the master\n\n\t\t// Send count to master\n\t\tint source = 0;\n\t\tint tag = 0;\n\t\tMPI::COMM_WORLD.Send(&count, 1, MPI::INT, source, tag);\n\t}\n\n\t// The result is now in count\n\treturn count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N + j] == 1) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  const int DIM = sqrt(size);\n  const int NP = N/DIM;\n\n  /* TODO: Fill in your code here */\n\n  return 0;\n}",
            "}",
            "int num_ranks;\n  int rank;\n\n  // TODO: Complete this function.\n\n  MPI_Status status;\n  int recv_buf[N];\n  MPI_Recv(recv_buf, N, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1 && A[j * N + i] == 1) {\n        count++;\n      }\n    }\n  }\n  MPI_Reduce(&count, &recv_buf, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    return recv_buf[0];\n  }\n\n  return count;\n}",
            "// TODO\n}",
            "MPI_Status stat;\n\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  std::vector<int> row(A.begin()+N*rank, A.begin()+N*(rank+1));\n  int rowSum = 0;\n  for(int i = 0; i < N; i++) {\n    for(int j = 0; j < N; j++) {\n      rowSum += A[N*i+j];\n    }\n  }\n\n  if(rank == 0) {\n    std::vector<int> result(size);\n    for(int i = 1; i < size; i++) {\n      MPI_Recv(&result[i], 1, MPI_INT, i, 1, MPI_COMM_WORLD, &stat);\n    }\n    return std::accumulate(result.begin(), result.end(), rowSum);\n  }\n  else {\n    MPI_Send(&rowSum, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  }\n\n  return 0;\n}",
            "// TODO\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    // YOUR CODE HERE\n    int m = A.size()/N;\n    int count = 0;\n    for(int i = 0; i < m; i++)\n    {\n        for(int j = 0; j < m; j++)\n        {\n            if(A[i*m + j] == 1)\n                count++;\n        }\n    }\n    return count;\n}",
            "// Replace with your code\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint i;\n\tint j;\n\tint count = 0;\n\tint localCount;\n\tint localStart;\n\tint globalCount;\n\tint recvCount;\n\tint rankMinusOne;\n\tint rankPlusOne;\n\n\tif (N < size) {\n\t\tthrow std::runtime_error(\"N is less than the number of processes\");\n\t}\n\n\tlocalStart = rank*N/size;\n\tlocalCount = N/size;\n\n\tif (rank == 0) {\n\t\tfor (i = 0; i < localCount; ++i) {\n\t\t\tfor (j = i+1; j < localCount; ++j) {\n\t\t\t\tif (A[localStart+i+j*localCount] == 1) {\n\t\t\t\t\t++count;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor (i = 0; i < localCount; ++i) {\n\t\t\tfor (j = i+1; j < localCount; ++j) {\n\t\t\t\tif (A[localStart+i+j*localCount] == 1) {\n\t\t\t\t\t++localCount;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rank == 0) {\n\t\trecvCount = N/size;\n\t} else {\n\t\trecvCount = 1;\n\t}\n\n\trankPlusOne = rank+1;\n\trankMinusOne = rank-1;\n\n\tMPI_Reduce(&localCount, &globalCount, 1, MPI_INT, MPI_SUM, rankPlusOne, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tcount += globalCount;\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    int num_threads = 1;\n    if (A.size() == N*N) {\n        for (size_t i=0; i < N; ++i) {\n            for (size_t j=0; j < N; ++j) {\n                if (i!= j) {\n                    if (A[i*N+j] == 1) {\n                        ++count;\n                    }\n                }\n            }\n        }\n    } else {\n        std::cerr << \"Wrong size for A: \" << A.size() << std::endl;\n    }\n    return count;\n}",
            "// TODO\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int sum = 0;\n\n    if (rank == 0) {\n        for (size_t i = 0; i < N; i++) {\n            for (size_t j = 0; j < N; j++) {\n                if (A[i*N + j]!= 0) {\n                    sum++;\n                }\n            }\n        }\n    }\n\n    int sum_sum;\n\n    MPI_Reduce(&sum, &sum_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return sum_sum;\n}",
            "int count = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif(A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // count the number of edges on rank 0\n  int totalEdges = 0;\n  if (rank == 0) {\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (A[i*N + j] == 1) {\n          totalEdges++;\n        }\n      }\n    }\n  }\n\n  // sum the total number of edges with the root rank\n  MPI_Reduce(&totalEdges, &totalEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return totalEdges;\n}",
            "// TODO: Your code here\n  return 0;\n}",
            "int result = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        result++;\n      }\n    }\n  }\n  return result;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    // TODO: implement\n    return 0;\n}",
            "int n_edges = 0;\n\tfor(size_t i = 0; i < N; i++)\n\t\tfor(size_t j = 0; j < N; j++)\n\t\t\tif(i < j && A[i*N + j] > 0) n_edges++;\n\n\treturn n_edges;\n}",
            "int count = 0;\n    for (int i = 0; i < N; i++) {\n        for (int j = i + 1; j < N; j++) {\n            count += A[i * N + j] == 1;\n        }\n    }\n\n    return count;\n}",
            "// TODO: YOUR CODE HERE\n  return 0;\n}",
            "int numEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        numEdges++;\n      }\n    }\n  }\n  return numEdges;\n}",
            "if (A.size()!= N*N) {\n\t\tstd::cerr << \"A is not an NxN matrix\\n\";\n\t\treturn 0;\n\t}\n\n\tint num_nodes = N;\n\tint num_edges = 0;\n\n\tfor(int i = 0; i < A.size(); i++)\n\t{\n\t\tif(A[i] > 0)\n\t\t\tnum_edges++;\n\t}\n\t\n\n\tif (num_nodes <= 1) {\n\t\treturn 0;\n\t}\n\n\treturn num_edges;\n}",
            "int res = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      res += A[i * N + j];\n    }\n  }\n  return res;\n}",
            "int n;\n\tint n_total = 0;\n\tint rank = -1;\n\tMPI_Comm_size(MPI_COMM_WORLD, &n);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint edge_count = 0;\n\tint index = rank * N / n;\n\tint delta = N / n;\n\tfor (size_t i = 0; i < delta; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[index + j] == 1 && j > i) {\n\t\t\t\tedge_count++;\n\t\t\t}\n\t\t}\n\t\tindex += delta;\n\t}\n\tMPI_Reduce(&edge_count, &n_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn n_total;\n}",
            "int size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0) {\n\t\tstd::vector<int> counts(size, 0);\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\t\tcounts[rank]++;\n\t\t\t}\n\t\t}\n\n\t\tint total = 0;\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tMPI_Recv(&counts[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\ttotal += counts[i];\n\t\t}\n\t\treturn total / 2;\n\t} else {\n\t\tint count = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0;\n\t}\n\n}",
            "// TODO: implement\n\treturn 0;\n}",
            "if (N == 0) {\n    throw std::invalid_argument(\"N must be > 0\");\n  }\n  if (N * N!= A.size()) {\n    throw std::invalid_argument(\"A is not N x N\");\n  }\n  int count = 0;\n  int rank = 0;\n  int num_ranks = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n  if (rank == 0) {\n    if (num_ranks > N) {\n      throw std::invalid_argument(\"Too many ranks\");\n    }\n  }\n  std::vector<int> partial_counts(num_ranks);\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n  MPI_Gather(&count, 1, MPI_INT, partial_counts.data(), 1, MPI_INT, 0,\n             MPI_COMM_WORLD);\n  return rank == 0? std::accumulate(partial_counts.begin(), partial_counts.end(), 0) : 0;\n}",
            "// Your code here\n    //return 1;\n}",
            "int local_count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        local_count += 1;\n      }\n    }\n  }\n\n  int global_count = 0;\n  MPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return global_count;\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n  int rank = 0, size = 0;\n  MPI_Comm_rank(comm, &rank);\n  MPI_Comm_size(comm, &size);\n\n  // TODO: use MPI to count the number of edges in the graph A.\n  //       Every process has a complete copy of A.\n  //       The result is returned on rank 0.\n  int local_count = 0;\n  for(size_t i = 0; i < N; i++) {\n    for(size_t j = 0; j < i; j++) {\n      if(A[i*N + j]!= 0)\n        local_count++;\n    }\n  }\n\n  int global_count = 0;\n  MPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, 0, comm);\n\n  return global_count;\n}",
            "int count = 0;\n  for(size_t row = 0; row < N; row++)\n    for(size_t col = row; col < N; col++)\n      if(A[row * N + col] == 1)\n        count++;\n\n  return count;\n}",
            "const int rank = 0;\n\tconst int size = 1;\n\tint sum = 0;\n\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = i + 1; j < N; j++)\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tsum++;\n\n\treturn sum;\n}",
            "if (N < 2)\n    return 0;\n\n  int numEdges = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      if (A[N * i + j])\n        numEdges++;\n    }\n  }\n\n  return numEdges;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i)\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tif (A[N*i + j] == 1)\n\t\t\t\t++count;\n\treturn count;\n}",
            "if (N == 0) {\n    return 0;\n  }\n\n  // TODO: compute edge count in parallel using MPI\n  return 0;\n}",
            "int num_process = 0, rank = 0;\n    int *s = 0, *d = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_process);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int count = 0;\n    if (rank == 0) {\n        s = new int[N * N];\n        for (int i = 0; i < N; i++)\n            for (int j = 0; j < N; j++)\n                s[i * N + j] = A[i * N + j];\n        d = new int[num_process * N];\n        MPI_Scatter(s, N * N / num_process, MPI_INT, d, N * N / num_process,\n                    MPI_INT, 0, MPI_COMM_WORLD);\n        delete[] s;\n    }\n    else {\n        MPI_Scatter(NULL, 0, MPI_INT, NULL, 0, MPI_INT, 0, MPI_COMM_WORLD);\n        d = new int[N * N / num_process];\n        MPI_Scatter(s, N * N / num_process, MPI_INT, d, N * N / num_process,\n                    MPI_INT, 0, MPI_COMM_WORLD);\n        delete[] s;\n    }\n    for (int i = 0; i < N * N / num_process; i++) {\n        if (d[i] == 1)\n            count++;\n    }\n    int result = 0;\n    MPI_Reduce(&count, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    if (rank == 0)\n        std::cout << \"number of edges: \" << result << std::endl;\n    return result;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int const part = N / size;\n    int const offset = rank * part;\n\n    int count = 0;\n    for (int i = 0; i < part; ++i) {\n        for (int j = 0; j < part; ++j) {\n            if (A[i * N + j + offset] == 1) {\n                count++;\n            }\n        }\n    }\n\n    std::vector<int> counts(size, 0);\n    MPI_Gather(&count, 1, MPI_INT, counts.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        int result = 0;\n        for (int i = 0; i < counts.size(); ++i) {\n            result += counts[i];\n        }\n        return result;\n    }\n    else {\n        return -1;\n    }\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO: Implement this function\n  int result = 0;\n\n  return result;\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i < j) {\n        count += A[i * N + j];\n      }\n    }\n  }\n  return count;\n}",
            "int sum = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t}\n\n\tint sum_all;\n\tMPI_Allreduce(&sum, &sum_all, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\treturn sum_all;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// Count edges in a submatrix.\n  int countEdges(std::vector<int> const& A, int r0, int c0, int n) {\n    int count = 0;\n    for (int i = 0; i < n; ++i) {\n      for (int j = 0; j < n; ++j) {\n        if (A[i*n+j] && A[j*n+i]) ++count;\n      }\n    }\n    return count;\n  }\n\n  // Find the minimum number of rows and columns that can be distributed among\n  // the ranks.\n  int numRows = N;\n  int numCols = N;\n  int numRanks = 1;\n  for (int i = 0; i < numRows*numCols; ++i) {\n    int numRanksNeeded = std::ceil(sqrt(i+1));\n    if (numRanksNeeded > numRanks) {\n      numRanks = numRanksNeeded;\n      numRows = (int) std::ceil((double) N / numRanks);\n      numCols = std::ceil((double) N / numRanks);\n    }\n  }\n\n  // Compute the number of rows and columns owned by this rank.\n  int rowOffset = N / numRanks * rank;\n  int rowCount = N / numRanks;\n  if (rank == numRanks - 1) rowCount = N - rowOffset;\n\n  // Compute the number of edges in this submatrix.\n  int count = countEdges(A, rowOffset, 0, rowCount);\n\n  // Communicate results to rank 0.\n  int result = 0;\n  if (rank == 0) {\n    std::vector<int> counts(numRanks);\n    MPI_Gather(&count, 1, MPI_INT, &counts[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n    for (int i = 0; i < numRanks; ++i) result += counts[i];\n  } else {\n    MPI_Gather(&count, 1, MPI_INT, NULL, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  }\n  return result;\n}",
            "// TODO: Implement me!\n\treturn 0;\n}",
            "return 0;\n}",
            "return 0;\n}",
            "int M = A.size();\n    int count = 0;\n    for (int i = 0; i < M; ++i) {\n        for (int j = 0; j < M; ++j) {\n            if (A[i * M + j]) {\n                ++count;\n            }\n        }\n    }\n    return count;\n}",
            "// TODO\n    int size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    std::vector<int> A_part(N / size, N / size);\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (i < j)\n                A_part[i] += A[i * N + j];\n            else if (i > j)\n                A_part[j] += A[i * N + j];\n        }\n    }\n    int sum_part = 0;\n    for (int i = 0; i < N / size; ++i)\n        sum_part += A_part[i];\n    int sum = 0;\n    if (rank == 0) {\n        for (int i = 1; i < size; ++i) {\n            MPI_Status status;\n            MPI_Recv(&sum_part, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n            sum += sum_part;\n        }\n        sum *= 2;\n    } else {\n        MPI_Send(&sum_part, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n    return sum;\n}",
            "int num_edges = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i+1; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}\n\treturn num_edges;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int local_count = 0;\n    int count = 0;\n    for (size_t row = rank; row < N; row += size) {\n        for (size_t col = 0; col < row; ++col) {\n            local_count += A[row * N + col];\n        }\n    }\n    MPI_Reduce(&local_count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    if (rank == 0) {\n        return count;\n    }\n    return 0;\n}",
            "int const rank = MPI_Rank();\n  int const size = MPI_Size();\n\n  // The number of rows each rank will work on.\n  std::vector<size_t> counts(size);\n  counts[rank] = N / size;\n  for (size_t i = 1; i < size; i++)\n    counts[i] = counts[i - 1] + (N - (N / size) * i);\n\n  // Compute the number of edges for the rows I will work on.\n  std::vector<int> localEdges(counts[rank]);\n  for (size_t i = 0; i < counts[rank]; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j] == 1)\n\tlocalEdges[i]++;\n\n  // Reduce the local edges into a global number.\n  int globalEdges;\n  MPI_Reduce(&localEdges[0], &globalEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  // Rank 0 has the answer.\n  return globalEdges;\n}",
            "int r, s;\n\tMPI_Comm_size(MPI_COMM_WORLD, &s);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &r);\n\n\tstd::vector<int> localEdgeCount(s, 0);\n\tif (r == 0) {\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i < j && A[i*N + j] == 1) {\n\t\t\t\t\tlocalEdgeCount[i]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i < j && A[r*N + j] == 1) {\n\t\t\t\t\tlocalEdgeCount[r]++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint globalEdgeCount = 0;\n\tMPI_Reduce(localEdgeCount.data(), &globalEdgeCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn globalEdgeCount;\n}",
            "int rank, nprocs;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n\tif (A.size()!= N*N) {\n\t\tthrow std::runtime_error(\"invalid input matrix\");\n\t}\n\n\t// TODO\n\tint sum = 0;\n\tfor (size_t i = 0; i < A.size(); i++) {\n\t\tif (A[i] == 1) {\n\t\t\tsum++;\n\t\t}\n\t}\n\tint local_sum = sum;\n\n\tint temp_sum = 0;\n\tMPI_Reduce(&local_sum, &temp_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\treturn temp_sum;\n\t}\n\n\treturn sum;\n}",
            "if (N == 0)\n    return 0;\n  int result = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i * N + j] == 1)\n\t++result;\n  return result;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // Your code here.\n    int ans = 0;\n    int start = rank * (N / size);\n    int end = (rank + 1) * (N / size);\n    for (int i = start; i < end; i++) {\n        for (int j = 0; j < i; j++) {\n            if (A[i * N + j] == 1) {\n                ans++;\n            }\n        }\n    }\n\n    int sum;\n    MPI_Reduce(&ans, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return sum;\n}",
            "// Complete this function\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n  int size, rank;\n  MPI_Comm_size(comm, &size);\n  MPI_Comm_rank(comm, &rank);\n\n  // YOUR CODE GOES HERE\n\n  return 0;\n}",
            "int n_nodes = N*N;\n  std::vector<int> local_counts(n_nodes, 0);\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int local_rows = N / size;\n  int local_cols = N;\n\n  for (int i=0; i<N; ++i) {\n    for (int j=0; j<N; ++j) {\n      if (A[i*N+j]) {\n        local_counts[i*local_cols + j]++;\n      }\n    }\n  }\n\n  std::vector<int> all_counts(n_nodes*size);\n  MPI_Gather(local_counts.data(), n_nodes, MPI_INT,\n             all_counts.data(), n_nodes, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    int cnt = 0;\n    for (size_t i=0; i<all_counts.size(); ++i) {\n      if (all_counts[i] > 0) {\n        cnt++;\n      }\n    }\n    return cnt;\n  }\n\n  return 0;\n}",
            "std::vector<int> numEdges(N);\n\n    // TODO: Count number of edges and store in numEdges\n\n    // TODO: Sum up all the results\n\n    int result;\n    MPI_Reduce(&numEdges[0], &result, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return result;\n}",
            "int numEdges = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        ++numEdges;\n      }\n    }\n  }\n  return numEdges;\n}",
            "// TODO\n  int edge = 0;\n  for (int i = 0; i < N; i++){\n    for (int j = i+1; j < N; j++){\n      if (A[i*N + j] == 1 || A[j*N + i] == 1) {\n        edge++;\n      }\n    }\n  }\n  return edge;\n}",
            "int res = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i; j < N; j++) {\n      res += A[i * N + j];\n    }\n  }\n  return res;\n}",
            "int result = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i + 1; j < N; j++) {\n      result += A[i + j * N];\n    }\n  }\n  return result;\n}",
            "const int rank = MPI_Comm_rank(MPI_COMM_WORLD);\n\tconst int size = MPI_Comm_size(MPI_COMM_WORLD);\n\n\t// compute the number of edges on this rank\n\tint localEdgeCount = 0;\n\tfor (size_t i = rank; i < N; i += size) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++localEdgeCount;\n\t\t\t}\n\t\t}\n\t}\n\n\t// sum up all the local edge counts\n\tint globalEdgeCount = 0;\n\tMPI_Reduce(&localEdgeCount, &globalEdgeCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn globalEdgeCount;\n}",
            "int numProcs, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint* localSum = new int[N];\n\tfor(size_t i=0; i<N; ++i) {\n\t\tlocalSum[i] = 0;\n\t\tfor(size_t j=0; j<N; ++j) {\n\t\t\tlocalSum[i] += A[i*N + j];\n\t\t}\n\t}\n\n\tint* counts = new int[numProcs];\n\tMPI_Gather(localSum, N, MPI_INT, counts, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint result = 0;\n\tif(rank == 0) {\n\t\tfor(size_t i=0; i<N; ++i) {\n\t\t\tfor(size_t j=0; j<N; ++j) {\n\t\t\t\tresult += counts[i*N + j];\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tdelete[] localSum;\n\tdelete[] counts;\n\n\treturn result;\n}",
            "int num_edges = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        num_edges++;\n      }\n    }\n  }\n  return num_edges;\n}",
            "// TODO\n}",
            "int sum = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            sum += A[i + j * N];\n        }\n    }\n    return sum;\n}",
            "int rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint* B = new int[N];\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tB[i] = A[i*N];\n\t}\n\n\tint* C = new int[N];\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tC[i] = 0;\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tC[i] += A[i*N + j];\n\t\t}\n\t}\n\n\tint sum = 0;\n\tMPI_Reduce(&C, &sum, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tsum -= B[i];\n\t\t}\n\t\treturn sum;\n\t}\n\telse {\n\t\treturn -1;\n\t}\n}",
            "// YOUR CODE GOES HERE\n\tint n = A.size();\n\tint k = 0;\n\tfor (int i = 0; i < n; i++) {\n\t\tfor (int j = i + 1; j < n; j++) {\n\t\t\tif (A[i * n + j] == 1) {\n\t\t\t\tk++;\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Init(NULL, NULL);\n\tMPI_Comm_size(MPI_COMM_WORLD, &N);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &k);\n\tMPI_Status status;\n\tint size = n / N;\n\tint rest = n - size * N;\n\tint sum = 0;\n\tif (k < rest) {\n\t\tsize++;\n\t\tfor (int i = k * size; i < (k + 1) * size; i++) {\n\t\t\tfor (int j = i + 1; j < (k + 1) * size; j++) {\n\t\t\t\tif (A[i * n + j] == 1) {\n\t\t\t\t\tsum++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\tfor (int i = k * size + rest; i < (k + 1) * size + rest; i++) {\n\t\t\tfor (int j = i + 1; j < (k + 1) * size + rest; j++) {\n\t\t\t\tif (A[i * n + j] == 1) {\n\t\t\t\t\tsum++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif (k == 0) {\n\t\tstd::cout << sum << std::endl;\n\t}\n\tMPI_Finalize();\n\treturn sum;\n}",
            "int rank;\n  int size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int edgeCount = 0;\n\n  // Compute the number of rows assigned to this process\n  size_t chunk = N / size;\n  size_t start = rank * chunk;\n  size_t end   = rank == size - 1? N : start + chunk;\n\n  for (size_t i = start; i < end; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        edgeCount++;\n      }\n    }\n  }\n\n  // Send the result to the root\n  if (rank == 0) {\n    // Wait to receive results from all other processes\n    std::vector<int> results(size - 1);\n    MPI_Status status;\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&results[i - 1], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n    }\n\n    // Add the local results to the total\n    for (auto x : results) {\n      edgeCount += x;\n    }\n\n    return edgeCount;\n  } else {\n    // Send the local result to the root\n    MPI_Send(&edgeCount, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n}",
            "int numEdges = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i!= j && A[i*N+j] == 1) {\n                numEdges++;\n            }\n        }\n    }\n    return numEdges;\n}",
            "assert(A.size() == N*N);\n  // TODO: implement\n  return 0;\n}",
            "// TODO: replace this code with a solution\n  int result = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i*N+j]!= 0) {\n        ++result;\n      }\n    }\n  }\n  return result;\n}",
            "int rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint size = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint edgeCount = 0;\n\n\tint start = 0;\n\tint end = 0;\n\tif (size!= 1) {\n\t\tstart = N * rank / size;\n\t\tend = N * (rank + 1) / size;\n\t} else {\n\t\tstart = 0;\n\t\tend = N;\n\t}\n\n\tfor (int i = start; i < end; ++i) {\n\t\tfor (int j = 0; j < i; ++j) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\t++edgeCount;\n\t\t\t}\n\t\t}\n\t}\n\n\tint result = 0;\n\tif (size!= 1) {\n\t\tMPI_Reduce(&edgeCount, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tresult = edgeCount;\n\t}\n\n\treturn result;\n}",
            "int result = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = i + 1; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        result++;\n      }\n    }\n  }\n  return result;\n}",
            "return 0;\n}",
            "int res = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = i + 1; j < N; ++j) {\n\t\t\tres += A[i * N + j];\n\t\t}\n\t}\n\treturn res;\n}",
            "// TODO\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < N; j++)\n\t\t\tif (i < j && A[i * N + j]!= 0)\n\t\t\t\tcount++;\n\treturn count;\n}",
            "// TODO\n\tint count = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < i; ++j) {\n\t\t\tif(A[i * N + j] == 1)\n\t\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "int sum = 0;\n    // loop over all elements in matrix\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            // check if the element at (i, j) is not 0\n            // if it's not 0, increment the sum\n            if (A[i * N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n\n    return sum;\n}",
            "int result = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tresult += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "MPI_Datatype type = MPI_DATATYPE_NULL;\n\tint edgeCount = 0;\n\tMPI_Init(0, 0);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tif (rank == 0) {\n\t\tMPI_Type_vector(N, N, N, MPI_INT, &type);\n\t\tMPI_Type_commit(&type);\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Send(&A[0], 1, type, i, 0, MPI_COMM_WORLD);\n\t\t}\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Recv(&A[0], 1, type, i, 0, MPI_COMM_WORLD, &status);\n\t\t\tfor (int x = 0; x < N; x++) {\n\t\t\t\tfor (int y = 0; y < N; y++) {\n\t\t\t\t\tif (A[x + y * N] == 1)\n\t\t\t\t\t\tedgeCount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tMPI_Recv(&A[0], 1, type, 0, 0, MPI_COMM_WORLD, &status);\n\t\tfor (int x = 0; x < N; x++) {\n\t\t\tfor (int y = 0; y < N; y++) {\n\t\t\t\tif (A[x + y * N] == 1)\n\t\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Bcast(&edgeCount, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\treturn edgeCount;\n}",
            "int rank;\n    int size;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int m = A.size();\n\n    if (m!= N * N) {\n        throw std::runtime_error(\"Invalid matrix\");\n    }\n\n    // TODO: your code here\n    int count = 0;\n    int total = 0;\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                count++;\n            }\n        }\n    }\n\n    if (rank == 0) {\n        for (int i = 1; i < size; ++i) {\n            MPI_Recv(&total, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            total += count;\n        }\n    } else {\n        MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    return total;\n}",
            "int numEdges = 0;\n\n    // Your code here\n\n    return numEdges;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n  int rank, size;\n  MPI_Comm_rank(comm, &rank);\n  MPI_Comm_size(comm, &size);\n  int count = 0;\n\n  if (rank == 0) {\n    // TODO:\n  } else {\n    // TODO:\n  }\n\n  int rcount = 0;\n  int* rcounts = new int[size];\n  MPI_Gather(&count, 1, MPI_INT, rcounts, 1, MPI_INT, 0, comm);\n  if (rank == 0) {\n    for (size_t i = 0; i < size; ++i) {\n      rcount += rcounts[i];\n    }\n  }\n  return rcount;\n}",
            "int numEdges = 0;\n\n    MPI_Status status;\n    int rank;\n    int p;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    if (rank == 0) {\n        // The root does the counting\n        for (size_t i = 0; i < N; i++) {\n            for (size_t j = i; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    numEdges++;\n                }\n            }\n        }\n        for (int r = 1; r < p; r++) {\n            int count;\n            MPI_Recv(&count, 1, MPI_INT, r, 0, MPI_COMM_WORLD, &status);\n            numEdges += count;\n        }\n    }\n    else {\n        // Non-roots do the counting\n        int count = 0;\n        for (size_t i = rank; i < N; i += p) {\n            for (size_t j = 0; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    count++;\n                }\n            }\n        }\n        MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    return numEdges;\n}",
            "if (N <= 0)\n    throw std::invalid_argument(\"N must be positive\");\n  int rc = 0;\n  int rank, p;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &p);\n  if (A.size()!= N * N)\n    throw std::invalid_argument(\"A must be a square matrix of size N\");\n\n  // count local edges\n  int local_rc = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1)\n        ++local_rc;\n    }\n  }\n\n  // sum up all counts\n  int global_rc = 0;\n  MPI_Reduce(&local_rc, &global_rc, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0)\n    return global_rc;\n  return -1;\n}",
            "int sum = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i + 1; j < N; ++j) {\n            sum += A[i*N+j];\n        }\n    }\n    return sum;\n}",
            "int world_rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n  int world_size;\n  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n  int *sub_A = new int[N * (N / world_size)];\n\n  MPI_Scatter(&A[0], N * (N / world_size), MPI_INT, sub_A,\n\t      N * (N / world_size), MPI_INT, 0, MPI_COMM_WORLD);\n\n  int count = 0;\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (sub_A[i * (N / world_size) + j] == 1) {\n\tcount++;\n      }\n    }\n  }\n\n  int *recvcounts = new int[world_size];\n  int *displs = new int[world_size];\n\n  MPI_Gather(&count, 1, MPI_INT, recvcounts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (world_rank == 0) {\n    for (int i = 1; i < world_size; i++) {\n      recvcounts[0] += recvcounts[i];\n    }\n    return recvcounts[0];\n  }\n\n  return 0;\n}",
            "// TODO\n  return 0;\n}",
            "size_t numEdges = 0;\n\n\tfor (size_t row = 0; row < N; ++row) {\n\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\tif (A[row * N + col] == 1) {\n\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numEdges;\n}",
            "int nprocs, rank;\n    int *sendcounts = new int[N];\n    int *displs = new int[N];\n    for(int i = 0; i < N; i++) {\n        sendcounts[i] = N;\n    }\n    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int total_size = N * N;\n    int recvcount = total_size / nprocs;\n    if (rank!= 0) {\n        displs[0] = 0;\n        for(int i = 1; i < N; i++) {\n            displs[i] = displs[i - 1] + recvcount;\n        }\n    }\n    std::vector<int> A_p(recvcount);\n    MPI_Scatterv(&A[0], sendcounts, displs, MPI_INT,\n        &A_p[0], recvcount, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int count = 0;\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < N; j++) {\n            if (A_p[i * N + j]) {\n                count++;\n            }\n        }\n    }\n\n    int total;\n    MPI_Reduce(&count, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    delete[] sendcounts;\n    delete[] displs;\n    return total;\n}",
            "int result = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < i; ++j)\n      if (A[i * N + j] == 1)\n        ++result;\n  return result;\n}",
            "std::vector<int> sendBuf(N*N);\n\tstd::vector<int> recvBuf(N*N);\n\n\tMPI_Datatype mpi_matrix;\n\tMPI_Type_contiguous(N*N, MPI_INT, &mpi_matrix);\n\tMPI_Type_commit(&mpi_matrix);\n\n\tMPI_Request request;\n\tMPI_Status status;\n\n\tif (A.size()!= N*N)\n\t\tthrow \"matrix size mismatch\";\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (rank == 0) {\n\t\t// Master: distribute A to workers, receive results\n\t\tfor (int i = 1; i < size; ++i) {\n\t\t\tMPI_Isend(&A[0], 1, mpi_matrix, i, 0, MPI_COMM_WORLD, &request);\n\t\t}\n\t\tfor (int i = 1; i < size; ++i) {\n\t\t\tMPI_Recv(&recvBuf[0], 1, mpi_matrix, MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n\t\t\tMPI_Send(&A[0], 1, mpi_matrix, status.MPI_SOURCE, 0, MPI_COMM_WORLD);\n\t\t}\n\t} else {\n\t\t// Workers: process A, send result\n\t\tMPI_Recv(&recvBuf[0], 1, mpi_matrix, 0, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tcount += recvBuf[i*N + j];\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\tMPI_Type_free(&mpi_matrix);\n\tif (rank == 0) {\n\t\treturn count;\n\t}\n\treturn 0;\n}",
            "std::vector<int> count;\n\tint c = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\tc++;\n\t\t\t}\n\t\t}\n\t\tcount.push_back(c);\n\t}\n\n\tint result = std::reduce(count.begin(), count.end());\n\n\treturn result;\n}",
            "int my_count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[N * i + j]!= 0) {\n\t\t\t\t++my_count;\n\t\t\t}\n\t\t}\n\t}\n\n\tint count;\n\tMPI_Reduce(&my_count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn count;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "cuda",
        "prompt": "/* Count the number of edges in the graph defined by the adjacency matrix A.\n   Store the result in numEdges.\n   A is an NxN adjacency matrix stored in row-major.\n   Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\n__global__ void edgeCount(const int *A, size_t N, int *numEdges) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Set local variable to the number of edges found by this thread\n  int numLocalEdges = 0;\n\n  // Get the row and column for this thread\n  int row = threadIdx.y + blockIdx.y * blockDim.y;\n  int col = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // If thread is in bounds, check for edges\n  if ((row < N) && (col < N)) {\n    if (A[row * N + col] == 1) {\n      numLocalEdges++;\n    }\n  }\n\n  // Atomic add to global variable\n  atomicAdd(numEdges, numLocalEdges);\n}",
            "//TODO: implement kernel\n  int tid = threadIdx.x;\n  int sum = 0;\n  for (int i = tid; i < N; i += blockDim.x) {\n    for (int j = 0; j < N; j++) {\n      sum += (A[i * N + j] > 0);\n    }\n  }\n  __syncthreads();\n  atomicAdd(numEdges, sum);\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint n = 0;\n\n\tfor (int j = 0; j < N; ++j) {\n\t\tif (i < N && A[i * N + j])\n\t\t\tn++;\n\t}\n\n\tif (i < N)\n\t\tatomicAdd(numEdges, n);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\t\n\t// Each thread has its own memory and can modify it without affecting the other threads\n\t// The thread count is equal to the number of vertices in the graph\n\t// Each thread should look at its own row\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\t// We only want to count the edges once\n\t\t// If the number at index i is 1 and the number at index j is 1, then there is an edge between i and j\n\t\t// If i == j then it is not an edge, and we don't want to count that\n\t\tif ((A[i * N + tid] + A[tid * N + i]) > 0 && (i!= tid)) {\n\t\t\tsum += 1;\n\t\t}\n\t}\n\t// Add the number of edges to the total\n\tatomicAdd(numEdges, sum);\n}",
            "//\n  //\n  //\n}",
            "// Use a grid-stride loop\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  int sum = 0;\n  for (int i = idx; i < N * N; i += stride) {\n    sum += A[i];\n  }\n  atomicAdd(numEdges, sum);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    int idx = tid * N;\n    int sum = 0;\n    for (int i = 0; i < N; ++i) {\n        sum += A[idx + i];\n    }\n    sum /= 2;\n    atomicAdd(numEdges, sum);\n}",
            "// Implement this\n}",
            "// Each thread computes one value in the result vector\n  // using a matrix entry\n  int myId = blockIdx.x * blockDim.x + threadIdx.x;\n  int x = myId / N;\n  int y = myId % N;\n  if (x < N && y < N && A[x*N + y]) {\n    atomicAdd(numEdges, 1);\n  }\n}",
            "int thread = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint sum = 0;\n\t\n\tfor(int i = thread; i < N; i += stride) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t}\n\n\t*numEdges += sum;\n}",
            "// TODO: Implement this function\n  size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N)\n    for (size_t j = i + 1; j < N; j++)\n      if (A[j * N + i]!= 0 || A[i * N + j]!= 0)\n        atomicAdd(numEdges, 1);\n}",
            "int count = 0;\n    int row = blockIdx.x * blockDim.x + threadIdx.x;\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[row * N + i] && A[row * N + j])\n                count += 1;\n        }\n    }\n    atomicAdd(numEdges, count);\n}",
            "// The number of edges is the sum of the elements in the matrix A.\n\t// Each thread computes the sum of one row of the matrix A, and then\n\t// sum the results.\n\t// To avoid bank conflicts, each thread needs to work with a single row.\n\t// Therefore, the number of threads must be at least N.\n\t// Each thread works with row i, where i is its thread ID.\n\t// The matrix A is stored in row-major order, and each row is N integers long.\n\t// Therefore, the start of row i of A is at A + i * N.\n\t// Each thread works with a single integer in its row, and so has a stride of 1.\n\t// For example, if there are 32 threads, then threads 0-31 work with row 0 of A,\n\t// threads 32-63 work with row 1 of A, and so on.\n\n\tint tid = threadIdx.x; // Thread ID\n\tint threadSum = 0; // The sum for the current thread\n\n\t// Iterate through the row of A the current thread works with.\n\t// Add each element to the thread's sum.\n\tfor (int i = tid; i < N; i += blockDim.x) {\n\t\tthreadSum += A[tid * N + i];\n\t}\n\n\t// Synchronize all threads before summing the thread sums.\n\t__syncthreads();\n\n\t// If there are at least 512 threads, then there are 64 warps.\n\t// Use a shared memory array to keep track of the thread sums.\n\t// Each warp uses one integer to keep track of its sum, and so the\n\t// shared memory array must be 64 integers long.\n\t// The first warp uses the first integer, the second uses the second,\n\t// and so on.\n\t// Therefore, the start of the array for the current warp is at\n\t// sharedSums + warpID.\n\textern __shared__ int sharedSums[];\n\tint warpSum = threadSum;\n\tint warpID = tid / 32; // Warp ID\n\tif (warpID < 32) {\n\t\tsharedSums[warpID] = warpSum;\n\t}\n\n\t// Synchronize all threads in the block before summing the warp sums.\n\t// Note that there may be at most 1024 threads in the block, so this\n\t// synchronization must occur before the block has completed.\n\t// Note also that the __syncthreads() statement must occur within a kernel.\n\t__syncthreads();\n\n\t// Sum the warp sums if there are 512 or more threads in the block.\n\tif (warpID < 32) {\n\t\tint index = warpID + (warpID / 2);\n\t\tif (index < 32) {\n\t\t\tsharedSums[index] += sharedSums[index + 32];\n\t\t}\n\t}\n\n\t// Synchronize all threads in the block before storing the result.\n\t// Note that this synchronization must occur after the block has completed.\n\t// Note also that the __syncthreads() statement must occur within a kernel.\n\t__syncthreads();\n\n\t// If the current thread is thread 0, then store the result in numEdges.\n\tif (tid == 0) {\n\t\t*numEdges = sharedSums[0];\n\t}\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n\tint start = i*N;\n\tif (A[start + j] == 1) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "int idx = threadIdx.x;\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tsum += A[i*N + j];\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tsize_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i == j) return;\n\tif (i >= N || j >= N) return;\n\tif (A[i * N + j] == 1) atomicAdd(numEdges, 1);\n}",
            "int sum = 0;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tfor (size_t i = tid; i < N; i += gridDim.x * blockDim.x) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "__shared__ int numEdges_shared[NUM_THREADS];\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tnumEdges_shared[tid] = 0;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tnumEdges_shared[tid] += A[tid + i * N];\n\t\t}\n\t}\n\t__syncthreads();\n\n\tint i = blockDim.x / 2;\n\twhile (i!= 0) {\n\t\tif (tid < i) {\n\t\t\tnumEdges_shared[tid] += numEdges_shared[tid + i];\n\t\t}\n\t\t__syncthreads();\n\t\ti /= 2;\n\t}\n\n\tif (tid == 0) {\n\t\tatomicAdd(numEdges, numEdges_shared[0]);\n\t}\n}",
            "__shared__ int s_edges[512];\n  s_edges[threadIdx.x] = 0;\n\n  __syncthreads();\n  for (size_t j = threadIdx.x; j < N; j += blockDim.x) {\n    for (size_t i = 0; i < N; i++) {\n      if (A[i + j * N] == 1) {\n        s_edges[threadIdx.x]++;\n      }\n    }\n  }\n\n  __syncthreads();\n  for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      s_edges[threadIdx.x] += s_edges[threadIdx.x + s];\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    atomicAdd(numEdges, s_edges[0]);\n  }\n}",
            "size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t stride = blockDim.x * gridDim.x;\n    size_t num_threads = stride * gridDim.x;\n    __shared__ int count;\n    count = 0;\n    int id = threadIdx.x + blockIdx.x * blockDim.x;\n    for (size_t i = id; i < N * N; i += num_threads)\n    {\n        if (A[i] == 1)\n        {\n            count++;\n        }\n    }\n    atomicAdd(numEdges, count);\n}",
            "int tid = threadIdx.x;\n  int blockId = blockIdx.x;\n  int i;\n  __shared__ int total;\n  __shared__ int *blockCount;\n  if (blockId == 0) {\n    if (tid == 0)\n      *blockCount = 0;\n    __syncthreads();\n  }\n  if (tid == 0)\n    total = 0;\n  for (i = 0; i < N; i++) {\n    total += A[tid * N + i];\n  }\n  blockCount[tid] = total;\n  __syncthreads();\n  if (blockId == 0) {\n    if (tid == 0) {\n      *numEdges = blockCount[0];\n    } else {\n      *numEdges += blockCount[tid];\n    }\n  }\n}",
            "int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\tint numThreads = blockDim.x * gridDim.x;\n\tint sum = 0;\n\n\tfor (int i = threadID; i < N; i += numThreads) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint sum = 0;\n\tfor (int i = tid; i < N * N; i += blockDim.x * gridDim.x) {\n\t\tint col = i / N;\n\t\tint row = i % N;\n\t\tsum += A[col * N + row];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "unsigned int index = threadIdx.x + blockDim.x*blockIdx.x;\n  unsigned int stride = blockDim.x*gridDim.x;\n  for (unsigned int i = index; i < N; i += stride) {\n    for (unsigned int j = 0; j < N; j++) {\n      if (A[N*i + j] == 1) {\n        atomicAdd(numEdges, 1);\n        break;\n      }\n    }\n  }\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tsize_t stride = gridDim.x * blockDim.x;\n\tfor (size_t j = i; j < N; j += stride) {\n\t\tif (i == j) continue;\n\t\tif (A[i + j * N] == 1) {\n\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint count = 0;\n\n\tif (index >= N * N)\n\t\treturn;\n\n\tint i = index / N;\n\tint j = index % N;\n\n\tif (i == j)\n\t\treturn;\n\n\t// Count the number of edges in the graph defined by the adjacency matrix A.\n\t// Store the result in numEdges.\n\t// A is an NxN adjacency matrix stored in row-major.\n\t// Use CUDA to compute in parallel. The kernel is launched with at least N threads.\n\n\t// Example:\n\n\t// input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n\t// output: 3\n\n\tint sum = 0;\n\n\tsum = A[i * N + j] + A[j * N + i];\n\n\tif (sum == 2)\n\t\tcount++;\n\n\t// add the result in atomic\n\tatomicAdd(numEdges, count);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N) {\n        int i = tid;\n        int count = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]) count++;\n        }\n        numEdges[tid] = count;\n    }\n}",
            "*numEdges = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i < N && j < N)\n\t\tif (A[i * N + j])\n\t\t\tatomicAdd(numEdges, 1);\n}",
            "__shared__ int temp[THREADS_PER_BLOCK];\n  int tid = threadIdx.x;\n  int start = N * (blockIdx.x * THREADS_PER_BLOCK + tid);\n  int end = start + N;\n  int local_sum = 0;\n\n  for (int i = start; i < end; i++) {\n    if (A[i] == 1) {\n      local_sum++;\n    }\n  }\n\n  temp[tid] = local_sum;\n\n  __syncthreads();\n\n  if (tid < 128) {\n    temp[tid] += temp[tid + 128];\n  }\n\n  __syncthreads();\n\n  if (tid < 64) {\n    temp[tid] += temp[tid + 64];\n  }\n\n  __syncthreads();\n\n  if (tid == 0) {\n    atomicAdd(numEdges, temp[0]);\n  }\n}",
            "int i = threadIdx.x;\n  int num = 0;\n  for (int j = 0; j < N; ++j) {\n    if (A[i + j * N] == 1) {\n      num += 1;\n    }\n  }\n  atomicAdd(numEdges, num);\n}",
            "// TODO: Fill this in\n}",
            "int row, col;\n    int tid = threadIdx.x;\n    int cnt = 0;\n\n    /* Use the thread id to get the correct row and column.\n       Do not use if or for loops here.  */\n    row = tid;\n    col = N;\n\n    /* Add up the adjacent elements (i.e., element (i, j) and element (j, i)) in the\n       adjacency matrix A.  Use A[i*N + j] to access the element at row i and column j\n       in the matrix.  You can add both elements in one statement, e.g.,\n\n       int sum = A[i*N + j] + A[j*N + i];\n\n       Store the result in cnt.  */\n\n    int sum = A[row * N + col] + A[col * N + row];\n\n    /* Store the number of edges in the variable numEdges, and only one thread should\n       do this.  Use the if statement, as well as the atomicAdd function.  */\n\n    if (tid == 0) {\n        atomicAdd(numEdges, sum);\n    }\n}",
            "int index = blockDim.x * blockIdx.x + threadIdx.x;\n  if (index < N * N) {\n    __shared__ volatile int cache[N];\n\n    int sum = 0;\n    int i = index / N;\n    int j = index % N;\n    if (i < N && j < N) {\n      sum = A[i * N + j];\n    }\n    cache[threadIdx.x] = sum;\n    __syncthreads();\n    int t = threadIdx.x;\n    while (t < N) {\n      sum += cache[t];\n      t += blockDim.x;\n    }\n    if (threadIdx.x == 0) {\n      atomicAdd(numEdges, sum);\n    }\n  }\n}",
            "size_t row = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (row >= N) return;\n\n\tint count = 0;\n\tfor (size_t j = 0; j < N; j++) {\n\t\tif (A[row*N+j] == 1)\n\t\t\tcount++;\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  __shared__ int count;\n  if (x == 0 && y == 0)\n    count = 0;\n\n  __syncthreads();\n\n  if (x >= N || y >= N)\n    return;\n\n  if (A[x * N + y]!= 0) {\n    atomicAdd(&count, 1);\n  }\n\n  __syncthreads();\n\n  if (x == 0 && y == 0) {\n    *numEdges = count;\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint cnt = 0;\n\tfor (int i = tid; i < N; i += blockDim.x * gridDim.x) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tcnt += (A[i * N + j]!= 0);\n\t\t}\n\t}\n\tatomicAdd(numEdges, cnt);\n}",
            "int idx = threadIdx.x + blockDim.x * blockIdx.x;\n  if (idx >= N) return;\n\n  int count = 0;\n  for (int i = 0; i < N; i++)\n    count += (A[i * N + idx]!= 0);\n\n  atomicAdd(numEdges, count);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if(idx >= N)\n    return;\n\n  int count = 0;\n  int row = idx;\n  for(int i = 0; i < N; ++i)\n    if(A[row*N + i])\n      count++;\n\n  atomicAdd(numEdges, count);\n}",
            "int sum = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j;\n\n\tfor (j = 0; j < N; j++) {\n\t\tif (A[j * N + i] == 1) {\n\t\t\tsum++;\n\t\t}\n\t}\n\n\t//write the sum of 1's to the output array.\n\tif (i == 0) {\n\t\t*numEdges = sum;\n\t}\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\n    // For each vertex, count the number of edges incident on that vertex\n    // The kernel is launched with at least N threads, and each thread computes\n    // one edge count\n    int count = 0;\n    if (i < N) {\n        for (int j = 0; j < N; j++) {\n            count += A[i * N + j];\n        }\n    }\n\n    // Add the edge counts from all threads to the first element of numEdges\n    // The threadIdx.x == 0 is the master thread, and the atomicAdd function\n    // makes sure that this is done safely\n    if (threadIdx.x == 0) {\n        atomicAdd(numEdges, count);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) return;\n  if (A[i*N + i] == 1)\n    atomicAdd(numEdges, N-1);\n  else\n    for (int j=i+1; j < N; ++j) {\n      if (A[i*N + j] == 1)\n        atomicAdd(numEdges, 1);\n    }\n}",
            "int numEdgesLocal = 0;\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  for (int i = tid; i < N; i += gridDim.x * blockDim.x) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i + j * N] > 0) {\n        ++numEdgesLocal;\n      }\n    }\n  }\n\n  atomicAdd(numEdges, numEdgesLocal);\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n    int tid = threadIdx.x;\n\n    __shared__ int cache[128];\n    cache[tid] = 0;\n    __syncthreads();\n\n    int i, j;\n\n    for (i = 0; i < N; i+= blockDim.x) {\n        if (id < N) {\n            if (A[i*N+id]) {\n                atomicAdd(&cache[tid], 1);\n            }\n        }\n    }\n\n    __syncthreads();\n\n    for (j = 128 / 2; j > 0; j /= 2) {\n        if (tid < j) {\n            atomicAdd(&cache[tid], cache[tid + j]);\n        }\n\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicAdd(numEdges, cache[0]);\n    }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    int edgeCount = 0;\n    if (tid < N) {\n        for (int j = 0; j < N; j++) {\n            if (A[tid * N + j]!= 0) {\n                edgeCount++;\n            }\n        }\n    }\n    *numEdges = edgeCount;\n}",
            "int idx = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (idx < N) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tsum += A[idx * N + i];\n\t\t}\n\t\tnumEdges[idx] = sum;\n\t}\n}",
            "// TODO: Implement the kernel using the shared memory.\n\n}",
            "// TODO\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint temp = 0;\n\tif (tid < N)\n\t{\n\t\tfor (int i = tid; i < N * N; i += N)\n\t\t{\n\t\t\ttemp += A[i];\n\t\t}\n\t}\n\tatomicAdd(numEdges, temp);\n}",
            "const size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int sum = 0;\n\n    if (tid < N * N) {\n        sum = A[tid];\n    }\n\n    // atomic add to sum up all the edge values\n    atomicAdd(numEdges, sum);\n}",
            "size_t i = threadIdx.x;\n  *numEdges = 0;\n  for (size_t j = 0; j < N; j++) {\n    if (i!= j && A[i * N + j]!= 0) {\n      (*numEdges)++;\n    }\n  }\n}",
            "int sum = 0;\n    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = idx; i < N; i += stride) {\n        for (int j = 0; j < N; j++) {\n            sum += A[i * N + j];\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[tid*N + i] == 1) {\n\t\t\tsum += 1;\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int threadIndex = blockDim.x * blockIdx.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    for(int i = threadIndex; i < N; i += stride){\n        if(A[i*N+i] == 1){\n            atomicAdd(numEdges, i);\n        }\n    }\n}",
            "int myIndex = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (myIndex < N) {\n\n\t\tint temp = 0;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\n\t\t\tif (A[myIndex * N + i]) {\n\n\t\t\t\t++temp;\n\t\t\t}\n\t\t}\n\n\t\tatomicAdd(numEdges, temp);\n\t}\n}",
            "int num = 0;\n\tint row = blockIdx.x;\n\tint col = threadIdx.x;\n\tint value = A[row * N + col];\n\tif (value == 1) {\n\t\tnum++;\n\t}\n\n\t__shared__ int sdata[BLOCK_SIZE];\n\tsdata[threadIdx.x] = num;\n\t__syncthreads();\n\n\tint idx = threadIdx.x + (BLOCK_SIZE / 2);\n\tif (idx < BLOCK_SIZE / 2) {\n\t\tsdata[idx] += sdata[idx + (BLOCK_SIZE / 2)];\n\t}\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numEdges, sdata[0]);\n\t}\n}",
            "__shared__ int sum;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = i + 1;\n  sum = 0;\n\n  if (i < N && j < N) {\n    if (A[i * N + j] || A[j * N + i])\n      sum++;\n  }\n  atomicAdd(numEdges, sum);\n}",
            "/*\n\t  A[i][j] = 1 if vertex i is adjacent to vertex j, 0 otherwise\n\t  The kernel should be launched with N threads,\n\t  with each thread processing one row of A.\n\t*/\n\t\n\t/* BEGIN YOUR CODE HERE */\n\t\n\t/*\n\tint numEdges = 0;\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i * N + j] == 1) numEdges++;\n\t}\n\tatomicAdd(numEdges, numEdges);\n\t*/\n\n\t/* END YOUR CODE HERE */\n\t\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tcount += A[i*N+j];\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "// Your code here\n}",
            "int sum = 0;\n\tint i = threadIdx.x;\n\tint j = threadIdx.y;\n\n\tif (i < N && j < N) {\n\t\tsum = A[i*N + j];\n\t}\n\n\t// __syncthreads();\n\tatomicAdd(numEdges, sum);\n}",
            "// Get the thread index\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Get the row and column of the thread's adjacency matrix element\n\tint row = tid / N;\n\tint col = tid % N;\n\n\t// Initialize the number of edges to zero\n\t__shared__ int numEdgesPerBlock;\n\tif (threadIdx.x == 0)\n\t\tnumEdgesPerBlock = 0;\n\t__syncthreads();\n\n\t// Check if the thread's element is set to 1\n\tif (A[tid] == 1) {\n\t\t// Count the number of 1s in the column\n\t\tint rowSum = 0;\n\t\tfor (int i = row * N; i < (row + 1) * N; ++i)\n\t\t\trowSum += A[i];\n\n\t\t// If the column sum is 2, there is an edge\n\t\tif (rowSum == 2)\n\t\t\tatomicAdd(&numEdgesPerBlock, 1);\n\t}\n\n\t// Atomic add the number of edges in this block to the global value\n\tatomicAdd(&numEdges[0], numEdgesPerBlock);\n}",
            "const int row = blockIdx.x;\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row * N + i] == 1) {\n\t\t\tsum++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row >= N) {\n\t\treturn;\n\t}\n\n\tint sum = 0;\n\tfor (int col = 0; col < N; col++) {\n\t\tsum += A[row * N + col];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int rowIdx = blockDim.x * blockIdx.x + threadIdx.x;\n\tint count = 0;\n\tif (rowIdx < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N*i + rowIdx]) count++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n\n  __shared__ int counts[THREADS_PER_BLOCK];\n\n  counts[threadIdx.x] = 0;\n  if (row < N && col < N) {\n    if (A[row * N + col] > 0) {\n      atomicAdd(&counts[threadIdx.x], 1);\n    }\n  }\n\n  __syncthreads();\n\n  for (int stride = THREADS_PER_BLOCK / 2; stride > 0; stride >>= 1) {\n    if (threadIdx.x < stride) {\n      counts[threadIdx.x] += counts[threadIdx.x + stride];\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    atomicAdd(numEdges, counts[0]);\n  }\n}",
            "int *out = numEdges;\n  int tid = threadIdx.x;\n  if (tid < N) {\n    int start = tid * N;\n    int end = start + N;\n    int count = 0;\n    for (int i = start; i < end; i++) {\n      if (A[i] == 1) {\n        count++;\n      }\n    }\n    out[tid] = count;\n  }\n}",
            "/* Your code goes here */\n}",
            "/* Declare shared memory array for adjacency matrix */\n    extern __shared__ int sharedA[];\n    int* sA = sharedA;\n\n    /* Determine block ID and thread ID */\n    unsigned int tid = threadIdx.x;\n    unsigned int bid = blockIdx.x;\n\n    /* Copy block of adjacency matrix to shared memory */\n    if(tid < N)\n        sA[tid] = A[bid*N + tid];\n    __syncthreads();\n\n    /* Determine number of edges in block */\n    int count = 0;\n    for(unsigned int i = 0; i < N; i++)\n    {\n        int x = sA[i];\n        for(unsigned int j = 0; j < N; j++)\n        {\n            int y = sA[j];\n            if(i < j && x == y)\n            {\n                count++;\n                break;\n            }\n        }\n    }\n\n    /* Sum results from all blocks */\n    __syncthreads();\n    atomicAdd(numEdges, count);\n}",
            "int i = threadIdx.x;\n\t__shared__ int sum;\n\tsum = 0;\n\tfor (int j = 0; j < N; ++j) {\n\t\tsum += A[i*N + j];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "/* YOUR CODE HERE */\n  int i = threadIdx.x;\n  int j = threadIdx.y;\n  __shared__ int sum;\n\n  int temp = A[i * N + j];\n  if (i < N && j < N && i!= j && temp == 1) {\n    atomicAdd(&sum, 1);\n  }\n  if (blockDim.x == N && threadIdx.y == 0 && threadIdx.x == 0) {\n    numEdges[0] = sum;\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  int count = 0;\n  for (int i = tid; i < N; i += stride) {\n    int countInRow = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[N * i + j] == 1) {\n        countInRow += 1;\n      }\n    }\n    count += countInRow;\n  }\n  atomicAdd(numEdges, count);\n}",
            "int i = threadIdx.x;\n\t__shared__ int numEdgesLocal;\n\n\tif (i < N)\n\t\tnumEdgesLocal = 0;\n\t__syncthreads();\n\n\tfor (int j = i; j < N; j++)\n\t\tnumEdgesLocal += A[i*N + j];\n\t__syncthreads();\n\n\tif (i < N)\n\t\tnumEdges[0] += numEdgesLocal;\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint sum = 0;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[tid * N + i]) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i < N) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n  }\n}",
            "// TODO\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n\tint total = 0;\n\tint temp = 0;\n\tfor (int k = 0; k < N; k++) {\n\t\ttemp = A[i*N + k] + A[k*N + j];\n\t\tif (temp!= 0) {\n\t\t\ttotal++;\n\t\t}\n\t}\n\tatomicAdd(numEdges, total);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid >= N) {\n        return;\n    }\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n        sum += A[i * N + tid];\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\n  if(i < N) {\n    int count = 0;\n    for(size_t j = 0; j < N; j++) {\n      if(A[i*N + j] > 0) {\n        count++;\n      }\n    }\n    atomicAdd(numEdges, count);\n  }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row >= N) return;\n\n\tint sum = 0;\n\tfor (int col = 0; col < N; col++)\n\t\tsum += A[row * N + col];\n\n\tatomicAdd(numEdges, sum);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tint numEdges_ = 0;\n\tfor (int i = index; i < N; i += stride) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tnumEdges_ += A[i * N + j];\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, numEdges_);\n\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[idx * N + i])\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x;\n\tint row = A[i*N+i];\n\tfor (int j=0; j<N; j++) {\n\t\tif ((i < N-1 && A[i*N+j]!= 0) || (i == N-1 && A[j]!= 0)) {\n\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "// your code here\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i < N && j < N && i < j && A[i*N+j]) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "// TODO: add code here\n\n}",
            "int i = threadIdx.x;\n\tint sum = 0;\n\n\tif (i < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tsum += 1;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, sum);\n\t}\n}",
            "int numLocalEdges = 0;\n\tint i = blockDim.x*blockIdx.x + threadIdx.x;\n\tint j = blockDim.y*blockIdx.y + threadIdx.y;\n\tif (i < N && j < N) {\n\t\tif (i!=j && A[i*N + j])\n\t\t\tnumLocalEdges++;\n\t}\n\n\tatomicAdd(numEdges, numLocalEdges);\n}",
            "int start = threadIdx.x;\n\tint stride = blockDim.x;\n\tint count = 0;\n\n\tfor (int i = start; i < N; i += stride) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int row = blockIdx.x*blockDim.x + threadIdx.x;\n\n\tif(row<N) {\n\t\tint sum=0;\n\t\tfor(int col=0; col<N; col++)\n\t\t\tif(A[row*N+col]==1)\n\t\t\t\tsum++;\n\t\t*(numEdges+row) = sum;\n\t}\n\n}",
            "__shared__ int s_A[TILE_WIDTH][TILE_WIDTH];\n  __shared__ int s_counter[TILE_WIDTH][TILE_WIDTH];\n\n  // Calculate the global row index and column index\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n  // Copy the data from global memory to shared memory\n  s_A[threadIdx.x][threadIdx.y] = A[row*N + col];\n  s_counter[threadIdx.x][threadIdx.y] = 0;\n\n  // Synchronize the threads in this block\n  __syncthreads();\n\n  // Calculate the number of neighbors for the current vertex\n  for(int i=0; i<TILE_WIDTH; i++){\n    if(s_A[threadIdx.x][i] == 1){\n      s_counter[threadIdx.x][threadIdx.y] += 1;\n    }\n  }\n\n  // Synchronize the threads in this block\n  __syncthreads();\n\n  // The number of neighbors for the current vertex is only valid if it is in the\n  // upper triangle part of the matrix (excluding diagonal)\n  if(col > row){\n    atomicAdd(numEdges, s_counter[threadIdx.x][threadIdx.y]);\n  }\n\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  size_t j = i;\n\n  // Check to make sure i is in bounds for the NxN matrix\n  if (i < N * N) {\n    // Check to see if the cell at i is an edge.\n    if (A[i] == 1) {\n      // If it is an edge, increment the number of edges variable\n      atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "int sum = 0;\n    int i = blockIdx.x;\n    int j = threadIdx.x;\n\n    if(A[i*N + j] == 1)\n        atomicAdd(numEdges, 1);\n\n}",
            "// Your code here\n\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n    int size = blockDim.x * gridDim.x;\n    int sum = 0;\n    for (size_t i = id; i < N; i += size) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[i * N + j] == 1) {\n                sum++;\n            }\n        }\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int col = threadIdx.x;\n\tint row = blockIdx.x;\n\tint sum = 0;\n\n\tif (col >= N || row >= N) return;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row * N + i] == 1 && A[col * N + i] == 1)\n\t\t\tsum++;\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "// Your code here.\n\n}",
            "// use CUDA to calculate the number of edges in the graph\n  // store the result in numEdges\n  int t_idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int count = 0;\n\n  for(int i = 0; i < N; i++){\n    for(int j = 0; j < N; j++){\n      if(i!= j && A[t_idx*N+j] > 0 && A[t_idx*N+i] > 0){\n        count++;\n      }\n    }\n  }\n\n  if (t_idx == 0) {\n    atomicAdd(numEdges, count);\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif(i < N){\n\t\tint sum = 0;\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tsum += A[i * N + j];\n\t\t}\n\t\tnumEdges[i] = sum;\n\t}\n}",
            "// TODO: Your code goes here\n\t\n}",
            "int sum = 0;\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = gridDim.x * blockDim.x;\n\n  // TODO: write your kernel\n\n  __syncthreads();\n\n  atomicAdd(numEdges, sum);\n}",
            "// Insert code here\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n  int count = 0;\n  for (int row = 0; row < N; row++) {\n    count += A[row * N + col];\n  }\n  __syncthreads();\n  atomicAdd(numEdges, count);\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid >= N) return;\n\n    for (int i = 0; i < N; i++) {\n        if (A[tid*N + i] > 0) {\n            atomicAdd(numEdges, 1);\n        }\n    }\n}",
            "int globalId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint sum = 0;\n\tint i;\n\tfor (i = 0; i < N; i++) {\n\t\tsum += A[i * N + globalId];\n\t}\n\tsum -= A[globalId * N + globalId];\n\tif (sum % 2 == 1) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "int i, j;\n  i = blockIdx.x * blockDim.x + threadIdx.x;\n  j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if ((i<N) && (j<N)) {\n    if (A[i*N+j] == 1) {\n      atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "// Each thread computes one element of the adjacency matrix\n\tint id = threadIdx.x;\n\tint count = 0;\n\tif (id < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[id*N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\t// Store the result in numEdges\n\tif (id == 0) {\n\t\t*numEdges = count;\n\t}\n}",
            "__shared__ int cache[THREADS_PER_BLOCK];\n  int thread_id = threadIdx.x + blockIdx.x * blockDim.x;\n  cache[threadIdx.x] = 0;\n\n  if (thread_id < N) {\n    for (int i = thread_id; i < N; i += blockDim.x * gridDim.x) {\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j]) {\n          cache[threadIdx.x] += 1;\n        }\n      }\n    }\n  }\n\n  __syncthreads();\n  if (thread_id < N) {\n    for (int i = 1; i < blockDim.x; i *= 2) {\n      if (threadIdx.x % (2 * i) == 0) {\n        cache[threadIdx.x] += cache[threadIdx.x + i];\n      }\n      __syncthreads();\n    }\n\n    atomicAdd(numEdges, cache[0]);\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\tint count = 0;\n\tif (i < N && j < N) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[i * N + k] && A[k * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "__shared__ int s_count[THREADS_PER_BLOCK];\n\tconst int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int gridSize = blockDim.x * gridDim.x;\n\ts_count[threadIdx.x] = 0;\n\tfor (int i = tid; i < N; i += gridSize) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\ts_count[threadIdx.x] += A[i * N + j];\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// reduction\n\tif (threadIdx.x < 32) {\n\t\tfor (int i = 16; i > 0; i >>= 1) {\n\t\t\ts_count[threadIdx.x] += s_count[threadIdx.x + i];\n\t\t}\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\t*numEdges = s_count[0];\n\t}\n}",
            "// Use an atomic add to update *numEdges with the count of edges in A\n\t// Hint: Atomic operations can only be used in device code\n\tatomicAdd(numEdges, 0);\n}",
            "__shared__ int counter;\n  __shared__ int numThreads;\n  __shared__ int *threadCounter;\n  if (threadIdx.x == 0) {\n    counter = 0;\n    numThreads = blockDim.x;\n    threadCounter = (int*)malloc(numThreads*sizeof(int));\n    for (int i=0; i<numThreads; i++) {\n      threadCounter[i] = 0;\n    }\n  }\n  __syncthreads();\n  int i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i < N*N) {\n    threadCounter[threadIdx.x] = threadCounter[threadIdx.x] + A[i];\n  }\n  __syncthreads();\n  for (int s=numThreads/2; s>0; s>>=1) {\n    if (threadIdx.x < s) {\n      threadCounter[threadIdx.x] = threadCounter[threadIdx.x] + threadCounter[threadIdx.x + s];\n    }\n    __syncthreads();\n  }\n  if (threadIdx.x == 0) {\n    counter = counter + threadCounter[threadIdx.x];\n  }\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    *numEdges = counter;\n    free(threadCounter);\n  }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tint laneID = threadIdx.x % 32;\n\tint warpID = threadIdx.x / 32;\n\tint mysum = 0;\n\tint mycount;\n\tint laneIDcount;\n\tint myresult;\n\t\n\tfor (int i = tid; i < N; i += gridDim.x*blockDim.x)\n\t{\n\t\tint temp = A[i*N + i];\n\t\tmysum = mysum + temp;\n\t}\n\t\n\tmycount = __popc(mysum);\n\n\t\n\t\n\t\n\t//laneIDcount = __shfl_down_sync(0xFFFFFFFF, mycount, 16);\n\t//laneIDcount = __shfl_down_sync(0xFFFFFFFF, mycount, 8);\n\t//laneIDcount = __shfl_down_sync(0xFFFFFFFF, mycount, 4);\n\t//laneIDcount = __shfl_down_sync(0xFFFFFFFF, mycount, 2);\n\t//laneIDcount = __shfl_down_sync(0xFFFFFFFF, mycount, 1);\n\tlaneIDcount = __shfl_sync(0xFFFFFFFF, mycount, laneID + 16, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID + 8, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID + 4, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID + 2, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID + 1, 32);\n\t\n\tif(laneID == 0)\n\t{\n\t\tmyresult = mycount + laneIDcount;\n\t\tatomicAdd(numEdges, myresult);\n\t}\n\t\n\t//laneIDcount = __shfl_up_sync(0xFFFFFFFF, mycount, 1, 32);\n\t//laneIDcount += __shfl_up_sync(0xFFFFFFFF, mycount, 2, 32);\n\t//laneIDcount += __shfl_up_sync(0xFFFFFFFF, mycount, 4, 32);\n\t//laneIDcount += __shfl_up_sync(0xFFFFFFFF, mycount, 8, 32);\n\t//laneIDcount += __shfl_up_sync(0xFFFFFFFF, mycount, 16, 32);\n\tlaneIDcount = __shfl_sync(0xFFFFFFFF, mycount, laneID - 1, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID - 2, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID - 4, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID - 8, 32);\n\tlaneIDcount += __shfl_sync(0xFFFFFFFF, mycount, laneID - 16, 32);\n\n\tif(laneID == 31)\n\t{\n\t\tmyresult = mycount + laneIDcount;\n\t\tatomicAdd(numEdges, myresult);\n\t}\n\t\n\t\n\t\n\t\n\t\n\t//__syncthreads();\n\t\n\t//int myresult = __shfl_sync(0xFFFFFFFF, mycount, 0, 32);\n\t//int myresult = __shfl_sync(0xFFFFFFFF, mycount, 16, 32);\n\t//int myresult = __shfl_sync(0xFFFFFFFF, mycount, 8, 32);\n\t//int myresult = __shfl_sync(0xFFFFFFFF, mycount, 4, 32);\n\t//int myresult = __shfl_sync(0xFFFFFFFF, mycount, 2, 32);\n\t//int myresult = __sh",
            "// TODO\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx < N) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tcount += A[idx*N + j];\n\t\t}\n\t\t*numEdges += count;\n\t}\n}",
            "int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (threadID < N) {\n\t\tint count = 0;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[i * N + threadID] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Each thread will count the edges from its column of A.\n\tif (i < N) {\n\t\tint count = 0;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tcount += A[i * N + j];\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "const int tid = threadIdx.x;\n\t__shared__ int s[100]; // shared memory\n\tif (tid < N) {\n\t\ts[tid] = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N*tid + i])\n\t\t\t\ts[tid]++;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tfor (int i = 50; i > 0; i >>= 1) {\n\t\tif (tid < i)\n\t\t\ts[tid] += s[tid + i];\n\t\t__syncthreads();\n\t}\n\tif (tid == 0) {\n\t\t*numEdges = s[0];\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint totalEdges = 0;\n\tfor (int i = tid; i < N; i += stride) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\ttotalEdges += 1;\n\t\t\t}\n\t\t}\n\t}\n\t// Set the output value to the number of edges in the graph\n\tif (tid == 0) {\n\t\t*numEdges = totalEdges;\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tcount += A[tid*N+i];\n\t\t*(numEdges + tid) = count;\n\t}\n}",
            "int sum = 0;\n\tint numThreads = blockDim.x;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint n = N / numThreads;\n\n\tfor (int i = 0; i < n; i++) {\n\t\tif (A[tid * N + i] == 1) {\n\t\t\tsum++;\n\t\t}\n\t}\n\n\t__shared__ int s[1024];\n\n\tif (sum!= 0) {\n\t\tatomicAdd(s, sum);\n\t}\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numEdges, s[0]);\n\t}\n}",
            "// Write your code here.\n\t__shared__ int s_sum[1024];\n\tunsigned int tid = threadIdx.x;\n\tunsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tunsigned int grid_size = blockDim.x * gridDim.x;\n\n\tint mySum = 0;\n\tfor (; i < N * N; i += grid_size)\n\t{\n\t\tif (i % N!= i / N)\n\t\t{\n\t\t\tmySum += A[i];\n\t\t}\n\t}\n\n\ts_sum[tid] = mySum;\n\t__syncthreads();\n\tif (blockDim.x >= 512)\n\t{\n\t\tif (tid < 256)\n\t\t{\n\t\t\ts_sum[tid] += s_sum[tid + 256];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (blockDim.x >= 256)\n\t{\n\t\tif (tid < 128)\n\t\t{\n\t\t\ts_sum[tid] += s_sum[tid + 128];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (blockDim.x >= 128)\n\t{\n\t\tif (tid < 64)\n\t\t{\n\t\t\ts_sum[tid] += s_sum[tid + 64];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (tid < 32)\n\t{\n\t\tvolatile int *vsum = s_sum;\n\t\tif (blockDim.x >= 64)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 32];\n\t\t}\n\t\tif (blockDim.x >= 32)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 16];\n\t\t}\n\t\tif (blockDim.x >= 16)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 8];\n\t\t}\n\t\tif (blockDim.x >= 8)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 4];\n\t\t}\n\t\tif (blockDim.x >= 4)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 2];\n\t\t}\n\t\tif (blockDim.x >= 2)\n\t\t{\n\t\t\tvsum[tid] += vsum[tid + 1];\n\t\t}\n\t}\n\n\tif (tid == 0)\n\t{\n\t\tnumEdges[blockIdx.x] = s_sum[0];\n\t}\n}",
            "int i = blockIdx.x;\n  int j = threadIdx.x;\n\n  if(i >= N || j >= N) {\n    return;\n  }\n\n  if (i == j) {\n    return;\n  }\n\n  // If A[i][j] == 1, then there is an edge from vertex i to vertex j\n  // If A[i][j] == 0, then there is no edge from vertex i to vertex j\n\n  if(A[i * N + j] == 1) {\n    atomicAdd(numEdges, 1);\n  }\n}",
            "const int tid = blockDim.x*blockIdx.x + threadIdx.x;\n  if (tid < N) {\n    for (int i = 0; i < N; ++i) {\n      if (A[i*N + tid]!= 0)\n        atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "}",
            "__shared__ int numEdgesShared;\n\tnumEdgesShared = 0;\n\n\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i >= N) return;\n\n\t// Sum up the number of 1s in the row.\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tnumEdgesShared++;\n\t\t}\n\t}\n\n\t// Copy the sum from shared memory back to global memory.\n\t// Note that this is a very slow operation and the reason why this kernel is\n\t// slow.\n\t__syncthreads();\n\tif (threadIdx.x == 0) {\n\t\t*numEdges += numEdgesShared;\n\t}\n}",
            "int colId = blockIdx.x * blockDim.x + threadIdx.x;\n  int rowId = blockIdx.y * blockDim.y + threadIdx.y;\n  int threadId = threadIdx.x + threadIdx.y * blockDim.x;\n\n  __shared__ int numThreads;\n\n  if (threadId == 0) {\n    numThreads = blockDim.x * blockDim.y;\n  }\n\n  __syncthreads();\n\n  for (int i = 0; i < numThreads; i++) {\n    if (colId < N && rowId < N) {\n      if (A[rowId * N + colId] == 1) {\n        atomicAdd(numEdges, 1);\n      }\n    }\n    colId += blockDim.x;\n  }\n}",
            "size_t tid = threadIdx.x;\n\n  // Load the element at the thread's location into local memory.\n  int myElement = A[tid];\n\n  // Use shared memory to perform an intermediate sum.\n  extern __shared__ int partialSums[];\n  partialSums[tid] = myElement;\n\n  // Wait for the block to finish all memory operations.\n  __syncthreads();\n\n  // Perform a summation of the elements in the block.\n  // The final value in partialSums[0] will contain the result.\n  for (int offset = 1; offset < N; offset *= 2) {\n    __syncthreads();\n    if (tid + offset < N) {\n      partialSums[tid] += partialSums[tid + offset];\n    }\n  }\n\n  // Load the final result into global memory.\n  if (tid == 0) {\n    numEdges[blockIdx.x] = partialSums[0];\n  }\n}",
            "*numEdges = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] > 0) {\n                (*numEdges)++;\n            }\n        }\n    }\n}",
            "// TODO\n}",
            "int sum = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j])\n\t\t\t\tsum += 1;\n\t\t}\n\t}\n\t*numEdges = sum;\n}",
            "const int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (id >= N) return;\n\t// TODO\n\n\t__syncthreads();\n\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tsum += A[i * N + id];\n\t}\n\tnumEdges[id] = sum;\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n\n  // Initialize shared memory.\n  __shared__ int rowCount[BLOCK_SIZE];\n  __shared__ int numEdgesShared;\n  int numEdgesBlock = 0;\n  int *colRowPtr = rowCount;\n\n  // Thread 0 for each row sets the shared memory row count to 0.\n  if(threadIdx.x == 0) {\n    *numEdges = 0;\n    rowCount[row] = 0;\n  }\n\n  // Wait for shared memory to be initialized.\n  __syncthreads();\n\n  // Each thread adds to its row count if it is a neighbor.\n  // If it is a neighbor, it must also write the total to shared memory.\n  if(col < N) {\n    if(A[row * N + col]) {\n      atomicAdd(&rowCount[row], 1);\n      numEdgesBlock += 1;\n    }\n  }\n\n  // Wait for all threads to write to shared memory.\n  __syncthreads();\n\n  // Thread 0 for each row adds the row count to the total edge count.\n  if(threadIdx.x == 0) {\n    atomicAdd(&numEdgesShared, rowCount[row]);\n  }\n\n  // Wait for all threads to write to shared memory.\n  __syncthreads();\n\n  // Thread 0 adds its block edge count to the total edge count in shared memory.\n  if(threadIdx.x == 0) {\n    atomicAdd(numEdges, numEdgesShared);\n  }\n}",
            "// TODO: implement\n\n}",
            "// Find the start of each row in the adjacency matrix\n\tint rowStart = (blockIdx.x * blockDim.x) * N;\n\n\t// Store the result in the first element of numEdges\n\tint num = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tnum += A[rowStart + i];\n\t}\n\tnumEdges[0] += num / 2;\n}",
            "int row = blockDim.x * blockIdx.x + threadIdx.x;\n\tint col = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (row < N && col < N)\n\t\tif (A[row * N + col]!= 0)\n\t\t\tatomicAdd(numEdges, 1);\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int count = 0;\n\n    if (i < N) {\n        for (int j = 0; j < N; j++)\n            if (A[i*N + j])\n                count++;\n\n        atomicAdd(numEdges, count);\n    }\n}",
            "// Your code here\n    __shared__ int blockSum[BLOCKSIZE];\n\n    // 1. Calculate local sum\n    int lSum = 0;\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    if (x < N && y < N) {\n        lSum = A[x * N + y];\n    }\n\n    // 2. Sum up local sums\n    int i = threadIdx.y;\n    int j = threadIdx.x;\n    for (; i < BLOCKSIZE && j < BLOCKSIZE; i *= 2, j *= 2) {\n        int lSumTemp = __shfl_down_sync(0xFFFFFFFF, lSum, i, BLOCKSIZE);\n        if (j < i)\n            lSum += lSumTemp;\n    }\n\n    // 3. Store local sum in shared memory\n    if (threadIdx.y == 0 && threadIdx.x < BLOCKSIZE)\n        blockSum[threadIdx.x] = lSum;\n    __syncthreads();\n\n    // 4. Sum up local sums\n    i = blockIdx.x * blockDim.x + threadIdx.x;\n    j = blockIdx.y * blockDim.y + threadIdx.y;\n    int idx = threadIdx.x;\n    for (; i < N && j < N; i *= 2, j *= 2, idx = threadIdx.y * BLOCKSIZE + threadIdx.x) {\n        int lSumTemp = __shfl_down_sync(0xFFFFFFFF, blockSum[idx], 1, BLOCKSIZE);\n        if (idx % 2 == 0)\n            blockSum[idx] += lSumTemp;\n    }\n\n    // 5. Store global sum in global memory\n    if (blockIdx.x == 0 && blockIdx.y == 0 && threadIdx.y == 0 && threadIdx.x < BLOCKSIZE)\n        *numEdges += blockSum[threadIdx.x];\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tif (i < N) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0)\n\t\t\t\tcount++;\n\t\t}\n\t\t*numEdges = count;\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (i!= tid && A[tid * N + i] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TO DO\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint cnt = 0;\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tcnt += A[i*N + j];\n\t\tnumEdges[i] = cnt;\n\t}\n}",
            "// Store the thread's ID in a variable\n\tint index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// If we're not on the last row of the matrix, we can count\n\t// the number of edges\n\tif (index < N * N) {\n\t\t// Count the number of edges\n\t\tatomicAdd(numEdges, A[index]);\n\t}\n\n\t// Don't do anything else\n\treturn;\n}",
            "__shared__ int myEdges;\n  int id = blockIdx.x * blockDim.x + threadIdx.x;\n  myEdges = 0;\n  if(id < N){\n    for(size_t i = 0; i < N; i++){\n      if(A[i*N + id] == 1){\n        myEdges++;\n      }\n    }\n  }\n  atomicAdd(&numEdges[0], myEdges);\n}",
            "int sum = 0;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tsum += A[tid * N + i];\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "__shared__ int count[THREADS_PER_BLOCK];\n\n    int i = blockIdx.x*blockDim.x + threadIdx.x;\n    int j = blockIdx.y*blockDim.y + threadIdx.y;\n\n    if (i < N && j < N) {\n        int adj = A[i*N + j];\n        count[threadIdx.y] += adj;\n    }\n\n    __syncthreads();\n\n    if (threadIdx.y == 0) {\n        atomicAdd(numEdges, count[threadIdx.x]);\n    }\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n\t// int id = threadIdx.x;\n\tint count = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = i + 1; j < N; j++) {\n\t\t\tif(A[i * N + j]!= 0 || A[j * N + i]!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if(i < N) {\n    for(int j = 0; j < N; j++) {\n      if(A[i * N + j]!= 0)\n        atomicAdd(numEdges, 1);\n    }\n  }\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // count the number of edges\n    if (A[col] == 1)\n        atomicAdd(numEdges, 1);\n}",
            "int sum = 0;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tcount = gridDim.x * blockDim.x;\n\tfor (size_t i = tid; i < N; i += tcount) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int tid = threadIdx.x;\n\n  if (tid == 0) {\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n      sum += A[tid * N + i];\n    }\n    *numEdges = sum;\n  }\n}",
            "size_t index = threadIdx.x;\n\n  // For each row\n  if (index < N) {\n    // For each column in that row\n    int localEdges = 0;\n    for (size_t j = 0; j < N; j++) {\n      localEdges += A[index * N + j];\n    }\n\n    // Update the global counter\n    atomicAdd(numEdges, localEdges);\n  }\n}",
            "const int n = N;\n  const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  __shared__ int s[BLOCK_SIZE];\n  int t;\n  int temp = 0;\n  for (int i = tid; i < n; i += blockDim.x * gridDim.x) {\n    t = 0;\n    for (int j = 0; j < n; j++) {\n      t += A[i*n+j];\n    }\n    temp += t;\n  }\n  s[threadIdx.x] = temp;\n  __syncthreads();\n  if (threadIdx.x == 0) {\n    for (int i = 1; i < blockDim.x; i++) {\n      s[0] += s[i];\n    }\n    atomicAdd(numEdges, s[0]);\n  }\n}",
            "/* TODO: Replace me! */\n  /*\n   * The code is written to be used with a 2D block, i.e.\n   * <<<gridSize, blockSize>>>.\n   * gridSize is computed as\n   * gridSize = (N + blockSize.x - 1) / blockSize.x\n   * blockSize.x is expected to be equal to blockSize.y.\n   */\n  const int x = blockIdx.x * blockDim.x + threadIdx.x;\n  if (x < N) {\n    int result = 0;\n    for (int y = 0; y < N; ++y) {\n      result += A[x * N + y];\n    }\n    atomicAdd(numEdges, result);\n  }\n}",
            "int tId = threadIdx.x;\n\tint tNum = blockDim.x;\n\tint laneId = tId % warpSize;\n\tint i, j;\n\t\n\t__shared__ int totalNumEdges;\n\tif (tId == 0) {\n\t\ttotalNumEdges = 0;\n\t}\n\t__syncthreads();\n\n\tfor (i = tId; i < N; i += tNum) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tatomicAdd(&totalNumEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n\t\n\tatomicAdd(&numEdges[0], totalNumEdges);\n}",
            "int threadIdx = threadIdx.x;\n    int blockDim = blockDim.x;\n    int blockIdx = blockIdx.x;\n    int idx = blockIdx * blockDim + threadIdx;\n\n    __shared__ int numEdges_shared[N];\n    __shared__ int temp[N];\n\n    // Initialize numEdges_shared[threadIdx] to zero\n    numEdges_shared[threadIdx] = 0;\n\n    // Copy A[idx] into temp[threadIdx]\n    temp[threadIdx] = A[idx];\n\n    // Wait for all threads in the block to finish\n    __syncthreads();\n\n    // Use a block-wide reduction to add up all values in numEdges_shared\n    for (int i = 1; i < blockDim; i *= 2) {\n        if (threadIdx >= i) {\n            numEdges_shared[threadIdx] += numEdges_shared[threadIdx - i];\n        }\n        __syncthreads();\n    }\n\n    // Write numEdges_shared[threadIdx] into numEdges[blockIdx]\n    if (threadIdx == 0) {\n        atomicAdd(numEdges, numEdges_shared[threadIdx]);\n    }\n}",
            "// YOUR CODE HERE\n\n    int idx = threadIdx.x;\n    int num_threads = blockDim.x;\n    __shared__ int edges[256];\n\n    if (idx < N) {\n        int edges = 0;\n        for (int i = 0; i < N; i++) {\n            if (A[idx * N + i] == 1) {\n                edges++;\n            }\n        }\n        edges[idx] = edges;\n    }\n    __syncthreads();\n\n    if (idx == 0) {\n        for (int i = 1; i < num_threads; i++) {\n            edges[0] += edges[i];\n        }\n        *numEdges = edges[0];\n    }\n}",
            "// This kernel can be done in parallel\n    int sum = 0;\n    int row = blockIdx.x;\n    int col = threadIdx.x;\n    if(row < N && col < N){\n        sum = A[row*N + col];\n    }\n    atomicAdd(numEdges, sum);\n}",
            "int tid = threadIdx.x;\n\tint n = blockDim.x;\n\n\t// We use n/2 threads to process one row\n\tint r = tid / (n/2);\n\tint c = tid % (n/2);\n\n\t__shared__ int sharedA[16][16];\n\tif (r < N) {\n\t\tsharedA[r][c] = A[r*N + c];\n\t\tsharedA[r][c + n/2] = A[r*N + c + n/2];\n\t}\n\n\t__syncthreads();\n\n\t// We use 2 threads to process one element\n\tint i = tid / 2;\n\tint j = tid % 2;\n\n\tif (i < n/2 && j < n/2) {\n\t\tint sum = sharedA[i][j] + sharedA[i][j + 1] + sharedA[i + 1][j] + sharedA[i + 1][j + 1];\n\t\tif (sum == 1) {\n\t\t\tatomicAdd(numEdges, 1);\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = gridDim.x * blockDim.x;\n  int count = 0;\n\n  for (int i = tid; i < N; i += stride) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0) {\n        count++;\n      }\n    }\n  }\n  atomicAdd(numEdges, count);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (i == tid) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (A[tid * N + i] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "// Use the threadId to get the right row.\n\tint row = threadIdx.x;\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[row*N + i] == 1) {\n\t\t\tcount += 1;\n\t\t}\n\t}\n\n\t// Store the number of edges.\n\t__syncthreads();\n\tatomicAdd(numEdges, count);\n}",
            "int tid = threadIdx.x;\n    int i = tid;\n    int j;\n\n    extern __shared__ int numEdge[];\n    extern __shared__ int visited[];\n    extern __shared__ int count[];\n    for(j = 0; j < N; j++) {\n        numEdge[j] = 0;\n        visited[j] = 0;\n        count[j] = 0;\n    }\n    for(j = 0; j < N; j++) {\n        if(A[i*N + j]!= 0) {\n            count[j] = 1;\n        }\n    }\n\n    int flag = 0;\n    while(flag!= 1) {\n        flag = 1;\n        __syncthreads();\n        for(j = 0; j < N; j++) {\n            if(count[j] == 0) {\n                numEdge[j]++;\n                visited[j] = 1;\n                flag = 0;\n                break;\n            }\n        }\n        __syncthreads();\n        for(j = 0; j < N; j++) {\n            if(visited[j] == 1) {\n                count[j] = 0;\n                visited[j] = 0;\n            }\n        }\n    }\n    __syncthreads();\n    int sum = 0;\n    for(j = 0; j < N; j++) {\n        sum += numEdge[j];\n    }\n    numEdges[0] = sum;\n}",
            "}",
            "int col = blockIdx.x;\n    int row = threadIdx.x;\n    int c = col * N + row;\n    __shared__ int s[32];\n    int threadNum = threadIdx.x;\n    int count = 0;\n    while (col < N) {\n        if (col < N && row < N && A[c] == 1)\n            count++;\n        s[threadNum] = count;\n        __syncthreads();\n        for (int j = 16; j >= 1; j >>= 1) {\n            if (threadNum < j) {\n                s[threadNum] += s[threadNum + j];\n            }\n            __syncthreads();\n        }\n        if (threadNum == 0) {\n            numEdges[blockIdx.x] = s[0];\n        }\n        col += blockDim.x;\n        row += blockDim.y;\n        c = col * N + row;\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i < j && A[i * N + j] == 1) {\n\t\t\t\tatomicAdd(numEdges, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int tid = threadIdx.x;\n  if (tid >= N) return;\n\n  __shared__ int sum[1024];\n  sum[tid] = 0;\n  for (int i = tid; i < N; i += blockDim.x) {\n    sum[tid] += A[i * N + tid];\n  }\n  __syncthreads();\n\n  for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (tid < s) sum[tid] += sum[tid + s];\n    __syncthreads();\n  }\n\n  if (tid == 0)\n    *numEdges = sum[0];\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint rowStart = tid*N;\n\t\tint rowEnd = rowStart + N;\n\t\tint sum = 0;\n\t\tfor (int i = rowStart; i < rowEnd; ++i) {\n\t\t\tsum += A[i];\n\t\t}\n\t\t*numEdges += sum;\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tint edges = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j]!= 0) {\n\t\t\t\tedges++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numEdges, edges);\n\t}\n}",
            "__shared__ int shared_A[BLOCK_SIZE];\n  int i, j, count = 0, index;\n\n  for (i = 0; i < N; i += BLOCK_SIZE) {\n    index = blockIdx.x * blockDim.x + threadIdx.x;\n    if (index < N) {\n      shared_A[threadIdx.x] = A[index * N + i];\n    }\n    __syncthreads();\n\n    for (j = i; j < N; j++) {\n      if (shared_A[threadIdx.x] > 0 && A[threadIdx.x * N + j] > 0) {\n        count++;\n      }\n    }\n  }\n  __syncthreads();\n  atomicAdd(numEdges, count);\n}",
            "size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n    if (i < N) {\n        int sum = 0;\n        for (int j = 0; j < N; j++) {\n            sum += A[i * N + j];\n        }\n        numEdges[i] = sum;\n    }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint sum = 0;\n\tint i, j;\n\tfor (i = 0; i < N; i++) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "int sum = 0;\n  int r = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (r >= N) {\n    return;\n  }\n\n  for (int c = 0; c < N; ++c) {\n    if (A[r * N + c] == 1) {\n      sum += 1;\n    }\n  }\n\n  atomicAdd(numEdges, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint start = i * N;\n\tint end = start + N;\n\tint edges = 0;\n\n\tfor (int k = start; k < end; ++k) {\n\t\tif (A[k] == 1) {\n\t\t\t++edges;\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, edges);\n}",
            "__shared__ int sdata[64];\n\tconst int myIndex = threadIdx.x + blockIdx.x * blockDim.x;\n\tint i = myIndex / N;\n\tint j = myIndex % N;\n\tint sum = 0;\n\tif (i < N && j < N && i!= j) {\n\t\tsum += A[i * N + j];\n\t}\n\tsdata[threadIdx.x] = sum;\n\t__syncthreads();\n\n\t// perform parallel reduction\n\tfor (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n\t\tif (threadIdx.x < s) {\n\t\t\tsdata[threadIdx.x] += sdata[threadIdx.x + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\tnumEdges[blockIdx.x] = sdata[0];\n\t}\n}",
            "__shared__ int shared[128]; // use a shared array of 128 integers\n\tint i = blockIdx.x * blockDim.x + threadIdx.x; // compute the index of each thread\n\tint count = 0;\n\tif(i < N) {\n\t\t// compute the number of neighbors\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t\tshared[threadIdx.x] = count; // put the count in shared memory\n\t}\n\telse {\n\t\tshared[threadIdx.x] = 0;\n\t}\n\t__syncthreads(); // make sure that the shared array has been written\n\t// use a shared array of 128 integers\n\t// to count the number of edges\n\tint blockSize = blockDim.x;\n\twhile (blockSize > 0) {\n\t\tint k = blockSize / 2;\n\t\tif (threadIdx.x < k) {\n\t\t\tshared[threadIdx.x] += shared[threadIdx.x + k];\n\t\t}\n\t\t__syncthreads();\n\t\tblockSize = k;\n\t}\n\tif (threadIdx.x == 0) {\n\t\tnumEdges[blockIdx.x] = shared[0];\n\t}\n}",
            "int i, j;\n  int sum = 0;\n\n  for (i = blockIdx.x; i < N; i += gridDim.x) {\n    for (j = 0; j < N; j++) {\n      if (A[i * N + j])\n        sum++;\n    }\n  }\n  atomicAdd(numEdges, sum);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n    if (tid < N) {\n        int i = 0;\n        int j = 0;\n        while (i < N && j < N) {\n            int e = 0;\n            for (j = 0; j < N; j++) {\n                e = e + A[i*N + j];\n            }\n            if (e > 0)\n                atomicAdd(numEdges, 1);\n            i++;\n        }\n    }\n}",
            "int tid = threadIdx.x;\n\tint count = 0;\n\tfor (int i = tid; i < N; i += blockDim.x) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numEdges, count);\n}",
            "size_t x = blockIdx.x * blockDim.x + threadIdx.x;\n    int sum = 0;\n    if (x >= N) return;\n\n    for (size_t y = 0; y < N; y++) {\n        sum += A[y*N + x];\n    }\n\n    if (sum > 0)\n        atomicAdd(numEdges, 1);\n}",
            "__shared__ int sum[1024];\n  sum[threadIdx.x] = 0;\n\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int bid = blockIdx.x;\n  int nThreads = blockDim.x * gridDim.x;\n  // The thread is responsible for a certain number of edges\n  int numThreadEdges = (N * (N - 1)) / (nThreads) + 1;\n  // The thread is responsible for a certain number of rows in the matrix\n  int numThreadRows = N / nThreads + 1;\n  // Starting index of the row\n  int row = tid * numThreadRows;\n\n  for (int i = 0; i < numThreadEdges; i++) {\n    // Avoid out of bounds\n    if (row < N && row + numThreadRows > N) {\n      break;\n    }\n    // For each row, loop through all columns\n    for (int j = 0; j < N; j++) {\n      // Avoid out of bounds\n      if (row + i / N < N && j < N) {\n        // If the element in the matrix is 1, add to the sum\n        if (A[row * N + j] == 1) {\n          sum[threadIdx.x]++;\n        }\n      }\n    }\n    row += numThreadRows;\n  }\n\n  __syncthreads();\n\n  if (bid == 0) {\n    int sumTotal = 0;\n    for (int i = 0; i < blockDim.x; i++) {\n      sumTotal += sum[i];\n    }\n    *numEdges = sumTotal;\n  }\n}",
            "// TODO: implement edgeCount\n\t// Assume that the number of threads equals the number of vertices\n\tint id = blockDim.x * blockIdx.x + threadIdx.x;\n\tint sum = 0;\n\tfor (int i = id; i < N*N; i += blockDim.x*gridDim.x) {\n\t\tif (i%N == id)\n\t\t\tsum += A[i];\n\t}\n\tatomicAdd(numEdges, sum);\n}",
            "// TODO\n\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // tid is the global thread index\n  int thread_num = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1 && i < j) {\n        thread_num += 1;\n      }\n    }\n  }\n  *numEdges = thread_num;\n}",
            "//...\n}",
            "int id = threadIdx.x;\n  int row = id / N;\n  int col = id % N;\n  int sum = 0;\n  __shared__ int mySum[BLOCK_SIZE];\n\n  if (row < N && col < N) {\n    sum = A[row * N + col];\n  }\n  mySum[threadIdx.x] = sum;\n\n  __syncthreads();\n\n  for (int s = BLOCK_SIZE / 2; s > 0; s = s / 2) {\n    if (threadIdx.x < s) {\n      mySum[threadIdx.x] += mySum[threadIdx.x + s];\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    numEdges[blockIdx.x] = mySum[0];\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint temp = 0;\n\tif (i < N && j < N && A[i * N + j] > 0) {\n\t\tatomicAdd(numEdges, 1);\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int myCount = 0;\n  if (tid < N) {\n    for (int i = tid; i < N; i += N) {\n      for (int j = 0; j < N; j++) {\n        myCount += A[tid * N + j] * A[i * N + j];\n      }\n    }\n  }\n  // Add the counts together using atomicAdd.\n  atomicAdd(numEdges, myCount);\n}",
            "int tid = threadIdx.x;\n\tint i = tid;\n\tif (i < N) {\n\t\tint count = 0;\n\t\twhile (i < N) {\n\t\t\tif (A[i] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\ti += blockDim.x;\n\t\t}\n\t\tatomicAdd(numEdges, count);\n\t}\n}",
            "//...\n  __syncthreads();\n  //...\n  atomicAdd(numEdges, numEdgesPerThread);\n}",
            "__shared__ int s[BLOCK_SIZE];\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint sum = 0;\n\tif (tid < N) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + tid]!= 0) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\ts[threadIdx.x] = sum;\n\t__syncthreads();\n\tint t = 1;\n\tfor (int stride = blockDim.x / 2; stride >= 1; stride /= 2) {\n\t\tif (threadIdx.x < stride) {\n\t\t\ts[threadIdx.x] += s[threadIdx.x + stride];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (threadIdx.x == 0) {\n\t\tnumEdges[blockIdx.x] = s[0];\n\t}\n}",
            "__shared__ int shared_mem[1024];\n\n  int *local_count = &shared_mem[threadIdx.x];\n  // Initialize to 0\n  *local_count = 0;\n\n  // Wait for all the threads to finish\n  __syncthreads();\n\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // Add all the numbers in the A[i] to the counter\n  for (int j = 0; j < N; j++) {\n    if (A[i * N + j]!= 0) {\n      (*local_count)++;\n    }\n  }\n\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    *numEdges += *local_count;\n  }\n}",
            "int i = threadIdx.x + blockDim.x * blockIdx.x;\n\tint j = threadIdx.y + blockDim.y * blockIdx.y;\n\tint counter = 0;\n\tif(i < N && j < N && A[i * N + j]!= 0){\n\t\tcounter++;\n\t}\n\t__syncthreads();\n\tatomicAdd(numEdges, counter);\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (col >= N) return;\n\n\tint cnt = 0;\n\tfor (int row = 0; row < N; row++) {\n\t\tif (A[row*N + col]) {\n\t\t\tcnt++;\n\t\t}\n\t}\n\tnumEdges[col] = cnt;\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    int count = 0;\n    if (tid < N) {\n        int i = tid;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] > 0) {\n                count++;\n            }\n        }\n    }\n    atomicAdd(numEdges, count);\n}",
            "// TODO: Your code here\n\tint tid = threadIdx.x;\n\tint numEdgesLocal = 0;\n\n\tfor (int i = tid; i < N; i += blockDim.x) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j]) {\n\t\t\t\tnumEdgesLocal++;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, numEdgesLocal);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[tid * N + i]) count++;\n\t\t}\n\t\t*numEdges += count;\n\t}\n}",
            "// TODO: implement\n}",
            "int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n\tint num_threads = gridDim.x * blockDim.x;\n\tint sum = 0;\n\tfor (int i = threadID; i < N; i += num_threads) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j])\n\t\t\t\tsum++;\n\t\t}\n\t}\n\n\tatomicAdd(numEdges, sum);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint id = index / N;\n\tint offset = index % N;\n\tint temp = A[id * N + offset];\n\tif (temp == 1)\n\t\tatomicAdd(numEdges, 1);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n\n    for (int i = tid; i < N * N; i += stride) {\n        if (A[i] == 1) {\n            atomicAdd(numEdges, 1);\n        }\n    }\n}",
            "int globalThreadIndex = blockDim.x*blockIdx.x + threadIdx.x;\n  int count = 0;\n  for (int i=0; i<N; i++) {\n    if (A[i*N+i] == 1) {\n      count++;\n    }\n  }\n  atomicAdd(numEdges, count);\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "11_graph_edge_count",
        "parallelism_model": "mpi+omp",
        "prompt": "#include <mpi.h>\n#include <omp.h>\n\n/* Count the number of edges in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The result is returned on rank 0.\n   Example:\n\n\t input: [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]]\n   output: 3\n*/\nint edgeCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "if (N == 0) {\n    return 0;\n  }\n\n  if (N == 1) {\n    return A[0];\n  }\n\n  int num_threads;\n\n#pragma omp parallel\n  {\n#pragma omp single\n    {\n      num_threads = omp_get_num_threads();\n    }\n  }\n\n  // The number of tasks per thread, given the total number of tasks and the number of threads.\n  int tasks_per_thread = N / num_threads;\n\n  // The remainder of the division.\n  int tasks_remainder = N - tasks_per_thread * num_threads;\n\n  // The number of threads which will have one extra task to process.\n  int num_threads_with_extra_tasks = tasks_remainder;\n\n  int rank = omp_get_thread_num();\n\n  // The number of tasks this thread will process.\n  int num_tasks = tasks_per_thread + (rank < num_threads_with_extra_tasks);\n\n  // The first task this thread will process.\n  int task_first = tasks_per_thread * rank + (rank < num_threads_with_extra_tasks? rank : num_threads_with_extra_tasks);\n\n  // The last task this thread will process.\n  int task_last = tasks_per_thread * (rank + 1) + (rank + 1 < num_threads_with_extra_tasks? rank + 1 : num_threads_with_extra_tasks);\n\n  int sum = 0;\n  for (int task = task_first; task < task_last; ++task) {\n    sum += A[task * N + task];\n  }\n\n  // The number of ranks in the MPI communicator.\n  int num_ranks;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\n  // The rank of this MPI rank in the MPI communicator.\n  int rank_world;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank_world);\n\n  int global_sum;\n  if (rank_world == 0) {\n    // If this is rank 0, we need to gather the results of each thread from all the other ranks.\n    for (int thread = 0; thread < num_threads; ++thread) {\n      // We have to figure out which rank is responsible for this thread.\n      // The formula is the same as above, but applied to ranks instead of tasks.\n      int rank_of_thread = tasks_per_thread * thread + (thread < num_threads_with_extra_tasks? thread : num_threads_with_extra_tasks);\n      if (rank_of_thread == rank_world) {\n        // This is this rank.\n        global_sum += sum;\n      } else {\n        // This is not this rank. We need to receive a message from that rank.\n        int sum_of_thread;\n        MPI_Status status;\n        MPI_Recv(&sum_of_thread, 1, MPI_INT, rank_of_thread, 0, MPI_COMM_WORLD, &status);\n        global_sum += sum_of_thread;\n      }\n    }\n  } else {\n    // If this is not rank 0, just send the result of the current thread to rank 0.\n    int global_sum_dummy;\n    MPI_Send(&sum, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n\n  return global_sum;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int myNumEdges = 0;\n#pragma omp parallel for reduction(+:myNumEdges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = i; j < N; ++j) {\n      myNumEdges += A[i * N + j];\n    }\n  }\n\n  int globalNumEdges = 0;\n  MPI_Reduce(&myNumEdges, &globalNumEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return globalNumEdges;\n}",
            "int rank, size, total, my_total;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// calculate the number of edges on each rank\n\tmy_total = 0;\n\tfor (size_t i = rank; i < A.size(); i+=size)\n\t{\n\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\tmy_total += A[i * N + j];\n\t}\n\n\t// add up all totals across all ranks\n\tMPI_Reduce(&my_total, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// return the number of edges on rank 0\n\tif (rank == 0)\n\t\treturn total;\n\treturn -1;\n}",
            "}",
            "}",
            "int mySum = 0;\n\n    #pragma omp parallel for reduction(+:mySum)\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < i; ++j) {\n            mySum += A[i * N + j];\n        }\n    }\n\n    return mySum;\n}",
            "}",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "if (A.size()!= N * N) {\n        throw std::invalid_argument(\"A is not a square matrix.\");\n    }\n\n    int result = 0;\n\n#pragma omp parallel for reduction(+ : result)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (i!= j && A[i * N + j]) {\n                result++;\n            }\n        }\n    }\n\n    return result;\n}",
            "// TODO: your code here\n\n\tint edge_count = 0;\n\n\tMPI_Status status;\n\tint num_procs, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0) {\n\t\tstd::vector<int> send_counts(num_procs, N / num_procs);\n\t\tfor (int i = 0; i < N % num_procs; ++i) {\n\t\t\tsend_counts[i]++;\n\t\t}\n\t\tMPI_Request req[2 * num_procs];\n\t\tfor (int i = 0; i < num_procs; ++i) {\n\t\t\tif (i == rank) continue;\n\t\t\tMPI_Isend(&A[send_counts[i] * i], send_counts[i], MPI_INT, i, 0, MPI_COMM_WORLD, &req[2 * i]);\n\t\t\tMPI_Irecv(&A[send_counts[i] * i], send_counts[i], MPI_INT, i, 0, MPI_COMM_WORLD, &req[2 * i + 1]);\n\t\t}\n\t\tMPI_Waitall(2 * num_procs, req, MPI_STATUSES_IGNORE);\n\t} else {\n\t\tint recv_count;\n\t\tMPI_Recv(&recv_count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tMPI_Send(&A[0], recv_count, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tif (rank == 0) {\n\t\tomp_set_num_threads(omp_get_num_procs());\n#pragma omp parallel for reduction(+:edge_count)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\t\tedge_count++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn edge_count;\n}",
            "int count = 0;\n    // Your code goes here\n    return count;\n}",
            "int rank, size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int local_edge_count = 0;\n    for (size_t i = 0; i < N; i++)\n        for (size_t j = 0; j < i; j++)\n            if (A[i * N + j] == 1)\n                local_edge_count++;\n\n    // Reduce the results\n    int global_edge_count = 0;\n    MPI_Reduce(&local_edge_count, &global_edge_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return global_edge_count;\n}",
            "int sum = 0;\n#pragma omp parallel for reduction(+:sum)\n    for (size_t i = 0; i < N; i++)\n    {\n        for (size_t j = 0; j < N; j++)\n        {\n            if (A[i * N + j] == 1 && i < j)\n            {\n                sum++;\n            }\n        }\n    }\n    return sum;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int count = 0;\n  int start = rank * (N / size);\n  int end = (rank + 1) * (N / size);\n  int nth = omp_get_num_threads();\n  int tid = omp_get_thread_num();\n  int localStart = start + tid * (end - start) / nth;\n  int localEnd = start + (tid + 1) * (end - start) / nth;\n\n  #pragma omp parallel for reduction(+: count)\n  for (int i = localStart; i < localEnd; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i!= j && A[i * N + j]) {\n        count++;\n      }\n    }\n  }\n\n  int result = 0;\n  MPI_Reduce(&count, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "int m = 0;\n  int myrank = 0;\n  int size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  std::vector<int> A_local;\n  if (myrank!= 0) {\n    A_local = A;\n  }\n  int mypart = N / size;\n  int rest = N % size;\n  if (myrank == 0) {\n    for (int i = 1; i < size; ++i) {\n      MPI_Send(&A[i * mypart], mypart, MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n  } else {\n    MPI_Recv(&A_local[0], mypart, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    for (int i = 0; i < rest; ++i) {\n      A_local[i] += A[mypart * size + i];\n    }\n  }\n  if (myrank == 0) {\n    for (int i = 0; i < size; ++i) {\n      std::vector<int> temp;\n      if (i == 0) {\n        temp = A_local;\n      } else {\n        MPI_Recv(&A_local[0], mypart, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      }\n      for (int j = 0; j < temp.size(); j += 4) {\n        m += (temp[j] + temp[j + 1] + temp[j + 2] + temp[j + 3]) / 2;\n      }\n    }\n  }\n  if (myrank!= 0) {\n    MPI_Send(&m, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  if (myrank == 0) {\n    return m;\n  }\n}",
            "int rank, nprocs;\n    int *counts, *displ;\n    int *temp, *temp2;\n    int temp_sum;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n    // Counts and displacement are arrays of size N\n    counts = new int[N];\n    displ = new int[N];\n\n    // Every process stores a copy of the matrix\n    // temp is only used for temporary storage during MPI_Reduce\n    temp = new int[N];\n\n    // Count the edges in the local portion of the matrix\n    temp_sum = 0;\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < i; j++) {\n            if (A[i * N + j])\n                temp_sum++;\n        }\n    }\n\n    // Set up counts and displacements for reduction\n    for (int i = 0; i < N; i++) {\n        counts[i] = 0;\n        displ[i] = 0;\n    }\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < i; j++) {\n            if (A[i * N + j]) {\n                counts[i]++;\n                counts[j]++;\n            }\n        }\n    }\n\n    for (int i = 1; i < N; i++) {\n        displ[i] = displ[i-1] + counts[i-1];\n    }\n\n    // Sum up the numbers on every process, storing the result in temp\n    MPI_Reduce(temp_sum, temp, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    // temp2 is only used for the reduction on rank 0\n    temp2 = new int[N];\n    for (int i = 0; i < N; i++) {\n        temp2[i] = 0;\n    }\n\n    if (rank == 0) {\n        // Reduce temp to temp2\n        MPI_Reduce(temp, temp2, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n        // Count the edges in temp2, and return that value\n        int sum = 0;\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < i; j++) {\n                if (temp2[i] && temp2[j])\n                    sum++;\n            }\n        }\n        return sum;\n    } else {\n        // Reduce temp to temp2\n        MPI_Reduce(temp, temp2, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    }\n\n    // Free memory\n    delete [] counts;\n    delete [] displ;\n    delete [] temp;\n    delete [] temp2;\n\n    return 0;\n}",
            "int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    /* YOUR CODE HERE */\n    int n = N / 4;\n    int k = n * n;\n    int edge_count = 0;\n\n    if (rank == 0)\n    {\n        for (int i = 0; i < n; i++)\n        {\n            for (int j = 0; j < n; j++)\n            {\n                for (int m = 0; m < n; m++)\n                {\n                    for (int l = 0; l < n; l++)\n                    {\n                        edge_count += A[i * n + j] * A[m * n + l] * A[n * n + m * n + i] * A[n * n + n * n + j * n + l];\n                    }\n                }\n            }\n        }\n    }\n    else\n    {\n        edge_count = 0;\n    }\n\n    int edge_count_all;\n    MPI_Reduce(&edge_count, &edge_count_all, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    /* END YOUR CODE */\n    return edge_count_all;\n}",
            "int edgeCount = 0;\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i*N + j]) {\n                ++edgeCount;\n            }\n        }\n    }\n    return edgeCount;\n}",
            "int nEdges=0;\n  #pragma omp parallel for reduction(+:nEdges)\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = 0; j < N; ++j) {\n      if(i!=j && A[i*N + j]) {\n        ++nEdges;\n      }\n    }\n  }\n\n  int nEdgesPerRank=0;\n  MPI_Reduce(&nEdges, &nEdgesPerRank, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return nEdgesPerRank;\n}",
            "int edgeCount = 0;\n\n\t/* Your code goes here */\n\tint *Alocal = new int[N*N];\n\t#pragma omp parallel for reduction(+:edgeCount)\n\tfor (int i=0; i<N; i++) {\n\t\tfor (int j=i+1; j<N; j++) {\n\t\t\tif (A[i*N+j] == 1) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\t/* End of your code */\n\treturn edgeCount;\n}",
            "int rank, size;\n    int localN = N/size;\n    int edges = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int i = rank*localN;\n    for(; i < (rank+1)*localN; i++) {\n        int k = 0;\n        while(k < N) {\n            edges += A[i*N + k];\n            k++;\n        }\n    }\n    int localEdges;\n    int totalEdges;\n    MPI_Reduce(&edges, &localEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    MPI_Gather(&localEdges, 1, MPI_INT, &totalEdges, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    if(rank == 0)\n        return localEdges;\n    return 0;\n}",
            "int numEdges = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j]) {\n        #pragma omp atomic\n        numEdges += 1;\n      }\n    }\n  }\n  return numEdges;\n}",
            "// TODO\n}",
            "int num_threads, tid, sum;\n    MPI_Status status;\n    int count_num_threads;\n    int recvcounts[count_num_threads], displ[count_num_threads];\n    int sum_received;\n\n    int edge_count = 0;\n    int num_of_edges = 0;\n\n    num_threads = omp_get_max_threads();\n    count_num_threads = num_threads;\n\n    int *sums = new int[count_num_threads];\n    int *edge_counts = new int[count_num_threads];\n\n    for (int i = 0; i < count_num_threads; i++) {\n        displ[i] = i * N;\n        recvcounts[i] = N;\n    }\n\n    #pragma omp parallel private(tid, sum)\n    {\n        tid = omp_get_thread_num();\n\n        for (int i = tid; i < N; i += num_threads) {\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j]!= 0) {\n                    edge_counts[tid] += 1;\n                }\n            }\n        }\n\n        sums[tid] = edge_counts[tid];\n        #pragma omp barrier\n        #pragma omp master\n        {\n            for (int i = 0; i < count_num_threads; i++) {\n                edge_count += sums[i];\n            }\n        }\n\n    }\n\n    MPI_Reduce(&edge_count, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    MPI_Bcast(&sum, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    return sum;\n}",
            "const int rank = omp_get_thread_num();\n\tconst int size = omp_get_num_threads();\n\tconst int numEdges = A.size() / (N * N);\n\tconst int perThread = numEdges / size;\n\tconst int residual = numEdges % size;\n\tconst int start = rank * perThread;\n\tconst int end = start + perThread + (rank < residual? 1 : 0);\n\tint result = 0;\n\n\tfor(int i = start; i < end; ++i) {\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A[i * N + j]) {\n\t\t\t\tresult += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int num_procs, my_rank, rc;\n  int edgeCount_result;\n\n  rc = MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  rc = MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n  /* allocate space for a copy of A on every rank */\n  int *A_copy = new int[N*N];\n\n  for (int i = 0; i < N*N; i++) {\n    A_copy[i] = A[i];\n  }\n\n  /* initialize the number of edges count to 0 */\n  edgeCount_result = 0;\n\n  /* use omp for loop to perform edge counting */\n  #pragma omp parallel for schedule(dynamic) num_threads(num_procs) reduction(+:edgeCount_result)\n  for (int i = 0; i < N*N; i++) {\n    if (A_copy[i] == 1) {\n      edgeCount_result++;\n    }\n  }\n\n  if (my_rank == 0) {\n    printf(\"MPI Ranks: %d. Threads: %d. Edges: %d.\\n\", num_procs, omp_get_max_threads(), edgeCount_result);\n  }\n\n  /* free the memory allocated to A_copy on every rank */\n  delete [] A_copy;\n\n  /* use MPI_Reduce to get the result from all ranks */\n  int result;\n  MPI_Reduce(&edgeCount_result, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  /* return the result from rank 0 */\n  return result;\n}",
            "int rank, size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int count = 0;\n    size_t start = rank * N / size;\n    size_t end = (rank + 1) * N / size;\n    if (rank == size - 1) {\n        end = N;\n    }\n    for (size_t i = start; i < end; i++) {\n        for (size_t j = 0; j < i; j++) {\n            if (A[N * i + j]!= 0) {\n                count++;\n            }\n        }\n    }\n\n    MPI_Reduce(&count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return count;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    if (size == 1) {\n        int edges = 0;\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (i!= j && A[i*N + j] == 1) {\n                    ++edges;\n                }\n            }\n        }\n        return edges;\n    }\n\n    int chunks = size;\n    int chunkSize = N / chunks;\n    int remainder = N % chunks;\n    int first = rank * chunkSize;\n    int last = (rank == size - 1)? N : first + chunkSize + remainder;\n    int edges = 0;\n\n    // TODO: Compute the number of edges in A[first:last, first:last] using OpenMP.\n\n    return edges;\n}",
            "// TO DO: your code here\n}",
            "int result = 0;\n  for (int i = 0; i < A.size(); ++i) {\n    if (A[i] == 1) {\n      result += 1;\n    }\n  }\n  return result;\n}",
            "int sum=0;\n\tint size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint *sums;\n\tif (rank==0) {\n\t\tsums = (int *)malloc(sizeof(int)*size);\n\t}\n\n\tint start=rank*N/size;\n\tint stop=std::min(start+N/size, N);\n\n\t#pragma omp parallel for\n\tfor (int i = start; i < stop; i++) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[N*i+j]!= 0) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\t#pragma omp atomic\n\t\tsum += count;\n\t}\n\n\tif (rank==0) {\n\t\tMPI_Reduce(MPI_IN_PLACE, sums, size, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\tint finalSum = 0;\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tfinalSum += sums[i];\n\t\t}\n\t\treturn finalSum;\n\t} else {\n\t\tMPI_Reduce(&sum, 0, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\treturn sum;\n\t}\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// Initialize the result (local to this rank) to 0.\n    int result = 0;\n\n    // This is the part you have to do.\n    // Add the number of edges (1) to the result if A[i][j]==1\n    // for any i, j such that i<j\n\n\n    // Every rank reports the number of edges in A (local to this rank) to rank 0.\n    // Rank 0 collects the results and computes the total number of edges.\n    MPI_Reduce(&result, NULL, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    // Return the result on rank 0.\n    return result;\n}",
            "// TODO\n\tint edge_count = 0;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint my_rows_start = rank * (N/size);\n\tint my_rows_end = my_rows_start + (N/size);\n\tint local_count = 0;\n\tfor (int i = my_rows_start; i < my_rows_end; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j]!= 0)\n\t\t\t\tlocal_count++;\n\t\t}\n\t}\n\tMPI_Reduce(&local_count, &edge_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (rank == 0)\n\t\treturn edge_count;\n\telse\n\t\treturn 0;\n}",
            "// TODO\n\treturn 0;\n}",
            "// TODO: implement this function\n\tint numEdge = 0;\n\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; ++i){\n\t\tfor(int j = 0; j < N; ++j){\n\t\t\tif (A[i*N+j]!= 0 && i < j){\n\t\t\t\tnumEdge++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numEdge;\n}",
            "int rank, p;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n\n    std::vector<int> localA(N*N / p);\n    MPI_Scatter(&A[0], N*N/p, MPI_INT, &localA[0], N*N/p, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int result = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (localA[i*N + j])\n                result++;\n        }\n    }\n\n    int partial = 0;\n    MPI_Reduce(&result, &partial, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return partial;\n}",
            "int count = 0;\n  int edge_count = 0;\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  if (rank == 0)\n  {\n    for (int i = 0; i < N; ++i)\n    {\n      for (int j = 0; j < N; ++j)\n      {\n        if (i < j)\n        {\n          if (A[i * N + j] == 1)\n          {\n            count++;\n          }\n        }\n      }\n    }\n    count = count / 2;\n  }\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  edge_count = count / size;\n  return edge_count;\n}",
            "// TODO\n}",
            "int ret = 0;\n  #pragma omp parallel for\n  for(size_t i=0; i<N; ++i)\n  for(size_t j=0; j<N; ++j)\n    ret += A[i*N+j];\n  return ret;\n}",
            "int rank = 0;\n\tint size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// TODO: implement edge count\n\n\treturn 0;\n}",
            "int rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint sum;\n\t\n\tif (rank == 0)\n\t{\n\t\tsum = 0;\n\t\tfor (int i = 1; i < A.size(); i++)\n\t\t{\n\t\t\tfor (int j = 0; j < i; j++)\n\t\t\t{\n\t\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tMPI_Reduce(&sum, NULL, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t}\n\telse\n\t{\n\t\tsum = 0;\n\t\tfor (int i = 1; i < A.size(); i++)\n\t\t{\n\t\t\tfor (int j = 0; j < i; j++)\n\t\t\t{\n\t\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\tMPI_Reduce(&sum, NULL, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn sum;\n}",
            "int rank, size;\n  int sum = 0;\n  int localSum = 0;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  std::vector<int> A_local;\n  A_local.reserve(N);\n\n  int chunkSize = (int) ceil((double)N/size);\n  int begin = rank*chunkSize;\n  int end = begin + chunkSize;\n  if (end > N) end = N;\n\n  for (int i = 0; i < N; i++) {\n    A_local.push_back(A[i]);\n  }\n\n  #pragma omp parallel for reduction(+:localSum)\n  for (int i = begin; i < end; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i!= j) {\n        if (A_local[i*N + j] == 1) localSum++;\n      }\n    }\n  }\n\n  MPI_Reduce(&localSum, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return sum;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  const int chunk_size = N / size;\n  int count = 0;\n  int start = chunk_size * rank;\n  int end = std::min(N, start + chunk_size);\n  for (int i = start; i < end; ++i) {\n    for (int j = i + 1; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n  // std::cout << \"Rank \" << rank << \" \" << count << std::endl;\n\n  int all_count = 0;\n  MPI_Reduce(&count, &all_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return all_count;\n}",
            "int numEdges = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for reduction(+:numEdges)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i < j && A[i * N + j])\n\t\t\t\t\t++numEdges;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numEdges;\n}",
            "int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int result;\n  if (rank == 0) {\n    result = 0;\n  }\n\n  int total_edges = 0;\n  #pragma omp parallel for reduction(+:total_edges)\n  for (int i = 0; i < N; i++) {\n    for (int j = i; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        total_edges++;\n      }\n    }\n  }\n\n  int partial_result = 0;\n  if (rank == 0) {\n    partial_result = total_edges;\n  }\n\n  int tmp[2];\n  tmp[0] = partial_result;\n  tmp[1] = total_edges;\n\n  int buf[2 * size];\n  MPI_Gather(tmp, 2, MPI_INT, buf, 2, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    for (int i = 1; i < size; i++) {\n      result += buf[2 * i];\n    }\n  }\n\n  return result;\n}",
            "int n_threads;\n\tomp_set_num_threads(4);\n\t#pragma omp parallel shared(A, n_threads)\n\t{\n\t\tn_threads = omp_get_num_threads();\n\t\t//std::cout << \"Num of threads: \" << n_threads << std::endl;\n\t\t#pragma omp master\n\t\t{\n\t\t\tstd::cout << \"Num of threads: \" << n_threads << std::endl;\n\t\t}\n\t}\n\tint count = 0;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t#pragma omp parallel for num_threads(n_threads) reduction(+: count)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1 && i < j) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tif (rank == 0) {\n\t\tint sum = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 && i < j) {\n\t\t\t\t\tsum++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tstd::cout << \"Total number of edges is: \" << sum << std::endl;\n\t\treturn sum;\n\t}\n\telse {\n\t\treturn count;\n\t}\n\t\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i!= j and A[i*N+j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int n = N;\n  int my_id;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_id);\n  int root = 0;\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int* recv = new int[size - 1];\n  int count = 0;\n\n  for (size_t i = 0; i < n; i++) {\n    for (size_t j = 0; j < n; j++) {\n      if (i == j) continue;\n      if (A[i * n + j] == 1) count++;\n    }\n  }\n  int count_sum = 0;\n  MPI_Gather(&count, 1, MPI_INT, recv, 1, MPI_INT, root, MPI_COMM_WORLD);\n  for (size_t i = 0; i < size - 1; i++) {\n    count_sum += recv[i];\n  }\n  if (my_id == root) {\n    int ans = count_sum;\n    for (size_t i = 1; i < size; i++) {\n      MPI_Recv(&count_sum, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      ans += count_sum;\n    }\n    delete[] recv;\n    return ans;\n  }\n  if (my_id!= root) {\n    MPI_Send(&count, 1, MPI_INT, root, 0, MPI_COMM_WORLD);\n  }\n  return 0;\n}",
            "int world_size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (N % world_size!= 0) {\n\t\tprintf(\"N must be divisible by the number of processors.\\n\");\n\t\tMPI_Abort(MPI_COMM_WORLD, 1);\n\t}\n\n\tint local_size = N / world_size;\n\n\tint sum = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < local_size; i++) {\n\t\tfor (int j = 0; j < local_size; j++) {\n\t\t\tif (A[local_size * rank + i + j * N] == 1) {\n\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint global_sum = 0;\n\n\tMPI_Reduce(&sum, &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\treturn global_sum;\n\t} else {\n\t\treturn 0;\n\t}\n\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  /* YOUR CODE GOES HERE */\n\n  /* END YOUR CODE */\n}",
            "int local_count = 0;\n  //... your code here...\n\n  // add up the local counts\n  // use a reduction (https://www.mpi-forum.org/docs/mpi-1.1/mpi-11-html/node50.htm)\n  int global_count;\n  MPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  // return the total count from all ranks\n  if (0 == rank) {\n    return global_count;\n  }\n\n  // return -1 from all other ranks\n  return -1;\n}",
            "int result = 0;\n\tint my_result = 0;\n\tint rsize, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &rsize);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint start_index = rank * (N / rsize);\n\tint end_index = (rank + 1) * (N / rsize);\n\tint sum = 0;\n\tif(rank == 0){\n\t\t#pragma omp parallel for\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tfor(int j = 0; j < i; j++){\n\t\t\t\tif(A[i * N + j]){\n\t\t\t\t\tresult++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse{\n\t\t#pragma omp parallel for\n\t\tfor(int i = start_index; i < end_index; i++){\n\t\t\tfor(int j = 0; j < i; j++){\n\t\t\t\tif(A[i * N + j]){\n\t\t\t\t\tmy_result++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Reduce(&my_result, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif(rank == 0){\n\t\tresult += sum;\n\t}\n\treturn result;\n}",
            "int numEdges = 0;\n  #pragma omp parallel for reduction(+:numEdges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i*N + j]) {\n        numEdges += 1;\n      }\n    }\n  }\n  return numEdges;\n}",
            "int rank = 0;\n\tint size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tconst int n = N;\n\n\tint count = 0;\n\n\tfor (int i = 0; i < n; i++) {\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (A[i * n + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Datatype MPI_CUSTOM_TYPE;\n\tMPI_Type_contiguous(sizeof(int), MPI_BYTE, &MPI_CUSTOM_TYPE);\n\tMPI_Type_commit(&MPI_CUSTOM_TYPE);\n\n\tint sendCounts[size];\n\tint displs[size];\n\n\tfor (int i = 0; i < size; i++) {\n\t\tsendCounts[i] = n / size;\n\t}\n\n\tfor (int i = 0; i < n; i++) {\n\t\tif (i < n % size) {\n\t\t\tsendCounts[i]++;\n\t\t}\n\t}\n\n\tdispls[0] = 0;\n\n\tfor (int i = 1; i < size; i++) {\n\t\tdispls[i] = displs[i - 1] + sendCounts[i - 1];\n\t}\n\n\tstd::vector<int> A1(sendCounts[rank] * n);\n\n\tMPI_Scatterv(A.data(), sendCounts, displs, MPI_CUSTOM_TYPE, A1.data(),\n\t\tsendCounts[rank] * n, MPI_CUSTOM_TYPE, 0, MPI_COMM_WORLD);\n\n\tint count1 = 0;\n\n\tfor (int i = 0; i < sendCounts[rank]; i++) {\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (A1[i * n + j] == 1) {\n\t\t\t\tcount1++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&count1, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tMPI_Type_free(&MPI_CUSTOM_TYPE);\n\n\treturn count;\n}",
            "std::vector<int> counts;\n  #pragma omp parallel\n  {\n    #pragma omp single\n    counts.resize(omp_get_num_threads());\n    #pragma omp for schedule(static)\n    for(size_t i = 0; i < N; ++i)\n      for(size_t j = 0; j < N; ++j)\n        if(A[i * N + j])\n          ++counts[omp_get_thread_num()];\n  }\n\n  int nCounts = 0;\n  #pragma omp parallel for reduction(+: nCounts)\n  for(size_t i = 0; i < counts.size(); ++i)\n    nCounts += counts[i];\n\n  int nTotalCounts = 0;\n  MPI_Reduce(&nCounts, &nTotalCounts, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return nTotalCounts;\n}",
            "int result = 0;\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "// Replace this statement with your implementation\n  return 0;\n}",
            "return 0;\n}",
            "int edge_count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i < j && A[N * i + j] == 1)\n                edge_count++;\n        }\n    }\n    return edge_count;\n}",
            "/* Your code here */\n\n    return 0;\n}",
            "// You may assume that the adjacency matrix is square and N is the number of vertices in the graph.\n\n  int sum = 0;\n  int count = 0;\n\n  int rank = omp_get_thread_num();\n  int size = omp_get_num_threads();\n  int start = 0 + rank*N/size;\n  int end = start + N/size;\n  #pragma omp parallel for reduction(+: sum)\n  for(int i = 0; i < N; i++) {\n    for(int j = 0; j < N; j++) {\n      if (A[i*N + j]!= 0)\n        sum++;\n    }\n  }\n\n  MPI_Reduce(&sum, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if(rank == 0) {\n    return count;\n  } else {\n    return 0;\n  }\n}",
            "return 0;\n}",
            "int p = omp_get_num_procs();\n    int t = omp_get_num_threads();\n    int n = N;\n    int m = n * n;\n\n    int *count = (int *) malloc(n * sizeof(int));\n\n    for(int i = 0; i < n; i++) {\n        count[i] = 0;\n    }\n\n    #pragma omp parallel for num_threads(p) default(none) shared(A, count, m, n) schedule(static, m / p)\n    for(int i = 0; i < m; i++) {\n        int row = i / n;\n        int col = i % n;\n        if(A[row] == 1 && A[col] == 1) {\n            count[i] = 1;\n        }\n    }\n\n    int *sum = (int *) malloc(n * sizeof(int));\n    int *buf = (int *) malloc(n * sizeof(int));\n    int root = 0;\n\n    #pragma omp parallel for num_threads(p) default(none) shared(sum, count, n, root) schedule(static, n / t)\n    for(int i = 0; i < n; i++) {\n        sum[i] = count[i];\n    }\n\n    for(int i = 1; i < p; i++) {\n        #pragma omp barrier\n        if(i == root) {\n            #pragma omp master\n            MPI_Gather(sum, n, MPI_INT, buf, n, MPI_INT, root, MPI_COMM_WORLD);\n        } else {\n            MPI_Gather(sum, n, MPI_INT, buf, n, MPI_INT, root, MPI_COMM_WORLD);\n        }\n\n        #pragma omp barrier\n        if(i == root) {\n            #pragma omp master\n            for(int j = 0; j < n; j++) {\n                sum[j] = 0;\n                for(int k = 0; k < p; k++) {\n                    sum[j] += buf[k * n + j];\n                }\n            }\n        }\n    }\n\n    #pragma omp barrier\n    if(i == root) {\n        #pragma omp master\n        int total = 0;\n        for(int j = 0; j < n; j++) {\n            total += sum[j];\n        }\n        return total;\n    }\n}",
            "// TODO\n}",
            "int edgeCount = 0;\n\n\t// TODO: use MPI and OpenMP to compute the edge count in parallel\n\n\treturn edgeCount;\n}",
            "// TODO: Fill this in\n  return -1;\n}",
            "return 0;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t row = 0; row < N; ++row) {\n\t\tfor (size_t col = 0; col < N; ++col) {\n\t\t\tif (col!= row && A[row*N + col] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int numThreads;\n  // TODO\n}",
            "int localEdgeCount = 0;\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 1) {\n                ++localEdgeCount;\n            }\n        }\n    }\n    return localEdgeCount;\n}",
            "std::vector<int> sumOfRow(N,0);\n\n  // for(auto i=0; i<N; i++)\n  // {\n  //   sumOfRow[i] = 0;\n  // }\n\n  // for(auto i=0; i<N; i++)\n  // {\n  //   sumOfRow[i] = std::accumulate(A.begin()+i*N, A.begin()+(i+1)*N, 0);\n  // }\n\n  #pragma omp parallel for\n  for(auto i=0; i<N; i++)\n  {\n    sumOfRow[i] = std::accumulate(A.begin()+i*N, A.begin()+(i+1)*N, 0);\n  }\n\n  std::vector<int> sumOfColumn(N,0);\n\n  // for(auto i=0; i<N; i++)\n  // {\n  //   sumOfColumn[i] = 0;\n  // }\n\n  // for(auto i=0; i<N; i++)\n  // {\n  //   sumOfColumn[i] = std::accumulate(A.begin()+i, A.begin()+N*N, 0);\n  // }\n\n  #pragma omp parallel for\n  for(auto i=0; i<N; i++)\n  {\n    sumOfColumn[i] = std::accumulate(A.begin()+i, A.begin()+N*N, 0);\n  }\n\n  int edgeCount = 0;\n\n  for(auto i=0; i<N; i++)\n  {\n    for(auto j=0; j<N; j++)\n    {\n      if(A[i*N+j]!= 0 && sumOfRow[i] == sumOfColumn[j])\n      {\n        edgeCount++;\n      }\n    }\n  }\n\n  return edgeCount;\n}",
            "// TODO: Your code goes here!\n    int count = 0;\n    #pragma omp parallel for reduction(+:count)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (i < j && A[i * N + j]) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int num_threads = 4;\n  int num_ranks = 1;\n  int rank = 0;\n\n  int total = 0;\n  #pragma omp parallel num_threads(num_threads) shared(total)\n  {\n    int local_total = 0;\n\n    #pragma omp for schedule(static)\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = i + 1; j < N; j++) {\n        if (A[i*N + j] == 1)\n          local_total++;\n      }\n    }\n\n    #pragma omp critical\n    {\n      total += local_total;\n    }\n  }\n\n  return total;\n}",
            "int numEdges = 0;\n  #pragma omp parallel for reduction(+ : numEdges)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (i!= j && A[i + j * N] == 1) {\n        ++numEdges;\n      }\n    }\n  }\n  return numEdges;\n}",
            "int num_processes, process_id;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &process_id);\n\n  // Get a copy of A\n  std::vector<int> A_local;\n  int chunk_size = N / num_processes;\n  int remainder = N % num_processes;\n  int a_start = chunk_size * process_id + std::min(process_id, remainder);\n  int a_end = a_start + chunk_size + (process_id < remainder);\n  if (process_id == 0) a_end = N;\n  for (int i = a_start; i < a_end; i++)\n    for (int j = 0; j < N; j++)\n      A_local.push_back(A[i * N + j]);\n\n  // Count edges\n  int n_edges_local = 0;\n#pragma omp parallel for reduction(+ : n_edges_local)\n  for (int i = 0; i < A_local.size(); i++)\n    n_edges_local += A_local[i];\n\n  // Reduce edges across all processes\n  int n_edges_global = 0;\n  MPI_Reduce(&n_edges_local, &n_edges_global, 1, MPI_INT, MPI_SUM, 0,\n             MPI_COMM_WORLD);\n\n  return n_edges_global;\n}",
            "int result;\n\n    // Fill in your solution here.\n\n    return result;\n}",
            "int numEdges = 0;\n#pragma omp parallel\n#pragma omp for reduction(+:numEdges)\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0)\n                ++numEdges;\n        }\n    }\n    return numEdges;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+: count)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] > 0) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int result = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t#pragma omp atomic\n\t\t\t\tresult++;\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n    size_t rank = 0;\n    size_t size = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int start = (rank * N) / size;\n    int end = ((rank + 1) * N) / size;\n\n    int local_count = 0;\n\n    for (int i = start; i < end; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0) {\n                ++local_count;\n            }\n        }\n    }\n    int global_count = 0;\n    MPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return global_count;\n}",
            "int result = 0;\n  #pragma omp parallel for reduction(+:result)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (i < j && A[i*N + j] == 1) {\n        result++;\n      }\n    }\n  }\n  return result;\n}",
            "int count = 0;\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; ++i)\n\t\tfor(size_t j = 0; j < N; ++j)\n\t\t\tif(A[i * N + j] && i < j)\n\t\t\t\tcount += 1;\n\treturn count;\n}",
            "int numThreads = omp_get_max_threads();\n\tint edgeCount = 0;\n\tint myRank = 0;\n\tint root = 0;\n\tint size = 0;\n\n\tint myThreads = 0;\n\tint* myA = nullptr;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tmyA = new int[N*N];\n\t\n\tMPI_Scatter(A.data(), N*N/size, MPI_INT, myA, N*N/size, MPI_INT, root, MPI_COMM_WORLD);\n\n\tmyThreads = omp_get_max_threads();\n\t#pragma omp parallel num_threads(myThreads)\n\t{\n\t\tint start = 0;\n\t\tint end = 0;\n\t\tint myID = omp_get_thread_num();\n\n\t\tstart = myID * (N/myThreads);\n\t\tend = start + (N/myThreads);\n\n\t\tfor (int i = start; i < end; i++)\n\t\t{\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif (myA[i*N + j] == 1)\n\t\t\t\t\tedgeCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&edgeCount, &edgeCount, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\n\tif (myRank == root)\n\t{\n\t\treturn edgeCount;\n\t}\n\telse\n\t{\n\t\treturn 0;\n\t}\n}",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor (size_t i=0; i<N; i++) {\n\t\tfor (size_t j=i+1; j<N; j++) {\n\t\t\tresult += A[i*N + j];\n\t\t}\n\t}\n\treturn result;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+: count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = i; j < N; ++j) {\n\t\t\tif (i!= j && A[N * i + j] == 1) {\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int ans = 0;\n\n#pragma omp parallel for reduction(+:ans)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                ans += 1;\n            }\n        }\n    }\n\n    return ans;\n}",
            "// TODO: your code here\n\n\treturn 0;\n}",
            "// TODO: Implement this function\n    return 0;\n}",
            "int nprocs, rank, numEdges = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint edges_local = 0;\n\tfor (size_t i = rank; i < A.size(); i += nprocs) {\n\t\tfor (size_t j = 0; j < A[i]; j++) {\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tedges_local++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&edges_local, &numEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn numEdges;\n}",
            "int n_rank, r_rank;\n    int local_result;\n    int global_result;\n    MPI_Comm_rank(MPI_COMM_WORLD, &r_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &n_rank);\n    /* Compute the number of rows of A that the local rank has.\n       This is the number of edges in the local submatrix. */\n    int N_rows = N / n_rank;\n    /* Get a local copy of the relevant rows of A. */\n    std::vector<int> local_A(N_rows * N, 0);\n    /* The first rows of A belong to rank 0. Then it's the turn of rank 1,\n       then rank 2, and so on...*/\n    int start_row = r_rank * N_rows;\n    std::copy(A.begin() + start_row * N, A.begin() + (start_row + N_rows) * N, local_A.begin());\n    /* Compute the local result. */\n    local_result = 0;\n    for (size_t row = 0; row < N_rows; row++) {\n        for (size_t col = 0; col < N; col++) {\n            local_result += local_A[row * N + col];\n        }\n    }\n    /* Reduce the results among the ranks.\n       See MPI documentation for more information. */\n    MPI_Reduce(&local_result, &global_result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return global_result;\n}",
            "int count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j] == 1) {\n\t\t\t\tcount += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n\t\n\t// TODO\n\t\n\treturn count;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // The number of edges in the submatrix of A assigned to this rank.\n    int count = 0;\n    if (rank == 0) {\n        // Rank 0 has the complete matrix, so count all the edges.\n#pragma omp parallel for reduction(+:count)\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = i + 1; j < N; ++j) {\n                count += A[i * N + j] + A[j * N + i];\n            }\n        }\n    }\n    else {\n        // Other ranks have only part of the matrix, so count the edges.\n        int count_local = 0;\n#pragma omp parallel for reduction(+:count_local)\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = i + 1; j < N; ++j) {\n                count_local += A[i * N + j] + A[j * N + i];\n            }\n        }\n\n        // Send local count to rank 0.\n        MPI_Send(&count_local, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    if (rank!= 0) {\n        return 0;\n    }\n\n    // Combine the counts from all the ranks.\n    int counts[size];\n    for (size_t i = 0; i < size; ++i) {\n        MPI_Status status;\n        MPI_Recv(&counts[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n    }\n    int totalCount = 0;\n    for (size_t i = 0; i < size; ++i) {\n        totalCount += counts[i];\n    }\n    return totalCount / 2;\n}",
            "int count = 0;\n\t// Replace this line with your parallel implementation\n\tcount = edgeCountSeq(A, N);\n\t// End replace\n\treturn count;\n}",
            "int rank;\n  int size;\n  int result = 0;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // TODO: Your code here.\n  int edgeCount = 0;\n  #pragma omp parallel for reduction(+:edgeCount)\n  for(int i=0; i<N; i++){\n      for(int j=0; j<N; j++){\n          if(A[i*N+j] == 1){\n              edgeCount++;\n          }\n      }\n  }\n  int result_temp[size];\n  MPI_Gather(&edgeCount, 1, MPI_INT, result_temp, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if(rank==0){\n      result = 0;\n      for(int i=0; i<size; i++){\n          result += result_temp[i];\n      }\n  }\n  return result;\n\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int myCount = 0;\n  if (rank == 0) {\n    // TODO: Implement\n  }\n  int count;\n  MPI_Reduce(&myCount, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return count;\n}",
            "int nb_edges = 0;\n\n    #pragma omp parallel for reduction(+ : nb_edges)\n    for (size_t i = 0; i < A.size(); ++i)\n    {\n        if (A[i] == 1)\n        {\n            for (size_t j = 0; j < A.size(); ++j)\n            {\n                if (A[j] == 1)\n                {\n                    nb_edges++;\n                }\n            }\n        }\n    }\n\n    int result = 0;\n\n    MPI_Reduce(&nb_edges, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "// YOUR CODE HERE\n\n\treturn 0;\n}",
            "// your code here\n}",
            "int my_rank, num_procs;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\n  // your code goes here\n  int local_sum = 0;\n  if(my_rank == 0) {\n    for(size_t i = 0; i < N; i++) {\n      for(size_t j = i+1; j < N; j++) {\n        if(A[i*N + j] == 1) {\n          local_sum++;\n        }\n      }\n    }\n  }\n  else {\n    for(size_t i = 0; i < N; i++) {\n      for(size_t j = i+1; j < N; j++) {\n        if(A[i*N + j] == 1) {\n          local_sum++;\n        }\n      }\n    }\n  }\n\n  int result_sum;\n  MPI_Reduce(&local_sum, &result_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return result_sum;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\t// TODO\n\tint count = 0;\n\tint* recvBuffer = NULL;\n\tif (rank == 0) {\n\t\tint sendBuffer[size];\n\t\tfor (int i = 0; i < size; ++i) {\n\t\t\tsendBuffer[i] = 0;\n\t\t}\n\t\tMPI_Request requests[size];\n\t\tMPI_Status statuses[size];\n\n\t\t// 0 -> N-1\n\t\tfor (int i = 1; i < size; ++i) {\n\t\t\tMPI_Isend(&count, 1, MPI_INT, i, 1, MPI_COMM_WORLD, &requests[i]);\n\t\t}\n\n\t\t// N-1 -> 0\n\t\tfor (int i = 0; i < size - 1; ++i) {\n\t\t\tMPI_Irecv(&sendBuffer[i], 1, MPI_INT, MPI_ANY_SOURCE, 1, MPI_COMM_WORLD, &requests[i]);\n\t\t}\n\n\t\t// 0 to 0\n\t\tfor (int i = 0; i < size - 1; ++i) {\n\t\t\tMPI_Wait(&requests[i], &statuses[i]);\n\t\t\tint src = statuses[i].MPI_SOURCE;\n\t\t\tsendBuffer[src] = count;\n\t\t\tcount += sendBuffer[src];\n\t\t}\n\n\t\t// 0 -> N-1\n\t\tfor (int i = 1; i < size; ++i) {\n\t\t\tMPI_Send(&count, 1, MPI_INT, i, 2, MPI_COMM_WORLD);\n\t\t}\n\n\t\t// N-1 -> 0\n\t\tfor (int i = 0; i < size - 1; ++i) {\n\t\t\tMPI_Recv(&sendBuffer[i], 1, MPI_INT, MPI_ANY_SOURCE, 2, MPI_COMM_WORLD, &statuses[i]);\n\t\t\tint src = statuses[i].MPI_SOURCE;\n\t\t\tsendBuffer[src] = count;\n\t\t}\n\n\t\t// 0 to 0\n\t\tfor (int i = 0; i < size - 1; ++i) {\n\t\t\tcount += sendBuffer[i];\n\t\t}\n\t} else {\n\t\tint sendBuffer;\n\t\tMPI_Request request;\n\t\tMPI_Status status;\n\t\t// 0 -> N-1\n\t\tMPI_Isend(&count, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, &request);\n\t\t// N-1 -> 0\n\t\tMPI_Recv(&sendBuffer, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, &status);\n\t\tcount += sendBuffer;\n\t\t// 0 -> N-1\n\t\tMPI_Send(&count, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n\t\t// N-1 -> 0\n\t\tMPI_Recv(&sendBuffer, 1, MPI_INT, 0, 2, MPI_COMM_WORLD, &status);\n\t\tcount += sendBuffer;\n\t}\n\n\tif (rank == 0) {\n\t\tfree(recvBuffer);\n\t}\n\n\treturn count;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int local_edges = 0;\n    #pragma omp parallel for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = i; j < N; ++j) {\n            if (i!= j && A[i * N + j] == 1) {\n                local_edges++;\n            }\n        }\n    }\n\n    int global_edges = 0;\n    MPI_Reduce(&local_edges, &global_edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return global_edges;\n}",
            "int N_ranks, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &N_ranks);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    size_t edge_count = 0;\n    if (rank == 0) {\n        std::cout << \"Running on \" << N_ranks << \" ranks.\" << std::endl;\n    }\n    for (int r = 0; r < N_ranks; r++) {\n        int start = r * (N / N_ranks);\n        int end = std::min(start + (N / N_ranks), N);\n        int local_edge_count = 0;\n        for (int i = start; i < end; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j] && i!= j) {\n                    local_edge_count++;\n                }\n            }\n        }\n        MPI_Reduce(&local_edge_count, &edge_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    }\n    return edge_count;\n}",
            "// Add code here\n  int result = 0;\n  int* local = new int[N];\n  for (int i = 0; i < N; i++){\n    local[i] = 0;\n  }\n\n  for (int i = 0; i < N; i++){\n    for (int j = 0; j < N; j++){\n      local[i] += A[i*N+j];\n    }\n  }\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++){\n    for (int j = 0; j < N; j++){\n      local[i] += A[i*N+j];\n    }\n  }\n  for (int i = 0; i < N; i++){\n    result += local[i] / 2;\n  }\n  return result;\n\n}",
            "std::vector<int> local_edge_counts(N);\n\t#pragma omp parallel for schedule(static)\n\tfor (int i = 0; i < N; i++) {\n\t\tlocal_edge_counts[i] = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i < j && A[i * N + j]) local_edge_counts[i]++;\n\t\t}\n\t}\n\tMPI_Reduce(local_edge_counts.data(), NULL, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn edgeCount(A, N);\n}",
            "// TODO\n    return 0;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO: YOUR CODE HERE\n\n  return 0;\n}",
            "if (N == 1)\n        return 0;\n    else if (N == 2)\n        return A[0];\n    else {\n        int num_threads = omp_get_num_threads();\n        int rank = omp_get_thread_num();\n        int i, j;\n\n        int *part_count = new int[num_threads];\n        for (i = 0; i < num_threads; i++)\n            part_count[i] = 0;\n\n        for (i = rank * N / num_threads; i < (rank + 1) * N / num_threads; i++) {\n            for (j = i; j < N; j++) {\n                if (A[i * N + j] == 1)\n                    part_count[rank] += 1;\n            }\n        }\n\n        int *total_count = new int[num_threads];\n        MPI_Reduce(part_count, total_count, num_threads, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n        int total = 0;\n\n        for (i = 0; i < num_threads; i++)\n            total += total_count[i];\n\n        delete[] part_count;\n        delete[] total_count;\n\n        return total;\n    }\n}",
            "int edgeCount = 0;\n  #pragma omp parallel for reduction(+ : edgeCount)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (i!= j && A[i*N + j])\n        ++edgeCount;\n    }\n  }\n\n  return edgeCount;\n}",
            "// You have to implement this function.\n\treturn 0;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // compute number of rows and columns each rank will handle\n  int nRows = N / size;\n  int nCols = N / size;\n  // compute number of rows and columns that each rank will be responsible for\n  // the last ranks will handle more rows or columns if there are any leftovers\n  int nRowsRank = nRows;\n  if (rank + 1 < size)\n    nRowsRank = nRows + 1;\n  int nColsRank = nCols;\n  if (rank + 1 < size)\n    nColsRank = nCols + 1;\n\n  // get local copy of matrix\n  int *localMatrix = new int[nRowsRank * nColsRank];\n  for (int i = 0; i < nRowsRank; i++)\n    for (int j = 0; j < nColsRank; j++)\n      localMatrix[i * nColsRank + j] = A[i * N + j];\n\n  // initialize result array for each rank\n  int *result = new int[nRowsRank];\n  for (int i = 0; i < nRowsRank; i++)\n    result[i] = 0;\n\n  // loop through rows, find edges for each row, add to result\n  int nThreads = omp_get_max_threads();\n  #pragma omp parallel num_threads(nThreads)\n  {\n    int rankInThread = omp_get_thread_num();\n    for (int i = 0; i < nRowsRank; i++) {\n      for (int j = 0; j < nColsRank; j++) {\n        if (localMatrix[i * nColsRank + j] == 1) {\n          // if it's a column that belongs to another rank, send\n          if (j >= nCols) {\n            MPI_Send(&i, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);\n            MPI_Send(&j, 1, MPI_INT, rank + 1, 0, MPI_COMM_WORLD);\n            // if it's a row that belongs to another rank, receive\n          } else if (i >= nRows) {\n            int from, to;\n            MPI_Recv(&from, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            MPI_Recv(&to, 1, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            result[from]++;\n          } else {\n            result[i]++;\n          }\n        }\n      }\n    }\n  }\n\n  // gather results from other ranks\n  std::vector<int> results;\n  if (rank == 0) {\n    results.resize(size);\n  }\n  MPI_Gather(result, nRowsRank, MPI_INT, results.data(), nRowsRank, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // sum up the results\n  int sum = 0;\n  if (rank == 0) {\n    for (auto r : results) {\n      sum += r;\n    }\n  }\n\n  // free memory\n  delete[] localMatrix;\n  delete[] result;\n\n  return sum;\n}",
            "int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    size_t edgeCount = 0;\n    if (rank == 0) {\n        for (size_t i = 0; i < N; i++) {\n            for (size_t j = 0; j < N; j++) {\n                if (A[i*N + j] == 1) {\n                    edgeCount++;\n                }\n            }\n        }\n    }\n    MPI_Bcast(&edgeCount, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    return edgeCount;\n}",
            "int rank, size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int count = 0;\n  int local_count = 0;\n  int row_size = N / size;\n  int row_start = row_size * rank;\n  int row_end = row_start + row_size;\n\n  if(rank == 0)\n    row_end = N;\n  else if(rank == size - 1)\n    row_end = N + (N % size);\n\n  #pragma omp parallel for reduction(+: local_count)\n  for(int i = row_start; i < row_end; i++) {\n    for(int j = i + 1; j < N; j++) {\n      if(A[i * N + j] == 1)\n        local_count++;\n    }\n  }\n\n  MPI_Reduce(&local_count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return count;\n}",
            "int numEdges = 0;\n\n    // Add your code here\n\n    return numEdges;\n}",
            "// TODO\n\n  return 0;\n}",
            "/* YOUR CODE GOES HERE */\n\n  return -1;\n}",
            "int edges = 0;\n\tint rank = 0;\n\tint p = 0;\n\tint m = 0;\n\tint q = 0;\n\tint i = 0;\n\tint j = 0;\n\tint size = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint r = 0;\n\tint mpi_size = size;\n\tint r0 = 0;\n\tint r1 = 0;\n\tint r2 = 0;\n\tint r3 = 0;\n\tint r4 = 0;\n\tint r5 = 0;\n\tint r6 = 0;\n\tint r7 = 0;\n\tint r8 = 0;\n\tint r9 = 0;\n\tint r10 = 0;\n\tint r11 = 0;\n\tint r12 = 0;\n\tint r13 = 0;\n\tint r14 = 0;\n\tint r15 = 0;\n\tint r16 = 0;\n\tint r17 = 0;\n\tint r18 = 0;\n\tint r19 = 0;\n\tint r20 = 0;\n\tint r21 = 0;\n\tint r22 = 0;\n\tint r23 = 0;\n\tint r24 = 0;\n\tint r25 = 0;\n\tint r26 = 0;\n\tint r27 = 0;\n\tint r28 = 0;\n\tint r29 = 0;\n\tint r30 = 0;\n\tint r31 = 0;\n\tint r32 = 0;\n\tint r33 = 0;\n\tint r34 = 0;\n\tint r35 = 0;\n\tint r36 = 0;\n\tint r37 = 0;\n\tint r38 = 0;\n\tint r39 = 0;\n\tint r40 = 0;\n\tint r41 = 0;\n\tint r42 = 0;\n\tint r43 = 0;\n\tint r44 = 0;\n\tint r45 = 0;\n\tint r46 = 0;\n\tint r47 = 0;\n\tint r48 = 0;\n\tint r49 = 0;\n\tint r50 = 0;\n\tint r51 = 0;\n\tint r52 = 0;\n\tint r53 = 0;\n\tint r54 = 0;\n\tint r55 = 0;\n\tint r56 = 0;\n\tint r57 = 0;\n\tint r58 = 0;\n\tint r59 = 0;\n\tint r60 = 0;\n\tint r61 = 0;\n\tint r62 = 0;\n\tint r63 = 0;\n\tint r64 = 0;\n\tint r65 = 0;\n\tint r66 = 0;\n\tint r67 = 0;\n\tint r68 = 0;\n\tint r69 = 0;\n\tint r70 = 0;\n\tint r71 = 0;\n\tint r72 = 0;\n\tint r73 = 0;\n\tint r74 = 0;\n\tint r75 = 0;\n\tint r76 = 0;\n\tint r77 = 0;\n\tint r78 = 0;\n\tint r79 = 0;\n\tint r80 = 0;\n\tint r81 = 0;\n\tint r82 = 0;\n\tint r83 = 0;\n\tint r84 = 0;\n\tint r85 = 0;\n\tint r86 = 0;\n\tint r87 = 0;\n\tint r88 = 0;\n\tint r89 = 0;\n\tint r90 = 0;\n\tint r91 = 0;\n\tint r92 = 0;",
            "}",
            "int n = N;\n\tint num_procs;\n\tint rank;\n\tint num_edges = 0;\n\n\t// MPI\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// OpenMP\n\tint i;\n\tomp_set_num_threads(omp_get_num_procs());\n\n\t// Count edges\n\t#pragma omp parallel for private(i) reduction(+:num_edges)\n\tfor (i = 0; i < n; i++) {\n\t\tfor (int j = 0; j < n; j++) {\n\t\t\tif (A[i * n + j]!= 0 && i!= j) {\n\t\t\t\tnum_edges++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Gather results\n\tint *results = (int *) calloc(num_procs, sizeof(int));\n\tMPI_Gather(&num_edges, 1, MPI_INT, results, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// Sum results\n\tif (rank == 0) {\n\t\tint total_edges = 0;\n\t\tfor (int i = 0; i < num_procs; i++) {\n\t\t\ttotal_edges += results[i];\n\t\t}\n\t\treturn total_edges;\n\t}\n\n\treturn 0;\n}",
            "// TODO: Your code here\n\tint rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint count = 0;\n\tint n = N/size;\n\tint *local_edge = new int[n];\n\tint *result = new int[n];\n\n\tif(rank == 0) {\n\t\tfor(int i=0; i<N; ++i) {\n\t\t\tfor(int j=0; j<N; ++j) {\n\t\t\t\tif(A[i*N+j] == 1) {\n\t\t\t\t\t++count;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfor(int i=0; i<N; ++i) {\n\t\t\tfor(int j=0; j<N; ++j) {\n\t\t\t\tif(A[i*N+j] == 1) {\n\t\t\t\t\t++local_edge[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(local_edge, result, n, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tdelete [] local_edge;\n\n\treturn rank == 0? count : result[0];\n}",
            "// TODO\n    return 0;\n}",
            "int count = 0;\n  int rank, size;\n\n  // Initialize OpenMP threads and determine the number of threads.\n  int num_threads = omp_get_max_threads();\n  #pragma omp parallel\n  {\n    rank = omp_get_thread_num();\n    size = omp_get_num_threads();\n  }\n\n  // Each thread has its own array to keep track of the count of edges\n  // in the submatrix of A assigned to the thread.\n  int* count_thread = new int[num_threads]();\n\n  // Divide the matrix A into MPI processes and assign one submatrix to each process.\n  // The submatrix assigned to each process is an MxN submatrix of A, where\n  // M = (N / size) + (N % size) and N = N / size.\n  // The submatrix assigned to rank 0 is [A[0]... A[M-1][0]... A[N-1]].\n  // The submatrix assigned to rank 1 is [A[M]... A[2*M-1][0]... A[N-1]].\n  // and so on.\n  int m = N / size;\n  int r = N % size;\n\n  // Initialize MPI ranks.\n  MPI_Init(NULL, NULL);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // Divide the submatrix into blocks.\n  // Every block is of size MxN.\n  // The last block is of size M + R x N, where R = N % size.\n  int row_block = m;\n  int col_block = N;\n\n  if (rank == 0) {\n    // Initialize the first MPI process.\n    // Calculate the number of edges in the submatrix of A assigned to this process.\n    for (int i = 0; i < m; i++) {\n      for (int j = 0; j < N; j++) {\n        if (i < N && A[i*N + j]) {\n          count++;\n        }\n      }\n    }\n  } else if (rank < r) {\n    // Initialize the remaining (size-1) processes with R processes.\n    // Calculate the number of edges in the submatrix of A assigned to this process.\n    int offset = (m + 1) * (rank - 1);\n    for (int i = 0; i < m + 1; i++) {\n      for (int j = 0; j < N; j++) {\n        if (i + offset < N && A[i + offset*N + j]) {\n          count++;\n        }\n      }\n    }\n  } else {\n    // Initialize the remaining (size-R) processes with (size-R) processes.\n    // Calculate the number of edges in the submatrix of A assigned to this process.\n    int offset = (m + 1) * (rank - 1);\n    for (int i = 0; i < m; i++) {\n      for (int j = 0; j < N; j++) {\n        if (i + offset < N && A[i + offset*N + j]) {\n          count++;\n        }\n      }\n    }\n  }\n\n  // Communicate the number of edges in each submatrix to the rank 0 process.\n  MPI_Reduce(&count, &count_thread[rank], 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  // Add the counts together to get the final edge count.\n  if (rank == 0) {\n    for (int i = 1; i < size; i++) {\n      count += count_thread[i];\n    }\n  }\n\n  // Clean up MPI.\n  MPI_Finalize();\n\n  return count;\n}",
            "int rank, p;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n    int num_rows = N / p;\n    int edges = 0;\n\n    int *sendCounts = new int[p]();\n    int *displacements = new int[p]();\n\n    if (rank!= 0) {\n        for (int i = 0; i < num_rows; ++i) {\n            for (int j = 0; j < i; ++j) {\n                if (A[i * N + j])\n                    ++sendCounts[rank];\n            }\n        }\n    }\n\n    MPI_Gather(sendCounts, 1, MPI_INT, displacements, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        for (int i = 0; i < p; ++i) {\n            for (int j = 0; j < num_rows; ++j) {\n                for (int k = 0; k < j; ++k) {\n                    if (A[i * num_rows + j] && A[i * num_rows + k])\n                        ++edges;\n                }\n            }\n        }\n        for (int i = 0; i < p; ++i) {\n            for (int j = 0; j < displacements[i]; ++j) {\n                edges++;\n            }\n        }\n    }\n    delete[] sendCounts;\n    delete[] displacements;\n    return edges;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int local_edges = 0;\n    int local_counts[size];\n    #pragma omp parallel for reduction(+:local_edges)\n    for (int i = rank; i < N; i+=size) {\n        for (int j = 0; j < N; ++j) {\n            if (i!= j and A[i*N + j] == 1) {\n                ++local_edges;\n            }\n        }\n    }\n    MPI_Gather(&local_edges, 1, MPI_INT, local_counts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    int global_edges = 0;\n    if (rank == 0) {\n        for (int i = 0; i < size; ++i) {\n            global_edges += local_counts[i];\n        }\n    }\n    return global_edges;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int total = 0;\n\n  // TODO\n  // add OpenMP parallel for loop to compute number of edges\n\n  MPI_Reduce(&total, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return total;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO: Your code here\n  int totalCount = 0;\n  int localCount = 0;\n  int start = N/size*rank;\n  int end = N/size*(rank + 1);\n  for (int i = start; i < end; i++){\n      for(int j = 0; j < N; j++){\n          if (A[i*N + j] == 1){\n              localCount++;\n          }\n      }\n  }\n\n  MPI_Reduce(&localCount, &totalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return totalCount;\n}",
            "if (N == 0) {\n    return 0;\n  }\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int numProcs;\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\n  if (numProcs == 1) {\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i*N + j] == 1) {\n          count++;\n        }\n      }\n    }\n    return count;\n  }\n\n  std::vector<int> A_local;\n  A_local.resize(N*N);\n\n  if (rank == 0) {\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        A_local[i*N + j] = A[i*N + j];\n      }\n    }\n  }\n\n  MPI_Bcast(A_local.data(), N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int count_local = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A_local[i*N + j] == 1) {\n        count_local++;\n      }\n    }\n  }\n\n  int count_global;\n  MPI_Reduce(&count_local, &count_global, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  int count;\n  if (rank == 0) {\n    count = count_global;\n  }\n\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return count;\n}",
            "int rank, numproc;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &numproc);\n\n    if(N % numproc!= 0){\n        printf(\"Not enough processors for N.\\n\");\n        return -1;\n    }\n\n    int count = 0;\n\n#pragma omp parallel for reduction(+:count) num_threads(16)\n    for (size_t row = 0; row < N; row++){\n        for (size_t col = 0; col < N; col++){\n            if (row == col){\n                continue;\n            }\n            if (A[row*N + col] == 1){\n                count++;\n            }\n        }\n    }\n\n    //Rank 0 will have the final answer\n    if (rank == 0){\n        for (int i = 1; i < numproc; i++){\n            int temp;\n            MPI_Recv(&temp, 1, MPI_INT, i, i, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n            count += temp;\n        }\n    }\n    else{\n        MPI_Send(&count, 1, MPI_INT, 0, rank, MPI_COMM_WORLD);\n    }\n    return count;\n}",
            "int rank = 0;\n  int size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int edgeCount = 0;\n\n  /* Your code goes here */\n  int localEdgeCount = 0;\n\n  if (rank == 0) {\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i*N + j] == 1) {\n          localEdgeCount++;\n        }\n      }\n    }\n\n    int sum = 0;\n    for (int i = 1; i < size; i++) {\n      MPI_Recv(&sum, 1, MPI_INT, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      localEdgeCount += sum;\n    }\n  }\n  else {\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i*N + j] == 1) {\n          sum++;\n        }\n      }\n    }\n\n    MPI_Send(&sum, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  }\n\n  MPI_Bcast(&localEdgeCount, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return localEdgeCount;\n}",
            "// YOUR CODE HERE\n}",
            "int sum = 0;\n\n  #pragma omp parallel\n  {\n    int my_sum = 0;\n    int i = omp_get_thread_num();\n\n    #pragma omp for schedule(static)\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i * N + j]) {\n          my_sum++;\n        }\n      }\n    }\n\n    #pragma omp critical\n    sum += my_sum;\n  }\n\n  return sum;\n}",
            "int count = 0;\n  int N_threads = omp_get_max_threads();\n#pragma omp parallel for schedule(dynamic, 1) num_threads(N_threads) reduction(+:count)\n  for(size_t i = 0; i < N; i++) {\n    for(size_t j = 0; j < i; j++) {\n      if(A[i*N+j] == 1)\n        count++;\n    }\n  }\n  return count;\n}",
            "int result = 0;\n\n\t// your code here\n\tint my_rank = 0, p = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tif (my_rank == 0) {\n\t\tint* A_new = new int[N * N];\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tA_new[i * N + j] = A[i * N + j];\n\t\t\t}\n\t\t}\n\t\tstd::vector<int> count(p);\n\t\tfor (int r = 1; r < p; ++r) {\n\t\t\tMPI_Recv(&(A_new[N * N / p * r]), N * N / p, MPI_INT, r, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A_new[i * N + j]) {\n\t\t\t\t\tfor (int k = 0; k < p; ++k) {\n\t\t\t\t\t\tif (i / N * p + k == j / N) {\n\t\t\t\t\t\t\tcount[k]++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (int i = 1; i < p; ++i) {\n\t\t\tMPI_Send(&count[0], p, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t}\n\t\tfor (int i = 0; i < p; ++i) {\n\t\t\tresult += count[i];\n\t\t}\n\t}\n\telse {\n\t\tint* A_new = new int[N * N / p];\n\t\tfor (size_t i = 0; i < N * N / p; ++i) {\n\t\t\tA_new[i] = A[i + N * N / p * (my_rank - 1)];\n\t\t}\n\t\tMPI_Send(&(A_new[0]), N * N / p, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\tMPI_Recv(&result, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t}\n\treturn result;\n}",
            "int num_processors, rank, size, start, end;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &num_processors);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int num_rows = N / num_processors;\n    int remainder = N % num_processors;\n    int i, j;\n\n    if (rank == 0) {\n        start = 0;\n        end = num_rows + remainder;\n    } else {\n        start = rank * num_rows + remainder;\n        end = start + num_rows;\n    }\n\n    int result = 0;\n    int row_size = N;\n\n    // count the number of edges in the local rows assigned to this process\n    for (i = start; i < end; i++) {\n        for (j = 0; j < row_size; j++) {\n            if (A[i*N+j]) {\n                result++;\n            }\n        }\n    }\n\n    // reduce the counts from each process to one on rank 0\n    MPI_Reduce(&result, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "const int size = omp_get_max_threads();\n\tconst int rank = omp_get_thread_num();\n\tstd::vector<int> B = A;\n\tint result = 0;\n\n\tfor (int i = rank; i < N; i += size) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && B[i * N + j]) {\n\t\t\t\tresult++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}",
            "std::vector<int> tmp;\n    tmp.resize(N);\n    MPI_Reduce(&A[0], &tmp[0], N * N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    if (omp_get_thread_num()!= 0) {\n        return 0;\n    }\n    int sum = 0;\n    for (size_t i = 0; i < N * N; i++) {\n        sum += tmp[i];\n    }\n    return sum;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i!= j && A[i + j * N] == 1) {\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "int rank, numRanks;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tint edgeCounts[numRanks];\n\tint totalEdgeCount = 0;\n\tint const numThreads = omp_get_max_threads();\n\tstd::vector<int> localA(A);\n#pragma omp parallel num_threads(numThreads)\n\t{\n\t\tstd::vector<int> localA(localA);\n\t\tint const threadID = omp_get_thread_num();\n\t\tint const threadCount = omp_get_num_threads();\n\t\tint const iStart = (rank * N / numRanks) + threadID;\n\t\tint const iEnd = (rank + 1) * N / numRanks + threadID;\n\t\tint localEdgeCount = 0;\n\t\tfor (int i = iStart; i < iEnd; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tlocalEdgeCount += (i!= j && localA[i * N + j]!= 0);\n\t\t\t}\n\t\t}\n\t\tedgeCounts[rank] = localEdgeCount;\n\t\tif (threadID == 0) {\n\t\t\tMPI_Reduce(MPI_IN_PLACE, edgeCounts, numRanks, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\t} else {\n\t\t\tMPI_Reduce(edgeCounts, edgeCounts, numRanks, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\tMPI_Gather(&edgeCounts[rank], 1, MPI_INT, edgeCounts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < numRanks; ++i) {\n\t\t\ttotalEdgeCount += edgeCounts[i];\n\t\t}\n\t}\n\treturn totalEdgeCount;\n}",
            "int res = 0;\n  int num_threads = omp_get_max_threads();\n  int rank = omp_get_thread_num();\n  int size = omp_get_num_threads();\n  int chunks = N / size;\n  int reminder = N % size;\n  int from, to;\n  if (rank < reminder) {\n    from = (rank * chunks) + rank;\n    to = (rank + 1) * chunks + rank;\n  } else {\n    from = (rank * chunks) + reminder;\n    to = (rank + 1) * chunks + reminder;\n  }\n\n  int offset = 0;\n  for (int i = from; i < to; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        res++;\n        // printf(\"%d %d\\n\", i, j);\n      }\n    }\n  }\n  return res;\n}",
            "// TODO: implement me!\n\treturn 0;\n}",
            "int edgeCount = 0;\n  int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // Your code here.\n  \n  return edgeCount;\n}",
            "// Your code here\n\tint n = N;\n\tint m = (n + 1) / 2;\n\tint num_threads = 1;\n\n\t#pragma omp parallel\n\t{\n\t\tnum_threads = omp_get_num_threads();\n\t}\n\n\tstd::vector<int> local_edge_counts(num_threads, 0);\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < n; i++) {\n\t\tint edge_count = 0;\n\t\tfor (size_t j = 0; j < i; j++) {\n\t\t\tif (A[i * n + j] == 1) {\n\t\t\t\tedge_count += 1;\n\t\t\t}\n\t\t}\n\t\tlocal_edge_counts[omp_get_thread_num()] += edge_count;\n\t}\n\n\tstd::vector<int> global_edge_counts(num_threads, 0);\n\tMPI_Allreduce(local_edge_counts.data(), global_edge_counts.data(),\n\t\tnum_threads, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n\tint global_edge_count = 0;\n\tfor (int i = 0; i < num_threads; i++) {\n\t\tglobal_edge_count += global_edge_counts[i];\n\t}\n\n\treturn global_edge_count;\n}",
            "int result = 0;\n  int rank;\n  int size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int rowLength = N / size;\n  int remainder = N % size;\n  int startRow = rowLength * rank;\n  int numRows = rowLength;\n  if (rank < remainder) {\n    startRow += rank;\n    numRows++;\n  } else if (rank >= remainder) {\n    startRow += remainder;\n  }\n  int numCols = N;\n  if (rank == size - 1) {\n    numRows = N - startRow;\n  }\n\n  for (int i = 0; i < numRows; i++) {\n    for (int j = 0; j < numCols; j++) {\n      if (A[startRow * N + j] == 1 && j > startRow) {\n        result++;\n      }\n    }\n  }\n\n  int temp;\n  MPI_Reduce(&result, &temp, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0)\n    return temp;\n  else\n    return 0;\n}",
            "int sum = 0;\n  int rank, nprocs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n  // Your code goes here\n  int *counts = new int[nprocs];\n  int localSum = 0;\n  int start = rank * (N / nprocs);\n  int end = (rank + 1) * (N / nprocs);\n  if(rank == nprocs - 1) end = N;\n#pragma omp parallel for\n  for(int i = start; i < end; i++) {\n    for(int j = 0; j < i; j++) {\n      if(A[i * N + j] == 1) localSum++;\n    }\n  }\n  counts[rank] = localSum;\n  int sumTotal = 0;\n  for(int i = 0; i < nprocs; i++) {\n    MPI_Reduce(&counts[i], &sumTotal, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  }\n  sum = sumTotal;\n  delete[] counts;\n  return sum;\n}",
            "int myCount = 0;\n\t#pragma omp parallel for reduction(+:myCount)\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tmyCount += A[i*N + j];\n\t\t}\n\t}\n\tint count;\n\tMPI_Reduce(&myCount, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn count/2;\n}",
            "int myId;\n\tint numRanks;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myId);\n\n\tint myTotal = 0;\n\tif (myId == 0) {\n\t\tmyTotal = 0;\n\t\tfor (size_t i = 0; i < N; i++)\n\t\t\tfor (size_t j = 0; j < i; j++)\n\t\t\t\tmyTotal += A[i * N + j];\n\n\t\treturn myTotal;\n\t}\n\n\tint total = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t\tfor (size_t j = 0; j < i; j++)\n\t\t\ttotal += A[i * N + j];\n\n\tMPI_Reduce(&total, &myTotal, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn myTotal;\n}",
            "// TODO: Fill this in\n\treturn 0;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    // number of edges in graph\n    int total = 0;\n    int counter = 0;\n    // for MPI\n    int i = 0;\n    int rankSize;\n    int count = 0;\n    // number of edges in each node\n    int myEdgeCount[size];\n\n    // for omp\n    int myRank = rank;\n    int myN = N;\n    int myTotal = 0;\n    int myCount = 0;\n    int myCounter = 0;\n\n    // for every rank\n    if (rank == 0) {\n        rankSize = N;\n    } else {\n        rankSize = N/size;\n    }\n\n    // for omp\n    #pragma omp parallel shared(A, myRank, myTotal, myCount, myCounter) private(myN, i)\n    {\n        myN = rankSize;\n        #pragma omp for\n        for (i = 0; i < myN; i++) {\n            for (int j = 0; j < myN; j++) {\n                if (A[i*myN + j] == 1) {\n                    myCounter++;\n                }\n            }\n            myTotal = myTotal + myCounter;\n            myCount = myCount + 1;\n            myCounter = 0;\n        }\n    }\n\n    MPI_Gather(&myTotal, 1, MPI_INT, myEdgeCount, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Reduce(&myCount, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    MPI_Reduce(&myEdgeCount[0], &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        printf(\"My total is %d\\n\", total);\n        printf(\"The total number of edges is %d\\n\", total/2);\n    }\n    return total/2;\n}",
            "int count = 0;\n\n  if (N < 1) {\n    return count;\n  }\n\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[i*N + j]!= 0) {\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "// Use OpenMP to compute in parallel\n#pragma omp parallel for reduction(+ : edges)\n\t// Use MPI to compute in parallel\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tfor(int i=0; i<N; i++) {\n\t\tfor(int j=0; j<N; j++) {\n\t\t\tif(A[i*N + j] == 1) edges++;\n\t\t}\n\t}\n\treturn edges;\n}",
            "int nrank, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nrank);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank == 0) {\n\t\tstd::cout << \"MPI: using \" << nrank << \" ranks\\n\";\n\t}\n\n\tint result = 0;\n\n\t// Do the computation on the current rank.\n\tint start = rank * (N / nrank);\n\tint stop = (rank + 1) * (N / nrank);\n\tfor (int i = start; i < stop; i++) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tresult += A[i*N + j] + A[j*N + i];\n\t\t}\n\t}\n\n\t// Do the reduction.\n\tint nresults;\n\tMPI_Reduce(&result, &nresults, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// Return the result.\n\tif (rank == 0) {\n\t\tstd::cout << \"MPI: result = \" << nresults << \"\\n\";\n\t}\n\n\treturn nresults;\n}",
            "int edgeCount = 0;\n\tif (A[0] == 1) edgeCount++;\n\tfor (size_t i = 1; i < N; i++) {\n\t\tif (A[i] == 1) edgeCount++;\n\t}\n\treturn edgeCount;\n}",
            "int numEdges = 0;\n\n  // TODO\n\n  return numEdges;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i+1; j < N; j++) {\n\t\t\tif (A[i*N + j] > 0)\n\t\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int localN = N / size;\n\n  int sum = 0;\n  for (int i = 0; i < localN; i++) {\n    for (int j = 0; j < localN; j++) {\n      if (i < j) sum += A[i * localN + j];\n    }\n  }\n\n  int result;\n  MPI_Reduce(&sum, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return result;\n}",
            "int n_processes, my_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_processes);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n\tint p, q;\n\tp = 0;\n\tq = n_processes;\n\twhile (p < q) {\n\t\tint r = (p + q) / 2;\n\t\tif (my_rank < r) {\n\t\t\tq = r;\n\t\t}\n\t\telse {\n\t\t\tp = r + 1;\n\t\t}\n\t}\n\n\tint n_threads = omp_get_max_threads();\n\tint n_per_thread = N / n_threads;\n\tint n_left = N - n_threads * n_per_thread;\n\n\tint count = 0;\n\n\t#pragma omp parallel for num_threads(n_threads) shared(A, count, n_per_thread, n_left)\n\tfor (int i = 0; i < n_threads; ++i) {\n\t\tint start = i * n_per_thread;\n\t\tint end = start + n_per_thread;\n\t\tif (i == 0) {\n\t\t\tstart += n_left;\n\t\t}\n\t\telse if (i == n_threads - 1) {\n\t\t\tend -= n_left;\n\t\t}\n\t\tint count_thread = 0;\n\t\tfor (int k = start; k < end; ++k) {\n\t\t\tfor (int l = 0; l < N; ++l) {\n\t\t\t\tif (A[k * N + l] && A[l * N + k]) {\n\t\t\t\t\t++count_thread;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\tcount += count_thread;\n\t}\n\tif (my_rank == 0) {\n\t\treturn count;\n\t}\n\telse {\n\t\treturn 0;\n\t}\n}",
            "auto numOfEdges = 0;\n  std::vector<int> row(N);\n\n  /* Your solution goes here */\n  int my_rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  int num_of_ranks = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_of_ranks);\n\n  if (my_rank == 0) {\n    for (size_t i = 0; i < N; i++) {\n      row = std::vector<int>(A.begin() + i * N, A.begin() + i * N + N);\n      MPI_Send(&row[0], N, MPI_INT, my_rank, 0, MPI_COMM_WORLD);\n    }\n  }\n\n  if (my_rank == 0) {\n    for (int i = 1; i < num_of_ranks; i++) {\n      MPI_Status status;\n      MPI_Probe(i, 0, MPI_COMM_WORLD, &status);\n      int count;\n      MPI_Get_count(&status, MPI_INT, &count);\n      std::vector<int> tmp(count);\n      MPI_Recv(&tmp[0], count, MPI_INT, status.MPI_SOURCE, 0, MPI_COMM_WORLD,\n               MPI_STATUS_IGNORE);\n      numOfEdges += count;\n    }\n  } else {\n    std::vector<int> tmp(N);\n    MPI_Status status;\n    MPI_Recv(&tmp[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    for (size_t i = 0; i < N; i++) {\n      if (tmp[i] == 1) {\n        numOfEdges++;\n      }\n    }\n  }\n  return numOfEdges;\n}",
            "int my_rank = 0, num_ranks = 0, my_size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n    MPI_Comm_size(MPI_COMM_WORLD, &my_size);\n\n    const int edges = 0;\n    int edges_sum = 0;\n\n    int start_index = my_rank*N/num_ranks;\n    int end_index = (my_rank+1)*N/num_ranks;\n\n    if(my_rank == num_ranks-1) {\n        end_index = N;\n    }\n\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < i; j++) {\n            if(A[i*N + j] == 1) {\n                edges_sum++;\n            }\n        }\n    }\n\n    MPI_Reduce(&edges_sum, &edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return edges;\n}",
            "// your code here\n}",
            "int size, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    if (rank == 0) {\n        std::cout << \"Number of MPI processes: \" << size << std::endl;\n    }\n\n    // number of edges in the submatrix of rank 0\n    int result = 0;\n\n    // number of edges in the submatrix of this rank\n    int local_result = 0;\n\n    // every process has a complete copy of the input\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (i < j)\n                local_result += A[i * N + j];\n        }\n    }\n\n    // sum of the local results\n    int sum;\n\n    // reduce the local result using the sum operation\n    MPI_Reduce(&local_result, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        result = sum;\n    }\n\n    return result;\n}",
            "/*\n   * TODO: your solution goes here\n   */\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int num_proc;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n  if (N % num_proc!= 0) {\n    std::cerr << \"Error: Number of rows in A does not divide evenly by the number of ranks\" << std::endl;\n    return -1;\n  }\n  if (N < num_proc) {\n    std::cerr << \"Error: Number of rows in A is less than the number of ranks\" << std::endl;\n    return -1;\n  }\n\n  std::vector<int> A_copy(A);\n  int count = 0;\n  int const start = rank * N / num_proc;\n  int const end = start + N / num_proc;\n\n#pragma omp parallel for reduction(+:count)\n  for (int i = start; i < end; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A_copy[i * N + j]!= 0) {\n        count += 1;\n      }\n    }\n  }\n\n  int count_all;\n  MPI_Reduce(&count, &count_all, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    return count_all;\n  } else {\n    return 0;\n  }\n}",
            "int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < i; ++j) {\n      if (A[i * N + j] == 1) {\n        ++count;\n      }\n    }\n  }\n  return count;\n}",
            "int count=0;\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = i+1; j < N; ++j)\n      if (A[i*N+j])\n\t++count;\n  return count;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for reduction(+:count)\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j]) {\n\t\t\t\tif(i < j) count++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  return count;\n}",
            "// MPI code goes here.\n\tMPI_Init(NULL, NULL);\n\tint numprocs, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t\n\t// OpenMP code goes here.\n\tint count=0;\n\tomp_set_num_threads(numprocs);\n\t\n\tif(rank==0){\n\t\tfor(int i=0;i<N;i++){\n\t\t\tfor(int j=0;j<N;j++){\n\t\t\t\tif(i!=j && A[i*N+j]==1) count++;\n\t\t\t}\n\t\t}\n\t\tstd::cout << count << std::endl;\n\t}\n\t\n\tMPI_Finalize();\n\treturn count;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint i = rank * N / size;\n\tint j = (rank + 1) * N / size;\n\tif (rank == size - 1) j = N;\n\tint count = 0;\n\tfor (; i < j; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) continue;\n\t\t\tif (A[N*i+j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> counts(size);\n\tMPI_Gather(&count, 1, MPI_INT, counts.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\tint sum = 0;\n\t\tfor (int r = 0; r < size; r++) {\n\t\t\tsum += counts[r];\n\t\t}\n\t\treturn sum;\n\t}\n\treturn 0;\n}",
            "int nthreads = omp_get_max_threads();\n\tint nranks = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nranks);\n\tassert(nranks >= nthreads);\n\n\tint rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint edges = 0;\n\n\t// Every rank works on every line of A\n\t#pragma omp parallel for num_threads(nthreads) reduction(+:edges)\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// Every thread works on every column of a line\n\t\t#pragma omp parallel for num_threads(nthreads) reduction(+:edges)\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[N*i + j] == 1)\n\t\t\t\tedges++;\n\t\t}\n\t}\n\t\n\tint edgeCount = 0;\n\tMPI_Reduce(&edges, &edgeCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (rank == 0)\n\t\treturn edgeCount;\n\telse\n\t\treturn 0;\n}",
            "int myId, numProcs;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &myId);\n\n  int start = myId * (N/numProcs);\n  int end = (myId + 1) * (N/numProcs);\n  if(myId == numProcs - 1){\n    end = N;\n  }\n  int localEdges = 0;\n  int localEdgesCounter;\n  #pragma omp parallel for private(localEdgesCounter) reduction(+:localEdges)\n  for(int i = start; i < end; i++){\n    for(int j = 0; j < N; j++){\n      localEdgesCounter = 0;\n      if(A[i * N + j] == 1){\n        localEdgesCounter += 1;\n      }\n      if(A[j * N + i] == 1){\n        localEdgesCounter += 1;\n      }\n      localEdges += localEdgesCounter;\n    }\n  }\n\n  int globalEdges;\n\n  MPI_Reduce(&localEdges, &globalEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  int output;\n\n  if(myId == 0){\n    output = globalEdges;\n  }\n\n  return output;\n}",
            "int result = 0;\n  int my_result;\n\n  #pragma omp parallel for schedule(dynamic) reduction(+:result)\n  for(int i=0;i<N;i++){\n    for(int j=0;j<N;j++){\n      if(A[i*N+j]==1){\n        result++;\n      }\n    }\n  }\n  return result;\n}",
            "int num_threads;\n\tint rank;\n\tint n_procs;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n\n\tstd::vector<int> local_A;\n\tint count = 0;\n\tint final_count = 0;\n\n\tnum_threads = omp_get_max_threads();\n\n\tint local_count;\n\tint local_N = N / n_procs;\n\tint local_i;\n\tint local_j;\n\tint local_k;\n\n\tif (rank == 0) {\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tfinal_count = count;\n\t}\n\n\tlocal_A.assign(A.begin() + rank * local_N * local_N, A.begin() + (rank + 1) * local_N * local_N);\n\n\tomp_set_num_threads(num_threads);\n\n\t#pragma omp parallel shared(local_A) private(local_i, local_j, local_k)\n\t{\n\t\tlocal_count = 0;\n\t\tlocal_i = omp_get_thread_num();\n\t\tlocal_j = 0;\n\t\tlocal_k = 0;\n\n\t\twhile (local_j < local_N) {\n\t\t\twhile (local_k < local_N) {\n\t\t\t\tif (local_A[local_i * local_N + local_j] == 1 && local_A[local_j * local_N + local_k] == 1) {\n\t\t\t\t\tlocal_count++;\n\t\t\t\t}\n\t\t\t\tlocal_k++;\n\t\t\t}\n\t\t\tlocal_j++;\n\t\t\tlocal_k = 0;\n\t\t}\n\n\t\t#pragma omp atomic\n\t\tfinal_count += local_count;\n\t}\n\n\tif (rank == 0) {\n\t\treturn final_count;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "int edgeCount=0;\n  #pragma omp parallel for\n  for(int i=0; i<N; i++){\n    for(int j=0; j<N; j++){\n      if(A[i*N+j] == 1) {\n        edgeCount++;\n      }\n    }\n  }\n  return edgeCount;\n}",
            "// Your code goes here!\n\n  int count = 0;\n  for(int i = 0; i < N; ++i){\n    for(int j = 0; j < N; ++j){\n      if(A[i*N + j] == 1){\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint edges = 0;\n\tif (rank == 0) {\n\t\t// root rank\n\t\t#pragma omp parallel for reduction(+ : edges)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) edges++;\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\t// non-root ranks\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) edges++;\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&edges, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\tint sum = 0;\n\tif (rank == 0) {\n\t\t// root rank\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tint temp;\n\t\t\tMPI_Recv(&temp, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tsum += temp;\n\t\t}\n\t\treturn sum + edges;\n\t}\n\treturn edges;\n}",
            "// Your code goes here.\n    int result = 0;\n    for(int i = 0; i < N; i++){\n        for(int j = i+1; j < N; j++){\n            if(A[i * N + j] == 1)\n                result++;\n        }\n    }\n\n    return result;\n\n}",
            "// TODO: replace this with your code\n    int result = 0;\n    #pragma omp parallel for reduction(+ : result)\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (i == j) continue;\n            if (A[i * N + j] == 1) result += 1;\n        }\n    }\n    return result;\n}",
            "int rank = 0;\n    int numRanks = 0;\n    int edges = 0;\n    int numEdges = 0;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\n    edges = 0;\n    if (rank == 0) {\n        numEdges = (N * (N - 1)) / 2;\n    }\n    MPI_Bcast(&numEdges, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int n = numEdges / numRanks;\n    int m = 0;\n    if (rank!= 0) {\n        m = rank * n;\n    }\n\n    int a = 0;\n    if (rank == 0) {\n        for (size_t i = 0; i < A.size(); i++) {\n            a = A[i];\n            if (a > 0) {\n                edges += n;\n            }\n        }\n    } else {\n        for (size_t i = m; i < m + n; i++) {\n            a = A[i];\n            if (a > 0) {\n                edges += 1;\n            }\n        }\n    }\n\n    MPI_Reduce(&edges, &numEdges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        return numEdges;\n    } else {\n        return 0;\n    }\n}",
            "return -1;\n}",
            "std::vector<int> local_sums(omp_get_max_threads(), 0);\n    omp_set_dynamic(0);\n    omp_set_num_threads(omp_get_max_threads());\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; ++i) {\n        int local_sum = 0;\n        for(size_t j = 0; j < N; ++j) {\n            local_sum += A[i * N + j];\n        }\n        local_sums[omp_get_thread_num()] += local_sum;\n    }\n\n    int global_sum = 0;\n    MPI_Reduce(local_sums.data(), &global_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return global_sum;\n}",
            "int x=1;\n\t\tint y=0;\n\t\tint t=0;\n\t\tint sum=0;\n\n\t\tomp_set_num_threads(4);\n\n\t\t#pragma omp parallel default(shared) num_threads(4)\n\t\t{\n\t\t\t#pragma omp sections nowait\n\t\t\t{\n\t\t\t\t#pragma omp section\n\t\t\t\t{\n\t\t\t\t\tfor(int i=0;i<(N/2);i++){\n\t\t\t\t\t\tfor(int j=0;j<(N/2);j++){\n\t\t\t\t\t\t\tif(A[j+x*N]==1)\n\t\t\t\t\t\t\t\tsum++;\n\t\t\t\t\t\t\t\ty++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t#pragma omp section\n\t\t\t\t{\n\t\t\t\t\tfor(int i=N/2;i<N;i++){\n\t\t\t\t\t\tfor(int j=0;j<N;j++){\n\t\t\t\t\t\t\tif(A[j+x*N]==1)\n\t\t\t\t\t\t\t\tsum++;\n\t\t\t\t\t\t\t\ty++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t#pragma omp section\n\t\t\t\t{\n\t\t\t\t\tfor(int i=0;i<N;i++){\n\t\t\t\t\t\tfor(int j=N/2;j<(3*N/2);j++){\n\t\t\t\t\t\t\tif(A[j+x*N]==1)\n\t\t\t\t\t\t\t\tsum++;\n\t\t\t\t\t\t\t\ty++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t#pragma omp section\n\t\t\t\t{\n\t\t\t\t\tfor(int i=0;i<N;i++){\n\t\t\t\t\t\tfor(int j=3*N/2;j<N;j++){\n\t\t\t\t\t\t\tif(A[j+x*N]==1)\n\t\t\t\t\t\t\t\tsum++;\n\t\t\t\t\t\t\t\ty++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn sum;\n\n\n\t\tint sum=0;\n\t\tfor(int i=0;i<N;i++){\n\t\t\tfor(int j=0;j<N;j++){\n\t\t\t\tif(A[i+j*N]==1)\n\t\t\t\t\tsum++;\n\t\t\t}\n\t\t}\n\t\treturn sum;\n\n\n}",
            "// TODO: implement this function\n}",
            "// TODO\n  return 0;\n}",
            "// TODO: insert your code here.\n\tint local_edges = 0;\n\t#pragma omp parallel\n\t{\n\t\tint rank = omp_get_thread_num();\n\t\tint thread = omp_get_num_threads();\n\t\tint start = rank * N/thread;\n\t\tint end = (rank+1) * N/thread;\n\t\t//printf(\"%d %d\\n\", start, end);\n\t\tfor(int i = start; i < end; i++) {\n\t\t\tfor(int j = start; j < end; j++) {\n\t\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\t\tlocal_edges += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint global_edges = 0;\n\tMPI_Reduce(&local_edges, &global_edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t//printf(\"%d %d\\n\", rank, global_edges);\n\treturn global_edges;\n}",
            "int r = 0;\n\n\t#pragma omp parallel for reduction(+:r)\n\tfor(size_t i = 0; i < A.size(); i += 4)\n\t{\n\t\tfor(size_t j = 1; j < 4; ++j)\n\t\t{\n\t\t\tif(A[i + j] > 0)\n\t\t\t\tr += 1;\n\t\t}\n\t}\n\n\treturn r;\n}",
            "int local_count = 0;\n  #pragma omp parallel for reduction(+: local_count)\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (i!= j && A[i + j * N] == 1)\n        local_count++;\n\n  // Combine results from all ranks\n  MPI_Reduce(&local_count, NULL, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return local_count;\n}",
            "int num_proc, proc_id;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &proc_id);\n\t\n\tstd::vector<int> local_A;\n\t\n\tint edges = 0;\n\tint loc_edges = 0;\n\t\n\tif(proc_id == 0) {\n\t\tlocal_A.resize(N*N);\n\t\tfor(size_t i = 0; i < N*N; i++) {\n\t\t\tlocal_A[i] = A[i];\n\t\t}\n\t}\n\t\n\tMPI_Bcast(local_A.data(), N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\tfor(size_t i = proc_id; i < N; i += num_proc) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(local_A[i*N + j] == 1) {\n\t\t\t\tloc_edges++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint global_edges;\n\tMPI_Reduce(&loc_edges, &global_edges, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\n\treturn global_edges;\n}",
            "// TODO: write the code\n}",
            "// TODO: Implement\n\tint edgecount = 0;\n\t\n\t#pragma omp parallel for default(none) shared(A, N, edgecount)\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A[i * N + j] > 0){\n\t\t\t\t#pragma omp atomic\n\t\t\t\tedgecount += 1;\n\t\t\t}\n\t\t}\n\t}\n\t\n    return edgecount;\n}",
            "int p, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &p);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int row_size = N / p;\n  int rest = N % p;\n\n  int num_edges = 0;\n\n#pragma omp parallel for reduction(+ : num_edges)\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i == j) {\n        continue;\n      }\n      if (A[i * N + j] == 1) {\n        num_edges++;\n      }\n    }\n  }\n\n  int recv_num = 0;\n  MPI_Status status;\n  if (p > 1) {\n    if (rank == 0) {\n      for (int i = 1; i < p; i++) {\n        MPI_Recv(&recv_num, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n        num_edges += recv_num;\n      }\n    } else {\n      MPI_Send(&num_edges, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n  }\n\n  return num_edges;\n}",
            "// TODO: your code here\n}",
            "int num_procs, proc_id;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &proc_id);\n\n    if (proc_id == 0) {\n        int num_edges = 0;\n        for (size_t i = 0; i < A.size(); ++i) {\n            if (A[i] == 1) {\n                num_edges++;\n            }\n        }\n        return num_edges;\n    }\n    else {\n        return 0;\n    }\n}",
            "int result = 0;\n#pragma omp parallel for reduction(+ : result)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tresult += 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "auto rowNum = static_cast<int>(N);\n    auto colNum = static_cast<int>(N);\n    auto threadNum = omp_get_max_threads();\n    std::vector<int> result(threadNum, 0);\n#pragma omp parallel for num_threads(threadNum)\n    for (int i = 0; i < rowNum; i++) {\n        for (int j = i + 1; j < colNum; j++) {\n            if (A[i * rowNum + j] == 1) {\n#pragma omp atomic\n                result[omp_get_thread_num()] += 1;\n            }\n        }\n    }\n    int final_result = 0;\n    for (auto x : result) {\n        final_result += x;\n    }\n    return final_result;\n}",
            "int res = 0;\n  int nRanks, rankId;\n  int tag = 1000;\n  MPI_Comm_size(MPI_COMM_WORLD, &nRanks);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rankId);\n  if (rankId == 0) {\n    int i, j, nThreads;\n    std::vector<int> counts(nRanks);\n#pragma omp parallel\n    {\n      nThreads = omp_get_num_threads();\n      if (omp_get_thread_num() == 0) {\n\tprintf(\"Using %d MPI ranks and %d OpenMP threads\\n\", nRanks, nThreads);\n      }\n#pragma omp for schedule(dynamic) reduction(+:res)\n      for (i = 0; i < N; i++)\n\tfor (j = i + 1; j < N; j++)\n\t  if (A[i*N + j] == 1)\n\t    res++;\n    }\n    // Send each thread's count to rank 0\n    for (i = 1; i < nRanks; i++)\n      MPI_Send(&res, 1, MPI_INT, i, tag, MPI_COMM_WORLD);\n    for (i = 0; i < nRanks; i++)\n      MPI_Recv(&counts[i], 1, MPI_INT, i, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    // Sum all the counts\n    for (i = 0; i < nRanks; i++)\n      res += counts[i];\n  } else {\n    // Other ranks receive the result from rank 0\n    MPI_Recv(&res, 1, MPI_INT, 0, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    // Send their count to rank 0\n    MPI_Send(&res, 1, MPI_INT, 0, tag, MPI_COMM_WORLD);\n  }\n  return res;\n}",
            "int rank = 0;\n    int size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int blockSize = N / size;\n\n    if (rank!= 0) {\n        if (rank!= size - 1) {\n            std::vector<int> A_part(blockSize * N, 0);\n            MPI_Recv(&A_part[0], blockSize * N, MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        }\n    } else {\n        std::vector<int> A_part(blockSize * (size - 1), 0);\n        MPI_Recv(&A_part[0], blockSize * (size - 1), MPI_INT, rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n\n    int count = 0;\n\n    if (rank == 0) {\n        for (size_t i = 0; i < N; i++) {\n            for (size_t j = 0; j < N; j++) {\n                if (i < j && A[i * N + j] == 1)\n                    count++;\n            }\n        }\n    } else if (rank == size - 1) {\n        for (size_t i = 0; i < blockSize; i++) {\n            for (size_t j = 0; j < N; j++) {\n                if (i * blockSize + i < j && A[(i * blockSize + i) * N + j] == 1)\n                    count++;\n            }\n        }\n    } else {\n        for (size_t i = 0; i < blockSize; i++) {\n            for (size_t j = 0; j < N; j++) {\n                if (i * blockSize + i < j && A[(i * blockSize + i) * N + j] == 1)\n                    count++;\n            }\n        }\n    }\n\n    std::vector<int> count_parts(size - 1, 0);\n    std::vector<int> count_parts2(size - 1, 0);\n\n    MPI_Gather(&count, 1, MPI_INT, &count_parts[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int res = 0;\n\n    if (rank == 0) {\n        for (size_t i = 0; i < size - 1; i++)\n            res += count_parts[i];\n        res /= 2;\n    } else {\n        MPI_Gather(&count, 1, MPI_INT, &count_parts2[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n        MPI_Send(&count_parts2[0], 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    return res;\n}",
            "int num_of_edges = 0;\n\n  // TODO: insert your code here\n\n  return num_of_edges;\n}",
            "if (N == 0) {\n    return 0;\n  }\n  if (N == 1) {\n    return A[0];\n  }\n\n  int edge_count = 0;\n  int n = N/2;\n  std::vector<int> B(n*n);\n\n  #pragma omp parallel\n  {\n    int my_rank = omp_get_thread_num();\n    int n_threads = omp_get_num_threads();\n    int row_begin = my_rank * n;\n    int row_end = row_begin + n;\n\n    // compute part of B\n    #pragma omp for reduction(+:edge_count)\n    for(int i = 0; i < n; i++) {\n      for(int j = 0; j < n; j++) {\n        int a11 = A[(i * N) + j];\n        int a21 = A[(i * N) + (j + n)];\n        int a12 = A[((i + n) * N) + j];\n        int a22 = A[((i + n) * N) + (j + n)];\n\n        int b = (a11 ^ a22) + (a21 ^ a12);\n\n        B[(i * n) + j] = b;\n        edge_count += b;\n      }\n    }\n\n    // send and receive from another thread\n    if(my_rank == 0) {\n      for(int i = 1; i < n_threads; i++) {\n        int row_begin = i * n;\n        MPI_Recv(&B[row_begin*n], n*n, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      }\n    }\n    if(my_rank!= 0) {\n      MPI_Send(&B[row_begin*n], n*n, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n\n    // combine with other threads\n    if(my_rank == 0) {\n      for(int i = 1; i < n_threads; i++) {\n        int row_begin = i * n;\n        for(int j = 0; j < n; j++) {\n          for(int k = 0; k < n; k++) {\n            B[row_begin*n + j] += B[(row_begin+n)*n + k];\n          }\n        }\n      }\n    }\n    #pragma omp barrier\n\n    // reduce edge_count\n    if(my_rank == 0) {\n      for(int i = 0; i < n; i++) {\n        for(int j = 0; j < n; j++) {\n          edge_count += B[i*n + j];\n        }\n      }\n    }\n  }\n  return edge_count;\n}",
            "int rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint numRows = N / size;\n\tint numCols = N;\n\tint edgeCount = 0;\n\n\tif (rank == 0) {\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Send(A.data() + i * numRows * numCols, numRows * numCols, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t}\n\n\t\tfor (int i = 0; i < numRows * numCols; i++) {\n\t\t\tif (A[i]) edgeCount++;\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tint localEdgeCount = 0;\n\t\t\tMPI_Recv(&localEdgeCount, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tedgeCount += localEdgeCount;\n\t\t}\n\n\t} else {\n\t\tint localEdgeCount = 0;\n\t\tint *localA = (int *) malloc(numRows * numCols * sizeof(int));\n\n\t\tMPI_Recv(localA, numRows * numCols, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t\t#pragma omp parallel for reduction(+:localEdgeCount)\n\t\tfor (int i = 0; i < numRows * numCols; i++) {\n\t\t\tif (localA[i]) localEdgeCount++;\n\t\t}\n\n\t\tMPI_Send(&localEdgeCount, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\treturn edgeCount;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "kokkos",
        "prompt": "#include <Kokkos_Core.hpp>\n\n/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix.\n\t Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(Kokkos::View<const int**> &A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "Kokkos::View<int*> count(\"count\", N);\n  Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int i) {\n    if(count[i] == 0) {\n      Kokkos::single(Kokkos::PerThread(Kokkos::PerThreadSpace<>(i)), [&]() {\n        count[i] = 1;\n        for(size_t j = 0; j < N; j++) {\n          if(A(i,j)!= 0 && count[j] == 0) {\n            Kokkos::single(Kokkos::PerThread(Kokkos::PerThreadSpace<>(j)), [&]() {\n              count[j] = 1;\n            });\n          }\n        }\n      });\n    }\n  });\n  Kokkos::fence();\n  int ret = 0;\n  for(size_t i = 0; i < N; i++) {\n    ret += count[i];\n  }\n  return ret;\n}",
            "auto components = Kokkos::View<int*>(\"components\", N);\n  Kokkos::parallel_for(\n    \"initialize components\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    [&] (int i) { components[i] = i; }\n  );\n\n  int numComponents = 0;\n  Kokkos::parallel_for(\n    \"find components\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    [&] (int i) {\n      for (int j = i + 1; j < N; j++) {\n        if (A(i,j)!= 0) {\n          // find the root of the tree containing component[j]\n          int k = j;\n          while (components(k)!= k) {\n            k = components(k);\n          }\n          // make all nodes that point to j point to the root of that tree instead\n          while (components(j)!= j) {\n            int oldParent = components(j);\n            components(j) = k;\n            j = oldParent;\n          }\n        }\n      }\n    }\n  );\n\n  Kokkos::parallel_reduce(\n    \"count components\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    [&] (int i, int &numComponentsLocal) {\n      // find the root of the tree containing i\n      int k = i;\n      while (components(k)!= k) {\n        k = components(k);\n      }\n      // if k is not the same as i, then the node at i is in the same tree as k\n      if (k!= i) {\n        // so set the component number to the same as the root\n        components(i) = k;\n      }\n\n      // if this component has not yet been seen, count it\n      if (components(i) == i) {\n        numComponentsLocal++;\n      }\n    },\n    numComponents\n  );\n\n  return numComponents;\n}",
            "int count = 0;\n  Kokkos::View<int*> isvisited(\"isvisited\", N);\n  Kokkos::parallel_for(\"count_components\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(const int& i) {\n                         if (isvisited(i) == 0) {\n                           isvisited(i) = 1;\n                           count++;\n                           for (int j = 0; j < N; j++) {\n                             if (A(i, j) == 1 && isvisited(j) == 0) {\n                               isvisited(j) = 1;\n                             }\n                           }\n                         }\n                       });\n  Kokkos::fence();\n  return count;\n}",
            "// Create a boolean array to store the component\n\tKokkos::View<int*> component(\"component\", N);\n\t// Fill it with all zeros (i.e. unassigned)\n\tKokkos::deep_copy(component, 0);\n\n\t// Create a boolean array to record whether a component is already assigned\n\tKokkos::View<int*> assigned(\"assigned\", N);\n\t// Fill it with all zeros (i.e. unassigned)\n\tKokkos::deep_copy(assigned, 0);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\t// If we've already assigned this node\n\t\tif (assigned(i)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Assign this node to a component\n\t\tint componentId = 1;\n\n\t\t// Mark this node as assigned\n\t\tassigned(i) = 1;\n\n\t\t// Find all connected nodes\n\t\tint node;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tnode = A(i, j);\n\t\t\tif (node == 1) {\n\t\t\t\tif (!assigned(j)) {\n\t\t\t\t\tassigned(j) = 1;\n\t\t\t\t}\n\t\t\t\tcomponent(j) = componentId;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Count the number of components\n\tint componentCount = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component(i) > 0) {\n\t\t\tcomponentCount++;\n\t\t}\n\t}\n\n\treturn componentCount;\n}",
            "// Fill this in\n  return 0;\n}",
            "// Compute the number of connected components\n\t//...\n\n\treturn -1;\n}",
            "// TODO: implement this function\n\n    return -1;\n}",
            "/* Implement this function */\n  return 0;\n}",
            "// TODO: insert your solution code here\n\n\t// Kokkos::View<bool**> visited(\"visited\", N, N);\n\tKokkos::View<bool**> visited(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"visited\"), N, N);\n\tKokkos::parallel_for(\"initialize_visited\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tvisited(i, j) = false;\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tKokkos::View<size_t*> count(\"count\", N);\n\tKokkos::parallel_for(\"initialize_count\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tcount(i) = 0;\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(\"count_cc\", N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A(i, j)!= 0) {\n\t\t\t\tif (!visited(i, j)) {\n\t\t\t\t\tDFS(A, visited, count, i, j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tsize_t sum = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tsum += count(i);\n\t}\n\n\treturn sum;\n}",
            "// TODO\n\t// 1. Declare a Kokkos::View<int> of size N. Call it labels.\n\t// 2. Create a parallel_for Kokkos kernel, where each thread sets labels[i] to i.\n\t// 3. Create a parallel_for Kokkos kernel, where each thread visits all rows and columns of A.\n\t// 4. If the row and column are in the same connected component, set labels[row] = labels[col].\n\t// 5. Create a parallel_reduce Kokkos kernel, where each thread adds the difference between\n\t//    its label and the first element of labels to a local sum. Then, at the end, add up all the\n\t//    local sums to get the final count.\n\n}",
            "// Define a C++ functor to do the computation\n\tclass MyFunctor {\n\tpublic:\n\t\tKokkos::View<int**> A;\n\t\tint *visited;\n\t\tint *component;\n\t\tMyFunctor(Kokkos::View<int**> &A, int *visited, int *component) : A(A), visited(visited), component(component) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator()(int i) const {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tcomponent[i] = i;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tif (visited[j] == 0) {\n\t\t\t\t\t\t\tcomponent[i] = component[j];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\t// Define the functor as a policy\n\tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Static>, Kokkos::IndexType<int>> rangePolicy(0, N);\n\n\tint *visited = new int[N];\n\tint *component = new int[N];\n\tfor (int i = 0; i < N; ++i) {\n\t\tvisited[i] = 0;\n\t\tcomponent[i] = i;\n\t}\n\n\tMyFunctor myFunctor(A, visited, component);\n\tKokkos::parallel_for(rangePolicy, myFunctor);\n\n\tint connectedComponents = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 1) {\n\t\t\t++connectedComponents;\n\t\t}\n\t}\n\n\tdelete[] visited;\n\tdelete[] component;\n\n\treturn connectedComponents;\n}",
            "int numberOfComponents = 0;\n\tKokkos::View<int*> isConnected(\"isConnected\", N);\n\tKokkos::View<int*> componentId(\"componentId\", N);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ExecPolicy::seq, int>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tisConnected[i] = 1;\n\t\tcomponentId[i] = 0;\n\t});\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ExecPolicy::seq, int>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tKokkos::atomic_compare_exchange(&isConnected[j], 1, 0);\n\t\t\t\tKokkos::atomic_compare_exchange(&componentId[j], 0, i);\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::ExecPolicy::seq, int>(0, N), KOKKOS_LAMBDA(const int i, int &sum) {\n\t\tif (isConnected[i]) {\n\t\t\tsum++;\n\t\t}\n\t}, numberOfComponents);\n\n\treturn numberOfComponents;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> componentCount(\"Component Count\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    for (int j = 0; j < N; ++j) {\n      if (i == j) continue;\n      if (A(i,j)) {\n        componentCount(i)++;\n      }\n    }\n  });\n\n  int total = 0;\n  for (size_t i = 0; i < N; ++i) {\n    total += componentCount(i);\n  }\n\n  return total;\n}",
            "/* ================ Your Code Here ================ */\n\n  int numComponents = 0;\n\n  // TODO: Implement me!\n\n  return numComponents;\n\n  /* ================================================= */\n\n}",
            "Kokkos::View<int*> componentCounts(\"componentCounts\", N);\n  // TODO: set up a parallel_for loop to iterate through the rows of A\n  // and compute the number of connected components in the graph.\n  // See Kokkos Documentation for parallel_for.\n  // http://kokkos.org/classkokkos_1_1parallel__for.html\n  // http://kokkos.org/doc/0.5.0/md_ceba5515321077560f2b75a185a9b5e6.html\n\n  Kokkos::View<int*> tmp(\"tmp\", N);\n  Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(int i) {\n\t\tcomponentCounts[i] = 0;\n  });\n\n  Kokkos::parallel_for(\"componentCount2\", N, KOKKOS_LAMBDA(int i) {\n\t\tif(A(i, i) == 1) {\n\t\t\tcomponentCounts[i] = 1;\n\t\t} else {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif(i!= j) {\n\t\t\t\t\tif(A(i, j) == 1) {\n\t\t\t\t\t\tcomponentCounts[i] = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n  });\n\n  Kokkos::parallel_for(\"componentCount3\", N, KOKKOS_LAMBDA(int i) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(componentCounts[i] == 1 && i!= j) {\n\t\t\t\tif(A(i, j) == 1) {\n\t\t\t\t\tcomponentCounts[i] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n  });\n\n  Kokkos::parallel_reduce(\"componentCount4\", N, KOKKOS_LAMBDA(int i, int &sum) {\n\t\tsum += componentCounts[i];\n  }, Kokkos::Sum<int>(0));\n\n  return 0;\n}",
            "int *visited;\n  Kokkos::View<int*, Kokkos::HostSpace> h_visited(\"visited\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> h_componentCount(\"componentCount\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> h_componentList(\"componentList\", N);\n\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> componentCount;\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> componentList;\n\n  componentCount = Kokkos::View<int*>(\"componentCount\", N);\n  componentList = Kokkos::View<int*>(\"componentList\", N);\n\n  Kokkos::deep_copy(componentCount, 0);\n  Kokkos::deep_copy(componentList, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n      KOKKOS_LAMBDA (const int i) {\n\n      h_visited[i] = 0;\n\n    });\n\n  Kokkos::deep_copy(h_visited, visited);\n\n  int count = 0;\n  int component = 0;\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n      KOKKOS_LAMBDA (const int i) {\n\n      if (visited[i] == 0) {\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n            KOKKOS_LAMBDA (const int j) {\n\n          if (h_visited[j] == 0) {\n            h_componentCount[j] = count;\n            h_componentList[j] = component;\n            h_visited[j] = 1;\n          }\n\n        });\n\n        count++;\n        component++;\n      }\n\n    });\n\n  Kokkos::deep_copy(componentCount, h_componentCount);\n  Kokkos::deep_copy(componentList, h_componentList);\n  Kokkos::deep_copy(visited, h_visited);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n      KOKKOS_LAMBDA (const int i) {\n\n      if (componentCount[i]!= 0) {\n\n        int k = componentCount[i];\n        int l = componentList[i];\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n            KOKKOS_LAMBDA (const int j) {\n\n          if (h_visited[j] == 0 && A(j, i)!= 0) {\n            h_componentCount[j] = k;\n            h_componentList[j] = l;\n            h_visited[j] = 1;\n          }\n\n        });\n      }\n\n    });\n\n  Kokkos::deep_copy(componentCount, h_componentCount);\n  Kokkos::deep_copy(componentList, h_componentList);\n  Kokkos::deep_copy(visited, h_visited);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n      KOKKOS_LAMBDA (const int i) {\n\n      if (visited[i] == 0) {\n\n        int k = 0;\n        int l = 0;\n\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N),\n            KOKKOS_LAMBDA (const int j) {\n\n          if (h_visited[j] == 0 && A(j, i)!= 0) {\n            k = componentCount[j];\n            l = componentList[j];\n            h_visited[j] = 1;",
            "int num_components = 0;\n  Kokkos::View<int**> component(Kokkos::ViewAllocateWithoutInitializing(\"component\"), N, N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; j++) {\n      component(i, j) = -1;\n    }\n  });\n  Kokkos::fence();\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    int id = 0;\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1 && component(j, j) < 0) {\n        id = j;\n      }\n    }\n    if (id == 0) {\n      component(i, i) = id;\n      num_components++;\n    }\n    for (int j = 0; j < N; j++) {\n      if (A(i, j) == 1 && component(j, j) < 0) {\n        component(j, j) = id;\n        for (int k = 0; k < N; k++) {\n          if (A(j, k) == 1 && component(k, k) < 0) {\n            component(k, k) = id;\n          }\n        }\n      }\n    }\n  });\n  Kokkos::fence();\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (component(i, j) == component(j, j)) {\n        component(i, j) = -1;\n      }\n    }\n  }\n  Kokkos::fence();\n\n  int num_components_local = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &count) {\n    for (int j = 0; j < N; j++) {\n      if (component(i, j) >= 0) {\n        count++;\n      }\n    }\n  }, Kokkos::Sum<int>(num_components_local));\n  Kokkos::fence();\n  Kokkos::single(Kokkos::PerTeam(Kokkos::PerThread::master), [&]() {\n    printf(\"num_components_local = %d\\n\", num_components_local);\n  });\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int num_components_global = 0;\n  MPI_Reduce(&num_components_local, &num_components_global, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    printf(\"num_components_global = %d\\n\", num_components_global);\n  }\n  return num_components_global;\n}",
            "if (N == 0) return 0;\n  Kokkos::View<int*> componentCount(\"componentCount\", N);\n  Kokkos::View<int**> neighbors(\"neighbors\", N, N);\n  Kokkos::View<int*> queue(\"queue\", N);\n  Kokkos::View<bool*> visited(\"visited\", N);\n\n  auto is_component_connected = [=] (int c, int i) {\n    for (int j = 0; j < N; j++) {\n      if (neighbors(i, j) == 1) {\n        componentCount(c) += 1;\n        return true;\n      }\n    }\n    return false;\n  };\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (int i) {\n    if (visited(i) == false) {\n      int c = 1;\n      visited(i) = true;\n      queue(0) = i;\n      int front = 0, back = 1;\n      while (front < back) {\n        int current = queue(front);\n        for (int j = 0; j < N; j++) {\n          if (A(current, j) == 1) {\n            neighbors(current, j) = 1;\n            neighbors(j, current) = 1;\n            if (visited(j) == false) {\n              visited(j) = true;\n              queue(back) = j;\n              back++;\n            }\n          }\n        }\n        front++;\n      }\n      if (!is_component_connected(c, i)) c++;\n    }\n  });\n\n  int sum = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA (int i, int& sum) {\n    sum += componentCount(i);\n  }, Kokkos::Sum<int>(sum));\n\n  return sum;\n}",
            "// This is a recursive implementation, but we need to keep track of which\n  // elements have been visited.\n  auto visited = Kokkos::View<int*>(\"visited\", N);\n\n  Kokkos::deep_copy(visited, 0);\n\n  class Count {\n  public:\n\t  int* visited;\n\t  Kokkos::View<const int**> A;\n\n\t  KOKKOS_INLINE_FUNCTION\n\t  void operator() (const int i, int& num) const {\n\t\tif (visited[i] == 0) {\n\t\t  num++;\n\t\t  visited[i] = 1;\n\t\t  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), *this);\n\t\t}\n\t  }\n  };\n\n  int num = 0;\n  Kokkos::parallel_reduce(\"Count\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), Count{visited.data(), A}, num);\n\n  return num;\n}",
            "Kokkos::View<bool*> visited(\"visited\", N);\n  Kokkos::deep_copy(visited, false);\n\n  Kokkos::View<int*> num_components(\"num_components\", 1);\n  Kokkos::deep_copy(num_components, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Serial>(0, N), [&] (int i) {\n    if (visited(i)) return;\n    int component = 0;\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Serial>(0, N), [&] (int j) {\n      if (A(i, j) == 1) {\n        component++;\n      }\n    });\n    Kokkos::atomic_add(&num_components(0), component);\n  });\n\n  int result = 0;\n  Kokkos::deep_copy(result, num_components);\n  return result;\n}",
            "// Your code goes here\n\tKokkos::View<int*> num_components(\"num_components\", N);\n\tKokkos::View<int*> num_components_update(\"num_components_update\", N);\n\n\tKokkos::deep_copy(num_components, 0);\n\tKokkos::deep_copy(num_components_update, 0);\n\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i,j)) {\n\t\t\t\t\tnum_components(i) = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tif (num_components(i) == 1) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(j,i)) {\n\t\t\t\t\t\tnum_components(j) = 1;\n\t\t\t\t\t\tnum_components_update(j)++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int &update) {\n\t\t\tupdate += num_components_update(i);\n\t\t},\n\t\tKokkos::Sum<int>(num_components_update(0))\n\t);\n\n\tint total_num_components = 0;\n\n\tKokkos::deep_copy(num_components, num_components_update);\n\tKokkos::deep_copy(num_components_update, 0);\n\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tif (num_components(i) == 1) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(j,i)) {\n\t\t\t\t\t\tnum_components(j) = 1;\n\t\t\t\t\t\tnum_components_update(j)++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int &update) {\n\t\t\tupdate += num_components_update(i);\n\t\t},\n\t\tKokkos::Sum<int>(num_components_update(0))\n\t);\n\n\tKokkos::deep_copy(num_components, num_components_update);\n\tKokkos::deep_copy(num_components_update, 0);\n\n\tKokkos::parallel_reduce(\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i, int &update) {\n\t\t\tupdate += num_components(i);\n\t\t},\n\t\tKokkos::Sum<int>(total_num_components)\n\t);\n\n\treturn total_num_components;\n}",
            "Kokkos::View<int*> color(\"color\", N);\n\tKokkos::View<int*> nextColor(\"nextColor\", 1);\n\tKokkos::View<int*> numColor(\"numColor\", 1);\n\tKokkos::parallel_for(\"ColorComponents\", N, KOKKOS_LAMBDA(int i) {\n\t\tcolor(i) = -1;\n\t});\n\n\tKokkos::parallel_for(\"ColorComponents\", N, KOKKOS_LAMBDA(int i) {\n\t\tif (color(i)!= -1) return;\n\t\tint c = 0;\n\t\tKokkos::Experimental::push_arg<int*>(&color, i, &c);\n\t\tKokkos::Experimental::push_arg<int*>(&nextColor, 0, &c);\n\t\tKokkos::Experimental::push_arg<int*>(&numColor, 0, 0);\n\t\tKokkos::Experimental::push_arg<int>(N, i);\n\t\tKokkos::Experimental::push_arg<int>(N, 0);\n\t\tKokkos::parallel_for(\"ColorComponents\", N, KOKKOS_LAMBDA(int j) {\n\t\t\tif (color(j)!= -1) return;\n\t\t\tKokkos::Experimental::push_arg<int*>(&color, j, &c);\n\t\t\tKokkos::Experimental::push_arg<int*>(&nextColor, 0, &c);\n\t\t\tKokkos::Experimental::push_arg<int*>(&numColor, 0, 0);\n\t\t\tKokkos::Experimental::push_arg<int>(N, i);\n\t\t\tKokkos::Experimental::push_arg<int>(N, j);\n\t\t\tif (A(i, j) == 1)\n\t\t\t\tKokkos::Experimental::push_call(Kokkos::Experimental::CallInfo(2, 1, 3));\n\t\t\telse\n\t\t\t\tKokkos::Experimental::push_call(Kokkos::Experimental::CallInfo(1, 0, 3));\n\t\t});\n\t\tKokkos::Experimental::pop_call(1, 2);\n\t});\n\n\tKokkos::View<int**> A_t(\"A_t\", N, N);\n\tKokkos::parallel_for(\"Transpose\", N, KOKKOS_LAMBDA(int i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tA_t(j, i) = A(i, j);\n\t\t}\n\t});\n\n\tKokkos::parallel_for(\"ColorComponents\", N, KOKKOS_LAMBDA(int i) {\n\t\tif (color(i)!= -1) return;\n\t\tint c = 0;\n\t\tKokkos::Experimental::push_arg<int*>(&color, i, &c);\n\t\tKokkos::Experimental::push_arg<int*>(&nextColor, 0, &c);\n\t\tKokkos::Experimental::push_arg<int*>(&numColor, 0, 0);\n\t\tKokkos::Experimental::push_arg<int>(N, i);\n\t\tKokkos::Experimental::push_arg<int>(N, 0);\n\t\tKokkos::parallel_for(\"ColorComponents\", N, KOKKOS_LAMBDA(int j) {\n\t\t\tif (color(j)!= -1) return;\n\t\t\tKokkos::Experimental::push_arg<int*>(&color, j, &c);\n\t\t\tKokkos::Experimental::push_arg<int*>(&nextColor, 0, &c);\n\t\t\tKokkos::Experimental::push_arg<int*>(&numColor, 0, 0);\n\t\t\tKokkos::Experimental::push_arg<int>(N, i);\n\t\t\tKokkos::Experimental::push_arg<int",
            "// TODO: Implement.\n\treturn 0;\n}",
            "using GraphViewType = Kokkos::View<int*>;\n\n  // Your code here.\n  // (Note: Kokkos has a range-based for loop, see\n  // http://kokkos.org/2.8.00/kokkos_8hpp.html#ad651b27440a39f4d612446454025f257)\n  GraphViewType num_components(\"num_components\", N);\n  Kokkos::parallel_for(\"cc_init\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int i) {\n    num_components(i) = i;\n  });\n\n  // Kokkos::parallel_for(\"cc_union_find\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int i) {\n  //   // Your code here.\n  //   // (Note: Kokkos has a range-based for loop, see\n  //   // http://kokkos.org/2.8.00/kokkos_8hpp.html#ad651b27440a39f4d612446454025f257)\n  // });\n\n  int total = 0;\n  for (int i = 0; i < N; ++i) {\n    if (num_components(i) == i) ++total;\n  }\n  return total;\n}",
            "Kokkos::View<int*> comp(\"component\", N);\n\tKokkos::deep_copy(comp, 0);\n\n\t// Your code here\n\treturn 0;\n}",
            "// CODE HERE\n}",
            "// your code here\n\n  return -1;\n}",
            "Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> colors(\"Colors\", N);\n  Kokkos::parallel_for(\"initialize_colors\", N, KOKKOS_LAMBDA(const int i) {\n    colors(i) = i;\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> numComponents(\"NumComponents\", 1);\n  numComponents(0) = 0;\n  Kokkos::parallel_for(\"find_connected_components\", N, KOKKOS_LAMBDA(const int i) {\n    // Check all of this node's neighbors and their neighbors\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)!= 0 && i!= j) {\n        // Check if they have the same color\n        // if not, they are in different connected components\n        if (colors(i)!= colors(j)) {\n          // The second node is a neighbor of the first, so they must be in the same component\n          // Therefore, pick a color for the first, and make all of its neighbors have that color\n          int color = colors(i);\n          for (int k = 0; k < N; k++) {\n            if (colors(k) == colors(j)) {\n              colors(k) = color;\n            }\n          }\n          numComponents(0) += 1;\n        }\n      }\n    }\n  });\n  Kokkos::fence();\n\n  return numComponents(0);\n}",
            "const size_t nworkers = 16;\n\tKokkos::View<int**> C(\"C\", N, N);\n\tKokkos::parallel_for(\"init\", nworkers, KOKKOS_LAMBDA(const int &i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tC(j, i) = j;\n\t\t}\n\t});\n\tKokkos::View<int**> L(\"L\", N, N);\n\tfor (int i = 0; i < N; ++i) {\n\t\tL(i, i) = 1;\n\t\tfor (int j = 0; j < i; ++j) {\n\t\t\tL(i, j) = A(i, j);\n\t\t}\n\t}\n\tint count = 0;\n\tKokkos::parallel_reduce(\"count\", nworkers, KOKKOS_LAMBDA(const int &i, int &lcount) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (L(j, k) == 1) {\n\t\t\t\t\tint index = -1;\n\t\t\t\t\tfor (int l = 0; l < N; ++l) {\n\t\t\t\t\t\tif (L(l, k) == 1) {\n\t\t\t\t\t\t\tif (index == -1) {\n\t\t\t\t\t\t\t\tindex = l;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tif (C(j, l)!= C(j, index)) {\n\t\t\t\t\t\t\t\t\tif (C(j, l) < C(j, index)) {\n\t\t\t\t\t\t\t\t\t\tC(j, index) = C(j, l);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\t\tC(j, l) = C(j, index);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (L(j, k) == 1) {\n\t\t\t\t\tif (C(j, k)!= C(j, j)) {\n\t\t\t\t\t\tlcount += 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}, count);\n\treturn count;\n}",
            "// initialize B to -1, 0, 1,..., N-1\n  Kokkos::View<int*> B(\"B\", N);\n  auto B_h = Kokkos::create_mirror_view(B);\n  for (size_t i = 0; i < N; i++)\n    B_h(i) = i;\n  Kokkos::deep_copy(B, B_h);\n\n  // run DFS on each unvisited node to find connected components\n  for (size_t i = 0; i < N; i++) {\n    if (B_h(i) == -1)\n      continue;\n\n    Kokkos::View<int*> stack(\"stack\", N);\n    auto stack_h = Kokkos::create_mirror_view(stack);\n\n    // run DFS\n    stack_h(0) = i;\n    int stack_size = 1;\n    while (stack_size > 0) {\n      int u = stack_h(stack_size - 1);\n      stack_h(stack_size - 1) = -1;\n      stack_size--;\n\n      for (size_t v = 0; v < N; v++) {\n        if (B_h(v)!= -1 && A(u, v)!= 0) {\n          stack_h(stack_size) = v;\n          B_h(v) = B_h(u);\n          stack_size++;\n        }\n      }\n    }\n\n    Kokkos::deep_copy(stack, stack_h);\n  }\n\n  // count the number of connected components\n  int num_components = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (B_h(i)!= -1)\n      num_components++;\n  }\n\n  Kokkos::finalize();\n  return num_components;\n}",
            "// Insert your code here\n    int *visited = new int[N];\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n\n    int *count = new int[N];\n    for (int i = 0; i < N; i++) {\n        count[i] = 0;\n    }\n\n    int component_count = 0;\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            count[i] = 1;\n            component_count++;\n            dfs(A, N, i, visited, count);\n        }\n    }\n\n    return component_count;\n}",
            "typedef Kokkos::DefaultExecutionSpace Exec;\n  typedef Kokkos::RangePolicy<Exec> Policy;\n  typedef Kokkos::View<int*, Exec> WorkArray;\n\n  // Count the number of components by iterating through each vertex in the graph.\n  // The number of connected components in the graph is stored in the number_of_components variable.\n  // We use a work array to keep track of the number of vertices that have already been processed.\n  // When a vertex is visited, all of the vertices it is connected to are marked as visited.\n  // When the loop finishes, the number of vertices that have not been visited is the number of connected components.\n  // Note: this algorithm is not guaranteed to work in all cases. For example, it will fail if there is a cycle in the graph.\n  WorkArray num_visited(\"num_visited\", N);\n  Kokkos::deep_copy(num_visited, 0);\n  int number_of_components = 0;\n  Kokkos::parallel_for(\n    Policy(0, N),\n    KOKKOS_LAMBDA(const int& v) {\n      if(num_visited(v) == 0) {\n        // Mark the vertex as visited\n        num_visited(v) = 1;\n        // Traverse all vertices connected to this vertex\n        for(int u = 0; u < N; u++) {\n          if(A(v, u) == 1) {\n            num_visited(u) = 1;\n          }\n        }\n        // Increment the number of connected components\n        number_of_components++;\n      }\n    }\n  );\n  Kokkos::fence();\n  return number_of_components;\n}",
            "Kokkos::View<int*> visited(\"visited\", N);\n\tKokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int i) {\n\t\tvisited(i) = 0;\n\t});\n\n\tKokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int i) {\n\t\tif (visited(i) == 0) {\n\t\t\tKokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tvisited(j) = 1;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n\n\tint numConnected = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited(i) == 1) {\n\t\t\tnumConnected++;\n\t\t}\n\t}\n\n\treturn numConnected;\n}",
            "// TODO: write code here to count the number of connected components\n  return 0;\n}",
            "// This function should be implemented using a parallel algorithm.\n    //\n    // It should run in parallel over the set of all nodes in the graph.\n    // Each node should be visited only once.\n    //\n    // Inside the body of the parallel loop, use the BFS algorithm to\n    // traverse the graph and count the number of connected components.\n    // You can use the `component_count.hpp` header file for this.\n    //\n    // The code below gives one possible implementation, but feel free to\n    // experiment with other ideas.\n\n    // First, create a vector of the same size as the graph\n    // to keep track of which nodes we have visited.\n    Kokkos::View<bool*> visited(\"visited\", N);\n\n    // This will be the number of connected components we find\n    int component_count = 0;\n    Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(size_t i) {\n        if (visited[i] == false) {\n            component_count += connected_component_count(A, i, visited);\n        }\n    });\n\n    return component_count;\n}",
            "Kokkos::View<int*> component(\"component\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) { component(i) = i; });\n  Kokkos::fence();\n\n  // TODO: Fill in code here\n  // Hint: Use Kokkos::View<int**> component(\"component\", N, N) and\n  // Kokkos::parallel_for to merge the components\n  // Kokkos::single to count the number of components\n  return -1;\n}",
            "// TODO: Replace the following with your implementation\n\n  // Find the number of connected components in the adjacency matrix A.\n  // Each connected component is defined by a subset of vertices where\n  // there exists a path between every pair of vertices in the subset.\n\n  // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&] (const int i) {\n  //   for (int j = 0; j < N; j++) {\n  //     if (A(i, j)!= 0) {\n  //       // A[i][j] = 1;\n  //     }\n  //   }\n  // });\n  //\n  // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&] (const int i) {\n  //   for (int j = 0; j < N; j++) {\n  //     if (A(i, j) == 1) {\n  //       // A[i][j] = 0;\n  //     }\n  //   }\n  // });\n  //\n  // Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&] (const int i, int& sum) {\n  //   for (int j = 0; j < N; j++) {\n  //     if (A(i, j) == 0) {\n  //       sum += 1;\n  //     }\n  //   }\n  // }, count);\n\n  return 1;\n}",
            "int num_comps = 0;\n  int num_unvisited = 0;\n  int unvisited = 0;\n\n  // TODO\n\n  return num_comps;\n}",
            "typedef Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic> > range_policy;\n\n\t// Create a single atomic to keep track of the number of components\n\t// You may need to define your own type for this atomic. See\n\t// http://kokkos.org/blog/2015/09/17/atomics/ for more details.\n\tKokkos::View<size_t*> atomic_count(\"num_components\", 1);\n\tKokkos::deep_copy(atomic_count, size_t(0));\n\n\t// Define a functor for the parallel_for\n\tstruct ComponentCountFunctor {\n\t\tKokkos::View<const int**> A;\n\t\tKokkos::View<size_t*> atomic_count;\n\t\tsize_t N;\n\n\t\tComponentCountFunctor(Kokkos::View<const int**> A,\n\t\t\t\tKokkos::View<size_t*> atomic_count, size_t N)\n\t\t\t: A(A), atomic_count(atomic_count), N(N) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator() (const int &i) const {\n\t\t\t// TODO\n\t\t}\n\t};\n\n\t// Run the functor in parallel\n\tComponentCountFunctor functor(A, atomic_count, N);\n\tKokkos::parallel_for(range_policy(0, N), functor);\n\n\t// Grab the final number of components from the atomic\n\tsize_t num_components = 0;\n\tKokkos::deep_copy(num_components, atomic_count);\n\n\treturn num_components;\n}",
            "// Create the component array, which will be used to track which node belongs to which component\n  Kokkos::View<int*> components(\"Component\", N);\n  Kokkos::parallel_for(\"initializeComponents\", Kokkos::RangePolicy<Kokkos::Reduce<Kokkos::Cuda>>(0, N),\n    [&] (int i) {\n      components(i) = i;\n    });\n  Kokkos::fence();\n\n  // Merge components that are connected by some path\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) == 1) {\n        int c1 = components(i);\n        int c2 = components(j);\n        if (c1!= c2) {\n          Kokkos::parallel_for(\"mergeConnectedComponents\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n            [&] (int k) {\n              if (components(k) == c2) {\n                components(k) = c1;\n              }\n            });\n          Kokkos::fence();\n        }\n      }\n    }\n  }\n\n  // Count the number of unique components\n  int uniqueComponents = 0;\n  Kokkos::parallel_reduce(\"countUniqueComponents\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    [&] (int i, int& sum) {\n      sum += (components(i) == i);\n    }, uniqueComponents);\n  Kokkos::fence();\n\n  return uniqueComponents;\n}",
            "using Kokkos::DefaultHostExecutionSpace;\n    Kokkos::View<int*, DefaultHostExecutionSpace> comp(\"comp\", N);\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i) {\n        comp(i) = 0;\n    });\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) == 1) {\n                comp(i) = comp(j);\n                break;\n            }\n        }\n    });\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j) == 1) {\n                comp(j) = comp(i);\n            }\n        }\n    });\n    int nComp = 0;\n    for (int i = 0; i < N; ++i) {\n        if (comp(i) == 0) {\n            comp(i) = nComp++;\n        }\n    }\n    return nComp;\n}",
            "Kokkos::View<int*> count(\"count\", N);\n\tKokkos::View<int*> color(\"color\", N);\n\tKokkos::parallel_for(\"init_color\", N, KOKKOS_LAMBDA(const int i) {\n\t\tcolor(i) = 0;\n\t});\n\tKokkos::parallel_for(\"init_count\", N, KOKKOS_LAMBDA(const int i) {\n\t\tcount(i) = 0;\n\t});\n\tKokkos::parallel_for(\"connect_components\", N, KOKKOS_LAMBDA(const int i) {\n\t\tint num_colors = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(A(i, j) == 1 && color(j) == 0) {\n\t\t\t\tif(color(i) == 0) {\n\t\t\t\t\tcolor(i) = 1;\n\t\t\t\t\tnum_colors++;\n\t\t\t\t}\n\t\t\t\tcolor(j) = color(i);\n\t\t\t}\n\t\t}\n\t\tcount(color(i)) += num_colors;\n\t});\n\tint* count_host = new int[N];\n\tint* color_host = new int[N];\n\tKokkos::deep_copy(count_host, count);\n\tKokkos::deep_copy(color_host, color);\n\tint result = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tif(color_host[i]!= 0) {\n\t\t\tresult++;\n\t\t}\n\t}\n\tdelete[] count_host;\n\tdelete[] color_host;\n\treturn result;\n}",
            "// Implement your solution here. You may use Kokkos parallelization primitives,\n\t// but you may not use anything else in Kokkos (e.g. atomics).\n}",
            "// TODO: fill in\n  //\n  // Some hints:\n  //\n  // 1. Use Kokkos::View<int[]> to create a Kokkos view that can hold the component ids of the nodes.\n  // 2. Use Kokkos::parallel_for to parallelize the loop that initializes the component ids.\n  // 3. Use Kokkos::parallel_for to parallelize the loop that finds the connected components.\n  // 4. Use Kokkos::parallel_reduce to count the number of connected components.\n  //\n  // You can use the following functions:\n  //\n  // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),...)\n  // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),...)\n  // Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),...)\n  // Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),...)\n  //\n  // You can use the following functions:\n  //\n  // Kokkos::DefaultHostExecutionSpace\n  // Kokkos::DefaultExecutionSpace\n  //\n  // You can use the following functions:\n  //\n  // A.extent(0)\n  // A.extent(1)\n  // A(i, j)\n  //\n  // You can use the following functions:\n  //\n  // Kokkos::atomic_compare_exchange\n  // Kokkos::atomic_fetch_add\n  //\n  // You can use the following functions:\n  //\n  // printf(...);\n  // fprintf(stdout,...);\n  // fprintf(stderr,...);\n  //\n  // You can use the following functions:\n  //\n  // Kokkos::HostSpace::execution_space::fence();\n  // Kokkos::DeviceSpace::execution_space::fence();\n  //\n  // You can use the following functions:\n  //\n  // Kokkos::abort(...);\n\n  // We'll start with a simple sequential implementation:\n  int components = 0;\n  std::vector<bool> visited(N);\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i])\n      continue;\n    visited[i] = true;\n    for (size_t j = 0; j < N; j++) {\n      if (A(i, j) == 0)\n        continue;\n      visited[j] = true;\n    }\n    components++;\n  }\n  return components;\n}",
            "using Kokkos::ALL;\n  using Kokkos::AUTO;\n  using Kokkos::parallel_for;\n  using Kokkos::range;\n\n  // Create a workspace for component IDs\n  Kokkos::View<int*> componentIDs(\"componentIDs\", N);\n  Kokkos::deep_copy(componentIDs, 0);\n\n  // Compute the connected components using BFS\n  // TODO: implement BFS here\n\n  // Count the number of distinct component IDs and return the result\n  Kokkos::View<int*> numComponents(\"numComponents\", 1);\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    int num = 0;\n    for (int i = 0; i < componentIDs.size(); i++) {\n      if (componentIDs(i) == 0) {\n        num++;\n      }\n    }\n    numComponents(0) = num;\n  });\n\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentIDs.size(); i++) {\n      if (componentIDs(i) == 0) {\n        componentIDs(i) = 1;\n      }\n    }\n  });\n\n  // Create a workspace for connected components\n  Kokkos::View<int*> componentSizes(\"componentSizes\", numComponents(0));\n\n  // Populate the workspace\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    int num = 0;\n    for (int i = 0; i < componentIDs.size(); i++) {\n      if (componentIDs(i)!= 0) {\n        componentSizes(componentIDs(i) - 1)++;\n      }\n    }\n  });\n\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentIDs.size(); i++) {\n      if (componentIDs(i)!= 0) {\n        componentIDs(i) = 1;\n      }\n    }\n  });\n\n  // Return the number of components\n  int result;\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentSizes.size(); i++) {\n      if (componentSizes(i)!= 0) {\n        numComponents(0)++;\n      }\n    }\n  });\n\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentSizes.size(); i++) {\n      if (componentSizes(i)!= 0) {\n        componentSizes(i) = 1;\n      }\n    }\n  });\n\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentIDs.size(); i++) {\n      if (componentIDs(i)!= 0) {\n        componentIDs(i) = 1;\n      }\n    }\n  });\n\n  Kokkos::deep_copy(numComponents, 0);\n  Kokkos::parallel_for(range(1), KOKKOS_LAMBDA(const int) {\n    for (int i = 0; i < componentSizes.size(); i++) {\n      if (componentSizes(i)!= 0) {\n        componentSizes(i) = 1;",
            "// Allocate the component array\n\tKokkos::View<int*> components(\"components\", N);\n\tKokkos::View<int*> numComponents(\"numComponents\", 1);\n\tKokkos::deep_copy(components, 0);\n\tKokkos::deep_copy(numComponents, 0);\n\n\t// The componentCountFunctor class provides the logic for determining the component that each vertex belongs to.\n\t// For simplicity, it assumes that the first vertex in the graph is 0.\n\t// For example, if the first vertex is 1, then we would need to subtract 1 from the vertex ID in the functor.\n\t// As another example, if the first vertex is 2, then we would need to subtract 2 from the vertex ID in the functor.\n\tclass componentCountFunctor {\n\t\tpublic:\n\t\tKokkos::View<int*> components;\n\t\tKokkos::View<int*> numComponents;\n\n\t\tcomponentCountFunctor(Kokkos::View<int*> components, Kokkos::View<int*> numComponents) : components(components), numComponents(numComponents) {}\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator() (const int& i) const {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tif (components(j) == 0) {\n\t\t\t\t\t\tcomponents(i) = 1;\n\t\t\t\t\t\tcomponents(j) = 1;\n\t\t\t\t\t\tKokkos::atomic_increment(numComponents);\n\t\t\t\t\t} else if (components(i) == 0) {\n\t\t\t\t\t\tcomponents(i) = components(j);\n\t\t\t\t\t\tKokkos::atomic_increment(numComponents);\n\t\t\t\t\t} else if (components(j)!= components(i)) {\n\t\t\t\t\t\tcomponents(j) = components(i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Static> > policy(0, N);\n\tKokkos::parallel_for(\"componentCount\", policy, componentCountFunctor(components, numComponents));\n\n\t// Return the number of components.\n\tint numComponentsHost;\n\tKokkos::deep_copy(numComponentsHost, numComponents);\n\treturn numComponentsHost;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> componentCount(\"componentCount\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> stack(\"stack\", N);\n  Kokkos::View<bool*, Kokkos::HostSpace> visited(\"visited\", N);\n\n  auto countComponents = KOKKOS_LAMBDA(const int idx) {\n    if(visited(idx))\n      return;\n    componentCount(idx) = 0;\n    stack(0) = idx;\n    int stackTop = 0;\n\n    while(stackTop >= 0) {\n      int v = stack(stackTop);\n      stackTop--;\n      if(!visited(v)) {\n        visited(v) = true;\n        componentCount(idx) += 1;\n        for(int u = 0; u < N; u++) {\n          if(A(v, u)) {\n            stackTop++;\n            stack(stackTop) = u;\n          }\n        }\n      }\n    }\n  };\n\n  Kokkos::parallel_for(N, countComponents);\n  int maxCount = 0;\n  for(int i = 0; i < N; i++) {\n    if(componentCount(i) > maxCount)\n      maxCount = componentCount(i);\n  }\n\n  return maxCount;\n}",
            "/* We will use two atomic counters to track which components are completed.\n\t   One for all components, and one for each component.\n\t   The first is for the master counter.\n\t   The second is for the component counter.\n\t*/\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> master_count_arr(\"master_count_arr\", 1);\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> component_count_arr(\"component_count_arr\", 1);\n\n\t// Initialize the count arrays\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,1), KOKKOS_LAMBDA(const int &i) {\n\t\tmaster_count_arr(0) = 0;\n\t\tcomponent_count_arr(0) = 0;\n\t});\n\n\t// Create the atomic counter objects\n\tKokkos::Atomic<int> master_count(master_count_arr);\n\tKokkos::Atomic<int> component_count(component_count_arr);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0,N), KOKKOS_LAMBDA(const int &i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j) == 1) {\n\t\t\t\tKokkos::atomic_increment(&component_count);\n\t\t\t}\n\t\t}\n\t\tKokkos::atomic_increment(&master_count);\n\t});\n\t// Wait until the threads are done\n\tKokkos::fence();\n\n\t// Copy the values of the atomic counters to the host\n\tint master_count_val;\n\tint component_count_val;\n\tKokkos::deep_copy(master_count_val, master_count);\n\tKokkos::deep_copy(component_count_val, component_count);\n\n\t// Print the result\n\tstd::cout << \"Number of threads: \" << master_count_val << std::endl;\n\tstd::cout << \"Number of components: \" << component_count_val << std::endl;\n\tstd::cout << \"Number of components connected: \" << component_count_val - 1 << std::endl;\n\n\treturn component_count_val - 1;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\tKokkos::View<int*, execution_space> coloring(\"coloring\", N);\n\n\t// Parallel loop, assuming that the default execution space is a CUDA device\n\tKokkos::parallel_for(\n\t\t\"color_graph\",\n\t\tKokkos::RangePolicy<execution_space>(0, N),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t// i is the vertex label\n\t\t// Initialize to -1 as uncolored\n\t\tcoloring(i) = -1;\n\t}\n\t);\n\n\t// Parallel loop, assuming that the default execution space is a CUDA device\n\tKokkos::parallel_for(\n\t\t\"color_graph\",\n\t\tKokkos::RangePolicy<execution_space>(0, N),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t// i is the vertex label\n\t\t// Check if i is already colored\n\t\tif (coloring(i) == -1) {\n\t\t\t// Initialize i as the first color\n\t\t\tcoloring(i) = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t// If i is connected to j\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t// Check if j is already colored\n\t\t\t\t\twhile (coloring(j) == -1) {}\n\t\t\t\t\t// If j is colored, but is different from i's color\n\t\t\t\t\tif (coloring(j)!= coloring(i)) {\n\t\t\t\t\t\t// Set j to the same color as i\n\t\t\t\t\t\tcoloring(j) = coloring(i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t);\n\n\t// Sum the number of different colors\n\t// Parallel loop, assuming that the default execution space is a CUDA device\n\tKokkos::parallel_reduce(\n\t\t\"sum_colors\",\n\t\tKokkos::RangePolicy<execution_space>(0, N),\n\t\tKOKKOS_LAMBDA(const int& i, int& sum) {\n\t\tsum += (coloring(i)!= -1);\n\t},\n\tKokkos::Sum<int>(0)\n\t);\n\n\t// Done, so return the sum\n\treturn sum;\n}",
            "// Compute the connected component of a graph represented by an adjacency matrix A.\n\t// Assume Kokkos has already been initialized.\n\t// Return the number of connected components.\n\n\t// You may wish to use Kokkos::View<int**>::HostMirror for the host view\n\t// as well as Kokkos::View<int**>::HostMirror::HostMirror\n\t// to avoid copying data between the host and the device.\n\n\treturn 0;\n}",
            "// TODO: Your code goes here\n}",
            "/*\n\tKokkos::View<int*> color(\"color\",N);\n\t//fill color array with -1\n\tKokkos::parallel_for(\"init\", N, KOKKOS_LAMBDA(const int i){\n\t\tcolor(i) = -1;\n\t});\n\t//change color array to 0, 1, 2, 3...\n\tKokkos::parallel_for(\"color\", N, KOKKOS_LAMBDA(const int i){\n\t\tif(color(i) == -1){\n\t\t\tcolor(i) = 0;\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(A(i,j) == 1){\n\t\t\t\t\tcolor(j) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\t//count\n\tKokkos::View<int*> count(\"count\",N);\n\t//fill count with 1\n\tKokkos::parallel_for(\"init_count\", N, KOKKOS_LAMBDA(const int i){\n\t\tcount(i) = 1;\n\t});\n\t//sum\n\tKokkos::parallel_for(\"sum_count\", N, KOKKOS_LAMBDA(const int i){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(color(j) == color(i) && j!= i){\n\t\t\t\tcount(i) += count(j);\n\t\t\t}\n\t\t}\n\t});\n\tint res = 0;\n\t//max\n\tKokkos::parallel_for(\"max\", N, KOKKOS_LAMBDA(const int i){\n\t\tif(res < count(i)){\n\t\t\tres = count(i);\n\t\t}\n\t});\n\n\treturn res;\n\t*/\n\n\n\tKokkos::View<int*> color(\"color\",N);\n\t//fill color array with -1\n\tKokkos::parallel_for(\"init\", N, KOKKOS_LAMBDA(const int i){\n\t\tcolor(i) = -1;\n\t});\n\t//change color array to 0, 1, 2, 3...\n\tKokkos::parallel_for(\"color\", N, KOKKOS_LAMBDA(const int i){\n\t\tif(color(i) == -1){\n\t\t\tcolor(i) = 0;\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(A(i,j) == 1){\n\t\t\t\t\tcolor(j) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\t//count\n\tKokkos::View<int*> count(\"count\",N);\n\t//fill count with 1\n\tKokkos::parallel_for(\"init_count\", N, KOKKOS_LAMBDA(const int i){\n\t\tcount(i) = 1;\n\t});\n\t//sum\n\tKokkos::parallel_for(\"sum_count\", N, KOKKOS_LAMBDA(const int i){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(color(j) == color(i) && j!= i){\n\t\t\t\tcount(i) += count(j);\n\t\t\t}\n\t\t}\n\t});\n\tint res = 0;\n\t//max\n\tKokkos::parallel_for(\"max\", N, KOKKOS_LAMBDA(const int i){\n\t\tif(res < count(i)){\n\t\t\tres = count(i);\n\t\t}\n\t});\n\n\treturn res;\n}",
            "// TODO: implement this function\n  return -1;\n}",
            "Kokkos::View<int*> count(\"count\", N);\n  Kokkos::deep_copy(count, 1);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    for(int j = 0; j < N; j++) {\n      if(A(i,j)!= 0) {\n        Kokkos::atomic_increment(&count(j));\n      }\n    }\n  });\n\n  int total = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &tot) {\n    tot += count(i);\n  }, total);\n\n  return total;\n}",
            "int *flags = new int[N];\n  for (int i = 0; i < N; i++) {\n    flags[i] = 0;\n  }\n\n  Kokkos::parallel_for(\n      \"countConnectedComponents\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n      KOKKOS_LAMBDA(int i) {\n        if (flags[i] == 0) {\n          // we haven't visited this vertex yet\n          flags[i] = 1;\n          for (int j = 0; j < N; j++) {\n            // if we have an edge from i to j,\n            // set the flag of j to be 1 as well\n            if (A(i, j) == 1) {\n              flags[j] = 1;\n            }\n          }\n        }\n      });\n\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (flags[i] == 1) {\n      count++;\n    }\n  }\n\n  delete[] flags;\n  return count;\n}",
            "// Use a view to keep track of the components of each node.\n  // For the input graph, this should be: {0, 1, 0, 0}\n  Kokkos::View<int*> component(Kokkos::ViewAllocateWithoutInitializing(\"component\"), N);\n\n  // Initialize the components to 0, 1, 2,...\n  Kokkos::parallel_for(\"init_component\", N, KOKKOS_LAMBDA(size_t i) {\n    component(i) = i;\n  });\n\n  // Combine the components of two nodes if they are connected.\n  Kokkos::parallel_for(\"join_components\", N, KOKKOS_LAMBDA(size_t i) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j && A(i, j) && component(i)!= component(j)) {\n        // Find the component id for i.\n        size_t compI = component(i);\n\n        // Find the component id for j.\n        size_t compJ = component(j);\n\n        // Merge the components\n        Kokkos::atomic_compare_exchange_strong<int>(&component(compI), &compI, compJ);\n      }\n    }\n  });\n\n  // Return the number of unique components.\n  // Use a Kokkos::View<int> to keep track of the number of unique components.\n  Kokkos::View<int> unique(Kokkos::ViewAllocateWithoutInitializing(\"unique\"), 1);\n  Kokkos::parallel_for(\"count_components\", N, KOKKOS_LAMBDA(size_t i) {\n    // Get the component id for i.\n    int compI = component(i);\n\n    // Find the largest component id.\n    size_t maxComp = Kokkos::atomic_fetch_max(&unique(0), compI);\n    if (maxComp < compI) {\n      // If compI is the new largest component, update maxComp.\n      Kokkos::atomic_max(&unique(0), compI);\n    }\n  });\n\n  return unique(0) + 1;\n}",
            "// Write your code here\n    return 0;\n}",
            "using ExecutionSpace = Kokkos::DefaultHostExecutionSpace;\n  Kokkos::View<int*> num_components(\"num_components\", N);\n  Kokkos::deep_copy(num_components, 0);\n  Kokkos::parallel_for(\n      \"component_count\", Kokkos::RangePolicy<ExecutionSpace>(0, N),\n      [=](int i) {\n        // TODO: implement\n        int count = 0;\n        for (int j = 0; j < N; ++j) {\n          if (A(i, j)!= 0)\n            count++;\n        }\n        num_components(i) = count;\n      });\n\n  int total_components = 0;\n  Kokkos::parallel_reduce(\n      \"component_count_reduce\", Kokkos::RangePolicy<ExecutionSpace>(0, N),\n      [=](int i, int &update) {\n        update += num_components(i);\n      },\n      total_components);\n\n  return total_components;\n}",
            "Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> colors(\"colors\", N);\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> components(\"components\", N);\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> visited(\"visited\", N);\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> queue(\"queue\", N);\n  Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> rowCounts(\"rowCounts\", N);\n\n  // Initialize everything to 0\n  Kokkos::deep_copy(colors, 0);\n  Kokkos::deep_copy(components, 0);\n  Kokkos::deep_copy(visited, 0);\n  Kokkos::deep_copy(queue, 0);\n  Kokkos::deep_copy(rowCounts, 0);\n\n  // Main loop. For each row in A, compute the connected component number (component) and color of the row.\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n\t\t       [&](int row) {\n\t\t\t if (colors(row) == 0) {\n\t\t\t   components(row) = 1; // Start a new component\n\t\t\t   queue(0) = row;\n\t\t\t   rowCounts(0) = 1;\n\n\t\t\t   for (int i = 0; i < rowCounts(0); i++) { // Iterate over all elements in queue\n\t\t\t     int index = queue(i);\n\n\t\t\t     for (int j = 0; j < N; j++) {\n\t\t\t       if (visited(j) == 0 && A(index, j)!= 0) { // If we haven't visited this neighbor\n\t\t\t\t queue(rowCounts(0)) = j;\n\t\t\t\t rowCounts(0) += 1;\n\t\t\t\t visited(j) = 1;\n\t\t\t       }\n\t\t\t     }\n\t\t\t   }\n\n\t\t\t   colors(row) = 1;\n\n\t\t\t   for (int i = 1; i < rowCounts(0); i++) { // For each element in queue\n\t\t\t     colors(queue(i)) = colors(row);\n\t\t\t     components(queue(i)) = components(row);\n\t\t\t   }\n\t\t\t }\n\t\t       });\n\n  // Sum the number of components. We know that every row will be colored with a different number\n  // except for rows with the same connected component number, which will all be the same color.\n  // So we just need to sum the unique colors.\n  int totalComponents = 0;\n  for (int i = 0; i < N; i++) {\n    if (colors(i)!= 0) {\n      totalComponents++;\n    }\n  }\n\n  return totalComponents;\n}",
            "// Initialize a vector of N integers to store the component id of each vertex\n\tKokkos::View<int*> componentIds(\"componentIds\", N);\n\n\t// Initialize to all -1 (unvisited)\n\tKokkos::deep_copy(componentIds, -1);\n\n\t// Initialize a vector of N booleans to track which vertices have been visited\n\tKokkos::View<bool*> visited(\"visited\", N);\n\n\t// Initialize to all false (unvisited)\n\tKokkos::deep_copy(visited, false);\n\n\t// Initialize the count of components\n\tint count = 0;\n\n\t// Perform BFS from each unvisited vertex (to create connected components)\n\tKokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(int i) {\n\t\tif (!visited[i]) {\n\t\t\tcomponentCount_BFS(A, componentIds, visited, i, count);\n\t\t}\n\t});\n\tKokkos::fence();\n\n\treturn count;\n}",
            "const size_t MAX_NUM_THREADS = 128;\n  const size_t MAX_NUM_TEAMS = 128;\n\n  int num_connected_components = 0;\n\n  Kokkos::parallel_reduce(\n\t\tKokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Static>>(N, MAX_NUM_THREADS, MAX_NUM_TEAMS),\n\t\tKOKKOS_LAMBDA(const Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Static> >::member_type& member, int& num_connected_components) {\n\t\t\tconst int i = member.league_rank();\n\t\t\tKokkos::Single::forEach(Kokkos::RangeSingle(member, N), [&](const int j) {\n\t\t\t\tif (A(i, j) == 1 && i!= j)\n\t\t\t\t{\n\t\t\t\t\tnum_connected_components++;\n\t\t\t\t}\n\t\t\t});\n\t\t}, num_connected_components);\n\n  return num_connected_components;\n}",
            "// You will need to implement this function\n\treturn 0;\n}",
            "Kokkos::View<int*> colors(\"colors\", N);\n  Kokkos::deep_copy(colors, -1);\n  int count = 0;\n  Kokkos::parallel_for(\n      \"count\",\n      Kokkos::RangePolicy<Kokkos::",
            "// Your code goes here\n\tKokkos::View<int*> count(\"count\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n\t\tcount(i) = 1;\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tcount(i) = 0;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint numComponents = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (count(i) == 1) {\n\t\t\tnumComponents += 1;\n\t\t}\n\t}\n\treturn numComponents;\n}",
            "// Create a device view of the adjacency matrix\n  Kokkos::View<const int**, Kokkos::LayoutRight, Kokkos::MemoryUnmanaged> A_dev(A.data(), N, N);\n  // Create a device view of an int to hold the component count\n  Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::MemoryUnmanaged> component_count_dev(\"component_count_dev\", 1);\n\n  // Initialize to 0 on the device\n  Kokkos::parallel_for(\"init\", Kokkos::RangePolicy<Kokkos::LaunchBounds<1,1>>(0, 1),\n    KOKKOS_LAMBDA (int) {\n      component_count_dev(0) = 0;\n    }\n  );\n  Kokkos::fence();\n\n  // Iterate over each edge in the adjacency matrix and determine if the edge connects two components\n  Kokkos::parallel_for(\"component_count\", Kokkos::RangePolicy<Kokkos::LaunchBounds<1,1>>(0, N),\n    KOKKOS_LAMBDA (int i) {\n      for(int j = 0; j < N; ++j) {\n        if (A_dev(i, j) > 0) {\n          // If edge connects two components, then increment the component count\n          if (i!= j) {\n            atomic_increment(&component_count_dev(0));\n          }\n          // Set A(i,j) = A(j,i) = 0 to prevent double-counting\n          A_dev(i, j) = 0;\n          A_dev(j, i) = 0;\n        }\n      }\n    }\n  );\n  Kokkos::fence();\n\n  // Synchronize the component count to the host\n  int component_count = 0;\n  Kokkos::deep_copy(component_count, component_count_dev);\n\n  return component_count;\n}",
            "// allocate and initialize flags array\n    Kokkos::View<int *> flags(\"flags\", N);\n    Kokkos::deep_copy(flags, 0);\n\n    // count the number of components\n    int count = 0;\n\n    for (int i = 0; i < N; ++i) {\n\n        // if this node has been flagged, continue to the next node\n        if (flags(i)) continue;\n\n        // otherwise, count the number of connected components and flag them\n        count++;\n        for (int j = 0; j < N; ++j) {\n            if (A(i, j)) flags(j) = 1;\n        }\n    }\n\n    return count;\n}",
            "using namespace Kokkos;\n  using namespace Kokkos::ViewAllocate;\n  using namespace Kokkos::View;\n  using namespace Kokkos::Experimental;\n  using atomic_t = typename std::conditional<sizeof(long) == sizeof(int),\n                                             Kokkos::Experimental::Atomic<int, Experimental::MemorySpace::Unified>,\n                                             Kokkos::Experimental::Atomic<long, Experimental::MemorySpace::Unified>>::type;\n  using memspace_t = typename atomic_t::memory_space;\n  // TODO: you may wish to change these to a larger type\n  using idx_t = int;\n  using array_t = View<int* [3], LayoutLeft, memspace_t>;\n  using int_t = int;\n\n  // Get the default execution space and device type\n  auto const myspace = memspace_t();\n  auto const mydevice = myspace.device();\n\n  // allocate views to hold the results and flags\n  View<int*, memspace_t> numComponents(\"numComponents\", 1);\n  View<int*, memspace_t> numFlags(\"numFlags\", 1);\n  array_t results(\"results\", N);\n\n  // allocate a workspace to hold the results of each thread's execution\n  // in parallel, each thread will update its part of the array with the number\n  // of components found\n  array_t resultsWorkspace(\"resultsWorkspace\", N);\n\n  // allocate a workspace to hold the flags of each thread's execution\n  // in parallel, each thread will update its part of the array with the number\n  // of flags found\n  array_t flagsWorkspace(\"flagsWorkspace\", N);\n\n  // set all flags to -1 (unvisited)\n  Kokkos::parallel_for(\n      \"initializeFlags\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, N),\n      KOKKOS_LAMBDA(const idx_t i) { flagsWorkspace(i, 0) = -1; });\n\n  // set numComponents to 0\n  Kokkos::parallel_for(\n      \"initializeNumComponents\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, 1),\n      KOKKOS_LAMBDA(const idx_t i) { numComponents(i) = 0; });\n\n  // set numFlags to 0\n  Kokkos::parallel_for(\n      \"initializeNumFlags\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, 1),\n      KOKKOS_LAMBDA(const idx_t i) { numFlags(i) = 0; });\n\n  // set all components to 0\n  Kokkos::parallel_for(\n      \"initializeResults\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, N),\n      KOKKOS_LAMBDA(const idx_t i) { results(i, 0) = 0; });\n\n  // set all components to 0\n  Kokkos::parallel_for(\n      \"initializeResultsWorkspace\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, N),\n      KOKKOS_LAMBDA(const idx_t i) { resultsWorkspace(i, 0) = 0; });\n\n  // set all flags to 0\n  Kokkos::parallel_for(\n      \"initializeFlagsWorkspace\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, N),\n      KOKKOS_LAMBDA(const idx_t i) { flagsWorkspace(i, 0) = 0; });\n\n  // This is the kernel that does all the work\n  // Here, we are doing a breadth first search of the graph\n  // to count the number of components found\n  // Note that the for loop is unrolled here to avoid using a lambda in the kernel.\n  Kokkos::parallel_for(\n      \"breadthFirstSearch\",\n      Kokkos::RangePolicy<decltype(myspace)>(0, N),\n      KOKKOS_LAMBDA(const idx_t i) {\n\tint flag = 0;\n\tint count",
            "int num_components = 0;\n\n  // Your code goes here\n\n  return num_components;\n}",
            "int count = 0;\n\tKokkos::View<int*, Kokkos::HostSpace> visited(\"visited\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> to_visit(\"to_visit\", N);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0, N),\n\t\t[&](const int i) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tcount++;\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tto_visit[0] = i;\n\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tto_visit[0] = j;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\t\twhile (to_visit[v]!= -1) {\n\t\t\t\t\t\tvisited[to_visit[v]] = 1;\n\n\t\t\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t\t\tif (A(to_visit[v], j) == 1) {\n\t\t\t\t\t\t\t\tto_visit[v + 1] = j;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tto_visit[v] = -1;\n\t\t\t\t\t\tv++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\treturn count;\n}",
            "// Put your code here!\n\n  return 0; // placeholder\n}",
            "Kokkos::View<int*> componentIds(\"componentIds\", N);\n  Kokkos::View<int*> workQueue(\"workQueue\", N);\n  auto workQueueBeg = Kokkos::View<int*>::HostMirror(workQueue);\n\n  Kokkos::parallel_for(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      // Initialize each node to a unique component\n      componentIds(i) = i;\n      workQueue(i) = i;\n    }\n  );\n\n  int nextComponentId = N;\n  while (!workQueueBeg.empty()) {\n    int nodeId = workQueueBeg.pop_back();\n    int myComponent = componentIds(nodeId);\n    for (int i = 0; i < N; ++i) {\n      if (A(nodeId, i) && componentIds(i) == componentIds(nodeId)) {\n        workQueueBeg.push_back(i);\n        componentIds(i) = myComponent;\n      }\n    }\n  }\n\n  int numComponents = 0;\n  Kokkos::parallel_reduce(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i, int &count) {\n      count += (componentIds(i) == i);\n    },\n    numComponents\n  );\n  return numComponents;\n}",
            "int num_components = 0;\n  for (int i = 0; i < N; ++i) {\n\t  // TODO: use Kokkos to compute the number of components in the graph defined by A\n\t  // Hint: Use a Kokkos::parallel_for loop over the rows of A, and Kokkos::single to\n\t  // keep track of the number of components in the graph.\n  }\n  return num_components;\n}",
            "const int numThreadsPerTeam = 128;\n\tconst int numTeams = N / numThreadsPerTeam;\n\n\t// TODO: fill in\n\treturn 0;\n}",
            "// TODO\n    return 0;\n}",
            "// TODO: implement\n}",
            "// Create a boolean array to store whether a node has been visited\n  Kokkos::View<bool*> visited(\"visited\", N);\n\n  // Create a boolean array to store whether a node has been assigned to a component\n  Kokkos::View<bool*> assigned(\"assigned\", N);\n\n  // Create an integer array to store which component a node belongs to\n  Kokkos::View<int*> components(\"components\", N);\n\n  // Initialize arrays to zero\n  Kokkos::parallel_for(\"init\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(int i) {\n                         visited(i) = false;\n                         assigned(i) = false;\n                         components(i) = 0;\n                       });\n\n  int componentCount = 0;\n  // Loop over all nodes\n  Kokkos::parallel_for(\"loop\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(int i) {\n                         // If the node has been assigned, skip it\n                         if (assigned(i)) return;\n\n                         // Otherwise, check if it is connected to any other node\n                         if (A(i, i) == 1) {\n                           // Mark the current node as visited\n                           visited(i) = true;\n                           assigned(i) = true;\n                           components(i) = componentCount;\n\n                           // Visit all unvisited adjacent nodes\n                           for (size_t j = 0; j < N; j++) {\n                             if (A(i, j) == 1 &&!visited(j)) {\n                               visited(j) = true;\n                               assigned(j) = true;\n                               components(j) = componentCount;\n                             }\n                           }\n                           componentCount++;\n                         }\n                       });\n\n  // Use a Kokkos reduction to count the number of components\n  return Kokkos::reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), components, 0);\n}",
            "Kokkos::View<int*> component(\"component\", N);\n\tKokkos::View<int*> count(\"count\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\t\tif (component(i) == 0) {\n\t\t\tint count = 0;\n\t\t\tcomponent(i) = 1;\n\t\t\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int j) {\n\t\t\t\tif (A(i, j)!= 0 && component(j) == 0) {\n\t\t\t\t\tcomponent(j) = 1;\n\t\t\t\t\tcount += 1;\n\t\t\t\t}\n\t\t\t});\n\t\t\tcount(i) = count;\n\t\t}\n\t});\n\t\n\tKokkos::View<int*> total(\"total\", 1);\n\tint totalVal = 0;\n\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& sum) {\n\t\tsum += count(i);\n\t}, total);\n\tKokkos::deep_copy(totalVal, total);\n\n\treturn totalVal;\n}",
            "// Your code here\n  return 0;\n}",
            "typedef Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> IntVector;\n\ttypedef Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> IntVector;\n\t// TODO: insert code here\n\tint *visited = (int*)malloc(sizeof(int) * N);\n\tfor(int i = 0; i < N; i++) visited[i] = 0;\n\n\tint count = 0;\n\n\tfor(int i = 0; i < N; i++) {\n\t\tif(visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tint current = i;\n\t\t\twhile(visited[current] == 1) {\n\t\t\t\tvisited[current] = 2;\n\t\t\t\tcount++;\n\t\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\t\tif(A(current, j) == 1 && visited[j] == 1) {\n\t\t\t\t\t\tvisited[j] = 2;\n\t\t\t\t\t\tcurrent = j;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfree(visited);\n\treturn count;\n}",
            "Kokkos::View<int*> comp(\"comp\", N);\n\n  Kokkos::parallel_for(\"componentCount\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (int i) {\n      comp(i) = 0;\n    });\n\n  Kokkos::parallel_for(\"componentCount2\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (int i) {\n      if (comp(i) == 0) {\n        int c = 0;\n        Kokkos::parallel_for(\"componentCount3\",\n          Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (int j) {\n            if (comp(j) == 0) {\n              comp(j) = c;\n            }\n          });\n        c++;\n      }\n    });\n\n  Kokkos::parallel_for(\"componentCount4\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (int i) {\n      if (A(i, i) == 0) {\n        comp(i) = comp(i) + 1;\n      }\n    });\n\n  Kokkos::parallel_for(\"componentCount5\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (int i) {\n      for (int j = 0; j < N; j++) {\n        if (i!= j && A(i, j)!= 0) {\n          comp(i) = comp(j);\n        }\n      }\n    });\n\n  return *(Kokkos::max(comp));\n}",
            "Kokkos::View<int**> A_copy = Kokkos::create_mirror_view(A);\n  Kokkos::deep_copy(A_copy, A);\n\n  Kokkos::View<int*> num_components(\"num_components\", N);\n  int num_components_h;\n\n  {\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [=] (int i) {\n      num_components(i) = 1;\n    });\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [=] (int i) {\n      for (int j = i+1; j < N; j++) {\n        if (A_copy(i, j) > 0) {\n          Kokkos::atomic_max(&num_components(j), num_components(i));\n        }\n      }\n    });\n    Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [=] (int i, int &result) {\n      result = Kokkos::max(result, num_components(i));\n    }, Kokkos::Max<int>(num_components_h));\n  }\n\n  // copy result back to host and return\n  Kokkos::deep_copy(num_components, num_components);\n  return num_components_h;\n}",
            "int* components = new int[N];\n\tfor(size_t i = 0; i < N; i++)\n\t\tcomponents[i] = i;\n\n\t// TODO: Use Kokkos to merge components\n\n\tint count = 0;\n\tfor(size_t i = 0; i < N; i++)\n\t\tif(components[i] == i)\n\t\t\tcount++;\n\n\tdelete[] components;\n\n\treturn count;\n}",
            "// TODO: complete this function\n  Kokkos::View<int*> C = Kokkos::View<int*>(\"C\", N);\n\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::ExecPolicy::parallel_for_tag>(0, N), [&](int i) {\n        C(i) = 0;\n      });\n\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::ExecPolicy::parallel_for_tag>(0, N), [&](int i) {\n        for (int j = 0; j < N; j++) {\n          if (i!= j && A(i, j) == 1 && C(j) == 0) {\n            C(j) = 1;\n            componentCount(A, N);\n          }\n        }\n      });\n\n  Kokkos::View<int*> count(\"count\", 1);\n  Kokkos::parallel_reduce(\n      Kokkos::RangePolicy<Kokkos::ExecPolicy::parallel_for_tag>(0, N), [&](int i, int &local) {\n        if (C(i) == 0) {\n          local++;\n        }\n      },\n      count);\n\n  return count(0);\n}",
            "// TODO\n  return 0;\n}",
            "using namespace Kokkos;\n\n\t/*\n\tThe graph has one component if A[i][j]==0 for all i,j.\n\tOtherwise, it has two components.\n\t*/\n\n\tif (A.extent(0)!= A.extent(1)) {\n\t\tprintf(\"Matrix must be square.\\n\");\n\t\treturn -1;\n\t}\n\n\tconst int numThreads = omp_get_max_threads();\n\tint *comp = (int *)malloc(sizeof(int) * N);\n\tint numComponents = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tcomp[i] = 0;\n\t}\n\n#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tint myComponent = i;\n\t\tif (comp[i] == 0) {\n\t\t\tcomp[i] = numComponents + 1;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\tmyComponent = comp[j];\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomp[i] = myComponent;\n\t\t}\n\t}\n\n\t// Check for two components\n\tfor (int i = 0; i < N; i++) {\n\t\tif (comp[i] == 0) {\n\t\t\tnumComponents++;\n\t\t}\n\t}\n\tfree(comp);\n\treturn numComponents;\n}",
            "// First check that the input is valid.\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j and A(i,j) == 1 and A(j,i) == 0) {\n\t\t\t\tstd::cout << \"Input must be symmetric.\" << std::endl;\n\t\t\t\treturn -1;\n\t\t\t}\n    }\n  }\n\n  // Initialize a Kokkos parallel for loop for this algorithm.\n  Kokkos::parallel_for(\n\t\t  Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t  KOKKOS_LAMBDA(const int i) {\n\n    // Initialize a stack for BFS.\n    std::stack<int> stack;\n    stack.push(i);\n\n    // Set up a vector to indicate whether a node has been visited.\n    Kokkos::View<bool*> visited(\"visited\", N);\n    Kokkos::deep_copy(visited, false);\n    Kokkos::deep_copy(visited[i], true);\n\n    // Initialize a vector to hold the component id for each node.\n    Kokkos::View<int*> cid(\"cid\", N);\n    Kokkos::deep_copy(cid, -1);\n    int cur_id = 0;\n\n    // BFS\n    while (stack.size()!= 0) {\n      int current = stack.top();\n      stack.pop();\n      for (int j = 0; j < N; j++) {\n        if (A(current,j) == 1 and!visited[j]) {\n          stack.push(j);\n          visited[j] = true;\n          cid[j] = cid[current];\n        }\n      }\n    }\n\n    // Set all component ids to the same id if they're connected.\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) == 1 and cid[i]!= cid[j]) {\n        int old_cid = cid[j];\n        for (int k = 0; k < N; k++) {\n          if (cid[k] == old_cid) {\n            cid[k] = cid[i];\n          }\n        }\n      }\n    }\n\n  });\n\n  // Initialize an array to hold the unique component ids.\n  Kokkos::View<int*> cid_unique(\"cid\", N);\n  Kokkos::deep_copy(cid_unique, -1);\n  int cur_id = 0;\n\n  // Populate the unique component ids array.\n  Kokkos::parallel_for(\n\t\t  Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\t  KOKKOS_LAMBDA(const int i) {\n    if (cid_unique[i] == -1) {\n      cid_unique[i] = cur_id;\n      cur_id++;\n    }\n  });\n\n  // Return the number of components.\n  return cur_id;\n}",
            "Kokkos::View<int*> component(Kokkos::ViewAllocateWithoutInitializing(\"component\"), N);\n\tKokkos::parallel_for(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(int i) {\n\t\t\t\tcomponent(i) = i;\n\t\t\t}\n\t);\n\tKokkos::parallel_for(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(int i) {\n\t\t\t\tfor(int j = i + 1; j < N; j++) {\n\t\t\t\t\tif(A(i, j)) {\n\t\t\t\t\t\tint compI = component(i);\n\t\t\t\t\t\tint compJ = component(j);\n\t\t\t\t\t\tif(compI!= compJ) {\n\t\t\t\t\t\t\tfor(int k = 0; k < N; k++) {\n\t\t\t\t\t\t\t\tif(component(k) == compJ) {\n\t\t\t\t\t\t\t\t\tcomponent(k) = compI;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t);\n\n\tKokkos::View<int*> componentCounts(Kokkos::ViewAllocateWithoutInitializing(\"componentCounts\"), N);\n\tKokkos::parallel_for(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(int i) {\n\t\t\t\tcomponentCounts(i) = 0;\n\t\t\t}\n\t);\n\n\tfor(int i = 0; i < N; i++) {\n\t\tcomponentCounts(component(i))++;\n\t}\n\n\tKokkos::View<int*> componentCountsAccum(\"componentCountsAccum\", 1);\n\tKokkos::parallel_reduce(\n\t\t\tKokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n\t\t\tKOKKOS_LAMBDA(int i, int &total) {\n\t\t\t\ttotal += componentCounts(i);\n\t\t\t},\n\t\t\tKokkos::Sum<int>(componentCountsAccum(0))\n\t);\n\tint total = Kokkos::create_mirror_view(componentCountsAccum)(0);\n\n\treturn total;\n}",
            "// Your code here\n  Kokkos::View<int*> compCount(\"compCount\", N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [&] (int i) {\n    // If already assigned, nothing to do\n    if (compCount(i) > 0)\n      return;\n\n    // Assign compCount(i) with the id of the root component\n    compCount(i) = i;\n\n    // Traverse all the components connected to component i\n    for (size_t j = 0; j < N; ++j) {\n      if (compCount(j) > 0 && A(i, j) == 1) {\n        // Combine the two components\n        compCount(i) = std::min(compCount(i), compCount(j));\n      }\n    }\n  });\n\n  // Find the max component id\n  int maxCompId = 0;\n  for (int i = 0; i < N; ++i) {\n    if (compCount(i) > maxCompId) {\n      maxCompId = compCount(i);\n    }\n  }\n\n  return maxCompId;\n}",
            "using ViewType = Kokkos::View<int*>;\n  int* comp = (int*)malloc(sizeof(int) * N);\n  for(int i = 0; i < N; i++) {\n    comp[i] = i;\n  }\n\n  // TODO: define a Kokkos reduction view and populate it with the result of the algorithm\n\n  // TODO: define a Kokkos parallel for loop to perform the BFS algorithm on comp\n\n  // TODO: check if you need to synchronize\n\n  int count = 0;\n  for(int i = 0; i < N; i++) {\n    if(comp[i] == i) {\n      count++;\n    }\n  }\n  free(comp);\n  return count;\n}",
            "if (A.extent(0)!= N) {\n    throw std::invalid_argument(\"Expected A to be an NxN matrix.\");\n  }\n\n  // TODO: Implement me!\n  return -1;\n}",
            "Kokkos::View<int*> count(\"count\", N);\n  Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::View<int*> c(\"c\", 1);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    visited(i) = 0;\n    count(i) = 0;\n  });\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    if (visited(i) == 0) {\n      // use DFS to count the number of connected components\n      Kokkos::View<int*> stack(\"stack\", N);\n      int top = 0;\n      stack(top++) = i;\n      visited(i) = 1;\n      count(i) = 1;\n      while (top!= 0) {\n        const int u = stack(--top);\n        for (int v = 0; v < N; v++) {\n          if (A(u, v)!= 0 && visited(v) == 0) {\n            stack(top++) = v;\n            visited(v) = 1;\n            count(i)++;\n          }\n        }\n      }\n    }\n  });\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &total) {\n    total += count(i);\n  }, c);\n  return c(0);\n}",
            "// Fill in your code here.\n}",
            "int ncc = 0;\n\tKokkos::View<int*> visited(\"visited\", N);\n\tKokkos::parallel_for(\n\t\t\t\"componentCount\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int i) {\n\t\t\t\tif (visited(i) == 0) {\n\t\t\t\t\tvisited(i) = 1;\n\t\t\t\t\tKokkos::parallel_for(\n\t\t\t\t\t\t\t\"DFS\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(int j) {\n\t\t\t\t\t\t\t\tif (A(i, j) == 1 && visited(j) == 0) {\n\t\t\t\t\t\t\t\t\tvisited(j) = 1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t++ncc;\n\t\t\t\t}\n\t\t\t});\n\treturn ncc;\n}",
            "Kokkos::View<int*> visited(\"visited\", N);\n\tKokkos::View<int*> componentID(\"componentID\", N);\n\tKokkos::parallel_for(\"cc\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tif(visited(i) == 0) {\n\t\t\tcomponentID(i) = 1;\n\t\t\tKokkos::parallel_for(\"cc\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int j) {\n\t\t\t\tif(visited(j) == 0 && A(i, j)) {\n\t\t\t\t\tcomponentID(j) = 1;\n\t\t\t\t\tvisited(j) = 1;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n\tint compCount = 0;\n\tKokkos::parallel_for(\"cc\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tif(componentID(i) == 1) {\n\t\t\tcompCount++;\n\t\t}\n\t});\n\treturn compCount;\n}",
            "// Your code here.\n}",
            "// Your code goes here\n\treturn 0;\n}",
            "// Create a view to hold the component labels.  At first, we'll assume all\n    // of them are labeled 0.\n    Kokkos::View<int*> labels(\"labels\", N);\n    Kokkos::deep_copy(labels, 0);\n\n    // Create a queue, which is an integer array where we'll keep track of\n    // all the nodes that we still need to process.  We'll use this queue\n    // to store the node that we are currently processing.\n    Kokkos::View<int*> queue(\"queue\", N);\n    Kokkos::deep_copy(queue, 0);\n\n    // This array is used to keep track of how many nodes we still have left\n    // in the queue.  We'll use this to determine when we've finished processing\n    // all of the nodes.\n    int queueSize = 0;\n\n    // This loop iterates over all of the nodes in the graph.  In each pass\n    // through this loop, we'll process a node, and all of its neighbors, and\n    // mark them as part of the same component.\n    for (int i = 0; i < N; ++i) {\n\n        // As long as we still have nodes in the queue, we'll process them.\n        while (queueSize) {\n\n            // Peek at the first node in the queue.  This is the current node\n            // that we're processing.\n            int currentNode = queue[0];\n\n            // If the node is still labeled 0, then we'll give it a label.\n            // Otherwise, we'll skip it, because it's already been processed.\n            if (labels(currentNode) == 0) {\n                labels(currentNode) = 1;\n\n                // For each of the current node's neighbors, mark them as\n                // part of the same component, and add them to the queue.\n                for (int j = 0; j < N; ++j) {\n                    if (A(currentNode, j)) {\n                        labels(j) = 1;\n                        queue[queueSize++] = j;\n                    }\n                }\n            }\n\n            // Remove the current node from the queue, because we're done\n            // processing it.\n            for (int j = 0; j < queueSize - 1; ++j) {\n                queue(j) = queue(j + 1);\n            }\n            queueSize -= 1;\n        }\n    }\n\n    // Return the number of components.\n    return Kokkos::",
            "// TODO: Replace this with your code\n\treturn -1;\n}",
            "int num_comps = 0;\n\tKokkos::View<int*> is_visited(\"is_visited\", N);\n\tKokkos::View<int*> comps(\"comps\", N);\n\n\tKokkos::parallel_for(\"Init\", N, KOKKOS_LAMBDA(const int i) {\n\t\tis_visited(i) = 0;\n\t\tcomps(i) = i;\n\t});\n\n\t// Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int i) {\n\t// \t// If we have not already visited this vertex\n\t// \tif (is_visited(i) == 0) {\n\t// \t\t// Count number of components\n\t// \t\tnum_comps += 1;\n\n\t// \t\t// Traverse the component\n\t// \t\tKokkos::parallel_for(\"traverse\", N, KOKKOS_LAMBDA(const int j) {\n\t// \t\t\t// If j is in the same component, and is a neighbor of i\n\t// \t\t\tif (is_visited(j) == 0 && A(i,j) == 1) {\n\t// \t\t\t\tis_visited(j) = 1;\n\t// \t\t\t\tcomps(j) = comps(i);\n\t// \t\t\t}\n\t// \t\t});\n\t// \t}\n\t// });\n\n\treturn num_comps;\n}",
            "using namespace Kokkos;\n  // Create 2 views:\n  // 1. Component IDs, which we'll return after the algorithm is done.\n  // 2. Array of counts of connected components.\n  View<int*> componentIDs(\"componentIDs\", N);\n  View<int*> numComponents(\"numComponents\", 1);\n\n  // Create a parallel_for over all matrix elements.\n  Kokkos::parallel_for(\n    \"componentCount\",\n    N,\n    KOKKOS_LAMBDA(const int& i) {\n      // Mark each element unprocessed.\n      // Unprocessed elements will have a value of -1.\n      componentIDs(i) = -1;\n    });\n  Kokkos::fence();\n\n  // Create a functor class to perform a DFS on the graph\n  class DFSFunctor {\n  private:\n    View<int*> componentIDs;\n    View<int*> numComponents;\n    const Kokkos::View<const int**> A;\n    const size_t N;\n\n  public:\n    DFSFunctor(\n      View<int*> componentIDs_,\n      View<int*> numComponents_,\n      Kokkos::View<const int**> A_,\n      size_t N_) :\n      componentIDs(componentIDs_),\n      numComponents(numComponents_),\n      A(A_),\n      N(N_) {}\n\n    KOKKOS_INLINE_FUNCTION void operator()(const int& i) const {\n      // If already visited, do nothing.\n      if (componentIDs(i)!= -1) {\n        return;\n      }\n\n      // Mark the vertex as visited.\n      componentIDs(i) = 0;\n\n      // If not an edge, do nothing.\n      if (!A(i, i)) {\n        return;\n      }\n\n      // Recursively visit all the edges of this vertex.\n      // This works because DFS is guaranteed to visit all connected components in order.\n      // We can simply increment our count.\n      numComponents(0)++;\n      for (int j = 0; j < N; j++) {\n        if (A(i, j)) {\n          this->operator()(j);\n        }\n      }\n    }\n  };\n\n  // Run the functor.\n  DFSFunctor dfsFunctor(componentIDs, numComponents, A, N);\n  Kokkos::parallel_for(\n    \"DFS\",\n    N,\n    dfsFunctor);\n  Kokkos::fence();\n\n  // Copy the componentIDs array back to the host.\n  View<int*> componentIDsHost(Kokkos::ViewAllocateWithoutInitializing(\"componentIDsHost\"), N);\n  Kokkos::deep_copy(componentIDsHost, componentIDs);\n  int* componentIDsData = componentIDsHost.data();\n\n  // Determine the number of components.\n  int numComponents = 0;\n  for (int i = 0; i < N; i++) {\n    if (componentIDsData[i] == 0) {\n      numComponents++;\n    }\n  }\n\n  return numComponents;\n}",
            "/* Write your solution here */\n\n}",
            "// TODO: compute connected components in A\n\t// return the number of components found\n}",
            "typedef Kokkos::View<int*> view_type;\n  view_type v(Kokkos::ViewAllocateWithoutInitializing(\"v\"), N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n    v(i) = -1;\n  });\n\n  int num_components = 0;\n\n  // TODO: use Kokkos to find the connected components\n\n  return num_components;\n}",
            "//TODO: Complete this function\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> componentCount(Kokkos::ViewAllocateWithoutInitializing(\"componentCount\"), N);\n  Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(const int i) {\n    // TODO: use Kokkos::minloc_reduce to find the index of the first element of a row in A that is 1\n    //   (i.e., find a neighbor of A[i])\n    // TODO: use Kokkos::reduce to find the number of 1s in the row\n    //   (i.e., the number of neighbors of A[i])\n    // HINT: Use Kokkos::Sum.  If you use Kokkos::Min, you'll get the index of the first element.\n    // TODO: use Kokkos::deep_copy to write the result to componentCount\n    componentCount(i) = 0;\n  });\n  Kokkos::deep_copy(componentCount, componentCount);\n  int result = 0;\n  for (int i = 0; i < N; ++i) {\n    result += componentCount(i);\n  }\n  return result;\n}",
            "Kokkos::View<int*> workspace(\"workspace\", N);\n  Kokkos::View<int*> component_counts(\"component_counts\", 1);\n  Kokkos::deep_copy(workspace, 0);\n  Kokkos::deep_copy(component_counts, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n    [=](const int i) {\n      if(workspace(i) == 0) {\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n          [=](const int j) {\n            if(A(i, j) == 1) {\n              workspace(j) = 1;\n            }\n          });\n        component_counts(0) += 1;\n      }\n    });\n\n  Kokkos::deep_copy(workspace, 0);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n    [=](const int i) {\n      if(workspace(i) == 0) {\n        Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n          [=](const int j) {\n            if(A(j, i) == 1) {\n              workspace(j) = 1;\n            }\n          });\n        component_counts(0) += 1;\n      }\n    });\n\n  int count;\n  Kokkos::deep_copy(count, component_counts);\n  return count;\n}",
            "// TODO\n  // Write code that computes the number of connected components\n  // in the graph defined by the adjacency matrix A.\n  // A is an NxN adjacency matrix.\n  // Use Kokkos to compute in parallel.\n  // Assume Kokkos has already been initialized.\n\n  // Your code here\n}",
            "// TODO: Implement this function\n}",
            "/*\n\tint N = A.extent(0);\n\t*/\n\tKokkos::View<int*, Kokkos::HostSpace> compCnt(\"compCnt\", N);\n\tKokkos::View<int*, Kokkos::HostSpace> visited(\"visited\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tvisited(i) = 0;\n\t});\n\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tcompCnt(i) = 0;\n\t});\n\n\tint * compCnt_ptr = compCnt.data();\n\tint * visited_ptr = visited.data();\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited_ptr[i] == 0) {\n\t\t\tint comp = 0;\n\t\t\t// TODO\n\t\t\tcompCnt_ptr[i] = 0;\n\t\t\t//compCnt(i) = 0;\n\t\t\t//Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& j) {\n\t\t\t//});\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (compCnt(i) > 0) {\n\t\t\tcount += 1;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "using view_type = Kokkos::View<int*>;\n  // Write code here.\n  return -1;\n}",
            "int num_components = 0;\n\n\t//TODO: Fill in the body of this function.\n\treturn num_components;\n}",
            "// TODO: Implement componentCount\n\treturn 0;\n}",
            "// TODO\n}",
            "int componentCount = 0;\n  Kokkos::View<int*, Kokkos::HostSpace> components(\"components\", N);\n  // TODO: Kokkos::parallel_for over the rows of A.\n  //\t Inside the parallel_for, iterate over the columns and set the value of components(i) to j if A(i,j) == 1 and components(i) is unset.\n  // TODO: Compute the number of unique elements of components and store it in componentCount.\n\n  return componentCount;\n}",
            "// The component labels (0, 1, 2,...) of each vertex.\n\tKokkos::View<int*> components(\"components\", N);\n\tKokkos::deep_copy(components, 0);\n\n\t// A single work-item of the parallel_for, which is used to mark components.\n\tauto mark = KOKKOS_LAMBDA(const int& i) {\n\t\tif (components(i) == 0) {\n\t\t\t// This vertex hasn't been marked yet.\n\t\t\t// Visit all neighbors.\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\tcomponents(j) = components(i) + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\t// The parallel_for has 1 work-item per vertex.\n\t// The lambda is executed in parallel, so each work-item of the parallel_for\n\t// can access the array of components.\n\tKokkos::parallel_for(N, mark);\n\n\t// Count the number of connected components.\n\tint numComponents = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (components(i)!= 0) {\n\t\t\t++numComponents;\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "Kokkos::View<int*> v(\"v\", N);\n\tKokkos::View<int*> w(\"w\", N);\n\tKokkos::View<int*> color(\"color\", N);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tKokkos::parallel_for(\n\t\t\t\"init\",\n\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int &j) {\n\t\t\t\tv(j) = 0;\n\t\t\t\tw(j) = 0;\n\t\t\t\tcolor(j) = 0;\n\t\t\t}\n\t\t);\n\t\tKokkos::fence();\n\n\t\tKokkos::parallel_for(\n\t\t\t\"find_components\",\n\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int &j) {\n\t\t\t\tif (color(j) == 0) {\n\t\t\t\t\tdfs(A, color, v, w, j);\n\t\t\t\t}\n\t\t\t}\n\t\t);\n\t\tKokkos::fence();\n\n\t\tint number_of_components = 0;\n\t\tKokkos::parallel_reduce(\n\t\t\t\"count_components\",\n\t\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\t\tKOKKOS_LAMBDA(const int &j, int &tot) {\n\t\t\t\tif (color(j) == 1) {\n\t\t\t\t\ttot += 1;\n\t\t\t\t}\n\t\t\t},\n\t\t\tnumber_of_components\n\t\t);\n\t\tKokkos::fence();\n\n\t\treturn number_of_components;\n\t}\n\n\treturn 0;\n}",
            "// TODO: Your code here\n\n\treturn 0;\n}",
            "Kokkos::View<int*> componentCount(\"componentCount\", N);\n\tKokkos::deep_copy(componentCount, 0);\n\n\t// TODO: Fill in the rest of the componentCount function\n\n\treturn 0;\n}",
            "// Use a boolean array to represent which nodes have been visited\n\tKokkos::View<bool*> visited(\"visited\", N);\n\n\t// Use a rank array to track which node has the most connections\n\t// Only used for finding the connected component with the most nodes\n\tKokkos::View<int*> rank(\"rank\", N);\n\n\t// initialize all arrays to 0\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tvisited(i) = false;\n\t\trank(i) = 0;\n\t});\n\n\t// Loop over every node and find all connected components\n\tint connected_components = 0;\n\tint most_connections = 0;\n\tKokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i, int &count) {\n\t\t// skip if we have already visited this node\n\t\tif (!visited(i)) {\n\t\t\t// this node has not been visited yet, so it has no connections\n\t\t\tint connected_component_size = 0;\n\t\t\t// we are currently at node i, so it has been visited\n\t\t\tvisited(i) = true;\n\t\t\trank(i) = 1;\n\n\t\t\t// find all connected components\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t// skip the diagonal and any nodes we have already visited\n\t\t\t\tif (i == j || visited(j)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// if node j is connected to node i, recursively find all connected nodes\n\t\t\t\tif (A(i, j)) {\n\t\t\t\t\tconnected_component_size += findConnected(A, visited, rank, i, j, N);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// keep track of the connected component with the most nodes\n\t\t\tif (connected_component_size > most_connections) {\n\t\t\t\tmost_connections = connected_component_size;\n\t\t\t}\n\n\t\t\tcount++;\n\t\t}\n\t}, connected_components);\n\n\t// connected_components contains the number of connected components\n\t// most_connections contains the number of nodes in the largest component\n\treturn connected_components;\n}",
            "// TODO: your code here\n\treturn 0;\n}",
            "Kokkos::View<int*> component_ids(\"component_ids\", N);\n  Kokkos::View<int*> component_sizes(\"component_sizes\", N);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [&] (const int i) {\n    // TODO: Initialize component_ids and component_sizes\n  });\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), [&] (const int i) {\n    for (int j = 0; j < N; ++j) {\n      if (i == j) continue;\n      if (A(i,j)!= 0) {\n        // TODO: Union the components of i and j\n      }\n    }\n  });\n\n  int num_components = 0;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(const int i, int& local_sum) {\n      if (component_sizes(i)!= 0) {\n        // TODO: Add one to the number of components\n      }\n    }, Kokkos::Sum<int>(num_components));\n\n  return num_components;\n}",
            "Kokkos::View<int*> A_flat(\"A_flat\", N * N);\n  int numComponents = 0;\n\n  Kokkos::parallel_reduce(N * N, KOKKOS_LAMBDA(const int i, int& local_numComponents) {\n    local_numComponents++;\n  }, numComponents);\n\n  return numComponents;\n}",
            "Kokkos::View<int*> num_components(\"num_components\", N);\n  Kokkos::View<int*> component_sizes(\"component_sizes\", N);\n  Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::View<int*> component_size_order(\"component_size_order\", N);\n  Kokkos::View<int*> component_sizes_ordered(\"component_sizes_ordered\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    num_components(i) = i;\n    component_sizes(i) = 1;\n    visited(i) = 0;\n    component_size_order(i) = 0;\n  });\n\n  int num_components_final = 0;\n  int current_component = 0;\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) &&!visited(j)) {\n        visited(j) = 1;\n        num_components(j) = current_component;\n        component_sizes(current_component) += 1;\n      }\n    }\n  });\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    component_size_order(i) = i;\n  });\n\n  // TODO: sort component_sizes and component_size_order\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    if (component_size_order(i) < N - 1) {\n      component_sizes_ordered(component_size_order(i)) = component_sizes(i);\n    }\n  });\n\n  int largest_component_size = 0;\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    if (component_sizes_ordered(i) > largest_component_size) {\n      largest_component_size = component_sizes_ordered(i);\n    }\n  });\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    if (component_sizes(i) == largest_component_size) {\n      num_components_final += 1;\n    }\n  });\n\n  return num_components_final;\n}",
            "int numComponents = 0;\n  std::vector<int> componentIds;\n\n  // Loop over rows\n  for (int i = 0; i < N; ++i) {\n    // Mark row as seen\n    componentIds.push_back(i);\n    numComponents++;\n\n    // Loop over the row's neighbors\n    for (int j = 0; j < N; ++j) {\n      if (A(i,j) == 1) {\n        // If neighbor is not seen, mark it and combine it with the row's component\n        if (std::find(componentIds.begin(), componentIds.end(), j) == componentIds.end()) {\n          componentIds.push_back(j);\n          numComponents--;\n        }\n      }\n    }\n  }\n\n  return numComponents;\n}",
            "Kokkos::View<int*> visited(\"visited\", N);\n\n  // TODO: fill in\n\n  return count;\n}",
            "// Set up a \"result\" array to keep track of the result\n  Kokkos::View<int*> result(\"result\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    result(i) = -1;\n  });\n\n  // Now fill in the result array\n  // Do this in parallel using Kokkos\n  // We can use Kokkos::atomic_fetch_or() to add 1 to the component count if the index is not yet visited\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    if (result(i) == -1) {\n      for (int j = 0; j < N; ++j) {\n        Kokkos::atomic_fetch_or(&result(j), A(i, j) * (i == j));\n      }\n    }\n  });\n\n  // Count the number of components by adding up the result array\n  int count = 0;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(int i, int &accumulator) {\n    accumulator += result(i) == -1;\n  }, count);\n\n  return count;\n}",
            "// You may want to use a parallel_for loop.\n  // You may need to use Kokkos::atomic_add() for the counter.\n  // You may want to use a Kokkos::View to store the component labels.\n  // You may want to use the Kokkos::deep_copy() function to copy labels back to host memory.\n  // You may want to use the Kokkos::HostSpace execution space.\n  //\n  // Hint: you don't need to write any loops!\n\n  // TODO: Your code here.\n  Kokkos::View<int**> labels(\"labels\", N, N);\n  Kokkos::parallel_for(\"component_labeling\", Kokkos::RangePolicy<Kokkos::HostSpace, int>(0, N), KOKKOS_LAMBDA(const int i){\n    for (int j = 0; j < N; j++){\n      if (A(i,j) == 1){\n        if (labels(i,j) == 0){\n          labels(i, j) = 1;\n          int k = 0;\n          for (; k < N; k++){\n            if (A(k, j) == 1){\n              labels(i, k) = 1;\n            }\n          }\n          for (int l = 0; l < N; l++){\n            if (A(i, l) == 1 && labels(l, j) == 0){\n              labels(i, l) = 1;\n              labels(l, j) = 1;\n            }\n          }\n        }\n      }\n    }\n  });\n\n  int count = 0;\n  for (int i = 0; i < N; i++){\n    for (int j = 0; j < N; j++){\n      if (labels(i,j) == 0)\n        count++;\n    }\n  }\n  Kokkos::deep_copy(A, labels);\n  return count;\n}",
            "// TODO: replace this with your implementation\n\treturn 0;\n}",
            "auto A_host = Kokkos::create_mirror_view(A);\n\tKokkos::deep_copy(A_host, A);\n\n\t// TODO: Your code here.\n\tint count = 0;\n\treturn count;\n}",
            "// TODO: implement\n  int num_components = 0;\n  for(size_t i = 0; i < N; ++i) {\n    int count = 0;\n    for(size_t j = 0; j < N; ++j) {\n      if(A(i, j) == 1) {\n        ++count;\n      }\n    }\n    if(count == 1) {\n      ++num_components;\n    }\n  }\n  return num_components;\n}",
            "// Declare variables here.\n\n\t// Perform computation here.\n\t// This should be parallelized with Kokkos.\n\n\t// Return the number of components.\n}",
            "Kokkos::View<int*> result(\"result\", N);\n\n  Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(size_t i) {\n    result(i) = i;\n  });\n\n  Kokkos::parallel_for(\"componentCount\", N, KOKKOS_LAMBDA(size_t i) {\n    for (size_t j = 0; j < N; j++) {\n      if (i!= j && A(i, j) == 1) {\n        result(i) = result(j);\n        break;\n      }\n    }\n  });\n\n  return *std::max_element(result.data(), result.data() + N);\n}",
            "Kokkos::View<int*> d_cc(\"cc\", N);\n  Kokkos::View<int*> d_cc_prev(\"cc_prev\", N);\n  Kokkos::View<int*> d_cc_count(\"cc_count\", 1);\n  Kokkos::View<bool*> d_done(\"done\", 1);\n\n  Kokkos::parallel_for(\n   \"cc_init\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      d_cc(i) = i;\n  });\n\n  Kokkos::deep_copy(d_cc_prev, d_cc);\n  Kokkos::deep_copy(d_cc_count, 0);\n\n  int change = 1;\n  while (change) {\n    change = 0;\n\n    Kokkos::parallel_for(\n     \"cc_merge\",\n      Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n      KOKKOS_LAMBDA(const int i) {\n        int cc_i = d_cc(i);\n        for (int j = 0; j < N; j++) {\n          if (A(i, j)!= 0) {\n            int cc_j = d_cc(j);\n            if (cc_j < cc_i) {\n              d_cc(i) = cc_j;\n              change = 1;\n            }\n          }\n        }\n    });\n\n    Kokkos::parallel_for(\n     \"cc_prop\",\n      Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n      KOKKOS_LAMBDA(const int i) {\n        if (d_cc(i)!= d_cc_prev(i)) {\n          change = 1;\n        }\n    });\n\n    Kokkos::deep_copy(d_cc_prev, d_cc);\n  }\n\n  Kokkos::parallel_for(\n   \"cc_count\",\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      if (d_done(0) == 0) {\n        int cc_i = d_cc(i);\n        atomic_inc(d_cc_count(0), cc_i);\n      }\n  });\n\n  Kokkos::deep_copy(d_done, 1);\n\n  int cc_count;\n  Kokkos::deep_copy(cc_count, d_cc_count);\n\n  return cc_count;\n}",
            "Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::View<int*> cnt(\"cnt\", N);\n  // initialize kokkos views\n  Kokkos::parallel_for(\"init\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i) {\n    visited(i) = 0;\n    cnt(i) = 0;\n  });\n  // for each row, if not visited yet, do a dfs\n  Kokkos::parallel_for(\"dfs\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i) {\n    if (visited(i) == 0) {\n      cnt(i) = dfs_impl(i, A, visited, 0);\n    }\n  });\n  // find the maximum of the cnt\n  Kokkos::parallel_reduce(\"count\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i, int& max) {\n    max = std::max(max, cnt(i));\n  }, Kokkos::Max<int>(0));\n\n  return max;\n}",
            "// TODO\n}",
            "// Your code goes here.\n  Kokkos::View<int*, Kokkos::HostSpace> vis(N);\n  Kokkos::View<int*, Kokkos::HostSpace> cnt(N);\n  Kokkos::View<int*, Kokkos::HostSpace> parent(N);\n  Kokkos::View<int*, Kokkos::HostSpace> ccs(N);\n  Kokkos::View<int*, Kokkos::HostSpace> comp(N);\n  Kokkos::View<int*, Kokkos::HostSpace> comps(N);\n  Kokkos::View<int*, Kokkos::HostSpace> d(N);\n  Kokkos::View<int*, Kokkos::HostSpace> dfs(N);\n  Kokkos::View<int*, Kokkos::HostSpace> count(N);\n  Kokkos::View<int*, Kokkos::HostSpace> com(N);\n  Kokkos::View<int*, Kokkos::HostSpace> coms(N);\n\n  for(int i = 0; i < N; ++i)\n    vis(i) = 0;\n  for(int i = 0; i < N; ++i)\n    cnt(i) = 0;\n  for(int i = 0; i < N; ++i)\n    parent(i) = 0;\n  for(int i = 0; i < N; ++i)\n    ccs(i) = 0;\n  for(int i = 0; i < N; ++i)\n    comp(i) = 0;\n  for(int i = 0; i < N; ++i)\n    comps(i) = 0;\n  for(int i = 0; i < N; ++i)\n    d(i) = 0;\n  for(int i = 0; i < N; ++i)\n    dfs(i) = 0;\n  for(int i = 0; i < N; ++i)\n    count(i) = 0;\n  for(int i = 0; i < N; ++i)\n    com(i) = 0;\n  for(int i = 0; i < N; ++i)\n    coms(i) = 0;\n\n  int count_cc = 0;\n\n  for(int i = 0; i < N; ++i)\n  {\n    if(vis(i) == 0)\n    {\n      ccs(i) = 1;\n      Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(i,N), [&] (int k)\n      {\n        if(vis(k) == 0)\n        {\n          if(A(i,k) == 1)\n          {\n            vis(k) = 1;\n            ccs(i) = ccs(i) + 1;\n          }\n        }\n      });\n      count_cc = count_cc + 1;\n      parent(i) = i;\n    }\n  }\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace>(0,N), [&] (int i)\n  {\n    for(int j = 0; j < N; ++j)\n    {\n      if(vis(i) == 1 && vis(j) == 1)\n      {\n        for(int k = 0; k < N; ++k)\n        {\n          if(A(i,k) == 1 && A(j,k) == 1)\n          {\n            ccs(i) = ccs(i) + 1;\n            ccs(j) = ccs(j) + 1;\n          }\n        }\n      }\n    }\n  });\n\n  for(int i = 0; i < N; ++i)\n  {\n    if(vis(i) == 0)\n    {\n      comp(i) = 1;\n      parent(i) = i;\n    }\n    else\n    {\n      parent(i) = parent(parent(i));",
            "// Step 1: create Kokkos views for components, compCount, and componentSize\n    // for the current vertex and component counts.\n    Kokkos::View<int*> comp(\"components\", N);\n    Kokkos::View<int*> compCount(\"componentCount\", 1);\n    Kokkos::View<int*> componentSize(\"componentSize\", 1);\n\n    // Step 2: create Kokkos views for the current vertex and current component.\n    Kokkos::View<int*> currVertex(\"currVertex\", 1);\n    Kokkos::View<int*> currComp(\"currComp\", 1);\n\n    // Step 3: initialize all components to 0, all compCount to 1, and all componentSize to N.\n    Kokkos::deep_copy(comp, 0);\n    Kokkos::deep_copy(compCount, 0);\n    Kokkos::deep_copy(componentSize, N);\n\n    // Step 4: for each vertex in the graph, start a BFS.\n    //\t\t\t If we are currently on a new component, increment the component count.\n    //\t\t\t Then, mark all vertices that belong to this component and count them.\n    //\t\t\t Then, increment the current vertex by 1.\n    int i;\n    for (i = 0; i < N; i++) {\n        Kokkos::deep_copy(currVertex, i);\n        Kokkos::deep_copy(currComp, 0);\n        int neighbor;\n        for (int j = 0; j < N; j++) {\n            neighbor = A(i, j);\n            if (neighbor == 1) {\n                if (comp(j) == 0) {\n                    Kokkos::deep_copy(currComp, 1);\n                    comp(j) = currComp;\n                } else if (comp(j)!= currComp) {\n                    comp(j) = currComp;\n                }\n            }\n        }\n        Kokkos::deep_copy(currVertex, currVertex + 1);\n        if (currComp == 1) {\n            Kokkos::deep_copy(compCount, compCount + 1);\n        }\n    }\n    return compCount;\n}",
            "// Count the number of components.\n\tint nComponents = 0;\n\n\t// Create an array to hold the components.\n\tKokkos::View<int*> visited(\"visited\", N);\n\tKokkos::deep_copy(visited, 0);\n\n\t// Iterate over the adjacency matrix.\n\tKokkos::parallel_for(\"CC\", N, KOKKOS_LAMBDA(const int i) {\n\t\t// If the current vertex has not been visited.\n\t\tif (visited(i) == 0) {\n\t\t\t// Mark the component as visited.\n\t\t\tnComponents++;\n\t\t\tvisited(i) = 1;\n\n\t\t\t// Iterate through the neighbors of this vertex.\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j)!= 0) {\n\t\t\t\t\t// If the neighbor has not been visited, mark it as visited.\n\t\t\t\t\tif (visited(j) == 0) {\n\t\t\t\t\t\tvisited(j) = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\treturn nComponents;\n}",
            "//\n    // Create a Kokkos view to store the component ID for each vertex.\n    // Initialize it to -1 for unassigned and to the vertex ID for singletons.\n    //\n    Kokkos::View<int*> component(\"component\", N);\n    Kokkos::parallel_for(\"initialize\", N, KOKKOS_LAMBDA(const int &i) {\n        if (A(i, i) == 0)\n            component(i) = -1;\n        else\n            component(i) = i;\n    });\n    Kokkos::fence();\n\n    //\n    // Use a Kokkos reducer to count the number of components.\n    //\n    Kokkos::View<int*> componentCount(\"componentCount\", 1);\n    Kokkos::parallel_reduce(\"count\", N, KOKKOS_LAMBDA(const int &i, int &n) {\n        if (component(i)!= -1)\n            n++;\n    }, Kokkos::Sum<int>(componentCount));\n\n    //\n    // Find all of the connected components by doing a breadth first search starting at each vertex.\n    //\n    Kokkos::parallel_for(\"bfs\", N, KOKKOS_LAMBDA(const int &i) {\n        if (component(i)!= -1) {\n            Kokkos::View<int**> componentView(\"componentView\", N, N);\n            Kokkos::deep_copy(componentView, component);\n            std::queue<int> queue;\n            queue.push(i);\n            while (!queue.empty()) {\n                int v = queue.front();\n                queue.pop();\n                for (int w = 0; w < N; ++w) {\n                    if (A(v, w) == 1 && component(w)!= -1) {\n                        component(w) = component(v);\n                        queue.push(w);\n                    }\n                }\n            }\n            Kokkos::deep_copy(component, componentView);\n        }\n    });\n    Kokkos::fence();\n\n    //\n    // Print the component ID for each vertex.\n    //\n    for (int i = 0; i < N; ++i) {\n        std::cout << \"component(\" << i << \") = \" << component(i) << std::endl;\n    }\n\n    //\n    // Return the number of components.\n    //\n    int sum;\n    Kokkos::deep_copy(sum, componentCount);\n    return sum;\n}",
            "int num_comps = 0;\n  Kokkos::View<int**> visited(\"visited\", N, N);\n  Kokkos::deep_copy(visited, 0);\n\n  // TODO: Fill this in\n\n  return num_comps;\n}",
            "// TODO: implement me!\n\treturn 0;\n}",
            "// Fill in the body of this function\n\n\tKokkos::View<int*> result(\"result\", N);\n\n\tKokkos::deep_copy(result, 0);\n\tKokkos::deep_copy(A, 0);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tif (result(i) < result(j)) {\n\t\t\t\t\tresult(i) = result(j);\n\t\t\t\t}\n\t\t\t\tif (result(j) < result(i)) {\n\t\t\t\t\tresult(j) = result(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (result(i) == 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// TODO: implement this function using Kokkos\n\n  return 0;\n}",
            "// Create an execution policy. This will determine how many threads are\n\t// used and whether each thread should execute in parallel.\n\t// Note that you can pass a Kokkos::RangePolicy (below) to any Kokkos\n\t// parallel_for loop to control how the loop is executed (e.g.,\n\t// you can set the number of iterations each thread will work on).\n\t// You can also use Kokkos::RangePolicy::all (below) to execute all\n\t// iterations in parallel.\n\tKokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace> exec_policy(0, N);\n\n\t// Create a parallel_for loop and execute it\n\t// Note: you can put code inside the for loop (e.g., your count logic)\n\tKokkos::parallel_for(exec_policy, KOKKOS_LAMBDA (const int i) {\n\t\t// Put your logic here to count the number of connected components\n\t\t// in the graph defined by A.\n\n\t\t// Example logic\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(A(i, j) == 1) {\n\t\t\t\t// Count the number of connected components in the graph\n\t\t\t\t// Example:\n\t\t\t\t//    input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n\t\t\t\t//    output: 2\n\t\t\t}\n\t\t}\n\t});\n\t// Make sure to call Kokkos::fence() at the end to ensure all\n\t// threads in your parallel_for loop have finished.\n\tKokkos::fence();\n\n\t// Count logic goes here. You can use the A View to iterate through\n\t// the matrix and count the number of connected components.\n\n\t// Return the number of connected components.\n\treturn 0;\n}",
            "// Count the number of connected components.\n\n\t// Kokkos's initialization and finalization routines are not re-entrant.\n\t// Ensure that they are only called once.\n\tstatic bool kokkos_initialized = false;\n\tif (!kokkos_initialized) {\n\t\tKokkos::initialize();\n\t\tkokkos_initialized = true;\n\t}\n\n\tKokkos::View<int*> comp_id(\"Component IDs\", N);\n\n\t// Your code goes here.\n\n\tKokkos::fence();\n\tint num_components = *Kokkos::View<int*>::HostMirror(comp_id).data();\n\n\tif (!kokkos_initialized) {\n\t\tKokkos::finalize();\n\t\tkokkos_initialized = false;\n\t}\n\n\treturn num_components;\n}",
            "// Declare views for flags and counts.\n\tKokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::View<int*> componentCounts(\"componentCounts\", N);\n\n\t// Use parallel_for to process each vertex in the graph.\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA (size_t i) {\n\n\t\t// If this vertex has already been visited, skip it.\n\t\tif (visited[i]) { return; }\n\n\t\t// Start a new component by adding one to the count.\n\t\tcomponentCounts[i]++;\n\n\t\t// Mark this vertex as visited.\n\t\tvisited[i] = true;\n\n\t\t// Now explore all neighbors.\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t// If there is an edge from i to j, and j has not been visited,\n\t\t\t// then add one to the component count.\n\t\t\tif (A(i, j)!= 0 &&!visited[j]) {\n\t\t\t\tcomponentCounts[i]++;\n\t\t\t\tvisited[j] = true;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Copy the result to the host.\n\tauto h_componentCounts = Kokkos::create_mirror_view(componentCounts);\n\tKokkos::deep_copy(h_componentCounts, componentCounts);\n\n\t// Compute the total number of components.\n\tint total = 0;\n\tfor (size_t i = 0; i < N; i++) { total += h_componentCounts[i]; }\n\n\treturn total;\n}",
            "// TODO: your code here\n\n  return -1;\n}",
            "// Create views for the workspaces needed by the algorithm\n\tKokkos::View<int*> color(\"color\", N);\n\tKokkos::View<int*> front(\"front\", N);\n\tKokkos::View<int*> next(\"next\", N);\n\n\t// Create a functor to do the work and run it on the device\n\tstruct ComponentCounter {\n\t\tKokkos::View<int*> color;\n\t\tKokkos::View<int*> front;\n\t\tKokkos::View<int*> next;\n\t\tKokkos::View<const int**> A;\n\t\tconst size_t N;\n\t\tint numComponents;\n\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator()(const int v) const {\n\t\t\tcolor(v) = 0;\n\t\t\tnext(v) = -1;\n\t\t}\n\n\t\t// The parallel_for function needs to know what range of indices to loop over.\n\t\t// In this case, we want to loop over every vertex in the graph.\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid init(const int i) const {\n\t\t\tcolor(i) = 0;\n\t\t\tfront(i) = i;\n\t\t}\n\n\t\t// The work is actually done here.\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid join(const int i, int& lsum) const {\n\t\t\t// The functor we're creating is a parallel_reduce, which means that it\n\t\t\t// is called once for each element of the range, and then again with the\n\t\t\t// results of the calls to each element. We use this to update the\n\t\t\t// number of connected components.\n\t\t\tlsum += 1;\n\t\t}\n\n\t\tComponentCounter(Kokkos::View<int*> color, Kokkos::View<int*> front, Kokkos::View<int*> next, Kokkos::View<const int**> A, const size_t N):\n\t\t\tcolor(color), front(front), next(next), A(A), N(N), numComponents(0) {}\n\n\t\t// Define a parallel_for work function that will be called for each vertex\n\t\t// in the graph. It starts the search at each vertex by calling findSet().\n\t\t// We use the functor we defined above to do the work.\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid operator()(const int i) const {\n\t\t\t// Find the component that this vertex belongs to and increment the count\n\t\t\t// by 1.\n\t\t\tnumComponents += findSet(i);\n\t\t}\n\n\t\t// This is the bread and butter of the algorithm. This function does the\n\t\t// work of finding the set that the vertex belongs to, unioning it with\n\t\t// the set that it is in, and marking the vertex as visited.\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tint findSet(const int v) const {\n\t\t\t// If this vertex hasn't been visited before, it's the root of a new component.\n\t\t\tif (color(v) == 0) {\n\t\t\t\t// Start a DFS at this vertex and add it to the list of vertices that\n\t\t\t\t// have been visited.\n\t\t\t\tint cur = v;\n\t\t\t\tfront(cur) = next(cur);\n\t\t\t\tcolor(cur) = 1;\n\n\t\t\t\t// While there are vertices in the frontier...\n\t\t\t\twhile (front(cur) >= 0) {\n\t\t\t\t\t// Get the next vertex from the frontier and then find the root of the set\n\t\t\t\t\t// that it belongs to.\n\t\t\t\t\tint w = front(cur);\n\t\t\t\t\tint rootW = findSet(w);\n\n\t\t\t\t\t// If the root of the set that this vertex belongs to isn't the same\n\t\t\t\t\t// as the root of the set that the previous vertex belongs to, then\n\t\t\t\t\t// the sets are different and we need to union them.\n\t\t\t\t\tif (rootW!= cur) {",
            "int numComponents = 0;\n\t// Your code goes here!\n\treturn numComponents;\n}",
            "Kokkos::View<int**> A_new(\"A_new\", N, N);\n    Kokkos::deep_copy(A_new, A);\n    for(size_t k = 0; k < N; k++) {\n        for(size_t i = 0; i < N; i++) {\n            for(size_t j = 0; j < N; j++) {\n                if(A_new(i, j) == 1) {\n                    for(size_t l = 0; l < N; l++) {\n                        if(A_new(l, j) == 1) {\n                            A_new(i, l) = 1;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    int sum = 0;\n    for(size_t i = 0; i < N; i++) {\n        int cnt = 0;\n        for(size_t j = 0; j < N; j++) {\n            if(A_new(i, j) == 1) {\n                cnt++;\n            }\n        }\n        if(cnt == 0) {\n            sum++;\n        }\n    }\n    return sum;\n}",
            "Kokkos::View<int*> comp(\"Component\", N);\n\tKokkos::deep_copy(comp, 0);\n\tint maxComp = 0;\n\n\t// TODO: Your code here!\n\n\treturn maxComp;\n}",
            "using namespace Kokkos;\n\n  // TODO: Replace this code with your implementation.\n  // You may need to use Kokkos::View or Kokkos::Subview.\n  // You can pass View or Subview to any Kokkos routine.\n  // You can use Kokkos::parallel_for to do parallel work.\n  // You can use Kokkos::single to do serial work.\n  // You can use Kokkos::fence to force synchronization between\n  // parallel_for and single.\n  // You can use Kokkos::RangePolicy to iterate over indices.\n  // You can use Kokkos::Experimental::H",
            "int *component = (int*)malloc(N*sizeof(int));\n  int *worklist = (int*)malloc(N*sizeof(int));\n  int num_components = 0;\n  for (int i = 0; i < N; i++) {\n    if (!component[i]) {\n      num_components++;\n      int queue_head = 0;\n      int queue_tail = 0;\n      worklist[queue_tail++] = i;\n      component[i] = num_components;\n      while (queue_head!= queue_tail) {\n        int j = worklist[queue_head++];\n        for (int k = 0; k < N; k++) {\n          if (A(j, k) &&!component[k]) {\n            component[k] = num_components;\n            worklist[queue_tail++] = k;\n          }\n        }\n      }\n    }\n  }\n  free(worklist);\n  free(component);\n  return num_components;\n}",
            "int result = 0;\n  Kokkos::View<int**> visited(\"visited\", N, N);\n  Kokkos::View<int*> componentCounts(\"componentCounts\", N);\n  Kokkos::parallel_for(\"count_components\", N, KOKKOS_LAMBDA(const int i) {\n    Kokkos::View<int*> componentCounts(\"componentCounts\", N);\n    Kokkos::View<int**> visited(\"visited\", N, N);\n    visited(i, i) = 1;\n    componentCounts(i) = 1;\n    Kokkos::parallel_for(\"component_bfs\", N, KOKKOS_LAMBDA(const int j) {\n      if (i == j) {\n        return;\n      }\n      if (A(i, j) &&!visited(j, i)) {\n        visited(i, j) = 1;\n        visited(j, i) = 1;\n        componentCounts(i) += componentCounts(j);\n      }\n    });\n  });\n\n  return result;\n}",
            "// TODO: Replace the code below to count the number of connected components in A.\n  // Remember that a component is connected if all vertices in the component are reachable from each other.\n  // You may assume that all vertices in the component can reach each other.\n  // You may assume that all rows and columns of A are sorted in increasing order.\n  // You may assume that A[i][j] == 0 if and only if A[j][i] == 0.\n  // You may assume that the number of elements in A is N^2.\n  int count = 0;\n\n  Kokkos::View<int**> V(\"V\", N, N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t  for (int j = 0; j < N; ++j) {\n\t\t  if (i == j) {\n\t\t\t  V(i, j) = 1;\n\t\t  }\n\t\t  else {\n\t\t\t  V(i, j) = 0;\n\t\t  }\n\t  }\n  });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t  for (int j = 0; j < i; ++j) {\n\t\t  if (A(i, j) > 0) {\n\t\t\t  for (int k = 0; k < N; ++k) {\n\t\t\t\t  if (V(i, k) == 1 && V(j, k) == 0) {\n\t\t\t\t\t  V(j, k) = 1;\n\t\t\t\t  }\n\t\t\t  }\n\t\t  }\n\t  }\n  });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t  for (int j = i; j < N; ++j) {\n\t\t  if (A(i, j) > 0) {\n\t\t\t  for (int k = 0; k < N; ++k) {\n\t\t\t\t  if (V(i, k) == 1 && V(j, k) == 0) {\n\t\t\t\t\t  V(j, k) = 1;\n\t\t\t\t  }\n\t\t\t  }\n\t\t  }\n\t  }\n  });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t  for (int j = 0; j < N; ++j) {\n\t\t  if (V(i, j) == 1) {\n\t\t\t  count++;\n\t\t\t  break;\n\t\t  }\n\t  }\n  });\n  return count;\n}",
            "// TODO: Your code here\n\n  // You may want to start with the following code, but you can change it\n\n  Kokkos::View<int*> componentCount(\"Component Count\", N);\n  Kokkos::parallel_for(\"Initialize component count\",\n      Kokkos::RangePolicy<decltype(A.device_type())>(0,N),\n      KOKKOS_LAMBDA(const int& i) {\n\t  componentCount(i) = -1;\n  });\n\n  Kokkos::parallel_for(\"Count Components\",\n      Kokkos::RangePolicy<decltype(A.device_type())>(0,N),\n      KOKKOS_LAMBDA(const int& i) {\n\t  if(componentCount(i) == -1){\n\t\t  int component_count = 0;\n\t\t  Kokkos::parallel_for(\"Depth first search\",\n\t\t\t  Kokkos::RangePolicy<decltype(A.device_type())>(0,N),\n\t\t\t  KOKKOS_LAMBDA(const int& j) {\n\t\t\t  if(A(i,j) && componentCount(j) == -1){\n\t\t\t\t  Kokkos::single(Kokkos::PerThread(A.device_type()),[&](){\n\t\t\t\t\t  componentCount(j) = component_count;\n\t\t\t\t  });\n\t\t\t\t  Kokkos::parallel_for(\"Depth first search\",\n\t\t\t\t\t  Kokkos::RangePolicy<decltype(A.device_type())>(0,N),\n\t\t\t\t\t  KOKKOS_LAMBDA(const int& k) {\n\t\t\t\t\t  if(A(j,k) && componentCount(k) == -1){\n\t\t\t\t\t\t  Kokkos::single(Kokkos::PerThread(A.device_type()),[&](){\n\t\t\t\t\t\t\t  componentCount(k) = component_count;\n\t\t\t\t\t\t  });\n\t\t\t\t\t  }\n\t\t\t\t  });\n\t\t\t  }\n\t\t  });\n\t\t  component_count++;\n\t  }\n  });\n\n  int sum = 0;\n  for(size_t i=0; i<N; i++){\n\t  sum += componentCount(i);\n  }\n  return sum;\n}",
            "// Create an array to track whether each vertex has been visited or not\n  Kokkos::View<int*, Kokkos::LayoutLeft, Kokkos::CudaSpace> visited(\"visited\", N);\n\n  // We use a parallel for to visit each vertex. For each vertex, we need to:\n  //   - mark the vertex as visited\n  //   - visit each neighboring vertex and mark it as visited if it is not already\n  Kokkos::parallel_for(\"mark_components\",\n      Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n    visited(i) = 1;\n    for (int j = 0; j < N; j++) {\n      if (A(i,j) && visited(j) == 0) {\n        visited(j) = 1;\n      }\n    }\n  });\n\n  // We can now use the visited array to count how many vertices were not marked as visited\n  int num_connected = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited(i)) {\n      num_connected++;\n    }\n  }\n\n  return num_connected;\n}",
            "int cnt = 0;\n\tKokkos::View<bool**> visited(\"visited\", N, N);\n\tKokkos::parallel_for(\n\t\tKokkos::RangePolicy<Kokkos::Reduce<Kokkos::Sum<int>, Kokkos::TagType>>(0, N),\n\t\tKOKKOS_LAMBDA(int i, int &localCnt) {\n\t\t\tif (!visited(i, i)) {\n\t\t\t\tint c = 0;\n\t\t\t\t// use a stack to traverse the graph\n\t\t\t\tstd::stack<int> stack;\n\t\t\t\tstack.push(i);\n\t\t\t\tvisited(i, i) = true;\n\t\t\t\twhile (!stack.empty()) {\n\t\t\t\t\tint v = stack.top();\n\t\t\t\t\tstack.pop();\n\t\t\t\t\tfor (int u = 0; u < N; u++) {\n\t\t\t\t\t\tif (A(v, u) &&!visited(u, u)) {\n\t\t\t\t\t\t\tvisited(u, u) = true;\n\t\t\t\t\t\t\tstack.push(u);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tlocalCnt += 1;\n\t\t\t}\n\t\t}, Kokkos::Sum<int>(cnt));\n\n\treturn cnt;\n}",
            "using namespace Kokkos;\n\ttypedef View<int**> view_type;\n\tview_type workspace( \"workspace\", N, N );\n\n\t// TODO: Copy input matrix to workspace\n\t\n\t// TODO: Loop over N and call componentCountRecursive(workspace, i, i)\n\n\t// TODO: Return the total number of components\n\n\treturn 0;\n}",
            "// Your code goes here\n\treturn 0;\n}",
            "int* counts = new int[N];\n  for(int i = 0; i < N; i++) {\n    counts[i] = -1;\n  }\n  int numComponents = 0;\n  Kokkos::parallel_for(\"countComponents\", \n    Kokkos::RangePolicy<Kokkos::ExecPolicy>(0, N), \n    KOKKOS_LAMBDA (const int& i) {\n    if(counts[i] == -1) {\n      int count = 0;\n      Kokkos::parallel_for(\"countComponents\", \n        Kokkos::RangePolicy<Kokkos::ExecPolicy>(0, N), \n        KOKKOS_LAMBDA (const int& j) {\n        if(A(i, j) == 1 && counts[j] == -1) {\n          counts[j] = i;\n          count++;\n        }\n        });\n      if(count == 0) {\n        numComponents++;\n      }\n    }\n    });\n  Kokkos::deep_copy(counts, counts);\n  for(int i = 0; i < N; i++) {\n    if(counts[i]!= -1) {\n      int root = i;\n      while(counts[root]!= root) {\n        root = counts[root];\n      }\n      counts[root] = -1;\n      counts[i] = root;\n    }\n  }\n  for(int i = 0; i < N; i++) {\n    if(counts[i]!= -1) {\n      counts[i] = 0;\n    }\n  }\n  for(int i = 0; i < N; i++) {\n    if(counts[i]!= -1) {\n      numComponents++;\n    }\n  }\n  delete[] counts;\n  return numComponents;\n}",
            "// TODO: Replace this with your code\n\t// The for loop uses a parallel_for, which takes a functor (or lambda) as a parameter.\n\t// The functor can take 3 parameters: the index i, the \"tag\" to tell the functor which\n\t// thread to run on, and an execution space to run on.\n\t// In this case, we don't need the \"tag\" or the execution space, so you can write\n\t//\n\t// [=] (int i) {\n\t//     // code here\n\t// }\n\t//\n\t// or\n\t//\n\t// [&] (int i) {\n\t//     // code here\n\t// }\n\t//\n\t// The \"tag\" tells Kokkos which thread to run on, and is an optimization. See Kokkos documentation\n\t// for more information.\n\n\t// TODO: Fill in this loop\n\n  int numComponents = 0;\n\n  Kokkos::View<int*> connectedComps(\"Connected Components\", N);\n\n  Kokkos::parallel_for(N, [&] (int i) {\n    int isConnected = 0;\n    for (int j = 0; j < N; ++j) {\n      if (A(i,j) == 1 && i!= j) {\n        if (connectedComps(i) == 0) {\n          connectedComps(i) = j+1;\n          isConnected = 1;\n        } else if (connectedComps(i)!= j+1) {\n          connectedComps(i) = connectedComps(j);\n        }\n      }\n    }\n    if (isConnected == 0 && connectedComps(i) == 0) {\n      connectedComps(i) = i+1;\n      ++numComponents;\n    }\n  });\n\n  Kokkos::fence();\n\n  return numComponents;\n}",
            "// TODO: compute the number of connected components in the graph defined by A\n\n  int numComponents = 0;\n  return numComponents;\n}",
            "Kokkos::View<int*> component(\"component\", N);\n\tKokkos::View<int*> component_count(\"component_count\", N);\n\n\t// Create a lambda function that will operate on a single component\n\tKOKKOS_INLINE_FUNCTION\n\tvoid component_op(int& component, int& component_count, int i, Kokkos::View<const int**> &A) {\n\t\tint v = i;\n\t\t// find the root of the connected component containing v\n\t\twhile (component[v]!= 0)\n\t\t\tv = component[v];\n\n\t\t// Merge the connected component containing v with the connected component containing w\n\t\tint w = i;\n\t\twhile (component[w]!= 0) {\n\t\t\tcomponent[w] = v;\n\t\t\tcomponent_count[v] += 1;\n\t\t\tw = component[w];\n\t\t}\n\t}\n\n\t// Create a parallel_for loop that operates on each node\n\tKokkos::parallel_for(\"component_count\", N, KOKKOS_LAMBDA(int i) {\n\t\tcomponent_op(component, component_count, i, A);\n\t});\n\n\t// Sum the counts\n\tint components = Kokkos::parallel_reduce(\"sum_count\", N, KOKKOS_LAMBDA(int i, int& sum) {\n\t\t\tsum += component_count[i];\n\t\t\treturn sum;\n\t}, 0);\n\n\treturn components;\n}",
            "// TODO: Your code goes here\n  return 0;\n}",
            "// Declare and initialize your componentCount variable to 0.\n  int componentCount = 0;\n\n  // You should use Kokkos::parallel_for and a lambda here.\n\n  // Your code should fill the componentCount variable with the number of connected\n  // components in the graph.\n  // Hint: Use a 1D array with size N, instead of 2D array with size NxN.\n\n  // Your code should be parallel.\n  // Hint: Use a lambda function.\n\n  // Don't forget to wait for the Kokkos computations to finish.\n  // Hint: Kokkos::fence();\n\n  return componentCount;\n}",
            "Kokkos::View<int*> visited(\"visited\", N);\n  Kokkos::View<int*> components(\"components\", N);\n  auto num_connected_components = Kokkos::subview(components, Kokkos::ALL());\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    [=] (const int i) {\n      if (visited[i] == 0) {\n        visited[i] = 1;\n        int count = 0;\n        auto dfs = [&](const int index) {\n          count++;\n          visited[index] = 1;\n          for (int j = 0; j < N; j++) {\n            if (visited[j] == 0 && A[index][j] == 1) {\n              dfs(j);\n            }\n          }\n        };\n        dfs(i);\n        num_connected_components[i] = count;\n      }\n  });\n  Kokkos::fence();\n\n  int total_count = 0;\n  for (size_t i = 0; i < N; i++) {\n    total_count += num_connected_components[i];\n  }\n\n  return total_count;\n}",
            "// Allocate and initialize Kokkos arrays.\n  // A_host and A_device will be filled with the same data.\n  Kokkos::View<int**> A_host(\"A_host\", N, N);\n  Kokkos::View<int**> A_device(\"A_device\", N, N);\n  Kokkos::deep_copy(A_host, A);\n\n  // Copy data to GPU.\n  Kokkos::deep_copy(A_device, A_host);\n\n  // Create a Kokkos View for the number of components.\n  Kokkos::View<int*> n_components(\"n_components\", 1);\n\n  // Run the kernel on the GPU.\n  // The number of components will be written to n_components[0].\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n      [=](const int idx) {\n        if (A_device(idx, 0) == 0) {\n          return;\n        }\n        int current_component = 0;\n        for (int i = 1; i < N; i++) {\n          if (A_device(idx, i) == 1) {\n            A_device(i, 0) = current_component;\n            A_device(idx, i) = 0;\n          }\n        }\n        current_component++;\n        n_components[0] = current_component;\n      },\n      Kokkos::Cuda(A_device.label()));\n\n  // Copy data from GPU back to host.\n  Kokkos::deep_copy(A_host, A_device);\n\n  // Return the number of components in A_host.\n  return n_components[0];\n}",
            "// TODO\n  // You will need to use Kokkos::parallel_for to do the actual computation.\n  // To keep track of whether a node has been visited or not, you will need\n  // a Kokkos::View<bool*, Kokkos::LayoutLeft, Kokkos::HostSpace>\n  // Use Kokkos::HostSpace to store the results on the host.\n  // Remember to use Kokkos::deep_copy to transfer the results to the host.\n  // You may want to use Kokkos::LayoutLeft to make the array of booleans\n  // contiguous in memory.\n}",
            "typedef Kokkos::DefaultHostExecutionSpace ExecutionSpace;\n\ttypedef Kokkos::DefaultExecutionSpace HostExecutionSpace;\n\ttypedef Kokkos::View<int**, HostExecutionSpace> HostView;\n\tHostView hostA(\"A\", N, N);\n\tKokkos::deep_copy(hostA, A);\n\tint n_comp = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tbool visited[N];\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tvisited[j] = false;\n\t\t}\n\t\tdfs(hostA, N, i, visited);\n\t\tn_comp++;\n\t}\n\treturn n_comp;\n}",
            "// Replace this code with your solution\n\treturn -1;\n}",
            "Kokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::deep_copy(visited, false);\n\tint numVisited = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// mark i as visited\n\t\tvisited(i) = true;\n\n\t\t// count the number of neighbors that have been visited\n\t\tnumVisited++;\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A(i, j)!= 0 && visited(j) == false) {\n\t\t\t\tnumVisited--;\n\t\t\t}\n\t\t}\n\t}\n\treturn numVisited;\n}",
            "int num_components = 0;\n\n\t// your code here\n\treturn num_components;\n}",
            "// TODO: Implement me\n    return 0;\n}",
            "// Kokkos::parallel_for\n  // Kokkos::View\n\n  return 0;\n}",
            "Kokkos::View<int*> component_id(\"component_id\", N);\n    int max_component_id = 0;\n\n    // TODO: Implement component count using Kokkos.\n\n    return max_component_id;\n}",
            "Kokkos::View<int*> comp(\"Component\", N);\n\n\t// Initialize components to 0\n\tKokkos::parallel_for(\"Init\", N, KOKKOS_LAMBDA(const int i) {\n\t\tcomp(i) = 0;\n\t});\n\tKokkos::fence();\n\n\t// Assign components based on connectedness\n\tKokkos::parallel_for(\"Assign\", N, KOKKOS_LAMBDA(const int i) {\n\t\tif (comp(i) == 0) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i,j)!= 0) {\n\t\t\t\t\tcomp(j) = comp(i) + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\t// Sum up the number of unique components\n\tsize_t numComponents = 0;\n\tKokkos::parallel_reduce(\"Count\", N, KOKKOS_LAMBDA(const int i, int& sum) {\n\t\tsum += comp(i);\n\t}, numComponents);\n\tKokkos::fence();\n\n\treturn numComponents;\n}",
            "// Your code here\n\treturn -1;\n}",
            "int num_connected_components = 0;\n\n  // Kokkos::View<int*> componentCounts(\"Component counts\", N);\n  // Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n  //   componentCounts(i) = 0;\n  // });\n\n  // Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n  //   for (int j = 0; j < N; ++j) {\n  //     if (A(i, j) == 1) {\n  //       Kokkos::atomic_fetch_add(&componentCounts(i), 1);\n  //       Kokkos::atomic_fetch_add(&componentCounts(j), 1);\n  //     }\n  //   }\n  // });\n\n  // Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int &num_components) {\n  //   if (componentCounts(i) > 0) {\n  //     ++num_components;\n  //   }\n  // }, num_connected_components);\n\n  //",
            "// Your code here!\n\n  return 0;\n}",
            "Kokkos::View<int*> componentIds(\"componentId\", N);\n\n\tKokkos::parallel_for(\"componentCount\", N,\n\t\t[=](const int i) {\n\t\tcomponentIds(i) = i;\n\t});\n\n\tint maxCompId = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i,j) > 0) {\n\t\t\t\t// Union: If they are in different components,\n\t\t\t\t// change the component id of the smaller one\n\t\t\t\t// to be the component id of the larger one\n\t\t\t\tif (componentIds(i)!= componentIds(j)) {\n\t\t\t\t\tif (componentIds(i) > componentIds(j)) {\n\t\t\t\t\t\tcomponentIds(j) = componentIds(i);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcomponentIds(i) = componentIds(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tKokkos::deep_copy(maxCompId, Kokkos::Max<int>(componentIds));\n\n\treturn maxCompId + 1;\n}",
            "/* Your code here */\n\n\treturn 0;\n}",
            "// Create a Kokkos view for the result\n  Kokkos::View<int*> componentCount(\"componentCount\", N);\n  // Fill it with the value 0\n  Kokkos::deep_copy(componentCount, 0);\n\n  // Create a parallel lambda that runs on the default execution space and\n  // fills in componentCount\n  Kokkos::parallel_for(\n    \"Fill componentCount\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(int i) {\n\n      // Initialize componentCount[i] with the value 0\n      componentCount[i] = 0;\n\n      // For each row of A\n      for (int j = 0; j < N; j++) {\n\n        // If A(i,j) is 1, then we have found a neighbor of i\n        if (A(i,j) == 1) {\n\n          // We have found a neighbor of i that is already in a component\n          if (componentCount[j]!= 0) {\n\n            // Set the component of i to the same as j\n            componentCount[i] = componentCount[j];\n            break;\n          }\n        }\n      }\n\n      // If i has not been assigned to a component, then assign it to a new component\n      if (componentCount[i] == 0) {\n        componentCount[i] = N;\n      }\n    }\n  );\n\n  // Create a host-side copy of the result view\n  Kokkos::HostSpace::host_mirror_type::view_type componentCount_h(componentCount);\n  Kokkos::deep_copy(componentCount_h, componentCount);\n\n  // Count the number of components in the host-side copy\n  int cCount = 0;\n  for (int i = 0; i < N; i++) {\n    if (componentCount_h(i) > cCount) {\n      cCount = componentCount_h(i);\n    }\n  }\n\n  return cCount;\n}",
            "// TODO: Replace this with your implementation.\n  // You should be using Kokkos parallelism and\n  // atomic operations to perform this computation.\n\n  // This is a good place to start:\n  // http://kokkos.github.io/md_doc_kokkos-tutorials-introduction-to-kokkos-part-1.html\n\n  // 1) Use Kokkos parallel_for to fill this array:\n  //    component[i] = the id of the component that node i is in.\n  //    Initialize the array to the node id.\n  // 2) Use Kokkos parallel_for to compute the size of each component.\n  //    You will need an atomic update to do this.\n  //    component_size[component[i]] += 1\n  // 3) Use Kokkos parallel_reduce to count the number of unique components.\n  //    AtomicIncrement\n\n  Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::HostSpace> component(\"component\", N);\n\n  Kokkos::parallel_for(\"Init\", 0, N, KOKKOS_LAMBDA(const int i) {\n    component[i] = i;\n  });\n\n  // Compute the component of each node.\n  Kokkos::parallel_for(\"Components\", 0, N, KOKKOS_LAMBDA(const int i) {\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        if (component[j] < component[i]) {\n          component[i] = component[j];\n        }\n      }\n    }\n  });\n\n  // Compute the component size.\n  Kokkos::View<int*, Kokkos::LayoutStride, Kokkos::HostSpace> component_size(\"component_size\", N);\n  Kokkos::parallel_for(\"ComponentSize\", 0, N, KOKKOS_LAMBDA(const int i) {\n    int id = component[i];\n    Kokkos::atomic_increment(&component_size[id]);\n  });\n\n  int count = 0;\n  Kokkos::parallel_reduce(\"Count\", 0, N, KOKKOS_LAMBDA(const int i, int &count) {\n    int id = component[i];\n    if (component_size[id] > 0) {\n      count++;\n    }\n  }, Kokkos::Sum<int>(count));\n\n  return count;\n}",
            "// TODO: Implement me\n\n  return -1;\n}",
            "Kokkos::View<int*> componentNumber(\"ComponentNumber\", N);\n\n\t// Create a Kokkos parallel_for loop\n\tKokkos::parallel_for(\n\t\tN, KOKKOS_LAMBDA(int i) {\n\t\t\t// Each element is initially a separate component\n\t\t\tcomponentNumber(i) = i;\n\t\t}\n\t);\n\n\t// Create a Kokkos parallel_for loop\n\tKokkos::parallel_for(\n\t\tN, KOKKOS_LAMBDA(int i) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t// If i and j are in the same component, continue\n\t\t\t\tif (componentNumber(i) == componentNumber(j)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// If i and j are not in the same component,\n\t\t\t\t// and j is adjacent to i, put them in the same component\n\t\t\t\tif (A(i, j)) {\n\t\t\t\t\tcomponentNumber(j) = componentNumber(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\t// Kokkos is finished, return to host memory\n\tint* componentNumber_host = new int[N];\n\tKokkos::deep_copy(componentNumber_host, componentNumber);\n\n\t// Find the number of unique values in componentNumber\n\tstd::vector<int> componentNumbers(N);\n\tstd::vector<int> componentCounts(N);\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponentNumbers[i] = componentNumber_host[i];\n\t\tcomponentCounts[i] = 1;\n\t}\n\tstd::sort(componentNumbers.begin(), componentNumbers.end());\n\tauto it = std::unique(componentNumbers.begin(), componentNumbers.end());\n\tint uniqueComponents = std::distance(componentNumbers.begin(), it);\n\n\t// For each unique component, count the number of elements\n\tint componentCount = 0;\n\tfor (int i = 0; i < uniqueComponents; i++) {\n\t\tint count = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (componentNumbers[i] == componentNumber_host[j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tcomponentCounts[i] = count;\n\t}\n\n\t// Return the number of connected components\n\tint count = 0;\n\tfor (int i = 0; i < uniqueComponents; i++) {\n\t\tcount += componentCounts[i];\n\t}\n\treturn count;\n}",
            "Kokkos::View<int*> counts(\"counts\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    counts(i) = 0;\n  });\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1 && i!= j) {\n        counts(i) += counts(j);\n      }\n    }\n  });\n  Kokkos::View<int*> max = Kokkos::View<int*>(\"max\", 1);\n  Kokkos::parallel_reduce(1, KOKKOS_LAMBDA(int, max_) {\n    for (int i = 0; i < N; ++i) {\n      if (counts(i) > max_)\n        max_ = counts(i);\n    }\n  }, Kokkos::Max<int>(max));\n  return max[0];\n}",
            "Kokkos::View<int**> isVisited(\"isVisited\", N, N);\n  Kokkos::parallel_for(\n  \tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n  \tKOKKOS_LAMBDA(size_t i) {\n      Kokkos::parallel_for(\n    \t  Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n    \t  KOKKOS_LAMBDA(size_t j) {\n            isVisited(i, j) = 0;\n    \t  }\n      );\n  \t}\n  );\n  Kokkos::View<int*> count(\"count\", N);\n  Kokkos::parallel_for(\n  \tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n  \tKOKKOS_LAMBDA(size_t i) {\n  \t  count(i) = 0;\n  \t}\n  );\n  Kokkos::parallel_for(\n    Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n  \tKOKKOS_LAMBDA(size_t i) {\n  \t  Kokkos::parallel_for(\n    \t  Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n    \t  KOKKOS_LAMBDA(size_t j) {\n            if (A(i, j) == 1) {\n              count(i) = 1;\n            }\n    \t  }\n      );\n  \t}\n  );\n  Kokkos::parallel_for(\n  \tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n  \tKOKKOS_LAMBDA(size_t i) {\n      Kokkos::parallel_for(\n    \t  Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n    \t  KOKKOS_LAMBDA(size_t j) {\n            isVisited(i, j) = count(i);\n    \t  }\n      );\n  \t}\n  );\n  int result = 0;\n  Kokkos::parallel_reduce(\n  \tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n  \tKOKKOS_LAMBDA(size_t i, int &lsum) {\n  \t  Kokkos::parallel_reduce(\n    \t  Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic, Kokkos::Dynamic>>((size_t)0, N),\n    \t  KOKKOS_LAMBDA(size_t j, int &lsum) {\n            if (A(i, j) == 1 && isVisited(i, j)!= isVisited(j, i)) {\n              isVisited(i, j) = isVisited(j, i);\n              lsum += 1;\n            }\n    \t  }, lsum\n      );\n  \t}, result\n  );\n  return result;\n}",
            "// You can either use a Kokkos::View to store the number of connected components,\n\t// or you can use the local_exec space (which is the default execution space for Kokkos)\n\t// to store the number of connected components.\n\n\t// TODO\n\treturn 0;\n}",
            "// Your code goes here.\n}",
            "// create array of component ids for each node\n\tKokkos::View<int*> component(\"Component\", N);\n\n\t// create a flag array for determining if a node has already been visited\n\tKokkos::View<bool*> visited(\"Visited\", N);\n\n\t// initialize the arrays to 0\n\tKokkos::deep_copy(visited, false);\n\tKokkos::deep_copy(component, 0);\n\n\t// parallel loop\n\t// Kokkos::parallel_for takes a lambda function, which is defined and executed within the for loop\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int i) {\n\n\t\t// if the node is already visited, stop\n\t\tif (visited(i)) return;\n\n\t\t// set the component id of the current node to i, and set the flag to true\n\t\tcomponent(i) = i;\n\t\tvisited(i) = true;\n\n\t\t// loop through all neighbors of the current node\n\t\tfor (int j = 0; j < N; j++) {\n\n\t\t\t// if the current node is not connected to this neighbor, move on to the next neighbor\n\t\t\tif (A(i, j) == 0) continue;\n\n\t\t\t// if the neighbor has not been visited, recursively call the function\n\t\t\tif (!visited(j)) {\n\t\t\t\tcomponentCount(A, N);\n\t\t\t} else {\n\t\t\t\t// if the neighbor is already visited, set the component id of the neighbor to the id of the current node\n\t\t\t\t// this is done so that all nodes in the same component have the same component id\n\t\t\t\tif (component(j)!= component(i)) component(j) = component(i);\n\t\t\t}\n\t\t}\n\t});\n\n\t// count the number of unique component ids\n\t// for this, we create a set that stores the component ids, and count the number of elements in the set\n\tstd::set<int> s;\n\tfor (int i = 0; i < N; i++) s.insert(component(i));\n\n\treturn s.size();\n}",
            "// Declare and define our view: a set of integers of size N.\n    // Initialized to 0.\n    Kokkos::View<int*> visited(\"visited\", N);\n    Kokkos::deep_copy(visited, 0);\n\n    int num_components = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(visited(i) == 0) {\n            num_components++;\n            componentCount_helper(A, visited, i, N);\n        }\n    }\n\n    return num_components;\n}",
            "// TODO: Implement me\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> componentMap(\"componentMap\", N);\n\tint component = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tcomponent++;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponentMap(i) = component;\n\t}\n\n\treturn component;\n}",
            "Kokkos::View<int*, Kokkos::HostSpace> isCc(\"isCc\", N);\n  int numCcs = 0;\n  Kokkos::parallel_for(\"count_components\", Kokkos::RangePolicy<Kokkos::HostSpace>(0, N), [&] (int i) {\n    int myCc = -1;\n    if(isCc(i) < 0) {\n      // unvisited vertex, find its connected component\n      myCc = i;\n      for(int j = 0; j < N; ++j) {\n        if(isCc(j) < 0 && A(i,j) > 0) {\n          isCc(j) = myCc;\n        }\n      }\n    }\n    numCcs += (myCc >= 0);\n  });\n  return numCcs;\n}",
            "/* The return value. */\n  int num_components = 0;\n\n  /* Kokkos: parallel_reduce will execute the loop body \"body\" on all elements in A.\n   *\n   * It's a reduce function, so for each element in A, the function \"body\" is\n   * executed and the result of the computation is combined with a value called\n   * \"value\" at each step.\n   */\n  Kokkos::parallel_reduce(\"componentCount\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA (const int& i, int& value) {\n\t\t\t   int num_connected = 0;\n\t\t\t   /* TODO: check if vertex i is connected to any vertices other than itself.\n\t\t\t   * If it is, then increment num_connected by one.\n\t\t\t   * Hint: you'll need a for loop here.\n\t\t\t   * Hint 2: You can use the Kokkos::atomic_fetch_add function to increment num_connected\n\t\t\t   * atomically (meaning that multiple threads can increment num_connected without race\n\t\t\t   * conditions).\n\t\t\t   */\n\t\t\t\t for (int j=0;j<N;j++) {\n\t\t\t\t\t if (i!=j && A(i,j)>0)\n\t\t\t\t\t\t Kokkos::atomic_fetch_add(&num_connected, 1);\n\t\t\t\t }\n\t\t\t   if (num_connected!=0)\n\t\t\t\t   Kokkos::atomic_fetch_add(&value, 1);\n\t\t\t   },\n\t\t\t   num_components);\n\n  return num_components;\n}",
            "// TODO: Replace the body of this function with your own implementation\n\treturn 0;\n}",
            "Kokkos::View<bool**> visited(\"visited\", N, N);\n  Kokkos::View<int**> compIdx(\"compIdx\", N, N);\n  Kokkos::View<int*> numComp(\"numComp\", 1);\n\n  Kokkos::deep_copy(visited, false);\n  Kokkos::deep_copy(compIdx, -1);\n  Kokkos::deep_copy(numComp, 0);\n\n  // Use a reduction to count the number of connected components\n  // Assume that the first column in the adjacency matrix is the source vertex\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int i, int& compCount) {\n    if (visited(i, 0) == false) {\n      compCount++;\n      compCount += componentCount(i, 0, visited, compIdx, numComp, A);\n    }\n  }, Kokkos::Sum<int>(numComp(0)));\n\n  return numComp(0);\n}",
            "int numComps = 0;\n\tKokkos::View<int*> visited(\"visited\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int i) {\n\t\tif (visited[i] == 0) {\n\t\t\tnumComps++;\n\t\t\tKokkos::parallel_for(N, KOKKOS_LAMBDA(int j) {\n\t\t\t\tif (A(i,j) == 1 && visited[j] == 0) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n\tKokkos::fence();\n\treturn numComps;\n}",
            "int numComponents = 0;\n\n  // TODO: Initialize numComponents to the number of nodes in the graph\n\n\tfor (size_t i = 0; i < N; ++i) {\n    // TODO: If node i is not visited, explore its connected component\n    // TODO: Use a Kokkos::View to store the nodes of the component\n    // TODO: Set node i's value in the adjacency matrix to 0\n    // TODO: Increment the number of components\n\t}\n\n  return numComponents;\n}",
            "// TODO: implement\n\n\t// count the connected components\n\tKokkos::View<int*> comps(\"comps\", N);\n\tauto compLabel = Kokkos::subview(comps, Kokkos::ALL);\n\tKokkos::parallel_for( \"component_labeling\", N, KOKKOS_LAMBDA (const int i) {\n\t\tauto Arow = Kokkos::subview(A, i, Kokkos::ALL);\n\t\tcompLabel[i] = i;\n\t\t// Find the root\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (Arow[j] > 0) {\n\t\t\t\tcompLabel[i] = j;\n\t\t\t}\n\t\t}\n\t\tKokkos::single(Kokkos::PerThread(i), [&]() {\n\t\t\t// Merge\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (i == j)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (Arow[j] > 0) {\n\t\t\t\t\tcompLabel[j] = compLabel[i];\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t});\n\t// Kokkos::single(Kokkos::PerThread(0), [&]() {\n\t// \tfor (int i = 0; i < N; ++i) {\n\t// \t\tKokkos::printf(\"node %d, label %d\\n\", i, compLabel[i]);\n\t// \t}\n\t// });\n\t// Count the number of unique labels\n\tKokkos::View<int*> numComps(\"num_comps\", 1);\n\tauto numComp = Kokkos::subview(numComps, 0);\n\tnumComp(0) = 0;\n\tKokkos::parallel_for( \"component_counter\", N, KOKKOS_LAMBDA (const int i) {\n\t\tauto compLabel = Kokkos::subview(comps, i);\n\t\tint tmp = 0;\n\t\tKokkos::single(Kokkos::PerThread(i), [&]() {\n\t\t\ttmp = compLabel[0];\n\t\t});\n\t\tKokkos::parallel_reduce( \"component_counter\", N, KOKKOS_LAMBDA (const int j, int &tmp) {\n\t\t\tauto compLabel = Kokkos::subview(comps, j);\n\t\t\tif (compLabel[0] == tmp)\n\t\t\t\ttmp++;\n\t\t}, numComp);\n\t});\n\tKokkos::fence();\n\treturn numComp(0);\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "omp",
        "prompt": "#include <omp.h>\n\n/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n\t Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tstd::cout << \"Thread \" << omp_get_thread_num() << \": \" << \"i = \" << i << std::endl;\n\t}\n\n\treturn 0;\n}",
            "int i, j, count = 0;\n\n\t#pragma omp parallel for private(j)\n  for (i = 0; i < N; i++)\n    for (j = i; j < N; j++)\n      if (i!= j && A[i*N + j])\n        count++;\n\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n\n  // Initialize the visited array\n  for (int i = 0; i < N; i++) {\n    if (A[i * N + i] == 1) {\n      visited[i] = 1;\n    }\n  }\n\n  // Traverse the matrix to check for connected components\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      if (A[i * N + i] == 1) {\n        count++;\n        visited[i] = 1;\n      }\n\n      // Traverse the row, and column for a connected component\n      #pragma omp parallel for\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 && visited[j] == 0) {\n          visited[j] = 1;\n        }\n        if (A[j * N + i] == 1 && visited[j] == 0) {\n          visited[j] = 1;\n        }\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\tstd::vector<bool> isVisited(N, false);\n\n\t#pragma omp parallel for shared(count)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!isVisited[i]) {\n\t\t\tDFS(A, isVisited, i, count);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "//TODO\n}",
            "/*\n\t  Your code here! You can use the following methods:\n\n      size_t numThreads = omp_get_num_threads(); // Get number of threads\n      size_t threadId = omp_get_thread_num(); // Get the ID of the current thread\n      size_t maxThreads = omp_get_max_threads(); // Get max number of threads\n\n      omp_set_num_threads(N); // Set number of threads to N\n      omp_set_nested(true); // Allow nested parallelism\n\n\t*/\n\n    return 0;\n}",
            "// Implement this function!\n\n\t\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n\n    #pragma omp parallel for schedule(dynamic) reduction(+:count)\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        dfs(i, A, visited);\n        count++;\n    }\n\n    return count;\n}",
            "// TODO: Your code here\n    std::vector<int> v(N);\n    std::vector<bool> visited(N);\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            int curr = i;\n            int count = 0;\n            while (!visited[curr]) {\n                visited[curr] = true;\n                v[curr] = i;\n                curr = v[curr];\n                count++;\n            }\n            v[curr] = i;\n        }\n    }\n\n    int num_components = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (v[i] == i) num_components++;\n    }\n\n    return num_components;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<int> componentCounts(N, 0);\n\n\t// Your code here!\n\n\treturn 0;\n}",
            "int cnt = 0;\n\tstd::vector<int> c(N, -1);\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tif (c[i] >= 0)\n\t\t{\n\t\t\tcontinue;\n\t\t}\n\t\tcnt++;\n\t\tfor (int j = i + 1; j < N; ++j)\n\t\t{\n\t\t\tif (A[i*N + j] == 1 && c[j] == -1)\n\t\t\t{\n\t\t\t\tc[j] = cnt;\n\t\t\t}\n\t\t}\n\t}\n\treturn cnt;\n}",
            "// TODO: Implement this function in parallel\n\t// Note: OpenMP will handle the thread creation\n\t// You do not need to worry about the number of threads\n\n\treturn 0;\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for (size_t v = 0; v < N; v++) {\n    if (!visited[v]) {\n      dfs(A, v, visited);\n      count++;\n    }\n  }\n  return count;\n}",
            "int component_count = 0;\n\n  //#pragma omp parallel for reduction(+: component_count) // Doesn't compile\n  for (int i = 0; i < N; ++i) {\n    std::vector<int> visited(N);\n\n    if (visited[i] == 1)\n      continue;\n\n    ++component_count;\n\n    std::queue<int> Q;\n    Q.push(i);\n\n    while (!Q.empty()) {\n      int v = Q.front();\n      Q.pop();\n\n      if (visited[v] == 1)\n        continue;\n\n      visited[v] = 1;\n\n      for (int u = 0; u < N; ++u) {\n        if (A[u * N + v] == 1 && visited[u] == 0) {\n          Q.push(u);\n        }\n      }\n    }\n  }\n\n  return component_count;\n}",
            "int count = 0;\n\n    std::vector<int> flags(N, 0);\n    std::vector<int> stack(N, 0);\n\n    int top = -1;\n\n    for (int i = 0; i < N; i++) {\n        if (flags[i] == 0) {\n            count++;\n            stack[++top] = i;\n            flags[i] = 1;\n            while (top!= -1) {\n                int vertex = stack[top--];\n                for (int j = 0; j < N; j++) {\n                    if (A[vertex * N + j] == 1 && flags[j] == 0) {\n                        flags[j] = 1;\n                        stack[++top] = j;\n                    }\n                }\n            }\n        }\n    }\n    return count;\n}",
            "int num_components = 0;\n\tstd::vector<int> component(N, -1);\n\n\t#pragma omp parallel for private(num_components, component)\n\tfor (int node = 0; node < N; node++) {\n\t\tif (component[node] == -1) {\n\t\t\tnum_components++;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(node);\n\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint current_node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tcomponent[current_node] = num_components;\n\t\t\t\tfor (int neighbor = 0; neighbor < N; neighbor++) {\n\t\t\t\t\tif (A[node*N + neighbor] == 1 && component[neighbor] == -1) {\n\t\t\t\t\t\tq.push(neighbor);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn num_components;\n}",
            "std::vector<int> visited(N);\n\tint count = 0;\n\t#pragma omp parallel for schedule(dynamic) reduction(+:count)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  int components = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      int count = 0;\n      std::queue<int> q;\n      q.push(i);\n      visited[i] = true;\n      while (!q.empty()) {\n        int idx = q.front();\n        q.pop();\n        for (size_t j = 0; j < N; ++j) {\n          if (!visited[j] && A[idx * N + j]) {\n            q.push(j);\n            visited[j] = true;\n            count++;\n          }\n        }\n      }\n      components++;\n    }\n  }\n  return components;\n}",
            "int total = 0;\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tstd::vector<int> temp;\n\t\t\tDFS(A, i, visited, temp);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n\n}",
            "std::vector<int> component(N);\n\n#pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    component[i] = i;\n  }\n\n  for(int i = 0; i < N; i++) {\n    for(int j = 0; j < N; j++) {\n      if(A[i * N + j] == 1) {\n\tint root_i = 0;\n\tint root_j = 0;\n\tfor(int k = 0; k < N; k++) {\n\t  if(component[k] == i) {\n\t    root_i = k;\n\t  }\n\t  if(component[k] == j) {\n\t    root_j = k;\n\t  }\n\t}\n\n\tif(root_i!= root_j) {\n\t  component[root_j] = root_i;\n\t}\n      }\n    }\n  }\n\n  int count = 0;\n  for(int i = 0; i < N; i++) {\n    for(int j = 0; j < N; j++) {\n      if(component[i] == component[j]) {\n\tcount++;\n      }\n    }\n  }\n\n  return count;\n}",
            "const int num_threads = omp_get_max_threads();\n\t#pragma omp parallel for num_threads(num_threads)\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A[i*N + j] == 0) {\n\t\t\t\tA[j*N + i] = 1;\n\t\t\t} else {\n\t\t\t\tA[j*N + i] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Compute connected components\n\tint num_components = 0;\n\tstd::vector<bool> visited(N);\n\n\t#pragma omp parallel for num_threads(num_threads)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tnum_components++;\n\t\t\t// Depth-first search\n\t\t\tstd::stack<int> S;\n\t\t\tS.push(i);\n\t\t\twhile (!S.empty()) {\n\t\t\t\tint current = S.top();\n\t\t\t\tS.pop();\n\t\t\t\tif (!visited[current]) {\n\t\t\t\t\tvisited[current] = true;\n\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\tif (!visited[j] && A[current*N + j] == 1) {\n\t\t\t\t\t\t\tS.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn num_components;\n}",
            "int* is_visited = new int[N];\n\tint* component_count = new int[N];\n\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tis_visited[i] = 0;\n\t\tcomponent_count[i] = 0;\n\t}\n\n\tint cc_count = 0;\n\n\t// Use OpenMP to parallelize the following code:\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!is_visited[i])\n\t\t{\n\t\t\tcc_count++;\n\n\t\t\t// Mark all the nodes in the connected component as visited\n\t\t\t// The following for loop is implemented to avoid creating any\n\t\t\t// dependency between the iteration.\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\n\t\t\twhile (!q.empty())\n\t\t\t{\n\t\t\t\tint v = q.front();\n\t\t\t\tq.pop();\n\n\t\t\t\tif (!is_visited[v])\n\t\t\t\t{\n\t\t\t\t\tis_visited[v] = 1;\n\n\t\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (A[v * N + j] &&!is_visited[j])\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] is_visited;\n\tdelete[] component_count;\n\treturn cc_count;\n}",
            "int numComponents = 0;\n\tint *visited = new int[N];\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\tnumComponents += 1;\n\t\t\tvisited[i] = 1;\n\t\t\tint next = i;\n\t\t\twhile (next < N && visited[next] == 0) {\n\t\t\t\tvisited[next] = 1;\n\t\t\t\tif (A[i*N + next] == 1) {\n\t\t\t\t\t#pragma omp critical\n\t\t\t\t\tnumComponents += 1;\n\t\t\t\t}\n\t\t\t\tnext++;\n\t\t\t}\n\t\t}\n\t}\n\tdelete[] visited;\n\treturn numComponents;\n}",
            "#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j]!= 0) {\n        A[i*N + j] = A[j*N + i] = 1;\n      }\n    }\n  }\n\n  int count = 0;\n\n  #pragma omp parallel for reduction(+:count)\n  for (size_t i = 0; i < N; ++i) {\n    int v = 0;\n    for (size_t j = 0; j < N; ++j) {\n      v += A[i*N + j];\n    }\n    if (v == 0) {\n      count += 1;\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n  std::vector<bool> visited(N);\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      dfs(A, i, visited);\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    if (A[i*N + i] == 1) {\n      #pragma omp critical\n      count++;\n    }\n  }\n\n  return count;\n}",
            "int components = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (A[i * N + i] == 1) {\n      components++;\n    }\n  }\n  return components;\n}",
            "int count = 0;\n\n    // TODO: Your code goes here\n\n    return count;\n}",
            "int result = 0;\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < N; i++)\n    {\n        std::vector<int> current_array;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                current_array.push_back(j);\n            }\n        }\n        for (int k = 0; k < current_array.size(); k++) {\n            for (int l = 0; l < current_array.size(); l++) {\n                if (l!= k && A[current_array[k] * N + current_array[l]] == 1) {\n                    int current_index = current_array[k];\n                    current_array.erase(current_array.begin() + k);\n                    A[current_index * N + current_array[l]] = 1;\n                    k = -1;\n                    break;\n                }\n            }\n        }\n\n        result += current_array.size();\n    }\n    return result;\n}",
            "// TODO: Fill this in.\n  return 0;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\t\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\t\n\t\tcount++;\n\t\tint index = i;\n\t\t\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[index * N + j] &&!visited[j]) {\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn count;\n}",
            "#pragma omp parallel\n  {\n    #pragma omp for\n    for (int i = 0; i < N; i++)\n      for (int j = i + 1; j < N; j++)\n        A[i] += A[j];\n\n    #pragma omp single\n    {\n      for (int i = 0; i < N; i++)\n        A[i] /= 2;\n    }\n  }\n  return 0;\n}",
            "int* visited = new int[N];\n\tfor(int i=0; i<N; ++i) {\n\t\tvisited[i] = 0;\n\t}\n\tint count = 0;\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif(!visited[i]) {\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif(!visited[j] && A[i*N+j]) {\n\t\t\t\t\t#pragma omp critical\n\t\t\t\t\t{\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tdelete [] visited;\n\treturn count;\n}",
            "int count = 0;\n\tint num = 0;\n\tstd::vector<bool> flag(N, false);\n#pragma omp parallel for shared(num)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!flag[i]) {\n\t\t\tflag[i] = true;\n\t\t\tnum++;\n\t\t\tdfs(A, i, &flag);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    #pragma omp parallel for num_threads(2) reduction(+:count)\n    for (int i = 0; i < N; ++i) {\n        count += countComponent(A, i, N);\n    }\n    return count;\n}",
            "int size = 1;\n\tint visited[N];\n\tint count = 0;\n\tint cnt = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[i] = 0;\n\t\t}\n\t}\n\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tsize = 1;\n\t\t\tdfs(i, A, visited, size, count);\n\t\t\tcnt++;\n\t\t}\n\t}\n\treturn cnt;\n\n}",
            "int count = 0;\n\n  // TODO: Replace me!\n  return 0;\n}",
            "std::vector<int> connected(N);\n\tstd::fill(connected.begin(), connected.end(), 0);\n\tint count = 0;\n\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[N*i + j]) {\n\t\t\t\tconnected[i] = 1;\n\t\t\t\tconnected[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (connected[i] == 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> vis(N, 0); // whether each node has been visited\n  std::vector<int> comp(N, 0); // each node is in which component\n  std::vector<int> color(N, 0); // color to distinguish components\n\n  auto componentHelper = [&](int node) {\n    vis[node] = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[node*N + j] == 1 &&!vis[j]) {\n        componentHelper(j);\n        comp[node] = comp[j];\n      }\n    }\n    comp[node] = 1;\n  };\n\n  for (int i = 0; i < N; i++) {\n    if (!vis[i]) {\n      componentHelper(i);\n      color[i] = 1;\n    }\n  }\n\n  int cnt = 0;\n  for (auto a : color) {\n    if (a == 1) {\n      cnt++;\n    }\n  }\n\n  return cnt;\n}",
            "// TODO: YOUR CODE HERE\n  std::vector<int> marked(N);\n\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!marked[i]) {\n      ++count;\n      dfs(A, i, marked);\n    }\n  }\n\n  return count;\n}",
            "if(N <= 1) return N;\n  std::vector<bool> visited(N, false);\n  std::vector<int> connected(N, 1);\n  for(size_t i=0; i<N; i++){\n    if(!visited[i]){\n      std::queue<size_t> queue;\n      queue.push(i);\n      while(!queue.empty()){\n        size_t curr = queue.front();\n        visited[curr] = true;\n        for(size_t j=0; j<N; j++){\n          if(A[curr*N + j] &&!visited[j]){\n            connected[j] = connected[i];\n            queue.push(j);\n          }\n        }\n        queue.pop();\n      }\n    }\n  }\n  int total = 0;\n  for(int c : connected) if(c) total++;\n  return total;\n}",
            "std::vector<bool> marked(N, false);\n    int count = 0;\n\n    #pragma omp parallel for default(shared) reduction(+: count)\n    for (int i = 0; i < N; i++) {\n        if (!marked[i]) {\n            std::queue<int> q;\n            q.push(i);\n            while (!q.empty()) {\n                auto v = q.front();\n                q.pop();\n                if (marked[v]) {\n                    continue;\n                }\n                marked[v] = true;\n                for (int w = 0; w < N; w++) {\n                    if (A[v*N + w] == 1) {\n                        q.push(w);\n                    }\n                }\n            }\n            count++;\n        }\n    }\n\n    return count;\n}",
            "int compsize = 0;\n\n\tstd::vector<int> visited(N, 0);\n\n\t// Iterate over every column of A.\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tcompsize += 1;\n\t\t\t}\n\n\t\t\tstd::vector<int> queue{i};\n\t\t\twhile (!queue.empty()) {\n\t\t\t\tint node = queue.back();\n\t\t\t\tqueue.pop_back();\n\n\t\t\t\tvisited[node] = 1;\n\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[N*node + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn compsize;\n}",
            "std::vector<int> component(N);\n\tint count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(component[i] == 0) {\n\t\t\tcomponent[i] = count++;\n\t\t\tint v = i;\n\t\t\t#pragma omp parallel for\n\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\tif(A[v * N + j] == 1) {\n\t\t\t\t\tcomponent[j] = component[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "#pragma omp parallel for\n\tfor(size_t k = 0; k < N; k++) {\n\t\tfor(size_t i = 0; i < N; i++) {\n\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] && A[j * N + k])\n\t\t\t\t\tA[i * N + k] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif (A[i * N + i]) {\n\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\tA[i * N + j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// TODO\n  std::vector<int> B(N);\n  int res = 0;\n\n  #pragma omp parallel for num_threads(4)\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        B[i] = j;\n        break;\n      }\n    }\n  }\n\n  for (int i = 0; i < N; ++i) {\n    if (B[i]!= i) {\n      continue;\n    }\n    ++res;\n    for (int j = i + 1; j < N; ++j) {\n      if (B[j] == i) {\n        B[j] = i;\n      }\n    }\n  }\n\n  return res;\n}",
            "int count = 0;\n\t// Fill this in.\n\treturn count;\n}",
            "#pragma omp parallel for\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A[i*N + j] == 0){\n\t\t\t\tA[i*N + j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tint count = 0;\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(A[i*N + j] == 0){\n\t\t\t\tcount++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n  #pragma omp parallel for reduction(+: count)\n  for (int i = 0; i < N; i++) {\n    // your code here\n  }\n  return count;\n}",
            "// Write your code here\n}",
            "int num_threads = omp_get_max_threads();\n  std::vector<int> labels(N);\n  for (int i = 0; i < N; ++i) {\n    labels[i] = i;\n  }\n\n  #pragma omp parallel for num_threads(num_threads) schedule(dynamic)\n  for (int i = 0; i < N; ++i) {\n    int id = i;\n    for (int j = 0; j < N; ++j) {\n      if (i!= j && A[i * N + j] && labels[i]!= labels[j]) {\n        if (labels[i] < labels[j]) {\n          labels[j] = labels[i];\n        } else {\n          labels[i] = labels[j];\n        }\n      }\n    }\n  }\n\n  int count = 0;\n  for (int i = 0; i < N; ++i) {\n    int cur = labels[i];\n    for (int j = i+1; j < N; ++j) {\n      if (labels[j] == cur) {\n        count++;\n        break;\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n#pragma omp parallel for num_threads(4)\n\tfor (int i = 0; i < N; i++) {\n\t\t// count all vertices in the current connected component\n\t\tif (A[i*N + i] == 0) {\n\t\t\t// no path to itself\n\t\t\tcontinue;\n\t\t}\n\t\t// start with the current vertex\n\t\tstd::vector<int> vertices{ i };\n\t\tcount++;\n\t\twhile (!vertices.empty()) {\n\t\t\t// pick the first vertex\n\t\t\tconst int x = vertices.back();\n\t\t\tvertices.pop_back();\n\t\t\t// check all vertices\n\t\t\tfor (int y = 0; y < N; y++) {\n\t\t\t\tif (A[x*N + y]!= 0 && A[y*N + x]!= 0) {\n\t\t\t\t\t// found a connection between vertices\n\t\t\t\t\tif (std::find(vertices.begin(), vertices.end(), y) == vertices.end()) {\n\t\t\t\t\t\tvertices.push_back(y);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int *flag = new int[N];\n\n    for (size_t i = 0; i < N; i++) {\n        flag[i] = 0;\n    }\n\n    int count = 0;\n    #pragma omp parallel for schedule(dynamic, 1)\n    for (size_t i = 0; i < N; i++) {\n        if (flag[i] == 0) {\n            dfs(A, i, flag);\n            count++;\n        }\n    }\n\n    return count;\n}",
            "std::vector<bool> visited(N, false);\n  int cnt = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n\n    if (!visited[i]) {\n      #pragma omp parallel\n      {\n        #pragma omp single\n        {\n          std::cout << \"Hello from the single thread\" << std::endl;\n        }\n      }\n      // BFS\n      std::deque<size_t> queue;\n      queue.push_back(i);\n\n      while (!queue.empty()) {\n        auto const u = queue.front();\n        queue.pop_front();\n\n        visited[u] = true;\n\n        for (size_t v = 0; v < N; ++v) {\n          if (!visited[v] && A[v * N + u] > 0) {\n            visited[v] = true;\n            queue.push_back(v);\n          }\n        }\n      }\n      ++cnt;\n    }\n  }\n\n  return cnt;\n}",
            "int n_comp = 0;\n\tint n_node = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor (int i=0; i<N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tn_comp++;\n\t\t\tdfs_visit(A, i, visited);\n\t\t\tn_node += 1;\n\t\t}\n\t}\n\n\treturn n_comp;\n}",
            "int count = 0;\n#pragma omp parallel for schedule(dynamic)\n  for (size_t i = 0; i < N; ++i) {\n    if (A[i * N + i] == 1) {\n      count++;\n    }\n  }\n  return count;\n}",
            "int num_of_comp = 0;\n  int const n = N;\n  std::vector<int> state(n);\n  std::vector<int> comp_map(n);\n\n  #pragma omp parallel\n  {\n    #pragma omp for schedule(static)\n    for (int i = 0; i < n; i++) {\n      state[i] = 1;\n      comp_map[i] = 0;\n    }\n\n    #pragma omp for schedule(static)\n    for (int i = 0; i < n; i++) {\n      for (int j = 0; j < n; j++) {\n        if (A[i * n + j] == 1) {\n          state[j] = 2;\n        }\n      }\n    }\n\n    #pragma omp for schedule(static)\n    for (int i = 0; i < n; i++) {\n      if (state[i] == 1) {\n        comp_map[i] = 1;\n        num_of_comp++;\n\n        for (int j = i + 1; j < n; j++) {\n          if (A[i * n + j] == 1) {\n            comp_map[j] = 1;\n          }\n        }\n\n        for (int j = 0; j < i; j++) {\n          if (A[j * n + i] == 1) {\n            comp_map[j] = 1;\n          }\n        }\n      }\n    }\n  }\n\n  return num_of_comp;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n\n  #pragma omp parallel for shared(count, A, visited, N)\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      #pragma omp critical\n      count++;\n\n      // DFS\n      std::vector<size_t> stack;\n      stack.push_back(i);\n\n      while (stack.size() > 0) {\n        size_t idx = stack.back();\n        stack.pop_back();\n\n        if (!visited[idx]) {\n          visited[idx] = 1;\n\n          for (size_t j = 0; j < N; j++) {\n            if (A[idx * N + j] &&!visited[j]) {\n              stack.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (A[i * N + i] == 1) {\n            #pragma omp critical\n            count++;\n        }\n    }\n    return count;\n}",
            "// Your code goes here\n\n    // return your answer for the number of components\n    return 0;\n}",
            "int numComponents = 0;\n\tint visited[N];\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++numComponents;\n\t\t\tdfs(A, visited, i, i);\n\t\t}\n\t}\n\treturn numComponents;\n}",
            "int* visited = new int[N];\n\tfor (int i = 0; i < N; i++) visited[i] = 0;\n\n\tint numComponents = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\tnumComponents++;\n\t\t\tvisit(A, i, visited, N);\n\t\t}\n\t}\n\n\tdelete[] visited;\n\n\treturn numComponents;\n}",
            "int numberOfComponents = 0;\n\n\t// Do something here\n\t\n\treturn numberOfComponents;\n}",
            "std::vector<bool> visited(N);\n  int component_count = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      visited[i] = true;\n      component_count++;\n      // use a stack to keep track of nodes to explore\n      std::stack<int> stack;\n      stack.push(i);\n\n      while (!stack.empty()) {\n        int current = stack.top();\n        stack.pop();\n        // explore all unvisited neighbors\n        for (int j = 0; j < N; j++) {\n          if (A[N * current + j] == 1 &&!visited[j]) {\n            visited[j] = true;\n            stack.push(j);\n          }\n        }\n      }\n    }\n  }\n  return component_count;\n}",
            "int count = 0;\n\t#pragma omp parallel for reduction(+: count)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tstd::vector<int> visited(N, 0);\n\t\tstd::queue<int> bfs;\n\t\tbfs.push(i);\n\t\tvisited[i] = 1;\n\t\twhile (bfs.size()!= 0) {\n\t\t\tint v = bfs.front();\n\t\t\tbfs.pop();\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (visited[j] == 0 && A[v*N+j] == 1) {\n\t\t\t\t\tbfs.push(j);\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcount++;\n\t}\n\treturn count;\n}",
            "int size = 0;\n\n\t#pragma omp parallel for reduction(+: size)\n\tfor(int i=0;i<N;i++){\n\t\tif(A[i*N+i] == 1){\n\t\t\tsize++;\n\t\t}\n\t}\n\t\n\treturn size;\n}",
            "// TODO\n    std::vector<int> componentCount(N, 0);\n    int totalComponents = 0;\n    int visited = 0;\n\n#pragma omp parallel for schedule(dynamic,1)\n    for(int i = 0; i < N; ++i)\n    {\n        for(int j = 0; j < N; ++j)\n        {\n            if(A[i*N+j] == 1)\n            {\n                visited = 1;\n#pragma omp critical\n                {\n                    if(componentCount[i] == 0)\n                    {\n                        componentCount[i] = j+1;\n                        totalComponents++;\n                    }\n                    else if(componentCount[j] == 0)\n                    {\n                        componentCount[j] = i+1;\n                        totalComponents++;\n                    }\n                    else if(componentCount[i]!= componentCount[j])\n                    {\n                        componentCount[i] = componentCount[j];\n                        totalComponents--;\n                    }\n                }\n            }\n        }\n    }\n    return totalComponents;\n}",
            "int counter = 0;\n\tstd::vector<int> visited(N,0);\n\tfor (int i=0; i<N; i++) {\n\t\tif (visited[i]==0) {\n\t\t\t//omp_set_num_threads(2);\n\t\t\t//#pragma omp parallel for\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\tif (A[i*N + j]!= 0 && visited[j]==0) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcounter++;\n\t\t}\n\t}\n\treturn counter;\n}",
            "int count = 0;\n\n\tstd::vector<bool> v(N);\n\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tstd::fill(v.begin(), v.end(), 0);\n\t\tif (!v[i]) {\n\t\t\t#pragma omp critical\n\t\t\tcount++;\n\t\t\tstd::vector<int> to_check(N);\n\t\t\tstd::vector<bool> check(N);\n\n\t\t\tv[i] = true;\n\t\t\tto_check[0] = i;\n\n\t\t\tsize_t head = 0;\n\t\t\tsize_t tail = 1;\n\n\t\t\twhile (head < tail) {\n\t\t\t\tint u = to_check[head];\n\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[N*u + j] &&!check[j]) {\n\t\t\t\t\t\tcheck[j] = true;\n\t\t\t\t\t\tv[j] = true;\n\t\t\t\t\t\tto_check[tail] = j;\n\t\t\t\t\t\ttail++;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\thead++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\n  std::vector<bool> visited(N, false);\n  std::vector<int> parent(N);\n\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      dfs(A, i, parent, visited);\n      count++;\n    }\n  }\n  return count;\n}",
            "int component_count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i] == 0)\n\t\t\tcontinue;\n\t\telse {\n\t\t\tcomponent_count++;\n\t\t\tA[i] = 0;\n\t\t}\n\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i] == 1) {\n\t\t\t\tA[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn component_count;\n}",
            "// TODO: your code here\n   std::vector<int> visited(N,0);\n   int visitedCount = 0;\n   int count = 0;\n   #pragma omp parallel\n   {\n   #pragma omp for\n   for(int i=0;i<N;i++){\n      if(visited[i]==0){\n         visitedCount++;\n         #pragma omp task\n         dfs(visited,A,i,N);\n      }\n   }\n   #pragma omp single\n   {\n   count = visitedCount;\n   }\n   }\n   return count;\n}",
            "std::vector<int> components(N);\n\n  for (size_t i = 0; i < N; i++)\n  {\n\t  #pragma omp parallel for\n    for (size_t j = 0; j < N; j++)\n    {\n      if (A[i * N + j] == 1 && i < j)\n      {\n        components[i] = j;\n      }\n    }\n  }\n\n  int count = 0;\n\n  for (int i = 0; i < N; i++)\n  {\n    if (components[i] == 0)\n    {\n      count++;\n    }\n  }\n\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\t#pragma omp parallel for num_threads(4)\n\tfor(int i = 0; i < N; i++)\n\t{\n\t\tif(!visited[i])\n\t\t{\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t}\n\t\t\t#pragma omp for\n\t\t\tfor(int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif(A[N*i + j] &&!visited[j])\n\t\t\t\t{\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int num_components = 0;\n\n\t// TODO: Fill in the correct code to compute the number of connected components\n\n\treturn num_components;\n}",
            "// TODO\n  int components = 0;\n  std::vector<int> visited(N, 0);\n  #pragma omp parallel for num_threads(4)\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      #pragma omp critical\n      { components++; }\n      int j = 0;\n      while (j < N) {\n        if (A[j*N + i] == 1 &&!visited[j]) {\n          #pragma omp critical\n          { visited[j] = 1; }\n          j = 0;\n        } else {\n          j++;\n        }\n      }\n    }\n  }\n\n  return components;\n}",
            "auto visited = std::vector<bool>(N, false);\n  int c = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      c++;\n      #pragma omp parallel\n      {\n        #pragma omp single\n        {\n          // Perform DFS on node i\n          std::vector<bool> discovered(N, false);\n          std::vector<bool> processed(N, false);\n          discovered[i] = true;\n          std::vector<size_t> stack;\n          stack.push_back(i);\n          while (!stack.empty()) {\n            size_t top = stack.back();\n            stack.pop_back();\n            processed[top] = true;\n            for (size_t j = 0; j < N; j++) {\n              if (A[N*top + j] &&!processed[j] &&!discovered[j]) {\n                discovered[j] = true;\n                stack.push_back(j);\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  return c;\n}",
            "// TODO: Fill this in\n\treturn 0;\n}",
            "std::vector<int> compCount(N, 1);\n\tstd::vector<bool> visited(N, false);\n\n\tfor(int i=0; i<N; i++) {\n\t\tif(!visited[i]) {\n\t\t\tstd::vector<int> next = {i};\n\t\t\twhile(next.size()) {\n\t\t\t\tint cur = next.back();\n\t\t\t\tnext.pop_back();\n\t\t\t\tvisited[cur] = true;\n\t\t\t\tfor(int j=0; j<N; j++) {\n\t\t\t\t\tif(A[cur*N + j] &&!visited[j]) {\n\t\t\t\t\t\tnext.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint count = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(visited[i]) count++;\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n  int n_comp = 0;\n\n  #pragma omp parallel for reduction(+: n_comp)\n  for(int i = 0; i < N; ++i) {\n    // skip if visited\n    if(visited[i]) continue;\n    // perform depth-first-search\n    std::stack<int> s;\n    s.push(i);\n    visited[i] = 1;\n    while(!s.empty()) {\n      int curr = s.top();\n      s.pop();\n      for(int j = 0; j < N; ++j) {\n        if(A[curr * N + j] == 1 && visited[j] == 0) {\n          visited[j] = 1;\n          s.push(j);\n        }\n      }\n    }\n    // increase number of connected components\n    n_comp++;\n  }\n  return n_comp;\n}",
            "std::vector<int> state(N);\n\tstd::fill(state.begin(), state.end(), -1);\n\n\tint count = 0;\n\t\n\tomp_lock_t *lock = new omp_lock_t[N];\n\tfor(int i = 0; i < N; i++){\n\t\tomp_init_lock(lock[i]);\n\t}\n\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++) {\n\t\tint j = i;\n\t\tif (state[j] == -1) {\n\t\t\tstate[j] = 0;\n\t\t\tcount++;\n\t\t\twhile (state[j]!= -1) {\n\t\t\t\tint k = 0;\n\t\t\t\tfor (int l = 0; l < N; l++) {\n\t\t\t\t\tif (A[j*N + l]) {\n\t\t\t\t\t\tomp_set_lock(lock[l]);\n\t\t\t\t\t\tif (state[l] == -1) {\n\t\t\t\t\t\t\tstate[l] = 0;\n\t\t\t\t\t\t\tcount++;\n\t\t\t\t\t\t\tk = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tomp_unset_lock(lock[l]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tj = k;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor(int i = 0; i < N; i++){\n\t\tomp_destroy_lock(lock[i]);\n\t}\n\n\treturn count;\n}",
            "if (A.size()!= N*N) {\n\t\tthrow std::invalid_argument(\"Incorrect size of input\");\n\t}\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp single\n\t\t{\n\t\t\tstd::vector<int> seen(N, 0);\n\t\t\tint count = 0;\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (seen[i] == 0) {\n\t\t\t\t\tcount++;\n\t\t\t\t\tdfs(A, seen, i, N);\n\t\t\t\t}\n\t\t\t}\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tstd::cout << \"Count: \" << count << std::endl;\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO: implement this method\n}",
            "int numComponents = 0;\n    // Add your code here\n    std::vector<bool> visited(N, false);\n    for (size_t i = 0; i < N; i++)\n    {\n        if (!visited[i])\n        {\n            numComponents++;\n            std::vector<int> q{i};\n            while (q.size())\n            {\n                size_t cur = q.back();\n                q.pop_back();\n                visited[cur] = true;\n                for (size_t j = 0; j < N; j++)\n                {\n                    if (!visited[j] && A[cur * N + j])\n                    {\n                        q.push_back(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return numComponents;\n}",
            "int numThreads = omp_get_num_procs();\n    omp_set_num_threads(numThreads);\n    int numConnected = 0;\n\n#pragma omp parallel for reduction(+: numConnected)\n    for (int i = 0; i < N; i++) {\n        int cnt = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1)\n                cnt++;\n        }\n        if (cnt == N-1) {\n            numConnected++;\n        }\n    }\n    return numConnected;\n}",
            "int count = 0;\n\n    #pragma omp parallel for default(shared) schedule(dynamic) reduction(+:count)\n    for (int i = 0; i < N; ++i) {\n        std::vector<int> visited(N, 0);\n        if (visited[i] == 0) {\n            count++;\n            std::stack<int> S;\n            S.push(i);\n            visited[i] = 1;\n\n            while (S.empty() == false) {\n                int v = S.top();\n                S.pop();\n\n                for (int w = 0; w < N; ++w) {\n                    if (A[v * N + w] == 1 && visited[w] == 0) {\n                        S.push(w);\n                        visited[w] = 1;\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "int components = 0;\n    #pragma omp parallel for reduction(+: components)\n    for(size_t i = 0; i < N; ++i) {\n        bool visited[N] = {false};\n        std::queue<int> q;\n        visited[i] = true;\n        q.push(i);\n\n        while(!q.empty()) {\n            int v = q.front();\n            q.pop();\n            for(int u = 0; u < N; ++u) {\n                if(!visited[u] && A[N*v + u]) {\n                    visited[u] = true;\n                    q.push(u);\n                }\n            }\n        }\n        components++;\n    }\n    return components;\n}",
            "int components = 0;\n  #pragma omp parallel for reduction(+:components)\n  for (size_t i = 0; i < N; i++) {\n    if (!A[i*N + i]) {\n      // unvisited node\n      // start a new component\n      int current_node = i;\n      int current_component = 1;\n      A[i*N + i] = 1; // mark node as visited\n      // go through all adjacent nodes and add to component\n      for (size_t j = 0; j < N; j++) {\n        if (A[i*N + j] && j!= i) {\n          current_node = j;\n          current_component++;\n          A[i*N + j] = 1; // mark node as visited\n        }\n      }\n      // if any nodes are still unvisited\n      for (size_t j = 0; j < N; j++) {\n        if (!A[i*N + j] && j!= i) {\n          current_node = j;\n          current_component++;\n          A[i*N + j] = 1; // mark node as visited\n        }\n      }\n      components += current_component;\n    }\n  }\n  return components;\n}",
            "int componentCount = 0;\n    std::vector<bool> visited(N, false);\n\n    // Write your code here\n\n    return componentCount;\n}",
            "// TODO: Your code here\n  int* visited = new int[N];\n  for (int i = 0; i < N; i++) {\n    visited[i] = -1;\n  }\n  std::vector<int> componentCount = std::vector<int>(N, 0);\n\n  for (int i = 0; i < N; i++) {\n    #pragma omp parallel for\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] && visited[i]!= j) {\n        visited[i] = j;\n        componentCount[i] = 1;\n        break;\n      } else if (A[i * N + j]) {\n        componentCount[i] = 0;\n      }\n    }\n  }\n\n  int counter = 0;\n  for (int i = 0; i < N; i++) {\n    counter += componentCount[i];\n  }\n  return counter;\n}",
            "int count = 0;\n    std::vector<int> visited(N);\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        #pragma omp critical\n        if (visited[i] == 0) {\n            DFS(i, A, N, visited);\n            count++;\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n\n\tstd::vector<bool> visited(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\n\t\t\tstd::vector<size_t> todo = { i };\n\n\t\t\twhile (!todo.empty()) {\n\t\t\t\tsize_t cur = todo.back();\n\t\t\t\ttodo.pop_back();\n\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[cur * N + j] &&!visited[j]) {\n\t\t\t\t\t\ttodo.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tvisited[cur] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tint visited[N][N];\n\n#pragma omp parallel for num_threads(16) reduction(+:count)\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\tif(A[i * N + j] == 1 && visited[i][j] == 0) {\n\t\t\t\tvisited[i][j] = 1;\n\t\t\t\tint x = i;\n\t\t\t\tint y = j;\n\n\t\t\t\twhile(x >= 0 && y >= 0 && x < N && y < N && A[x * N + y] == 1 && visited[x][y] == 0) {\n\t\t\t\t\tvisited[x][y] = 1;\n\t\t\t\t\tx++;\n\t\t\t\t\ty++;\n\t\t\t\t}\n\t\t\t\tx = i;\n\t\t\t\ty = j;\n\t\t\t\twhile(x >= 0 && y < N && x < N && y >= 0 && A[x * N + y] == 1 && visited[x][y] == 0) {\n\t\t\t\t\tvisited[x][y] = 1;\n\t\t\t\t\tx++;\n\t\t\t\t\ty--;\n\t\t\t\t}\n\t\t\t\tx = i;\n\t\t\t\ty = j;\n\t\t\t\twhile(x < N && y >= 0 && x >= 0 && y < N && A[x * N + y] == 1 && visited[x][y] == 0) {\n\t\t\t\t\tvisited[x][y] = 1;\n\t\t\t\t\tx--;\n\t\t\t\t\ty++;\n\t\t\t\t}\n\t\t\t\tx = i;\n\t\t\t\ty = j;\n\t\t\t\twhile(x < N && y < N && x >= 0 && y >= 0 && A[x * N + y] == 1 && visited[x][y] == 0) {\n\t\t\t\t\tvisited[x][y] = 1;\n\t\t\t\t\tx--;\n\t\t\t\t\ty--;\n\t\t\t\t}\n\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int numComponents = 0;\n    std::vector<int> visited(N, 0);\n    int visitedCounter = 0;\n    //std::vector<int> nextVisited;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            numComponents++;\n            #pragma omp critical\n            {\n                visitedCounter++;\n            }\n            #pragma omp single\n            {\n                std::cout << visitedCounter << std::endl;\n            }\n            //nextVisited.push_back(i);\n            DFS(A, visited, i);\n        }\n    }\n    //std::cout << \"visitedCounter: \" << visitedCounter << std::endl;\n    return numComponents;\n}",
            "std::vector<int> connected;\n  std::vector<int> visited;\n  int count = 0;\n  #pragma omp parallel num_threads(4)\n  {\n    #pragma omp for\n    for (size_t i = 0; i < N; i++) {\n      if (!visited[i]) {\n        visited[i] = 1;\n        connected[i] = i;\n      }\n      for (size_t j = i + 1; j < N; j++) {\n        if (A[i * N + j] == 1 && visited[j]!= 1) {\n          visited[j] = 1;\n          connected[j] = i;\n        }\n      }\n    }\n    #pragma omp for\n    for (size_t i = 0; i < N; i++) {\n      if (connected[i]!= i) {\n        connected[i] = connected[connected[i]];\n      }\n    }\n    #pragma omp for\n    for (size_t i = 0; i < N; i++) {\n      if (connected[i] == i) {\n        count++;\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\n  #pragma omp parallel for reduction(+:count)\n  for (int i = 0; i < N; i++) {\n    // count = 0;\n    std::vector<bool> seen(N, false);\n    std::stack<int> s;\n    s.push(i);\n    seen[i] = true;\n    count++;\n\n    while(!s.empty()) {\n      int v = s.top();\n      s.pop();\n      for (int j = 0; j < N; j++) {\n        if (!seen[j] && A[v * N + j]) {\n          seen[j] = true;\n          s.push(j);\n          count++;\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "#pragma omp parallel for\n  for (int i = 0; i < N; i++){\n\tfor (int j = i+1; j < N; j++){\n\t  if (A[i*N+j] == 1){\n\t\t  A[i*N+j] = 0;\n\t\t  A[j*N+i] = 0;\n\t\t  for (int k = 0; k < N; k++){\n\t\t\tif (A[i*N+k] == 1 && A[j*N+k] == 0){\n\t\t\t  A[j*N+k] = 1;\n\t\t\t  A[k*N+j] = 1;\n\t\t\t}\n\t\t\telse if (A[j*N+k] == 1 && A[i*N+k] == 0){\n\t\t\t  A[i*N+k] = 1;\n\t\t\t  A[k*N+i] = 1;\n\t\t\t}\n\t\t  }\n\t  }\n\t}\n  }\n  \n  int count = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++){\n\tint current = 0;\n\tfor (int j = 0; j < N; j++){\n\t  if (A[i*N+j] == 1)\n\t\tcurrent = 1;\n\t}\n\tif (current == 1)\n\t  count++;\n  }\n  \n  return count;\n}",
            "const int INF = 2147483647;\n\n\tstd::vector<int> dist(N, INF);\n\tint count = 0;\n\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(dist[i] == INF) {\n\t\t\tcount++;\n\t\t\tdist[i] = 0;\n\t\t\tstd::vector<int> stack;\n\t\t\tstack.push_back(i);\n\n\t\t\twhile(!stack.empty()) {\n\t\t\t\tint n = stack.back();\n\t\t\t\tstack.pop_back();\n\n\t\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\t\tif(A[N*n+j] == 1 && dist[j] == INF) {\n\t\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\t\tdist[j] = dist[n]+1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// count all connected components\n    std::vector<bool> visited(N, false);\n    int count = 0;\n\n    for(size_t i = 0; i < N; ++i) {\n        // if already visited, skip\n        if(visited[i]) {\n            continue;\n        }\n\n        // mark as visited, increment count, and search\n        visited[i] = true;\n        count++;\n        dfs(A, i, N, visited);\n    }\n    return count;\n}",
            "int num_of_comps = 0;\n\n    #pragma omp parallel\n    {\n        std::vector<bool> visited(N, false);\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; ++i) {\n            if (!visited[i]) {\n                int num_of_current_comp = 0;\n                std::queue<int> q;\n                q.push(i);\n                while (!q.empty()) {\n                    int v = q.front();\n                    q.pop();\n                    if (visited[v]) continue;\n                    num_of_current_comp++;\n                    visited[v] = true;\n                    for (int j = 0; j < N; ++j) {\n                        if (A[v * N + j] == 1 &&!visited[j]) {\n                            q.push(j);\n                        }\n                    }\n                }\n                #pragma omp critical\n                {\n                    num_of_comps += num_of_current_comp;\n                }\n            }\n        }\n    }\n\n    return num_of_comps;\n}",
            "int num_components = 0;\n\tstd::vector<int> visited(N, 0); // Initialized with 0s\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tnum_components++;\n\t\t\t}\n\t\t\tDFS(i, A, N, visited);\n\t\t}\n\t}\n\n\treturn num_components;\n}",
            "// TODO: Your code here.\n  return 0;\n}",
            "// TODO: complete this function\n}",
            "const int NTHREADS = 4;\n\t#pragma omp parallel num_threads(NTHREADS)\n\t{\n\t\t#pragma omp for schedule(static)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\t// TODO: Implement this function. You may use any mutexes or synchronization\n\t\t\t// primitives, though you should not use std::mutex or std::unique_lock\n\t\t\t// directly.\n\t\t\t// To use mutexes, you must declare them as private\n\t\t\t// variables in this scope.\n\t\t}\n\t}\n}",
            "int c = 0;\n\n  #pragma omp parallel for reduction(+: c)\n  for (int i = 0; i < N; ++i) {\n    bool visited[N] = {false};\n    std::stack<int> s;\n    s.push(i);\n    visited[i] = true;\n\n    while (!s.empty()) {\n      int u = s.top();\n      s.pop();\n      for (int v = 0; v < N; ++v) {\n        if (A[u * N + v] &&!visited[v]) {\n          s.push(v);\n          visited[v] = true;\n        }\n      }\n    }\n\n    c++;\n  }\n\n  return c;\n}",
            "int count = 0;\n\tstd::vector<bool> seen(N, false);\n\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (seen[i])\n\t\t\tcontinue;\n\t\tseen[i] = true;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tseen[j] = true;\n\t\t}\n\t\tcount++;\n\t}\n\treturn count;\n}",
            "int n = N;\n  int m = N*N;\n  int c = 0;\n  std::vector<int> p(n, 0);\n  std::vector<int> q(n, 0);\n  int p_count = 0;\n  int q_count = 0;\n\n  #pragma omp parallel for schedule(dynamic, 1)\n  for (int i = 0; i < m; i++) {\n    int i1 = i / N;\n    int i2 = i % N;\n    if (A[i] == 1) {\n      #pragma omp critical\n      {\n        p[p_count] = i1;\n        q[q_count] = i2;\n        p_count++;\n        q_count++;\n        if (p_count == n) {\n          p_count = 0;\n          q_count = 0;\n        }\n      }\n      if (i2 < N - 1) {\n        #pragma omp atomic\n        c++;\n      }\n    }\n  }\n  return c;\n}",
            "// your code here\n    int count = 0;\n    std::vector<int> isVisited(N);\n    for(int i = 0; i < N; i++) {\n        isVisited[i] = 0;\n    }\n    #pragma omp parallel for\n    for(int i = 0; i < N; i++) {\n        #pragma omp parallel for\n        for(int j = 0; j < N; j++) {\n            if(A[i*N+j] == 1 && isVisited[i] == 0) {\n                isVisited[i] = 1;\n            }\n            if(A[i*N+j] == 1 && isVisited[j] == 0) {\n                isVisited[j] = 1;\n            }\n        }\n    }\n    for(int i = 0; i < N; i++) {\n        if(isVisited[i] == 1) {\n            count++;\n        }\n    }\n    return count;\n}",
            "size_t count = 0;\n  std::vector<bool> visited(N);\n\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      visited[i] = true;\n#pragma omp parallel for\n      for (size_t j = 0; j < N; j++) {\n        if (A[i*N+j] &&!visited[j]) {\n          visited[j] = true;\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "std::vector<bool> visited(N);\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) {\n            continue;\n        }\n        ++count;\n        std::stack<size_t> s;\n        s.push(i);\n        visited[i] = true;\n\n        while (!s.empty()) {\n            size_t top = s.top();\n            s.pop();\n\n            for (size_t j = 0; j < N; ++j) {\n                if (!visited[j] && A[top * N + j] == 1) {\n                    s.push(j);\n                    visited[j] = true;\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "int components = 0;\n\tfor (size_t node = 0; node < N; ++node) {\n\t\tif (A[node] > 0) {\n\t\t\tcomponents++;\n\t\t\t// TODO: Implement DFS to count connected components here\n\t\t}\n\t}\n\treturn components;\n}",
            "// TODO: fill in your code here\n\n\treturn 0;\n}",
            "int count=0;\n\tint i;\n\tint j;\n\n#pragma omp parallel private(i, j)\n\t{\n\n\t\t// for each iteration, one thread computes one component\n#pragma omp for\n\t\tfor (i=0; i<N; i++) {\n\t\t\tfor (j=0; j<N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\n\t\t\t\t\t// mark all nodes with value 1 as visited\n\t\t\t\t\tA[i * N + j] = 2;\n\t\t\t\t\tcount++;\n\n\t\t\t\t\t// traverse all nodes connected to node i\n\t\t\t\t\t// mark as visited\n\t\t\t\t\twhile (j < N) {\n\t\t\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t\t\tA[i * N + j] = 2;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tj++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// TODO: Use OpenMP to count the number of components in the graph defined by A\n\t//       using an efficient algorithm.\n\tint count = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t// check if i is not visited\n\t\t\tif (A[i*N + i] == 0) {\n\t\t\t\t// search for component\n\t\t\t\tint j = i;\n\t\t\t\tbool found = false;\n\t\t\t\twhile (!found) {\n\t\t\t\t\t// check if j is not visited\n\t\t\t\t\tif (A[j*N + j] == 0) {\n\t\t\t\t\t\t// search for next vertex in component\n\t\t\t\t\t\tint k = j;\n\t\t\t\t\t\tfound = true;\n\t\t\t\t\t\twhile (A[k*N + k]!= 0) {\n\t\t\t\t\t\t\tif (A[k*N + k] == 0) {\n\t\t\t\t\t\t\t\tfound = false;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse if (k < N - 1) {\n\t\t\t\t\t\t\t\tk++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tfound = false;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// color component with 0s and 1s\n\t\t\t\t\t\tif (found) {\n\t\t\t\t\t\t\tfor (int k = 0; k < k - j + 1; k++) {\n\t\t\t\t\t\t\t\tA[j*N + k + j] = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tj++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tj++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t#pragma omp critical\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, visited, i, count);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// Make a vector of visited elements\n\tstd::vector<int> visited(N);\n\t// Mark all elements as not visited\n\tfor (size_t i = 0; i < N; ++i)\n\t\tvisited[i] = 0;\n\t// Mark a random element as visited\n\tvisited[0] = 1;\n\n\t// Count the connected components\n\tint components = 0;\n\n#pragma omp parallel shared(N, A, visited)\n\t{\n\t\tint myComponents = 0;\n#pragma omp for\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\t// If it is not visited, visit it and count it\n\t\t\tif (visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tmyComponents++;\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[i * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#pragma omp critical\n\t\tcomponents += myComponents;\n\t}\n\treturn components;\n}",
            "// YOUR CODE HERE\n\treturn 0;\n}",
            "std::vector<int> vis(N, 0);\n  int count = 0;\n#pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    if (vis[i] == 0) {\n      ++count;\n      // Do a DFS from i\n      std::stack<int> stack;\n      stack.push(i);\n      while (!stack.empty()) {\n        int cur = stack.top();\n        stack.pop();\n        if (vis[cur] == 0) {\n          vis[cur] = 1;\n          for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]!= 0 && vis[j] == 0) {\n              stack.push(j);\n            }\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "// TODO: Implement using OpenMP\n  int count = 0;\n  int* visited = new int[N];\n  for (int i = 0; i < N; i++)\n    visited[i] = 0;\n  #pragma omp parallel for schedule(dynamic, 1)\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      #pragma omp critical\n      count++;\n      #pragma omp parallel for schedule(dynamic, 1)\n      for (int j = 0; j < N; j++)\n        if (A[i*N+j] == 1 && visited[j] == 0)\n          visited[j] = 1;\n    }\n  }\n  delete[] visited;\n  return count;\n}",
            "// TODO: Your code here\n    std::vector<int> visited(N, 0);\n    int count = 0;\n\n#pragma omp parallel for shared(visited) default(none)\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n#pragma omp critical\n            count++;\n            dfs(A, N, i, visited);\n        }\n    }\n\n    return count;\n}",
            "int components = 0;\n\tstd::vector<bool> visited(N, false);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++components;\n\t\t\tstd::vector<bool> stack(N, false);\n\t\t\tstack[i] = true;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (stack[j]) {\n\t\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\t\tif (A[j*N + k] == 1 &&!visited[k]) {\n\t\t\t\t\t\t\tstack[k] = true;\n\t\t\t\t\t\t\tvisited[k] = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn components;\n}",
            "int num_cc = 0;\n    std::vector<int> visited(N, 0);\n    for (int i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            dfs_helper(A, visited, i, N);\n            num_cc += 1;\n        }\n    }\n    return num_cc;\n}",
            "int count = 0;\n\n  #pragma omp parallel for\n  for(size_t i=0; i<N; i++)\n  {\n    if(A[i*N+i])\n    {\n      #pragma omp critical\n      count++;\n    }\n  }\n\n  return count;\n}",
            "int total = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tstd::vector<bool> visited(N);\n\t\tstd::vector<bool> inComponent(N);\n\t\tdfs(A, N, i, i, visited, inComponent);\n\t\tint count = std::accumulate(inComponent.begin(), inComponent.end(), 0);\n\t\t#pragma omp atomic\n\t\ttotal += count;\n\t}\n\treturn total;\n}",
            "int count = 0;\n\tstd::vector<int> visited(N);\n\tstd::vector<int> temp(N);\n\tstd::fill(visited.begin(), visited.end(), 0);\n\tstd::fill(temp.begin(), temp.end(), 0);\n\tint t;\n#pragma omp parallel for private(t)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\ttemp[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (temp[k] == 1) {\n\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int ncomps = 0;\n\n\t// Initialize component labels\n\tstd::vector<int> label(N);\n\tstd::iota(label.begin(), label.end(), 0);\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i!= j && A[i * N + j]) {\n\t\t\t\t\tif (label[i]!= label[j]) {\n\t\t\t\t\t\t#pragma omp critical\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif (label[i]!= label[j]) {\n\t\t\t\t\t\t\t\tint l = label[i];\n\t\t\t\t\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\t\t\t\t\tif (label[k] == label[j]) {\n\t\t\t\t\t\t\t\t\t\tlabel[k] = l;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t++ncomps;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn ncomps;\n}",
            "int componentCount = 0;\n    std::vector<bool> visited(N);\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (not visited[i]) {\n            std::vector<int> q;\n            q.push_back(i);\n            while (not q.empty()) {\n                int cur = q.back();\n                q.pop_back();\n                visited[cur] = true;\n                for (int j = 0; j < N; j++) {\n                    if (A[cur * N + j] and not visited[j]) {\n                        q.push_back(j);\n                    }\n                }\n            }\n            componentCount++;\n        }\n    }\n    return componentCount;\n}",
            "int *A_ptr = A.data();\n\n  int *components = new int[N];\n  int *isvisited = new int[N];\n  for (int i = 0; i < N; i++) {\n    components[i] = 0;\n    isvisited[i] = 0;\n  }\n  int current = 1;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int comp_num = 0;\n    if (isvisited[i] == 0 && A_ptr[i * N + i] == 1) {\n      components[i] = current;\n      isvisited[i] = 1;\n      comp_num = current;\n      for (int j = 0; j < N; j++) {\n        if (A_ptr[i * N + j] == 1) {\n          #pragma omp critical\n          {\n            components[j] = comp_num;\n            isvisited[j] = 1;\n          }\n        }\n      }\n      current++;\n    }\n  }\n\n  std::set<int> comp_set;\n  int comp_cnt = 0;\n  for (int i = 0; i < N; i++) {\n    comp_set.insert(components[i]);\n  }\n\n  comp_cnt = comp_set.size();\n\n  return comp_cnt;\n}",
            "int numComponents = 0;\n    // Your code goes here\n    return numComponents;\n}",
            "// TODO\n}",
            "int connected_components = 0;\n\tstd::vector<int> visited(N, 0);\n\t#pragma omp parallel for reduction(+ : connected_components)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 1) continue;\n\t\tbool component_found = false;\n\t\tstd::vector<int> stack({i});\n\t\twhile (stack.size() > 0) {\n\t\t\tint index = stack.back();\n\t\t\tstack.pop_back();\n\t\t\tif (visited[index] == 1) continue;\n\t\t\tvisited[index] = 1;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[index * N + j] == 1) {\n\t\t\t\t\tstack.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomponent_found = true;\n\t\t}\n\t\tif (component_found) {\n\t\t\tconnected_components++;\n\t\t}\n\t}\n\treturn connected_components;\n}",
            "auto A_matrix = reinterpret_cast<int*>(A.data());\n  // TODO: replace this code with something that counts the number of connected components.\n  // You may want to use a parallel loop here.\n  return 0;\n}",
            "auto visited = std::vector<int>(N, 0);\n  auto count = 0;\n\n#pragma omp parallel\n  {\n    auto local_count = 0;\n#pragma omp for reduction(+ : local_count)\n    for (auto i = 0u; i < N; ++i) {\n      if (!visited[i]) {\n        local_count++;\n        std::queue<int> q;\n        q.push(i);\n        while (!q.empty()) {\n          auto v = q.front();\n          q.pop();\n          for (auto j = 0u; j < N; ++j) {\n            if (A[N * v + j]) {\n              if (!visited[j]) {\n                q.push(j);\n                visited[j] = 1;\n              }\n            }\n          }\n        }\n      }\n    }\n#pragma omp critical\n    count += local_count;\n  }\n  return count;\n}",
            "int totalComponents = 0;\n\n    #pragma omp parallel for reduction(+:totalComponents)\n    for (int i = 0; i < N; i++) {\n        // TODO: implement algorithm here\n        totalComponents += 1;\n    }\n\n    return totalComponents;\n}",
            "auto isConnected = [&A](int i, int j) {\n        return i >= 0 && i < N && j >= 0 && j < N && A[i*N + j];\n    };\n\n    auto isReachable = [&A](int i, int j) {\n        return i == j || isConnected(i, j) || isConnected(j, i);\n    };\n\n    auto reach = [&isReachable](std::vector<int>& visited, int i, int j) {\n        for (int k = 0; k < N; k++) {\n            if (!visited[k] && isReachable(i, k) && isReachable(j, k)) {\n                visited[k] = 1;\n                reach(visited, i, k);\n                reach(visited, j, k);\n            }\n        }\n    };\n\n    std::vector<int> visited(N);\n    int components = 0;\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            visited[i] = 1;\n            reach(visited, i, i);\n            components++;\n        }\n    }\n\n    return components;\n}",
            "int numComponents = 0;\n  #pragma omp parallel for num_threads(omp_get_num_procs()) schedule(static)\n  for (size_t i = 0; i < N; ++i) {\n    bool alreadyProcessed = false;\n    // TODO: Check if this vertex is connected to any already processed vertices\n    // If so, ignore it and move on.\n    if(false)\n      continue;\n    // TODO: Process this vertex and any vertices that are connected to it.\n    // You may wish to use std::stack for this.\n\n    // TODO: Increment the component counter by 1.\n\n  }\n  return numComponents;\n}",
            "int *componentCountArray = (int*)malloc(sizeof(int)*N);\n\tbool *visited = (bool*)calloc(N, sizeof(bool));\n\t\n\tint components = 0;\n\t\n\t#pragma omp parallel for shared(componentCountArray,visited)\n\tfor (int i = 0; i < N; i++) {\n\t\t\n\t\tif(!visited[i]) {\n\t\t\t\n\t\t\tint count = 0;\n\t\t\t\n\t\t\tstd::stack<int> stack;\n\t\t\tstack.push(i);\n\t\t\t\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tint current = stack.top();\n\t\t\t\tstack.pop();\n\t\t\t\t\n\t\t\t\tif (!visited[current]) {\n\t\t\t\t\tvisited[current] = true;\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (!visited[j] && A[current * N + j] == 1) {\n\t\t\t\t\t\tstack.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tcomponentCountArray[i] = count;\n\t\t\t\tcomponents++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn components;\n}",
            "// TODO: Your code here\n}",
            "/* TODO: Fill in */\n    return -1;\n}",
            "int num_component = 0;\n\tstd::vector<int> component(N, 0);\n\tstd::vector<int> stack(N, 0);\n\n\t#pragma omp parallel for schedule(dynamic, 1)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component[i])\n\t\t\tcontinue;\n\t\tcomponent[i] = 1;\n\t\tint stack_top = 0;\n\t\tstack[stack_top++] = i;\n\t\twhile (stack_top) {\n\t\t\tint j = stack[--stack_top];\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (!component[k] && A[j * N + k]) {\n\t\t\t\t\tcomponent[k] = 1;\n\t\t\t\t\tstack[stack_top++] = k;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (component[i])\n\t\t\tnum_component++;\n\t}\n\treturn num_component;\n}",
            "int count = 0;\n    #pragma omp parallel for\n    for(int i=0;i<N;i++)\n        for(int j=0;j<N;j++)\n            if(A[i*N+j]==1)\n                count++;\n    return count;\n}",
            "std::vector<bool> visited(N, false);\n  int components = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n\n    #pragma omp critical\n    components += 1;\n\n    std::queue<int> queue;\n    queue.push(i);\n    while (!queue.empty()) {\n      auto current = queue.front();\n      queue.pop();\n\n      for (size_t j = 0; j < N; ++j) {\n        if (A[i * N + j] == 1 &&!visited[j]) {\n          visited[j] = true;\n          queue.push(j);\n        }\n      }\n    }\n  }\n  return components;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\t\n\t#pragma omp parallel for\n\tfor(size_t i = 0; i < N; i++){\n\t\tif(visited[i] == false){\n\t\t\tcount++;\n\t\t\tDFS(i, A, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\n    #pragma omp parallel for schedule(static)\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            std::vector<int> stack;\n            stack.push_back(i);\n            visited[i] = 1;\n            while (stack.size() > 0) {\n                int v = stack.back();\n                stack.pop_back();\n                for (int j = 0; j < N; j++) {\n                    if (!visited[j] && A[v * N + j] == 1) {\n                        stack.push_back(j);\n                        visited[j] = 1;\n                    }\n                }\n            }\n        }\n    }\n\n    int count = 0;\n    for (auto v : visited) {\n        if (v == 1) count++;\n    }\n\n    return count;\n}",
            "int num_comp = 0;\n\tomp_lock_t *locks = new omp_lock_t[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tomp_init_lock(&locks[i]);\n\t}\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tstd::vector<int> marked(N, 0);\n\t\tomp_set_lock(&locks[i]);\n\t\tmarked[i] = 1;\n\t\tif (!marked[i]) {\n\t\t\tdfs(A, i, marked);\n\t\t\tnum_comp++;\n\t\t}\n\t\tomp_unset_lock(&locks[i]);\n\t}\n\treturn num_comp;\n}",
            "std::vector<bool> isVisited(N, false);\n  int count = 0;\n\n  #pragma omp parallel for schedule(dynamic, 1)\n  for (int i = 0; i < N; i++) {\n    if (!isVisited[i]) {\n      #pragma omp critical\n      count++;\n      DFS(A, N, isVisited, i);\n    }\n  }\n  return count;\n}",
            "// Write your code here\n    int count = 0;\n    std::vector<bool> visited(N, false);\n    for (int i = 0; i < N; i++) {\n        if (visited[i]) continue;\n        count++;\n        std::vector<bool> local(N, false);\n        std::vector<int> queue;\n        queue.push_back(i);\n        visited[i] = true;\n        local[i] = true;\n        while (!queue.empty()) {\n            int node = queue.back();\n            queue.pop_back();\n            for (int j = 0; j < N; j++) {\n                if (A[node * N + j] == 1 &&!visited[j]) {\n                    visited[j] = true;\n                    local[j] = true;\n                    queue.push_back(j);\n                }\n            }\n        }\n        for (int i = 0; i < N; i++) {\n            if (local[i] == true) {\n                visited[i] = false;\n            }\n        }\n    }\n    return count;\n}",
            "std::vector<int> S(N, 1);\n  std::vector<int> P(N, 1);\n\n  int count = 0;\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]) {\n        S[i] += S[j];\n        if (S[j] > S[i]) {\n          P[i] = j;\n        }\n      }\n    }\n  }\n\n  for (size_t i = 0; i < N; ++i) {\n    if (P[i] == 1) {\n      ++count;\n    }\n  }\n\n  return count;\n}",
            "int count = 0;\n    int connected = 0;\n    //TODO: use OpenMP to count the number of connected components\n    int i,j;\n    int flag[N];\n\n    for (i=0; i<N; i++)\n    {\n        flag[i]=0;\n    }\n\n    for (i=0; i<N; i++)\n    {\n        if(flag[i]==0)\n        {\n            flag[i]=1;\n            connected++;\n            for(j=0; j<N; j++)\n            {\n                if(A[i*N+j]==1)\n                {\n                    if(flag[j]==0)\n                    {\n                        flag[j]=1;\n                        connected++;\n                    }\n                }\n            }\n        }\n    }\n\n    return connected;\n}",
            "std::vector<bool> visited(N);\n  auto compCount = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i]) continue;\n    // use bfs to get a connected component\n    std::queue<int> q;\n    q.push(i);\n    while (!q.empty()) {\n      auto curr = q.front();\n      q.pop();\n      if (visited[curr]) continue;\n      visited[curr] = true;\n      for (size_t j = 0; j < N; j++) {\n        if (A[curr * N + j]) {\n          q.push(j);\n        }\n      }\n    }\n    compCount++;\n  }\n  return compCount;\n}",
            "int count = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i * N + i]) {\n\t\t\t++count;\n\t\t\t// DFS\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int num_components = 0;\n\n  // YOUR CODE HERE!\n  #pragma omp parallel for num_threads(4) schedule(dynamic, 1000)\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j]) {\n        int num_components = 1;\n      }\n    }\n  }\n  \n\n  return num_components;\n}",
            "int count = 0;\n  std::vector<int> C(N);\n\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; i++) {\n    for(size_t j = i + 1; j < N; j++) {\n      if(A[i * N + j] == 1) {\n        C[i] = j;\n        break;\n      }\n    }\n  }\n  return count;\n}",
            "// YOUR CODE HERE\n    int res = 0;\n    std::vector<int> visited (A.size(), 0);\n    #pragma omp parallel for num_threads(4) schedule(static,1)\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            int count = 0;\n            std::vector<int> temp;\n            #pragma omp critical\n            {\n                res++;\n            }\n            visited[i] = 1;\n            temp.push_back(i);\n            while (temp.size() > 0) {\n                int cur = temp[temp.size() - 1];\n                #pragma omp critical\n                {\n                    count++;\n                }\n                for (int j = 0; j < N; j++) {\n                    if (A[cur * N + j] == 1 && visited[j] == 0) {\n                        #pragma omp critical\n                        {\n                            visited[j] = 1;\n                            temp.push_back(j);\n                        }\n                    }\n                }\n                temp.pop_back();\n            }\n        }\n    }\n    return res;\n}",
            "int count = 0;\n\n\t// use DFS to find all components\n\tstd::vector<bool> visited(N, false);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tDFS(A, i, visited, N);\n\t\t++count;\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n\n# pragma omp parallel for schedule(dynamic)\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      std::stack<int> s;\n      s.push(i);\n      visited[i] = true;\n      while (!s.empty()) {\n        auto u = s.top(); s.pop();\n        for (size_t v = 0; v < N; ++v) {\n          if (A[u * N + v] &&!visited[v]) {\n            s.push(v);\n            visited[v] = true;\n          }\n        }\n      }\n      ++count;\n    }\n  }\n  return count;\n}",
            "int components = 0;\n\tbool* visited = new bool[N];\n\tstd::fill(visited, visited+N, false);\n\n\t#pragma omp parallel for\n\tfor(int i=0; i<N; ++i){\n\t\tif(visited[i]) continue;\n\t\t// Breadth first search\n\t\tstd::queue<int> Q;\n\t\tQ.push(i);\n\t\twhile(!Q.empty()){\n\t\t\tint node = Q.front();\n\t\t\tQ.pop();\n\t\t\tif(visited[node]) continue;\n\t\t\tvisited[node] = true;\n\t\t\tfor(int j=0; j<N; ++j){\n\t\t\t\tif(A[node*N + j]){\n\t\t\t\t\tQ.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcomponents++;\n\t}\n\n\tdelete[] visited;\n\treturn components;\n}",
            "int nthreads = 0;\n\tint ncomponents = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tnthreads = omp_get_num_threads();\n\t\t#pragma omp for reduction(+ : ncomponents)\n\t\tfor(size_t i = 0; i < N; ++i) {\n\t\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\t\tif(A[i*N + j]) {\n\t\t\t\t\t// count the number of connected components\n\t\t\t\t\t// by looking at which vertices are reachable\n\t\t\t\t\t// from i\n\t\t\t\t\tstd::unordered_set<size_t> seen{i};\n\t\t\t\t\tstd::queue<size_t> q;\n\t\t\t\t\tq.push(i);\n\t\t\t\t\twhile(!q.empty()) {\n\t\t\t\t\t\tauto u = q.front();\n\t\t\t\t\t\tq.pop();\n\t\t\t\t\t\tfor(size_t v = 0; v < N; ++v) {\n\t\t\t\t\t\t\tif(A[u*N + v]) {\n\t\t\t\t\t\t\t\tif(seen.find(v) == seen.end()) {\n\t\t\t\t\t\t\t\t\tq.push(v);\n\t\t\t\t\t\t\t\t\tseen.insert(v);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\t++ncomponents;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tstd::cout << nthreads << \" threads used\" << std::endl;\n\treturn ncomponents;\n}",
            "int count = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t// initialize component counter for each thread\n\t\tint private_count = 0;\n\t\t#pragma omp for\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tbool visited[N];\n\t\t\tmemset(visited, false, sizeof(bool)*N);\n\t\t\tstd::vector<int> component;\n\t\t\tcomponent.push_back(i);\n\t\t\twhile (component.size() > 0) {\n\t\t\t\tint node = component.back();\n\t\t\t\tcomponent.pop_back();\n\t\t\t\tif (visited[node]) {\n\t\t\t\t\tcontinue;\n\t\t\t\t} else {\n\t\t\t\t\tvisited[node] = true;\n\t\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[node * N + j] == 1) {\n\t\t\t\t\t\t\tcomponent.push_back(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tprivate_count++;\n\t\t}\n\n\t\t// sum up counters of each thread and store in count\n\t\t#pragma omp critical\n\t\tcount += private_count;\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    #pragma omp parallel for reduction(+ : count)\n    for (size_t i = 0; i < N; ++i) {\n        if (A[i * N + i]) {\n            std::vector<bool> seen(N, false);\n            std::queue<size_t> q;\n            q.push(i);\n            seen[i] = true;\n            while (!q.empty()) {\n                size_t x = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[x * N + j] &&!seen[j]) {\n                        q.push(j);\n                        seen[j] = true;\n                    }\n                }\n            }\n            ++count;\n        }\n    }\n    return count;\n}",
            "std::vector<int> color(N);\n\n  // TODO: Implement me\n\n  return -1;\n}",
            "std::vector<int> components(N, 0);\n\n    for (int i = 0; i < N; ++i) {\n        if (components[i]!= 0)\n            continue;\n\n        std::vector<int> visited;\n        int count = 0;\n\n        #pragma omp parallel for shared(A) reduction(+:count)\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] == 0)\n                continue;\n\n            for (int k = 0; k < N; ++k) {\n                if (A[j * N + k] == 1 &&\n                    components[k] == 0 &&\n                    std::find(visited.begin(), visited.end(), k) == visited.end()) {\n                    visited.push_back(k);\n                    components[k] = components[i] + 1;\n                    count++;\n                }\n            }\n        }\n\n        if (count!= 0)\n            components[i] = components[i] + 1;\n    }\n\n    int componentCount = 0;\n    for (int i = 0; i < N; ++i) {\n        if (components[i] == 0)\n            continue;\n\n        componentCount++;\n    }\n\n    return componentCount;\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n    std::vector<int> id(N, -1);\n\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            count++;\n            std::queue<int> q;\n            q.push(i);\n            while (!q.empty()) {\n                int v = q.front();\n                q.pop();\n                if (!visited[v]) {\n                    visited[v] = true;\n                    id[v] = count - 1;\n                    for (int i = 0; i < N; i++) {\n                        if (A[N * v + i] == 1 &&!visited[i])\n                            q.push(i);\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "// Your code goes here!\n  return -1;\n}",
            "int comp_count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint visited[N];\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[j] = 0;\n\t\t}\n\t\tint curr = i;\n\t\tif (visited[curr] == 0) {\n\t\t\tcomp_count++;\n\t\t\tvisited[curr] = 1;\n\t\t\t#pragma omp parallel for num_threads(4)\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\tcurr = j;\n\t\t\t\t\tvisited[curr] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn comp_count;\n}",
            "int count = 0;\n\tstd::vector<bool> componentVisited(N, false);\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!componentVisited[i]) {\n\t\t\tcount++;\n\t\t\tcomponentVisited[i] = true;\n\t\t\tstd::queue<int> toVisit;\n\t\t\ttoVisit.push(i);\n\t\t\twhile (!toVisit.empty()) {\n\t\t\t\tint current = toVisit.front();\n\t\t\t\ttoVisit.pop();\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[current * N + j] &&!componentVisited[j]) {\n\t\t\t\t\t\ttoVisit.push(j);\n\t\t\t\t\t\tcomponentVisited[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> count(N, 0);\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            count[i] = 1;\n            std::vector<int> curr_component;\n            curr_component.push_back(i);\n            for (int j = 0; j < N; ++j) {\n                if (i == j)\n                    continue;\n                if (A[i * N + j] == 1) {\n                    curr_component.push_back(j);\n                    visited[j] = true;\n                }\n            }\n            for (int k = 0; k < curr_component.size(); ++k) {\n                for (int m = 0; m < curr_component.size(); ++m) {\n                    int ii = curr_component[k];\n                    int jj = curr_component[m];\n                    if (A[ii * N + jj] == 1) {\n                        count[i]++;\n                    }\n                }\n            }\n        }\n    }\n    int res = 0;\n    for (int i = 0; i < N; ++i) {\n        res += count[i];\n    }\n    return res;\n}",
            "int ret = 0;\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tstd::vector<bool> visited(N);\n\t\t\tint num = 0;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tnum++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (num > 0) {\n\t\t\t\t#pragma omp atomic\n\t\t\t\tret++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ret;\n}",
            "int ncc = 0;\n\tstd::vector<int> label(N, 0);\n\n#pragma omp parallel for schedule(guided)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (label[i] == 0) {\n\t\t\tncc++;\n\t\t\tint currentLabel = ncc;\n\t\t\tlabel[i] = currentLabel;\n\t\t\tstd::vector<int> Q;\n\t\t\tQ.push_back(i);\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tint cur = Q.back();\n\t\t\t\tQ.pop_back();\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[cur * N + j]!= 0 && label[j] == 0) {\n\t\t\t\t\t\tlabel[j] = currentLabel;\n\t\t\t\t\t\tQ.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ncc;\n}",
            "// TODO\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n#pragma omp parallel\n  {\n    int id = omp_get_thread_num();\n    int num_threads = omp_get_num_threads();\n#pragma omp for\n    for (size_t i = 0; i < N; i++) {\n      if (!visited[i]) {\n        int j = 0;\n        int currentComponentSize = 1;\n        while (j < N) {\n          if (A[i * N + j] == 1 &&!visited[j]) {\n            currentComponentSize++;\n            visited[j] = true;\n          }\n          j++;\n        }\n#pragma omp atomic\n        count += currentComponentSize;\n      }\n    }\n  }\n  return count;\n}",
            "// Your code here\n\t\n\tint num = 0;\n\tstd::vector<int> visited(N,0);\n\tint count = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!visited[i]) {\n\t\t\tDfs(A, visited, i, count);\n\t\t\tnum++;\n\t\t}\n\t}\n\treturn num;\n}",
            "std::vector<int> visited(N, 0);\n    int count = 0;\n\n    #pragma omp parallel for\n    for(int i = 0; i < N; i++) {\n        if(visited[i] == 0) {\n            #pragma omp critical\n            count += 1;\n\n            // Perform DFS\n            std::deque<int> stack;\n            stack.push_front(i);\n            while(!stack.empty()) {\n                int u = stack.front();\n                stack.pop_front();\n\n                visited[u] = 1;\n\n                // Visit all unvisited neighbors.\n                for(int v = 0; v < N; v++) {\n                    if(A[u * N + v]!= 0 && visited[v] == 0) {\n                        stack.push_front(v);\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> visited(N);\n  int num_of_comps = 0;\n  #pragma omp parallel for\n  for (int i=0; i<N; i++) {\n    if (visited[i]==0) {\n      #pragma omp critical\n      {\n        num_of_comps++;\n      }\n      std::queue<int> Q;\n      Q.push(i);\n      while(!Q.empty()) {\n        int x = Q.front();\n        Q.pop();\n        visited[x] = 1;\n        for (int y=0; y<N; y++) {\n          if (A[x*N+y]==1 && visited[y]==0)\n            Q.push(y);\n        }\n      }\n    }\n  }\n  return num_of_comps;\n}",
            "int n_components = 0;\n  #pragma omp parallel for reduction(+:n_components) schedule(dynamic)\n  for(int i = 0; i < N; ++i) {\n    bool visited[N];\n    memset(visited, false, sizeof(bool) * N);\n    std::stack<int> stack;\n    stack.push(i);\n    visited[i] = true;\n    while(!stack.empty()) {\n      int j = stack.top();\n      stack.pop();\n      for(int k = 0; k < N; ++k) {\n        if(A[j * N + k] == 1) {\n          if(!visited[k]) {\n            stack.push(k);\n            visited[k] = true;\n          }\n        }\n      }\n    }\n    ++n_components;\n  }\n\n  return n_components;\n}",
            "std::vector<bool> visited(N, false);\n\n  // Fill this in.\n  int count = 0;\n\n  return count;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\t#pragma omp critical\n\t\t\tcount++;\n\t\t\tstd::cout << \"found one\\n\";\n\n\t\t\tstd::queue<int> next;\n\t\t\tnext.push(i);\n\n\t\t\twhile (!next.empty()) {\n\t\t\t\tint curr = next.front();\n\t\t\t\tnext.pop();\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[curr*N + j] == 1 &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tnext.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count=0;\n  int* isVisited = new int[N];\n  std::fill_n(isVisited,N,0);\n  for(size_t i = 0; i < N; ++i){\n    if(isVisited[i]==0){\n      std::cout << \"Starting from \" << i << std::endl;\n      bfs(i,isVisited,A,N);\n      count++;\n    }\n  }\n  delete [] isVisited;\n  return count;\n}",
            "int nthreads = omp_get_max_threads();\n  std::vector<int> connected_components(nthreads, 0);\n  // your code here\n  return 0;\n}",
            "std::vector<int> visited(N, 0);\n\tint component_count = 0;\n\n\t//#pragma omp parallel num_threads(omp_get_num_procs()-1)\n\t{\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (!visited[i]) {\n\t\t\t\tcomponent_count++;\n\t\t\t\tstd::queue<int> q;\n\t\t\t\tq.push(i);\n\t\t\t\tvisited[i] = 1;\n\n\t\t\t\twhile (!q.empty()) {\n\t\t\t\t\tint v = q.front();\n\t\t\t\t\tq.pop();\n\n\t\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[v * N + j] == 1 &&!visited[j]) {\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn component_count;\n}",
            "#pragma omp parallel\n\t{\n\t\t#pragma omp single\n\t\t{\n\t\t\tint num_of_components = 0;\n\t\t\tstd::vector<bool> visited(N);\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (not visited[i]) {\n\t\t\t\t\tnum_of_components++;\n\t\t\t\t\t#pragma omp task\n\t\t\t\t\t{\n\t\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\t\tif (A[i*N + j]) {\n\t\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn num_of_components;\n\t\t}\n\t}\n}",
            "int numComponents = 0;\n\n  #pragma omp parallel for schedule(dynamic) reduction(+:numComponents)\n  for (size_t i = 0; i < N; i++) {\n    if (A[i*N + i]) { // if we have not visited this node before\n      #pragma omp critical\n      numComponents++;\n\n      #pragma omp parallel for schedule(dynamic)\n      for (size_t j = i*N; j < (i+1)*N; j++) {\n        A[j] = 1;\n      }\n    }\n  }\n\n  return numComponents;\n}",
            "/* YOUR CODE HERE */\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\t++count;\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "auto visited = new bool[N];\n    for (size_t i = 0; i < N; i++) {\n        visited[i] = false;\n    }\n\n    int count = 0;\n    #pragma omp parallel for reduction(+:count) schedule(dynamic)\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            count++;\n            std::stack<size_t> stack;\n            stack.push(i);\n            while (!stack.empty()) {\n                size_t node = stack.top();\n                stack.pop();\n                if (!visited[node]) {\n                    visited[node] = true;\n                    for (size_t j = 0; j < N; j++) {\n                        if (A[N * node + j] > 0 &&!visited[j]) {\n                            stack.push(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    delete[] visited;\n    return count;\n}",
            "if (N == 0) return 0;\n  int num_cc = 0;\n  #pragma omp parallel\n  {\n    #pragma omp for reduction(+:num_cc)\n    for (size_t i = 0; i < N; i++)\n      if (A[i*N + i] == 1) {\n        // Find the connected component starting at node i.\n        std::vector<bool> visited(N, false);\n        std::stack<int> nodes_to_visit;\n        nodes_to_visit.push(i);\n        while (!nodes_to_visit.empty()) {\n          // Get the next node to visit.\n          int next = nodes_to_visit.top();\n          nodes_to_visit.pop();\n          // If it is already visited, skip it.\n          if (visited[next]) continue;\n          // Mark it as visited and explore all the connected components.\n          visited[next] = true;\n          for (int j = 0; j < N; j++)\n            if (A[next*N + j] == 1) {\n              nodes_to_visit.push(j);\n            }\n        }\n        num_cc++;\n      }\n  }\n  return num_cc;\n}",
            "// TODO: Implement\n    int count = 0;\n    std::vector<int> visited(N,0);\n#pragma omp parallel for\n    for(int i = 0; i < N; i++){\n        if(!visited[i])\n        {\n            int x;\n            for(x = 0; x < N; x++){\n                if(A[i * N + x]!= 0){\n                    break;\n                }\n            }\n            if(x == N)\n            {\n                visited[i] = 1;\n                continue;\n            }\n            else\n            {\n                count++;\n                std::vector<int> stack;\n                stack.push_back(i);\n                while(stack.size()!= 0){\n                    int tmp = stack.back();\n                    stack.pop_back();\n                    visited[tmp] = 1;\n                    for(int j = 0; j < N; j++){\n                        if(A[tmp * N + j]!= 0 &&!visited[j])\n                        {\n                            stack.push_back(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return count;\n}",
            "size_t numOfNodes = N * N;\n    int count = 0;\n\n    bool *visited = new bool[numOfNodes];\n\n    for (int i = 0; i < numOfNodes; i++) {\n        visited[i] = false;\n    }\n\n#pragma omp parallel for private(count)\n    for (int i = 0; i < numOfNodes; i++) {\n        if (!visited[i]) {\n            count++;\n            // Traverse the nodes in the same connected component starting from the current node\n            std::function<void(int)> dfs = [&](int node) {\n                visited[node] = true;\n                for (int i = 0; i < N; i++) {\n                    if (A[node * N + i] == 1 &&!visited[i]) {\n                        dfs(i);\n                    }\n                }\n            };\n\n            dfs(i);\n        }\n    }\n    delete[] visited;\n    return count;\n}",
            "int componentCount = 0;\n\tint count = 0;\n\tint total = 0;\n\tint *visited = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcomponentCount += 1;\n\t\t\tcount = 0;\n\t\t\t#pragma omp parallel for private(total) num_threads(2)\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcount += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttotal += count;\n\t\t}\n\t}\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = -1;\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (visited[j] == 0) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tcomponentCount -= 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t// for (int i = 0; i < N; i++) {\n\t// \tcout << visited[i] <<'';\n\t// }\n\t// cout << endl;\n\tdelete[] visited;\n\n\treturn componentCount;\n}",
            "int num_components = 0;\n\tstd::vector<bool> visited(N);\n\tint threads = omp_get_max_threads();\n\tstd::vector<std::vector<int>> queue(threads);\n\tstd::vector<std::vector<int>> queue_next(threads);\n\n\t// Each thread has its own queue\n\tfor (int i = 0; i < threads; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tqueue[i].push_back(j);\n\t\t}\n\t}\n\n\t#pragma omp parallel shared(A, visited, queue, queue_next, num_components)\n\t{\n\t\t#pragma omp for schedule(dynamic, 1)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited[i]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tint tid = omp_get_thread_num();\n\t\t\tstd::vector<int> temp = queue[tid];\n\t\t\tqueue[tid].clear();\n\t\t\tqueue_next[tid].clear();\n\t\t\tfor (int vertex : temp) {\n\t\t\t\tif (visited[vertex]) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tqueue[tid].push_back(vertex);\n\t\t\t\tvisited[vertex] = true;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[vertex * N + j] &&!visited[j]) {\n\t\t\t\t\t\tqueue_next[tid].push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tqueue[tid].insert(queue[tid].end(), queue_next[tid].begin(), queue_next[tid].end());\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tnum_components += 1;\n\t\t}\n\t}\n\treturn num_components;\n}",
            "std::vector<bool> visited(N);\n    std::fill(visited.begin(), visited.end(), false);\n\n    // Your code goes here\n    int counter = 0;\n    for (size_t i = 0; i < N; ++i){\n        if (!visited[i]){\n            counter++;\n            std::queue<size_t> Q;\n            Q.push(i);\n            while (!Q.empty()){\n                size_t v = Q.front();\n                Q.pop();\n                visited[v] = true;\n                for (size_t j = 0; j < N; ++j){\n                    if (!visited[j] && A[N*v + j] == 1){\n                        Q.push(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return counter;\n}",
            "// TODO: implement me\n    return 0;\n}",
            "// your code goes here\n\n\treturn 0;\n}",
            "int count = 0;\n    #pragma omp parallel for\n    for(size_t i = 0; i < N; ++i)\n    {\n        int start = A[i*N + i];\n        std::vector<int> bfs;\n        bfs.push_back(start);\n        bool done = false;\n        while(!done)\n        {\n            int front = bfs.back();\n            bfs.pop_back();\n            for(int j = 0; j < N; ++j)\n            {\n                if(A[front*N + j] && std::find(bfs.begin(), bfs.end(), j) == bfs.end())\n                {\n                    bfs.push_back(j);\n                }\n            }\n            if(front == start)\n            {\n                done = true;\n                count++;\n            }\n        }\n    }\n    return count;\n}",
            "std::vector<int> is_visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (is_visited[i] == 0) {\n\t\t\tstd::vector<int> next_nodes(N, 0);\n\t\t\tstd::vector<int> next_nodes_index(N, 0);\n\t\t\tint current_node = i;\n\t\t\twhile (current_node!= -1) {\n\t\t\t\tis_visited[current_node] = 1;\n\t\t\t\tint node_count = 0;\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[current_node * N + j] == 1 && is_visited[j] == 0) {\n\t\t\t\t\t\tnext_nodes[node_count] = j;\n\t\t\t\t\t\tnode_count++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tnext_nodes_index[0] = 0;\n\t\t\t\tfor (int i = 0; i < node_count; i++) {\n\t\t\t\t\tfor (int j = 0; j < node_count; j++) {\n\t\t\t\t\t\tif (next_nodes[i] < next_nodes[j]) {\n\t\t\t\t\t\t\tint temp = next_nodes[i];\n\t\t\t\t\t\t\tnext_nodes[i] = next_nodes[j];\n\t\t\t\t\t\t\tnext_nodes[j] = temp;\n\t\t\t\t\t\t\tint temp_index = next_nodes_index[i];\n\t\t\t\t\t\t\tnext_nodes_index[i] = next_nodes_index[j];\n\t\t\t\t\t\t\tnext_nodes_index[j] = temp_index;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcurrent_node = -1;\n\t\t\t\tfor (int i = 0; i < node_count; i++) {\n\t\t\t\t\tif (next_nodes[i]!= current_node) {\n\t\t\t\t\t\tcurrent_node = next_nodes[i];\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "/* Your solution goes here.  */\n    std::vector<int> visited(N,0);\n    int visited_count = 0;\n    for(int i = 0; i < N; i++){\n        if(visited[i] == 0){\n            visited[i] = 1;\n            visited_count++;\n            #pragma omp parallel for\n            for(int j = 0; j < N; j++){\n                if(A[i*N + j] == 1 && visited[j] == 0){\n                    visited[j] = 1;\n                    visited_count++;\n                }\n            }\n        }\n    }\n    return visited_count;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N);\n\t#pragma omp parallel for num_threads(8)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i])\n\t\t\tcontinue;\n\t\t// Traverse the graph in Breadth-First Search order and mark the nodes visited\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\tvisited[i] = true;\n\t\twhile (!q.empty()) {\n\t\t\tint id = q.front();\n\t\t\tq.pop();\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[N * id + j] == 1 &&!visited[j]) {\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcount++;\n\t}\n\treturn count;\n}",
            "// Fill code here.\n    return 0;\n}",
            "int count = 0;\n    #pragma omp parallel for reduction(+:count)\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j]) {\n                count += 1;\n            }\n        }\n    }\n    return count;\n}",
            "std::vector<int> color(N, -1);\n  int num_component = 0;\n\n  /*\n   * TODO: Compute the number of connected components in the graph defined by\n   * the adjacency matrix A, and store the component number for each node in the\n   * array color.\n   *\n   * Hint: you can use an integer array to keep track of which component each\n   * node is in.\n   *\n   * You can do this in two ways:\n   *\n   * 1. Use a depth-first search to explore the graph, and assign each node a\n   * unique component number. This is a good choice for large graphs where\n   * parallelism is important.\n   *\n   * 2. Use a breadth-first search to explore the graph.\n   *\n   * Both ways will give you the correct answer, so you can use either one.\n   * It is worthwhile to compare the time and space complexity of both methods.\n   */\n\n  for (size_t i = 0; i < N; ++i)\n  {\n    if (color[i]!= -1)\n      continue;\n\n    std::queue<size_t> Q;\n    Q.push(i);\n    color[i] = num_component;\n\n    while (!Q.empty())\n    {\n      auto current = Q.front();\n      Q.pop();\n\n      for (size_t j = 0; j < N; ++j)\n      {\n        if (A[current * N + j] == 1 && color[j] == -1)\n        {\n          Q.push(j);\n          color[j] = num_component;\n        }\n      }\n    }\n    num_component++;\n  }\n\n  return num_component;\n}",
            "/* TODO: Complete this function */\n  return 0;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "serial",
        "prompt": "/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "std::vector<int> visited(N, 0);\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            ++count;\n            visited[i] = 1;\n            DFS_R(A, visited, i);\n        }\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      depthFirstSearch(A, N, i, &visited);\n      ++count;\n    }\n  }\n  return count;\n}",
            "// number of connected components\n    int count = 0;\n\n    // vector of flags for visited nodes\n    std::vector<bool> visited(N, false);\n\n    // loop over the rows\n    for (int i = 0; i < N; i++) {\n        // only look at nodes that are not yet visited\n        if (visited[i]) {\n            continue;\n        }\n        // recursive depth-first search (DFS) to find a connected component\n        count += componentDFS(A, i, visited);\n    }\n    // return the number of components found\n    return count;\n}",
            "std::vector<bool> visited(N);\n  std::fill(visited.begin(), visited.end(), false);\n  int count = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      dfs(A, visited, i, N);\n    }\n  }\n\n  return count;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\n\tauto adjacency_matrix = std::vector<int>(N*N);\n\tstd::copy(A.begin(), A.end(), adjacency_matrix.begin());\n\tauto visited = std::vector<bool>(N, false);\n\tauto count = 0;\n\n\tfor (auto i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++count;\n\t\t\tdfs(adjacency_matrix, visited, i, N);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "if (A.size() == 0) return 0;\n\tsize_t count = 0;\n\tstd::vector<bool> seen(N);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (seen[i] || A[i] == 0) continue;\n\t\tsize_t c = 0;\n\t\tdfs(A, seen, i, c);\n\t\tcount++;\n\t}\n\treturn count;\n}",
            "if (A.size()!= N * N)\n\t\tthrow std::runtime_error(\"invalid adjacency matrix size\");\n\n\tstd::vector<int> parents(N, -1);\n\tint components = 0;\n\n\tfor (int row = 0; row < N; ++row) {\n\t\tif (parents[row] == -1) {\n\t\t\t++components;\n\t\t\tparents[row] = row;\n\t\t\tfor (int col = 0; col < N; ++col) {\n\t\t\t\tif (A[row * N + col]) {\n\t\t\t\t\tint root = find(parents, col);\n\t\t\t\t\tparents[root] = row;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn components;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<std::vector<int>> adjacency(N);\n\n\t// Create adjacency list from adjacency matrix.\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\tadjacency[i].push_back(j);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\t\t\tDFS(adjacency, visited, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO: Your code here\n\tstd::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == false) {\n\t\t\tdfs_helper(A, visited, N, i, count);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> marked(N);\n\tstd::vector<int> count(N, 0);\n\tint cc = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!marked[i]) {\n\t\t\tdfs(A, N, i, count, marked, cc);\n\t\t}\n\t}\n\treturn cc;\n}",
            "// Your code goes here.\n    std::stack<int> s;\n    std::vector<int> v(N, 0);\n    int count = 0;\n\n    for (int i = 0; i < N; ++i) {\n        if (v[i] == 0 && A[i] > 0) {\n            v[i] = 1;\n            s.push(i);\n\n            while (!s.empty()) {\n                int c = s.top();\n                s.pop();\n\n                for (int i = 0; i < N; ++i) {\n                    if (A[c] > 0 && A[c] > 0 && v[i] == 0) {\n                        v[i] = 1;\n                        s.push(i);\n                        ++count;\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> is_visited(N);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (is_visited[i] == 0) {\n\t\t\t++count;\n\t\t\tDfs(A, is_visited, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "if(N <= 0) {\n        return 0;\n    }\n\n    std::vector<bool> visited(N);\n    std::queue<int> bfsQueue;\n\n    int components = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(!visited[i]) {\n            components++;\n            bfsQueue.push(i);\n            while(!bfsQueue.empty()) {\n                int vertex = bfsQueue.front();\n                bfsQueue.pop();\n                visited[vertex] = true;\n                for(size_t j = 0; j < N; ++j) {\n                    if(A[vertex * N + j] &&!visited[j]) {\n                        bfsQueue.push(j);\n                    }\n                }\n            }\n        }\n    }\n\n    return components;\n}",
            "// DFS implementation.\n  std::vector<int> visited(N, 0);\n  int count = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      count++;\n      DFS_helper(A, visited, N, i);\n    }\n  }\n\n  return count;\n}",
            "// Write your code here\n\tstd::vector<int> visited(N);\n\tstd::vector<int> adjacency(N, -1);\n\tint numComponents = 0;\n\n\tfor(int i = 0; i < N; i++){\n\t\tif(visited[i] == 0){\n\t\t\tnumComponents++;\n\t\t\tbfs(i, visited, adjacency, A);\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N, false);\n  int components = 0;\n\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n\n    std::stack<int> s;\n    s.push(i);\n    visited[i] = true;\n\n    while (!s.empty()) {\n      int u = s.top();\n      s.pop();\n\n      for (int v = 0; v < N; ++v) {\n        if (A[u * N + v] &&!visited[v]) {\n          s.push(v);\n          visited[v] = true;\n        }\n      }\n    }\n\n    ++components;\n  }\n\n  return components;\n}",
            "// TODO: Your code here\n  return 0;\n}",
            "// TODO: write your solution here\n\tint count = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tif (!visited[i])\n\t\t{\n\t\t\t++count;\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> component(N); // -1 = unvisited, 0 = connected, > 0 = visited with component\n    int connected = 0;\n\n    auto visit = [&](int node) {\n        if (component[node] < 0) { // unvisited\n            component[node] = 0;\n            connected++;\n            for (int i = 0; i < N; ++i) {\n                if (A[node * N + i] == 1) {\n                    visit(i);\n                }\n            }\n        }\n    };\n\n    for (int i = 0; i < N; ++i) {\n        visit(i);\n    }\n    return connected;\n}",
            "// Your code goes here.\n  return 0;\n}",
            "// TODO: your code here\n  return 0;\n}",
            "// B is a 1xN vector storing the index of the component each vertex belongs to.\n\tstd::vector<int> B(N);\n\n\tint numOfComponents = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// If this vertex is not yet connected to a component, create one.\n\t\tif (B[i] == 0) {\n\t\t\tnumOfComponents++;\n\t\t\tint currentComponent = numOfComponents;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t// Visit all the neighbours of the vertex i.\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t// If the neighbour is not yet connected to any component,\n\t\t\t\t\t// connect it to the current component.\n\t\t\t\t\tif (B[j] == 0) {\n\t\t\t\t\t\tB[j] = currentComponent;\n\t\t\t\t\t}\n\t\t\t\t\t// If the neighbour is already connected to a component,\n\t\t\t\t\t// connect the current component to the one of the neighbour.\n\t\t\t\t\telse {\n\t\t\t\t\t\tB[currentComponent] = B[j];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numOfComponents;\n}",
            "std::vector<int> components(N, -1);\n  std::stack<int> nodes;\n  std::queue<int> q;\n  int component_count = 0;\n  int node;\n\n  // Start the search with node 0.\n  q.push(0);\n  nodes.push(0);\n  components[0] = component_count++;\n\n  while (!q.empty()) {\n    node = q.front();\n    q.pop();\n\n    for (size_t i = 0; i < N; ++i) {\n      if (A[node*N+i] && components[i] < 0) {\n        components[i] = components[node];\n        q.push(i);\n        nodes.push(i);\n      }\n    }\n\n    while (!nodes.empty() && nodes.top()!= node) {\n      nodes.pop();\n    }\n    if (!nodes.empty()) {\n      nodes.pop();\n    }\n  }\n\n  return component_count;\n}",
            "std::vector<int> visited(N);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t++count;\n\t\t\tDFS(A, visited, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> dfs_sequence;\n\tint component_count = 0;\n\t\n\tfor (size_t row = 0; row < N; row++) {\n\t\tif (visited[row]) { continue; }\n\t\tcomponent_count++;\n\t\tdfs_sequence = dfs(A, visited, row);\n\t\tfor (size_t col = 0; col < dfs_sequence.size(); col++) {\n\t\t\tif (visited[dfs_sequence[col]]) { continue; }\n\t\t\tdfs_sequence = dfs(A, visited, dfs_sequence[col]);\n\t\t}\n\t}\n\treturn component_count;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tDFS(A, visited, i);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N);\n    int count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            dfs(A, N, i, visited);\n            ++count;\n        }\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::stack<int> st;\n\tint numComponents = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\n\t\tif (visited[i] == 0) {\n\n\t\t\tvisited[i] = 1;\n\t\t\tst.push(i);\n\n\t\t\twhile (!st.empty()) {\n\n\t\t\t\tauto currNode = st.top();\n\t\t\t\tst.pop();\n\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\n\t\t\t\t\tif (A[currNode * N + j] &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tst.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tnumComponents++;\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N);\n  std::vector<bool> onStack(N);\n  std::vector<int> dfsParent(N);\n  size_t components = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      size_t connected = dfsCount(A, N, visited, onStack, i, dfsParent);\n      if (connected > 1)\n        ++components;\n    }\n  }\n  return components;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, i, visited, N, count);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "if (N == 0) {\n    return 0;\n  }\n  std::vector<int> colors(N, -1);\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (colors[i] == -1) {\n      ++count;\n      std::queue<size_t> q;\n      q.push(i);\n      while (!q.empty()) {\n        size_t j = q.front();\n        q.pop();\n        colors[j] = 0;\n        for (size_t k = 0; k < N; ++k) {\n          if (A[j * N + k] && colors[k] == -1) {\n            q.push(k);\n            colors[k] = 0;\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N);\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tvisited[i] = 1;\n\t\t\tDFS(A, N, i, visited);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "if (N < 1)\n\t\treturn 0;\n\n\tstd::vector<int> visited(N, 0);\n\tstd::function<void(size_t)> dfs = [&dfs, &A, &visited](size_t i) {\n\t\tif (visited[i] > 0)\n\t\t\treturn;\n\t\tvisited[i] = 1;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 1)\n\t\t\t\tdfs(j);\n\t\t}\n\t};\n\tsize_t count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(i);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++count;\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint visited_count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (A[i] == 1 && visited[i] == 0) {\n\t\t\tdfs(A, i, visited);\n\t\t\tvisited_count++;\n\t\t}\n\t}\n\treturn visited_count;\n}",
            "int cnt{0};\n  std::vector<bool> v(N, false);\n  for (int i = 0; i < N; i++) {\n    if (v[i]) continue;\n    v[i] = true;\n    cnt++;\n    dfs(A, i, v);\n  }\n  return cnt;\n}",
            "if (N <= 1) {\n\t\treturn N;\n\t}\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, visited, i, N);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int components = 0;\n  std::vector<bool> visited(N);\n  for (size_t i = 0; i < N; i++) {\n    if (A[i] == 1 &&!visited[i]) {\n      components++;\n      dfs(A, i, N, visited);\n    }\n  }\n  return components;\n}",
            "// initialize a vector storing the id of each vertex\n\tstd::vector<int> id(N);\n\n\t// initialize the vector of counts, each count represents the number of vertices in a component\n\tstd::vector<int> count(N);\n\tfor(int i = 0; i < N; i++) {\n\t\tid[i] = i;\n\t\tcount[i] = 1;\n\t}\n\n\t// merge two components when there is an edge between them\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = i + 1; j < N; j++) {\n\t\t\tif(A[i * N + j]) {\n\t\t\t\tunionIds(id, i, j);\n\t\t\t}\n\t\t}\n\t}\n\n\t// compute the number of connected components\n\tint countComponent = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tcountComponent += count[id[i]];\n\t}\n\n\treturn countComponent;\n}",
            "// TODO: Implement this function\n  int count = 0;\n  std::vector<int> visited(N);\n  std::function<void(int)> dfs = [&](int i) {\n    visited[i] = 1;\n    for (int j = 0; j < N; ++j) {\n      if (visited[j] == 0 && A[i*N+j]) {\n        dfs(j);\n      }\n    }\n  };\n\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      dfs(i);\n      count++;\n    }\n  }\n\n  return count;\n}",
            "int ans = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, visited, i);\n\t\t\t++ans;\n\t\t}\n\t}\n\n\treturn ans;\n}",
            "// The algorithm is based on a simple dfs and is as follows:\n    //    1. mark all the nodes as not visited\n    //    2. for each vertex, if not visited, start dfs to count the number of nodes\n    //    3. return the count\n\n    // 1. mark all the nodes as not visited\n    std::vector<bool> visited(N, false);\n\n    // 2. for each vertex, if not visited, start dfs to count the number of nodes\n    int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            count++;\n            dfs(A, i, visited);\n        }\n    }\n\n    // 3. return the count\n    return count;\n}",
            "std::vector<int> connected(N, -1);\n\tstd::queue<int> q;\n\tint n = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (connected[i] == -1) {\n\t\t\tq.push(i);\n\t\t\tconnected[i] = n++;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint u = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\t\tif (A[N*u+v] == 1 && connected[v] == -1) {\n\t\t\t\t\t\tconnected[v] = connected[u];\n\t\t\t\t\t\tq.push(v);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn n;\n}",
            "int components = 0;\n    std::vector<int> visited(N, 0);\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            visited[i] = 1;\n            components++;\n            for (size_t j = 0; j < N; ++j) {\n                if (A[N * i + j] &&!visited[j]) {\n                    visited[j] = 1;\n                }\n            }\n        }\n    }\n\n    return components;\n}",
            "std::vector<int> visited(N, 0);\n    int num = 0;\n    for(int i = 0; i < N; ++i) {\n        if(visited[i] == 0) {\n            dfs(A, i, visited, &num);\n        }\n    }\n    return num;\n}",
            "// Your code goes here.\n\t// ------------------------------------------------------------\n\t// TODO: You can use a BFS or DFS algorithm for this problem.\n\t// ------------------------------------------------------------\n\n\tstd::vector<int> colors(N);\n\tstd::fill(colors.begin(), colors.end(), -1);\n\tint color = 0;\n\tint components = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (colors[i] == -1) {\n\t\t\tstd::queue<size_t> q;\n\t\t\tq.push(i);\n\t\t\tcolors[i] = color;\n\n\t\t\twhile (!q.empty()) {\n\t\t\t\tsize_t v = q.front();\n\t\t\t\tq.pop();\n\n\t\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[v * N + j] && colors[j] == -1) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tcolors[j] = color;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcomponents++;\n\t\t\tcolor++;\n\t\t}\n\t}\n\n\treturn components;\n}",
            "// TODO: Your code here\n    return -1;\n}",
            "std::vector<bool> visited(N, false);\n    std::queue<size_t> q;\n\n    auto count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i] && A[i * N + i]) {\n            visited[i] = true;\n            q.push(i);\n            while (!q.empty()) {\n                auto node = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; j++) {\n                    if (A[node * N + j] &&!visited[j]) {\n                        visited[j] = true;\n                        q.push(j);\n                    }\n                }\n            }\n            count++;\n        }\n    }\n\n    return count;\n}",
            "int result = 0;\n\tint visited[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tDFS(i, visited, A, N);\n\t\t\tresult++;\n\t\t}\n\t}\n\n\treturn result;\n}",
            "int num_of_components = 0;\n  std::vector<bool> marked(N, false);\n\n  for (size_t i = 0; i < N; i++) {\n    if (!marked[i]) {\n      dfs(A, N, i, marked);\n      num_of_components++;\n    }\n  }\n\n  return num_of_components;\n}",
            "std::vector<bool> marked(N, false);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!marked[i]) {\n\t\t\t++count;\n\t\t\tmarked[i] = true;\n\t\t\tdfs(A, marked, N, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO\n\treturn 0;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<int> components(N, 0);\n\tint cc = 0;\n\tint cnt = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcc++;\n\t\t\tcnt = 0;\n\t\t\tdfs(i, A, visited, components, &cnt);\n\t\t}\n\t}\n\n\treturn cc;\n}",
            "std::vector<int> marked(N);\n    int count = 0;\n\n    for (int i = 0; i < N; i++) {\n        if (marked[i] == 0) {\n            count++;\n            dfs(A, i, marked);\n        }\n    }\n\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (A[i * N + i]) {\n            count++;\n            for (size_t j = i; j < N; ++j) {\n                if (A[i * N + j]) {\n                    dfs(A, j, N, i);\n                }\n            }\n        }\n    }\n    return count;\n}",
            "// TODO: Write your solution here\n  std::vector<int> visited(N, 0);\n  std::queue<int> Q;\n\n  int cnt = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i] == 0 && A[i * N + i] == 0) {\n      visited[i] = 1;\n      Q.push(i);\n      cnt++;\n      while (!Q.empty()) {\n        int curr = Q.front();\n        Q.pop();\n        for (size_t j = 0; j < N; ++j) {\n          if (A[curr * N + j] == 1) {\n            if (visited[j] == 0) {\n              visited[j] = 1;\n              Q.push(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return cnt;\n}",
            "std::vector<int> colors(N, -1);\n  int color = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (colors[i] == -1) {\n      color = dfs(A, colors, i, color);\n      ++color;\n    }\n  }\n  return color;\n}",
            "// Your code here\n  int count = 0;\n  std::vector<bool> visited(N, false);\n  for(size_t i = 0; i < N; ++i) {\n    if(visited[i]) continue;\n    count++;\n    std::queue<int> q;\n    q.push(i);\n    while(!q.empty()) {\n      int cur = q.front();\n      visited[cur] = true;\n      q.pop();\n      for(int j = 0; j < N; ++j) {\n        if(!visited[j] && A[cur * N + j] == 1) {\n          q.push(j);\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\n\t// Store the nodes that have been visited.\n\tstd::vector<bool> visited(N);\n\n\t// Recursively visit each node.\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\t\t\tvisit(A, N, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "auto s = 0;\n\tauto color = std::vector<int>(N, -1);\n\n\tauto color_dfs = [&color, N](int const& i, auto const& dfs) -> void {\n\t\tcolor[i] = 0;\n\t\tfor (auto j = 0u; j < N; ++j) {\n\t\t\tif (color[j] == -1 && A[i * N + j] == 1) {\n\t\t\t\tdfs(j, dfs);\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (auto i = 0u; i < N; ++i) {\n\t\tif (color[i] == -1) {\n\t\t\tcolor_dfs(i, color_dfs);\n\t\t\ts += 1;\n\t\t}\n\t}\n\treturn s;\n}",
            "std::vector<int> visited(N);\n\tint c = 0;\n\tfor (size_t i = 0; i < N; i++)\n\t\tif (visited[i] == 0)\n\t\t\tdfs(A, visited, i, c);\n\n\treturn c;\n}",
            "std::vector<bool> vis(N, false);\n  std::function<void(int, std::vector<int> const&)> dfs = [&](int v, std::vector<int> const& A) {\n    vis[v] = true;\n    for (size_t i = 0; i < N; ++i) {\n      if (!vis[i] && A[v * N + i]) dfs(i, A);\n    }\n  };\n  for (size_t i = 0; i < N; ++i) {\n    if (!vis[i]) dfs(i, A);\n  }\n  int count = 0;\n  for (auto x : vis) if (x) ++count;\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n\n    auto dfs = [&](int v) {\n        visited[v] = 1;\n        for (size_t j = 0; j < N; ++j) {\n            if (A[N * v + j] == 1 &&!visited[j])\n                dfs(j);\n        }\n    };\n\n    int components = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            ++components;\n            dfs(i);\n        }\n    }\n\n    return components;\n}",
            "std::vector<bool> visited(N);\n\tstd::queue<int> q;\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tq.push(i);\n\t\t\tvisited[i] = true;\n\t\t\tcount++;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint top = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[top * N + j]) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "if (N <= 0) {\n    return 0;\n  }\n\n  std::vector<int> marked(N);\n  for (size_t i = 0; i < N; i++) {\n    if (marked[i] == 0) {\n      dfs(A, i, N, marked);\n    }\n  }\n\n  return std::accumulate(marked.begin(), marked.end(), 0);\n}",
            "std::vector<bool> visited(N, false);\n\tint components = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, N, i, visited);\n\t\t\tcomponents++;\n\t\t}\n\t}\n\treturn components;\n}",
            "int count = 0;\n  std::vector<int> visited(N, 0);\n\n  for(int i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      dfs(A, i, visited);\n      ++count;\n    }\n  }\n  return count;\n}",
            "if (N == 0) return 0;\n\n    std::vector<bool> vis(N, false);\n\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!vis[i]) {\n            DFS(A, N, vis, i);\n            count++;\n        }\n    }\n\n    return count;\n}",
            "std::vector<bool> visited(N);\n    size_t count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            ++count;\n            dfs(A, visited, N, i);\n        }\n    }\n    return count;\n}",
            "// This solution uses a modified version of the DFS algorithm to visit all nodes\n\tstd::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == false) {\n\t\t\tDFS(A, visited, i);\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N);\n  int count = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      count++;\n      dfs(A, i, &visited);\n    }\n  }\n\n  return count;\n}",
            "std::vector<int> componentID(N);\n  std::vector<int> connected(N);\n\n  std::queue<int> Q;\n\n  int ccID = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (componentID[i] == 0) {\n      Q.push(i);\n      componentID[i] = ccID;\n\n      while (!Q.empty()) {\n        int curr = Q.front();\n        Q.pop();\n\n        for (size_t j = 0; j < N; j++) {\n          if (A[N * curr + j] &&!connected[j]) {\n            connected[j] = 1;\n            Q.push(j);\n            componentID[j] = ccID;\n          }\n        }\n      }\n\n      ccID++;\n\n      for (size_t j = 0; j < N; j++) {\n        connected[j] = 0;\n      }\n    }\n  }\n\n  return ccID;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tvisit(i, visited, A, N);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i])\n\t\t\tcontinue;\n\t\tdfs(i, A, visited);\n\t\tcount++;\n\t}\n\treturn count;\n}",
            "if (A.empty()) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<bool> visited(N, false);\n\tint num_components = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tvisitAll(i, A, visited, N);\n\t\t\tnum_components++;\n\t\t}\n\t}\n\n\treturn num_components;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::function<void(size_t)> dfs = [&dfs, &A, &visited, &count, N](size_t vertex) {\n\t\tif (!visited[vertex]) {\n\t\t\tvisited[vertex] = true;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[vertex * N + j] &&!visited[j]) {\n\t\t\t\t\tdfs(j);\n\t\t\t\t}\n\t\t\t}\n\t\t\t++count;\n\t\t}\n\t};\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tdfs(i);\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<bool> inStack(N, false);\n\tstd::vector<int> stack;\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tvisited[i] = true;\n\t\tstack.push_back(i);\n\t\tinStack[i] = true;\n\n\t\twhile (!stack.empty()) {\n\t\t\tint current = stack.back();\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[current * N + j] == 1) {\n\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\t\tinStack[j] = true;\n\t\t\t\t\t}\n\t\t\t\t\telse if (inStack[j]) {\n\t\t\t\t\t\twhile (stack.back()!= j) {\n\t\t\t\t\t\t\tinStack[stack.back()] = false;\n\t\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (stack.back() == current) {\n\t\t\t\tcount++;\n\t\t\t\tstack.pop_back();\n\t\t\t\tinStack[current] = false;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> used(N);\n    int count = 0;\n    for (size_t i = 0; i < N; ++i)\n        if (!used[i]) {\n            ++count;\n            dfs(A, i, used);\n        }\n    return count;\n}",
            "auto visited = std::vector<bool>(N, false);\n\tauto count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t//std::cout << \"visit: \" << i << std::endl;\n\t\t\t++count;\n\t\t\tvisit(A, i, N, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "/*\n\t\t\t\t\t\t1 0 1 1\n\t\t\t\t\t\t0 0 1 1\n\t\t\t\t\t\t1 0 1 0\n\t\t\t\t\t\t0 0 0 0\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t| |||| |\n\t\t\t\t\t\t|",
            "if (N == 0)\n\t\treturn 0;\n\n\t// Initialize a vector of size N representing\n\t// whether each vertex has been visited.\n\tstd::vector<bool> visited(N, false);\n\n\t// Initialize the number of connected components to zero.\n\t// This will be incremented in the while loop.\n\tint components = 0;\n\n\t// Initialize the current vertex index.\n\tint vertex = 0;\n\n\t// Loop through all vertices in the graph.\n\twhile (vertex < N) {\n\t\t// Skip if the current vertex has been visited.\n\t\tif (visited[vertex]) {\n\t\t\t++vertex;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Otherwise, perform a depth-first search from this vertex.\n\t\tvisited[vertex] = true;\n\t\tDFS(vertex, A, visited);\n\t\tcomponents++;\n\t\tvertex++;\n\t}\n\n\treturn components;\n}",
            "int count = 0;\n  std::vector<bool> visited(N, false);\n\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      DFS(A, visited, i);\n      count++;\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      count++;\n      dfs(A, i, visited, N);\n    }\n  }\n\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<int> count(N, 0);\n\tint num_components = 0;\n\n\t// Traverse the graph\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, i, visited, count);\n\t\t\tnum_components++;\n\t\t}\n\t}\n\n\treturn num_components;\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n\n    std::function<void(size_t)> dfs = [&dfs, &visited, &count, &A, N](size_t node) {\n        visited[node] = true;\n        ++count;\n\n        for (size_t i = 0; i < N; ++i) {\n            if (!visited[i] && A[node * N + i]) {\n                dfs(i);\n            }\n        }\n    };\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            dfs(i);\n        }\n    }\n\n    return count;\n}",
            "/*\n     * Your code here\n     */\n    // If the node is not visited\n    // Mark it as visited\n    // Make DFS call for all the adjacent nodes\n    // O(N^2)\n    // vector<bool> visited(N, false);\n    // int components = 0;\n    // for (int i = 0; i < N; ++i) {\n    //     if (visited[i]) {\n    //         continue;\n    //     }\n    //     dfs(A, i, visited);\n    //     ++components;\n    // }\n    // return components;\n\n    // BFS\n    // O(N)\n    vector<bool> visited(N, false);\n    int components = 0;\n    for (int i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            bfs(A, i, visited);\n            ++components;\n        }\n    }\n    return components;\n}",
            "std::vector<int> parent(N, -1);\n\tauto find = [&](int u) {\n\t\tif (parent[u] == -1)\n\t\t\treturn u;\n\t\tint v = find(parent[u]);\n\t\tparent[u] = v;\n\t\treturn v;\n\t};\n\tfor (size_t u = 0; u < N; ++u)\n\t\tfor (size_t v = 0; v < N; ++v)\n\t\t\tif (A[u * N + v]) {\n\t\t\t\tint root_u = find(u);\n\t\t\t\tint root_v = find(v);\n\t\t\t\tif (root_u!= root_v)\n\t\t\t\t\tparent[root_u] = root_v;\n\t\t\t}\n\n\tint count = 0;\n\tfor (size_t u = 0; u < N; ++u)\n\t\tif (parent[u] == -1)\n\t\t\t++count;\n\n\treturn count;\n}",
            "int visited = 0;\n\tstd::vector<int> explored(N, 0);\n\t// std::vector<int> stack;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (explored[i] == 0) {\n\t\t\t// stack.push_back(i);\n\t\t\t++visited;\n\t\t\texplore(A, explored, i, N);\n\t\t}\n\t}\n\n\treturn visited;\n}",
            "std::vector<int> visited(N);\n\n  std::function<void(int)> dfs = [&](int vertex) {\n    visited[vertex] = true;\n    for (int i = 0; i < N; i++) {\n      if (A[N * vertex + i] &&!visited[i]) {\n        dfs(i);\n      }\n    }\n  };\n\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      dfs(i);\n      count++;\n    }\n  }\n\n  return count;\n}",
            "if (N == 0)\n\t\treturn 0;\n\n\tint num_components = 0;\n\tstd::vector<int> visited(N);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tnum_components++;\n\t\t\tbfs(A, i, visited);\n\t\t}\n\t}\n\n\treturn num_components;\n}",
            "std::vector<int> v(N, -1);\n  std::vector<int> component(1);\n  int index = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (v[i] == -1) {\n      component[0] = 0;\n      DFS(A, i, &v, &component, &index);\n    }\n  }\n  return index;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\t\t\tdfs(A, N, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "if (A.empty()) return 0;\n\n    std::vector<int> visited(N, 0);\n    int components = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        ++components;\n        std::queue<int> Q;\n        Q.push(i);\n\n        while (!Q.empty()) {\n            int id = Q.front();\n            Q.pop();\n            visited[id] = 1;\n\n            for (size_t j = 0; j < N; ++j) {\n                if (!visited[j] && A[N * id + j] == 1)\n                    Q.push(j);\n            }\n        }\n    }\n\n    return components;\n}",
            "int count = 0;\n\tstd::vector<int> visited(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, visited, N, i);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i]) {\n      continue;\n    }\n    std::queue<size_t> q;\n    q.push(i);\n    visited[i] = true;\n    ++count;\n    while (!q.empty()) {\n      size_t j = q.front();\n      q.pop();\n      for (size_t k = 0; k < N; ++k) {\n        if (A[j * N + k] &&!visited[k]) {\n          q.push(k);\n          visited[k] = true;\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      dfs(A, visited, count, i, N);\n    }\n  }\n\n  return count;\n}",
            "int componentCount = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (A[i * N + i] == 1) {\n      componentCount++;\n\n      std::vector<bool> visited(N);\n      std::vector<int> toVisit = { i };\n\n      while (!toVisit.empty()) {\n        int v = toVisit.back();\n        toVisit.pop_back();\n        visited[v] = true;\n\n        for (int w = 0; w < N; w++) {\n          if (A[v * N + w] == 1 &&!visited[w]) {\n            toVisit.push_back(w);\n          }\n        }\n      }\n    }\n  }\n\n  return componentCount;\n}",
            "// TODO: Your code here\n\tstd::vector<int> components(N);\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 1 && i!= j) {\n\t\t\t\tif (components[i]!= components[j]) {\n\t\t\t\t\tcount--;\n\t\t\t\t\tint min = components[i] < components[j]? components[i] : components[j];\n\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\tif (components[k] == components[j]) {\n\t\t\t\t\t\t\tcomponents[k] = min;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (components[i] == i) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "if (N == 0)\n    return 0;\n\n  std::vector<int> visited(N, 0);\n  int componentCount = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      componentCount++;\n      dfs(A, N, i, visited);\n    }\n  }\n\n  return componentCount;\n}",
            "int numComponents = 0;\n\tstd::vector<bool> visited(N, false);\n\t\n\t// For each node\n\tfor (int i = 0; i < N; i++) {\n\t\t// If we haven't visited it yet\n\t\tif (!visited[i]) {\n\t\t\t// Run DFS starting from node i\n\t\t\tdfs(A, N, visited, i);\n\t\t\tnumComponents++;\n\t\t}\n\t}\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, i, visited);\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int result = 0;\n\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tresult += 1;\n\t\t\tbfs(A, visited, i);\n\t\t}\n\t}\n\n\treturn result;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]!= 0) {\n\t\t\tcontinue;\n\t\t}\n\t\tdfs(A, visited, i, count);\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n    std::vector<bool> visited(N);\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            ++count;\n            dfs(i, A, N, visited);\n        }\n    }\n    return count;\n}",
            "if (N == 0 || A.empty()) {\n        return 0;\n    }\n\n    // Auxiliary vector to track the visitation state.\n    std::vector<int> visited(N, 0);\n\n    // We will use the DFS algorithm.\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            dfs(A, i, visited, N);\n            ++count;\n        }\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n\n\tauto dfs = [&visited](std::vector<int> const& A, size_t N, int start) {\n\t\tif (start >= N)\n\t\t\treturn;\n\n\t\tstd::vector<int> stack;\n\t\tstack.push_back(start);\n\t\tvisited[start] = 1;\n\n\t\twhile (stack.size()) {\n\t\t\tint curr = stack.back();\n\t\t\tstack.pop_back();\n\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[curr * N + j] &&!visited[j]) {\n\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i)\n\t\tif (!visited[i])\n\t\t\tdfs(A, N, i);\n\n\tint count = 0;\n\tfor (auto n : visited)\n\t\tif (n)\n\t\t\t++count;\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\t++count;\n\t\t\tdfs(A, visited, i, N);\n\t\t}\n\t}\n\treturn count;\n}",
            "int count = 0;\n    for (int i = 0; i < N; i++) {\n        if (A[i * N + i] == 0) {\n            count++;\n            DFS(i, A, N);\n        }\n    }\n    return count;\n}",
            "auto adj = createAdjacencyMatrix(A, N);\n    std::vector<int> visited(N, 0);\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (adj[i][0] == 0)\n            continue;\n        if (visited[i] == 1)\n            continue;\n        std::queue<int> q;\n        q.push(i);\n        visited[i] = 1;\n        while (!q.empty()) {\n            int node = q.front();\n            q.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (visited[j] == 1)\n                    continue;\n                if (adj[node][j] == 0)\n                    continue;\n                q.push(j);\n                visited[j] = 1;\n            }\n        }\n        count++;\n    }\n    return count;\n}",
            "/*\n\t\tWe can think of this problem in terms of the number of nodes visited by a DFS traversal.\n\t\tBecause the graph is represented by an adjacency matrix, we can implement DFS by simply\n\t\ttraversing the matrix.\n\n\t\tThe number of connected components in the graph is the number of nodes we can visit in\n\t\ta DFS traversal. To accomplish this, we can simply set the value of the current node to\n\t\tthe value we're searching for.\n\n\t\t1. Create a vector of visited nodes\n\t\t2. Run through the adjacency matrix once to initialize the vector\n\t\t3. Run through the adjacency matrix again, keeping track of connected nodes\n\t\t4. Return the number of connected nodes\n\t*/\n\tint connectedNodes = 0;\n\tstd::vector<int> visited(N, 0);\n\n\t// 1. Initialize the visited vector\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 1 && visited[j]!= 1) {\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t// 2. Loop through the adjacency matrix again\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t// If we encounter a connected node, increment the number of connected nodes\n\t\t\tif (A[i * N + j] == 1 && visited[j] == 1) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tconnectedNodes++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn connectedNodes;\n}",
            "/*\n    Write your code here.\n    */\n    std::vector<int> visited(N);\n    std::stack<int> stack;\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            stack.push(i);\n            while (stack.size()!= 0) {\n                int curr = stack.top();\n                stack.pop();\n                if (!visited[curr]) {\n                    ++count;\n                    visited[curr] = 1;\n                    for (size_t j = 0; j < N; ++j) {\n                        if (A[curr*N + j] == 1 &&!visited[j]) {\n                            stack.push(j);\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return count;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            dfs(A, i, N);\n            count++;\n        }\n    }\n    return count;\n}",
            "int count = 0;\n   std::vector<int> visited(N, 0);\n\n   for (size_t i = 0; i < N; ++i) {\n      if (visited[i]) {\n         continue;\n      }\n      count++;\n      std::queue<int> queue;\n      queue.push(i);\n      visited[i] = 1;\n      while (!queue.empty()) {\n         int node = queue.front();\n         queue.pop();\n         for (int j = 0; j < N; ++j) {\n            if (A[N * node + j] == 1 &&!visited[j]) {\n               queue.push(j);\n               visited[j] = 1;\n            }\n         }\n      }\n   }\n   return count;\n}",
            "std::unordered_map<int, int> componentMap;\n    std::stack<int> stack;\n    int c = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (componentMap.find(i)!= componentMap.end()) {\n            continue;\n        }\n\n        stack.push(i);\n\n        while (!stack.empty()) {\n            int v = stack.top();\n            stack.pop();\n            componentMap[v] = c;\n\n            for (size_t i = 0; i < N; i++) {\n                if (A[N * v + i] == 1 && componentMap.find(i) == componentMap.end()) {\n                    stack.push(i);\n                }\n            }\n        }\n\n        c++;\n    }\n\n    return c;\n}",
            "// if the matrix is empty return 0\n\tif (N == 0) {\n\t\treturn 0;\n\t}\n\n\t// find the number of connected components in the graph defined by A\n\tstd::vector<int> visited(N, 0); // create a vector to keep track of the nodes we've already visited\n\tint connectedComponents = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// if the current node has not been visited, use a DFS to traverse the graph\n\t\tif (visited[i] == 0) {\n\t\t\tDFS(A, visited, i);\n\t\t\tconnectedComponents++;\n\t\t}\n\t}\n\n\treturn connectedComponents;\n}",
            "// Initialize visited array and set all elements to 0\n\tstd::vector<int> visited(N);\n\tfor(int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\t// Initialize the count of connected components as 0\n\tint count = 0;\n\t// Visit each vertex and do a dfs traversal to find the number of connected components\n\tfor(int i = 0; i < N; i++) {\n\t\tif(visited[i] == 0) {\n\t\t\tdfs(A, visited, i, N);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// create a vector of size N and initialize it to 0\n\tstd::vector<int> v(N, 0);\n\t// traverse the matrix\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\t// if the ith entry and the jth entry of the matrix is 1 and \n\t\t\t// the ith and the jth entries in the vector are different,\n\t\t\t// set the jth entry of the vector to the ith entry\n\t\t\tif (A[N*i + j] == 1 && v[i]!= v[j]) {\n\t\t\t\tv[j] = v[i];\n\t\t\t}\n\t\t}\n\t}\n\t// find the number of unique entries in the vector\n\tstd::set<int> set;\n\tfor (int i = 0; i < N; i++) {\n\t\tset.insert(v[i]);\n\t}\n\treturn set.size();\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\t\t\tvisitComponent(A, i, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "if (A.empty()) return 0;\n\tif (N == 1) return 1;\n\n\t// Check whether there are any cycles in the graph.\n\t// If there are, we will not be able to calculate\n\t// the number of connected components.\n\tbool hasCycle = false;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tstd::vector<bool> visited(N, false);\n\t\tif (checkForCycles(A, N, i, visited, i, hasCycle)) {\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\tif (!hasCycle) {\n\t\t// If there are no cycles, we can calculate the number of connected components.\n\t\tint count = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tstd::vector<bool> visited(N, false);\n\t\t\tcount += checkForCycles(A, N, i, visited, i, hasCycle);\n\t\t}\n\t\treturn count;\n\t}\n\n\t// If there are cycles, we will need to remove them in order to calculate\n\t// the number of connected components.\n\tstd::vector<bool> deleted(N, false);\n\tstd::vector<std::vector<int>> D(N, std::vector<int>(N, 0));\n\tfor (size_t i = 0; i < N; i++) {\n\t\tstd::vector<bool> visited(N, false);\n\t\tdeleted[i] = checkForCycles(A, N, i, visited, i, hasCycle);\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tD[i][j] = A[i][j] &!deleted[i] &!deleted[j];\n\t\t}\n\t}\n\n\t// Now we have the adjacency matrix D which does not contain any cycles.\n\t// We can use BFS to count the number of connected components.\n\t// Each connected component is a tree, so we can use a similar approach\n\t// as in the number of islands problem.\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!deleted[i]) {\n\t\t\tcount++;\n\t\t\tstd::queue<int> queue;\n\t\t\tqueue.push(i);\n\t\t\twhile (!queue.empty()) {\n\t\t\t\tint current = queue.front();\n\t\t\t\tqueue.pop();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (D[current][j] &&!deleted[j]) {\n\t\t\t\t\t\tqueue.push(j);\n\t\t\t\t\t\tdeleted[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int components = 0;\n    std::vector<bool> visited(N, false);\n    std::vector<int> neighbours;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) {\n            continue;\n        }\n\n        visited[i] = true;\n        components++;\n\n        neighbours = getNeighbours(i, A, N);\n\n        for (auto const& j : neighbours) {\n            if (!visited[j]) {\n                visited[j] = true;\n            }\n        }\n    }\n\n    return components;\n}",
            "// TODO: Replace this code with a faster implementation\n\tstd::vector<bool> v(N);\n\tstd::queue<int> q;\n\tint components = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (v[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\t++components;\n\t\tv[i] = true;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint cur = q.front();\n\t\t\tq.pop();\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[cur * N + j] &&!v[j]) {\n\t\t\t\t\tv[j] = true;\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn components;\n}",
            "// Write your code here.\n  std::vector<bool> visited(N, false);\n  int connectedComponents = 0;\n  for (int i = 0; i < N; ++i) {\n    if (visited[i]) {\n      continue;\n    }\n    ++connectedComponents;\n    std::queue<int> q;\n    q.push(i);\n    while (!q.empty()) {\n      int cur = q.front();\n      q.pop();\n      visited[cur] = true;\n      for (int j = 0; j < N; ++j) {\n        if (!visited[j] && A[cur*N+j] == 1) {\n          q.push(j);\n        }\n      }\n    }\n  }\n  return connectedComponents;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcomponent(A, N, i, visited);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "// Write your code here.\n    std::vector<bool> visited(N, false);\n    int count = 0;\n\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            std::queue<int> Q;\n            Q.push(i);\n\n            while (!Q.empty()) {\n                int curr = Q.front();\n                Q.pop();\n                visited[curr] = true;\n\n                for (int j = 0; j < N; j++) {\n                    if (!visited[j] && A[curr * N + j]) {\n                        Q.push(j);\n                    }\n                }\n            }\n\n            count++;\n        }\n    }\n\n    return count;\n}",
            "// Write your code here.\n\tstd::vector<int> DFS_num(N, 0);\n\tstd::vector<int> DFS_low(N, 0);\n\tint index = 0;\n\tint numOfCC = 0;\n\tstd::stack<int> S;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (DFS_num[i] == 0) {\n\t\t\t// DFS_num[i] = index;\n\t\t\t// DFS_low[i] = index;\n\t\t\t// index++;\n\t\t\tS.push(i);\n\n\t\t\t// if the stack is empty, it means that we've finished exploring the current component\n\t\t\twhile (!S.empty()) {\n\t\t\t\tint v = S.top();\n\t\t\t\tS.pop();\n\n\t\t\t\tif (DFS_num[v] == 0) {\n\t\t\t\t\tDFS_num[v] = index;\n\t\t\t\t\tDFS_low[v] = index;\n\t\t\t\t\tindex++;\n\n\t\t\t\t\t// explore neighbors\n\t\t\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\t\t\tif (A[N * v + i] == 1) {\n\t\t\t\t\t\t\tif (DFS_num[i] == 0) {\n\t\t\t\t\t\t\t\t// DFS_num[i] = index;\n\t\t\t\t\t\t\t\t// DFS_low[i] = index;\n\t\t\t\t\t\t\t\t// index++;\n\t\t\t\t\t\t\t\tS.push(i);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t// update the lowest index in the current connected component\n\t\t\t\t\t\t\t\tDFS_low[v] = std::min(DFS_low[v], DFS_low[i]);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// if the lowest index in the current component is the same as the DFS number of the vertex,\n\t\t\t\t// then this is a root node of the current connected component\n\t\t\t\tif (DFS_low[v] == DFS_num[v]) {\n\t\t\t\t\tnumOfCC++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn numOfCC;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\tstd::function<void(size_t)> dfs = [&dfs, &visited, &A, &count, N](size_t i) {\n\t\tif (visited[i]) return;\n\n\t\tvisited[i] = true;\n\t\tcount++;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) dfs(j);\n\t\t}\n\t};\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tdfs(i);\n\t}\n\n\treturn count;\n}",
            "/*\n    Time Complexity: O(N + (N^2) + (N^2)) = O(N^2)\n    Space Complexity: O(N)\n    */\n\tauto vis = std::vector<bool>(N);\n\tauto count = 0;\n\n\tfor (auto i = 0; i < N; i++) {\n\t\tif (!vis[i]) {\n\t\t\tdfs(i, A, vis, N);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> component(N, 0);\n    int count = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (component[i] == 0) {\n            count++;\n            dfs(component, A, i);\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> adjacency_matrix(N*N);\n    for(size_t i = 0; i < N*N; ++i) {\n        adjacency_matrix[i] = A[i];\n    }\n    std::vector<bool> visited(N, false);\n    int count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(!visited[i]) {\n            count++;\n            dfs(adjacency_matrix, visited, i, N);\n        }\n    }\n    return count;\n}",
            "std::vector<int> comp(N, 0);\n    int count = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                if (comp[i]!= comp[j]) {\n                    comp[j] = comp[i];\n                    ++count;\n                }\n            }\n        }\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n\tint components = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++components;\n\t\t\tvisitComponent(A, visited, i);\n\t\t}\n\t}\n\treturn components;\n}",
            "auto visited = std::vector<bool>(N, false);\n\n\tauto dfs = [&A, N, &visited](size_t vertex) {\n\t\tif (visited[vertex]) {\n\t\t\treturn;\n\t\t}\n\n\t\tvisited[vertex] = true;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[vertex * N + j] &&!visited[j]) {\n\t\t\t\tdfs(j);\n\t\t\t}\n\t\t}\n\t};\n\n\tauto connectedComponents = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i);\n\t\t\t++connectedComponents;\n\t\t}\n\t}\n\n\treturn connectedComponents;\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            visited[i] = true;\n            dfs(A, i, visited);\n            count++;\n        }\n    }\n\n    return count;\n}",
            "int visited[N] = {0};\n\tint count = 0;\n\n\t// BFS starting from each node and check if the node is visited\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = 1;\n\n\t\t\twhile (!q.empty()) {\n\t\t\t\tauto const node = q.front();\n\t\t\t\tq.pop();\n\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[node * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcount++;\n\t\t\tdfs(A, N, visited, i);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<std::vector<size_t>> adj_list(N);\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = i; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        adj_list[i].push_back(j);\n        adj_list[j].push_back(i);\n      }\n    }\n  }\n\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i]) {\n      continue;\n    }\n    ++count;\n    std::queue<size_t> q;\n    q.push(i);\n    while (!q.empty()) {\n      auto node = q.front();\n      q.pop();\n      visited[node] = true;\n      for (auto nbr : adj_list[node]) {\n        if (!visited[nbr]) {\n          q.push(nbr);\n        }\n      }\n    }\n  }\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::queue<int> q;\n\tint components = 0;\n\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(!visited[i]) {\n\t\t\tvisited[i] = 1;\n\t\t\tq.push(i);\n\t\t\tcomponents++;\n\n\t\t\twhile(!q.empty()) {\n\t\t\t\tauto vertex = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\t\tif(A[vertex * N + j] &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn components;\n}",
            "std::vector<int> dfs(N, 0);\n    int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (dfs[i] == 0) {\n            count++;\n            dfs_helper(A, N, dfs, i);\n        }\n    }\n    return count;\n}",
            "std::unordered_map<int, int> index;\n  std::queue<int> q;\n  int i;\n\n  for(i=0; i<N; i++) {\n    if(A[i]!= i) {\n      index.emplace(i,i);\n      q.push(i);\n    }\n  }\n\n  while(!q.empty()) {\n    i = q.front();\n    q.pop();\n    for(size_t j=0; j<N; j++) {\n      if(A[j] == i) {\n        q.push(j);\n        index[j] = index[i];\n      }\n    }\n  }\n\n  for(auto const& [key, val] : index) {\n    std::cout << \"key: \" << key << \" val: \" << val << std::endl;\n  }\n\n  return index.size();\n}",
            "std::vector<int> visited(N, 0);\n    int connected_components = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i] == 0) {\n            dfs(A, visited, N, i, ++connected_components);\n        }\n    }\n    return connected_components;\n}",
            "int count = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tDFS(A, i, visited);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> components(N, 0);\n\tint count = 0;\n\n\tfor (size_t row = 0; row < N; row++) {\n\t\tif (!components[row]) {\n\t\t\tcount++;\n\t\t\tdfs(A, N, row, components);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tint numComponents = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++numComponents;\n\t\t\tdfs(A, i, visited);\n\t\t}\n\t}\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N, false);\n    std::stack<int> components;\n    int numComponents = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            components.push(i);\n            while (!components.empty()) {\n                int current = components.top();\n                components.pop();\n                visited[current] = true;\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[current * N + j] &&!visited[j]) {\n                        components.push(j);\n                    }\n                }\n            }\n            numComponents++;\n        }\n    }\n    return numComponents;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tif(visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tcount++;\n\n\t\tstd::vector<int> queue;\n\t\tqueue.push_back(i);\n\t\tvisited[i] = true;\n\n\t\twhile(!queue.empty()) {\n\t\t\tauto current = queue.back();\n\t\t\tqueue.pop_back();\n\n\t\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\t\tif(!visited[j] && A[current * N + j]) {\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(i, A, visited);\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N);\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        std::queue<int> q;\n        q.push(i);\n        visited[i] = true;\n        while (!q.empty()) {\n            int x = q.front();\n            q.pop();\n            for (size_t y = 0; y < N; ++y) {\n                if (!A[x * N + y]) continue;\n                if (visited[y]) continue;\n                q.push(y);\n                visited[y] = true;\n            }\n        }\n    }\n    return std::count(visited.cbegin(), visited.cend(), true);\n}",
            "// Write your code here\n\n    int c = 0;\n    std::vector<bool> visited(N, false);\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            c++;\n            dfs(A, N, i, visited);\n        }\n    }\n    return c;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> group(N, -1);\n    int groupCount = 0;\n\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            bfs(A, i, visited, group, groupCount);\n        }\n    }\n    return groupCount;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, visited, i, count);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = i; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tint x = 0;\n\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\tif (A[i * N + k] && A[j * N + k]) {\n\t\t\t\t\t\t++x;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (x == N - 1) {\n\t\t\t\t\t++count;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> colors(N);\n\tstd::fill(colors.begin(), colors.end(), 0);\n\tint count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(colors[i] == 0) {\n\t\t\tcolors[i] = 1;\n\t\t\tdfs(i, A, colors, count);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "// Your code here\n}",
            "int count{0};\n\tstd::vector<bool> vis(N);\n\tfor (auto i = 0; i < N; ++i) {\n\t\tif (!vis[i]) {\n\t\t\tdfs(A, i, vis, N);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> stack;\n  int components = 0;\n\n  auto dfs = [&](int v) {\n    stack.push_back(v);\n    visited[v] = true;\n    for (int i = 0; i < N; ++i) {\n      if (A[v * N + i]) {\n        if (!visited[i]) {\n          dfs(i);\n        }\n      }\n    }\n  };\n\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      dfs(i);\n      components++;\n    }\n  }\n\n  return components;\n}",
            "if (N <= 0 || A.size() == 0)\n\t\tthrow std::invalid_argument(\"Input is incorrect\");\n\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(i, visited, A);\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> marked(N);\n\tint count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!marked[i]) {\n\t\t\tdfs(A, N, i, marked, count);\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\n\t// visit all nodes, for each node,\n\t// do a DFS, incrementing a component counter for each\n\t// node that has not been visited\n\tint componentCount = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]!= 1) {\n\t\t\t++componentCount;\n\t\t\tdfs(A, visited, i, N);\n\t\t}\n\t}\n\n\treturn componentCount;\n}",
            "// TODO: implement\n}",
            "std::vector<int> D(N);\n\tstd::vector<bool> visited(N);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tdfs(A, D, visited, i, i);\n\t\t}\n\t}\n\n\t// Count the number of times 1 appears in the array D\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (D[i] == 1) {\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "// First we create a vector of the same size as A\n\t// to keep track of which vertex has already been visited\n\t// and which haven't\n\tstd::vector<int> visited(N, 0);\n\n\t// Keep track of the number of connected components\n\tint connectedComponent = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]) continue;\n\t\tconnectedComponent++;\n\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\twhile (!q.empty()) {\n\t\t\tint vertex = q.front();\n\t\t\tq.pop();\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 &&!visited[j]) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn connectedComponent;\n}",
            "std::vector<int> DFSnum(N, 0);\n\tstd::vector<int> low(N, 0);\n\tstd::vector<int> parent(N, 0);\n\tstd::vector<int> S(N, 0);\n\tstd::vector<int> T(N, 0);\n\tint counter = 0;\n\tint root = 0;\n\tint k = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (DFSnum[i] == 0) {\n\t\t\troot = i;\n\t\t\tk = i;\n\t\t\tDFSnum[i] = 1;\n\t\t\tS[i] = 1;\n\t\t\tT[i] = k;\n\t\t\tlow[i] = k;\n\t\t\tparent[i] = -1;\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j]!= 0 && DFSnum[j] == 0) {\n\t\t\t\t\tDFSnum[j] = 1;\n\t\t\t\t\tS[j] = 1;\n\t\t\t\t\tT[j] = k;\n\t\t\t\t\tlow[j] = k;\n\t\t\t\t\tparent[j] = static_cast<int>(i);\n\t\t\t\t\tk++;\n\t\t\t\t}\n\t\t\t\telse if (A[i * N + j]!= 0 && DFSnum[j]!= 0) {\n\t\t\t\t\tlow[j] = std::min(low[j], DFSnum[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t\twhile (S[root]!= 0) {\n\t\t\t\tT[parent[root]] = std::min(T[parent[root]], low[root]);\n\t\t\t\tif (T[parent[root]] >= DFSnum[root]) {\n\t\t\t\t\tcounter++;\n\t\t\t\t}\n\t\t\t\tS[root] = 0;\n\t\t\t\troot = parent[root];\n\t\t\t}\n\t\t}\n\t}\n\treturn counter;\n}",
            "auto constexpr kZero = 0;\n\tstd::vector<int> visited(N, kZero);\n\n\tint components = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, i, visited, N);\n\t\t\tcomponents++;\n\t\t}\n\t}\n\n\treturn components;\n}",
            "std::vector<int> visited(N, 0);\n\tstd::vector<std::vector<int>> connected(N, std::vector<int>());\n\n\tint count = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tbfs(connected, A, N, visited, i);\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n    std::vector<int> connected(N, 0);\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) {\n            continue;\n        }\n\n        // start a new component\n        ++count;\n        connected[i] = 1;\n        visited[i] = 1;\n        std::queue<int> q;\n        q.push(i);\n\n        while (!q.empty()) {\n            int curr = q.front();\n            q.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (connected[j]) {\n                    continue;\n                }\n\n                if (A[curr * N + j]) {\n                    visited[j] = 1;\n                    connected[j] = 1;\n                    q.push(j);\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> visited(N);\n\n\tauto dfs = [&](auto&& self, int curr) -> void {\n\t\tif (visited[curr]) return;\n\n\t\tvisited[curr] = 1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[curr * N + i]) self(self, i);\n\t\t}\n\t};\n\n\tint comp_count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tcomp_count++;\n\t\t\tdfs(dfs, i);\n\t\t}\n\t}\n\n\treturn comp_count;\n}",
            "std::vector<bool> visited(N);\n  int count = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      dfs(A, i, visited);\n    }\n  }\n\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n  int components = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      components++;\n      dfs(A, visited, i, N);\n    }\n  }\n  return components;\n}",
            "assert(N == A.size() && \"The size of the adjacency matrix must match the input N\");\n\tstd::vector<int> visited(N, false);\n\tint components = 0;\n\n\tstd::function<void(int)> dfs = [&](int node) {\n\t\tif (visited[node]) return;\n\t\tvisited[node] = true;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node*N + i]) dfs(i);\n\t\t}\n\t};\n\tfor (int i = 0; i < N; i++) dfs(i);\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]) components++;\n\t}\n\treturn components;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor(int i = 0; i < N; ++i) {\n\t\tif(visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tdfs(A, visited, i, N);\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N);\n\tint count = 0;\n\tfor(size_t i = 0; i < N; ++i)\n\t\tif(!visited[i]) {\n\t\t\tvisited[i] = true;\n\t\t\tfor(size_t j = 0; j < N; ++j)\n\t\t\t\tif(A[i*N + j])\n\t\t\t\t\tvisited[j] = true;\n\t\t\t++count;\n\t\t}\n\treturn count;\n}",
            "// 1. create a bool vector indicating if a node is visited or not\n  // 2. create a recursive method that:\n  //    - checks the current node for the \"visited\" bool\n  //    - if not visited, then the method recursively calls itself on all the \n  //      connected nodes and marks the \"visited\" bool as true.\n  // 3. return the number of \"visited\" bool that are false at the end of the function.\n\n  // create a visited vector and mark all nodes as not visited.\n  std::vector<bool> visited(N, false);\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      visited[i] = true;\n      dfs(A, i, visited, N);\n    }\n  }\n\n  return count;\n}",
            "std::vector<int> visited(N);\n  std::queue<int> q;\n  int num_components = 0;\n\n  for (int i = 0; i < N; ++i) {\n    if (visited[i])\n      continue;\n    num_components++;\n    visited[i] = 1;\n    q.push(i);\n    while (!q.empty()) {\n      auto current = q.front();\n      q.pop();\n\n      for (int j = 0; j < N; ++j) {\n        if (A[current * N + j] &&!visited[j]) {\n          visited[j] = 1;\n          q.push(j);\n        }\n      }\n    }\n  }\n\n  return num_components;\n}",
            "int count = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, i, N, visited);\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "// your code here\n  return 0;\n}",
            "int count = 0;\n  std::vector<bool> visited(N, false);\n\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      ++count;\n      dfs(i, A, visited);\n    }\n  }\n\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\tdfs(A, visited, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> components(N, -1);\n\n    for (int i = 0; i < N; i++) {\n        if (components[i]!= -1) {\n            continue;\n        }\n        std::queue<int> q;\n        q.push(i);\n        components[i] = i;\n        while (!q.empty()) {\n            int u = q.front();\n            q.pop();\n            for (int v = 0; v < N; v++) {\n                if (u == v) {\n                    continue;\n                }\n                if (A[u * N + v]) {\n                    q.push(v);\n                    components[v] = i;\n                }\n            }\n        }\n    }\n\n    int componentCount = 0;\n    for (int i = 0; i < N; i++) {\n        if (components[i] == -1) {\n            componentCount++;\n        }\n    }\n\n    return componentCount;\n}",
            "if (A.empty()) {\n    throw std::domain_error(\"The input matrix is empty\");\n  }\n  if (N == 0) {\n    throw std::domain_error(\"The input matrix is empty\");\n  }\n\n  std::vector<int> visited(N, 0);\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      count++;\n      std::queue<int> q;\n      q.push(i);\n      while (!q.empty()) {\n        int cur = q.front();\n        q.pop();\n        visited[cur] = 1;\n        for (size_t j = 0; j < N; ++j) {\n          if (visited[j] == 0 && A[cur * N + j]) {\n            q.push(j);\n          }\n        }\n      }\n    }\n  }\n  return count;\n}",
            "// The adjacency matrix is symmetric, so we only need to consider one half.\n    // Each row in the matrix contains the number of connected edges between that\n    // node and all the other nodes. If the number of edges between the node and\n    // another node is zero, we know that the two nodes are not connected. If it\n    // is non-zero, we know that there is a path between the two nodes.\n    // If we know the number of connected nodes, we can get the number of\n    // components in the graph by subtracting the number of nodes from N.\n    int num_connected_nodes = 0;\n\n    for (size_t row = 0; row < N; ++row) {\n        for (size_t col = 0; col < N; ++col) {\n            if (A[row * N + col]) {\n                ++num_connected_nodes;\n            }\n        }\n    }\n\n    return N - num_connected_nodes;\n}",
            "// create a vector of bools, one for each row\n  std::vector<bool> rows(N, false);\n  std::vector<bool> cols(N, false);\n  int count = 0;\n  // traverse all the rows in A\n  for (size_t row = 0; row < N; ++row) {\n    // if the row is not yet visited, visit the column at each 1\n    if (!rows[row]) {\n      rows[row] = true;\n      for (size_t col = 0; col < N; ++col) {\n        // if there is a 1 in the current row, and we haven't visited this column,\n        // then we have found a new component, so increment the count\n        if (A[row * N + col] &&!cols[col]) {\n          ++count;\n          cols[col] = true;\n        }\n      }\n    }\n  }\n  return count;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tstd::queue<int> Q;\n\t\tQ.push(i);\n\t\tvisited[i] = true;\n\t\tcount++;\n\n\t\twhile (!Q.empty()) {\n\t\t\tint curr = Q.front();\n\t\t\tQ.pop();\n\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[curr * N + j] &&!visited[j]) {\n\t\t\t\t\tQ.push(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N);\n\tstd::vector<int> cmp;\n\tstd::queue<int> queue;\n\n\tstd::for_each(visited.begin(), visited.end(), [](bool& item) { item = false; });\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) continue;\n\t\tcmp.push_back(i);\n\t\tvisited[i] = true;\n\t\tqueue.push(i);\n\t\twhile (!queue.empty()) {\n\t\t\tint c = queue.front();\n\t\t\tqueue.pop();\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (!visited[j] && A[j * N + c] == 1) {\n\t\t\t\t\tcmp.push_back(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\tqueue.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn cmp.size();\n}",
            "if (N == 0) return 0;\n\n\tstd::vector<int> visited(N, 0);\n\tstd::queue<int> Q;\n\tint components = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = 1;\n\t\t++components;\n\t\tQ.push(i);\n\t\twhile (!Q.empty()) {\n\t\t\tint curr = Q.front();\n\t\t\tQ.pop();\n\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (visited[j]) continue;\n\t\t\t\tif (A[curr * N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tQ.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn components;\n}",
            "if (N == 0) return 0;\n    std::vector<int> visited(N, 0);\n    int components = 0;\n    for (size_t i = 0; i < N; ++i) {\n        if (!visited[i]) {\n            ++components;\n            dfs(A, N, visited, i);\n        }\n    }\n    return components;\n}",
            "auto vis = std::vector<bool>(N);\n\tstd::vector<int> stack;\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!vis[i]) {\n\t\t\tstack.push_back(i);\n\t\t\tvis[i] = true;\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tauto current = stack.back();\n\t\t\t\tstack.pop_back();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[current * N + j] == 1 &&!vis[j]) {\n\t\t\t\t\t\tstack.push_back(j);\n\t\t\t\t\t\tvis[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<int> component(N, 0); // components vector\n\tstd::queue<int> Q; // the nodes of the current component\n\n\tint index = 0; // the current component index\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i]!= 0) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tcomponent[i] = ++index; // give the current component an id\n\t\tQ.push(i); // push the current node in the queue\n\n\t\twhile (!Q.empty()) {\n\t\t\tsize_t node = Q.front();\n\t\t\tQ.pop();\n\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[node*N + j] == 1) {\n\t\t\t\t\tif (component[j]!= 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\n\t\t\t\t\tcomponent[j] = index; // give all connected nodes of the current node the same id\n\t\t\t\t\tQ.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn index;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\tint count = 0;\n\tstd::vector<bool> visited(N);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\tvisited[i] = true;\n\t\twhile (!q.empty()) {\n\t\t\tint j = q.front();\n\t\t\tq.pop();\n\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\tif (A[i * N + k] &&!visited[k]) {\n\t\t\t\t\tq.push(k);\n\t\t\t\t\tvisited[k] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t++count;\n\t}\n\treturn count;\n}",
            "if (A.size() == 0) {\n    return 0;\n  }\n\n  std::queue<size_t> Q;\n  std::vector<bool> visited(N, false);\n  size_t count = 0;\n\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      Q.push(i);\n      count += 1;\n\n      while (!Q.empty()) {\n        size_t row = Q.front();\n        Q.pop();\n\n        for (size_t j = 0; j < N; ++j) {\n          if (!visited[j] && A[row * N + j]) {\n            Q.push(j);\n            visited[j] = true;\n          }\n        }\n      }\n    }\n  }\n\n  return count;\n}",
            "if (A.size()!= N * N)\n\t\tthrow std::invalid_argument(\"Size of A does not match N\");\n\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> parents(N, 0);\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i])\n\t\t\tcontinue;\n\t\t// Depth first search\n\t\tstd::stack<size_t> stack;\n\t\tstack.push(i);\n\t\twhile (!stack.empty()) {\n\t\t\tauto u = stack.top();\n\t\t\tstack.pop();\n\t\t\tvisited[u] = true;\n\t\t\t// Mark all unvisited neighbors as children of u.\n\t\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\t\tif (A[v * N + u] &&!visited[v]) {\n\t\t\t\t\tparents[v] = u;\n\t\t\t\t\tstack.push(v);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t// Build the equivalence class by following the parents.\n\tstd::vector<int> counts(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i])\n\t\t\tcounts[i] = i;\n\t\telse {\n\t\t\t// i is an unreachable vertex, but may have a parent.\n\t\t\tauto parent = parents[i];\n\t\t\tif (parent == 0)\n\t\t\t\tcontinue;\n\t\t\twhile (visited[parent])\n\t\t\t\tparent = parents[parent];\n\t\t\tcounts[i] = parent;\n\t\t}\n\t}\n\tint count = 0;\n\tfor (auto x : counts)\n\t\tif (x > 0)\n\t\t\t++count;\n\treturn count;\n}",
            "// TODO: Implement me\n\treturn 0;\n}",
            "int components = 0;\n    std::vector<int> visited(N, 0);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]!= 0) {\n            continue;\n        }\n\n        std::stack<int> S;\n        S.push(i);\n        visited[i] = 1;\n\n        while (!S.empty()) {\n            int u = S.top();\n            S.pop();\n\n            for (size_t v = 0; v < N; ++v) {\n                if (A[u * N + v]!= 0 && visited[v] == 0) {\n                    S.push(v);\n                    visited[v] = 1;\n                }\n            }\n        }\n\n        components += 1;\n    }\n\n    return components;\n}",
            "std::vector<int> vis(N, 0);\n\tstd::vector<int> stack;\n\tstack.push_back(0);\n\tvis[0] = 1;\n\tint count = 1;\n\twhile (stack.size() > 0) {\n\t\tint v = stack.back();\n\t\tstack.pop_back();\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[v * N + i] == 1 && vis[i] == 0) {\n\t\t\t\tvis[i] = 1;\n\t\t\t\tstack.push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (vis[i] == 0) {\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visted(N, false);\n  std::stack<int> toVisit;\n  int components = 0;\n  for(size_t i = 0; i < N; i++) {\n    if(!visted[i]) {\n      toVisit.push(i);\n      components++;\n      while(!toVisit.empty()) {\n        int const vertex = toVisit.top();\n        toVisit.pop();\n        if(!visted[vertex]) {\n          visted[vertex] = true;\n          for(size_t j = 0; j < N; j++) {\n            if(A[vertex * N + j] == 1) {\n              toVisit.push(j);\n            }\n          }\n        }\n      }\n    }\n  }\n  return components;\n}",
            "if (A.size()!= N * N) {\n        throw std::invalid_argument(\"The matrix is not valid\");\n    }\n\n    std::vector<int> connected(N, 0);\n    int count = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        if (connected[i] == 0) {\n            std::queue<int> q;\n            q.push(i);\n            connected[i] = 1;\n            while (!q.empty()) {\n                auto x = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[i * N + j] && connected[j] == 0) {\n                        connected[j] = 1;\n                        q.push(j);\n                    }\n                }\n            }\n            count++;\n        }\n    }\n\n    return count;\n}",
            "std::vector<int> visited(N);\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tvisited[i] = 1;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[N*node + j]) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "if (N <= 1) {\n    return 1;\n  }\n  int components = 0;\n  std::unordered_set<int> explored;\n  for (int i = 0; i < N; i++) {\n    if (explored.find(i)!= explored.end()) {\n      continue;\n    }\n    dfs(i, A, N, explored);\n    components++;\n  }\n  return components;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\tdfs(A, visited, i);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n    for(size_t i = 0; i < N; ++i) {\n        if(not visited[i]) {\n            ++count;\n            dfs(i, A, visited);\n        }\n    }\n    return count;\n}",
            "std::vector<int> visited(N, 0);\n\tint c = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\t++c;\n\t\t\tdfs(A, N, visited, i);\n\t\t}\n\t}\n\n\treturn c;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "hip",
        "prompt": "/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n\t Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void componentCount(const int *A, size_t N, int *numComponents) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "__shared__ int smem[256];\n  const int gid = blockIdx.x*blockDim.x + threadIdx.x;\n  const int tid = threadIdx.x;\n  int components = 0;\n\n  // Load the data into the shared memory\n  if (gid < N) {\n    smem[tid] = A[gid];\n  } else {\n    smem[tid] = 0;\n  }\n\n  __syncthreads();\n\n  // Scan the shared memory\n  int offset = 1;\n  for (int d = blockDim.x/2; d > 0; d/=2) {\n    __syncthreads();\n    if (tid < d) {\n      smem[tid] += smem[tid + d];\n    }\n    offset *= 2;\n  }\n\n  if (tid == 0) {\n    atomicAdd(numComponents, smem[0]);\n  }\n}",
            "// Get the index of the thread\n\tint idx = blockIdx.x * blockDim.x + threadIdx.x;\n\t// Get the index of the component the thread is in\n\tint compIdx = 0;\n\t// Initialize the component vector\n\tint *component = (int *)malloc(N * sizeof(int));\n\t// Initialize the component vector\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponent[i] = 0;\n\t}\n\tif (idx < N) {\n\t\tcomponent[idx] = idx;\n\t}\n\t// Mark all adjacent components as the same\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[idx * N + j] == 1) {\n\t\t\t\tcomponent[i] = j;\n\t\t\t}\n\t\t}\n\t}\n\t// Find the max component\n\tfor (int i = 0; i < N; i++) {\n\t\tif (compIdx < component[i]) {\n\t\t\tcompIdx = component[i];\n\t\t}\n\t}\n\t// Add to the number of components\n\tatomicAdd(numComponents, 1);\n}",
            "// TODO\n}",
            "// Initialize the component count to zero.\n\t*numComponents = 0;\n\n\t// Perform a breadth-first search on the graph, and increment the count for each connected component.\n\t// If the number of components is more than 1, then return early.\n\t// If the number of components is 1, we know that we've visited every vertex in the graph, and the search is complete.\n\tfor (int i = 0; i < N; i++) {\n\t\tint currComponent = 0;\n\t\tif (A[i * N + i] == 0) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tint nVisited = 0;\n\t\tint *visited = new int[N];\n\t\tmemset(visited, 0, N * sizeof(int));\n\n\t\tint *queue = new int[N];\n\t\tqueue[0] = i;\n\t\tvisited[i] = 1;\n\t\tnVisited++;\n\n\t\twhile (nVisited!= 0) {\n\t\t\tint curr = queue[0];\n\t\t\tnVisited--;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[curr * N + j] == 1) {\n\t\t\t\t\tif (visited[j] == 0) {\n\t\t\t\t\t\tqueue[nVisited] = j;\n\t\t\t\t\t\tnVisited++;\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tdelete[] visited;\n\t\tdelete[] queue;\n\n\t\tif (currComponent == 1) {\n\t\t\t*numComponents += 1;\n\t\t}\n\t}\n}",
            "int myId = blockDim.x * blockIdx.x + threadIdx.x;\n  int myStart = myId * N;\n  int myEnd = myStart + N;\n  int num = 0;\n  for (int j = myStart; j < myEnd; ++j) {\n    if (A[j] == 1) {\n      num++;\n      break;\n    }\n  }\n  *numComponents = num;\n}",
            "__shared__ int count[256];\n  __shared__ int component[256];\n\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int bid = blockIdx.x;\n  int offset = gridDim.x * blockDim.x;\n\n  if (tid < N) {\n    component[tid] = 0;\n    count[tid] = 0;\n  }\n  __syncthreads();\n\n  while (tid < N) {\n    if (A[tid * N + bid] == 1) {\n      if (count[bid] == 0) {\n        component[bid] = component[tid];\n        count[bid] = count[tid];\n      } else {\n        if (component[tid]!= component[bid]) {\n          if (count[component[tid]] > count[component[bid]]) {\n            component[bid] = component[tid];\n            count[bid] = count[tid];\n          } else {\n            component[tid] = component[bid];\n            count[tid] = count[bid];\n          }\n        }\n      }\n    }\n    tid += offset;\n  }\n  __syncthreads();\n\n  if (blockIdx.x == 0) {\n    int total_count = 0;\n    for (int i = 0; i < N; i++) {\n      if (component[i] == 0) {\n        count[i] = 1;\n        total_count++;\n      }\n    }\n    *numComponents = total_count;\n  }\n}",
            "__shared__ int sData[BLOCKSIZE];\n\tint id = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (id >= N) return;\n\tint row = id / N;\n\tint col = id % N;\n\tsData[threadIdx.x] = A[row*N + col];\n\t__syncthreads();\n\tfor (int s = BLOCKSIZE/2; s > 0; s >>= 1) {\n\t\tif (threadIdx.x < s) {\n\t\t\tsData[threadIdx.x] += sData[threadIdx.x + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numComponents, sData[0]);\n\t}\n}",
            "// The id of the thread\n\tconst int id = (blockIdx.x * blockDim.x) + threadIdx.x;\n\n\t// If this thread is inside the matrix\n\tif (id < N) {\n\n\t\t// AMD HIP requires the following sync to prevent race conditions\n\t\t__syncthreads();\n\n\t\t// This thread is the master of the component to which it belongs\n\t\tif (A[id * N + id] == 1) {\n\n\t\t\t// For each row in the matrix\n\t\t\tfor (int i = 0; i < N; i++) {\n\n\t\t\t\t// Explore the adjacent vertices if they have not been visited\n\t\t\t\tif (A[id * N + i] == 1 && id < i) {\n\n\t\t\t\t\t// Find the component master\n\t\t\t\t\tcomponentCount(A, N, numComponents);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// The number of components is equal to the number of masters\n\tif (id < N) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "const int col = threadIdx.x; // Current column\n\tconst int row = blockIdx.x;  // Current row\n\tif (row == col) {\n\t\t// Self-loop. Skip.\n\t\treturn;\n\t}\n\n\t// Initialize the worklist for the BFS with the current row.\n\t__shared__ int s_worklist[1024];\n\ts_worklist[threadIdx.x] = row;\n\n\t// Initialize the visited mask for the BFS.\n\t__shared__ unsigned int s_visited[1024];\n\ts_visited[threadIdx.x] = 0;\n\n\t// Start the BFS.\n\twhile (s_worklist[threadIdx.x] >= 0) {\n\t\t// Get the next node to visit.\n\t\tconst int src = s_worklist[threadIdx.x];\n\t\ts_worklist[threadIdx.x] = -1;\n\n\t\t// Check if we've already visited this node.\n\t\tconst unsigned int mask = (1 << src);\n\t\tif (s_visited[threadIdx.x] & mask) {\n\t\t\t// Already visited. Skip.\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Mark the current node as visited.\n\t\ts_visited[threadIdx.x] |= mask;\n\n\t\t// Iterate over the neighbors.\n\t\tif (A[row * N + src]) {\n\t\t\t// Enqueue the neighbor.\n\t\t\ts_worklist[threadIdx.x] = col;\n\t\t}\n\t}\n\n\t// Sum the visited nodes across the warp.\n\ts_visited[threadIdx.x] = __popc(s_visited[threadIdx.x]);\n\n\t// Add the number of visited nodes to the number of nodes in the current component.\n\tatomicAdd(numComponents, s_visited[threadIdx.x]);\n}",
            "// Each thread computes the component count for the element in the adjacency matrix\n  // defined by the thread's coordinates\n  if (A[blockIdx.x * N + blockIdx.y] == 1) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint num = 0;\n\tint c = 0;\n\tint root = 0;\n\tif(id < N) {\n\t\tif (A[id * N + id] == 1) {\n\t\t\tc = 1;\n\t\t\tfor(int i = id; i < N; i++) {\n\t\t\t\tif (i == id) {\n\t\t\t\t\tcontinue;\n\t\t\t\t} else if (A[id * N + i] == 1) {\n\t\t\t\t\tnum = 0;\n\t\t\t\t\troot = i;\n\t\t\t\t\tfor (int j = i; j < N; j++) {\n\t\t\t\t\t\tif (i == j) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t} else if (A[i * N + j] == 1) {\n\t\t\t\t\t\t\tnum++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (num == c) {\n\t\t\t\t\t\tc++;\n\t\t\t\t\t} else {\n\t\t\t\t\t\troot = i;\n\t\t\t\t\t\tc++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t*numComponents = c;\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid >= N) {\n    return;\n  }\n  __shared__ int sdata[1024];\n  if (A[tid * N + tid]!= 0) {\n    atomicAdd(numComponents, 1);\n    for (int i = 0; i < N; i++) {\n      if (i!= tid) {\n        if (A[tid * N + i]!= 0) {\n          sdata[tid] = 1;\n          break;\n        }\n      }\n    }\n  }\n  __syncthreads();\n  int sum = 0;\n  for (int i = 0; i < blockDim.x; i++) {\n    sum += sdata[i];\n  }\n  if (tid == 0) {\n    atomicAdd(numComponents, sum);\n  }\n}",
            "int Nblocks = N / blockDim.x;\n  int i = Nblocks * blockIdx.x + threadIdx.x;\n  if (i >= N)\n    return;\n\n  int Nth = N / blockDim.x;\n  int i2 = Nth * blockIdx.x + threadIdx.x;\n\n  int num_components = 0;\n\n  if (A[i * N + i] == 1) {\n    for (int j = 0; j < N; ++j) {\n      if (j == i) {\n        continue;\n      }\n      if (A[i2 * N + j] == 1) {\n        if (atomicCAS(&A[i2 * N + j], 1, 0) == 1) {\n          num_components++;\n        }\n      }\n    }\n  }\n\n  atomicAdd(numComponents, num_components);\n}",
            "const int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (gid >= N) return;\n\n  for (int i = 0; i < N; i++) {\n    // TODO: if we can assume that the graph is symmetric, we could skip half of\n    // the comparisons by only considering the elements in the upper triangular\n    // matrix.\n    if (A[gid * N + i]) {\n      atomicAdd(numComponents, 1);\n      break;\n    }\n  }\n}",
            "__shared__ bool connected[32];\n\tconst int threadId = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (threadId >= N) return;\n\tconnected[threadIdx.x] = false;\n\t__syncthreads();\n\n\tint n = 0;\n\twhile (A[threadId + N * n]!= -1) {\n\t\tif (A[threadId + N * n] > threadId) {\n\t\t\tconnected[threadIdx.x] = true;\n\t\t}\n\t\tn++;\n\t}\n\n\t__syncthreads();\n\tint nthreads = blockDim.x * gridDim.x;\n\tif (threadIdx.x == 0) {\n\t\tn = 0;\n\t\tfor (int i = 0; i < nthreads; i++) {\n\t\t\tn += connected[i];\n\t\t}\n\t\tatomicAdd(numComponents, n);\n\t}\n}",
            "const size_t row = blockIdx.y*blockDim.y + threadIdx.y;\n  const size_t col = blockIdx.x*blockDim.x + threadIdx.x;\n\n  __shared__ int sdata[MAX_BLOCK_SIZE][MAX_BLOCK_SIZE];\n  int sum = 0;\n  if (row < N && col < N) {\n    sdata[threadIdx.y][threadIdx.x] = A[row*N + col];\n  }\n\n  __syncthreads();\n\n  if (row < N && col < N) {\n    for (int i = 0; i < blockDim.x; i++) {\n      sum += sdata[threadIdx.y][i];\n    }\n\n    for (int i = 0; i < blockDim.y; i++) {\n      sum += sdata[i][threadIdx.x];\n    }\n\n    atomicAdd(numComponents, sum);\n  }\n}",
            "unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n    unsigned int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i >= N || j >= N || i == j)\n        return;\n    __shared__ int cache[BLOCKDIM_X][BLOCKDIM_Y];\n    int c = 0;\n    if (A[i*N + j]!= 0) {\n        int i0 = i;\n        int j0 = j;\n        cache[threadIdx.x][threadIdx.y] = 1;\n        __syncthreads();\n        while (i0 < N && j0 < N && cache[i0 % BLOCKDIM_X][j0 % BLOCKDIM_Y] == 1) {\n            int t = i0 * N + j0;\n            A[t] = 0;\n            c++;\n            i0 = j0;\n            j0 = A[t];\n        }\n    }\n    atomicAdd(numComponents, c);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id < N) {\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + id] > 0) {\n        count++;\n      }\n    }\n    if (count == 0) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "const int row = blockIdx.x;\n  const int col = blockIdx.y;\n\n  if (row == col && A[row * N + col] == 1) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "const unsigned int row = blockDim.y * blockIdx.y + threadIdx.y;\n\tconst unsigned int col = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t__shared__ bool visited[BLOCKSIZE][BLOCKSIZE];\n\t__shared__ int count[BLOCKSIZE][BLOCKSIZE];\n\n\tvisited[threadIdx.y][threadIdx.x] = false;\n\tcount[threadIdx.y][threadIdx.x] = 0;\n\n\t__syncthreads();\n\n\tif (row < N && col < N) {\n\t\tif (!visited[threadIdx.y][threadIdx.x] && A[row * N + col]) {\n\t\t\tvisited[threadIdx.y][threadIdx.x] = true;\n\t\t\tcount[threadIdx.y][threadIdx.x] = 1;\n\t\t\tdfs(A, N, row, col, threadIdx.y, threadIdx.x, visited, count);\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n  if (id >= N) return;\n\n  if (A[id * N + id] == 1) {\n    int i = id;\n    int idComponent = i;\n    while (i < N) {\n      if (A[idComponent * N + i] == 1) {\n        i++;\n      } else {\n        i = N;\n      }\n    }\n    atomicAdd(numComponents, 1);\n  }\n}",
            "int row = threadIdx.x;\n  int col = blockIdx.x;\n  int numComponents = 0;\n  if (A[row * N + col]) {\n    // printf(\"connected %d %d\\n\", row, col);\n    numComponents++;\n  }\n  atomicAdd(numComponents, 1);\n}",
            "int tid = blockDim.x*blockIdx.y*gridDim.x\n\t\t\t  + blockDim.x*blockIdx.x\n\t\t\t  + threadIdx.x;\n\n\t__shared__ int scc[MAX_GRID_DIM][MAX_GRID_DIM];\n\t__shared__ int scc_id[MAX_GRID_DIM][MAX_GRID_DIM];\n\n\t// initialize the shared mem\n\tif(threadIdx.x == 0) {\n\t\tfor(int j = 0; j < gridDim.x; j++) {\n\t\t\tfor(int i = 0; i < gridDim.x; i++) {\n\t\t\t\tscc[i][j] = 0;\n\t\t\t\tscc_id[i][j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tint start_row = blockIdx.y * blockDim.x * gridDim.x + threadIdx.x;\n\tint start_col = blockIdx.x * blockDim.x * gridDim.x + threadIdx.x;\n\n\tint row = start_row;\n\tint col = start_col;\n\n\tint my_scc = 0;\n\tint my_scc_id = 0;\n\tint id = 0;\n\t// perform DFS\n\tfor(int i = 0; i < N; i++) {\n\t\tif(A[row*N + col] == 1) {\n\t\t\tif(row < col) {\n\t\t\t\tmy_scc_id = scc_id[row/gridDim.x][col/gridDim.x];\n\t\t\t} else {\n\t\t\t\tmy_scc_id = scc_id[col/gridDim.x][row/gridDim.x];\n\t\t\t}\n\t\t\tif(my_scc_id == 0) {\n\t\t\t\tid++;\n\t\t\t\tDFS(A, row, col, gridDim.x, &my_scc, &my_scc_id, scc, scc_id, &id);\n\t\t\t}\n\t\t}\n\t\t// go to next position\n\t\tif(row == N-1) {\n\t\t\trow = 0;\n\t\t\tcol++;\n\t\t} else {\n\t\t\trow++;\n\t\t}\n\t}\n\n\t// update the result\n\tatomicAdd(numComponents, my_scc);\n}",
            "const int rowIdx = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int colIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int stride = blockDim.x * gridDim.x;\n\n\tint myNumComponents = 0;\n\n\tfor (int i = rowIdx; i < N; i += stride) {\n\t\tif (A[colIdx + i * N])\n\t\t\tmyNumComponents++;\n\t}\n\n\tatomicAdd(numComponents, myNumComponents);\n}",
            "// TODO\n}",
            "// Use an atomic add to increment the value at numComponents\n    // Note: you may need to change this based on your device\n    atomicAdd(numComponents, 0);\n\n    // Fill in this function\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index >= N * N)\n    return;\n  int row = index / N;\n  int col = index % N;\n  if (A[row * N + col])\n    atomicAdd(numComponents, 1);\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (x >= N || y >= N) return;\n\n\tif (A[x + y*N] == 1 && x < y) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "const unsigned int tid = blockDim.x*blockIdx.x + threadIdx.x;\n\tif (tid < N*N) {\n\t\tconst unsigned int i = tid / N;\n\t\tconst unsigned int j = tid % N;\n\t\tif (i < N && A[tid] > 0) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "/* The row/col coordinate of the thread. */\n  int x = threadIdx.x + blockIdx.x * blockDim.x;\n  int y = threadIdx.y + blockIdx.y * blockDim.y;\n\n  /* Return if this is a thread that is not assigned to a valid point. */\n  if (x >= N || y >= N)\n    return;\n\n  /* The component id of the current thread. */\n  int id = A[x * N + y];\n\n  /* The number of threads in the current thread block. */\n  int numThreads = blockDim.x * blockDim.y;\n\n  /* The number of threads in each thread block. */\n  int numBlockThreads = blockDim.x * blockDim.y;\n\n  /* The number of thread blocks in the current grid. */\n  int numBlocks = gridDim.x * gridDim.y;\n\n  /* The number of points that have not been counted. */\n  int numUncounted = 1;\n\n  /* The size of the queue. */\n  int queueSize = 1;\n\n  /* The queue. */\n  int queue[numBlockThreads];\n\n  /* Set the first element of the queue to the current thread. */\n  queue[0] = id;\n\n  /* The number of iterations. */\n  int numIters = 0;\n\n  /* Process the elements in the queue. */\n  while (queueSize > 0 && numUncounted > 0) {\n    /* Number of threads to process in this iteration. */\n    int numThreadsToProcess = min(queueSize, numBlockThreads);\n\n    /* Number of points in the queue that have not been processed. */\n    int numUnprocessed = 0;\n\n    /* Number of points in the queue that have not been marked as visited. */\n    int numUnvisited = 0;\n\n    /* Process each element of the queue. */\n    for (int i = 0; i < numThreadsToProcess; i++) {\n      /* Get the current queue element. */\n      int q = queue[i];\n\n      /* Process all the neighbors of the current element. */\n      for (int j = 0; j < N; j++) {\n        /* Get the neighbor. */\n        int n = A[q * N + j];\n\n        /* Check if the neighbor has not been visited. */\n        if (n!= -1) {\n          /* Check if the neighbor has not been processed. */\n          if (n!= id) {\n            /* Update the number of points that have not been processed. */\n            numUnprocessed++;\n\n            /* Check if the neighbor is not in the current component. */\n            if (n!= id) {\n              /* Update the number of points that have not been marked as visited. */\n              numUnvisited++;\n            }\n          }\n        }\n      }\n    }\n\n    /* Check if all the points in the queue have been processed. */\n    if (numUnprocessed == 0) {\n      /* Update the number of uncounted points. */\n      numUncounted -= queueSize;\n    } else {\n      /* Mark all the unvisited points in the queue as visited. */\n      for (int i = 0; i < numThreadsToProcess; i++) {\n        /* Get the current queue element. */\n        int q = queue[i];\n\n        /* Mark the current point as visited. */\n        A[q * N + q] = -1;\n\n        /* Process all the neighbors of the current element. */\n        for (int j = 0; j < N; j++) {\n          /* Get the neighbor. */\n          int n = A[q * N + j];\n\n          /* Check if the neighbor is not in the current component. */\n          if (n!= -1) {\n            /* Check if the neighbor is not in the current component. */\n            if (n!= id) {\n              /* Mark the current point as visited. */\n              A[n * N + n] = -1;\n            }\n          }\n        }\n      }\n    }\n\n    /* If there are more points that have not been marked as visited. */\n    if (numUnvisited > 0) {\n      /* Update the number of threads to process. */\n      numThreadsToProcess = min(numUnvisited",
            "int index = blockDim.x * blockIdx.y * gridDim.x\t\t//rows preceeding current row in grid\n\t\t\t\t+ blockDim.x * blockIdx.x\t\t\t//blocks preceeding current block\n\t\t\t\t+ threadIdx.x;\n  // printf(\"thread %d index %d\\n\", threadIdx.x, index);\n  // if thread index is within bounds of A, perform computation\n  if (index < N) {\n\tint start = index;\n\t// traverse row, starting at index\n\twhile (A[index + N * index] && index < N) {\n\t  // printf(\"traversing row %d index %d \\n\", index, A[index + N * index]);\n\t  index = A[index + N * index] - 1;\n\t}\n\t// printf(\"final index %d\\n\", index);\n\tif (index == start) {\n\t  atomicAdd(numComponents, 1);\n\t}\n  }\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x;\n\tint y = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (x < N && y < N) {\n\t\tif (A[y * N + x] &&!A[x * N + y]) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// A is an adjacency matrix\n\t// N is the number of rows/columns in A\n\t// numComponents is a shared memory array of length N\n\tint threadIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (threadIdx < N) {\n\t\tnumComponents[threadIdx] = A[threadIdx * N + threadIdx];\n\t}\n\t__syncthreads();\n\tfor (int s = N / 2; s > 0; s /= 2) {\n\t\tif (threadIdx < s) {\n\t\t\tnumComponents[threadIdx] += numComponents[threadIdx + s];\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (threadIdx == 0) {\n\t\tatomicAdd(numComponents, numComponents[0]);\n\t}\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (x >= N || y >= N) return;\n\n  // Do a flood fill starting at each unmarked location (0) and count the number of connected locations\n  if (A[x * N + y] == 0) {\n    int count = 1;\n    A[x * N + y] = 2;\n    int Q[MAX_N_SIZE];\n    int front = 0, rear = 1;\n    Q[0] = x;\n    Q[1] = y;\n\n    while (front < rear) {\n      int i = Q[front];\n      int j = Q[front + 1];\n      if (i > 0 && A[(i - 1) * N + j] == 0) {\n        A[(i - 1) * N + j] = 2;\n        Q[rear] = i - 1;\n        Q[rear + 1] = j;\n        rear += 2;\n        count++;\n      }\n      if (j > 0 && A[i * N + j - 1] == 0) {\n        A[i * N + j - 1] = 2;\n        Q[rear] = i;\n        Q[rear + 1] = j - 1;\n        rear += 2;\n        count++;\n      }\n      if (i < N - 1 && A[(i + 1) * N + j] == 0) {\n        A[(i + 1) * N + j] = 2;\n        Q[rear] = i + 1;\n        Q[rear + 1] = j;\n        rear += 2;\n        count++;\n      }\n      if (j < N - 1 && A[i * N + j + 1] == 0) {\n        A[i * N + j + 1] = 2;\n        Q[rear] = i;\n        Q[rear + 1] = j + 1;\n        rear += 2;\n        count++;\n      }\n      front += 2;\n    }\n\n    atomicAdd(numComponents, count);\n  }\n}",
            "// threadIdx.x is the row, blockIdx.x is the column.\n  int i = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // Find the component index in which this thread is located.\n  int ci = A[blockIdx.x * N + i];\n  // printf(\"thread %d in component %d\\n\", threadIdx.x + blockIdx.x * blockDim.x, ci);\n\n  // First thread in the block is the leader.\n  if (threadIdx.x == 0) {\n    atomicAdd(numComponents, ci);\n  }\n}",
            "// TODO: Replace the following code with parallel GPU code.\n\t// \n\t// In this example, only the threads with id 0 (corresponding to the\n\t// block size) should compute the number of connected components.\n\t// You can use atomic operations to perform a reduction in parallel.\n\tif (blockIdx.x == 0 && blockIdx.y == 0 && threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tint num = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tbool visited[N];\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tvisited[j] = false;\n\t\t\t}\n\t\t\tif (!visited[i]) {\n\t\t\t\tDFS(A, N, visited, i);\n\t\t\t\tnum++;\n\t\t\t}\n\t\t}\n\t\t*numComponents = num;\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  int gridSize = blockDim.x * gridDim.x;\n\n  int start = id * N;\n  int end = (id + 1) * N;\n\n  for (int i = start; i < end; ++i) {\n    int connected = A[i];\n    if (connected > 0) {\n      atomicAdd(numComponents, 1);\n      break;\n    }\n  }\n}",
            "int x = blockIdx.x; // row number\n\tint y = blockIdx.y; // column number\n\n\t__shared__ bool visited[TILE_SIZE][TILE_SIZE];\n\t__shared__ int num_visited[TILE_SIZE];\n\n\tint row = x * TILE_SIZE + threadIdx.x;\n\tint col = y * TILE_SIZE + threadIdx.y;\n\tint index = row * N + col;\n\n\t// mark all nodes as unvisited\n\tif (threadIdx.x == 0)\n\t\tnum_visited[threadIdx.y] = 0;\n\n\t// if row and column are valid (inside matrix) and if the cell is not already visited\n\tif (row < N && col < N && A[index] == 1 &&!visited[threadIdx.y][threadIdx.x]) {\n\t\tvisited[threadIdx.y][threadIdx.x] = true;\n\t\tnum_visited[threadIdx.y]++;\n\t}\n\t__syncthreads();\n\n\t// Count the number of visisted nodes in this block\n\tif (threadIdx.y == 0) {\n\t\tatomicAdd(numComponents, num_visited[threadIdx.x]);\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i, j;\n\t// Only thread 0 of each block is responsible for managing the DFS\n\t// Use a bitset to keep track of what nodes have been visited\n\tint visited[32];\n\tfor (i = 0; i < 32; i++) {\n\t\tvisited[i] = 0;\n\t}\n\t// If the current thread is in bounds, DFS from it\n\tif (id < N) {\n\t\t__shared__ int count;\n\t\tif (threadIdx.x == 0) {\n\t\t\tcount = 0;\n\t\t}\n\t\t__syncthreads();\n\t\tif (bitIsSet(visited, id) == 0) {\n\t\t\tcount += 1;\n\t\t\tbitSet(visited, id);\n\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\t// If the edge is connected, mark the neighbor as visited\n\t\t\t\tif (A[id * N + j] == 1) {\n\t\t\t\t\tif (bitIsSet(visited, j) == 0) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tcomponentCount(A, N, &count);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, count);\n\t}\n}",
            "int i = blockIdx.x;\n  int j = threadIdx.x;\n\n  __shared__ int visited[BLOCK_SIZE];\n  __shared__ int count;\n  __shared__ int totalCount;\n  count = 0;\n  totalCount = 0;\n  if (i < N && j < N) {\n    if (i!= j) {\n      if (A[i * N + j] > 0) {\n        // i and j are connected\n        visited[threadIdx.x] = 1;\n      }\n      else {\n        // i and j are not connected\n        visited[threadIdx.x] = 0;\n      }\n    }\n    else {\n      // i and j are the same\n      visited[threadIdx.x] = 1;\n    }\n  }\n  else {\n    // i or j is out of bounds\n    visited[threadIdx.x] = 0;\n  }\n\n  __syncthreads();\n\n  if (visited[threadIdx.x] == 1) {\n    int id = threadIdx.x;\n    while (id < N) {\n      if (visited[id] == 1) {\n        visited[id] = 0;\n        int id2 = id;\n        while (id2 < N) {\n          if (visited[id2] == 1) {\n            visited[id2] = 0;\n            count++;\n          }\n          id2++;\n        }\n      }\n      id++;\n    }\n  }\n\n  atomicAdd(&totalCount, count);\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicAdd(numComponents, totalCount);\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif(id < N * N) {\n\t\tint r = id / N;\n\t\tint c = id % N;\n\t\tint rowId = r * N;\n\n\t\tif(A[rowId + c] == 1)\n\t\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "// get the global thread index\n\tint i = blockDim.x * blockIdx.y * gridDim.x + blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// if we're out of bounds, do nothing\n\tif (i >= N)\n\t\treturn;\n\n\tint count = 0;\n\tbool visited[N];\n\n\tfor (int j = 0; j < N; j++)\n\t\tvisited[j] = false;\n\n\tvisited[i] = true;\n\tcount = 1;\n\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A[i * N + j]!= 0)\n\t\t\tcount += componentCountHelper(A, N, j, visited);\n\t}\n\n\tatomicAdd(numComponents, count);\n}",
            "int tid = threadIdx.x + blockDim.x * blockIdx.x;\n\n  if (tid < N) {\n\n    int row = tid;\n    int numNeighbors = 0;\n\n    for (int col = 0; col < N; ++col) {\n      // If this is a 1, then tid has a connection to col\n      if (A[row * N + col] > 0) {\n        numNeighbors++;\n      }\n    }\n\n    // This thread has an edge to itself, so it is a component by itself\n    if (numNeighbors == 0) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int *visited = (int*) malloc(N * sizeof(int));\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tvisited[i] = 0;\n\t}\n\t__shared__ int is_visited[TILE_DIM][TILE_DIM];\n\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint id = (by * gridDim.x + bx) * (TILE_DIM * TILE_DIM) + (ty * TILE_DIM) + tx;\n\tint stride = gridDim.x * gridDim.y * (TILE_DIM * TILE_DIM);\n\n\tint component = 0;\n\twhile (id < N) {\n\t\tif (visited[id] == 0 && A[id * N + id] == 1) {\n\t\t\tvisited[id] = 1;\n\t\t\t++component;\n\t\t\tint row = id / N;\n\t\t\tint col = id % N;\n\t\t\tis_visited[ty][tx] = 0;\n\n\t\t\twhile (row < N && col < N) {\n\t\t\t\t// if the node is not visited and is a neighbor\n\t\t\t\tif (visited[row * N + col] == 0 && A[row * N + col] == 1) {\n\t\t\t\t\tis_visited[ty][tx] = 1;\n\t\t\t\t\tvisited[row * N + col] = 1;\n\t\t\t\t\trow = row + N;\n\t\t\t\t} else {\n\t\t\t\t\t// move to next node\n\t\t\t\t\t++row;\n\t\t\t\t\tcol = col + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t\tfor (int j = 0; j < TILE_DIM; ++j) {\n\t\t\t\tfor (int i = 0; i < TILE_DIM; ++i) {\n\t\t\t\t\tif (is_visited[j][i]) {\n\t\t\t\t\t\tint new_row = (by * gridDim.x + bx) * (TILE_DIM * TILE_DIM) + (j * TILE_DIM) + i;\n\t\t\t\t\t\tvisited[new_row] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t\tid += stride;\n\t}\n\n\tatomicAdd(numComponents, component);\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n\tint numThreads = blockDim.x*gridDim.x;\n\tint componentId = id;\n\n\twhile(componentId < N) {\n\t\tif(A[id*N + componentId] == 1) {\n\t\t\t// find the component id\n\t\t\tint parent = find(A, id, componentId);\n\t\t\t// union the two components\n\t\t\tunionComponents(A, id, parent);\n\t\t}\n\t\tcomponentId += numThreads;\n\t}\n\n\tif(threadIdx.x == 0)\n\t\tatomicAdd(numComponents, countComponents(A, N));\n}",
            "// each thread is responsible for a single row\n  int row = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row >= N) return;\n\n  // each thread keeps track of whether it has visited a node that is not itself\n  int visited = 0;\n\n  for (int col = 0; col < N; col++) {\n    if (A[row * N + col] == 1) {\n      visited = 1;\n      break;\n    }\n  }\n\n  // If no neighbors were found, increment the number of components\n  // If we did have neighbors, and they are not ourselves, decrement the number of components\n  if (visited == 0 || row == col)\n    atomicAdd(numComponents, 1);\n  else\n    atomicAdd(numComponents, -1);\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  if(id < N) {\n    for(int i = 0; i < N; i++) {\n      if(A[id * N + i] == 1) {\n        *numComponents += 1;\n        break;\n      }\n    }\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid >= N)\n    return;\n\n  if (A[tid * N + tid] == 0)\n    return;\n\n  int currentComponent = -1;\n  while (A[tid * N + tid] > 0) {\n    currentComponent = A[tid * N + tid];\n    A[tid * N + tid] = 0;\n\n    // search in this row for another component to merge with\n    for (int i = 0; i < N; i++) {\n      if (i == tid)\n        continue;\n\n      if (A[tid * N + i] == currentComponent) {\n        A[tid * N + i] = A[i * N + currentComponent];\n      }\n    }\n\n    // search in this column for another component to merge with\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + tid] == currentComponent) {\n        A[i * N + tid] = A[tid * N + currentComponent];\n      }\n    }\n  }\n\n  if (currentComponent > 0) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "// TODO\n}",
            "// TODO: implement this\n  __shared__ bool sVisited[BLOCK_SIZE];\n  __shared__ int sParent[BLOCK_SIZE];\n\n  int myIdx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (myIdx < N) {\n    sVisited[threadIdx.x] = false;\n    sParent[threadIdx.x] = threadIdx.x;\n  }\n\n  __syncthreads();\n\n  if (myIdx < N) {\n    int cnt = 0;\n    for (int j = 0; j < N; j++) {\n      if (A[myIdx * N + j] == 1) {\n        cnt++;\n      }\n    }\n    if (cnt == 0) {\n      sVisited[threadIdx.x] = true;\n      sParent[threadIdx.x] = threadIdx.x;\n    }\n  }\n\n  __syncthreads();\n\n  for (int i = 0; i < N; i++) {\n    int a = myIdx;\n    int b = threadIdx.x;\n\n    while (sParent[a]!= a) {\n      a = sParent[a];\n    }\n\n    while (sParent[b]!= b) {\n      b = sParent[b];\n    }\n\n    if (a!= b) {\n      if (sVisited[a] == true && sVisited[b] == true) {\n        continue;\n      }\n      if (sVisited[a] == false && sVisited[b] == false) {\n        continue;\n      }\n\n      if (sVisited[a] == false) {\n        sVisited[a] = true;\n        sParent[a] = b;\n      } else {\n        sVisited[b] = true;\n        sParent[b] = a;\n      }\n    }\n\n    __syncthreads();\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (sParent[threadIdx.x] == i) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // If the current cell is 1, then it has a connection.\n    if (i < N && j < N && A[i * N + j]) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "__shared__ bool visited[TOTAL_THREADS];\n\n    for(int i = 0; i < TOTAL_THREADS; i++)\n        visited[i] = false;\n    __syncthreads();\n\n    int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n    int size = N * N;\n\n    if(threadId < size) {\n        if(visited[threadId] == false) {\n            int count = 1;\n            visited[threadId] = true;\n\n            int x = threadId % N;\n            int y = threadId / N;\n\n            // top\n            if(x > 0 && A[threadId - 1] == 1 && visited[threadId - 1] == false) {\n                count++;\n                visited[threadId - 1] = true;\n            }\n\n            // right\n            if(y < N - 1 && A[threadId + N] == 1 && visited[threadId + N] == false) {\n                count++;\n                visited[threadId + N] = true;\n            }\n\n            // bottom\n            if(x < N - 1 && A[threadId + 1] == 1 && visited[threadId + 1] == false) {\n                count++;\n                visited[threadId + 1] = true;\n            }\n\n            // left\n            if(y > 0 && A[threadId - N] == 1 && visited[threadId - N] == false) {\n                count++;\n                visited[threadId - N] = true;\n            }\n\n            atomicAdd(numComponents, count);\n        }\n    }\n}",
            "int blockId = blockIdx.x;\n\tint threadId = blockIdx.y;\n\n\t// For each thread in the block, explore the nodes that it points to and mark them as \"visited\".\n\t// Once a node is visited, it will never be visited again.\n\tfor (int node = threadId; node < N; node += blockDim.y) {\n\n\t\t// If a node has already been visited, skip it.\n\t\tif (A[threadId + node * N] == 0) continue;\n\n\t\t// Mark the node as \"visited\" by setting the adjacency to 0.\n\t\tA[threadId + node * N] = 0;\n\t\tA[node + threadId * N] = 0;\n\n\t\t// Recursively explore other nodes that this node points to.\n\t\tcomponentCount<<<1, N>>>(A, N, numComponents);\n\t}\n\n\t// Once all nodes have been explored, update the counter by 1.\n\tatomicAdd(numComponents, 1);\n}",
            "// TODO: Replace this atomic call with a global counter and a shared memory array.\n    // Use atomicCAS or atomicAdd to set the shared memory array (use a 1-D array)\n    // Use atomicCAS or atomicAdd to increment the global counter numComponents (use a 1-D array)\n    // After the kernel finishes, check that the number of components is correct.\n    // If the number of components is incorrect, then use printf to print out the adjacency matrix\n    // to the screen. This should help you debug.\n    // To test, try running:./a.out 16 8\n    __shared__ int numComponents_shared[1];\n    __shared__ int adjMatrix[16][16];\n\n    int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    if (row < N && col < N) {\n        adjMatrix[row][col] = A[row * N + col];\n    }\n\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        numComponents_shared[0] = 0;\n    }\n    __syncthreads();\n\n    if (row == col && adjMatrix[row][col] == 1) {\n        atomicAdd(numComponents_shared, 1);\n        printf(\"component at row %d and column %d\\n\", row, col);\n    }\n\n    __syncthreads();\n\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n        atomicAdd(numComponents, numComponents_shared[0]);\n    }\n}",
            "// TODO: Fill this in\n\n}",
            "int num = 0;\n    int numComponents = 0;\n\n    for(int i=0; i<N; i++) {\n\tfor(int j=0; j<N; j++) {\n\t\tif(A[i*N + j] == 1) {\n\t\t\tif (i == j) {\n\t\t\t\tnum++;\n\t\t\t}\n\t\t}\n\t}\n    }\n\n    if (num > 0) {\n\tnumComponents++;\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if (i >= N || j >= N) { return; }\n  if (i < j) { return; }\n  __shared__ int sm[32];\n  int count = 0;\n  if (A[i*N + j] == 1) {\n    count = 1;\n  }\n  if (threadIdx.x == 0) { sm[threadIdx.y] = count; }\n  __syncthreads();\n  if (threadIdx.y == 0) {\n    for (int i = 0; i < blockDim.y; i++) {\n      if (sm[i] == 1) { count++; }\n    }\n  }\n  __syncthreads();\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    atomicAdd(numComponents, count);\n  }\n}",
            "int tidx = blockIdx.x*blockDim.x + threadIdx.x;\n    int tidy = blockIdx.y*blockDim.y + threadIdx.y;\n\n    // Compute the maximum number of connected components\n    if (tidy >= N || tidx >= N) return;\n\n    int num_components = 0;\n    int component_id = -1;\n\n    for (int i=0; i < N; i++)\n    {\n        if (i == tidx)\n        {\n            num_components++;\n            component_id = num_components - 1;\n        }\n        else if (A[tidx*N + i] > 0)\n        {\n            atomicMin(&component_id, A[tidx*N + i] - 1);\n        }\n    }\n\n    for (int i=0; i < N; i++)\n    {\n        if (A[tidy*N + i] > 0)\n        {\n            atomicMin(&component_id, A[tidy*N + i] - 1);\n        }\n    }\n\n    if (component_id!= -1)\n        A[tidx*N + tidy] = component_id;\n    else\n        A[tidx*N + tidy] = -1;\n}",
            "// The adjacency matrix A is in column-major.\n\t// Compute the index of the 2D block and the 2D thread.\n\t// The 2D block is (n/N, n/N) where n is the total number of blocks in each dimension.\n\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\t// Initialize the visited array to zero.\n\tif (i == 0 && j == 0)\n\t\t*numComponents = 0;\n\n\t// Exit if (i,j) lies outside the matrix.\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\t// Load Aij into register.\n\tint Aij = A[i * N + j];\n\n\t// If Aij is 1, then update the number of connected components,\n\t// and mark (i,j) and all its connected neighbors as visited.\n\tif (Aij == 1) {\n\n\t\t// Mark (i,j) as visited.\n\t\tA[i * N + j] = 0;\n\n\t\t// Visit all neighbors of (i,j).\n\t\tint numNeighbors = 0;\n\t\tfor (int k = 0; k < N; ++k) {\n\n\t\t\t// Load Akj into register.\n\t\t\tint Akj = A[k * N + j];\n\n\t\t\t// If Akj is 1, mark (k,j) as visited.\n\t\t\tif (Akj == 1) {\n\t\t\t\tA[k * N + j] = 0;\n\t\t\t\t++numNeighbors;\n\t\t\t}\n\t\t}\n\n\t\t// If (i,j) has at least one neighbor, increment the number of connected components.\n\t\tif (numNeighbors > 0)\n\t\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "const int myRow = blockIdx.y * blockDim.y + threadIdx.y;\n  const int myCol = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (myRow < N && myCol < N) {\n    const int myIdx = myRow * N + myCol;\n\n    if (A[myIdx]!= 0 && myRow < myCol) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// A node is a root if its value is 0.\n\t// Initialize the value to the current index, which is used to detect cycles in the graph.\n\t// This is safe because we are only reading and writing to this location.\n\tif (idx < N && A[idx * N + idx] == 0) {\n\t\tA[idx * N + idx] = idx;\n\n\t\t// For all nodes adjacent to the current node, check if they are marked as visited (value!= 0)\n\t\t// If they are not, mark them as visited and set their root to this root.\n\t\t// If they are visited, check if their root is the same as the current root.\n\t\t// If it is not, it means that the node is part of a different component, so increment the count of components.\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (idx!= i && A[idx * N + i]!= 0) {\n\t\t\t\tif (A[i * N + i] == 0) {\n\t\t\t\t\tA[i * N + i] = idx;\n\t\t\t\t} else if (A[i * N + i]!= idx) {\n\t\t\t\t\t*numComponents = *numComponents + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int thread_id = blockDim.x * blockIdx.x + threadIdx.x;\n\tint num_threads = gridDim.x * blockDim.x;\n\n\tfor (int tid = thread_id; tid < N; tid += num_threads) {\n\t\t// If the ith node has not been processed, do a BFS from it\n\t\tif (A[tid * N + tid] == 0) {\n\t\t\tint depth = 0;\n\t\t\tint front[N];\n\t\t\tint front_head = 0;\n\t\t\tint front_tail = 0;\n\n\t\t\t// Add the node to the frontier\n\t\t\tfront[front_tail++] = tid;\n\n\t\t\t// While there are nodes in the frontier\n\t\t\twhile (front_head < front_tail) {\n\t\t\t\tint node = front[front_head++];\n\n\t\t\t\t// Explore all nodes adjacent to the current node\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t// If adjacent and not explored, add to frontier\n\t\t\t\t\tif (A[node * N + j] &&!A[j * N + j]) {\n\t\t\t\t\t\tfront[front_tail++] = j;\n\t\t\t\t\t\tA[j * N + j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Mark the current node as explored\n\t\t\t\tA[node * N + node] = 1;\n\t\t\t\t++depth;\n\t\t\t}\n\n\t\t\t// Increment the number of components if the maximum depth of the BFS is not 0\n\t\t\tif (depth)\n\t\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n\n\tif(i < N && j < N && A[i * N + j] == 1) {\n\t\tint x = findSet(i, A, N);\n\t\tint y = findSet(j, A, N);\n\t\tif(x!= y) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t\tunionSets(x, y, A, N);\n\t\t}\n\t}\n}",
            "const int i = blockIdx.x;\n\tconst int j = threadIdx.x;\n\tif (i == j) {\n\t\tint count = 0;\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (A[i * N + k] &&!A[k * N + j]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, count);\n\t}\n}",
            "int row = blockIdx.y;\n\tint col = blockIdx.x;\n\tint index = row * N + col;\n\n\tint numThreadsPerRow = gridDim.x;\n\tint numThreadsPerCol = gridDim.y;\n\n\tint rowStartIndex = row * N;\n\tint colStartIndex = col;\n\n\tint rowOffset = rowStartIndex + colStartIndex;\n\n\tint localComponentCount = 0;\n\n\tif (rowOffset == index) {\n\t\tif (A[index] == 1) {\n\t\t\tlocalComponentCount = 1;\n\t\t}\n\t}\n\n\tfor (int j = 0; j < numThreadsPerRow; ++j) {\n\t\tint leftIndex = rowStartIndex + (j * N + col);\n\t\tif (A[leftIndex] == 1) {\n\t\t\tlocalComponentCount++;\n\t\t}\n\t}\n\n\tfor (int j = 0; j < numThreadsPerCol; ++j) {\n\t\tint upIndex = row * N + (colStartIndex + j);\n\t\tif (A[upIndex] == 1) {\n\t\t\tlocalComponentCount++;\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, localComponentCount);\n}",
            "__shared__ int smem[CACHE_SIZE];\n  int tx = threadIdx.x, ty = threadIdx.y, bx = blockIdx.x, by = blockIdx.y;\n  int start = bx*CACHE_SIZE + tx;\n  int stride = CACHE_SIZE * gridDim.x;\n  int myNumComponents = 0;\n\n  for(int i = start; i < N; i+=stride) {\n    int iPos = i * N;\n    bool connected = false;\n\n    for(int j = ty; j < N; j += CACHE_SIZE) {\n      if(A[iPos + j] > 0) {\n        connected = true;\n        break;\n      }\n    }\n\n    if(connected) {\n      __syncthreads();\n\n      int myVal = 0;\n      if(ty == 0) {\n        myVal = smem[tx] + 1;\n        smem[tx] = 0;\n      }\n\n      __syncthreads();\n\n      atomicAdd(&smem[tx], myVal);\n      myNumComponents = smem[tx];\n      __syncthreads();\n    }\n  }\n\n  if(tx == 0 && ty == 0) {\n    atomicAdd(numComponents, myNumComponents);\n  }\n}",
            "__shared__ int visited[32];\n\t__shared__ int shared_row[32];\n\n\tint row = blockIdx.x;\n\tint col = threadIdx.x;\n\tint size = blockDim.x;\n\tint index = row * size + col;\n\n\tint numComp = 0;\n\tif (index < N * N) {\n\t\tif (A[index] == 1) {\n\t\t\tshared_row[col] = row;\n\t\t\tint row2 = shared_row[col];\n\t\t\tvisited[row2] = 1;\n\t\t\tif (row2 < N) {\n\t\t\t\tif (row2 == col) {\n\t\t\t\t\tint row3 = shared_row[col];\n\t\t\t\t\tif (visited[row3] == 1) {\n\t\t\t\t\t\tnumComp++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\tint sum = 0;\n\tfor (int i = 0; i < size; i++) {\n\t\tsum += shared_row[i];\n\t}\n\tif (sum == size) {\n\t\tnumComp++;\n\t}\n\n\tif (index == 0) {\n\t\t*numComponents = numComp;\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i >= N || j >= N)\n        return;\n    if (A[i * N + j]!= 0) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "const size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n  const size_t j = blockDim.y * blockIdx.y + threadIdx.y;\n  if (i < N && j < N) {\n    if (A[i * N + j]) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// use AMD HIP to compute in parallel.\n\t// The kernel is launched on an NxN grid of threads.\n\t//\n\t//  A is an NxN adjacency matrix stored in row-major.\n\t//  Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n\t//  Example:\n\t//\n\t//  input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n\t//  output: 2\n\n\tsize_t x = blockIdx.x * blockDim.x + threadIdx.x;\n\tsize_t y = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tint num = 0;\n\t//if x == y\n\tif(x < N && y < N && A[x * N + y] == 1){\n\t\tatomicAdd(&num, 1);\n\t}\n\t//if (x,y) is connected to the root of (y,y)\n\tif(x < N && y < N && A[x * N + y] == 1 && A[y * N + y] == 0){\n\t\tA[x * N + y] = 0;\n\t\tA[y * N + y] = 1;\n\t}\n\tatomicAdd(numComponents, num);\n}",
            "int componentId = -1;\n  // Get the column and row indices of the thread.\n  // Each thread works with one element of the matrix.\n  int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n  // Get the element of the matrix at the thread's column and row indices.\n  int element = A[i * N + j];\n  // If the element is 1,\n  // assign a unique id to the component in which it resides.\n  if (element == 1) {\n    if (atomicCAS(&componentId, -1, j) == -1) {\n      for (int k = 0; k < N; ++k) {\n        if (i == k) {\n          continue;\n        }\n        if (atomicCAS(&A[k * N + j], 1, 0) == 1) {\n          atomicCAS(&A[j * N + k], 1, 0);\n        }\n      }\n    }\n  }\n  // Sum the unique component ids to get the total number of components.\n  atomicAdd(numComponents, componentId!= -1? 1 : 0);\n}",
            "// This grid is made up of NxN blocks each with 1x1 threads\n    // The block id is the row number\n    // The thread id is the column number\n    int bid = blockIdx.x;\n    int tid = threadIdx.x;\n\n    // Check to see if this thread is in the valid range\n    // If it is not, then return immediately\n    if (bid >= N || tid >= N) return;\n\n    // Set the flag for whether this thread has been assigned a label\n    int assigned = 0;\n    int componentLabel = -1;\n\n    // Check to see if this thread's current component is labeled\n    if (A[bid * N + tid] == 1) {\n        // Traverse in all directions and label all neighbors\n        for (int i = -1; i <= 1; i++) {\n            for (int j = -1; j <= 1; j++) {\n                // Only traverse if not the same row/column\n                if (i!= 0 || j!= 0) {\n                    int neighbor = bid + i;\n                    int col = tid + j;\n\n                    // Check to see if this thread is in the valid range\n                    // If it is not, then return immediately\n                    if (neighbor >= N || col >= N) continue;\n\n                    // Check to see if the neighbor is connected to this thread\n                    if (A[neighbor * N + col] == 1) {\n                        // If so, then give it the same label\n                        if (componentLabel == -1) {\n                            componentLabel = A[neighbor * N + col];\n                        } else {\n                            if (A[neighbor * N + col]!= -1) {\n                                A[neighbor * N + col] = componentLabel;\n                                assigned++;\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    // Check to see if this thread has been assigned a label\n    if (assigned > 0) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "__shared__ int sData[BLOCKSIZE][BLOCKSIZE];\n  __shared__ int sVisited[BLOCKSIZE];\n  __shared__ int sCount[BLOCKSIZE];\n\n  // row and column in global memory\n  int globalRow = blockIdx.y * blockDim.y + threadIdx.y;\n  int globalCol = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // block row and col\n  int blockRow = threadIdx.y;\n  int blockCol = threadIdx.x;\n\n  // current thread's result\n  int myResult = 0;\n\n  // current thread's visited set\n  sVisited[blockRow] = 0;\n  sCount[blockRow] = 0;\n  __syncthreads();\n\n  // BFS on current thread's row\n  if (globalRow < N && globalCol < N) {\n    if (A[globalRow * N + globalCol] == 1 && sVisited[blockRow] == 0) {\n      sVisited[blockRow] = 1;\n      sData[blockRow][blockCol] = globalRow;\n      __syncthreads();\n\n      // enqueue globalRow to current thread's queue\n      for (int i = 0; i < blockDim.x; i++) {\n        if (globalCol + i < N && A[globalRow * N + globalCol + i] == 1 && sVisited[i] == 0) {\n          sData[i][blockDim.x + sCount[i]] = globalRow;\n          sCount[i]++;\n        }\n      }\n      __syncthreads();\n\n      while (sCount[blockRow] > 0) {\n        myResult++;\n\n        // dequeue globalRow from current thread's queue\n        int temp = sData[blockRow][blockCol];\n        sData[blockRow][blockCol] = sData[blockRow][blockDim.x + sCount[blockRow] - 1];\n        sCount[blockRow]--;\n\n        for (int i = 0; i < blockDim.x; i++) {\n          if (globalCol + i < N && A[temp * N + globalCol + i] == 1 && sVisited[i] == 0) {\n            sData[i][blockDim.x + sCount[i]] = temp;\n            sCount[i]++;\n          }\n        }\n        __syncthreads();\n      }\n    }\n  }\n  __syncthreads();\n\n  // reduction: sum the result of each thread\n  for (int stride = 1; stride < blockDim.x; stride *= 2) {\n    if (blockRow % (2 * stride) == 0 && blockRow + stride < blockDim.x) {\n      myResult += sData[blockRow + stride][blockCol];\n    }\n    __syncthreads();\n  }\n\n  // write result for this block to global mem\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    atomicAdd(numComponents, myResult);\n  }\n}",
            "const size_t i = threadIdx.x;\n\n\t// each thread will have its own visited mask\n\tunsigned visited = 0;\n\tfor (size_t j = 0; j < N; ++j) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tvisited |= 1 << j;\n\t\t}\n\t}\n\t\n\t// if this thread is in a component, we will increment the counter\n\t// for each thread that has a non-zero value in the visited mask,\n\t// and only do so if it was not previously visited\n\tif (visited!= 0) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint x = threadIdx.x;\n\tint y = threadIdx.y;\n\t__shared__ int sCount[32];\n\t__shared__ int sFlag[32];\n\t// printf(\"tid: %i, i: %i, j: %i\\n\", tid, i, j);\n\n\t// Initialize the flag array and the count array\n\tif (x == 0) {\n\t\tsFlag[y] = 0;\n\t\tsCount[y] = 0;\n\t}\n\t__syncthreads();\n\n\t// Traverse the graph\n\tif (A[tid] == 1 && A[j*N+i] == 1) {\n\t\tif (sFlag[y] == 0) {\n\t\t\tsFlag[y] = 1;\n\t\t\tsCount[y] = sCount[y] + 1;\n\t\t}\n\t}\n\n\t// Sum the count array\n\tfor(int stride = 1; stride < blockDim.y; stride *= 2) {\n\t\t__syncthreads();\n\t\tif (y % (2 * stride) == 0) {\n\t\t\tsCount[y] = sCount[y] + sCount[y + stride];\n\t\t}\n\t}\n\n\t// Store the count for this component to global memory\n\tif (x == 0 && y == 0) {\n\t\tatomicAdd(numComponents, sCount[0]);\n\t}\n}",
            "// TODO: implement\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid >= N) return;\n\n\t// Initialize visited array as all zeros.\n\tint visited[N];\n\tfor (int i = 0; i < N; i++)\n\t\tvisited[i] = 0;\n\n\t// BFS\n\tint queue[N];\n\tint head = 0;\n\tint tail = 0;\n\n\t// Mark the starting vertex as visited\n\tvisited[tid] = 1;\n\tqueue[tail] = tid;\n\ttail++;\n\n\twhile (head!= tail) {\n\t\tint vertex = queue[head];\n\t\thead++;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[vertex * N + i] &&!visited[i]) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tqueue[tail] = i;\n\t\t\t\ttail++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Count the number of vertices whose visited is 1\n\tint count = 0;\n\tfor (int i = 0; i < N; i++)\n\t\tif (visited[i])\n\t\t\tcount++;\n\n\t// Add this count to the total number of components\n\tatomicAdd(numComponents, count);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if(i >= N) return;\n\n  if(A[i*N+i] == 0)\n    return; // skip unconnected nodes\n\n  for(int j = i+1; j < N; ++j)\n    if(A[i*N+j] == 1 && A[j*N+i] == 1) {\n      A[i*N+j] = 0;\n      A[j*N+i] = 0;\n    }\n\n  __syncthreads();\n  atomicAdd(numComponents, 1);\n}",
            "__shared__ int componentCounts[256];\n\n\t// Compute the ID of the current thread\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// Initialize the component counts to 0\n\tif (threadIdx.x == 0) {\n\t\tcomponentCounts[blockIdx.x] = 0;\n\t}\n\n\t// Check if the current thread is a valid thread\n\tif (tid < N) {\n\t\t// Check if the current thread has not been assigned to a component yet\n\t\tif (A[tid * N + tid] == 0) {\n\t\t\t// Initialize the DFS stack and the visited vector\n\t\t\tstack<int> stack;\n\t\t\tvector<int> visited(N, false);\n\n\t\t\t// Add the current vertex to the stack\n\t\t\tstack.push(tid);\n\n\t\t\t// Start the DFS\n\t\t\twhile (!stack.empty()) {\n\t\t\t\t// Get the top vertex\n\t\t\t\tint v = stack.top();\n\t\t\t\tstack.pop();\n\n\t\t\t\t// Check if the current vertex has not been visited yet\n\t\t\t\tif (!visited[v]) {\n\t\t\t\t\t// Add the current vertex to the visited vector\n\t\t\t\t\tvisited[v] = true;\n\n\t\t\t\t\t// Increment the component count\n\t\t\t\t\tcomponentCounts[blockIdx.x]++;\n\n\t\t\t\t\t// Add the neighboring vertices to the stack\n\t\t\t\t\tfor (int w = 0; w < N; w++) {\n\t\t\t\t\t\tif (A[v * N + w] == 1 &&!visited[w]) {\n\t\t\t\t\t\t\tstack.push(w);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Synchronize the threads\n\t__syncthreads();\n\n\t// Reduce the component counts\n\tif (threadIdx.x == 0) {\n\t\tfor (int i = 1; i < blockDim.x; i++) {\n\t\t\tcomponentCounts[blockIdx.x] += componentCounts[i];\n\t\t}\n\t}\n\n\t// Synchronize the threads\n\t__syncthreads();\n\n\t// Write the total component count to the global memory\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numComponents, componentCounts[blockIdx.x]);\n\t}\n}",
            "int i = threadIdx.x + blockDim.x * blockIdx.x;\n\tint j = threadIdx.y + blockDim.y * blockIdx.y;\n\n\t// Each thread processes one row of the input matrix.\n\t// Note that the array is only NxN\n\tif (i >= N || j >= N) {\n\t\treturn;\n\t}\n\n\t// Each thread finds a component\n\tif (A[i * N + j] == 1) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int index = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (index >= N) return;\n\tint myComponent = 0;\n\tif (A[index * N + index] == 1) {\n\t\tmyComponent = index;\n\t}\n\telse {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[index * N + i] == 1) {\n\t\t\t\tmyComponent = min(myComponent, i);\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numComponents, 1);\n}",
            "__shared__ int component;\n\t__shared__ bool isInComponent;\n\t__shared__ int componentSize;\n\tconst int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tconst int blocksize = blockDim.x * gridDim.x;\n\n\t// Avoid processing elements not in the array.\n\tif (tid >= N) return;\n\n\t// Initialize the component and componentSize variables.\n\tcomponent = tid;\n\tcomponentSize = 1;\n\tisInComponent = true;\n\n\t// Check if the thread belongs to a component.\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[tid * N + i] == 1) {\n\t\t\t// Check if the thread is the root of the component.\n\t\t\tif (i == tid) {\n\t\t\t\t// If it is, update the size of the component and break.\n\t\t\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t\tcomponentSize++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t// If not, update the component and break.\n\t\t\tcomponent = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Use the atomicCAS function to avoid data races.\n\twhile (atomicCAS(&isInComponent, true, false) == true) {\n\t\t// Check if the thread is in the component.\n\t\tif (component == tid) {\n\t\t\t// Add the component size to the global count.\n\t\t\tatomicAdd(numComponents, componentSize);\n\t\t\tbreak;\n\t\t}\n\t}\n}",
            "__shared__ int sdata[256];\n\t// Get the number of connected components in this block.\n\tint nComps = 0;\n\tfor (int i = threadIdx.x; i < N; i += blockDim.x) {\n\t\tfor (int j = 0; j < i; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tnComps++;\n\t\t\t}\n\t\t}\n\t}\n\t// Reduce this block's number of connected components with all other blocks.\n\t// For now, assume all blocks have the same number of threads.\n\tsdata[threadIdx.x] = nComps;\n\t__syncthreads();\n\tfor (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n\t\tif (threadIdx.x < offset) {\n\t\t\tsdata[threadIdx.x] += sdata[threadIdx.x + offset];\n\t\t}\n\t\t__syncthreads();\n\t}\n\t// First thread in the block writes the block's total number of connected components to the output.\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numComponents, sdata[0]);\n\t}\n}",
            "extern __shared__ int shared[];\n  int myId = threadIdx.x + blockIdx.x * blockDim.x;\n  int threadId = threadIdx.x;\n  shared[threadId] = 0;\n  if (myId < N) {\n    // Set the first node to be the root of its component\n    if (threadId == 0) {\n      shared[0] = 1;\n    }\n    __syncthreads();\n    int curComponent = 0;\n    // Find the root of the component containing curNode\n    while (shared[curComponent]!= 1) {\n      curComponent++;\n    }\n    // Mark the component root if it has not already been marked\n    if (A[myId * N + myId] == 1) {\n      if (curComponent!= 0) {\n        if (threadId == 0) {\n          shared[0] = 1;\n        }\n      }\n    }\n    __syncthreads();\n    // Update the component root if the current node is the root of its component\n    if (A[myId * N + myId] == 1) {\n      int newRoot = 0;\n      while (shared[newRoot]!= 1) {\n        newRoot++;\n      }\n      // Mark the new root of the component\n      shared[newRoot] = 2;\n      __syncthreads();\n      // Update all nodes in the component to be rooted at the new root\n      for (int i = 0; i < N; i++) {\n        if (A[myId * N + i] == 1) {\n          A[myId * N + i] = newRoot;\n        }\n      }\n    }\n    __syncthreads();\n    // Count the number of marked components\n    if (shared[curComponent] == 2) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int i = blockDim.x*blockIdx.y + threadIdx.x;\n\tint j = blockDim.y*blockIdx.x + threadIdx.y;\n\n\tif (i >= N || j >= N || j <= i) return;\n\n\tint connected = 0;\n\tif (A[i*N + j] == 1) connected = 1;\n\tatomicAdd(numComponents, connected);\n}",
            "// TODO: replace the following code with your implementation.\n  // 1. Loop through the current row of A.\n  // 2. If the element is 1, set the corresponding element of B to be 1.\n  // 3. After the kernel, the number of 1s in B corresponds to the number of connected components.\n  int r = blockIdx.x * blockDim.x + threadIdx.x;\n  if (r < N) {\n    for (int c = 0; c < N; c++) {\n      if (A[r*N+c] == 1) {\n        atomicAdd(numComponents, 1);\n      }\n    }\n  }\n}",
            "unsigned int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned int i = idx/N;\n  unsigned int j = idx%N;\n  if(i > j)\n    return;\n  if(A[idx] > 0) {\n    atomicAdd(numComponents, 1);\n    //set the rest of the row to 1 to ensure we don't check this component again\n    for(unsigned int k=i+1;k<N;k++)\n      A[k*N + i] = 1;\n    //set the rest of the column to 1 to ensure we don't check this component again\n    for(unsigned int k=j+1;k<N;k++)\n      A[i*N + k] = 1;\n  }\n}",
            "// Your code here\n}",
            "const int row = blockIdx.y * blockDim.y + threadIdx.y;\n  const int col = blockIdx.x * blockDim.x + threadIdx.x;\n  if (row >= N || col >= N) return;\n  int value = 1;\n  if (A[row * N + col] == 0) value = 0;\n  atomicAdd(numComponents, value);\n}",
            "int i, j;\n  int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  if (tid >= N*N) return;\n  i = tid / N;\n  j = tid - i * N;\n  // each thread will do the following operations in parallel\n  if (A[i * N + j] == 1 && i!= j) {\n    if (atomicCAS(&A[j * N + i], 1, 0) == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// TODO\n}",
            "int col = blockIdx.x;\n    int row = threadIdx.x;\n    if (row >= N || col >= N || row == col) return;\n    // check if connected\n    if (A[col * N + row] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "__shared__ int numThreads;\n  __shared__ int threadId;\n\n  if (threadIdx.x == 0) {\n    numThreads = blockDim.x;\n    threadId = blockIdx.x * numThreads + threadIdx.x;\n  }\n\n  __syncthreads();\n\n  if (threadId < N * N) {\n    // Find the corresponding row/column in the matrix\n    int row = threadId / N;\n    int col = threadId % N;\n\n    // Only check if the row is less than the column\n    if (row < col && A[threadId]) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// TODO: Implement the component count kernel.\n  //\n  // We have to use atomics to update numComponents.\n  // We need to find out the total number of threads that\n  // are processing a given component.\n  //\n  // For each element A[i, j] that is 1,\n  // if (i, j) is visited, count it.\n  //\n  // If we are processing a new component, update the number of components.\n  //\n  // If the index (i, j) is out of bounds, we do not need to check it.\n  //\n  // Note that we need to use atomicMin() or atomicMax() to count\n  // the total number of threads in a given component.\n  //\n  // Note that we can use atomics for the component count as well,\n  // but it is not necessary.\n  //\n\n  int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // We check out of bounds.\n  if(i >= N || j >= N) return;\n\n  // We check if A[i, j] is 1.\n  if(A[i * N + j] == 1) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "int i, j, num = 0;\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int stride = blockDim.x * gridDim.x;\n  int *visited = (int*) malloc(sizeof(int)*N);\n  int *visited2 = (int*) malloc(sizeof(int)*N);\n  for(i = 0; i < N; ++i) {\n    visited[i] = 0;\n    visited2[i] = 0;\n  }\n  for(i = 0; i < N; i += stride) {\n    if(i+tid < N) {\n      if(visited[i+tid] == 0 && A[i+tid*N]!= 0) {\n\t++num;\n\tvisited[i+tid] = 1;\n\tfor(j = 0; j < N; ++j) {\n\t  if(A[i+tid*N+j]!= 0 && visited2[j] == 0) {\n\t    visited2[j] = 1;\n\t    visited[j] = 1;\n\t  }\n\t}\n      }\n    }\n  }\n  atomicAdd(numComponents, num);\n  free(visited);\n  free(visited2);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (idx < N) {\n        int connected = 0;\n\n        for (int i = 0; i < N; i++) {\n            connected = (A[i + idx * N] == 1)? connected + 1 : connected;\n        }\n\n        atomicAdd(numComponents, connected > 0? 1 : 0);\n    }\n}",
            "// get thread ID\n  int tid = blockDim.x * blockIdx.y * gridDim.x\n      + blockDim.x * blockIdx.x + threadIdx.x;\n  if (tid < N) {\n    // check if the node is connected to any other nodes\n    int i, isConnected = 0;\n    for (i = 0; i < N; i++) {\n      isConnected += A[N * i + tid];\n    }\n\n    // if the node is connected to at least one other node, add one to the component count\n    if (isConnected > 0) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// Get the thread's unique id\n\tint id = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\n\t// Early return if we're out of bounds\n\tif (id >= N) return;\n\n\t// If the current node is part of a component, then increment the number of components by 1.\n\tif (A[id * N + id] == 1) atomicAdd(numComponents, 1);\n}",
            "__shared__ int componentIDs[BLOCK_SIZE][BLOCK_SIZE];\n\n\tint i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\tint ID = i * N + j;\n\tif (i == j) {\n\t\t// if it is a diagonal entry, then it is the start of a new component.\n\t\t// give it a unique id.\n\t\tcomponentIDs[threadIdx.y][threadIdx.x] = *numComponents;\n\t\t*numComponents = *numComponents + 1;\n\t} else {\n\t\tcomponentIDs[threadIdx.y][threadIdx.x] = 0;\n\t}\n\n\t__syncthreads();\n\n\t// find the smallest component ID of the adjacent entries\n\tint minID = A[ID]? (int)min(componentIDs[i][threadIdx.x], componentIDs[threadIdx.y][j])\n\t\t\t\t\t  : componentIDs[threadIdx.y][threadIdx.x];\n\tcomponentIDs[threadIdx.y][threadIdx.x] = minID;\n\t__syncthreads();\n\n\t// write the new component ID back to the matrix\n\tif (i!= j)\n\t\tA[ID] = minID;\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ int visited[BLOCK_SIZE];\n\n  if (id < N && A[id * N + id] == 1) {\n    visited[threadIdx.x] = 1;\n  } else {\n    visited[threadIdx.x] = 0;\n  }\n\n  // Wait for all threads to finish\n  __syncthreads();\n\n  // Iterate through all threads and find the number of connected components\n  int i;\n  for (i = 0; i < blockDim.x; i++) {\n    if (threadIdx.x == i && visited[threadIdx.x] == 1) {\n      *numComponents = *numComponents + 1;\n      DFS(A, N, i);\n    }\n  }\n}",
            "int num_components = 0;\n\tint global_row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint col = blockIdx.y * blockDim.y + threadIdx.y;\n\tint size = N;\n\n\tif(global_row < N && col < N) {\n\n\t\tif(A[global_row * size + col]) {\n\n\t\t\tif(global_row == col) {\n\n\t\t\t\tnum_components++;\n\n\t\t\t} else {\n\n\t\t\t\tbool *visited = (bool *) calloc(N, sizeof(bool));\n\t\t\t\tint visited_count = 0;\n\n\t\t\t\t// Use Breadth First Search to search for the connected component\n\t\t\t\tbool *q = (bool *) calloc(N, sizeof(bool));\n\t\t\t\tq[global_row] = true;\n\n\t\t\t\tint *next = (int *) calloc(N, sizeof(int));\n\t\t\t\tint q_size = 0;\n\t\t\t\tint q_front = 0;\n\t\t\t\tint q_rear = 0;\n\t\t\t\tnext[0] = global_row;\n\t\t\t\tvisited[global_row] = true;\n\t\t\t\tvisited_count++;\n\t\t\t\tq_size++;\n\t\t\t\tq_rear++;\n\n\t\t\t\tint global_col = col;\n\n\t\t\t\twhile(q_front < q_rear) {\n\n\t\t\t\t\tint node = next[q_front];\n\t\t\t\t\tq_front++;\n\t\t\t\t\tvisited_count++;\n\n\t\t\t\t\tfor(int i = 0; i < N; i++) {\n\n\t\t\t\t\t\tif(A[node * N + i] &&!visited[i]) {\n\t\t\t\t\t\t\tq[q_rear] = true;\n\t\t\t\t\t\t\tvisited[i] = true;\n\t\t\t\t\t\t\tnext[q_rear] = i;\n\t\t\t\t\t\t\tq_size++;\n\t\t\t\t\t\t\tq_rear++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif(visited[global_col]) {\n\t\t\t\t\tnum_components++;\n\t\t\t\t}\n\n\t\t\t\tfree(visited);\n\t\t\t\tfree(q);\n\t\t\t\tfree(next);\n\t\t\t}\n\t\t}\n\t}\n\n\t// Use atomic to ensure correctness of final answer.\n\tatomicAdd(numComponents, num_components);\n}",
            "int i, j;\n  int tx = threadIdx.x + blockIdx.x * blockDim.x; // global thread index\n\n  if (tx >= N) {\n    return;\n  }\n\n  // check the current node\n  int count = 0;\n  if (A[tx*N + tx] == 1) {\n    count = 1;\n  }\n\n  // check the rest of the neighbors\n  for (i = 0; i < N; i++) {\n    for (j = 0; j < N; j++) {\n      if ((i!= tx) && (j!= tx) && (A[tx*N + i] == 1) && (A[i*N + j] == 1)) {\n        count++;\n      }\n    }\n  }\n\n  // the count is the number of components (only one component if count = 0)\n  atomicAdd(numComponents, count);\n}",
            "const int i = threadIdx.x + blockIdx.x * blockDim.x;\n  const int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n  extern __shared__ int sdata[];\n  int index = threadIdx.y * blockDim.x + threadIdx.x;\n  int myCount = 0;\n\n  if (i < N && j < N) {\n    myCount = A[i * N + j];\n  }\n  sdata[index] = myCount;\n\n  __syncthreads();\n\n  int sum;\n  if (threadIdx.x == 0 && threadIdx.y == 0) {\n    sum = 0;\n  }\n  __syncthreads();\n\n  for (unsigned int s = blockDim.x * blockDim.y / 2; s > 0; s >>= 1) {\n    if (index < s) {\n      sum += sdata[index];\n      sdata[index] = sum;\n    }\n    __syncthreads();\n  }\n  __syncthreads();\n\n  if (i < N && j < N && threadIdx.x == 0 && threadIdx.y == 0) {\n    if (sdata[0] == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int i, j, m;\n  int blockSize = blockDim.x;\n  int blockId = blockIdx.x;\n  int threadId = threadIdx.x;\n\n  // Allocate a 2D array of integers on the device.\n  extern __shared__ int dev_A[];\n\n  int *dev_Adj = dev_A;\n  int *dev_V   = dev_A + N;\n  int *dev_D   = dev_A + N*2;\n  int *dev_P   = dev_A + N*3;\n\n  for (i=0; i<N; i++) {\n    dev_V[i] = -1;\n  }\n\n  // Iterate over all of the vertices in the matrix,\n  // and find the number of connected components\n  // by performing a DFS starting at each vertex\n  for (m=0; m<N; m++) {\n    if (dev_V[m] == -1) {\n      // If this vertex has not been visited yet,\n      // then start a DFS from here.\n\n      // Initialize the DFS stack.\n      dev_D[0] = m;\n      dev_P[0] = -1;\n\n      // Keep track of the DFS size.\n      // The maximum number of vertices in a connected component\n      // is N.\n      dev_V[m] = 0;\n\n      // Iterate until the DFS stack is empty.\n      for (i=0; i<N; i++) {\n\n        // Pop a vertex from the stack.\n        j = dev_D[i];\n\n        // Check all neighbors of vertex j.\n        for (int k=0; k<N; k++) {\n\n          // If the neighbor has not been visited,\n          // then add it to the DFS stack.\n          if (dev_V[k] == -1 && dev_Adj[j*N+k] == 1) {\n            dev_D[i+1] = k;\n            dev_P[i+1] = j;\n            dev_V[k] = i+1;\n          }\n        }\n      }\n\n      // Add the DFS size to the total.\n      atomicAdd(numComponents, dev_V[m]);\n    }\n  }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint i, j;\n\t__shared__ int isVisited[BLOCKSIZE];\n\n\tif(idx < N) {\n\t\tisVisited[threadIdx.x] = 0;\n\t\t__syncthreads();\n\n\t\tif(A[idx * N + idx] == 0) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t} else {\n\t\t\tfor(i = 0; i < N; i++) {\n\t\t\t\tif(i == idx) continue;\n\t\t\t\tif(A[idx * N + i] == 1) {\n\t\t\t\t\tfor(j = 0; j < N; j++) {\n\t\t\t\t\t\tif(isVisited[j] == 0 && A[i * N + j] == 1) {\n\t\t\t\t\t\t\tisVisited[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;\n  int componentCount = 0;\n\n  // BFS on the graph using 1 thread per vertex\n  if (globalThreadId < N) {\n    int vertex = globalThreadId;\n\n    // Skip if vertex is already labeled\n    if (A[vertex * N + vertex]!= 0) {\n      return;\n    }\n\n    int queue[MAX_VERTICES];\n    int queueSize = 1;\n    int queueIndex = 0;\n\n    queue[0] = vertex;\n    A[vertex * N + vertex] = -1;\n\n    while (queueIndex < queueSize) {\n      int currVertex = queue[queueIndex];\n\n      for (int i = 0; i < N; i++) {\n        // Add to queue if there is an edge\n        if (A[currVertex * N + i]!= 0 && A[currVertex * N + i]!= -1) {\n          if (A[i * N + i] == 0) {\n            A[i * N + i] = -1;\n            queue[queueSize] = i;\n            queueSize++;\n          }\n          A[currVertex * N + i] = -1;\n        }\n      }\n      queueIndex++;\n    }\n    componentCount++;\n  }\n\n  // Find the total number of connected components in the graph\n  for (int i = 0; i < N; i++) {\n    if (A[i * N + i]!= 0) {\n      componentCount++;\n    }\n  }\n\n  // Add the count of the current vertex to the total count\n  atomicAdd(numComponents, componentCount);\n}",
            "size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n    if(idx >= N*N) return;\n\n    if(A[idx] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (i == j) {\n    int sum = 0;\n    for (int k = 0; k < N; k++) {\n      sum += A[i * N + k];\n    }\n    atomicAdd(numComponents, sum);\n  }\n}",
            "/* Get the 1D index of the thread from the 2D grid and block indices. */\n  size_t i = threadIdx.x + blockIdx.x * blockDim.x;\n  size_t j = threadIdx.y + blockIdx.y * blockDim.y;\n\n  /* If the current thread is outside the matrix or the edge is not a valid one, return early. */\n  if (i >= N || j >= N || A[i * N + j] == 0) return;\n\n  // TODO: Implement a parallel componentCount kernel that runs on the GPU using AMD HIP\n  //       Do not use any mutexes or atomics\n  //       Use the AMD HIP grid-stride loop to iterate over the entire matrix\n  //       Use the AMD HIP warp-stride loop to iterate over the rows of the current column of the grid-stride loop\n  //       Store the number of connected components in numComponents[0]\n  // Hint: Use __syncthreads() to synchronize threads in a block\n\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tid = threadIdx.x;\n\t__shared__ int component[N];\n\t\n\tif (id < N) {\n\t\tcomponent[id] = id;\n\t}\n\t\n\t__syncthreads();\n\t\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[id + i * N] > 0) {\n\t\t\t\tatomicMin(&component[id], component[id + j * N]);\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\t\n\tif (tid == 0) {\n\t\tint count = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (i == component[i]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\t*numComponents = count;\n\t}\n}",
            "const int i = blockIdx.y * N + blockIdx.x;\n  const int j = threadIdx.y * N + threadIdx.x;\n\n  int numComps = 0;\n\n  if (i < N && j < N && A[i * N + j] == 1) {\n    int currComp = 1;\n    for (int k = 0; k < N; k++) {\n      if (k == j)\n        continue;\n      if (A[i * N + k] == 1) {\n        currComp = 0;\n        break;\n      }\n    }\n    atomicAdd(numComponents, currComp);\n  }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n    __shared__ int myID;\n    __shared__ int mySize;\n    __shared__ int myComponent;\n    __shared__ int myNumComponents;\n\n    if (row < N && col < N) {\n        if (A[row * N + col] > 0) {\n            myID = -1;\n            mySize = 1;\n            myComponent = -1;\n            myNumComponents = 0;\n            if (row > 0) {\n                if (A[row * N + (col - 1)] > 0) {\n                    myID = atomicCAS(A + (col - 1) * N + row, 1, 0);\n                }\n            }\n            if (col > 0) {\n                if (A[row * N + (col - 1)] > 0) {\n                    myID = atomicCAS(A + (col - 1) * N + row, 1, 0);\n                }\n            }\n            if (myID == -1) {\n                myComponent = atomicAdd(numComponents, 1);\n            } else {\n                myComponent = myID;\n                atomicAdd(numComponents + myID, 1);\n            }\n            atomicAdd(numComponents + myComponent, 1);\n        }\n    }\n    __syncthreads();\n    if (row < N && col < N && A[row * N + col] > 0) {\n        atomicAdd(numComponents + myComponent, mySize);\n    }\n}",
            "size_t i = threadIdx.x;\n\tsize_t j = threadIdx.y;\n\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\tif (A[j * N + i])\n\t\tatomicAdd(numComponents, 1);\n}",
            "int row = blockIdx.y*blockDim.y+threadIdx.y;\n  int col = blockIdx.x*blockDim.x+threadIdx.x;\n  if (row >= N || col >= N) {\n    return;\n  }\n\n  __shared__ int comp[blockDim.x][blockDim.y];\n  comp[threadIdx.y][threadIdx.x] = 0;\n  __syncthreads();\n\n  int myComp = comp[threadIdx.y][threadIdx.x];\n  int otherComp = comp[threadIdx.y][threadIdx.x];\n\n  // TODO: Find a set of connected components in the graph defined by the adjacency matrix A\n\n  // TODO: Use atomicCAS to make sure that each thread only attempts to write once\n\n  // TODO: Use atomicAdd to increment the number of components\n\n  // TODO: Use atomicCAS to make sure that each thread only attempts to write once\n}",
            "// TODO: Compute the number of connected components in the graph.\n  //\n  // Here is a sample implementation:\n  //\n  // int *counts; // holds the number of elements connected to each element in A\n  // for (int i = 0; i < N; i++) {\n  //   counts[i] = 0;\n  //   for (int j = 0; j < N; j++) {\n  //     if (A[i*N + j] == 1)\n  //       counts[i]++;\n  //   }\n  // }\n  //\n  // *numComponents = 0;\n  // for (int i = 0; i < N; i++) {\n  //   if (counts[i] > 0) {\n  //     (*numComponents)++;\n  //   }\n  // }\n\n  // YOUR CODE HERE\n\n}",
            "int blockRow = blockIdx.y;\n  int blockCol = blockIdx.x;\n  int threadRow = threadIdx.y;\n  int threadCol = threadIdx.x;\n\n  // Allocate shared memory for the adjacency matrix.\n  extern __shared__ int sA[];\n  for (int i = threadRow; i < N; i += blockDim.y) {\n    for (int j = threadCol; j < N; j += blockDim.x) {\n      sA[i * N + j] = A[i * N + j];\n    }\n  }\n\n  __syncthreads();\n\n  // Use AMD HIP to parallelize the DFS.\n  // A simple DFS can be parallelized using the following strategy:\n  // - For each vertex, use a warp-wide voting scheme to decide whether to enter a DFS.\n  // - Use AMD HIP warp shuffle to exchange information.\n  //\n  // For details, please refer to the following publication:\n  // [Ramana, S., Bahl, A., & Wong, M. (2014).\n  //  A voting algorithm for graph traversal.\n  //  IEEE International Conference on High Performance Computing, Data, and Analytics, 2014.](http://dx.doi.org/10.1109/HiPC.2014.10)\n  int visited = 0;\n  if (threadRow == threadCol) {\n    int v = 0;\n    if (blockRow == blockCol) {\n      v = A[threadRow * N + threadCol];\n    } else if (threadCol < threadRow) {\n      v = sA[threadRow * N + threadCol];\n    } else {\n      v = sA[threadCol * N + threadRow];\n    }\n    int mask = 1 << threadCol;\n    int all;\n    int none;\n    warpVoteAny(v, mask, &all, &none);\n    if (none) {\n      return;\n    }\n\n    if (threadCol < threadRow) {\n      warpShflDown(mask, threadCol, threadRow, &v);\n    }\n    int count = 0;\n    if (all) {\n      count = warpBallot(v);\n      // Count the number of connected components.\n      atomicAdd(numComponents, __popc(count));\n    }\n  }\n}",
            "// Use atomic integer operations to count the number of connected components.\n\t// We can use atomic operations directly on the GPU, but for now, we have to use atomic\n\t// integer operations on the CPU.\n\t// This is OK since the GPU code will be executed once and the results stored in the CPU\n\t// copy of numComponents.\n\t//\n\t// See: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions\n\t//\n\t// Hint: use the AMD HIP atomic integer operations to avoid race conditions in your kernel.\n}",
            "int i = threadIdx.x + blockDim.x * blockIdx.x;\n  int j = threadIdx.y + blockDim.y * blockIdx.y;\n\n  int index = i * N + j;\n\n  // TODO: Your code here\n  __shared__ int adj[100][100];\n  __shared__ int visited[100];\n  if (i < N && j < N) adj[i][j] = A[index];\n  if (i == 0 && j == 0) visited[i] = 0;\n\n  int num = 0;\n  __syncthreads();\n  if (i < N && j < N && adj[i][j] == 1 && visited[i] == 0) {\n    visited[i] = 1;\n    num++;\n    for (int k = 0; k < N; k++) {\n      if (adj[i][k] == 1) {\n        num++;\n        visited[k] = 1;\n      }\n    }\n  }\n  if (threadIdx.x == 0 && threadIdx.y == 0) atomicAdd(numComponents, num);\n}",
            "/*\n      Note: the number of threads in a kernel must be a power of 2\n\n      You may find it useful to implement this using the following steps:\n      - initialize the numComponents to 0 (this is the number of components)\n      - use a for loop to loop through every row\n      - check the value in the adjacency matrix, if it is 1\n          - use atomicAdd to add 1 to the numComponents\n          - set the value in the adjacency matrix to 0\n      - end the for loop\n\n      Tip: Use atomicAdd in case multiple threads try to increment numComponents at the same time.\n      You may find atomicAdd in HIP's atomic functions: https://docs.nvidia.com/hip/hip-porting-guide/text/hip-porting-guide/basic-differences.html#atomic-functions\n    */\n    int i = blockIdx.x*blockDim.x + threadIdx.x;\n    if(i<N)\n    {\n        for(int j=0;j<N;j++)\n        {\n            if(A[j*N+i]==1)\n            {\n                atomicAdd(numComponents,1);\n                A[j*N+i]=0;\n            }\n        }\n    }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  if (tid < N) {\n    if (A[tid * N + tid] == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int myID = blockDim.x * blockIdx.x + threadIdx.x;\n  __shared__ int color[BLOCK_SIZE];\n  int globalID = myID * N + myID;\n\n  if (myID < N) {\n    color[myID] = myID;\n    if (A[globalID] == 1) {\n      int myColor = color[myID];\n      int myPrev = myColor;\n      while (color[myColor]!= myColor) {\n        myPrev = myColor;\n        myColor = color[myColor];\n      }\n      for (int j = myID + 1; j < N; j++) {\n        int globalID2 = myID * N + j;\n        if (A[globalID2] == 1) {\n          int myColor2 = color[j];\n          if (myColor2!= myColor) {\n            color[myColor2] = myColor;\n          }\n        }\n      }\n    }\n  }\n\n  __syncthreads();\n  __threadfence();\n\n  if (myID == 0) {\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n      int myColor = color[i];\n      if (myColor == i) {\n        count++;\n      }\n    }\n    *numComponents = count;\n  }\n}",
            "int tid = threadIdx.x + blockDim.x * blockIdx.x;\n  int tstride = blockDim.x * gridDim.x;\n  int component = -1;\n\n  for (int i = tid; i < N; i += tstride) {\n    if (A[i*N + i]) {\n      if (component == -1) {\n        component = i;\n      }\n      for (int j = 0; j < N; j++) {\n        if (i!= j) {\n          if (A[i*N + j]) {\n            A[j*N + component] = 1;\n          }\n        }\n      }\n    }\n  }\n\n  atomicAdd(numComponents, 1);\n}",
            "// Initialize the shared memory for communication\n  extern __shared__ int mem[];\n  int *comp = mem;\n  int *visited = &mem[N];\n  int *count = &mem[2*N];\n  int *lock = &mem[3*N];\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n  int bsize = blockDim.x;\n\n  // First step: Initialize the shared memory\n  if (tid < N) {\n    comp[tid] = bid;\n    visited[tid] = 0;\n    count[tid] = 0;\n    lock[tid] = 0;\n  }\n  __syncthreads();\n\n  // Second step: Traverse the graph using the DFS algorithm\n  if (tid < N) {\n    int cid = comp[tid];\n    if (A[bid * N + tid] == 1) {\n      if (visited[bid] == 0) {\n        visited[bid] = 1;\n        count[bid] = 1;\n      }\n      cid = comp[bid];\n      while (cid!= tid) {\n        int next = atomicMin(&lock[cid], bid);\n        if (next == bid) {\n          cid = atomicExch(&comp[tid], cid);\n        } else {\n          cid = atomicMin(&lock[tid], next);\n        }\n      }\n    }\n  }\n  __syncthreads();\n\n  // Third step: Count the number of components\n  if (tid == 0) {\n    *numComponents = 0;\n    for (int i = 0; i < N; i++) {\n      int cur = comp[i];\n      int countCur = count[cur];\n      if (countCur!= 0) {\n        atomicAdd(numComponents, countCur);\n      }\n    }\n  }\n}",
            "extern __shared__ int adjacencyMatrix[];\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int gid = tid / N;\n  int lid = tid % N;\n  if (gid < N && lid < N) {\n    adjacencyMatrix[gid * N + lid] = A[gid * N + lid];\n  }\n\n  __syncthreads();\n  if (tid < N) {\n    int visited = 0;\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n      if (!visited) {\n        visited = adjacencyMatrix[tid * N + i];\n        count++;\n      } else {\n        if (adjacencyMatrix[i * N + tid] && adjacencyMatrix[i * N + tid]!= adjacencyMatrix[tid * N + i]) {\n          count++;\n        }\n      }\n    }\n    atomicAdd(numComponents, count);\n  }\n}",
            "__shared__ int id[32];\n\t__shared__ int low[32];\n\n\tconst int tx = threadIdx.x;\n\tconst int ty = threadIdx.y;\n\tconst int bx = blockIdx.x;\n\tconst int by = blockIdx.y;\n\n\tif (tx < N && ty < N) {\n\t\tconst int index = tx + ty*N;\n\t\tint myId = index;\n\t\tif (A[index] == 0) {\n\t\t\tmyId = index;\n\t\t}\n\t\tid[tx] = myId;\n\t\tlow[tx] = myId;\n\t}\n\n\t__syncthreads();\n\n\tif (tx < N && ty < N) {\n\t\tconst int index = tx + ty*N;\n\t\tif (A[index]) {\n\t\t\tconst int src = id[tx];\n\t\t\tconst int dest = id[ty];\n\t\t\tif (src < dest) {\n\t\t\t\tconst int tmp = src;\n\t\t\t\tsrc = dest;\n\t\t\t\tdest = tmp;\n\t\t\t}\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (id[i] == dest) {\n\t\t\t\t\tatomicMin(&low[i], src);\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (id[i] == dest) {\n\t\t\t\t\tid[i] = low[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (tx == 0 && ty == 0) {\n\t\tconst int myId = id[ty*N+tx];\n\t\tint myLow = low[ty*N+tx];\n\t\tfor (int i = 1; i < N; i++) {\n\t\t\tconst int id = id[ty*N+i];\n\t\t\tconst int low = low[ty*N+i];\n\t\t\tif (id == myId && low!= myLow) {\n\t\t\t\tmyLow = low;\n\t\t\t\tatomicMin(&low[i], myLow);\n\t\t\t}\n\t\t}\n\t\tint cnt = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (id[i] == myId) {\n\t\t\t\tif (low[i] == myLow) {\n\t\t\t\t\tcnt++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, cnt);\n\t}\n}",
            "// Get the global row and column index for this thread\n  size_t rowIdx = blockIdx.y * blockDim.y + threadIdx.y;\n  size_t colIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Each thread has a unique ID within the block\n  int threadId = threadIdx.y * blockDim.x + threadIdx.x;\n\n  // Each thread has a unique ID for this block\n  int blockId = blockIdx.y * gridDim.x + blockIdx.x;\n\n  // If the current thread is valid, update numComponents\n  if (rowIdx < N && colIdx < N) {\n    int value = A[rowIdx * N + colIdx];\n    // Perform a reduction with atomics\n    atomicAdd(numComponents, value);\n  }\n}",
            "int x = blockIdx.x*blockDim.x + threadIdx.x;\n  int y = blockIdx.y*blockDim.y + threadIdx.y;\n  int id = threadIdx.x + blockDim.x*threadIdx.y;\n\n  // Shared memory to store the count of connected components\n  __shared__ int sharedComponentCount[BLOCK_DIM*BLOCK_DIM];\n  sharedComponentCount[id] = 0;\n  __syncthreads();\n\n  // Loop through the adjacent elements of the matrix\n  for (int k=0; k<N; k++) {\n    if (A[x*N + k]!= 0 && A[y*N + k]!= 0) {\n      sharedComponentCount[id] = 1;\n    }\n  }\n\n  // Sum the counts in shared memory\n  for (int stride = BLOCK_DIM/2; stride > 0; stride /= 2) {\n    __syncthreads();\n    if (id < stride) {\n      sharedComponentCount[id] += sharedComponentCount[id + stride];\n    }\n  }\n\n  // Copy to global memory\n  if (id == 0) {\n    atomicAdd(numComponents, sharedComponentCount[0]);\n  }\n}",
            "size_t tid = hipBlockIdx_x*hipBlockDim_x + hipThreadIdx_x;\n\n  if(tid < N) {\n    int id = tid;\n    if(A[tid * N + id] == 1) {\n      int c = count(A, N, id);\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// Compute the connected component number for the vertex with the given index\n\t// Use this method:\n\t// - start with -1.\n\t// - if vertex has a component number, return that number.\n\t// - if vertex is unvisited, assign vertex with smallest component number to vertex.\n\t// - if vertex is not unvisited, recursively call connected component count with that vertex.\n\t// - return the minimum component number of the vertices in the connected component\n\t//   whose vertex number is v.\n\t// - Update the global variable with the minimum.\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x; // global thread index\n\n    int globalId = tid;\n\n    __shared__ int s_label; // label for each block\n\n    __shared__ int s_size; // the number of elements in each block\n\n    if (globalId < N) {\n\n        int label = tid;\n\n        int size = 0;\n\n        while (label < N) {\n\n            if (A[label * N + globalId] > 0) {\n\n                size++;\n\n            }\n\n            label += blockDim.x * gridDim.x;\n\n        }\n\n        if (tid == 0) {\n\n            s_size = size;\n\n            s_label = globalId;\n\n        }\n\n    }\n\n    __syncthreads();\n\n    if (tid < N) {\n\n        int label = tid;\n\n        while (label < N) {\n\n            if (A[label * N + globalId] > 0) {\n\n                A[label * N + globalId] = s_label;\n\n            }\n\n            label += blockDim.x * gridDim.x;\n\n        }\n\n    }\n\n    __syncthreads();\n\n    if (tid < N) {\n\n        int label = tid;\n\n        while (label < N) {\n\n            if (A[globalId * N + label] == s_label) {\n\n                A[globalId * N + label] = s_label;\n\n            }\n\n            label += blockDim.x * gridDim.x;\n\n        }\n\n    }\n\n    __syncthreads();\n\n    if (tid == 0) {\n\n        atomicAdd(numComponents, s_size);\n\n    }\n\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// Each thread is responsible for checking if an adjacent pair of elements (x,y) or (y,x)\n\t// are both 0 or both 1, since we only care about components with an even number of ones.\n\tif (x >= N || y >= N) return;\n\tbool adjacent = (A[x * N + y] == 1) || (A[y * N + x] == 1);\n\tbool same     = (A[x * N + y] == A[y * N + x]);\n\tif (adjacent && same)\n\t\tatomicAdd(numComponents, 1);\n}",
            "// Get the ID of the current thread\n  unsigned int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Initialize the number of components to 0 and the\n  // component ID of this thread to -1\n  if (id == 0) {\n    *numComponents = 0;\n  }\n  __syncthreads();\n  int compID = -1;\n\n  // If this thread's id is within the bounds of the graph,\n  // check whether it is connected to another component or not\n  if (id < N) {\n    for (int j = 0; j < N; j++) {\n      if (A[N*id + j] == 1) {\n        compID = j;\n      }\n    }\n  }\n\n  // If this thread's id is a root of a component, increment the number of components\n  if (compID!= -1 && id == compID) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "__shared__ int seen[BLOCKSIZE];\n  int tid = threadIdx.x;\n  int bidx = blockIdx.x;\n  int idx = bidx * BLOCKSIZE + tid;\n\n  // set seen[] to 0\n  if (tid < N) {\n    seen[tid] = 0;\n  }\n\n  __syncthreads();\n\n  if (tid < N) {\n    if (A[idx]!= 0 && seen[tid] == 0) {\n      // mark seen[][tid] as 1 and recursively call for all neighbors\n      seen[tid] = 1;\n\n      int jdx = idx + 1;\n\n      while (jdx < N * N) {\n        if (A[jdx]!= 0 && seen[jdx % N] == 0) {\n          seen[jdx % N] = 1;\n          componentCount(A, N, numComponents);\n          break;\n        }\n        jdx++;\n      }\n    }\n  }\n\n  // Count the number of 1's in seen[]\n  __shared__ int count;\n  int mycount = 0;\n\n  __syncthreads();\n\n  if (tid < N) {\n    mycount = seen[tid];\n  }\n\n  for (int i = 16; i > 0; i /= 2) {\n    __syncthreads();\n    if (tid < i) {\n      mycount += mycount;\n    }\n  }\n\n  if (tid == 0) {\n    atomicAdd(numComponents, mycount);\n  }\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n  if (tid < N) {\n    int numConnections = 0;\n    for (int i = 0; i < N; i++) {\n      if (A[tid * N + i]) {\n        numConnections++;\n      }\n    }\n    if (numConnections == 0) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// shared memory to store the current component ID and its size\n    extern __shared__ int shm[];\n\n    // The current row\n    int row = blockIdx.x;\n    // The current thread in the row\n    int thread = threadIdx.x;\n\n    // The ID of the current component\n    int componentId = shm[0];\n    // The size of the current component\n    int componentSize = shm[1];\n\n    // The component ID to be assigned to the new connected component\n    int newComponentId = componentId + 1;\n    // The size of the new connected component\n    int newComponentSize = 0;\n\n    // Compute the ID of the current adjacent vertex\n    int adjacencyId = row*N + thread;\n    int adjacencyVertex = -1;\n\n    // Check if the adjacent vertex exists\n    if (adjacencyId < N*N && A[adjacencyId] > 0) {\n        adjacencyVertex = adjacencyId/N;\n    }\n\n    // Check if the adjacent vertex is the same as the current one\n    if (adjacencyVertex == row) {\n        if (componentSize > 0) {\n            atomicAdd(numComponents, 1);\n            atomicMax(numComponents, newComponentId);\n        }\n        return;\n    }\n\n    // Check if the adjacent vertex is in the same component\n    if (componentSize > 0 && adjacencyVertex!= -1 && A[adjacencyId] == 1 && componentId == adjacencyVertex) {\n        return;\n    }\n\n    if (componentSize > 0 && adjacencyVertex!= -1 && A[adjacencyId] == 1) {\n        newComponentSize = componentSize;\n        // The current thread is the new component leader\n        atomicMin(&shm[1], newComponentSize);\n        newComponentSize = atomicMax(&shm[1], componentSize);\n        atomicAdd(&shm[0], 1);\n        atomicMax(&shm[0], newComponentId);\n        newComponentId = atomicMin(&shm[0], newComponentId);\n        atomicMax(&shm[1], newComponentSize);\n    } else if (adjacencyVertex!= -1 && A[adjacencyId] == 1) {\n        // The current thread is not the leader, it is the new component leader\n        newComponentSize = 1;\n        atomicMin(&shm[1], newComponentSize);\n        newComponentSize = atomicMax(&shm[1], componentSize);\n        atomicAdd(&shm[0], 1);\n        atomicMax(&shm[0], newComponentId);\n        newComponentId = atomicMin(&shm[0], newComponentId);\n        atomicMax(&shm[1], newComponentSize);\n        // Notify the leader\n        __threadfence();\n        shm[2] = 1;\n    } else if (adjacencyVertex!= -1 && A[adjacencyId] == 1) {\n        // The current thread is not the leader, it is not a new component leader\n        atomicMin(&shm[1], newComponentSize);\n        newComponentSize = atomicMax(&shm[1], componentSize);\n        atomicAdd(&shm[0], 1);\n        atomicMax(&shm[0], newComponentId);\n        newComponentId = atomicMin(&shm[0], newComponentId);\n        atomicMax(&shm[1], newComponentSize);\n        __threadfence();\n    }\n\n    __syncthreads();\n\n    // The current thread is the leader\n    if (thread == 0) {\n        componentId = newComponentId;\n        componentSize = newComponentSize;\n        atomicMin(&shm[1], componentSize);\n        __threadfence();\n    }\n\n    __syncthreads();\n\n    if (thread == 0) {\n        atomicMin(&shm[1], componentSize);\n        componentSize = atomicMax(&shm[1], componentSize);\n        atomicAdd(&shm[0], 1);\n        atomicMax(&shm[0], componentId);\n        componentId = atomicMin(&shm[0], componentId);\n        atomicMax(&shm[1], componentSize);\n    }\n\n    __syncthreads();\n\n    componentId = shm[",
            "// AMD HIP Block ID\n    unsigned int bx = blockIdx.x;\n    unsigned int by = blockIdx.y;\n\n    // AMD HIP Thread ID\n    unsigned int tx = threadIdx.x;\n    unsigned int ty = threadIdx.y;\n\n    // AMD HIP 2D thread ID\n    unsigned int tid = tx + ty * N;\n\n    // AMD HIP 2D block ID\n    unsigned int bid = bx + by * gridDim.x;\n\n    extern __shared__ int sdata[];\n\n    // load global memory to shared memory\n    sdata[tid] = A[tid];\n    __syncthreads();\n\n    for (int stride = N / 2; stride > 0; stride >>= 1) {\n        if (tid < stride) {\n            sdata[tid] = (sdata[tid] > sdata[tid + stride])? sdata[tid] : sdata[tid + stride];\n        }\n        __syncthreads();\n    }\n\n    // Atomic increment is not required since this is a single block\n    // since it's a single block, there is no contention.\n    if (tid == 0) {\n        atomicAdd(numComponents, sdata[0]);\n    }\n}",
            "const unsigned int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (threadId >= N) {\n    return;\n  }\n\n  // Initialize component ID to zero.\n  int componentId = 0;\n\n  // This is the \"visited\" vector from the algorithm.\n  int visited[N];\n  for (int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n\n  // Each thread will be responsible for a vertex.\n  // For each vertex, check if it has already been visited and if it has\n  // not, check all of its neighbors.\n  if (visited[threadId] == 0) {\n    visited[threadId] = 1;\n\n    // First, check all of the vertex's neighbors.\n    for (int i = 0; i < N; i++) {\n      if (A[threadId * N + i] == 1) {\n        if (visited[i] == 0) {\n          componentId = 1;\n          break;\n        }\n      }\n    }\n\n    // Now check all of the neighbor's neighbors.\n    for (int i = 0; i < N; i++) {\n      if (A[threadId * N + i] == 1) {\n        for (int j = 0; j < N; j++) {\n          if (A[i * N + j] == 1) {\n            if (visited[j] == 0) {\n              componentId = 1;\n              break;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  atomicAdd(numComponents, componentId);\n}",
            "int tid = hipThreadIdx_x + blockDim.x * hipBlockIdx_x;\n\tif (tid < N) {\n\t\t// 1. Find the current node in the graph and initialize the label\n\t\tint curComponent = tid;\n\t\tint label = tid;\n\t\tint done = 0;\n\t\tint *labelA = label + tid * N;\n\t\t// 2. Go over all the vertices in the adjacency matrix\n\t\twhile (done == 0) {\n\t\t\tint *labelB = labelA;\n\t\t\tfor (int j = tid; j < N; j++) {\n\t\t\t\t// 3. If the node is connected, check if it has a lower label\n\t\t\t\tif (A[tid * N + j] == 1) {\n\t\t\t\t\tint newLabel = labelB[j];\n\t\t\t\t\t// 4. If the current component is connected to a smaller label, use it\n\t\t\t\t\tif (curComponent > newLabel) {\n\t\t\t\t\t\tcurComponent = newLabel;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 5. Label all the vertices with the smaller label\n\t\t\t\tlabelB[j] = curComponent;\n\t\t\t}\n\t\t\t// 6. Set the done flag if all the nodes have been labeled\n\t\t\tdone = 1;\n\t\t\tfor (int j = tid; j < N; j++) {\n\t\t\t\tif (labelB[j] == tid) {\n\t\t\t\t\tdone = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// 7. Count the number of components by checking if the labels are the same as the current vertex\n\t\tif (label[tid] == tid) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  if (i < N && j < N) {\n    if (A[i + j * N] == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row < N && col < N && row!= col) {\n\t\t// Check if the current row and col are connected\n\t\tif (A[row + N*col] == 1) {\n\t\t\tint curComponent = atomicAdd(numComponents, 1);\n\n\t\t\t// Mark all of the connected neighbors\n\t\t\tmarkConnectedNeighbors(A, N, curComponent, row, col);\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ int component[256];\n  if (tid < N) {\n    component[threadIdx.x] = A[tid * N + tid];\n    __syncthreads();\n    int c = 0;\n    for (int i = 0; i < N; i++) {\n      if (component[i] == 1) {\n        c += 1;\n        int j = i + 1;\n        while (j < N) {\n          if (A[i * N + j] == 1) {\n            component[j] = 1;\n            j++;\n          } else {\n            break;\n          }\n        }\n        i = j - 1;\n      }\n    }\n    atomicAdd(numComponents, c);\n  }\n}",
            "// The ID of this thread\n    int id = threadIdx.x + blockIdx.x * blockDim.x;\n    if (id >= N) return;\n\n    // Set the count to zero\n    int count = 0;\n\n    // Set the thread to be inactive\n    __shared__ int isActive;\n    isActive = 0;\n\n    // Check if the thread is not active. If it is inactive, set it active.\n    // If the thread is already active, return\n    if (atomicCAS(&isActive, 0, 1) == 0) {\n        // The root of the component\n        int root = id;\n\n        // Mark root as visited\n        A[id] = 1;\n\n        // Visit neighbors of root\n        // Traverse the tree using BFS\n        for (int v = 0; v < N; ++v) {\n            // Check if root can reach v\n            if (A[root] == 1 && A[v] == 0) {\n                // Mark v as visited\n                A[v] = 1;\n\n                // Traverse the tree using BFS\n                for (int u = 0; u < N; ++u) {\n                    // Check if v can reach u\n                    if (A[v] == 1 && A[u] == 0) {\n                        // Mark u as visited\n                        A[u] = 1;\n                    }\n                }\n            }\n        }\n\n        // Set the thread to be inactive\n        atomicExch(&isActive, 0);\n\n        // Count the number of components\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int tidx = threadIdx.x + blockIdx.x * blockDim.x;\n\tif(tidx >= N) return;\n\tif(A[tidx] == 1) atomicAdd(numComponents, 1);\n}",
            "__shared__ int isVisited[N];\n  __shared__ int visitedComponentCount[N];\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) {\n    return;\n  }\n  if (A[i * N + i] == 1) {\n    isVisited[i] = 1;\n    visitedComponentCount[i] = 1;\n  } else {\n    isVisited[i] = 0;\n    visitedComponentCount[i] = 0;\n  }\n  for (int j = 0; j < N; j++) {\n    if (A[i * N + j] == 1 &&!isVisited[j]) {\n      isVisited[j] = 1;\n      visitedComponentCount[j] = visitedComponentCount[i];\n    }\n  }\n  for (int j = 0; j < N; j++) {\n    if (A[j * N + i] == 1 &&!isVisited[j]) {\n      visitedComponentCount[j] = visitedComponentCount[i];\n    }\n  }\n  for (int j = 0; j < N; j++) {\n    if (A[j * N + i] == 1 &&!isVisited[j]) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "const int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int stride = gridDim.x * blockDim.x;\n\n\t__shared__ int numBlockComponents;\n\n\tif (threadIdx.x == 0) {\n\t\tnumBlockComponents = 0;\n\t}\n\n\t__syncthreads();\n\n\tfor (int i = tid; i < N; i += stride) {\n\t\tif (!A[i * N + i]) {\n\t\t\tnumComponents[blockIdx.x]++;\n\t\t\treturn;\n\t\t}\n\n\t\tint curComponent = 1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] && A[i * N + j]!= 1) {\n\t\t\t\tcurComponent++;\n\t\t\t}\n\t\t}\n\t\tnumBlockComponents += curComponent;\n\t}\n\tatomicAdd(numComponents, numBlockComponents);\n}",
            "__shared__ int sData[SHARED_SIZE];\n  int tid = threadIdx.x;\n  int bid = blockIdx.x;\n\n  // each thread does a merge sort of 32 elements\n  for (int i = tid; i < SHARED_SIZE; i += blockDim.x) {\n    sData[i] = -1;\n  }\n  __syncthreads();\n\n  // load data to shared memory\n  int startIdx = bid * SHARED_SIZE * 2;\n  if (startIdx + tid < N) {\n    sData[tid] = A[startIdx + tid];\n    if (startIdx + SHARED_SIZE + tid < N) {\n      sData[tid + SHARED_SIZE] = A[startIdx + SHARED_SIZE + tid];\n    }\n  }\n\n  __syncthreads();\n  // merge sort\n  for (int i = 0; i < SHARED_SIZE / 2; i++) {\n    int left = 2 * i + tid;\n    int right = 2 * i + 1 + tid;\n    if (left >= SHARED_SIZE || right >= SHARED_SIZE) {\n      break;\n    }\n    if (sData[left] < sData[right]) {\n      int temp = sData[left];\n      sData[left] = sData[right];\n      sData[right] = temp;\n    }\n  }\n  __syncthreads();\n\n  // find number of components\n  if (tid == 0) {\n    int num = 0;\n    for (int i = 0; i < SHARED_SIZE; i++) {\n      if (sData[i]!= -1) {\n        num++;\n      }\n    }\n    atomicAdd(numComponents, num);\n  }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (id < N) {\n\t\tint *adj;\n\t\tif (A[id * N + id] == 0) {\n\t\t\t*numComponents = 0;\n\t\t\treturn;\n\t\t}\n\t\tadj = (int *)malloc(N * sizeof(int));\n\t\tmemcpy(adj, A + id * N, N * sizeof(int));\n\t\t*numComponents += countComponents(adj, N, id);\n\t\tfree(adj);\n\t}\n}",
            "const int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (idx >= N) return;\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[idx * N + i] == 1) {\n\t\t\tcount++;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (count == 0) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int idx = blockIdx.x*blockDim.x + threadIdx.x;\n  if(idx < N) {\n    __shared__ int myComponent;\n    int currentComponent = -1;\n    if(idx == 0) {\n      myComponent = atomicAdd(numComponents, 1);\n      currentComponent = myComponent;\n    }\n    __syncthreads();\n    if(A[idx*N+idx]!= 0) {\n      int id = idx;\n      while(A[id*N+id]!= 0) {\n        id = A[id*N+id] - 1;\n      }\n      __syncthreads();\n      int idComponent = id / N;\n      atomicMin(&currentComponent, idComponent);\n    }\n    __syncthreads();\n    A[idx*N+idx] = currentComponent + 1;\n  }\n}",
            "__shared__ int sdata[64];\n  int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int i = tid / N;\n  int j = tid % N;\n  int index = tid;\n  int myNumComponents = 1;\n  if (i < N && j < N) {\n    if (A[index]!= 0) {\n      myNumComponents = 0;\n      int k, n;\n      for (k = i - 1; k >= 0; k--) {\n        n = A[k * N + j];\n        if (n!= 0) {\n          myNumComponents = 1;\n          break;\n        }\n      }\n      if (myNumComponents == 0) {\n        for (k = i + 1; k < N; k++) {\n          n = A[k * N + j];\n          if (n!= 0) {\n            myNumComponents = 1;\n            break;\n          }\n        }\n      }\n      if (myNumComponents == 0) {\n        for (k = j - 1; k >= 0; k--) {\n          n = A[i * N + k];\n          if (n!= 0) {\n            myNumComponents = 1;\n            break;\n          }\n        }\n      }\n      if (myNumComponents == 0) {\n        for (k = j + 1; k < N; k++) {\n          n = A[i * N + k];\n          if (n!= 0) {\n            myNumComponents = 1;\n            break;\n          }\n        }\n      }\n    }\n    sdata[threadIdx.x] = myNumComponents;\n    __syncthreads();\n    int size = blockDim.x;\n    while (size > 32) {\n      if (threadIdx.x < size / 2) {\n        sdata[threadIdx.x] += sdata[threadIdx.x + size / 2];\n      }\n      __syncthreads();\n      size = size / 2;\n    }\n    if (threadIdx.x < 32) {\n      warpReduce(sdata, threadIdx.x);\n    }\n    if (threadIdx.x == 0) {\n      atomicAdd(numComponents, sdata[0]);\n    }\n  }\n}",
            "int myId = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (myId < N) {\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + myId]!= 0) {\n        atomicAdd(numComponents, 1);\n        return;\n      }\n    }\n  }\n}",
            "int row = blockIdx.x;\n\tint col = blockIdx.y;\n\tint index = col * N + row;\n\n\tint i = threadIdx.x;\n\tint j = threadIdx.y;\n\tint index2 = j * N + i;\n\n\t// First, we are looking for the first zero entry that is not on the main diagonal.\n\t// This is our starting point to start searching for connected components.\n\t// We want to start our search on a component that has not been searched before.\n\tif (row == col && A[index2] == 0 && i < N && j < N) {\n\t\tint count = 0;\n\n\t\t// If we found a zero entry that is not on the main diagonal, we are going to\n\t\t// perform a BFS search to find the number of components\n\t\tqueue<int> q;\n\t\tbool* searched = (bool*)malloc(N*N*sizeof(bool));\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tsearched[j*N + i] = false;\n\t\t\t}\n\t\t}\n\n\t\t// Mark this as searched\n\t\tsearched[index] = true;\n\n\t\t// We are going to perform BFS here to find the number of components\n\t\tq.push(index);\n\t\twhile (!q.empty()) {\n\t\t\tint current = q.front();\n\t\t\tq.pop();\n\n\t\t\t// If we found a zero entry that is not on the main diagonal, we are going to\n\t\t\t// perform a BFS search to find the number of components\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tint index2 = j * N + i;\n\t\t\t\t\tif (A[index2] == 1 &&!searched[index2]) {\n\t\t\t\t\t\tq.push(index2);\n\t\t\t\t\t\tsearched[index2] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\n\t\t// Perform atomic addition on the number of components\n\t\tatomicAdd(numComponents, count);\n\t}\n}",
            "const int i = blockIdx.y*blockDim.y + threadIdx.y;\n  const int j = blockIdx.x*blockDim.x + threadIdx.x;\n  __shared__ int shared[32][32];\n  if (i >= N || j >= N) return;\n  shared[threadIdx.y][threadIdx.x] = A[i*N+j];\n  __syncthreads();\n  if (shared[threadIdx.y][threadIdx.x] == 1) {\n    for (int t = 0; t < 32; t++) {\n      if (shared[threadIdx.y][t] == 1 && t!= threadIdx.x) {\n        shared[threadIdx.y][t] = 0;\n        shared[threadIdx.y][threadIdx.x] = 0;\n      }\n    }\n  }\n  __syncthreads();\n  if (shared[threadIdx.y][threadIdx.x] == 1) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n    int j = blockDim.y * blockIdx.y + threadIdx.y;\n    if (i < N && j < N && A[j * N + i] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int row = blockIdx.x;\n    int col = threadIdx.x;\n\n    // Count the number of connected components in the graph defined by the adjacency matrix A\n    int id = row * N + col;\n    if (row < N && col < N && A[id] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int n = blockDim.x;\n  int b = gridDim.x;\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n  if (x < N && y < N) {\n    int nnz = 0;\n    if (A[x * N + y]!= 0) {\n      nnz = 1;\n    }\n    __shared__ int cnt[256];\n    __syncthreads();\n    if (threadIdx.x == 0) {\n      cnt[threadIdx.y] = nnz;\n    }\n    __syncthreads();\n    for (int i = 1; i < blockDim.y; i *= 2) {\n      if (threadIdx.y % (2 * i) == 0) {\n        cnt[threadIdx.y] += cnt[threadIdx.y + i];\n      }\n      __syncthreads();\n    }\n    if (threadIdx.y == 0 && cnt[0]!= 0) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (idx < N) {\n\t\tint connected = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i * N + idx] == 1 || A[idx * N + i] == 1) {\n\t\t\t\tconnected = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (connected == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "int id = blockDim.x * blockIdx.x + threadIdx.x;\n\n  if (id < N) {\n    for (int i = 0; i < N; i++) {\n      if (A[id * N + i] == 1 && i!= id) {\n        atomicAdd(numComponents, 1);\n      }\n    }\n  }\n}",
            "int numThreads = gridDim.x * blockDim.x;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\t__shared__ int s_numComponents;\n\tint myNumComponents;\n\n\t// Count the number of connected components on each thread.\n\tfor (int i = tid; i < N; i += numThreads) {\n\t\tmyNumComponents = 0;\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tmyNumComponents += A[i * N + j];\n\t\t}\n\t\tatomicAdd(&s_numComponents, myNumComponents);\n\t}\n\n\t// Each thread writes to s_numComponents.\n\t__syncthreads();\n\n\t// Sum the results in s_numComponents.\n\tfor (int stride = 1; stride < blockDim.x; stride *= 2) {\n\t\tif (threadIdx.x % (2 * stride) == 0) {\n\t\t\ts_numComponents += __shfl_down_sync(0xFFFFFFFF, s_numComponents, stride);\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// Only the first thread in the block writes the result.\n\tif (tid == 0) {\n\t\tatomicAdd(numComponents, s_numComponents);\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int x, y, count = 0;\n\n    if (id < N*N) {\n        x = id / N;\n        y = id % N;\n\n        if ((A[id] > 0) && (id == x*N+y)) {\n            do {\n                for (int i = 0; i < N; i++) {\n                    if ((A[x*N+i] > 0) && (A[i*N+y] > 0)) {\n                        A[x*N+i] = 0;\n                        A[i*N+y] = 0;\n                    }\n                }\n\n                count++;\n            } while (A[id] > 0);\n        }\n\n        atomicAdd(numComponents, count);\n    }\n}",
            "// Get the x and y location of the calling thread\n    int x = blockIdx.x;\n    int y = blockIdx.y;\n\n    // If both x and y are less than N and the element at (x, y) is a 1,\n    // then we have found a connected component.\n    if(x < N && y < N && A[x * N + y]) {\n        *numComponents = *numComponents + 1;\n\n        // Mark all elements in this component as 0 so we don't double count it.\n        A[x * N + y] = 0;\n\n        for(int i = 0; i < N; i++) {\n            A[x * N + i] = 0;\n            A[i * N + y] = 0;\n        }\n    }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n  if (i >= N)\n    return;\n\n  if (A[i*N + i]!= 1) {\n    return;\n  }\n\n  __shared__ int shared[16];\n  int num_threads = blockDim.x;\n  int lane = threadIdx.x & 0xF;\n  int tid = threadIdx.x;\n\n  int c = 0;\n\n  do {\n    int nbr = __shfl_sync(0xFFFFFFFF, i, lane);\n\n    if (lane == 0) {\n      shared[tid] = A[i*N + nbr];\n    }\n\n    __syncthreads();\n\n    c += shared[tid];\n  } while (__any_sync(0xFFFFFFFF, c == 0));\n\n  if (lane == 0) {\n    atomicAdd(numComponents, c);\n  }\n}",
            "int myId = blockDim.x * blockIdx.y + threadIdx.x;\n    if (myId < N) {\n        if (A[myId] == 0)\n            return;\n        int currentComponent = A[myId];\n        int foundComponent = 0;\n        do {\n            foundComponent = atomicCAS(&A[myId], currentComponent, 0);\n        } while (foundComponent!= currentComponent);\n        atomicAdd(numComponents, 1);\n    }\n}",
            "// Your code here\n  *numComponents = 0;\n  // First, mark all vertices as unvisited\n  // If a vertex is visited, then set the value to be negative\n  int *visited = new int[N];\n  for (int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n  // Use a queue to store all the unvisited nodes.\n  std::queue<int> Q;\n  for (int i = 0; i < N; i++) {\n    // If a vertex is not visited, then add it to the queue and\n    // mark the vertex as visited\n    if (visited[i] == 0) {\n      visited[i] = -1;\n      Q.push(i);\n      while (!Q.empty()) {\n        // If the node in the queue is not visited, then mark it\n        // as visited and all its neighbors\n        int cur = Q.front();\n        Q.pop();\n        for (int j = 0; j < N; j++) {\n          if (A[cur * N + j] == 1 && visited[j] == 0) {\n            visited[j] = -1;\n            Q.push(j);\n          }\n        }\n      }\n      *numComponents += 1;\n    }\n  }\n  delete[] visited;\n}",
            "// use a bool to check if the index is visited\n  __shared__ bool visited[128];\n  // get the thread's id\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  // get the number of threads in the block\n  int blocksize = blockDim.x * blockDim.y;\n  // define a variable to store the number of components\n  int numComponentsShared = 0;\n  // only one thread in the block is responsible for counting\n  if (threadIdx.x == 0)\n    numComponentsShared = 1;\n  // for each index in the matrix\n  for (int i = tid; i < N * N; i += blocksize) {\n    // check if the index is visited\n    if (visited[i] == false) {\n      // if not, then mark it as visited\n      visited[i] = true;\n      // check if the index is connected to the left\n      if (i - 1 >= 0 && A[i] == 1 && visited[i - 1] == false) {\n        // if so, continue visiting in the left\n        visited[i - 1] = true;\n        // count it\n        numComponentsShared += 1;\n      }\n      // check if the index is connected to the right\n      if (i + 1 < N * N && A[i] == 1 && visited[i + 1] == false) {\n        // if so, continue visiting in the right\n        visited[i + 1] = true;\n        // count it\n        numComponentsShared += 1;\n      }\n      // check if the index is connected to the top\n      if (i - N >= 0 && A[i] == 1 && visited[i - N] == false) {\n        // if so, continue visiting in the top\n        visited[i - N] = true;\n        // count it\n        numComponentsShared += 1;\n      }\n      // check if the index is connected to the bottom\n      if (i + N < N * N && A[i] == 1 && visited[i + N] == false) {\n        // if so, continue visiting in the bottom\n        visited[i + N] = true;\n        // count it\n        numComponentsShared += 1;\n      }\n    }\n  }\n  // only one thread in the block is responsible for counting\n  __syncthreads();\n  // if the thread's id is 0, store the number of components in the shared\n  // memory to the global memory\n  if (threadIdx.x == 0)\n    atomicAdd(numComponents, numComponentsShared);\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx < N) {\n    atomicAdd(numComponents, A[idx * N + idx]);\n  }\n}",
            "//\n}",
            "// Each thread computes a single connected component\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\t// A thread is assigned to an element in the matrix A\n\tint componentIndex = 0;\n\tint componentSize = 0;\n\n\t// The thread computes the connected component containing (i,j)\n\tif (i < N && j < N) {\n\t\tif (A[i + j*N]) {\n\t\t\t// Initialize the stack to the (i,j) element\n\t\t\tint stack[N];\n\t\t\tstack[0] = i;\n\t\t\tcomponentSize = 1;\n\t\t\t// Loop while the stack is not empty\n\t\t\twhile (componentSize > 0) {\n\t\t\t\t// Pop the stack\n\t\t\t\ti = stack[--componentSize];\n\t\t\t\t// Add the element to the connected component\n\t\t\t\tA[i + j*N] = componentIndex;\n\t\t\t\t// Add all the elements connected to the element to the stack\n\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\tif (A[i + k*N]) {\n\t\t\t\t\t\t// Push the element to the stack\n\t\t\t\t\t\tstack[componentSize++] = k;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Increment the number of connected components\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (x >= N || y >= N) {\n    return;\n  }\n\n  if (A[x * N + y]) {\n    int num_blocks_x = (N + 1) / 2;\n    int num_blocks_y = (N + 1) / 2;\n    int tid = (x + y * (num_blocks_x + 1));\n    int cta_x = tid % num_blocks_x;\n    int cta_y = tid / num_blocks_x;\n    int component = (cta_y == 0) || (cta_x == 0);\n\n    __shared__ int s_numComponents;\n\n    if (component) {\n      s_numComponents = 1;\n    }\n\n    __syncthreads();\n\n    if (component) {\n      atomicAdd(numComponents, s_numComponents);\n    }\n  }\n}",
            "// TODO\n  unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (idx < N) {\n    unsigned int count = 0;\n    for (unsigned int i = 0; i < N; i++) {\n      if (A[idx * N + i])\n        count++;\n    }\n    atomicAdd(numComponents, count);\n  }\n}",
            "int thread_id = blockDim.x * blockIdx.x + threadIdx.x;\n\tint global_id = thread_id + blockDim.x * blockIdx.y;\n\tif (global_id >= N)\n\t\treturn;\n\n\tint cur_component = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i * N + global_id]!= 0) {\n\t\t\tcur_component++;\n\t\t}\n\t}\n\tatomicAdd(numComponents, cur_component);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < N) {\n    if (A[tid] == 1) {\n      for (int j = 0; j < N; j++) {\n        if (A[tid*N + j] == 1) {\n          atomicAdd(numComponents, 1);\n          break;\n        }\n      }\n    }\n  }\n}",
            "// TODO: Compute number of connected components\n  // TODO: Update the variable numComponents with the result\n\n  // Set each block to process N/blockDim.x rows\n  __shared__ int count[TILE_SIZE][TILE_SIZE];\n  int bx = blockIdx.x, by = blockIdx.y, tx = threadIdx.x, ty = threadIdx.y;\n  int row = bx*TILE_SIZE + tx, col = by*TILE_SIZE + ty;\n\n  // load the data from global memory into a 2D tile in shared memory\n  count[ty][tx] = A[row*N + col];\n  __syncthreads();\n\n  // Do a 2D reduction across the tile\n  for (int stride = TILE_SIZE / 2; stride > 0; stride >>= 1) {\n    if (tx < stride && col < N)\n      count[ty][tx] += count[ty][tx+stride];\n    __syncthreads();\n  }\n\n  // The 1st thread in each block writes the result to global memory\n  if (tx == 0 && col < N)\n    atomicAdd(numComponents, count[ty][tx]);\n}",
            "int *S = (int *) calloc(N, sizeof(int));\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] &&!S[j]) {\n                S[j] = 1;\n                break;\n            }\n        }\n    }\n\n    *numComponents = 0;\n    for (int i = 0; i < N; ++i) {\n        *numComponents += S[i];\n    }\n\n    free(S);\n}",
            "int tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint id = bx * blockDim.x + tx;\n\tint start = (id * (id + 1)) / 2;\n\tint end = (N * (N + 1)) / 2;\n\tint num = 0;\n\n\tfor (int i = start; i < end; ++i) {\n\t\tif (A[i] == 1) {\n\t\t\tnum++;\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, num);\n}",
            "int tidx = blockDim.x * blockIdx.x + threadIdx.x;\n\tint tidy = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif(tidx >= N || tidy >= N) return;\n\n\tif(A[tidx * N + tidy] == 0) {\n\t\treturn;\n\t}\n\n\tint tid = tidx * N + tidy;\n\tint cid = atomicAdd(numComponents, 1);\n\n\t// do the BFS\n\tdo {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[tid * N + j] == 1 && A[j * N + tidy] == 1) {\n\t\t\t\tatomicMin(&A[j * N + tidy], cid);\n\t\t\t}\n\t\t}\n\t} while(atomicExch(&A[tid * N + tidy], 0)!= cid);\n}",
            "size_t row = blockDim.x * blockIdx.x + threadIdx.x;\n  size_t col = blockDim.y * blockIdx.y + threadIdx.y;\n  if (row >= N || col >= N) return;\n\n  __shared__ int cache[BLOCK_SIZE];\n  int componentCount = 0;\n  cache[threadIdx.y] = A[row * N + col];\n\n  __syncthreads();\n\n  // All threads in the block have access to the shared memory cache\n  // Perform a breadth-first search of the graph\n  // Each thread in the block will explore a single component in the graph\n  if (cache[threadIdx.y]) {\n    componentCount = 1;\n    // Traverse the connected component\n    for (size_t i = 0; i < BLOCK_SIZE && col + i < N; i++) {\n      if (cache[i]) {\n        cache[i] = 0;\n        for (size_t j = 0; j < BLOCK_SIZE && (col + i) + j < N; j++) {\n          if (cache[(i + 1) * BLOCK_SIZE + j] &&\n              A[(row + i) * N + (col + i) + j]) {\n            cache[(i + 1) * BLOCK_SIZE + j] = 0;\n            componentCount++;\n          }\n        }\n      }\n    }\n  }\n  __syncthreads();\n\n  atomicAdd(numComponents, componentCount);\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n    int col = blockIdx.x * blockDim.x + threadIdx.x;\n    __shared__ bool visited[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ int count;\n\n    // if we are on the outside of the matrix, don't do anything\n    if (row >= N || col >= N) {\n        return;\n    }\n\n    // if we are on the edge of the matrix, but still inside, then we are not a\n    // node that is not connected\n    if (row == 0 || row == N - 1 || col == 0 || col == N - 1) {\n        return;\n    }\n\n    // if we have not already marked this node as visited\n    if (!visited[threadIdx.x][threadIdx.y]) {\n        // we need to do a breadth-first traversal of the graph\n        int rowBuffer[BLOCK_SIZE];\n        int colBuffer[BLOCK_SIZE];\n        int rowIdx = 0;\n        int colIdx = 0;\n        rowBuffer[rowIdx] = row;\n        colBuffer[colIdx] = col;\n        int bufferIdx = 1;\n        int curRow = row;\n        int curCol = col;\n        int nextRow = -1;\n        int nextCol = -1;\n        while (bufferIdx > 0) {\n            curRow = rowBuffer[rowIdx];\n            curCol = colBuffer[colIdx];\n            visited[threadIdx.x][threadIdx.y] = true;\n\n            // check up\n            if (A[curCol + curRow * N] > 0 &&!visited[curRow - 1][curCol]) {\n                rowBuffer[bufferIdx] = curRow - 1;\n                colBuffer[bufferIdx] = curCol;\n                bufferIdx++;\n            }\n            // check down\n            if (A[curCol + curRow * N] > 0 &&!visited[curRow + 1][curCol]) {\n                rowBuffer[bufferIdx] = curRow + 1;\n                colBuffer[bufferIdx] = curCol;\n                bufferIdx++;\n            }\n            // check left\n            if (A[curCol + curRow * N] > 0 &&!visited[curRow][curCol - 1]) {\n                rowBuffer[bufferIdx] = curRow;\n                colBuffer[bufferIdx] = curCol - 1;\n                bufferIdx++;\n            }\n            // check right\n            if (A[curCol + curRow * N] > 0 &&!visited[curRow][curCol + 1]) {\n                rowBuffer[bufferIdx] = curRow;\n                colBuffer[bufferIdx] = curCol + 1;\n                bufferIdx++;\n            }\n            // if we are done traversing this component, increment the count\n            if (curRow == rowBuffer[0] && curCol == colBuffer[0]) {\n                count++;\n            }\n\n            // pop the buffer and move on\n            rowIdx++;\n            colIdx++;\n            bufferIdx--;\n        }\n    }\n\n    // use atomicAdd to avoid race conditions\n    atomicAdd(numComponents, count);\n}",
            "int x = threadIdx.x + blockIdx.x * blockDim.x;\n    int y = threadIdx.y + blockIdx.y * blockDim.y;\n    int index = x + y * blockDim.x * gridDim.x;\n\n    int numComponents_l = *numComponents;\n\n    if (x >= N || y >= N || index >= N * N) {\n        return;\n    }\n\n    if (A[index] == 0) {\n        return;\n    }\n\n    int visited[16] = {0};\n    visited[0] = 1;\n\n    int q[16] = {x};\n    int q_head = 0;\n    int q_tail = 1;\n\n    int i = 0;\n    while (i < q_tail) {\n        int u = q[i];\n        for (int v = 0; v < N; v++) {\n            int index_uv = u + v * N;\n            int index_vu = v + u * N;\n            if (A[index_uv] == 1 || A[index_vu] == 1) {\n                if (visited[v] == 0) {\n                    visited[v] = 1;\n                    q[q_tail] = v;\n                    q_tail++;\n                }\n            }\n        }\n        i++;\n    }\n\n    // update the number of connected components found so far\n    *numComponents = max(numComponents_l, q_tail);\n}",
            "// Define the shared memory array to keep track of the connected components\n  extern __shared__ int s_visited[];\n  // Define the block size and the corresponding block ID\n  unsigned int blockSize = blockDim.x;\n  unsigned int bid = blockIdx.x;\n  // Define the thread ID inside the block\n  unsigned int tid = threadIdx.x;\n  // Initialize the shared memory\n  s_visited[tid] = 0;\n  __syncthreads();\n  // Perform a DFS on the graph\n  if (tid < N && A[bid*N+tid] > 0) {\n    DFS(A, N, bid, tid, s_visited);\n  }\n  // Each thread increments the number of connected components by one\n  atomicAdd(numComponents, 1);\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n  int cid = -1;\n  int num_tid = N;\n\n  // Check if this thread has work to do\n  if (tid >= N)\n    return;\n\n  // Each thread takes a vertex, and explores its connected component.\n  // If the vertex has been visited, then the connected component has\n  // already been counted, so just return.\n  if (A[tid*N+tid] == 1) {\n    atomicAdd(numComponents, 1);\n    return;\n  }\n\n  // Otherwise, this thread needs to explore its connected component.\n  // First, set the cid of the vertex.\n  A[tid*N+tid] = 1;\n  cid = tid;\n\n  // Loop until no vertices left in the component\n  while (num_tid > 0) {\n\n    // Atomically decrement the number of vertices left in the component\n    num_tid = atomicSub(numComponents, 1);\n\n    // Iterate over the neighbors of this vertex\n    for (int j = 0; j < N; j++) {\n      int nb = A[tid*N+j];\n\n      // If nb is not in this component and nb is a neighbor,\n      // set the cid of nb to cid\n      if (nb == 0 && A[j*N+tid] == 1) {\n        A[j*N+tid] = 1;\n        atomicAdd(&A[cid*N+j], 1);\n      }\n    }\n  }\n}",
            "int myIdx = blockIdx.x * blockDim.x + threadIdx.x;\n  int j, componentId = 0;\n\n  if (myIdx < N) {\n    for (j = 0; j < N; j++) {\n      if (A[j * N + myIdx] == 1)\n        componentId++;\n    }\n    atomicAdd(numComponents, componentId);\n  }\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if(x >= N || y >= N) return;\n\n  // check for connectivity\n  if(A[x + y * N]) {\n\n    // count the components\n    atomicAdd(numComponents, 1);\n  }\n\n}",
            "int i = threadIdx.x + blockDim.x * blockIdx.x; // global index\n  if (i >= N) return;\n  __shared__ int visited[1024];\n  visited[threadIdx.x] = 0;\n  __syncthreads();\n  // If not visited, do a DFS and mark as visited\n  if (visited[i] == 0 && A[i*N + i] == 1) {\n    visited[i] = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        visited[j] = 1;\n      }\n    }\n  }\n  __syncthreads();\n  int localSum = 0;\n  for (int j = 0; j < N; j++) {\n    localSum += visited[j];\n  }\n  atomicAdd(numComponents, localSum);\n}",
            "int rowID = blockIdx.y * blockDim.y + threadIdx.y;\n    int colID = blockIdx.x * blockDim.x + threadIdx.x;\n\n    int i, j;\n\n    // Check if the rowID and colID are in the bound of matrix\n    if (rowID < N && colID < N) {\n\n        // Set the visited array\n        int *visited = (int *)malloc(N * sizeof(int));\n        for (i = 0; i < N; i++) {\n            visited[i] = 0;\n        }\n\n        // Check the connected components recursively\n        if (A[rowID * N + colID] == 1 && visited[rowID] == 0) {\n            visited[rowID] = 1;\n            component(A, rowID, colID, N, visited);\n        }\n\n        int count = 0;\n        for (i = 0; i < N; i++) {\n            if (visited[i] == 1) {\n                count++;\n            }\n        }\n\n        *numComponents = count;\n\n        free(visited);\n    }\n}",
            "__shared__ int cache[BLOCK_SIZE * BLOCK_SIZE];\n  // TODO: Initialize cache[tid] with the vertex index\n\n  int tid = threadIdx.x + threadIdx.y * blockDim.x;\n  int gid = blockIdx.x * blockDim.x + threadIdx.x;\n  int bid = blockIdx.x;\n  int tid_x = threadIdx.x;\n  int tid_y = threadIdx.y;\n  int bid_x = blockIdx.x;\n  int bid_y = blockIdx.y;\n\n  if (gid < N) {\n    cache[tid] = -1;\n  }\n  __syncthreads();\n\n  // TODO: Perform BFS on the vertex gid\n  // TODO: Update cache[tid] with the current component id\n  // TODO: Increment numComponents when a new component is discovered\n\n  __syncthreads();\n\n  if (gid < N) {\n    atomicAdd(numComponents, 1);\n  }\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if(i < N && j < N && i!= j && A[i*N + j])\n    atomicAdd(numComponents, 1);\n}",
            "unsigned id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int component[TILE_SIZE];\n\n\tcomponent[threadIdx.x] = id < N? A[id] : 0;\n\tif (id == 0)\n\t\tcomponent[threadIdx.x] = 1;\n\n\t__syncthreads();\n\n\tfor (int offset = 1; offset < blockDim.x; offset *= 2) {\n\t\tint other = threadIdx.x + offset;\n\t\tif (other < blockDim.x) {\n\t\t\tcomponent[threadIdx.x] += component[other];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numComponents, component[0]);\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (idx < N) {\n\t\tif (A[idx] == 1) {\n\t\t\tint c = 1;\n\t\t\tint nbidx = idx + N;\n\t\t\tif (nbidx >= N * N) return;\n\t\t\twhile (A[nbidx]!= 0 && c!= N - 1) {\n\t\t\t\tnbidx = nbidx + N;\n\t\t\t\tc = c + 1;\n\t\t\t}\n\t\t\tif (c == N - 1) atomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// 2D block/thread ID\n\tint bx = blockIdx.x; int by = blockIdx.y;\n\t// 2D thread ID within a block\n\tint tx = threadIdx.x; int ty = threadIdx.y;\n\t// 1D thread ID\n\tint tid = bx * blockDim.x + tx;\n\tint tidy = by * blockDim.y + ty;\n\n\t__shared__ int sdata[TILE_SIZE][TILE_SIZE];\n\n\t// Loop over all tiles in A\n\tfor (int i = 0; i < N/TILE_SIZE; i++) {\n\t\t// Load the matrix tile into shared memory\n\t\tsdata[ty][tx] = A[tidy*N + tid];\n\t\t__syncthreads();\n\n\t\t// Traverse the matrix tile in shared memory and count components\n\t\tfor (int j = 0; j < TILE_SIZE; j++) {\n\t\t\tif (sdata[ty][j] == 1 && sdata[j][tx] == 1) {\n\t\t\t\tatomicAdd(numComponents, 1);\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "int num = *numComponents;\n\tint id = threadIdx.x + blockDim.x * blockIdx.x;\n\tif (A[id]!= 0) {\n\t\tnum++;\n\t}\n\t*numComponents = num;\n}",
            "// Use atomicCAS to update the number of components, numComponents\n  const int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  const int cnt = atomicCAS(&numComponents[0], 0, 1);\n  if (tid < N) {\n    const int r = tid / N;\n    const int c = tid % N;\n    if (A[r * N + c] == 1) {\n      atomicCAS(&numComponents[0], cnt, cnt + 1);\n    }\n  }\n}",
            "int row = blockIdx.x;\n\tint col = blockIdx.y;\n\n\tif (row < N && col < N) {\n\t\tint a = A[row + col * N];\n\t\tif (a == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.y + threadIdx.y;\n\n\tif (i < N && j < N) {\n\t\tatomicAdd(&numComponents[A[i*N+j]], 1);\n\t}\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n    int tid = threadIdx.x;\n\n    __shared__ int sdata[BLOCK_SIZE];\n\n    if (id >= N)\n        return;\n\n    sdata[tid] = A[id];\n    __syncthreads();\n\n    for (int s = BLOCK_SIZE / 2; s > 0; s >>= 1) {\n        if (tid < s) {\n            sdata[tid] = sdata[tid] + sdata[tid + s];\n        }\n        __syncthreads();\n    }\n\n    if (tid == 0) {\n        atomicAdd(numComponents, sdata[0]);\n    }\n}",
            "__shared__ bool visited[BLOCKSIZE * BLOCKSIZE];\n    __shared__ int parent[BLOCKSIZE * BLOCKSIZE];\n\n    int tid = threadIdx.y * blockDim.x + threadIdx.x;\n    int bid = blockIdx.y * gridDim.x + blockIdx.x;\n\n    for (int i = 0; i < BLOCKSIZE * BLOCKSIZE; i++) {\n        visited[i] = false;\n        parent[i] = -1;\n    }\n\n    for (int i = bid; i < N * N; i += gridDim.x * gridDim.y) {\n        int row = i / N;\n        int col = i % N;\n\n        if (!visited[row * BLOCKSIZE + col]) {\n            visited[row * BLOCKSIZE + col] = true;\n            parent[row * BLOCKSIZE + col] = -1;\n\n            for (int j = row * N + col; j < N * N; j += N) {\n                if (A[i] &&!visited[j]) {\n                    visited[j] = true;\n                    parent[j] = row * BLOCKSIZE + col;\n                }\n            }\n        }\n    }\n\n    __syncthreads();\n\n    for (int i = 0; i < BLOCKSIZE * BLOCKSIZE; i++) {\n        if (visited[i]) {\n            int p = i;\n            int root = i;\n            while (parent[p]!= -1) {\n                p = parent[p];\n                parent[root] = parent[p];\n                root = p;\n            }\n            visited[root] = false;\n        }\n    }\n\n    __syncthreads();\n\n    for (int i = tid; i < BLOCKSIZE * BLOCKSIZE; i += BLOCKSIZE * BLOCKSIZE) {\n        if (visited[i]) {\n            atomicAdd(numComponents, 1);\n        }\n    }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (id < N) {\n        int i = 0, j = 0;\n        while (i < N) {\n            j = 0;\n            while (j < N) {\n                if (A[i*N + j] > 0) {\n                    *numComponents = *numComponents + 1;\n                    break;\n                }\n                ++j;\n            }\n            ++i;\n        }\n    }\n}",
            "int myId = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (myId < N) {\n\t\tint c = 0;\n\t\tint rowStart = myId * N;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[rowStart + i] == 1) {\n\t\t\t\tc += 1;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, c);\n\t}\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "mpi",
        "prompt": "#include <mpi.h>\n\n/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n\t Use MPI to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The component count is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// your code goes here\n  return 0;\n}",
            "/* YOUR CODE HERE */\n}",
            "int numComponents = 0;\n\t// TODO: Your code here.\n\treturn numComponents;\n}",
            "// Your code here.\n\t// TODO:\n\tint *in_buffer = (int*)malloc(sizeof(int)*N*N);\n\tint *out_buffer = (int*)malloc(sizeof(int)*N*N);\n\n\tmemcpy(in_buffer, &A[0], sizeof(int)*N*N);\n\t\n\tint root = 0;\n\tint num_procs = 1;\n\tint my_rank = 0;\n\tint num_edges = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\tMPI_Datatype MPI_INT_N = MPI_INT;\n\tMPI_Type_contiguous(N, MPI_INT, &MPI_INT_N);\n\tMPI_Type_commit(&MPI_INT_N);\n\n\tMPI_Gather(in_buffer, 1, MPI_INT_N, out_buffer, 1, MPI_INT_N, root, MPI_COMM_WORLD);\n\n\tif (my_rank == root) {\n\t\tnum_edges = 0;\n\t\tfor (int i = 0; i < num_procs; i++) {\n\t\t\tint *A_i = out_buffer + N*N*i;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (A_i[j*N + k] == 1) {\n\t\t\t\t\t\tnum_edges++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Bcast(&num_edges, 1, MPI_INT, root, MPI_COMM_WORLD);\n\n\tstd::vector<bool> *visited = new std::vector<bool>(N);\n\tstd::fill(visited->begin(), visited->end(), false);\n\n\tint num_comp = 0;\n\n\tif (my_rank == root) {\n\t\tnum_comp = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited->at(i) == false) {\n\t\t\t\tnum_comp++;\n\t\t\t\tdfs(i, A, visited, N);\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Bcast(&num_comp, 1, MPI_INT, root, MPI_COMM_WORLD);\n\n\tfree(in_buffer);\n\tfree(out_buffer);\n\n\treturn num_comp;\n}",
            "return 0;\n}",
            "/* your code here */\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      std::function<void(int)> dfs = [&](int vertex) {\n        visited[vertex] = true;\n        for (int j = 0; j < N; j++) {\n          if (A[vertex * N + j])\n            dfs(j);\n        }\n      };\n      dfs(i);\n    }\n  }\n  return count;\n}",
            "// Your code goes here\n  int num = 0;\n  std::vector<int> group;\n  group.resize(N);\n  int count = 0;\n  int rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  for (int i = 0; i < N; i++) {\n    group[i] = 1;\n  }\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        group[i] = j;\n      }\n    }\n  }\n  for (int i = 0; i < N; i++) {\n    if (group[i] == i) {\n      count++;\n    }\n  }\n  int finalCount;\n  if (rank == 0) {\n    for (int i = 1; i < N; i++) {\n      MPI_Status status;\n      MPI_Recv(&num, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n      count += num;\n    }\n    finalCount = count;\n  } else {\n    MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n  return finalCount;\n}",
            "int count = 0;\n\t\n\t//Your code here\n\n\treturn count;\n}",
            "// TODO: implement componentCount\n  return -1;\n}",
            "// your code here\n\n  return 0;\n}",
            "return 0;\n}",
            "int connected_components = 0;\n  std::vector<bool> visited(N, false);\n\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      // start DFS\n      std::stack<int> myStack;\n      myStack.push(i);\n      while (!myStack.empty()) {\n        int node = myStack.top();\n        myStack.pop();\n        visited[node] = true;\n        for (size_t j = 0; j < N; ++j) {\n          if (A[N * node + j] == 1 &&!visited[j])\n            myStack.push(j);\n        }\n      }\n      ++connected_components;\n    }\n  }\n\n  return connected_components;\n}",
            "int count = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (A[i] == 0) continue;\n        count++;\n        for (size_t j = 0; j < N; j++) {\n            if (A[i] == 0) continue;\n            A[i] &= ~(A[j]);\n        }\n    }\n    return count;\n}",
            "std::vector<bool> visited(N, false);\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) continue;\n\t\tvisited[i] = true;\n\t\tcount++;\n\t\t//std::cout << i << std::endl;\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tvisited[j] = true;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "/* TODO */\n}",
            "// TODO: fill in\n}",
            "int count = 0;\n  int myCount = 0;\n  int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // Your code here\n  \n  MPI_Gather(&myCount, 1, MPI_INT, &count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return count;\n}",
            "// TODO: your code here\n    int *dist, *dist_total;\n    dist = (int *)malloc(N * sizeof(int));\n    dist_total = (int *)malloc(N * sizeof(int));\n    //fill the array with zeros\n    for (int i = 0; i < N; i++) {\n        dist[i] = 0;\n    }\n\n    //set the distance to 1 for each row of matrix and for the ith row, set distance to 0\n    for (int i = 0; i < N; i++) {\n        dist[i] = 1;\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j]!= 1) {\n                dist[i] = 0;\n                break;\n            }\n        }\n    }\n\n    //set the distance to 1 for each column of matrix and for the ith row, set distance to 0\n    for (int i = 0; i < N; i++) {\n        dist_total[i] = 1;\n        for (int j = 0; j < N; j++) {\n            if (A[j*N + i]!= 1) {\n                dist_total[i] = 0;\n                break;\n            }\n        }\n    }\n\n    //find the union of all the elements in the two arrays\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n        if (dist[i] == 1 && dist_total[i] == 1) {\n            count++;\n        }\n    }\n    return count;\n}",
            "// TODO: Add code here\n}",
            "int r = 0;\n\treturn r;\n}",
            "if (N == 0)\n        return 0;\n    int count = 0;\n    std::vector<int> visited(N, 0);\n    for (size_t i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            dfs(A, N, i, visited);\n            count++;\n        }\n    }\n    return count;\n}",
            "int count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(A[i * N + i]) {\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "return 0;\n}",
            "/*\n\t* Your solution should:\n\t*\n\t*   1. Have a master rank with rank 0.\n\t*\n\t*   2. All ranks have a copy of the matrix (use scatter/gather)\n\t*\n\t*   3. Use MPI_Scan to compute the number of components (see mpi.h)\n\t*\n\t*   4. Broadcast the number of components from rank 0 to all ranks (use MPI_Bcast)\n\t*\n\t*/\n\n\tMPI_Status status;\n\tint rank, p;\n\tint comps = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\tif (N == 0) {\n\t\treturn 0;\n\t}\n\tif (rank == 0) {\n\t\tint recvData[p-1];\n\t\tint sendData[p-1];\n\t\tint tmp = 0;\n\t\tfor (int i = 1; i < p; i++) {\n\t\t\tint tmp = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[j*N+i] == 1)\n\t\t\t\t\ttmp++;\n\t\t\t}\n\t\t\tsendData[i - 1] = tmp;\n\t\t}\n\t\tMPI_Scatter(sendData, 1, MPI_INT, &comps, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\tfor (int i = 1; i < p; i++) {\n\t\t\tMPI_Recv(&recvData[i - 1], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n\t\t}\n\t\tfor (int i = 0; i < p - 1; i++) {\n\t\t\tcomps = comps + recvData[i];\n\t\t}\n\t\tMPI_Bcast(&comps, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\treturn comps;\n\t}\n\telse {\n\t\tint tmp = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[rank*N+j] == 1)\n\t\t\t\ttmp++;\n\t\t}\n\t\tMPI_Scan(&tmp, &comps, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\t\treturn comps;\n\t}\n}",
            "// TODO: implement this function\n    std::vector<int> visited(N,0);\n    int count=0;\n    for(int i=0;i<N;i++){\n        if(visited[i]==0){\n            count++;\n            dfs(visited,i,A,N);\n        }\n    }\n\n    return count;\n}",
            "// TODO\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tconst int root = 0;\n\tint count;\n\tif(rank == root) {\n\t\tint my_count = 0;\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tif(A[i * N + i] == 1) {\n\t\t\t\tmy_count++;\n\t\t\t}\n\t\t}\n\t\tMPI_Reduce(&my_count, &count, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\t} else {\n\t\tint my_count = 0;\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tif(A[i * N + i] == 1) {\n\t\t\t\tmy_count++;\n\t\t\t}\n\t\t}\n\t\tMPI_Reduce(&my_count, NULL, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\t}\n\treturn count;\n}",
            "// Replace this line with your implementation.\n    return -1;\n}",
            "std::vector<int> colors(N, -1);\n  std::queue<int> queue;\n  int count = 0;\n\n  for (size_t row = 0; row < N; ++row) {\n    if (colors[row] == -1) {\n      colors[row] = 0;\n      queue.push(row);\n\n      while (!queue.empty()) {\n        int color = colors[queue.front()];\n        queue.pop();\n\n        for (size_t col = 0; col < N; ++col) {\n          if (A[row * N + col] == 1 && colors[col] == -1) {\n            colors[col] = color;\n            queue.push(col);\n          } else if (A[row * N + col] == 1 && colors[col]!= color) {\n            return 0;\n          }\n        }\n      }\n\n      count += 1;\n    }\n  }\n\n  return count;\n}",
            "if (A.size()!= N*N) {\n    std::cerr << \"ERROR: invalid input\" << std::endl;\n    std::exit(EXIT_FAILURE);\n  }\n\n  // TODO: compute the number of connected components in the graph defined by the adjacency matrix A\n  // A is an NxN adjacency matrix stored in row-major.\n\n  // NOTE: You can use BFS, DFS, Union-Find, or any other algorithm that you would use\n  // in the sequential case.\n\n  // BEGIN TODO\n  int component_count = 0;\n  // END TODO\n\n  return component_count;\n}",
            "int count = 0;\n\n\tfor (auto const& el : A) {\n\t\tif (el > 0) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int count = 0;\n  // TODO: Fill this in\n  return count;\n}",
            "int count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i*N + j] == 0) continue;\n\t\t\tif (i == j) continue;\n\t\t\t++count;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<int> seen(N);\n\tint count = 0;\n\tstd::function<void(int)> dfs = [&](int v) {\n\t\tseen[v] = true;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[v * N + i] &&!seen[i]) {\n\t\t\t\tdfs(i);\n\t\t\t}\n\t\t}\n\t};\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (!seen[i]) {\n\t\t\tcount++;\n\t\t\tdfs(i);\n\t\t}\n\t}\n\treturn count;\n}",
            "size_t n = A.size();\n\tstd::vector<bool> visited(n, false);\n\tstd::vector<int> component(n, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < n; i++) {\n\t\tif (!visited[i]) {\n\t\t\tcomponent[i] = count;\n\t\t\tdfs(A, i, visited, component, count);\n\t\t}\n\t}\n\n\tstd::vector<int> componentCount(n, 0);\n\tfor (size_t i = 0; i < n; i++) {\n\t\tcomponentCount[component[i]]++;\n\t}\n\n\treturn componentCount[count];\n}",
            "int count = 0;\n\t\n\tstd::vector<bool> visited(N);\n\tfor (size_t v = 0; v < N; v++) {\n\t\tif (!visited[v]) {\n\t\t\tstd::queue<size_t> Q;\n\t\t\tQ.push(v);\n\t\t\twhile (!Q.empty()) {\n\t\t\t\tauto w = Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tif (!visited[w]) {\n\t\t\t\t\tvisited[w] = true;\n\t\t\t\t\tfor (size_t u = 0; u < N; u++) {\n\t\t\t\t\t\tif (A[N*w+u]) {\n\t\t\t\t\t\t\tQ.push(u);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "/* Replace with your implementation */\n    return 0;\n}",
            "int count = 0;\n  bool seen[N];\n  for (size_t i = 0; i < N; ++i) {\n    seen[i] = false;\n  }\n  for (size_t i = 0; i < N; ++i) {\n    if (!seen[i]) {\n      count++;\n      // Mark i as seen, and the node i is connected to.\n      seen[i] = true;\n      dfs(i, A, N, seen);\n    }\n  }\n  return count;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint commCount = 0;\n\tif (rank == 0) {\n\t\t// Create a vector of visited vertices\n\t\tstd::vector<bool> visited(N, false);\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited[i])\n\t\t\t\tcontinue;\n\n\t\t\tcommCount++;\n\n\t\t\t// Traverse the graph and mark as visited\n\t\t\tstd::stack<int> st;\n\t\t\tst.push(i);\n\t\t\twhile (!st.empty()) {\n\t\t\t\tint v = st.top();\n\t\t\t\tst.pop();\n\t\t\t\tvisited[v] = true;\n\n\t\t\t\t// Push the unvisited neighbors to the stack\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[i * N + j]!= 0 &&!visited[j])\n\t\t\t\t\t\tst.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint commCountAll;\n\tMPI_Reduce(&commCount, &commCountAll, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn commCountAll;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint root = 0;\n\tint i = rank;\n\tint j = 0;\n\tint start = rank * N;\n\tint end = start + N;\n\tint count = 0;\n\tint localCount = 0;\n\n\twhile (i < end && j < N) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tlocalCount++;\n\t\t\tcount++;\n\t\t\twhile (j < N && A[i * N + j] == 1) {\n\t\t\t\tj++;\n\t\t\t}\n\t\t}\n\t\ti++;\n\t\tj = 0;\n\t}\n\tMPI_Reduce(&localCount, &count, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\treturn count;\n}",
            "int c = 0;\n\tstd::vector<bool> visited(N, false);\n\n\tfor (size_t v = 0; v < N; ++v) {\n\t\tif (visited[v]) continue;\n\t\tstd::vector<int> Q;\n\t\tQ.push_back(v);\n\t\twhile (!Q.empty()) {\n\t\t\tsize_t u = Q.back();\n\t\t\tQ.pop_back();\n\t\t\tif (visited[u]) continue;\n\t\t\t++c;\n\t\t\tvisited[u] = true;\n\t\t\tfor (size_t w = 0; w < N; ++w) {\n\t\t\t\tif (!visited[w] && A[u * N + w]) {\n\t\t\t\t\tQ.push_back(w);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn c;\n}",
            "int myID = 0;\n\tint nProcs = 1;\n\n\tint root = 0;\n\tint numOfComponents = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myID);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nProcs);\n\n\tint localSize = (N + nProcs - 1) / nProcs;\n\tint localStart = myID * localSize;\n\n\tint *A_local = new int[localSize * localSize];\n\n\tif (myID == 0) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tA_local[i * localSize + j] = A[i * N + j];\n\t\t\t}\n\t\t}\n\t}\n\n\t//broadcast to all\n\tMPI_Bcast(A_local, localSize * localSize, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tstd::vector<bool> visited(localSize);\n\tstd::vector<int> localComponents(localSize);\n\n\tfor (int i = 0; i < localSize; i++) {\n\t\tvisited[i] = false;\n\t\tlocalComponents[i] = 0;\n\t}\n\n\t//loop through every node\n\tfor (int i = 0; i < localSize; i++) {\n\t\t//for each node, check if it has been visited\n\t\tif (!visited[i]) {\n\t\t\t//if not, mark it as visited\n\t\t\tvisited[i] = true;\n\n\t\t\tfor (int j = 0; j < localSize; j++) {\n\t\t\t\tif (A_local[i * localSize + j] == 1 &&!visited[j]) {\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tlocalComponents[i] = 1;\n\t\t}\n\t}\n\n\tint *components = new int[nProcs];\n\tMPI_Gather(&localComponents[0], localSize, MPI_INT, components, localSize, MPI_INT, root, MPI_COMM_WORLD);\n\n\tif (myID == 0) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tnumOfComponents += A[i * N + j];\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 1; i < nProcs; i++) {\n\t\t\tfor (int j = 0; j < localSize; j++) {\n\t\t\t\tnumOfComponents += components[i * localSize + j];\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] components;\n\tdelete[] A_local;\n\n\treturn numOfComponents;\n}",
            "if(A.size()!=N*N)\n\t\treturn -1;\n\n\tstd::vector<int> visited(N, 0);\n\tint compCount=0;\n\n\tfor(int i=0; i<N; i++){\n\t\tif(visited[i])\n\t\t\tcontinue;\n\n\t\tint nextVertex=i;\n\t\twhile(visited[nextVertex]==0){\n\t\t\tvisited[nextVertex]=1;\n\t\t\tint currVertex=nextVertex;\n\t\t\tfor(int j=0; j<N; j++){\n\t\t\t\tif(A[currVertex*N+j] && visited[j]==0){\n\t\t\t\t\tnextVertex=j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcompCount++;\n\t}\n\treturn compCount;\n}",
            "return 0;\n}",
            "int componentCount = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcomponentCount++;\n\t\t\tstd::function<void(int)> dfs = [&](int v) {\n\t\t\t\tvisited[v] = 1;\n\t\t\t\tfor (int u = 0; u < N; u++) {\n\t\t\t\t\tif (A[N*v+u] == 1 && visited[u] == 0) {\n\t\t\t\t\t\tdfs(u);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tdfs(i);\n\t\t}\n\t}\n\n\treturn componentCount;\n}",
            "int* A_flat = new int[N*N];\n    for (size_t i=0; i<N; ++i) {\n        for (size_t j=0; j<N; ++j) {\n            A_flat[i*N + j] = A[i*N + j];\n        }\n    }\n    MPI_Comm comm = MPI_COMM_WORLD;\n    int worldSize, worldRank;\n    MPI_Comm_size(comm, &worldSize);\n    MPI_Comm_rank(comm, &worldRank);\n    int* componentCounts = new int[worldSize];\n\n    // TODO: Add code here\n\n    delete[] A_flat;\n    delete[] componentCounts;\n    return 0;\n}",
            "int numConnectedComponents = 0;\n    bool visited[N];\n    for (int i = 0; i < N; i++) {\n        if (!visited[i]) {\n            numConnectedComponents++;\n            bool foundNext = true;\n            std::stack<int> nodes;\n            nodes.push(i);\n            while (!nodes.empty()) {\n                int currentNode = nodes.top();\n                nodes.pop();\n                for (int j = 0; j < N; j++) {\n                    if (A[currentNode*N + j]) {\n                        if (visited[j]) {\n                            foundNext = false;\n                        } else {\n                            nodes.push(j);\n                            visited[j] = true;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return numConnectedComponents;\n}",
            "// TODO\n}",
            "int rank = 0;\n  int world = 1;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &world);\n  std::vector<int> B(A.size(), 0);\n  int n = static_cast<int>(N);\n  int i, j, k;\n\n  int count = 0;\n  if (rank == 0) {\n    for (i = 0; i < n; ++i) {\n      if (B[i * n + i] == 0) {\n        count++;\n        for (j = 0; j < n; ++j) {\n          if (A[i * n + j]!= 0) {\n            B[i * n + j] = 1;\n            for (k = 0; k < n; ++k) {\n              if (A[j * n + k]!= 0) {\n                B[i * n + k] = 1;\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  MPI_Bcast(B.data(), static_cast<int>(B.size()), MPI_INT, 0, MPI_COMM_WORLD);\n  int local_count = 0;\n  for (i = 0; i < n; ++i) {\n    if (B[i * n + i] == 0) {\n      local_count++;\n    }\n  }\n  MPI_Reduce(&local_count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return count;\n}",
            "if(N == 1) {\n        return 1;\n    }\n    std::vector<int> visited(N, 0);\n\n    int count = 0;\n    for(size_t i = 0; i < N; i++) {\n        if(visited[i] == 1) {\n            continue;\n        }\n\n        std::queue<int> q;\n        q.push(i);\n        count++;\n\n        while(!q.empty()) {\n            int x = q.front();\n            q.pop();\n            if(visited[x] == 1) {\n                continue;\n            }\n            visited[x] = 1;\n            for(size_t j = 0; j < N; j++) {\n                if(A[i*N + j] == 1) {\n                    q.push(j);\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "// TODO: Fill this in\n\tint count = 0;\n\n\treturn count;\n}",
            "int rc = MPI_SUCCESS;\n    int my_rank, num_proc;\n    rc = MPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n    rc = MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n    // TODO: Your code here\n\tint component_count = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t++component_count;\n\t\t\tDFS(A, visited, i, N);\n\t\t}\n\t}\n\n\t// Gather the results on rank 0\n\tint total_components = 0;\n\tif (my_rank == 0) {\n\t\ttotal_components = component_count;\n\t}\n\n\trc = MPI_Gather(&component_count, 1, MPI_INT, &total_components, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\treturn total_components;\n}",
            "int components = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    if (A[i * N + i] == 1) {\n      components++;\n    }\n  }\n\n  return components;\n}",
            "std::vector<int> visited(N, 0);\n  std::stack<int> s;\n  int count = 0;\n\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      s.push(i);\n      visited[i] = 1;\n\n      while (!s.empty()) {\n        int row = s.top();\n        s.pop();\n\n        for (int j = 0; j < N; ++j) {\n          if (A[row * N + j] &&!visited[j]) {\n            s.push(j);\n            visited[j] = 1;\n          }\n        }\n      }\n\n      ++count;\n    }\n  }\n\n  return count;\n}",
            "return 0;\n}",
            "// You code here.\n\treturn 0;\n}",
            "std::vector<int> S(N, 0);\n  std::vector<int> B(N, 0);\n\n  // Your code here!\n  return 0;\n}",
            "std::vector<bool> visited(N, false);\n\tint num_components = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tnum_components++;\n\t\t\tstd::vector<int> curr_component = {i};\n\t\t\twhile (curr_component.size() > 0) {\n\t\t\t\tint curr = curr_component.back();\n\t\t\t\tcurr_component.pop_back();\n\t\t\t\tvisited[curr] = true;\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (!visited[j] && A[curr * N + j] == 1)\n\t\t\t\t\t\tcurr_component.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn num_components;\n}",
            "//...\n  return -1; // replace this line\n}",
            "std::vector<int> component(N, 0);\n    int ccount = 0;\n\n    // Your code here\n    std::vector<int> rcv_buffer;\n    for (size_t i = 0; i < N; i++)\n    {\n        int v = 0;\n        for (size_t j = 0; j < N; j++)\n        {\n            v += A[i*N + j];\n        }\n        if (v == 0)\n        {\n            continue;\n        }\n        MPI_Send(&v, 1, MPI_INT, v, 0, MPI_COMM_WORLD);\n        MPI_Recv(&rcv_buffer[0], 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n\n    return ccount;\n}",
            "// TODO: Replace this line with your code!\n  return 0;\n}",
            "// TODO: YOUR CODE HERE!\n  return 0;\n}",
            "// TODO: Your code here\n  int rank;\n  int size;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int count_rank = 0;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1) {\n        count_rank += 1;\n      }\n    }\n  }\n  int count_sum = 0;\n  MPI_Reduce(&count_rank, &count_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return count_sum;\n}",
            "int count = 0;\n  // TODO: Your code here\n\n  return count;\n}",
            "std::vector<bool> visited(N, false);\n\tstd::queue<int> q;\n\tint count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tq.push(i);\n\t\t\t++count;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[node] = true;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[node * N + j] &&!visited[j]) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// Your code here\n\tint numComponents = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]) {\n\t\t\t\t// start a bfs\n\t\t\t\t// mark every vertex that has been visited\n\t\t\t\t// if the vertex has not been visited, increment the number of components\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "std::vector<int> component(N); // component label for each node\n    int componentCount = 0; // number of components\n    for (size_t i = 0; i < N; i++) {\n        if (component[i] == 0) {\n            component[i] = ++componentCount;\n            for (size_t j = 0; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    if (component[j]!= 0) {\n                        for (size_t k = 0; k < N; k++) {\n                            if (component[k] == component[j]) {\n                                component[k] = component[i];\n                            }\n                        }\n                    } else {\n                        component[j] = component[i];\n                    }\n                }\n            }\n        }\n    }\n    return componentCount;\n}",
            "return 0;\n}",
            "int rank, size, count = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // Your code here\n\n    return count;\n}",
            "int rank;\n  int size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  std::vector<int> component_count(N, 0);\n\n  int n = N;\n  int m = N;\n\n  int start = 0;\n  int end = 0;\n\n  int local_size = 0;\n\n  if (size == 1)\n  {\n      component_count = connectedComponents(A, N);\n      return component_count.size();\n  }\n\n  while (n > 1)\n  {\n    if (n % size == 0)\n    {\n      end = n / size;\n    }\n    else\n    {\n      end = n / size + 1;\n    }\n\n    local_size = end - start;\n\n    std::vector<int> local_components = connectedComponents(A, local_size);\n\n    for (int i = 0; i < local_components.size(); i++)\n    {\n      component_count[i] += local_components[i];\n    }\n\n    n -= local_size;\n    start += local_size;\n  }\n\n  std::vector<int> global_components(component_count.size(), 0);\n\n  MPI_Gather(&component_count[0], local_size, MPI_INT, &global_components[0], local_size, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank == 0)\n  {\n      int count = 0;\n      for (int i = 0; i < global_components.size(); i++)\n      {\n          if (global_components[i] > 0)\n          {\n              count++;\n          }\n      }\n      return count;\n  }\n\n  return 0;\n}",
            "int count = 0;\n\n\t// TODO\n\n\treturn count;\n}",
            "int rank = 0, size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // each rank needs to know which columns it's responsible for\n  int columns_per_rank = N / size;\n  int remainder = N % size;\n  int first_column = rank * columns_per_rank + std::min(rank, remainder);\n  int last_column = first_column + columns_per_rank - 1 + (rank < remainder);\n\n  // each rank needs to know which rows it's responsible for\n  int rows_per_rank = N / size;\n  int first_row = rank * rows_per_rank + std::min(rank, remainder);\n  int last_row = first_row + rows_per_rank - 1 + (rank < remainder);\n\n  // every rank has to run BFS on its part of the graph\n  int num_components = 0;\n  for (int r = first_row; r <= last_row; ++r) {\n    int visited = 0;\n    // initialize a queue with unvisited nodes from each connected component\n    for (int c = first_column; c <= last_column; ++c)\n      if (A[r * N + c]) {\n        ++visited;\n        for (int i = 0; i < N; ++i)\n          if (A[r * N + i])\n            std::cout << i << \" \";\n        std::cout << std::endl;\n      }\n    // if we haven't visited all columns, we need to do BFS\n    if (visited < N)\n      ++num_components;\n  }\n  // gather number of components on rank 0\n  if (rank!= 0)\n    MPI_Send(&num_components, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  else {\n    std::vector<int> num_components_per_rank(size, 0);\n    MPI_Recv(num_components_per_rank.data(), size, MPI_INT, MPI_ANY_SOURCE, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    for (auto v : num_components_per_rank)\n      num_components += v;\n  }\n  return num_components;\n}",
            "// TODO: implement\n}",
            "// TODO: Implement me!\n\treturn 0;\n}",
            "int *component = new int[N];\n  int *group = new int[N];\n\n  int num_component = 0;\n\n  for (int i = 0; i < N; i++) {\n    component[i] = -1;\n    group[i] = -1;\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (component[i] == -1) {\n      num_component++;\n      group[i] = num_component;\n\n      for (int j = 0; j < N; j++) {\n        if (component[j] == -1 && A[i * N + j] == 1) {\n          component[j] = num_component;\n          group[j] = num_component;\n        }\n      }\n    }\n  }\n\n  delete[] component;\n  delete[] group;\n\n  return num_component;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tstd::vector<int> comp_count(N, 0);\n\tstd::vector<int> out_comp_count(N, 0);\n\tint total_comp_count = 0;\n\n\t// TODO: fill in your code here\n\n\tif (rank == 0) {\n\t\t// TODO: collect the counts of the components from each rank\n\t\t// TODO: add up all the total counts in total_comp_count\n\t}\n\n\treturn total_comp_count;\n}",
            "// TODO\n\n\tint size;\n\tint rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> subA(N*N/size);\n\tMPI_Scatter(A.data(), N*N/size, MPI_INT, subA.data(), N*N/size, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(subA[i*N + j] == 1){\n\t\t\t\tint x = i*N + j;\n\t\t\t\tint y = i*N + j + 1;\n\t\t\t\tint z = (i + 1)*N + j;\n\t\t\t\tint w = (i + 1)*N + j + 1;\n\t\t\t\tif(rank == 0){\n\t\t\t\t\tif(subA[y] == 1){\n\t\t\t\t\t\tsubA[x] = 0;\n\t\t\t\t\t\tsubA[y] = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif(subA[z] == 1){\n\t\t\t\t\t\tsubA[x] = 0;\n\t\t\t\t\t\tsubA[z] = 0;\n\t\t\t\t\t}\n\t\t\t\t\tif(subA[w] == 1){\n\t\t\t\t\t\tsubA[x] = 0;\n\t\t\t\t\t\tsubA[w] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(rank == 1){\n\t\t\t\t\tif(subA[x] == 1){\n\t\t\t\t\t\tsubA[y] = 0;\n\t\t\t\t\t\tsubA[z] = 0;\n\t\t\t\t\t\tsubA[w] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(rank == 2){\n\t\t\t\t\tif(subA[x] == 1){\n\t\t\t\t\t\tsubA[y] = 0;\n\t\t\t\t\t\tsubA[z] = 0;\n\t\t\t\t\t\tsubA[w] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(rank == 3){\n\t\t\t\t\tif(subA[x] == 1){\n\t\t\t\t\t\tsubA[y] = 0;\n\t\t\t\t\t\tsubA[z] = 0;\n\t\t\t\t\t\tsubA[w] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint result;\n\tMPI_Reduce(&subA, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn result;\n}",
            "// TODO: implement\n}",
            "// TODO\n}",
            "int rank = 0;\n  int size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int count = 0;\n\n  // The root rank should send the data to the workers\n  if (rank == 0) {\n    // Send the number of elements in the matrix\n    MPI_Send(&N, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n\n    // Send the data to each worker\n    for (int i = 1; i < size; i++) {\n      MPI_Send(A.data() + (N*i), N, MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n  }\n\n  // The workers should receive the number of elements in the matrix\n  int workerN = 0;\n  MPI_Recv(&workerN, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n  // Each worker should receive the data for its portion of the matrix\n  std::vector<int> AWorker(workerN*workerN);\n  MPI_Recv(AWorker.data(), workerN*workerN, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n  // Each worker should count the number of connected components and report back to the root\n  int workerCount = 0;\n  if (rank!= 0) {\n    // Count the number of connected components in the data\n    workerCount = 0;\n  }\n  MPI_Reduce(&workerCount, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return count;\n}",
            "assert(A.size() == N * N);\n\n  std::vector<int> A_c = A;\n  std::vector<int> visited(A.size(), 0);\n\n  int num_comp = 0;\n\n  // for each row\n  for (size_t i = 0; i < N; ++i) {\n    // for each column in the row\n    for (size_t j = 0; j < N; ++j) {\n      // if we haven't visited this node yet and we are connected\n      if (visited[i * N + j] == 0 && A_c[i * N + j] == 1) {\n        // mark this node as visited\n        visited[i * N + j] = 1;\n        // traverse the graph starting from this node and mark all connected nodes as visited\n        for (size_t k = 0; k < N; ++k) {\n          if (A_c[i * N + k] == 1) {\n            A_c[i * N + k] = 0;\n            visited[i * N + k] = 1;\n          }\n        }\n        num_comp++;\n      }\n    }\n  }\n\n  return num_comp;\n}",
            "// TODO\n}",
            "int rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint *a = new int[N * N];\n\tint *b = new int[N * N];\n\tif(rank == 0) {\n\t\tfor(size_t i = 0; i < N * N; i++) {\n\t\t\ta[i] = A[i];\n\t\t}\n\t}\n\tfor(size_t i = 0; i < N * N; i++) {\n\t\tb[i] = 1;\n\t}\n\tMPI_Bcast(a, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(b, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint count = 0;\n\tfor(size_t i = 0; i < N; i++) {\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(a[i * N + j] == 1) {\n\t\t\t\tb[i * N + j] = 0;\n\t\t\t\tfor(size_t k = 0; k < N; k++) {\n\t\t\t\t\tif(a[i * N + k] == 1 && b[i * N + k] == 1) {\n\t\t\t\t\t\tb[i * N + k] = 0;\n\t\t\t\t\t\tfor(size_t m = 0; m < N; m++) {\n\t\t\t\t\t\t\tif(a[m * N + k] == 1 && b[m * N + k] == 1) {\n\t\t\t\t\t\t\t\tb[m * N + k] = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(&count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tdelete[] a;\n\tdelete[] b;\n\treturn count;\n}",
            "std::vector<int> V(N, 0);\n  int count = 0;\n  // TODO: implement\n  return count;\n}",
            "// TODO\n}",
            "return 0;\n}",
            "int size, rank, root = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint n = N;\n\tint *local_A = new int[n*n];\n\tint *local_B = new int[n*n];\n\tint *local_C = new int[n*n];\n\tint *local_D = new int[n*n];\n\tstd::copy(A.begin(), A.end(), local_A);\n\tstd::copy(A.begin(), A.end(), local_B);\n\tstd::copy(A.begin(), A.end(), local_C);\n\tstd::copy(A.begin(), A.end(), local_D);\n\n\tif (rank == 0)\n\t{\n\t\tMPI_Send(&local_A[0], n * n, MPI_INT, 1, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(&local_B[0], n * n, MPI_INT, 2, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(&local_C[0], n * n, MPI_INT, 3, 0, MPI_COMM_WORLD);\n\t}\n\telse if (rank == 1)\n\t{\n\t\tMPI_Recv(&local_A[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tfor (int i = 0; i < n; ++i)\n\t\t{\n\t\t\tfor (int j = 0; j < n; ++j)\n\t\t\t{\n\t\t\t\tlocal_B[i * n + j] = local_A[i * n + j] + local_A[j * n + i];\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&local_B[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\telse if (rank == 2)\n\t{\n\t\tMPI_Recv(&local_A[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tfor (int i = 0; i < n; ++i)\n\t\t{\n\t\t\tfor (int j = 0; j < n; ++j)\n\t\t\t{\n\t\t\t\tlocal_C[i * n + j] = local_A[i * n + j] + local_A[j * n + i];\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&local_C[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\telse if (rank == 3)\n\t{\n\t\tMPI_Recv(&local_A[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tfor (int i = 0; i < n; ++i)\n\t\t{\n\t\t\tfor (int j = 0; j < n; ++j)\n\t\t\t{\n\t\t\t\tlocal_D[i * n + j] = local_A[i * n + j] + local_A[j * n + i];\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&local_D[0], n * n, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\tMPI_Gather(&local_A[0], n * n, MPI_INT, &local_A[0], n * n, MPI_INT, root, MPI_COMM_WORLD);\n\n\tint num = 0;\n\tfor (int i = 0; i < n; ++i)\n\t{\n\t\tfor (int j = 0; j < n; ++j)\n\t\t{\n\t\t\tif (local_A[i * n + j] ==",
            "// TODO: YOUR CODE HERE\n    return 0;\n}",
            "std::vector<int> connected(N, 0);\n\tint componentCount = 0;\n\tint root = 0;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> disjoint_set;\n\tfor (int i = 0; i < N; i++) {\n\t\tdisjoint_set.push_back(i);\n\t}\n\n\t// MPI COMMUNICATION\n\tMPI_Status status;\n\tint recvcount;\n\tMPI_Request request;\n\tint i = rank;\n\n\t// MASTER SENDS DATA\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tint node_i = i;\n\t\t\t\tint node_j = j;\n\t\t\t\tif (A[i * N + j] == 1 && i < j) {\n\t\t\t\t\tMPI_Isend(&i, 1, MPI_INT, j, 0, MPI_COMM_WORLD, &request);\n\t\t\t\t\tMPI_Isend(&j, 1, MPI_INT, j, 0, MPI_COMM_WORLD, &request);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// EVERYONE COMPUTES\n\telse {\n\t\twhile (i < N) {\n\t\t\tMPI_Recv(&node_i, 1, MPI_INT, root, 0, MPI_COMM_WORLD, &status);\n\t\t\tMPI_Recv(&node_j, 1, MPI_INT, root, 0, MPI_COMM_WORLD, &status);\n\t\t\tstd::vector<int> parents = findParents(node_i, disjoint_set);\n\t\t\tstd::vector<int> parents2 = findParents(node_j, disjoint_set);\n\t\t\tif (parents[0]!= parents2[0] || parents[1]!= parents2[1]) {\n\t\t\t\tdisjoint_set.at(parents[0]) = parents2[0];\n\t\t\t\tdisjoint_set.at(parents[1]) = parents2[1];\n\t\t\t\ti = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\t}\n\n\t// MASTER COMPUTES AND SENDS BACK TO ROOT\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tint node_i = i;\n\t\t\t\tint node_j = j;\n\t\t\t\tif (A[i * N + j] == 1 && i < j) {\n\t\t\t\t\tstd::vector<int> parents = findParents(node_i, disjoint_set);\n\t\t\t\t\tstd::vector<int> parents2 = findParents(node_j, disjoint_set);\n\t\t\t\t\tif (parents[0]!= parents2[0] || parents[1]!= parents2[1]) {\n\t\t\t\t\t\tcomponentCount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Isend(&componentCount, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);\n\t}\n\n\tMPI_Barrier(MPI_COMM_WORLD);\n\tMPI_Finalize();\n\n\treturn componentCount;\n}",
            "if(N == 0) {\n\t\treturn 0;\n\t}\n\tif(N == 1) {\n\t\treturn 1;\n\t}\n\tstd::vector<int> parent(N);\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tparent[i] = i;\n\t}\n\n\t// for each i-j edge, if i and j are not connected yet,\n\t// they are now connected and we need to find the new\n\t// root of the group to which i belongs\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tfor(size_t j = 0; j < i; ++j) {\n\t\t\tif(A[i * N + j]) {\n\t\t\t\tint rootI = find(parent, i);\n\t\t\t\tint rootJ = find(parent, j);\n\n\t\t\t\tif(rootI!= rootJ) {\n\t\t\t\t\tparent[rootJ] = rootI;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// each rank keeps track of how many root elements it has found\n\tint localCount = 0;\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tlocalCount += parent[i] == i;\n\t}\n\n\t// root elements in every rank count as a connected component\n\tint count;\n\tMPI_Reduce(&localCount, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn count;\n}",
            "// TODO: implement\n  return 0;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// number of elements per rank\n\tauto n = N / size;\n\n\t// get rank's submatrix\n\tauto subA = std::vector<int>(n * n);\n\tstd::copy(A.begin() + n * rank, A.begin() + n * (rank + 1), subA.begin());\n\n\t// determine which rows are connected to each other\n\tstd::vector<bool> connected(n);\n\tfor (auto i = 0; i < n; ++i) {\n\t\tfor (auto j = 0; j < n; ++j) {\n\t\t\tif (subA[i * n + j]!= 0) {\n\t\t\t\tconnected[i] = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// determine which columns are connected to each other\n\tfor (auto i = 0; i < n; ++i) {\n\t\tfor (auto j = 0; j < n; ++j) {\n\t\t\tif (subA[j * n + i]!= 0) {\n\t\t\t\tconnected[j] = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t// determine number of connected components\n\tint num_connected = std::count(connected.begin(), connected.end(), true);\n\n\t// allgather the number of connected components in each submatrix\n\tauto counts = std::vector<int>(size);\n\tMPI_Allgather(&num_connected, 1, MPI_INT, counts.data(), 1, MPI_INT, MPI_COMM_WORLD);\n\n\t// sum the total number of connected components\n\tint total_num_connected = std::accumulate(counts.begin(), counts.end(), 0);\n\n\treturn total_num_connected;\n}",
            "return 0;\n}",
            "assert(A.size() == N * N);\n\tstd::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t++count;\n\t\t\tvisited[i] = 1;\n\n\t\t\tstd::queue<int> Q;\n\t\t\tQ.push(i);\n\n\t\t\twhile (Q.size() > 0) {\n\t\t\t\tint curr = Q.front();\n\t\t\t\tQ.pop();\n\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[curr*N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tQ.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tint connected_components = 0;\n\n\tauto dfs = [&visited, &connected_components] (size_t node, int row, int col, std::vector<int> const& A, size_t N) {\n\t\tif (row < 0 || row >= N || col < 0 || col >= N || visited[row] || A[row * N + col] == 0) {\n\t\t\treturn;\n\t\t}\n\n\t\tvisited[row] = true;\n\n\t\tfor (size_t i = 0; i < 4; ++i) {\n\t\t\tauto x = static_cast<int>(row) + DIR[i][0];\n\t\t\tauto y = static_cast<int>(col) + DIR[i][1];\n\t\t\tdfs(node, x, y, A, N);\n\t\t}\n\n\t\tconnected_components++;\n\t};\n\n\tfor (size_t node = 0; node < N; ++node) {\n\t\tfor (size_t i = 0; i < 4; ++i) {\n\t\t\tauto x = static_cast<int>(node) + DIR[i][0];\n\t\t\tauto y = static_cast<int>(node) + DIR[i][1];\n\t\t\tdfs(node, x, y, A, N);\n\t\t}\n\t}\n\n\treturn connected_components;\n}",
            "// TODO: implement\n\treturn 0;\n}",
            "if (N == 1) {\n\t\treturn 1;\n\t}\n\n\tint count = 1;\n\tint i = 0;\n\twhile (i < N) {\n\t\tif (A[i] == 1) {\n\t\t\ti++;\n\t\t}\n\t\telse {\n\t\t\tcount++;\n\t\t\twhile (A[i]!= 1) {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\ti++;\n\t}\n\treturn count;\n}",
            "/*\n\t\t  MPI_Allgather()\n\t\t    Each process sends a message to all other processes\n\t\t    MPI_Allgather(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm)\n\n\t\t  MPI_Reduce()\n\t\t    Reduce values from all processes into the current process\n\t\t    MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm)\n\n\t\t  MPI_Allreduce()\n\t\t    Reduce values from all processes into the current process\n\t\t    MPI_Allreduce(sendbuf, recvbuf, count, datatype, op, comm)\n\n\t\t  MPI_Allgatherv()\n\t\t    Each process sends a message to all other processes\n\t\t    MPI_Allgatherv(sendbuf, sendcount, sendtype, recvbuf, recvcounts, displs, recvtype, comm)\n\n\t\t  MPI_Alltoall()\n\t\t    Each process sends a message to all other processes\n\t\t    MPI_Alltoall(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, comm)\n\n\t\t  MPI_Alltoallv()\n\t\t    Each process sends a message to all other processes\n\t\t    MPI_Alltoallv(sendbuf, sendcounts, sdispls, sendtype, recvbuf, recvcounts, rdispls, recvtype, comm)\n\n\t\t  MPI_Gather()\n\t\t    Each process sends a message to the root process\n\t\t    MPI_Gather(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, root, comm)\n\n\t\t  MPI_Gatherv()\n\t\t    Each process sends a message to the root process\n\t\t    MPI_Gatherv(sendbuf, sendcount, sendtype, recvbuf, recvcounts, displs, recvtype, root, comm)\n\n\t\t  MPI_Scatter()\n\t\t    Root process sends a message to all other processes\n\t\t    MPI_Scatter(sendbuf, sendcount, sendtype, recvbuf, recvcount, recvtype, root, comm)\n\n\t\t  MPI_Scatterv()\n\t\t    Root process sends a message to all other processes\n\t\t    MPI_Scatterv(sendbuf, sendcounts, displs, sendtype, recvbuf, recvcount, recvtype, root, comm)\n\n\t\t  MPI_Reduce_scatter_block()\n\t\t    Reduce values from all processes into the current process\n\t\t    MPI_Reduce_scatter_block(sendbuf, recvbuf, recvcount, datatype, op, comm)\n\n\t\t  MPI_Reduce_scatter()\n\t\t    Reduce values from all processes into the current process\n\t\t    MPI_Reduce_scatter(sendbuf, recvbuf, recvcounts, datatype, op, comm)\n\n\t\t  MPI_Bcast()\n\t\t    Sends a message from the root process to all other processes\n\t\t    MPI_Bcast(buffer, count, datatype, root, comm)\n\n\t\t  MPI_Send()\n\t\t    Sends a message to a specified process\n\t\t    MPI_Send(buffer, count, datatype, dest, tag, comm)\n\n\t\t  MPI_Recv()\n\t\t    Receives a message from a specified process\n\t\t    MPI_Recv(buffer, count, datatype, source, tag, comm, status)\n\n\t\t  MPI_Sendrecv()\n\t\t    Sends a message to a specified process and receives a message from an unknown process\n\t\t    MPI_Sendrecv(sendbuf, sendcount, sendtype, dest, sendtag, recvbuf, recvcount, recvtype, source, recvtag, comm, status)\n\n\t\t  MPI_Sendrecv_replace()\n\t\t    Sends a message to a specified process and receives a message from an unknown process\n\t\t    MPI_Sendrecv_replace(buffer, count, datatype, dest, sendtag, source, rec",
            "std::vector<int> visited(N, 0);\n\n  // TODO\n  return 0;\n}",
            "MPI_Comm communicator = MPI_COMM_WORLD;\n  int rank;\n  MPI_Comm_rank(communicator, &rank);\n\n  int N_local = N/4;\n  std::vector<int> A_local(N_local * N_local);\n\n  MPI_Scatter(A.data(), N_local * N_local, MPI_INT, A_local.data(), N_local * N_local, MPI_INT, 0, communicator);\n\n  std::vector<bool> visited(N_local * N_local);\n  std::vector<int> to_visit;\n  int count = 0;\n  for (int i = 0; i < N_local; i++) {\n    for (int j = 0; j < N_local; j++) {\n      if (visited[i * N_local + j] == false && A_local[i * N_local + j] == 1) {\n        visited[i * N_local + j] = true;\n        to_visit.push_back(i * N_local + j);\n        while (to_visit.size()!= 0) {\n          int vertex = to_visit.back();\n          to_visit.pop_back();\n          for (int neighbor = 0; neighbor < N_local; neighbor++) {\n            int neighbor_index = vertex + neighbor;\n            if (A_local[neighbor_index] == 1 && visited[neighbor_index] == false) {\n              to_visit.push_back(neighbor_index);\n              visited[neighbor_index] = true;\n            }\n          }\n        }\n        count++;\n      }\n    }\n  }\n\n  int count_global;\n  MPI_Reduce(&count, &count_global, 1, MPI_INT, MPI_SUM, 0, communicator);\n  return count_global;\n}",
            "// TODO: implement\n\n\treturn 0;\n}",
            "int rank, num_proc;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n\n    std::vector<int> components(N, 0);\n    std::vector<int> rank_results(num_proc, 0);\n    int rank_result = 0;\n\n    for (int i = 0; i < N; i++) {\n        if (components[i] == 0) {\n            int j = i;\n            do {\n                components[j] = rank + 1;\n                rank_result++;\n                for (int k = 0; k < N; k++) {\n                    if (A[j * N + k] > 0 && components[k] == 0) {\n                        j = k;\n                        break;\n                    }\n                }\n            } while (j!= i);\n        }\n    }\n\n    MPI_Gather(&rank_result, 1, MPI_INT, rank_results.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    return (rank == 0)? std::accumulate(rank_results.begin(), rank_results.end(), 0) : 0;\n}",
            "// TODO: implement me!\n  // The rank 0 process has an additional check that needs to be added\n  // if A[i][j] == 1, set connected[i] = 1 and connected[j] = 1\n  // else, set connected[i] = 0\n  int connected[N];\n  for (int i = 0; i < N; i++) {\n    connected[i] = 0;\n  }\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        connected[i] = 1;\n        connected[j] = 1;\n      }\n    }\n  }\n\n  //check if any process has an element set to 0, if so, set it to 1\n  int anyDiscon;\n  anyDiscon = 0;\n  for (int i = 0; i < N; i++) {\n    if (connected[i] == 0) {\n      anyDiscon = 1;\n    }\n  }\n  int temp[N];\n  MPI_Bcast(temp, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Reduce(&anyDiscon, &connected, N, MPI_INT, MPI_LOR, 0, MPI_COMM_WORLD);\n\n  //count how many 1s in array connected, store count\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (connected[i] == 1) {\n      count++;\n    }\n  }\n  return count;\n}",
            "if (A.size()!= N*N) {\n        throw \"Input size must be N^2.\";\n    }\n    if (N < 1) {\n        throw \"Size must be at least 1.\";\n    }\n\n    /* your code goes here */\n    return 0;\n}",
            "// TODO\n    return 0;\n}",
            "// TODO\n}",
            "return 0;\n}",
            "// TODO: Implement me\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tstd::vector<int> componentCounts(size, 0);\n\n\t// The graph is split up into chunks of size N/size\n\t// Each rank has its own chunk of the graph and only communicates with its neighbors\n\tsize_t myStart = rank * N / size;\n\tsize_t myEnd = (rank + 1) * N / size;\n\tint myComponents = 0;\n\tfor (int i = myStart; i < myEnd; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[N * i + j]!= 0 &&!(i == j)) {\n\t\t\t\tint nextIndex = N * i + j;\n\t\t\t\tint currentIndex = N * i + i;\n\t\t\t\tif (A[nextIndex] == 1) {\n\t\t\t\t\tA[currentIndex] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tint currentIndex = N * i + i;\n\t\tif (A[currentIndex] == 1) {\n\t\t\tmyComponents++;\n\t\t}\n\t}\n\tMPI_Reduce(&myComponents, &componentCounts[0], 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn componentCounts[0];\n}",
            "}",
            "assert(A.size() == N*N);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i+1; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "int n_proc;\n\tint rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_proc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tif (n_proc <= 1) {\n\t\treturn componentCount_serial(A, N);\n\t}\n\n\tint count = 0;\n\n\treturn count;\n}",
            "int size = A.size();\n\tstd::vector<int> dist(size, -1);\n\tint count = 0;\n\tstd::queue<int> q;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (dist[i] == -1) {\n\t\t\tdist[i] = 0;\n\t\t\tq.push(i);\n\t\t\tcount++;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint index = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int j = 0; j < size; j++) {\n\t\t\t\t\tif (A[index * N + j]!= 0 && dist[j] == -1) {\n\t\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO\n}",
            "// Your code here\n    int rank, n_ranks;\n    MPI_Comm_size(MPI_COMM_WORLD, &n_ranks);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int l = N / n_ranks;\n    int extra = N % n_ranks;\n\n    // Create a vector for every rank containing the matrix chunk\n    std::vector<int> chunk;\n    // First (N % n_ranks) ranks have one extra row\n    if (rank < extra) {\n        for (int i = 0; i < l + 1; i++) {\n            for (int j = 0; j < N; j++) {\n                chunk.push_back(A[i * N + j]);\n            }\n        }\n    } else {\n        for (int i = 0; i < l; i++) {\n            for (int j = 0; j < N; j++) {\n                chunk.push_back(A[i * N + j]);\n            }\n        }\n    }\n\n    int n_components = 0;\n\n    // Compute component count for every rank\n    if (rank == 0) {\n        for (int i = 0; i < N; i++) {\n            for (int j = i + 1; j < N; j++) {\n                if (A[i * N + j] == 1) {\n                    n_components++;\n                }\n            }\n        }\n    }\n\n    // Compute component count for every rank\n    MPI_Reduce(&n_components, &n_components, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    if (rank == 0) {\n        return n_components;\n    } else {\n        return 0;\n    }\n}",
            "// TODO: Your code here\n\tint components = 0;\n\n\tint num_nodes = N * N;\n\tint root_rank = 0;\n\tint local_root_rank = 0;\n\tint proc_num;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &proc_num);\n\tMPI_Comm_size(MPI_COMM_WORLD, &proc_num);\n\n\tstd::vector<int> root_rank_count(proc_num, 0);\n\tstd::vector<int> local_root_rank_count(proc_num, 0);\n\n\tif (A[proc_num]!= 0) {\n\t\tlocal_root_rank_count[proc_num]++;\n\t\tcomponents++;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tif (i == j) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tlocal_root_rank = 0;\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (A[i*N + k] == 1) {\n\t\t\t\t\t\tlocal_root_rank++;\n\t\t\t\t\t\tif (local_root_rank == 1) {\n\t\t\t\t\t\t\tlocal_root_rank = proc_num;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (proc_num == local_root_rank) {\n\t\t\t\t\tcomponents++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tif (i == j) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\troot_rank = 0;\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (A[i*N + k] == 1) {\n\t\t\t\t\t\troot_rank++;\n\t\t\t\t\t\tif (root_rank == 1) {\n\t\t\t\t\t\t\troot_rank = proc_num;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\troot_rank_count[root_rank]++;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Reduce(local_root_rank_count.data(), root_rank_count.data(), proc_num, MPI_INT, MPI_SUM, root_rank, MPI_COMM_WORLD);\n\n\treturn components;\n}",
            "return 0;\n}",
            "if (N == 0) {\n        return 0;\n    }\n\n    // compute connected components\n    std::vector<int> visited(N, 0);\n    int visitedCount = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!visited[i]) {\n            dfs(A, visited, i);\n            visitedCount++;\n        }\n    }\n    return visitedCount;\n}",
            "// Implement this method!\n\treturn 0;\n}",
            "std::vector<int> visited(N, 0);\n  int count = 0;\n\n  // Your code here\n  if(A[0][0]==1){\n      visited[0]=1;\n      count++;\n      int x;\n      std::vector<int> q;\n      q.push_back(0);\n      while(q.size()>0){\n          x=q[0];\n          q.erase(q.begin());\n          for(int i=0;i<N;i++){\n              if(A[x][i]==1 && visited[i]!=1){\n                  q.push_back(i);\n                  visited[i]=1;\n              }\n          }\n      }\n  }\n\n  MPI_Reduce(&count,&count,1,MPI_INT,MPI_SUM,0,MPI_COMM_WORLD);\n  if(visited[0]==0){\n      MPI_Reduce(&count,&count,1,MPI_INT,MPI_SUM,0,MPI_COMM_WORLD);\n      count++;\n  }\n  return count;\n}",
            "std::vector<int> visited(N);\n\n\tauto visit = [&](int i) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (i!= j && A[N*i + j]) {\n\t\t\t\t\tvisit(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t};\n\n\tint count = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t++count;\n\t\t\tvisit(i);\n\t\t}\n\t}\n\treturn count;\n}",
            "return 0;\n}",
            "int rank, size, rcount, rdisp, sum, my_sum;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// Compute the number of components on rank 0\n\tmy_sum = 0;\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j]!= 0) my_sum++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Broadcast the result to all ranks\n\tMPI_Bcast(&my_sum, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn my_sum;\n}",
            "// TODO: implement\n  return -1;\n}",
            "//...\n}",
            "// TODO: Your code here\n  return 0;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t++count;\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (visited[j] == 0 && A[i * N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "return 0;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif(N < size)\n\t\tthrow std::runtime_error(\"N must be >= size\");\n\n\tstd::vector<int> connectedComponents(N, rank);\n\tfor(size_t i = 0; i < N; ++i) {\n\t\tif(rank == 0) {\n\t\t\tfor(size_t j = 0; j < N; ++j) {\n\t\t\t\tif(i!= j && A[i * N + j]!= 0) {\n\t\t\t\t\tconnectedComponents[i] = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tMPI_Bcast(&connectedComponents[i], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t}\n\t}\n\tint count = 0;\n\tfor(size_t i = 0; i < N; ++i)\n\t\tif(connectedComponents[i] == rank)\n\t\t\t++count;\n\n\tint total = 0;\n\tMPI_Reduce(&count, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn total;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Datatype rowType;\n\tint blockLen[] = {1, 1};\n\tMPI_Aint disp[] = {0, (MPI_Aint)sizeof(int)};\n\tMPI_Datatype typ[] = {MPI_INT, MPI_INT};\n\tMPI_Type_struct(2, blockLen, disp, typ, &rowType);\n\tMPI_Type_commit(&rowType);\n\n\t// Compute number of rows per rank.\n\tint numRows = N / size;\n\tint rankOffset = numRows * rank;\n\t// Compute number of rows this rank will handle.\n\tint localNumRows = rank == size - 1? N % size : numRows;\n\n\t// Each rank will have a local copy of the rows it's working on,\n\t// so that the BFS doesn't need to touch the global matrix.\n\tstd::vector<std::vector<int>> localA;\n\tfor (int i = 0; i < localNumRows; ++i) {\n\t\tlocalA.push_back(std::vector<int>(A.begin() + rankOffset + i * N, A.begin() + rankOffset + (i + 1) * N));\n\t}\n\n\t// Create a copy of the local matrix for each rank to work on.\n\tstd::vector<std::vector<int>> localB;\n\tlocalB.reserve(localA.size());\n\tfor (auto& row : localA) {\n\t\tlocalB.push_back(row);\n\t}\n\n\t// This is the queue that will be used to perform the BFS.\n\t// It's a queue of pairs of the row and column of an unvisited element.\n\tstd::queue<std::pair<int, int>> q;\n\n\t// This vector will mark which elements have been visited.\n\t// For simplicity, we use a 1D vector instead of a 2D matrix.\n\t// The index of an element is row * N + col.\n\tstd::vector<int> visited(N * N);\n\n\tint count = 0;\n\t// Do BFS on each component, as long as there are unvisited elements.\n\twhile (!q.empty() || std::find(visited.begin(), visited.end(), 0)!= visited.end()) {\n\t\tif (!q.empty()) {\n\t\t\t// Pop the next element to visit.\n\t\t\tauto [i, j] = q.front();\n\t\t\tq.pop();\n\t\t\t// Mark this element as visited.\n\t\t\tvisited[i * N + j] = 1;\n\t\t\t// Enqueue all unvisited elements adjacent to this element.\n\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\tif (localB[i][k] &&!visited[i * N + k]) {\n\t\t\t\t\tq.push(std::make_pair(i, k));\n\t\t\t\t}\n\t\t\t\tif (localB[k][j] &&!visited[k * N + j]) {\n\t\t\t\t\tq.push(std::make_pair(k, j));\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// No more elements to visit. Find the next unvisited element.\n\t\t\tstd::vector<int> newComponent;\n\t\t\tfor (int i = 0; i < localNumRows; ++i) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (!visited[i * N + j]) {\n\t\t\t\t\t\tq.push(std::make_pair(i, j));\n\t\t\t\t\t\t++count;\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// We just finished processing one component. Copy the local matrix to the global matrix.\n\t\tfor (int i = 0; i < localNumRows; ++i) {\n\t\t\tstd::copy(local",
            "int num_ranks, rank_id;\n\n\t// Find the number of ranks and the rank id.\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank_id);\n\n\t// Initialise the vector for the component count on every rank.\n\tstd::vector<int> component_count(num_ranks);\n\n\t// Define the size of the partition to be split up\n\tint size = N / num_ranks;\n\n\t// Create the vector to store the components on rank 0.\n\tstd::vector<int> components;\n\n\t// If the rank is 0, then create the vector to store the components on rank 0.\n\tif (rank_id == 0) {\n\t\tcomponents = std::vector<int>(num_ranks, 0);\n\t}\n\n\t// Define the number of components on rank 0.\n\tint count = 0;\n\n\t// Loop over every element in the adjacency matrix.\n\tfor (int i = 0; i < N; i++) {\n\n\t\t// Split the adjacency matrix into equal parts based on the number of ranks.\n\t\tif (i < size * (rank_id) || i >= size * (rank_id + 1)) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Loop over every element in the i-th row.\n\t\tfor (int j = 0; j < N; j++) {\n\n\t\t\t// If element j in the i-th row is 1, then check if element j in the j-th row is 1.\n\t\t\tif (A[i * N + j] == 1 && A[j * N + i] == 1) {\n\n\t\t\t\t// If the rank is 0, then increase the number of components by 1.\n\t\t\t\tif (rank_id == 0) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\n\t\t\t\t// Send an increment to rank 0.\n\t\t\t\tif (rank_id == 0) {\n\t\t\t\t\tMPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\t\t\t}\n\n\t\t\t\t// If the rank is 0, then receive the updated number of components from rank 0.\n\t\t\t\tif (rank_id == 0) {\n\t\t\t\t\tMPI_Recv(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// If the rank is 0, then store the number of components on rank 0.\n\tif (rank_id == 0) {\n\t\tcomponents[0] = count;\n\t}\n\n\t// Broadcast the number of components on rank 0 to every other rank.\n\tMPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn count;\n}",
            "std::vector<int> visited(N, 0);\n\tint count = 0;\n\tfor (size_t v = 0; v < N; ++v) {\n\t\tif (visited[v] == 0) {\n\t\t\t++count;\n\t\t\tdfs(A, N, v, visited);\n\t\t}\n\t}\n\treturn count;\n}",
            "// You will need to compute an array, B, of length N\n  // where B[i] is the number of connected components to which\n  // node i belongs.\n  // Then you will need to return the sum of the elements in B.\n  // TODO: fill in code here\n  std::vector<int> B(N, 0);\n  return std::accumulate(B.begin(), B.end(), 0);\n}",
            "// Your code here!\n}",
            "return 1;\n}",
            "// TODO\n  return 0;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\tfor(size_t i = 0; i < N; i++) {\n\t\tif(visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tcount++;\n\t\tstd::vector<bool> currLevel;\n\t\tcurrLevel.push_back(true);\n\t\tcurrLevel.push_back(false);\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[i*N + j] == 1) {\n\t\t\t\tcurrLevel.push_back(true);\n\t\t\t\tcurrLevel.push_back(false);\n\t\t\t}\n\t\t}\n\t\twhile(currLevel.size() > 1) {\n\t\t\tstd::vector<bool> nextLevel;\n\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\tif(A[currLevel[j*2]*N + currLevel[j*2+1]] == 1) {\n\t\t\t\t\tif(!visited[currLevel[j*2+1]]) {\n\t\t\t\t\t\tvisited[currLevel[j*2+1]] = true;\n\t\t\t\t\t\tnextLevel.push_back(true);\n\t\t\t\t\t\tnextLevel.push_back(currLevel[j*2+1]);\n\t\t\t\t\t}\n\t\t\t\t\tif(!visited[currLevel[j*2]]) {\n\t\t\t\t\t\tvisited[currLevel[j*2]] = true;\n\t\t\t\t\t\tnextLevel.push_back(true);\n\t\t\t\t\t\tnextLevel.push_back(currLevel[j*2]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurrLevel = nextLevel;\n\t\t}\n\t}\n\treturn count;\n}",
            "return N;\n}",
            "std::vector<int> adjacency_matrix(N*N);\n  std::copy(A.begin(), A.end(), adjacency_matrix.begin());\n\n  int size = adjacency_matrix.size();\n  int rank;\n  int numprocs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &numprocs);\n\n  int count = 0;\n  int *displs = (int *)malloc((numprocs + 1) * sizeof(int));\n  int *counts = (int *)malloc((numprocs + 1) * sizeof(int));\n  int *recvcounts = (int *)malloc((numprocs + 1) * sizeof(int));\n  int *recvdispls = (int *)malloc((numprocs + 1) * sizeof(int));\n\n  counts[rank] = size;\n  recvcounts[rank] = size;\n\n  MPI_Allgather(MPI_IN_PLACE, 1, MPI_INT, counts, 1, MPI_INT, MPI_COMM_WORLD);\n  MPI_Allgather(MPI_IN_PLACE, 1, MPI_INT, recvcounts, 1, MPI_INT, MPI_COMM_WORLD);\n\n  displs[0] = 0;\n  recvdispls[0] = 0;\n\n  for (int i = 1; i < numprocs + 1; ++i) {\n    displs[i] = displs[i - 1] + counts[i - 1];\n    recvdispls[i] = recvdispls[i - 1] + recvcounts[i - 1];\n  }\n\n  int *recvAdj = (int *)malloc(size * sizeof(int));\n  MPI_Allgatherv(MPI_IN_PLACE, 1, MPI_INT, recvAdj, recvcounts, recvdispls, MPI_INT, MPI_COMM_WORLD);\n\n  //std::cout << std::endl;\n  //for (int i = 0; i < size; ++i) {\n  //  std::cout << recvAdj[i] << \" \";\n  //}\n\n  std::vector<bool> visited(N, false);\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      std::queue<int> q;\n      q.push(i);\n      visited[i] = true;\n      int v = q.front();\n      while (!q.empty()) {\n        v = q.front();\n        q.pop();\n        for (int j = 0; j < N; ++j) {\n          if (recvAdj[v*N + j] == 1 &&!visited[j]) {\n            q.push(j);\n            visited[j] = true;\n          }\n        }\n      }\n      count++;\n    }\n  }\n\n  int gcount = 0;\n  MPI_Reduce(&count, &gcount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    std::cout << \"Number of connected components is \" << gcount << std::endl;\n  }\n\n  return gcount;\n}",
            "// TODO\n}",
            "// Your code here\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    std::vector<bool> connected(N, false);\n    if (rank == 0) {\n        connected[0] = true;\n    }\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1 &&!connected[j] && rank == 0) {\n                connected[j] = true;\n                count++;\n            }\n        }\n    }\n    if (rank == 0) {\n        return count;\n    }\n    return 0;\n}",
            "int count = 0;\n\tint visited[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\tdfs(i, A, visited, N);\n\t\t}\n\t}\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\t// Start a DFS from node i.\n\t\t\tstd::function<void(int)> DFS = [&](int u) {\n\t\t\t\tif (u < 0 || u >= N || visited[u]) return;\n\t\t\t\tvisited[u] = true;\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[u*N + j]) {\n\t\t\t\t\t\tDFS(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tcount++;\n\t\t\tDFS(i);\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO\n  return 0;\n}",
            "// Your code here.\n}",
            "// TODO: Implement\n\treturn 0;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\tfor (size_t v = 0; v < N; ++v) {\n\t\tif (visited[v]) {\n\t\t\tcontinue;\n\t\t}\n\t\tcount++;\n\t\tstd::queue<int> q;\n\t\tq.push(v);\n\t\twhile (!q.empty()) {\n\t\t\tint u = q.front();\n\t\t\tq.pop();\n\t\t\tvisited[u] = true;\n\t\t\tfor (size_t w = 0; w < N; ++w) {\n\t\t\t\tif (A[N*u + w] &&!visited[w]) {\n\t\t\t\t\tq.push(w);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO: fill this in\n\n  return 0;\n}",
            "// TODO\n}",
            "// TODO: Compute the number of connected components in A using BFS.\n\t//       Return this value on rank 0, and -1 on all other ranks.\n\tint count = 0;\n\n\tstd::vector<int> visited(N);\n\tstd::queue<int> bfsQueue;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tbfsQueue.push(i);\n\n\t\t\twhile (!bfsQueue.empty()) {\n\t\t\t\tint u = bfsQueue.front();\n\t\t\t\tbfsQueue.pop();\n\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[u * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\t\tbfsQueue.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t++count;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\t\n\tint numComponents = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> connected(N, 0);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = 1;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint curNode = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[curNode * N + j] && visited[j] == 0) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tconnected[i] = 1;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnumComponents++;\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "// TODO: FILL THIS IN\n    // Note that componentCount is a parallel program\n    // and must be thread-safe.\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int components;\n    if (rank == 0) {\n        // compute how many rows to send to each rank\n        std::vector<int> rowCounts(size);\n        for (int i = 0; i < size; ++i) {\n            rowCounts[i] = N/size;\n        }\n        // if the rows are not divisible, then distribute the remainder evenly\n        for (int i = 0; i < N % size; ++i) {\n            rowCounts[i]++;\n        }\n        // compute total number of rows that each rank has\n        std::vector<int> displacements(size);\n        for (int i = 1; i < size; ++i) {\n            displacements[i] = displacements[i-1] + rowCounts[i-1];\n        }\n        // send the rows to each rank\n        for (int i = 0; i < size; ++i) {\n            int* row = new int[rowCounts[i]*N];\n            MPI_Scatterv(A.data(), rowCounts.data(), displacements.data(), MPI_INT, row, rowCounts[i]*N, MPI_INT, i, MPI_COMM_WORLD);\n            // compute components\n            std::vector<bool> visited(rowCounts[i]*N);\n            std::vector<bool> connected;\n            std::vector<bool> connected2;\n            for (int j = 0; j < rowCounts[i]*N; ++j) {\n                if (!visited[j] && row[j]) {\n                    std::vector<int> component = {j};\n                    while (!component.empty()) {\n                        int c = component.back();\n                        component.pop_back();\n                        visited[c] = true;\n                        for (int k = 0; k < N; ++k) {\n                            if (row[c*N + k] &&!visited[k]) {\n                                component.push_back(k);\n                            }\n                        }\n                    }\n                    connected.push_back(true);\n                }\n                else if (row[j]) {\n                    connected2.push_back(true);\n                }\n            }\n            MPI_Gatherv(&connected[0], connected.size(), MPI_C_BOOL, &connected2[0], rowCounts.data(), displacements.data(), MPI_C_BOOL, 0, MPI_COMM_WORLD);\n            if (i == 0) {\n                components = 0;\n                for (int j = 0; j < connected2.size(); ++j) {\n                    if (connected2[j]) {\n                        components++;\n                    }\n                }\n            }\n            delete[] row;\n        }\n    }\n    else {\n        MPI_Scatterv(A.data(), rowCounts.data(), displacements.data(), MPI_INT, A.data(), rowCounts[rank-1]*N, MPI_INT, 0, MPI_COMM_WORLD);\n        std::vector<bool> visited(rowCounts[rank-1]*N);\n        std::vector<bool> connected;\n        for (int i = 0; i < rowCounts[rank-1]*N; ++i) {\n            if (!visited[i] && A[i]) {\n                std::vector<int> component = {i};\n                while (!component.empty()) {\n                    int c = component.back();\n                    component.pop_back();\n                    visited[c] = true;\n                    for (int j = 0; j < N; ++j) {\n                        if (A[c*N + j] &&!visited[j]) {\n                            component.push_back(j);\n                        }\n                    }\n                }\n                connected.push_back(true);\n            }\n        }\n        int",
            "// TODO\n}",
            "int count = 0;\n  std::vector<bool> visited(N, false);\n  std::queue<size_t> q;\n  for (size_t i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      q.push(i);\n      while (!q.empty()) {\n        size_t node = q.front();\n        q.pop();\n        if (visited[node]) continue;\n        visited[node] = true;\n        for (size_t j = 0; j < N; ++j) {\n          if (A[N * node + j]) {\n            q.push(j);\n          }\n        }\n      }\n      count++;\n    }\n  }\n  return count;\n}",
            "// TODO\n    return -1;\n}",
            "// TODO: Your code here.\n\treturn 0;\n}",
            "if (A.size()!= N * N) {\n\t\tthrow std::runtime_error(\"Invalid input\");\n\t}\n\tint componentCount = 0;\n\t// TODO: implement componentCount\n\treturn componentCount;\n}",
            "int myID = 0;\n\tint root = 0;\n\tint numProcs = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myID);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\t\n\tstd::vector<int> a(N*N);\n\tstd::vector<int> b(N*N);\n\tstd::vector<int> c(N*N);\n\n\tint k = 0;\n\tif (N < numProcs){\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\ta[k] = A[k];\n\t\t\t\tb[k] = A[k];\n\t\t\t\tk++;\n\t\t\t}\n\t\tk = 0;\n\t}\n\telse{\n\t\tfor (int i = myID; i < N; i += numProcs)\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\ta[k] = A[k];\n\t\t\t\tb[k] = A[k];\n\t\t\t\tk++;\n\t\t\t}\n\t\tk = 0;\n\t}\n\n\tstd::vector<int> c_all(N*N, 0);\n\n\tMPI_Bcast(&N, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint tag = 0;\n\tint num_msgs = N/numProcs;\n\tint msg_size = N;\n\tint num_recvs = 1;\n\t\n\tif (myID == 0){\n\t\tMPI_Status status[num_recvs];\n\t\t\n\t\tfor (int i = 1; i < numProcs; i++){\n\t\t\tMPI_Recv(&c_all[0], N*N, MPI_INT, i, tag, MPI_COMM_WORLD, &status[i]);\n\t\t}\n\t}\n\n\tstd::vector<int> component(N);\n\tstd::vector<bool> visited(N);\n\tint components = 0;\n\n\tfor (int i = 0; i < N; i++){\n\t\tif (!visited[i]){\n\t\t\tcomponent[i] = components;\n\t\t\tcomponents++;\n\t\t\tvisited[i] = true;\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tif (a[i*N + j] == 1){\n\t\t\t\t\tif (!visited[j]){\n\t\t\t\t\t\tcomponent[j] = components;\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (myID == 0){\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tc[i*N + j] = component[j];\n\t\t\t}\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tc_all[i*N + j] = c[i*N + j];\n\n\t\tfor (int i = 1; i < numProcs; i++){\n\t\t\tMPI_Send(&c_all[0], N*N, MPI_INT, i, tag, MPI_COMM_WORLD);\n\t\t}\n\t\t\n\t\tcomponents = 0;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tif (c_all[i*N + j] == i){\n\t\t\t\t\tcomponents++;\n\t\t\t\t}\n\t}\n\n\tif (myID == 0)\n\t\treturn components;\n\telse\n\t\treturn 0;\n}",
            "int component_count = 0;\n\n  //TODO\n\n  return component_count;\n}",
            "int numRanks;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tint myRank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n\tstd::vector<int> visited(N, false);\n\n\t// TODO: Compute the number of connected components in graph defined by A.\n\n\treturn 0;\n}",
            "int r = 0;\n\tint rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// TODO\n\tint* numComponents = (int*) malloc(sizeof(int) * size);\n\tint* componentCount = (int*) malloc(sizeof(int) * size);\n\tint* sendComponents = (int*) malloc(sizeof(int) * size);\n\tint* recvComponents = (int*) malloc(sizeof(int) * size);\n\tint* recvRank = (int*) malloc(sizeof(int) * size);\n\tint* sendRank = (int*) malloc(sizeof(int) * size);\n\n\tfor (int i = 0; i < size; i++)\n\t{\n\t\tnumComponents[i] = 0;\n\t\tcomponentCount[i] = 0;\n\t\tsendComponents[i] = 0;\n\t\trecvComponents[i] = 0;\n\t\tsendRank[i] = i;\n\t\trecvRank[i] = i;\n\t}\n\tint count = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[N*i + j] == 1)\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tnumComponents[rank] = count;\n\t\tMPI_Allgather(numComponents, 1, MPI_INT, recvComponents, 1, MPI_INT, MPI_COMM_WORLD);\n\t\tMPI_Allgather(sendRank, 1, MPI_INT, recvRank, 1, MPI_INT, MPI_COMM_WORLD);\n\t\tint maxComp = 0;\n\t\tint maxRank = 0;\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tif (maxComp < recvComponents[i])\n\t\t\t{\n\t\t\t\tmaxComp = recvComponents[i];\n\t\t\t\tmaxRank = recvRank[i];\n\t\t\t}\n\t\t}\n\t\tcomponentCount[rank] = maxComp;\n\t\tsendComponents[rank] = maxComp;\n\t\tsendRank[rank] = maxRank;\n\t\tMPI_Allgather(sendComponents, 1, MPI_INT, recvComponents, 1, MPI_INT, MPI_COMM_WORLD);\n\t\tMPI_Allgather(sendRank, 1, MPI_INT, recvRank, 1, MPI_INT, MPI_COMM_WORLD);\n\t\tcount = 0;\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tif (recvComponents[i] == 0)\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\tnumComponents[rank] = count;\n\t}\n\tMPI_Gather(componentCount, 1, MPI_INT, recvComponents, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tif (rank == 0)\n\t{\n\t\tr = 0;\n\t\tfor (int i = 0; i < size; i++)\n\t\t{\n\t\t\tr = r + recvComponents[i];\n\t\t}\n\t}\n\treturn r;\n}",
            "// Implement this function!\n\tstd::vector<bool> visited(N, false);\n\tint totalConnected = 0;\n\n\tfor (size_t start = 0; start < N; start++) {\n\t\tif (!visited[start]) {\n\t\t\ttotalConnected += dfs(A, start, visited);\n\t\t}\n\t}\n\n\treturn totalConnected;\n}",
            "int r = 0;\n\t\n\t// your code here\n\t\n\treturn r;\n}",
            "// TODO: Replace this with your implementation\n\t// Implement this with a breadth-first search.\n\t// Implement this with a breadth-first search.\n\tstd::vector<int> B(N,0);\n\tstd::queue<int> Q;\n\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tif(!B[i])\n\t\t{\n\t\t\tB[i]=i;\n\t\t\tQ.push(i);\n\t\t\tint current,neighbor;\n\t\t\twhile(!Q.empty())\n\t\t\t{\n\t\t\t\tcurrent=Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tfor(int j=0;j<N;j++)\n\t\t\t\t{\n\t\t\t\t\tif(A[current*N+j])\n\t\t\t\t\t{\n\t\t\t\t\t\tneighbor=B[j];\n\t\t\t\t\t\tif(B[current]!=neighbor)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor(int k=0;k<N;k++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tif(B[k]==neighbor)\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tB[k]=B[current];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint count=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tif(B[i]==i)\n\t\t{\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO\n}",
            "if (N <= 1) return N;\n    int nrank;\n    MPI_Comm_size(MPI_COMM_WORLD, &nrank);\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int* local_A = new int[N * N];\n    std::copy(A.begin(), A.end(), local_A);\n    int* local_ccounts = new int[N];\n    std::fill(local_ccounts, local_ccounts + N, 0);\n    std::vector<int> local_ccounts_vec(N, 0);\n    // Compute locally.\n    for (size_t i = 0; i < N; i++) {\n        // 1-based indexing.\n        local_ccounts[i] = 1;\n        local_ccounts_vec[i] = 1;\n        for (size_t j = 0; j < N; j++) {\n            if (local_A[i * N + j] == 1) {\n                local_ccounts[i] += local_ccounts[j];\n                local_ccounts_vec[i] += local_ccounts_vec[j];\n            }\n        }\n    }\n    // Combine results.\n    std::vector<int> counts(N, 0);\n    MPI_Reduce(&local_ccounts_vec[0], &counts[0], N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    int count = 0;\n    if (rank == 0) {\n        for (size_t i = 0; i < N; i++) {\n            count += (counts[i] == 1);\n        }\n    }\n    delete [] local_A;\n    delete [] local_ccounts;\n    return count;\n}",
            "// This is a simple breadth first search algorithm to check if the\n    // graph is connected.\n    //\n    // Time Complexity: O(V + E)\n    // Space Complexity: O(V)\n\n    // A set to keep track of visited nodes.\n    std::set<int> visited;\n\n    // A queue to store the next nodes to be visited.\n    std::queue<int> toVisit;\n\n    // Check if the graph is connected.\n    for (size_t i = 0; i < N; ++i) {\n        if (visited.find(i)!= visited.end())\n            continue;\n        toVisit.push(i);\n        while (!toVisit.empty()) {\n            auto const current = toVisit.front();\n            toVisit.pop();\n            for (size_t j = 0; j < N; ++j) {\n                if (A[current * N + j] && visited.find(j) == visited.end()) {\n                    visited.insert(j);\n                    toVisit.push(j);\n                }\n            }\n        }\n    }\n\n    // Return the size of the set (the number of visited nodes).\n    return visited.size();\n}",
            "// Your code here!\n\n  return 0;\n}",
            "assert(A.size() == N * N);\n\tint *visited = new int[N];\n\tint *parent = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tparent[i] = i;\n\t\tvisited[i] = 0;\n\t}\n\n\tint count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i!= j && A[i * N + j] == 1 && visited[i]!= 1 && visited[j]!= 1) {\n\t\t\t\tparent[j] = i;\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "return 0;\n}",
            "// TODO: compute the component count in parallel, assuming MPI has been initialized.\n\n\t// Use MPI_Bcast and MPI_Scatter to distribute A to the ranks.\n\t// Use MPI_Gather to collect the counts from the ranks.\n\n\tint numRanks, rankId;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rankId);\n\n\t// The number of rows assigned to each rank.\n\tsize_t nrows = (N + numRanks - 1) / numRanks;\n\n\t// The rank index at which my rows start.\n\tint startRow = rankId * nrows;\n\n\tstd::vector<int> myA(nrows * N);\n\n\t// Distribute the rows.\n\tMPI_Bcast(&A[0], N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Scatter(&A[0], nrows*N, MPI_INT, &myA[0], nrows*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// Compute the counts.\n\tstd::vector<int> counts(nrows);\n\tfor (size_t i = 0; i < nrows; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (myA[i*N + j]) {\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (myA[i*N + k]) {\n\t\t\t\t\t\tmyA[j*N + k] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (size_t j = 0; j < nrows; j++) {\n\t\t\tif (myA[i*N + j]) {\n\t\t\t\tcounts[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Count the number of connected components.\n\tstd::vector<int> result(1);\n\tresult[0] = std::accumulate(counts.begin(), counts.end(), 0);\n\n\t// Gather the results from the ranks.\n\tMPI_Gather(&result[0], 1, MPI_INT, &result[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn result[0];\n}",
            "int numproc, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numproc);\n\n\t// Compute connected components using MPI\n\t//...\n\treturn 0;\n}",
            "int nb_compo=1;\n\tint nb_proc;\n\tint rank;\n\n\tstd::vector<int> A_cpy;\n\t\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nb_proc);\n\t\n\tA_cpy.resize(N*N);\n\tif(rank==0)\n\t{\n\t\tfor(int i=0;i<N;i++)\n\t\t\tfor(int j=0;j<N;j++)\n\t\t\t{\n\t\t\t\tA_cpy[i*N+j]=A[i*N+j];\n\t\t\t}\n\t}\n\n\tMPI_Bcast(&(A_cpy[0]), N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t\n\n\tfor(int i=0;i<N;i++)\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A_cpy[i*N+j]==1)\n\t\t\t{\n\t\t\t\tint x, y;\n\t\t\t\tfor(x=0;x<N;x++)\n\t\t\t\t\tfor(y=0;y<N;y++)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(A_cpy[x*N+y]==0 && (x==i || x==j || y==i || y==j))\n\t\t\t\t\t\t\tA_cpy[x*N+y]=2;\n\t\t\t\t\t}\n\t\t\t\tnb_compo++;\n\t\t\t}\n\t\t}\n\n\tfor(int i=0;i<N;i++)\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A_cpy[i*N+j]==2)\n\t\t\t{\n\t\t\t\tint x, y;\n\t\t\t\tfor(x=0;x<N;x++)\n\t\t\t\t\tfor(y=0;y<N;y++)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(A_cpy[x*N+y]==0 && (x==i || x==j || y==i || y==j))\n\t\t\t\t\t\t\tA_cpy[x*N+y]=2;\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tint nb_compo_g;\n\t\n\tMPI_Reduce(&nb_compo, &nb_compo_g, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif(rank==0)\n\t\treturn nb_compo_g;\n\treturn 0;\n}",
            "// TODO: your code here\n\treturn 0;\n}",
            "int rank;\n\tint p;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tint comp = 0;\n\n\tfor (size_t i = 0; i < N; ++i)\n\t{\n\t\tint counter = 0;\n\t\tif (A[i*N + i] == 1)\n\t\t{\n\t\t\t//find all nodes in this component\n\t\t\tstd::vector<int> nodes;\n\t\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\t{\n\t\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t{\n\t\t\t\t\tnodes.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//broadcast all nodes to all other ranks\n\t\t\tfor (int k = 0; k < p; ++k)\n\t\t\t{\n\t\t\t\tMPI_Bcast(&nodes.size(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t\tMPI_Bcast(&nodes[0], nodes.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t}\n\n\t\t\t//mark all nodes\n\t\t\tfor (int j = 0; j < p; ++j)\n\t\t\t{\n\t\t\t\tif (rank == j)\n\t\t\t\t{\n\t\t\t\t\tfor (int m = 0; m < nodes.size(); ++m)\n\t\t\t\t\t{\n\t\t\t\t\t\tA[i*N + nodes[m]] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//broadcast all marked nodes back to all other ranks\n\t\t\tfor (int k = 0; k < p; ++k)\n\t\t\t{\n\t\t\t\tMPI_Bcast(&nodes.size(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t\tMPI_Bcast(&nodes[0], nodes.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t}\n\n\t\t\t//find all new nodes in this component\n\t\t\tstd::vector<int> new_nodes;\n\t\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\t{\n\t\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t{\n\t\t\t\t\tnew_nodes.push_back(j);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//broadcast all new nodes to all other ranks\n\t\t\tfor (int k = 0; k < p; ++k)\n\t\t\t{\n\t\t\t\tMPI_Bcast(&new_nodes.size(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t\tMPI_Bcast(&new_nodes[0], new_nodes.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t}\n\n\t\t\t//mark all nodes\n\t\t\tfor (int j = 0; j < p; ++j)\n\t\t\t{\n\t\t\t\tif (rank == j)\n\t\t\t\t{\n\t\t\t\t\tfor (int m = 0; m < new_nodes.size(); ++m)\n\t\t\t\t\t{\n\t\t\t\t\t\tA[i*N + new_nodes[m]] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//broadcast all marked nodes back to all other ranks\n\t\t\tfor (int k = 0; k < p; ++k)\n\t\t\t{\n\t\t\t\tMPI_Bcast(&new_nodes.size(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\t\tMPI_Bcast(&new_nodes[0], new_nodes.size(), MPI_INT, 0, M",
            "// your code here\n}",
            "/* TODO */\n  return 0;\n}",
            "// your code here\n  std::vector<int> flag(N);\n  int count=0;\n  for(size_t i=0;i<N;i++){\n      if(flag[i]==0){\n          //dfs(i);\n          flag[i]=1;\n          count++;\n      }\n  }\n  return count;\n}",
            "std::vector<int> visited(N, 0);\n\tint componentCount = 0;\n\t// loop through each element\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t// if it has already been visited, skip it\n\t\t\tif (visited[i] == 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// if it is a neighbor, mark it as visited\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t}\n\t\t\t// if it is not a neighbor, it is a new component\n\t\t\tif (A[i * N + j] == 0) {\n\t\t\t\tcomponentCount++;\n\t\t\t}\n\t\t}\n\t}\n\t// return the number of components\n\treturn componentCount;\n}",
            "return 0;\n}",
            "// TODO: your code here\n}",
            "// Use BFS or DFS to find connected components.\n    // Hint: Consider how to use a queue or stack to store the nodes in a connected component.\n\t  return 0;\n}",
            "std::vector<int> parent(N, 0);\n  // fill the parent array with the rank of the element\n  for (size_t i = 0; i < parent.size(); i++)\n    parent[i] = i;\n\n  // loop through each element of A\n  for (size_t i = 0; i < A.size(); i++) {\n    // skip self-loops\n    if (A[i] == 1)\n      continue;\n    // find the root of the component containing i\n    int root_i = find(parent, i);\n    // find the root of the component containing the element\n    int root_j = find(parent, i / N);\n    // if the components are not connected, join them\n    if (root_i!= root_j)\n      parent[root_j] = root_i;\n  }\n\n  // count the number of roots in the parent array\n  int count = 0;\n  for (size_t i = 0; i < parent.size(); i++) {\n    if (parent[i] == i)\n      count++;\n  }\n\n  return count;\n}",
            "int count = 0;\n\n\t// Your code here\n\n\treturn count;\n}",
            "// TODO\n\tint n = N;\n\tint i,j,k;\n\tint *v = (int*) malloc(n*sizeof(int));\n\tint *v_tmp = (int*) malloc(n*sizeof(int));\n\tint *q = (int*) malloc(n*sizeof(int));\n\tint *q_tmp = (int*) malloc(n*sizeof(int));\n\tint *visited = (int*) malloc(n*sizeof(int));\n\tfor(i=0;i<n;i++)\n\t{\n\t\tvisited[i] = 0;\n\t\tv[i] = i;\n\t\tv_tmp[i] = i;\n\t\tq[i] = i;\n\t\tq_tmp[i] = i;\n\t}\n\tint comp = 0;\n\tint visited_index = 0;\n\twhile(visited_index<n)\n\t{\n\t\tfor(i=0;i<n;i++)\n\t\t{\n\t\t\tfor(j=0;j<n;j++)\n\t\t\t{\n\t\t\t\tif(A[i*n+j] == 1)\n\t\t\t\t{\n\t\t\t\t\tif(v[i]!= v[j])\n\t\t\t\t\t{\n\t\t\t\t\t\tfor(k=0;k<n;k++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif(v[k] == v[j])\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tv[k] = v[i];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tvisited[visited_index] = 1;\n\t\tvisited_index++;\n\t\tcomp++;\n\t\tfor(i=0;i<n;i++)\n\t\t{\n\t\t\tif(visited[i] == 0)\n\t\t\t{\n\t\t\t\tfor(j=0;j<n;j++)\n\t\t\t\t{\n\t\t\t\t\tif(A[i*n+j] == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(v[i]!= v[j])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tfor(k=0;k<n;k++)\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tif(v[k] == v[j])\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\tv_tmp[k] = v[i];\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(i=0;i<n;i++)\n\t\t{\n\t\t\tv[i] = v_tmp[i];\n\t\t}\n\t\tint index = -1;\n\t\twhile(index!= visited_index-1)\n\t\t{\n\t\t\tindex = visited_index-1;\n\t\t\tfor(i=0;i<n;i++)\n\t\t\t{\n\t\t\t\tif(visited[i] == 0)\n\t\t\t\t{\n\t\t\t\t\tindex = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(index == visited_index-1)\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfor(i=0;i<n;i++)\n\t\t\t{\n\t\t\t\tif(visited[i] == 0)\n\t\t\t\t{\n\t\t\t\t\tfor(j=0;j<n;j++)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(A[i*n+j] == 1)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif(v[i]!= v[j])\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\tfor(k=0;k<n;k++)",
            "int rank, size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  std::vector<int> copy(A);\n\n  int n = N;\n  int numComponents = 0;\n  // for each node in the graph\n  for (size_t i = 0; i < N; i++) {\n    // if we've already seen this component\n    if (copy[i] == 0) {\n      continue;\n    }\n\n    int seen = 1;\n    std::queue<int> q;\n    q.push(i);\n\n    while(!q.empty()) {\n      int curr = q.front();\n      q.pop();\n\n      for (size_t j = 0; j < N; j++) {\n        // if we've already seen this component\n        if (copy[j] == 0) {\n          continue;\n        }\n\n        // if j is connected to curr\n        if (A[curr * N + j]) {\n          seen++;\n          // mark it as seen\n          copy[j] = 0;\n          // add it to the queue\n          q.push(j);\n        }\n      }\n    }\n\n    numComponents += seen;\n  }\n\n  std::vector<int> allSeen(size);\n  MPI_Gather(&numComponents, 1, MPI_INT, allSeen.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int total = 0;\n  if (rank == 0) {\n    for (int i : allSeen) {\n      total += i;\n    }\n  }\n\n  MPI_Bcast(&total, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return total;\n}",
            "// Your code goes here!\n}",
            "int rank, size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint result = 0;\n\tif (rank == 0) {\n\t\tstd::vector<int> B = A;\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = i + 1; j < N; ++j) {\n\t\t\t\tif (B[i * N + j]) {\n\t\t\t\t\tB[i * N + j] = 0;\n\t\t\t\t\tB[j * N + i] = 0;\n\t\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\t\tif (B[j * N + k]) {\n\t\t\t\t\t\t\tB[i * N + k] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (B[i * N + i]) {\n\t\t\t\t++result;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn result;\n}",
            "/* TODO: Your code goes here. */\n\treturn 0;\n}",
            "}",
            "const int rank = MPI::COMM_WORLD.Get_rank();\n\tconst int size = MPI::COMM_WORLD.Get_size();\n\tint count = 0;\n\tint current = rank * N / size;\n\tint final = (rank+1) * N / size;\n\n\tif (final > N) final = N;\n\tfor (int i = current; i < final; i++) {\n\t\tif (A[i * N + i] == 1) {\n\t\t\tcount++;\n\t\t\tint start = i * N + i;\n\t\t\tint current = start;\n\t\t\twhile (A[current] == 1) {\n\t\t\t\tint next = -1;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[current * N + j] == 1) {\n\t\t\t\t\t\tnext = j;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (next!= -1) {\n\t\t\t\t\tA[current * N + next] = 0;\n\t\t\t\t\tA[next * N + current] = 0;\n\t\t\t\t}\n\t\t\t\tcurrent = next;\n\t\t\t}\n\t\t}\n\t}\n\n\tint result;\n\tMPI::COMM_WORLD.Reduce(&count, &result, 1, MPI::INT, MPI::SUM, 0);\n\tif (rank == 0) return result;\n\treturn -1;\n}",
            "return -1;\n}",
            "return 0;\n}",
            "int ret = 0;\n\tint comp_num = 0;\n\tint visited[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tcomp_num++;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (visited[j] == 0 && A[i * N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn comp_num;\n}",
            "/* ************************************************************************** */\n    // TODO: Implement this function\n    int count = 0;\n    if (N == 0)\n    {\n        return 0;\n    }\n    std::vector<bool> visited(N, false);\n    for (size_t i = 0; i < N; i++)\n    {\n        if (!visited[i])\n        {\n            count++;\n            DFS(A, visited, i);\n        }\n    }\n    return count;\n}",
            "// Your code here\n}",
            "if(A.empty()) return 0;\n\t\n\tsize_t rank = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\n\tif(rank == 0) {\n\t\tstd::vector<int> flags(N, 0);\n\t\tstd::queue<int> q;\n\t\tint components = 0;\n\t\t\n\t\tfor(size_t i = 0; i < N; i++) {\n\t\t\tif(flags[i] == 0) {\n\t\t\t\tq.push(i);\n\t\t\t\tflags[i] = 1;\n\t\t\t\tcomponents++;\n\t\t\t\twhile(!q.empty()) {\n\t\t\t\t\tint index = q.front();\n\t\t\t\t\tq.pop();\n\t\t\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\t\t\tif(A[index*N + j] == 1 && flags[j] == 0) {\n\t\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\t\tflags[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tint total = 0;\n\t\tMPI_Reduce(&components, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t\t\n\t\treturn total;\n\t}\n\telse {\n\t\tint components = 0;\n\t\tMPI_Reduce(&components, NULL, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\t}\n}",
            "int mpi_size, mpi_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n  int send = 0;\n  int recv;\n  MPI_Status status;\n  std::vector<int> B;\n  if (N >= mpi_size) {\n    B = A;\n    int recv_from = mpi_rank + 1;\n    int send_to = mpi_rank - 1;\n    if (recv_from >= mpi_size) recv_from = 0;\n    if (send_to < 0) send_to = mpi_size - 1;\n    while (recv_from!= mpi_rank) {\n      MPI_Send(&send, 1, MPI_INT, send_to, 0, MPI_COMM_WORLD);\n      MPI_Recv(&recv, 1, MPI_INT, recv_from, 0, MPI_COMM_WORLD, &status);\n      for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n          if (B[i * N + j] && recv > 0) B[i * N + j] = 0;\n        }\n      }\n      send = recv;\n      send_to = recv_from;\n      recv_from = (recv_from + 1) % mpi_size;\n      if (send_to == mpi_rank) send = 0;\n    }\n  }\n  int ans = 0;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (B[i * N + j]) ans++;\n    }\n  }\n  MPI_Reduce(&ans, &ans, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return ans;\n}",
            "// TODO\n\treturn 0;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "cuda",
        "prompt": "/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n\t Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\n__global__ void componentCount(const int *A, size_t N, int *numComponents) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N) {\n\t\treturn;\n\t}\n\t// Check if i is the root of a component\n\tif (A[i * N + i] == 1) {\n\t\t// Mark all nodes as visited\n\t\tint *visited = (int *)malloc(N * sizeof(int));\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tvisited[j] = 0;\n\t\t}\n\t\t// Mark the root node as visited\n\t\tvisited[i] = 1;\n\t\t// Perform a BFS to count the number of nodes\n\t\tint count = 0;\n\t\tint *Q = (int *)malloc(N * sizeof(int));\n\t\tint tail = 0, head = 0;\n\t\tQ[head] = i;\n\t\ttail++;\n\t\tcount++;\n\t\twhile (tail!= head) {\n\t\t\tint j = Q[head];\n\t\t\thead++;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (visited[k] == 0 && A[j * N + k] == 1) {\n\t\t\t\t\tQ[tail] = k;\n\t\t\t\t\ttail++;\n\t\t\t\t\tcount++;\n\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t*numComponents += 1;\n\t\tfree(visited);\n\t\tfree(Q);\n\t}\n}",
            "int myID = threadIdx.x + blockIdx.x*blockDim.x;\n\tint myRow = myID/N;\n\tint myCol = myID%N;\n\n\t// only count connected components for the upper triangle\n\tif (myRow > myCol)\n\t\treturn;\n\n\t// initialize shared memory for the two atomic counters\n\t// this is a quick and dirty way to allocate shared memory, but it will only work\n\t// for this specific kernel\n\tint *counts;\n\tcounts = (int *)extern_shared_memory;\n\tcounts[threadIdx.x] = 0;\n\tcounts[threadIdx.x + blockDim.x] = 0;\n\n\tint count = 0;\n\tif (A[myRow*N+myCol] == 1) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t// if the component has been counted, we can stop searching this branch\n\t\t\tif (counts[threadIdx.x] == 1)\n\t\t\t\tbreak;\n\n\t\t\t// if the value in the matrix is 1 and the component has not been counted\n\t\t\t// increment the local counter and set the shared counter\n\t\t\tif (A[myRow*N+i] == 1 && (myRow == i)) {\n\t\t\t\tcount++;\n\t\t\t\tcounts[threadIdx.x] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numComponents, count);\n}",
            "// TODO: Write your code here\n\n}",
            "// TODO: your code here\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\n\tint x = tx + blockIdx.x*blockDim.x;\n\tint y = ty + blockIdx.y*blockDim.y;\n\n\tint id = x*N + y;\n\n\tint count = 0;\n\t\n\tif(x < N && y < N){\n\t\tif(A[id] == 1 && x!= y){\n\t\t\tint current = x;\n\t\t\twhile(current!= y){\n\t\t\t\tint id = current*N + current;\n\t\t\t\tif(A[id] == 1){\n\t\t\t\t\tcount++;\n\t\t\t\t\tcurrent = A[id];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(&numComponents[0], count);\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.y + threadIdx.y;\n\tint offset = i*N + j;\n\tif (i < N && j < N && A[offset] > 0) {\n\t\t// If A[i, j] is 1, then set all values in the row and column to 1\n\t\tint *row = (int*) &A[i * N];\n\t\tint *col = (int*) &A[j];\n\t\trow[j] = 1;\n\t\tcol[i] = 1;\n\t}\n}",
            "__shared__ bool visited[100];\n\t__shared__ int count;\n\tint threadIdx_x = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (threadIdx_x < N) {\n\t\tvisited[threadIdx_x] = false;\n\t}\n\tint x = threadIdx_x;\n\tint y = 0;\n\t//check adjacency matrix for edge\n\twhile (y < N) {\n\t\tif (A[threadIdx_x * N + y] == 1) {\n\t\t\tif (!visited[y]) {\n\t\t\t\tvisited[y] = true;\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t\ty++;\n\t}\n\n\t__syncthreads();\n\n\t//atomic increment\n\tatomicAdd(numComponents, count);\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    __shared__ int compCount[16];\n    if (threadIdx.x == 0) {\n        compCount[0] = 1;\n    }\n\n    __syncthreads();\n\n    if (index < N) {\n        if (A[index * N + index] == 1) {\n            for (int i = 0; i < compCount[0]; i++) {\n                if (A[index * N + i] == 1) {\n                    A[index * N + i] = 0;\n                    A[i * N + index] = 0;\n                }\n            }\n            compCount[0]++;\n        }\n    }\n    __syncthreads();\n    if (index < N) {\n        atomicAdd(numComponents, compCount[0]);\n    }\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\n\tif (i == j) {\n\t\tif (A[i*N + i] == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N) {\n\t\tif (A[i*N + i] == 1) {\n\t\t\t// if component is not yet visited, count it\n\t\t\tatomicAdd(numComponents, 1);\n\n\t\t\t// recursive search\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1 && A[j*N + j] == 0)\n\t\t\t\t\tcomponentCount(A, N, numComponents);\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "__shared__ int sdata[1024];\n    int myId = threadIdx.x + blockIdx.x * blockDim.x;\n    int myCount = 0;\n    if (myId < N*N) {\n        if (A[myId] == 1) {\n            myCount = 1;\n        }\n    }\n    sdata[threadIdx.x] = myCount;\n    __syncthreads();\n    if (threadIdx.x == 0) {\n        int total = 0;\n        for (int i = 0; i < blockDim.x; i++) {\n            total += sdata[i];\n        }\n        atomicAdd(numComponents, total);\n    }\n}",
            "__shared__ int sdata[BLOCKSIZE];\n\tint tid = threadIdx.x + blockDim.x * blockIdx.x;\n\tint cache = 0;\n\n\tfor (size_t i = tid; i < N; i += blockDim.x * gridDim.x) {\n\t\tif (A[i * N + tid] == 1) {\n\t\t\tcache = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tatomicAdd(numComponents, cache);\n}",
            "int n = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint comp = -1;\n\n\tif (n < N) {\n\t\tif (A[n*N + n] == 1) {\n\t\t\tcomp = 1;\n\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (i!= n && A[n*N + i] == 1) {\n\t\t\t\t\tcomp = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (comp == 1) {\n\t\t\t\tatomicAdd(numComponents, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "// Create local variables\n\tint localNumComponents = 0;\n\tint localComponentCount = 0;\n\tint row = blockIdx.x;\n\tint col = blockIdx.y;\n\tint threadIdxRow = threadIdx.x;\n\tint threadIdxCol = threadIdx.y;\n\tint rowIndex = row * N + threadIdxCol;\n\tint colIndex = col * N + threadIdxRow;\n\tint currentRow = A[rowIndex];\n\tint currentCol = A[colIndex];\n\n\t// Check if element is connected to the row above or to the left\n\tif(row!= 0) {\n\t\tif(currentCol == 1) {\n\t\t\tatomicAdd(&localComponentCount, 1);\n\t\t}\n\t}\n\tif(col!= 0) {\n\t\tif(currentRow == 1) {\n\t\t\tatomicAdd(&localComponentCount, 1);\n\t\t}\n\t}\n\tatomicAdd(&localNumComponents, localComponentCount);\n\n\t// Calculate the number of components of a given grid\n\tif(threadIdxRow == 0 && threadIdxCol == 0) {\n\t\tatomicAdd(numComponents, localNumComponents);\n\t}\n}",
            "__shared__ int connected[1000];\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i >= N)\n\t\treturn;\n\tint result = 0;\n\tint index = threadIdx.x;\n\tconnected[index] = 0;\n\tif (A[i * N + i]) {\n\t\tconnected[index] = 1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] &&!connected[j]) {\n\t\t\t\tconnected[index] = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\tfor (int i = 1; i < blockDim.x; i *= 2) {\n\t\tint j = 2 * i - 1;\n\t\tif (index >= j)\n\t\t\tconnected[index] += connected[index - j];\n\t\t__syncthreads();\n\t}\n\tif (index == 0)\n\t\tresult = connected[index];\n\t__syncthreads();\n\tatomicAdd(numComponents, result);\n}",
            "// 1. Define the shared memory buffer for the adjacency matrix\n\textern __shared__ int shared_A[];\n\tint i = blockIdx.x;\n\tint j = threadIdx.x;\n\n\tif(threadIdx.x < N)\n\t\tshared_A[threadIdx.x] = A[i * N + threadIdx.x];\n\t__syncthreads();\n\n\t// 2. Mark the nodes which are not connected to other nodes\n\t// \t\t as visited\n\tif(threadIdx.x == 0) {\n\t\tint count = 0;\n\t\tfor(int k = 0; k < N; ++k) {\n\t\t\tif(!shared_A[k]) {\n\t\t\t\tatomicAdd(&count, 1);\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, count);\n\t}\n\t// 3. Count the number of components in the graph\n\t// \t\t using DFS algorithm\n\tif(shared_A[i]) {\n\t\tif(shared_A[i] & (1 << j)) {\n\t\t\tdfs(shared_A, N, j);\n\t\t}\n\t}\n}",
            "int count = 0;\n    int id = threadIdx.y * blockDim.x + threadIdx.x;\n\n    // Check if the node belongs to a connected component\n    if (A[id * N + id] == 1) {\n        count++;\n    }\n\n    __syncthreads();\n    *numComponents += count;\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint numThreads = gridDim.x * blockDim.x;\n\tint currentComponent = 0;\n\tint component = 0;\n\t// If id less than number of threads, it is a valid id.\n\tif(id < numThreads){\n\t\tif(A[id] == 0)\n\t\t\tcomponent = id;\n\t\telse if(A[id] > 0 && A[id] < id)\n\t\t\tcomponent = A[id];\n\t}\n\t// Go over the remaining elements.\n\tfor(int i = id+numThreads; i < N*N; i+=numThreads){\n\t\tif(A[i] > 0){\n\t\t\tif(A[i] == id){\n\t\t\t\t// If i is the same id as i-numThreads, then that's the same component, increase the component count.\n\t\t\t\tif(i-numThreads == id)\n\t\t\t\t\tcurrentComponent++;\n\t\t\t}\n\t\t\telse if(A[i] < id){\n\t\t\t\t// If A[i] is less than id, then that's the same component.\n\t\t\t\tif(A[i] == A[id])\n\t\t\t\t\tcurrentComponent++;\n\t\t\t}\n\t\t}\n\t}\n\t// Set the component count to the component.\n\tif(id < N*N)\n\t\tA[id] = currentComponent;\n}",
            "size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n  // TODO: Replace the following code with your code for computing the number of connected components\n  if (index >= N)\n    return;\n  if (A[index*N + index] == 0)\n    return;\n  int curComponent = 0;\n  for (int i = 0; i < N; i++) {\n    if (A[index*N + i] == 1) {\n      curComponent++;\n      break;\n    }\n  }\n  for (int i = 0; i < N; i++) {\n    if (A[index*N + i] == 0)\n      continue;\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        curComponent++;\n        break;\n      }\n    }\n  }\n  atomicAdd(numComponents, curComponent);\n  // End of TODO\n}",
            "// Each thread is responsible for one row of the input matrix.\n    // Threads in the same row are allowed to race.\n    int myRow = threadIdx.x;\n    int myCol = threadIdx.y;\n\n    // If this thread is responsible for a non-empty row\n    if (A[myRow * N + myRow]) {\n\n        // Set the first component of this row to 1.\n        if (myCol == 0) {\n            atomicAdd(numComponents, 1);\n        }\n\n        // Check the value of the diagonal element of this row.\n        // If it is zero, this thread and all threads in this row are not part of the same component.\n        int myValue = A[myRow * N + myRow];\n        if (myValue == 0) {\n            return;\n        }\n\n        // Loop through all columns in the current row.\n        for (int j = myCol + 1; j < N; j++) {\n\n            // If this thread's value is non-zero, it is part of the same component.\n            // The value of its corresponding column in the current row must also be non-zero.\n            if (A[myRow * N + j] == 0) {\n                return;\n            }\n\n            // Set the corresponding column in this row to zero.\n            A[myRow * N + j] = 0;\n        }\n    }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  int componentId = 0;\n  int currentComponent = 0;\n\n  if (tid < N * N) {\n    if (A[tid] == 1) {\n      currentComponent = atomicAdd(numComponents, 1);\n    }\n  }\n\n  __syncthreads();\n\n  if (tid < N * N) {\n    if (A[tid] == 1) {\n      componentId = atomicMin(numComponents, currentComponent);\n    }\n  }\n  __syncthreads();\n\n  if (tid < N * N) {\n    if (A[tid] == 1) {\n      atomicMin(numComponents, componentId);\n    }\n  }\n}",
            "int tid = threadIdx.x;\n    int i = blockIdx.x;\n    int j = blockIdx.y;\n    // printf(\"tid: %d i: %d j: %d\\n\", tid, i, j);\n    if (i == j) {\n        if (A[i*N + j] == 1) {\n            atomicAdd(numComponents, 1);\n        }\n    }\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n\tint row = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t__shared__ bool visited[1024];\n\t__shared__ int numComp;\n\tif (threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tvisited[0] = false;\n\t\tnumComp = 0;\n\t}\n\t__syncthreads();\n\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] == 1) {\n\t\t\tif (visited[row] == false) {\n\t\t\t\t// found a new component\n\t\t\t\tvisited[row] = true;\n\t\t\t\tnumComp++;\n\t\t\t}\n\t\t\telse if (visited[col] == false) {\n\t\t\t\t// found a new component\n\t\t\t\tvisited[col] = true;\n\t\t\t\tnumComp++;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tatomicAdd(numComponents, numComp);\n\t}\n}",
            "int x = blockIdx.x;\n    int y = blockIdx.y;\n\n    __shared__ int xmin;\n    __shared__ int xmax;\n    __shared__ int ymin;\n    __shared__ int ymax;\n    __shared__ int s;\n\n    if(threadIdx.x == 0) {\n        xmin = (x > 0)? x-1 : 0;\n        xmax = (x < N-1)? x+1 : N-1;\n        ymin = (y > 0)? y-1 : 0;\n        ymax = (y < N-1)? y+1 : N-1;\n        s = 0;\n    }\n\n    __syncthreads();\n\n    if(A[x + y * N] > 0) {\n        if(x == 0) {\n            if(A[xmax + y * N] > 0) {\n                s++;\n            }\n        }\n        else if(x == N-1) {\n            if(A[xmin + y * N] > 0) {\n                s++;\n            }\n        }\n        else {\n            if(A[xmin + y * N] > 0) {\n                s++;\n            }\n            if(A[xmax + y * N] > 0) {\n                s++;\n            }\n        }\n\n        if(y == 0) {\n            if(A[x + ymax * N] > 0) {\n                s++;\n            }\n        }\n        else if(y == N-1) {\n            if(A[x + ymin * N] > 0) {\n                s++;\n            }\n        }\n        else {\n            if(A[x + ymin * N] > 0) {\n                s++;\n            }\n            if(A[x + ymax * N] > 0) {\n                s++;\n            }\n        }\n    }\n    __syncthreads();\n\n    atomicAdd(numComponents, s);\n}",
            "__shared__ int visited[MAX_SIZE];\n\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint size = blockDim.x * blockDim.y;\n\n\tvisited[threadIdx.x] = 0;\n\n\tint count = 0;\n\tif(i < N && j < N && A[i * N + j]) {\n\t\tif(visited[threadIdx.x] == 0) {\n\t\t\tcount = 0;\n\t\t\tint idx = i;\n\t\t\twhile (idx < N) {\n\t\t\t\tvisited[threadIdx.x] = 1;\n\t\t\t\tif(A[idx * N + j] && (i!= j)) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t\tidx += size;\n\t\t\t}\n\t\t\tatomicAdd(numComponents, count);\n\t\t}\n\t}\n}",
            "int num_threads = gridDim.x * blockDim.x;\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// This is a parallel reduction of the number of connected components.\n\t// We compute the number of connected components for this thread's range,\n\t// and then add it to the number of connected components computed by the previous thread.\n\t// We keep computing until we have only one thread left.\n\twhile(num_threads > 0) {\n\t\t// Perform reduction to compute the number of connected components for this thread's range.\n\t\tint range_components = 0;\n\t\tfor (int i = tid; i < N; i += num_threads) {\n\t\t\tint count = 0;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\trange_components += (count == 0 || count == N);\n\t\t}\n\n\t\t// Add this thread's range number of connected components to the previous thread's value.\n\t\t// We do this atomically to prevent two threads from overwriting each other.\n\t\tatomicAdd(numComponents, range_components);\n\n\t\t// Wait for all threads to finish before looping again\n\t\t__syncthreads();\n\t\tnum_threads /= 2;\n\t}\n}",
            "__shared__ int sdata[BLOCK_DIM][BLOCK_DIM];\n\t__shared__ int visited[BLOCK_DIM][BLOCK_DIM];\n\tint blockRow = blockIdx.y;\n\tint blockCol = blockIdx.x;\n\tint row = threadIdx.y;\n\tint col = threadIdx.x;\n\tint x = BLOCK_DIM * blockRow + row;\n\tint y = BLOCK_DIM * blockCol + col;\n\n\tif(x < N && y < N) {\n\t\tsdata[row][col] = 0;\n\t\tvisited[row][col] = 0;\n\t}\n\n\t__syncthreads();\n\n\tif(x >= N || y >= N || A[x * N + y] == 0) {\n\t\treturn;\n\t}\n\n\tint rowCount = 0;\n\n\twhile(x < N && visited[row][col] == 0) {\n\t\tvisited[row][col] = 1;\n\t\trowCount++;\n\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(A[i * N + x] == 1) {\n\t\t\t\tsdata[row][col] = 1;\n\t\t\t\tvisited[row][col] = 1;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\t}\n\n\tint blockCount = 0;\n\n\tfor(int i = 0; i < BLOCK_DIM; i++) {\n\t\tif(sdata[row][i] == 1) {\n\t\t\tblockCount++;\n\t\t}\n\t}\n\n\tif(rowCount > 0 && blockCount == 0) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor (int i = idx; i < N; i += stride) {\n\t\tif (A[i * N + i] == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "__shared__ int cache[256];\n  int compCount = 0;\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int numThreads = blockDim.x * gridDim.x;\n\n  int i = tid;\n  while (i < N) {\n    int component = 0;\n    if (A[i] == 1) {\n      int j = i + 1;\n      while (j < N) {\n        if (A[j] == 1) {\n          j++;\n        } else {\n          break;\n        }\n      }\n      component = j - i;\n    }\n    cache[threadIdx.x] = component;\n    __syncthreads();\n    // find the max\n    for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n      if (threadIdx.x < s)\n        cache[threadIdx.x] = max(cache[threadIdx.x], cache[threadIdx.x + s]);\n      __syncthreads();\n    }\n    if (threadIdx.x == 0) {\n      atomicAdd(numComponents, cache[0]);\n    }\n    i += numThreads;\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (A[i * N + j] == 1 && i!= j) {\n\t\t// Traverse all nodes and set them to 0, so that if we visit the same node again,\n\t\t// we know we have already visited all of its neighbors\n\t\tfor (int x = 0; x < N; ++x) {\n\t\t\tif (A[x * N + i] == 1) {\n\t\t\t\tA[x * N + i] = 0;\n\t\t\t}\n\t\t\tif (A[x * N + j] == 1) {\n\t\t\t\tA[x * N + j] = 0;\n\t\t\t}\n\t\t}\n\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i == j)\n\t\treturn;\n\tif (i >= N || j >= N)\n\t\treturn;\n\tif (A[i * N + j] == 0)\n\t\treturn;\n\n\t*numComponents = *numComponents + 1;\n}",
            "const int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid >= N * N)\n\t\treturn;\n\n\t__shared__ int rowSums[1024];\n\n\tif (threadIdx.x == 0)\n\t\trowSums[blockIdx.x] = 0;\n\n\t__syncthreads();\n\n\tint i = tid % N;\n\tint j = tid / N;\n\n\tif (A[tid] == 1)\n\t\tatomicAdd(rowSums + blockIdx.x, 1);\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0)\n\t\tatomicAdd(numComponents, rowSums[blockIdx.x]);\n}",
            "int i,j;\n\n\t// The component size is 1 for each thread.\n\t*numComponents = 1;\n\n\t// If the current element is 1, check the 8 neighbors and increment the component size for each connected component.\n\tfor(i = blockIdx.x*blockDim.x + threadIdx.x; i < N; i += blockDim.x*gridDim.x) {\n\t\tfor(j = 0; j < N; j++) {\n\t\t\tif((i!= j) && (A[i*N + j])) {\n\t\t\t\tatomicAdd(numComponents, 1);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int id = blockIdx.y*gridDim.x*blockDim.x+blockIdx.x*blockDim.x+threadIdx.x;\n  if (id < N*N) {\n    int i = id / N;\n    int j = id % N;\n    if (A[i*N+j]) {\n      // Mark all connected components as visited\n      for (int k = 0; k < N; k++) {\n        if (A[i*N+k] || A[k*N+i]) {\n          A[i*N+k] = 0;\n          A[k*N+i] = 0;\n        }\n      }\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// Get the component number for this thread\n\t// and use it to find the location to store it\n\tint c = getComponentNumber(A, N, blockIdx.x, blockIdx.y);\n\tint index = blockIdx.x * blockDim.x + blockIdx.y;\n\tatomicAdd(numComponents + index, c);\n}",
            "int row = blockIdx.x;\n    int col = threadIdx.x;\n\n    __shared__ int visited[N];\n    __shared__ int comp[N];\n\n    if (row < N && col < N) {\n        if (row == col) {\n            comp[row] = row;\n        } else {\n            comp[row] = -1;\n        }\n        visited[row] = 0;\n    }\n    __syncthreads();\n\n    int count = 0;\n    while (true) {\n        if (row < N && col < N && A[row * N + col] &&!visited[col]) {\n            count++;\n            comp[col] = row;\n            visited[col] = 1;\n        }\n        __syncthreads();\n\n        // Merge components\n        int minComp = INT_MAX;\n        for (int i = 0; i < N; i++) {\n            if (row < N && col < N && comp[row]!= -1 && comp[col]!= -1 && comp[row]!= comp[col]) {\n                int min = min(comp[row], comp[col]);\n                int max = max(comp[row], comp[col]);\n                comp[max] = min;\n                comp[min] = min;\n            }\n        }\n        __syncthreads();\n\n        int hasChanged = 0;\n        for (int i = 0; i < N; i++) {\n            if (row < N && col < N && comp[row]!= -1 && comp[row]!= i) {\n                comp[row] = comp[i];\n                hasChanged = 1;\n            }\n        }\n        __syncthreads();\n\n        if (!hasChanged) {\n            break;\n        }\n    }\n\n    if (row < N) {\n        atomicAdd(numComponents, count);\n    }\n}",
            "int i = threadIdx.x + blockDim.x * blockIdx.x;\n\tint j = threadIdx.y + blockDim.y * blockIdx.y;\n\n\tif (i < N && j < N && i!= j) {\n\t\tif (A[N * i + j]!= 0) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n\n}",
            "const int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    const int stride = blockDim.x * gridDim.x;\n\n    for (int i = tid; i < N * N; i += stride) {\n        // Do something with A[i]\n    }\n}",
            "__shared__ int componentIds[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ int componentCounts[BLOCK_SIZE][BLOCK_SIZE];\n\n  int tidx = threadIdx.x;\n  int tidy = threadIdx.y;\n  int bidx = blockIdx.x;\n  int bidy = blockIdx.y;\n\n  int gid = bidy * blockDim.x + bidx;\n  int gidx = gid;\n  int gidy = gid;\n\n  // Fill the component Id and the count of the component Id in the shared memory\n  componentIds[tidx][tidy] = gidx;\n  componentCounts[tidx][tidy] = 0;\n  __syncthreads();\n\n  // Traverse the matrix to find the neighbors of the current node and their respective component ids\n  for (int i = 0; i < N; i++) {\n    int nb = A[N * gid + i];\n    if (nb == 1) {\n      int nid = i;\n      int nbid = blockIdx.x + i / blockDim.x;\n      int nbidx = nbid;\n      int nbidy = nbid;\n\n      int ntidx = threadIdx.x;\n      int ntidy = threadIdx.y;\n\n      int ntidx = nbidx * blockDim.x + ntidx;\n      int ntidy = nbidy * blockDim.y + ntidy;\n\n      // Compare the component ids of the current node and the neighbor node\n      // If they are not equal then increment the count of the component id of the neighbor node\n      // Update the component id of the current node with the minimum component id of the two nodes\n      if (componentIds[tidx][tidy]!= componentIds[ntidx][ntidy]) {\n        atomicAdd(&componentCounts[ntidx][ntidy], 1);\n        componentIds[tidx][tidy] = min(componentIds[tidx][tidy], componentIds[ntidx][ntidy]);\n      }\n    }\n  }\n  __syncthreads();\n\n  // Find the maximum count of the component ids of the entire thread block\n  int maxCount = componentCounts[tidx][tidy];\n  for (int i = 1; i < blockDim.x * blockDim.y; i++) {\n    if (maxCount < componentCounts[tidx][i]) {\n      maxCount = componentCounts[tidx][i];\n    }\n  }\n  __syncthreads();\n\n  // Accumulate the max count in a global array to get the total number of components\n  if (tidx == 0 && tidy == 0) {\n    atomicAdd(numComponents, maxCount);\n  }\n}",
            "int row = blockDim.y * blockIdx.y + threadIdx.y;\n\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (row >= N || col >= N) return;\n\tif (A[row * N + col]!= 0) {\n\t\t__syncthreads();\n\t\t*numComponents += 1;\n\t}\n}",
            "int num_threads = gridDim.x * blockDim.x;\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = num_threads;\n\n\tif (id >= N) return;\n\n\t// Perform a DFS\n\tint start = id;\n\tint num_visited = 1;\n\tbool *visited = new bool[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = false;\n\t}\n\tvisited[start] = true;\n\tint count = 0;\n\n\twhile (count < N) {\n\t\tint next = (id + stride) % N;\n\t\tif (A[start * N + next] &&!visited[next]) {\n\t\t\tvisited[next] = true;\n\t\t\tstart = next;\n\t\t\tnum_visited++;\n\t\t} else {\n\t\t\tstart = (id + 1) % N;\n\t\t\tcount++;\n\t\t\tnum_visited = 1;\n\t\t}\n\t}\n\t// update the number of connected components\n\tatomicAdd(numComponents, num_visited);\n}",
            "int rowId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint colId = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (rowId < N && colId < N)\n\t{\n\t\tif (A[rowId * N + colId])\n\t\t{\n\t\t\tint myCount = 0;\n\t\t\t// Find the number of connected components in the sub-graph defined by the current element\n\t\t\t// and the elements below it in the column.\n\t\t\tfor (int i = 0; i < rowId; i++)\n\t\t\t{\n\t\t\t\tif (A[i * N + colId])\n\t\t\t\t{\n\t\t\t\t\tmyCount++;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Find the number of connected components in the sub-graph defined by the current element\n\t\t\t// and the elements to the right in the row.\n\t\t\tfor (int i = rowId + 1; i < N; i++)\n\t\t\t{\n\t\t\t\tif (A[i * N + colId])\n\t\t\t\t{\n\t\t\t\t\tmyCount++;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tatomicAdd(numComponents, myCount);\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    int index = i * N + j;\n    if (i < N && j < N) {\n        if (A[index] == 1) {\n            atomicAdd(numComponents, 1);\n            break;\n        }\n    }\n}",
            "int row = blockIdx.x*blockDim.x + threadIdx.x;\n    int col = blockIdx.y*blockDim.y + threadIdx.y;\n\n    __shared__ int sharedMemory[BLOCK_SIZE][BLOCK_SIZE];\n    int isConnected = 1;\n    if(row < N && col < N) {\n        isConnected = A[row*N + col];\n    }\n    sharedMemory[threadIdx.y][threadIdx.x] = isConnected;\n    __syncthreads();\n\n    int neighbors = 0;\n    for(int i = 0; i < BLOCK_SIZE; i++) {\n        neighbors += sharedMemory[threadIdx.y][i];\n    }\n\n    if(row < N && col < N) {\n        atomicAdd(numComponents, neighbors > 0);\n    }\n}",
            "__shared__ int shared[100];\n\n    // 1. Initialize shared memory to 0\n    // 2. Read A[i,j] and compare to 0 (not connected) or 1 (connected)\n    // 3. If connected, then add 1 to the shared memory\n    // 4. All threads in block read from shared memory and add to numComponents[0]\n    // 5. All threads in block read from shared memory and add to numComponents[1]\n    //...\n    // 6. All threads in block read from shared memory and add to numComponents[n]\n    // 7. numComponents[0] contains the number of connected components\n}",
            "__shared__ int visited[512];\n\tint row = blockIdx.y*blockDim.y + threadIdx.y;\n\tint col = blockIdx.x*blockDim.x + threadIdx.x;\n\n\tif(row == col) {\n\t\tvisited[threadIdx.y] = 0;\n\t} else {\n\t\tif(A[row*N + col] == 1) {\n\t\t\tvisited[threadIdx.y] = 1;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint num = 0;\n\tint sum = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(visited[i] == 1) {\n\t\t\tsum++;\n\t\t\tnum++;\n\t\t}\n\t}\n\n\tif(threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tatomicAdd(numComponents, num);\n\t}\n}",
            "// A[col * N + row]\n\t// A[col * N + row] = A[row * N + col]\n\n\tint row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint col = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] == 1 && A[col * N + row] == 1) {\n\t\t\tA[row * N + col] = 0;\n\t\t\tA[col * N + row] = 0;\n\t\t\t*numComponents = *numComponents + 1;\n\t\t}\n\t}\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n    int j = blockIdx.y*blockDim.y + threadIdx.y;\n\n    if (i < N && j < N && A[i*N+j] &&!atomicOr(&(numComponents[0]), 0)) {\n        atomicAdd(&(numComponents[0]), 1);\n        dfs(A, N, i, j);\n    }\n}",
            "unsigned int row, col;\n\tint numComponent = 0;\n\t// Loop over each row in the adjacency matrix\n\trow = blockIdx.x;\n\tcol = threadIdx.x;\n\tif (row < N && col < N && A[row * N + col] == 1) {\n\t\tnumComponent++;\n\t}\n\tatomicAdd(numComponents, numComponent);\n}",
            "int i = blockIdx.x;\n\n\tint cnt = 0;\n\n    for(int j = 0; j < N; j++) {\n\t\tif(A[i * N + j] == 1) cnt++;\n\t}\n\n\tif(cnt >= 1) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "const int x = blockIdx.x * blockDim.x + threadIdx.x;\n  const int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  __shared__ int component[BLOCK_SIZE * BLOCK_SIZE];\n\n  int componentId = -1;\n  int localComponentId = 0;\n  int flag = 0;\n  if (A[y * N + x]) {\n    // find component id\n    for (int i = 0; i < N; i++) {\n      if (component[i] == 0) {\n        localComponentId = i;\n        component[i] = 1;\n        if (y == i)\n          flag = 1;\n        break;\n      }\n    }\n    if (flag)\n      componentId = localComponentId;\n    else\n      componentId = component[y];\n\n    // update component\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + y]) {\n        if (component[i] == 0) {\n          component[i] = componentId;\n        }\n      }\n    }\n  }\n\n  __syncthreads();\n\n  // add new component to global count\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (component[i] > 0 && i == component[i])\n      count++;\n  }\n  atomicAdd(numComponents, count);\n}",
            "int r, c;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // If we are in bounds, count the number of connected components\n    // that contain the current node.\n    if (i < N*N) {\n        r = i / N;\n        c = i % N;\n        if (A[r*N + c] == 1) {\n            int start = r;\n            int end = c;\n            int cur = r*N + c;\n            while (r!= end || c!= start) {\n                cur += N + 1;\n                r = cur / N;\n                c = cur % N;\n                if (A[cur] == 1) {\n                    atomicAdd(numComponents, 1);\n                    break;\n                }\n            }\n        }\n    }\n}",
            "size_t index = threadIdx.x + blockIdx.x * blockDim.x;\n\n  if (index >= N * N)\n    return;\n\n  int row = index / N;\n  int col = index % N;\n  if (A[index] == 1 && row!= col) {\n    int r = row, c = col;\n    while (true) {\n      c = find(A, r, c, N);\n      if (r == c)\n        break;\n      r = c;\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "__shared__ int sdata[128];\n\t__shared__ bool visited[128];\n\tint threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\tint numThreads = blockDim.x * gridDim.x;\n\n\tint n = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[threadId * N + i] == 1) {\n\t\t\tn++;\n\t\t}\n\t}\n\n\tint id = threadId;\n\tfor (int i = 0; i < n; i++) {\n\t\tint v = A[id * N + i];\n\t\tint count = 0;\n\t\tif (visited[id] == 0) {\n\t\t\tvisited[id] = 1;\n\t\t\tint index = threadId * N;\n\t\t\twhile (index < N * N) {\n\t\t\t\tif (A[index] == 1 && id!= index / N) {\n\t\t\t\t\tsdata[threadId]++;\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t}\n\t\t\tsdata[threadId] = 1 + sdata[threadId];\n\t\t}\n\n\t\tcount = sdata[threadId];\n\n\t\tfor (int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n\t\t\t__syncthreads();\n\t\t\tif (threadIdx.x < offset) {\n\t\t\t\tsdata[threadIdx.x] += sdata[threadIdx.x + offset];\n\t\t\t}\n\t\t}\n\n\t\tif (threadIdx.x == 0) {\n\t\t\tatomicAdd(numComponents, count);\n\t\t}\n\t}\n}",
            "// TODO: implement the kernel\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N) return;\n  for (int j = 0; j < N; ++j) {\n    if (A[i*N+j] == 1) {\n      atomicAdd(numComponents, 1);\n      return;\n    }\n  }\n}",
            "/* TODO: Implement */\n}",
            "// This is the index into the flattened 1D version of A.\n    const int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n    if (index >= N * N) {\n        return;\n    }\n\n    int row = index / N;\n    int col = index % N;\n    if (A[index] > 0) {\n        __shared__ int components[THREADS_PER_BLOCK];\n        if (threadIdx.x == 0) {\n            components[0] = 0;\n        }\n        __syncthreads();\n        int myComponent = components[0];\n\n        for (int i = 0; i < N; i++) {\n            if (i == row) {\n                continue;\n            }\n            if (A[row * N + i] > 0) {\n                if (myComponent == 0) {\n                    myComponent = components[i];\n                } else {\n                    if (myComponent!= components[i]) {\n                        myComponent = 0;\n                    }\n                }\n            }\n        }\n        __syncthreads();\n        if (threadIdx.x == 0) {\n            atomicMax(numComponents, myComponent);\n        }\n        __syncthreads();\n        if (threadIdx.x == 0) {\n            if (myComponent == 0) {\n                components[0] += 1;\n            }\n        }\n        __syncthreads();\n        if (myComponent!= 0) {\n            components[row] = myComponent;\n        }\n        __syncthreads();\n    }\n    __syncthreads();\n}",
            "// Your code here.\n}",
            "extern __shared__ int shared[];\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int totalComponents = 0;\n\n  // If we are on a valid location in the array\n  if (tid < N) {\n    shared[threadIdx.x] = A[tid];\n    __syncthreads();\n\n    // If we are on the first element of a connected component\n    if (threadIdx.x == 0 && shared[0]!= 0) {\n      totalComponents++;\n    }\n  }\n  __syncthreads();\n\n  // Reduce the elements in the shared array to count the number of connected components\n  for (int s = blockDim.x / 2; s > 0; s >>= 1) {\n    if (threadIdx.x < s) {\n      if (shared[threadIdx.x]!= 0 && shared[threadIdx.x + s]!= 0) {\n        shared[threadIdx.x] = 0;\n      }\n    }\n    __syncthreads();\n  }\n\n  // All values in the shared array are non-zero iff they are part of a connected component\n  // If we are on a valid location in the array, add the number of connected components to the global array\n  if (tid < N) {\n    atomicAdd(numComponents, shared[0]);\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint num_threads = blockDim.x * gridDim.x;\n\t\n\tint id = tid;\n\tint component_count = 0;\n\n\twhile (id < N) {\n\t\tif (A[id] == 1) {\n\t\t\tcomponent_count++;\n\t\t}\n\t\tid += num_threads;\n\t}\n\t\n\tatomicAdd(numComponents, component_count);\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x; // global thread index\n\n  if(tid < N) {\n    int count = 0;\n    int start = tid;\n\n    while(A[tid*N + tid]) {\n      count++;\n      tid = A[tid*N + tid] - 1;\n    }\n\n    if(count > 0) {\n      atomicAdd(numComponents, 1);\n      atomicMin(A + tid*N + start, 0);\n    }\n  }\n}",
            "int col = threadIdx.x;\n    int row = blockIdx.x;\n\n    if (col < N && A[row * N + col]) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int i = threadIdx.x;\n    int j = threadIdx.y;\n    int idx = i * N + j;\n    __shared__ int visited[256];\n    __shared__ int count;\n\n    if (i == 0) {\n        count = 0;\n        for (int k = 0; k < 256; k++) {\n            visited[k] = 0;\n        }\n    }\n\n    __syncthreads();\n\n    if (i < N && j < N) {\n        if (A[idx] == 1) {\n            if (!visited[i] &&!visited[j]) {\n                visited[i] = 1;\n                visited[j] = 1;\n                count++;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    if (i == 0 && j == 0) {\n        *numComponents = count;\n    }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tint col = blockIdx.y * blockDim.y + threadIdx.y;\n\tint idx = row * N + col;\n\n\tif (idx < N*N) {\n\t\tif (A[idx] > 0 && row == col) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "/* YOUR CODE HERE */\n    __shared__ int visited[1000];\n    int *myvisited = &visited[threadIdx.x];\n    int myid = threadIdx.x + blockIdx.x * blockDim.x;\n    if(myid<N) {\n        *myvisited=0;\n        dfs(A, myid, myvisited, blockIdx.x*blockDim.x);\n    }\n    __syncthreads();\n    int mycount = 0;\n    for(int i=0;i<blockDim.x;i++){\n        if(*(myvisited+i)) mycount++;\n    }\n    atomicAdd(numComponents, mycount);\n}",
            "// TODO\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    int count = 0;\n    for (size_t j = 0; j < N; j++) {\n      count += A[i * N + j];\n    }\n    atomicAdd(numComponents, count);\n  }\n}",
            "//...\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int s[512];\n\t__shared__ int temp[512];\n\n\tint *s_ptr = s + threadIdx.x;\n\tint *temp_ptr = temp + threadIdx.x;\n\n\tif (i >= N) return;\n\n\tint num_components = 0;\n\tint visited = 0;\n\n\tif (A[i * N + i] == 0) return;\n\n\t*s_ptr = i;\n\n\twhile (*s_ptr!= -1) {\n\t\tnum_components++;\n\t\t*s_ptr = -1;\n\n\t\twhile (atomicAdd(s_ptr, 0) < 1) {\n\t\t\t*s_ptr = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 0) continue;\n\t\t\t\tif (atomicCAS(s_ptr, 0, j) == 0) {\n\t\t\t\t\tatomicExch(temp_ptr, j);\n\t\t\t\t} else if (atomicAdd(s_ptr, 0) >= 1) {\n\t\t\t\t\tatomicCAS(s_ptr, 0, atomicAdd(temp_ptr, 0));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, num_components);\n}",
            "int idx = threadIdx.x + blockDim.x*blockIdx.x;\n\tint i = idx / N;\n\tint j = idx % N;\n\tint size = 1;\n\tint color = -1;\n\n\tif(i!= j) {\n\t\tif(A[idx]!= 0) {\n\t\t\tcolor = atomicMin(&A[i * N + i], A[j * N + j]);\n\t\t\tsize = atomicAdd(&A[color * N + color], 1);\n\t\t}\n\t}\n\n\t// Block until all threads in the block have finished\n\t__syncthreads();\n\n\t// Atomic maximum for all blocks\n\tint tmp = atomicMax(numComponents, size);\n\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint size = blockDim.x * gridDim.x;\n\tint numComponents = 0;\n\tfor (int i = id; i < N; i += size) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tnumComponents++;\n\t\t\t}\n\t\t}\n\t}\n\tnumComponents = atomicAdd(numComponents, numComponents);\n}",
            "int row = blockIdx.x;\n\tint col = threadIdx.x;\n\tint index = row * N + col;\n\n\t// if the current row and column are connected, count this as a component\n\tif (row!= col && A[index] > 0)\n\t\tatomicAdd(numComponents, 1);\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n    // use an atomicAdd to keep a running total of the components\n    // hint: atomicAdd(&a, b) adds b to a in a thread-safe way\n    atomicAdd(numComponents, 1);\n}",
            "// Insert your code here\n    __shared__ int my_components;\n\n    if (threadIdx.x == 0) {\n        my_components = 0;\n    }\n\n    __syncthreads();\n\n    if (A[blockIdx.y * N + blockIdx.x] == 1) {\n        atomicAdd(&my_components, 1);\n    }\n\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        atomicAdd(numComponents, my_components);\n    }\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int rowId = id/N;\n    int colId = id%N;\n    if (rowId < N && colId < N && A[id] && rowId!= colId) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "// Initialize numComponents to zero.\n\t// Hint: You can use atomicAdd() to perform atomic addition on integers.\n\t// You can use threadIdx.x to determine which thread is running,\n\t// and use that to set the value of numComponents.\n\n\t// ***************\n\t// Your code here.\n\t// ***************\n\tint i = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (i == 0) {\n\t\tatomicAdd(numComponents, 0);\n\t}\n}",
            "// You have to do this to get the current thread ID\n\t// and then find the row and column of that thread\n\t// in the adjacency matrix.\n\t//\n\t// This is the row/col of A that corresponds to the current\n\t// thread (which you can compute using the thread ID).\n\t//\n\tint i = blockIdx.x;\n\tint j = blockIdx.y;\n\n\t// Compute if this edge is a bridge or not.\n\t//\n\t// If this edge is a bridge, atomically decrement the number\n\t// of connected components.\n\t//\n\n\t// The following is a stub to get you started.\n\t//\n\tif (A[i*N+j] == 1)\n\t{\n\t\tatomicAdd(numComponents, -1);\n\t}\n\telse\n\t{\n\t\t// Do nothing\n\t}\n}",
            "// TODO: compute the number of connected components in the graph.\n\t// if A[i][j]==1 then there is an edge between i and j\n\t// if A[i][j]==0 then there is no edge between i and j\n\n\tif (threadIdx.x == 0){\n\t\t*numComponents = 1;\n\t}\n\n\t__syncthreads();\n\n\tif(A[blockIdx.x * N + blockIdx.x] == 1){\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "__shared__ int component[BLOCK_DIM][BLOCK_DIM];\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// Initialize the component to -1\n\tif (threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tcomponent[0][0] = -1;\n\t}\n\n\t// Copy the components into the shared memory\n\tcomponent[threadIdx.y][threadIdx.x] = A[i * N + j];\n\t__syncthreads();\n\n\t// Check if the component is already set\n\tif (i >= N || j >= N || component[threadIdx.y][threadIdx.x]!= 1) {\n\t\treturn;\n\t}\n\n\t// Go through all adjacent cells\n\tfor (int k = 0; k < N; k++) {\n\t\t// If the adjacent cell is a 1, it belongs to the same component\n\t\tif (component[threadIdx.y][k] == 1 || component[k][threadIdx.x] == 1) {\n\t\t\tcomponent[threadIdx.y][threadIdx.x] = component[threadIdx.y][k];\n\t\t\tbreak;\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Set the components of the same group to the same number\n\tif (i == 0 && j == 0) {\n\t\tint curComponent = component[threadIdx.y][threadIdx.x];\n\t\tfor (int m = 0; m < N; m++) {\n\t\t\tfor (int n = 0; n < N; n++) {\n\t\t\t\tif (component[m][n] == 1) {\n\t\t\t\t\tcomponent[m][n] = curComponent;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Update the number of components\n\tif (threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tint curComponent = component[threadIdx.y][threadIdx.x];\n\t\tif (curComponent >= 0 && curComponent < N && numComponents[curComponent] == 0) {\n\t\t\tnumComponents[curComponent] = 1;\n\t\t}\n\t}\n}",
            "__shared__ int comp[16][16];\n  __shared__ int *marked;\n  __shared__ int num;\n\n  if(threadIdx.x == 0){\n    num = 0;\n    marked = (int *) calloc(N, sizeof(int));\n  }\n  __syncthreads();\n\n  int i = blockIdx.x;\n  int j = threadIdx.x;\n  comp[i][j] = 1;\n\n  for(int k = 0; k < N; k++) {\n    if(k == i || k == j) {\n      continue;\n    }\n\n    if(A[i*N+k] && A[j*N+k] && marked[k]!= 1) {\n      comp[i][j] = 0;\n    }\n  }\n  __syncthreads();\n\n  // Determine if component is connected\n  if(comp[i][j]) {\n    marked[i] = 1;\n    marked[j] = 1;\n    atomicAdd(&num, 1);\n  }\n  __syncthreads();\n\n  // Store the number of components found\n  if(threadIdx.x == 0){\n    *numComponents = num;\n  }\n}",
            "int tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\n\tint x = (by * blockDim.x + tx);\n\tint y = (bx * blockDim.y + ty);\n\n\tint *s = new int[N];\n\n\t__shared__ int s_tile[BLOCKDIM][BLOCKDIM];\n\t__shared__ int s_comp[BLOCKDIM][BLOCKDIM];\n\n\tint *tile = s_tile[ty][tx];\n\tint *comp = s_comp[ty][tx];\n\n\tif (x < N && y < N) {\n\t\ttile[ty * BLOCKDIM + tx] = A[y * N + x];\n\t}\n\n\t__syncthreads();\n\n\tif (x < N && y < N) {\n\t\tcomp[ty * BLOCKDIM + tx] = (ty * BLOCKDIM + tx);\n\t}\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < BLOCKDIM; i++) {\n\t\tif (tile[ty * BLOCKDIM + i] == 1) {\n\t\t\tcomp[ty * BLOCKDIM + i] = comp[ty * BLOCKDIM + tx];\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (x < N && y < N) {\n\t\tfor (int i = 0; i < BLOCKDIM; i++) {\n\t\t\tif (tile[i * BLOCKDIM + tx] == 1) {\n\t\t\t\tcomp[i * BLOCKDIM + tx] = comp[ty * BLOCKDIM + tx];\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint count = 0;\n\tint size = 0;\n\n\tfor (int i = 0; i < BLOCKDIM; i++) {\n\t\tif (comp[ty * BLOCKDIM + i] == (ty * BLOCKDIM + tx)) {\n\t\t\tcount++;\n\t\t}\n\t\tif (comp[ty * BLOCKDIM + i] == (ty * BLOCKDIM + tx)) {\n\t\t\tsize++;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (x < N && y < N) {\n\t\tif (count == 1) {\n\t\t\ts[y] = size;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tint sum = 0;\n\tif (x < N && y < N) {\n\t\tfor (int i = 0; i < BLOCKDIM; i++) {\n\t\t\tsum += s[ty * BLOCKDIM + i];\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (x < N && y < N) {\n\t\tif (sum > 0) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n\n\tdelete[] s;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i >= N)\n        return;\n\n    if (A[i * N + i]!= 0) {\n        int j = 0;\n        int current_index = i;\n        while (j < N) {\n            if (A[current_index * N + j]!= 0) {\n                A[current_index * N + j] = 0;\n                A[j * N + current_index] = 0;\n            }\n            j++;\n        }\n        *numComponents += 1;\n    }\n}",
            "int myId = threadIdx.x + blockDim.x * blockIdx.x;\n\tint numThreads = gridDim.x * blockDim.x;\n\t\n\tint count = 0;\n\tint myComponent;\n\n\tif (myId < N) {\n\t\tmyComponent = A[myId*N + myId];\n\t\tfor (int i = myId+1; i < N; i++) {\n\t\t\tif (A[myId*N + i]) {\n\t\t\t\tmyComponent = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i*N + myId]) {\n\t\t\t\tmyComponent = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t// Count connected components\n\t\tcount = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[myId*N + i]) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\n\t\tif (myComponent) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "__shared__ int s[N*N];\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint btid = threadIdx.x;\n\tint rid = tid/N;\n\tint cid = tid%N;\n\tint num_of_blocks = gridDim.x;\n\n\tint comp = -1;\n\tif (tid < N*N) {\n\t\ts[tid] = A[tid];\n\t}\n\n\t__syncthreads();\n\tif (tid < N*N) {\n\t\tint r = tid / N;\n\t\tint c = tid % N;\n\t\tif (s[tid] == 1) {\n\t\t\tif (rid == 0) {\n\t\t\t\t//int val = s[btid * N + c];\n\t\t\t\t//printf(\"%d\\n\", val);\n\t\t\t\tcomp = c;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tint r_up = rid - 1;\n\t\t\t\tint col = s[r_up * N + c];\n\t\t\t\tif (col >= 0) {\n\t\t\t\t\tcomp = col;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tif (comp >= 0) {\n\t\tint r_up = rid - 1;\n\t\twhile (r_up >= 0) {\n\t\t\tint col = s[r_up * N + c];\n\t\t\tif (col >= 0) {\n\t\t\t\tcomp = col;\n\t\t\t\tr_up--;\n\t\t\t}\n\t\t\telse {\n\t\t\t\ts[r_up * N + c] = comp;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (tid < N*N) {\n\t\tif (s[tid] == 1) {\n\t\t\tint col = s[btid * N + comp];\n\t\t\ts[btid * N + c] = col;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tid < N*N) {\n\t\tif (s[tid] == 1) {\n\t\t\tint r_down = rid + 1;\n\t\t\twhile (r_down < num_of_blocks) {\n\t\t\t\tint col = s[r_down * N + c];\n\t\t\t\tif (col >= 0) {\n\t\t\t\t\ts[r_down * N + c] = comp;\n\t\t\t\t\tr_down++;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tid < N*N) {\n\t\tint r_down = rid + 1;\n\t\twhile (r_down < num_of_blocks) {\n\t\t\tint col = s[r_down * N + c];\n\t\t\tif (col >= 0) {\n\t\t\t\ts[r_down * N + c] = comp;\n\t\t\t\tr_down++;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (tid < N*N) {\n\t\tint col = s[btid * N + comp];\n\t\ts[tid] = col;\n\t}\n\n\t__syncthreads();\n\n\tif (tid < N*N && s[tid] == 1) {\n\t\tint comp = s[tid];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (comp == s[i*N + c]) {\n\t\t\t\ts[i*N + c] = -1;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tid < N*N) {\n\t\tif (s[tid] == 1) {\n\t\t\tatomicAdd(numComponents, 1);",
            "size_t i = blockIdx.x;\n    size_t j = blockIdx.y;\n\n    if (i < N && j < N) {\n        if (i == j) {\n            return;\n        }\n\n        int *atomicNumComponents = (int *)atomicAdd((unsigned long long *)numComponents, 0);\n        if (A[i * N + j] == 1) {\n            *atomicNumComponents += 1;\n        }\n    }\n}",
            "// TODO: Implement this.\n\t__shared__ int n;\n\tif(threadIdx.x == 0)\n\t\tn = atomicAdd(numComponents, 1);\n\t__syncthreads();\n\tint start = blockIdx.x * blockDim.x + threadIdx.x;\n\tint end = (blockIdx.x + 1) * blockDim.x;\n\n\tfor (int i = start; i < end; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j]) {\n\t\t\t\tatomicMin(numComponents, n);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "size_t id = blockIdx.x * blockDim.x + threadIdx.x;\n  if (id < N) {\n    // Do work to determine the number of connected components.\n    // Store the result in numComponents.\n  }\n}",
            "__shared__ int shared_visited[20];\n\t__shared__ int shared_component[20];\n\t__shared__ int shared_count;\n\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid < N) {\n\t\tshared_visited[tid] = 0;\n\t\tshared_component[tid] = tid;\n\t}\n\t__syncthreads();\n\n\tif (tid < N) {\n\t\tint component = tid;\n\n\t\twhile (shared_component[component]!= component) {\n\t\t\tcomponent = shared_component[component];\n\t\t}\n\t\t\n\t\tint new_component = component;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (j!= component && A[component * N + j] && shared_visited[j] == 0) {\n\t\t\t\tnew_component = j;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tshared_component[component] = new_component;\n\t\tshared_visited[component] = 1;\n\n\t\t__syncthreads();\n\t\t\n\t\tif (shared_component[tid] == tid) {\n\t\t\tatomicAdd(&shared_count, 1);\n\t\t}\n\t\t__syncthreads();\n\t\t\n\t\t*numComponents = shared_count;\n\t}\n}",
            "// Declare and initialize shared memory.\n  __shared__ bool visited[MAX_N];\n  for (int i = 0; i < MAX_N; i++) {\n    visited[i] = false;\n  }\n\n  // Get the id of the thread.\n  int id = threadIdx.x + blockIdx.x * blockDim.x;\n\n  // We only need one thread to count the number of connected components.\n  if (id == 0) {\n    // Initialize numComponents.\n    *numComponents = 0;\n\n    // Check all vertices.\n    for (int i = 0; i < N; i++) {\n      // Check if the vertex has been visited.\n      if (visited[i] == false) {\n        // This vertex is not visited yet.\n        dfs(A, i, visited);\n        *numComponents += 1;\n      }\n    }\n  }\n}",
            "// TODO: Fill this in\n  // Start at the thread index\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  //printf(\"Thread index: %d\\n\", i);\n  // Check if it's in the array bounds\n  if (i >= N) return;\n\n  // Now we need to go through the entire array\n  for (int j = 0; j < N; j++) {\n    // If we find a neighbor that's 1\n    if (A[i * N + j] == 1) {\n      // Set the neighbor to 0, so it can't be used later\n      A[i * N + j] = 0;\n\n      // We will need to check the neighbor's neighbors\n      // The neighbors are in the same row as the element\n      // We also know the neighbors are in columns that are to the right of the index i\n      for (int k = i + 1; k < N; k++) {\n        // If we find a 1 that means this neighbor is connected to our index\n        if (A[i * N + k] == 1) {\n          // Set it to 0 so it won't be checked again\n          A[i * N + k] = 0;\n        }\n      }\n    }\n  }\n  // If we get here, we know there's a new component\n  atomicAdd(numComponents, 1);\n}",
            "int id = threadIdx.x + blockDim.x * blockIdx.x;\n  if (id >= N) return;\n  __shared__ int visited[1000];\n  int count = 0;\n  for (int i = 0; i < N; i++)\n    visited[i] = 0;\n  if (!visited[id]) {\n    count++;\n    visited[id] = 1;\n    for (int i = 0; i < N; i++) {\n      if (i == id)\n        continue;\n      if (A[id * N + i] &&!visited[i]) {\n        count++;\n        visited[i] = 1;\n      }\n    }\n  }\n  atomicAdd(numComponents, count);\n}",
            "int myId = blockIdx.x * blockDim.x + threadIdx.x;\n  // TODO: implement componentCount kernel\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int col = blockIdx.y * blockDim.y + threadIdx.y;\n  if (row >= N || col >= N)\n    return;\n\n  // TODO: fill in the kernel body\n}",
            "__shared__ bool isVisited[THREADS_PER_BLOCK];\n\n\t__shared__ int componentCountShared[THREADS_PER_BLOCK];\n\n\tint thread_id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tint thread_row = thread_id / N;\n\tint thread_col = thread_id % N;\n\n\tint start_row = thread_row * N;\n\tint start_col = thread_col * N;\n\n\tif(thread_id == 0){\n\t\t*numComponents = 0;\n\t\tcomponentCountShared[0] = 0;\n\t}\n\n\t__syncthreads();\n\n\tif(thread_id < N*N){\n\n\t\tbool isConnected = false;\n\t\tint count = 0;\n\t\t\n\t\tisVisited[thread_id] = false;\n\n\t\twhile(true){\n\t\t\tif(A[start_row + thread_col] == 1){\n\t\t\t\tisConnected = true;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif(thread_col == N-1){\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\n\t\t\tthread_col++;\n\t\t}\n\n\t\tif(isConnected){\n\t\t\tisVisited[thread_id] = true;\n\t\t\tint i = 0;\n\n\t\t\t//Visit the entire row.\n\t\t\tfor(i = 0; i < N; i++){\n\t\t\t\tif(i == thread_col){\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(A[start_row + i] == 1){\n\t\t\t\t\tisVisited[thread_row * N + i] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\ti = 0;\n\t\t\tfor(i = 0; i < N; i++){\n\t\t\t\tif(i == thread_row){\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif(A[i * N + thread_col] == 1){\n\t\t\t\t\tisVisited[i * N + thread_col] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif(thread_id == 0){\n\t\tfor(int i = 0; i < THREADS_PER_BLOCK; i++){\n\t\t\tif(isVisited[i]){\n\t\t\t\tcomponentCountShared[0]++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t__syncthreads();\n\n\tatomicAdd(numComponents, componentCountShared[0]);\n}",
            "__shared__ int count[THREADS_PER_BLOCK];\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int start = id * (N/gridDim.x);\n    int end = (id+1) * (N/gridDim.x);\n    if (id >= gridDim.x) {\n        return;\n    }\n\n    int num = 0;\n    for (int i = start; i < end; i++) {\n        int col = 0;\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                col = j;\n            }\n        }\n        if (A[i * N + col] == 1) {\n            num++;\n        }\n    }\n    count[threadIdx.x] = num;\n    __syncthreads();\n    for (unsigned int s = blockDim.x / 2; s > 0; s >>= 1) {\n        if (threadIdx.x < s) {\n            count[threadIdx.x] += count[threadIdx.x + s];\n        }\n        __syncthreads();\n    }\n    if (threadIdx.x == 0) {\n        atomicAdd(numComponents, count[0]);\n    }\n}",
            "unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n  unsigned int j = blockIdx.y*blockDim.y + threadIdx.y;\n  if (i < N && j < N && i!= j) {\n    if (A[i*N + j] == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i >= N || j >= N) return;\n    if (i == j) {\n        // Diagonal elements are unconnected.\n        return;\n    }\n    if (A[i * N + j] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint index = i * N + j;\n\n\tif (i < N && j < N && A[index] == 1 && A[i * N + j] == 1 && A[j * N + i] == 1) {\n\t\t// Found a new connected component\n\t\t*numComponents = *numComponents + 1;\n\t}\n}",
            "int *A_tmp = (int *) malloc(sizeof(int) * N * N);\n    memcpy(A_tmp, A, sizeof(int) * N * N);\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A_tmp[i * N + j]) {\n                A_tmp[i * N + j] = 1;\n                for (size_t k = 0; k < N; k++) {\n                    if (A_tmp[j * N + k] &&!A_tmp[i * N + k]) {\n                        A_tmp[i * N + k] = 1;\n                        A_tmp[j * N + k] = 1;\n                    }\n                }\n            }\n        }\n    }\n\n    *numComponents = 0;\n    for (size_t i = 0; i < N; i++) {\n        if (!A_tmp[i * N + i]) {\n            *numComponents++;\n        }\n    }\n\n    free(A_tmp);\n}",
            "// Get block and thread index\n    int blockId = blockIdx.x;\n    int threadId = blockIdx.y;\n\n    // Declare shared memory\n    __shared__ int componentId;\n    __shared__ bool visited[32];\n\n    if (threadId == 0) {\n        // Set all values in shared memory to false\n        for (int i = 0; i < 32; i++) {\n            visited[i] = false;\n        }\n\n        // Get the current component id\n        componentId = atomicAdd(numComponents, 1);\n    }\n\n    __syncthreads();\n\n    // Start from the current thread index\n    int j = threadId;\n\n    // Iterate over all the elements in the row\n    while (j < N) {\n        // If the adjacent element is not visited\n        if (A[blockId*N+j] &&!visited[j]) {\n            // Mark the adjacent element as visited\n            visited[j] = true;\n\n            // Iterate over all the elements in the column\n            for (int i = 0; i < N; i++) {\n                // If the adjacent element is not visited\n                if (A[i*N+j] &&!visited[i]) {\n                    // Mark the adjacent element as visited\n                    visited[i] = true;\n                }\n            }\n        }\n\n        // Go to the next element in the row\n        j += blockDim.y;\n    }\n\n    if (threadId == 0) {\n        // Mark all the visited elements as visited in the component\n        for (int i = 0; i < 32; i++) {\n            if (visited[i]) {\n                A[blockId*N+i] = componentId;\n            }\n        }\n    }\n\n    __syncthreads();\n}",
            "const int x = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int y = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (x < N && y < N) {\n\t\tif (A[x * N + y]!= 0) {\n\t\t\tint count = 1;\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (i == x) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tcount += A[x * N + i]!= 0 && A[i * N + y]!= 0;\n\t\t\t}\n\t\t\tatomicAdd(numComponents, count);\n\t\t}\n\t}\n}",
            "// Define the 2D grid and index\n\tint x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint idx = blockIdx.y * blockDim.x + blockIdx.x;\n\n\t// Define the shared memory\n\t__shared__ int row_cache[BLOCK_SIZE];\n\t__shared__ int col_cache[BLOCK_SIZE];\n\n\t// If we are in the bounds of the matrix\n\tif (x < N && y < N) {\n\t\tint row_idx = y * N + x;\n\t\tint col_idx = x * N + y;\n\n\t\t// Copy data to the shared memory\n\t\trow_cache[threadIdx.x] = A[row_idx];\n\t\tcol_cache[threadIdx.x] = A[col_idx];\n\n\t\t// Synchronize threads in this block\n\t\t__syncthreads();\n\n\t\t// Check if the cell is 1\n\t\tif (A[row_idx] == 1) {\n\t\t\t// Loop over all the elements of the column\n\t\t\tfor (int i = 0; i < BLOCK_SIZE; i++) {\n\t\t\t\t// If the cell is 1\n\t\t\t\tif (col_cache[i] == 1) {\n\t\t\t\t\t// Decrement the value\n\t\t\t\t\tatomicAdd(numComponents, -1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Loop over all the elements of the row\n\t\tfor (int i = 0; i < BLOCK_SIZE; i++) {\n\t\t\t// If the cell is 1\n\t\t\tif (row_cache[i] == 1) {\n\t\t\t\t// Decrement the value\n\t\t\t\tatomicAdd(numComponents, -1);\n\t\t\t}\n\t\t}\n\n\t}\n\n}",
            "// TODO: Implement this kernel.\n    // Use CUDA intrinsics __syncthreads() to implement a parallel reduction.\n    // numComponents should be set to the number of components.\n}",
            "int i = blockIdx.x; // row index of the thread\n\tint j = threadIdx.x; // column index of the thread\n\n\t// A[i,j] is 0 if there is no edge between i and j.\n\t// A[i,j] is 1 if there is an edge between i and j.\n\n\t// if A[i,j] is 1, then the thread i is connected to the thread j, which means that\n\t// if they belong to different components then they should be merged into the same one.\n\tif (i < N && j < N && A[i*N + j]) {\n\t\t*numComponents += 1;\n\t}\n}",
            "int tid = blockDim.x*blockIdx.x + threadIdx.x;\n  int stride = blockDim.x*gridDim.x;\n  int id;\n  for (id=tid; id<N; id+=stride) {\n    if (A[id*N+id] == 1) {\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "// TODO: Compute the connected components in A and write the number of components to numComponents.\n\t// Hint: Use a single thread to traverse the graph, maintaining a visited array to check if we have\n\t// already visited a node.\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i >= N)\n    return;\n\n  if (A[i * N + i]) {\n    int count = 1;\n    for (int j = 0; j < N; j++) {\n      if (i!= j && A[j * N + i])\n        count++;\n    }\n    atomicAdd(numComponents, count);\n  }\n}",
            "// TODO\n\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\tint j = threadIdx.y + blockIdx.y * blockDim.y;\n\n\t// We want to know the id of the component the current thread belongs to.\n\t// We will do this by using two shared memory arrays to keep track of the component ids\n\t// and the sizes of each component.\n\n\t// This array will hold the id of the component each thread belongs to.\n\textern __shared__ int componentId[];\n\n\t// This array will hold the size of each component.\n\textern __shared__ int componentSize[];\n\n\t// Initialize the componentId array so that it has a unique value for each thread.\n\tcomponentId[i] = i;\n\n\t// Each thread keeps track of how many nodes are in its component.\n\tcomponentSize[i] = 0;\n\n\t// Wait until all threads in the block have finished their initialization.\n\t__syncthreads();\n\n\t// Check if the current thread is out of bounds, if so, don't perform any operation.\n\tif (i < N && j < N) {\n\n\t\t// Check if there is an edge between nodes i and j.\n\t\tif (A[i * N + j] == 1) {\n\n\t\t\t// Check if the two nodes are in different components.\n\t\t\tif (componentId[i]!= componentId[j]) {\n\n\t\t\t\t// Merge the two components.\n\t\t\t\tint minComponentId = componentId[i];\n\t\t\t\tint maxComponentId = componentId[j];\n\n\t\t\t\tif (minComponentId > maxComponentId) {\n\t\t\t\t\tminComponentId = componentId[j];\n\t\t\t\t\tmaxComponentId = componentId[i];\n\t\t\t\t}\n\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (componentId[k] == maxComponentId) {\n\t\t\t\t\t\tcomponentId[k] = minComponentId;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Merge the component sizes.\n\t\t\t\tcomponentSize[minComponentId] += componentSize[maxComponentId];\n\t\t\t\tcomponentSize[maxComponentId] = 0;\n\t\t\t}\n\n\t\t\t// Increment the componentSize of the node.\n\t\t\tcomponentSize[componentId[i]] += 1;\n\t\t}\n\t}\n\n\t// Wait until all threads in the block have finished their operations.\n\t__syncthreads();\n\n\t// Use an atomic operation to sum the size of each component.\n\tatomicAdd(numComponents, componentSize[i]);\n}",
            "__shared__ int shared[BLOCK_SIZE][BLOCK_SIZE];\n\n    int x = blockIdx.x;\n    int y = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    int startX = tx + blockIdx.x * blockDim.x;\n    int startY = ty + blockIdx.y * blockDim.y;\n\n    int numComponents_thread = 0;\n\n    shared[ty][tx] = A[startX * N + startY];\n    __syncthreads();\n\n    for (int j = 0; j < BLOCK_SIZE; j++) {\n        if (shared[ty][tx] > 0)\n            numComponents_thread++;\n    }\n    __syncthreads();\n\n    for (int i = 1; i < BLOCK_SIZE; i *= 2) {\n        int value = 0;\n        if (tx < i && ty < i) {\n            value = shared[ty][tx];\n            value += shared[ty + i][tx];\n            shared[ty][tx] = value;\n        }\n        __syncthreads();\n    }\n    __syncthreads();\n\n    atomicAdd(numComponents, shared[0][0]);\n}",
            "int r = blockIdx.y * blockDim.y + threadIdx.y;\n  int c = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (r < N && c < N) {\n    if (A[r * N + c] == 1) {\n      int id = r;\n      int id2 = c;\n      while (A[id * N + id2] == 1) {\n        id2++;\n        if (id2 == N) {\n          id2 = 0;\n          id++;\n        }\n      }\n\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n    int n = N * N;\n\n    __shared__ int sData[256];\n    int size = blockDim.x * blockDim.y;\n    int tid = threadIdx.x + threadIdx.y * blockDim.x;\n    int start = tid * (n/size) + (tid >= (n%size)? (n%size) : 0);\n    int end = (tid + 1) * (n/size) + (tid + 1 >= (n%size)? (n%size) : 0);\n\n    if (A[i * N + j] == 1 && i!= j) {\n        int count = 0;\n        for (int k = start; k < end; k++) {\n            if (A[k/N * N + k%N] == 1 && k/N!= k%N) {\n                count++;\n            }\n        }\n        sData[tid] = count;\n        __syncthreads();\n\n        // Block reduce\n        for (int stride = blockDim.x * blockDim.y / 2; stride > 0; stride >>= 1) {\n            if (tid < stride) {\n                sData[tid] = max(sData[tid], sData[tid + stride]);\n            }\n            __syncthreads();\n        }\n\n        // Write out result\n        if (tid == 0) {\n            atomicAdd(numComponents, sData[0]);\n        }\n    }\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n\tint count = 0;\n\n\tif (i == j && A[i * N + j] == 0) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "// your code here\n}",
            "// TODO: Fill this in.\n  int row_idx = blockIdx.x;\n  int col_idx = threadIdx.x;\n  __shared__ int s_markers[BLOCK_SIZE];\n  int marker_idx = row_idx * blockDim.x + col_idx;\n\n  // Make sure we don't read out of bounds\n  if (row_idx >= N) return;\n  if (col_idx >= N) return;\n\n  // Read the value of the adjacency matrix into a register\n  int value = A[row_idx * N + col_idx];\n\n  // Initialize shared memory markers to -1\n  if (threadIdx.x < blockDim.x) {\n    s_markers[col_idx] = -1;\n  }\n  __syncthreads();\n\n  // Each thread will read an element from the adjacency matrix\n  if (value!= 0) {\n    // If an element is non-zero, check if the row or column is already marked\n    if (s_markers[row_idx] == -1 && s_markers[col_idx] == -1) {\n      // If the row and column are not marked, mark it and increment numComponents\n      atomicAdd(numComponents, 1);\n      s_markers[row_idx] = marker_idx;\n      s_markers[col_idx] = marker_idx;\n    }\n  }\n}",
            "// your code here\n}",
            "// TODO: compute number of connected components in A\n\n  __shared__ int shared[BLOCKSIZE][BLOCKSIZE];\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int bid = blockIdx.y * blockDim.y + threadIdx.y;\n  if (tid < N && bid < N) {\n    shared[threadIdx.y][threadIdx.x] = A[tid * N + bid];\n    __syncthreads();\n\n    if (shared[threadIdx.y][threadIdx.x] == 1) {\n      int count = 0;\n      for (int i = 0; i < BLOCKSIZE; ++i) {\n        if (i == threadIdx.y) {\n          for (int j = 0; j < BLOCKSIZE; ++j) {\n            if (shared[i][j] == 1) {\n              ++count;\n            }\n          }\n        }\n        __syncthreads();\n      }\n      atomicAdd(numComponents, count);\n    }\n  }\n}",
            "// TODO: Replace this line with your kernel code.\n}",
            "__shared__ int shared[BLOCK_SIZE][BLOCK_SIZE];\n\n\t// Initialize shared memory\n\tfor (int i = 0; i < BLOCK_SIZE; i++) {\n\t\tshared[threadIdx.x][i] = 0;\n\t}\n\n\t// Copy the block from A into shared memory\n\tint i, j;\n\tfor (i = 0; i < BLOCK_SIZE; i++) {\n\t\tj = threadIdx.x + blockIdx.x * BLOCK_SIZE;\n\t\tif (j < N && i < N)\n\t\t\tshared[threadIdx.x][i] = A[j * N + i];\n\t}\n\t__syncthreads();\n\n\t// Find the component containing this vertex,\n\t// by searching the row of A\n\tint component = 0;\n\tfor (i = 0; i < N; i++) {\n\t\tif (shared[threadIdx.x][i] == 1) {\n\t\t\tcomponent = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Perform a parallel breadth-first search to\n\t// find all connected components\n\tif (i < N) {\n\t\tfor (int j = 0; j < BLOCK_SIZE; j++) {\n\t\t\tif (shared[j][i] == 1) {\n\t\t\t\tint neighbor = componentCountHelper(shared, BLOCK_SIZE, component, j, i);\n\t\t\t\tif (neighbor!= component) {\n\t\t\t\t\tcomponent = neighbor;\n\t\t\t\t\tshared[j][i] = neighbor;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Write the number of components to global memory\n\t__syncthreads();\n\tif (threadIdx.x == 0)\n\t\tatomicAdd(numComponents, 1);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint *globalComponentId = new int[N];\n\n\tif (i == j)\n\t\tglobalComponentId[i] = i;\n\telse if (i < N && j < N) {\n\t\tif (A[i * N + j]) {\n\t\t\tint globalMin = min(globalComponentId[i], globalComponentId[j]);\n\t\t\tint globalMax = max(globalComponentId[i], globalComponentId[j]);\n\t\t\tglobalComponentId[globalMax] = globalMin;\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++)\n\t\tglobalComponentId[i] = globalComponentId[i];\n\n\tint unique = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (globalComponentId[i] == i)\n\t\t\tunique++;\n\t}\n\n\t*numComponents = unique;\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    if(i < N) {\n        int start = i;\n        int count = 0;\n        bool visited[N];\n        memset(visited, false, N);\n\n        while (!visited[start]) {\n            visited[start] = true;\n            count++;\n            start = findNext(start, A, N);\n        }\n        atomicAdd(numComponents, count);\n    }\n}",
            "int *marked;\n\tint *count;\n\tint tid = blockDim.x * blockIdx.y * gridDim.x\t+ blockDim.x * blockIdx.x + threadIdx.x;\n\tint threadCount;\n\n\tif (tid >= N)\n\t\treturn;\n\n\textern __shared__ int sdata[];\n\tmarked = sdata;\n\tcount = marked + N;\n\n\tif (A[tid * N + tid] == 0) {\n\t\tmarked[tid] = 0;\n\t\tatomicAdd(numComponents, 1);\n\t\treturn;\n\t}\n\n\tmarked[tid] = 1;\n\n\tthreadCount = 1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[tid * N + i] == 1 && marked[i] == 0) {\n\t\t\tatomicAdd(&threadCount, dfs(A, N, i, marked, tid));\n\t\t}\n\t}\n\tcount[tid] = threadCount;\n\tif (count[tid] > 0)\n\t\tatomicAdd(numComponents, 1);\n}",
            "// Insert your code here.\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor (int i = tid; i < N * N; i += stride) {\n\t\tif (A[i] == 1) {\n\t\t\tint r = i / N;\n\t\t\tint c = i % N;\n\n\t\t\tif (r == c) continue;\n\n\t\t\tint x = r;\n\t\t\tint y = c;\n\n\t\t\twhile (A[x * N + y] == 1) {\n\t\t\t\tint nextX = A[x * N + y] - 1;\n\t\t\t\tint nextY = A[y * N + x] - 1;\n\n\t\t\t\tif (nextX < 0 || nextX >= N || nextY < 0 || nextY >= N) break;\n\n\t\t\t\tA[x * N + y] = 0;\n\t\t\t\tA[y * N + x] = 0;\n\t\t\t\tA[nextX * N + nextY] = 0;\n\t\t\t\tA[nextY * N + nextX] = 0;\n\n\t\t\t\tx = nextX;\n\t\t\t\ty = nextY;\n\t\t\t}\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, 1);\n}",
            "__shared__ int A_shared[N*N];\n\n\t// Load the adjacency matrix into shared memory\n\tint i = threadIdx.y*blockDim.x + threadIdx.x;\n\tint j = blockIdx.y*blockDim.x + blockIdx.x;\n\tif(j < N*N) {\n\t\tA_shared[j] = A[j];\n\t}\n\n\t__syncthreads();\n\n\t// Each thread in the block handles a vertex\n\tint startVertex = i + N*blockIdx.x;\n\tif(startVertex < N && A_shared[startVertex * N + startVertex]) {\n\n\t\t// Perform a DFS on the sub-graph rooted at this vertex\n\t\tint stack[N];\n\t\tint top = 0;\n\t\tstack[top++] = startVertex;\n\t\tA_shared[startVertex * N + startVertex] = 0;\n\n\t\twhile(top) {\n\t\t\tint curr = stack[--top];\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif(A_shared[curr * N + j]) {\n\t\t\t\t\tA_shared[curr * N + j] = 0;\n\t\t\t\t\tstack[top++] = j;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t// Compute the number of components in the adjacency matrix\n\tint numComponents_shared = 0;\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A_shared[i * N + j]) {\n\t\t\t\tnumComponents_shared++;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t// Add up all the partial component counts\n\tif(threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tatomicAdd(numComponents, numComponents_shared);\n\t}\n}",
            "/*\n   * This function is called with a 1D thread grid (NxN threads).\n   * The thread with the id (0, 0) computes the number of components.\n   */\n\n  // TODO: Implement the componentCount kernel here\n\t// Set thread 0 to start\n\t__shared__ int count;\n\t__shared__ int visited[N];\n\tif(threadIdx.x == 0 && threadIdx.y == 0){\n\t\tcount = 0;\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tvisited[i] = 0;\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Each thread will count the component it is in\n\tif (A[blockIdx.x * N + threadIdx.x] == 1 && visited[threadIdx.x] == 0){\n\t\tcount++;\n\t\t// Set visited\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (A[i * N + threadIdx.x] == 1){\n\t\t\t\tvisited[i] = 1;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Broadcast the number of components to all threads\n\tif (threadIdx.x == 0 && threadIdx.y == 0){\n\t\t*numComponents = count;\n\t}\n\t__syncthreads();\n}",
            "int row = blockIdx.x;\n\tint col = blockIdx.y;\n\n\tif (row == col) {\n\t\treturn;\n\t}\n\n\tint index = row * N + col;\n\tif (A[index] == 1) {\n\t\tatomicAdd(&numComponents[0], 1);\n\t}\n\n}",
            "// Get the component ID of the current vertex.\n  int id = blockIdx.x;\n  int id_x = id / N;\n  int id_y = id % N;\n  int component = -1;\n\n  if (id_x < N && id_y < N) {\n    int tmp = A[id];\n\n    for (int i = 0; i < N; i++) {\n      if (tmp == 1) {\n        component = i;\n        break;\n      }\n\n      tmp /= 2;\n    }\n  }\n\n  atomicAdd(numComponents, component == -1? 0 : 1);\n}",
            "unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tunsigned int j = blockIdx.y * blockDim.y + threadIdx.y;\n\tunsigned int n = N * N;\n\n\tif (i < N && j < N) {\n\t\tif (i!= j && A[i * N + j] > 0) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// Declare shared memory\n  __shared__ int visited[16];\n\n  // Store the visited nodes in the shared memory\n  int index = threadIdx.x;\n  int size = N/16;\n  int row = blockIdx.x * 16;\n  if(blockIdx.x < size){\n    visited[threadIdx.x] = A[row + threadIdx.x];\n  }\n\n  // Use sync threads to synchronize all threads in the block\n  __syncthreads();\n\n  // Set the global memory index to the current thread's index in the shared memory\n  if(threadIdx.x < size){\n    A[row + threadIdx.x] = visited[threadIdx.x];\n  }\n\n  // Iterate through the shared memory\n  for(int i = 0; i < size; i++){\n    if(visited[i] == 1){\n      for(int j = 0; j < size; j++){\n        if(visited[j] == 1 && A[i*N + j] == 1){\n          visited[j] = 0;\n          A[i*N + j] = 0;\n          A[j*N + i] = 0;\n        }\n      }\n    }\n  }\n\n  // Add the visited nodes to the total number of visited nodes\n  atomicAdd(numComponents, 1);\n}",
            "const size_t tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (tid < N) {\n\t\t// set the current component as not seen\n\t\tA[tid * N + tid] = 0;\n\t}\n\n\t__syncthreads();\n\n\t// start the connected components search from the first element of A\n\tif (tid == 0) {\n\t\t*numComponents = 0;\n\t}\n\n\t// BFS for each element\n\tif (tid < N) {\n\t\tint count = 1;\n\t\tint next = tid;\n\t\twhile (next < N * N) {\n\t\t\t// check if the element is in the current component\n\t\t\tif (A[next] == 1) {\n\t\t\t\t// mark the element as seen\n\t\t\t\tA[next] = 0;\n\t\t\t\t// check its neighbors\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tint adj = i * N + next;\n\t\t\t\t\tint col = adj % N;\n\t\t\t\t\tint row = adj / N;\n\t\t\t\t\tif (A[adj] == 1) {\n\t\t\t\t\t\t// mark as seen\n\t\t\t\t\t\tA[adj] = 0;\n\t\t\t\t\t\t// add to the component\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t\t// add the neighbor to the stack\n\t\t\t\t\t\tif (i!= row) {\n\t\t\t\t\t\t\tnext = i;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tnext++;\n\t\t}\n\t\t// increment the number of components\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  int numComps = 0;\n  if (i < N) {\n    int j = 0;\n    while (j < N) {\n      if (A[j * N + i]!= 0) {\n        ++numComps;\n      }\n      ++j;\n    }\n    atomicAdd(numComponents, numComps);\n  }\n}",
            "unsigned int i = threadIdx.x + blockIdx.x * blockDim.x;\n  unsigned int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n  if (i >= N || j >= N)\n    return;\n\n  if (A[i + j * N] == 1)\n    atomicAdd(numComponents, 1);\n}",
            "__shared__ int state[CUDA_NUM_THREADS];\n\t__shared__ int nActive;\n\n\tint idx = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tint start, end;\n\tfor (int i = 0; i < N; i++) {\n\t\tstart = i * N;\n\t\tend = (i + 1) * N;\n\t\t// mark connected components\n\t\tfor (int j = start + idx; j < end; j += stride) {\n\t\t\tif (A[j] == 1) {\n\t\t\t\tstate[threadIdx.x] = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t// wait for the entire block to finish\n\t\t__syncthreads();\n\n\t\t// count unique components\n\t\tif (threadIdx.x == 0) {\n\t\t\tnActive = 0;\n\t\t\tint i;\n\t\t\tfor (i = 0; i < blockDim.x; i++) {\n\t\t\t\tif (state[i] == i) {\n\t\t\t\t\tnActive++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// write the result to memory\n\tif (threadIdx.x == 0) {\n\t\tatomicAdd(numComponents, nActive);\n\t}\n}",
            "size_t i = blockIdx.y*N + blockIdx.x;\n  size_t j = threadIdx.y*N + threadIdx.x;\n  __shared__ int visited[256][256];\n  if (i<N && j<N) {\n    // Initialize all cells in the shared memory matrix to 0.\n    if (threadIdx.y==0 && threadIdx.x==0) {\n      for (int x=0; x<N; x++) {\n        for (int y=0; y<N; y++) {\n          visited[x][y] = 0;\n        }\n      }\n    }\n    __syncthreads();\n    // If the current cell is not connected to any previous cells, do DFS on it.\n    if (A[i*N+j]==0 && visited[i][j]==0) {\n      visited[i][j] = 1;\n      int count = 1;\n      // Stack for DFS.\n      int stack[256];\n      // Push the current cell to the stack.\n      stack[0] = j;\n      int top = 0;\n      // Keep popping until the stack is empty.\n      while (top>=0) {\n        int node = stack[top];\n        top--;\n        for (int x=0; x<N; x++) {\n          // Push a connected node to the stack if it has not been visited.\n          if (A[i*N+x]==1 && visited[i][x]==0) {\n            stack[++top] = x;\n            visited[i][x] = 1;\n            count++;\n          }\n        }\n      }\n      atomicAdd(numComponents, 1);\n    }\n  }\n}",
            "__shared__ int shared[1024];\n\tint id = blockIdx.x*blockDim.x + threadIdx.x;\n\tint tid = threadIdx.x;\n\tint myComponent;\n\n\t// each thread will store 1 connected component in this\n\tint myConnectedComponent = -1;\n\tfor (int i = id; i < N*N; i += blockDim.x*gridDim.x) {\n\t\t// check the value at (i/N,i%N)\n\t\tint row = i / N;\n\t\tint col = i % N;\n\t\tif (A[i] == 1) {\n\t\t\t// set the connected component to be the row id\n\t\t\tmyConnectedComponent = row;\n\t\t\tbreak;\n\t\t}\n\t}\n\t// set myConnectedComponent to -1 if no edge exists\n\t// if no edge exists, then myConnectedComponent will not be set to a valid component id\n\tif (myConnectedComponent == -1) {\n\t\tmyConnectedComponent = -1;\n\t}\n\n\t// now that myConnectedComponent is set, merge with other threads\n\tfor (int i = 1; i < blockDim.x; i*=2) {\n\t\tif (tid % (2*i) == 0) {\n\t\t\tif (myConnectedComponent!= -1) {\n\t\t\t\tshared[tid] = myConnectedComponent;\n\t\t\t} else {\n\t\t\t\tshared[tid] = -1;\n\t\t\t}\n\t\t\t__syncthreads();\n\n\t\t\tif (shared[tid+i]!= -1) {\n\t\t\t\tmyConnectedComponent = shared[tid+i];\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\n\t// only thread 0 will write the result to global memory\n\tif (tid == 0) {\n\t\tif (myConnectedComponent!= -1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "// TODO: fill this in\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint idy = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t// If out of bounds, return\n\tif (idx >= N || idy >= N) return;\n\n\t// Mark visited by row\n\tbool visited[N];\n\tfor (int i = 0; i < N; i++) visited[i] = false;\n\n\t// BFS\n\tint queue[N];\n\tint front = 0, rear = 0;\n\tqueue[rear++] = idx;\n\tvisited[idx] = true;\n\n\twhile (front < rear) {\n\n\t\t// Dequeue\n\t\tidx = queue[front++];\n\n\t\t// Check neighbors\n\t\tif (A[idx * N + idy] &&!visited[idy]) {\n\t\t\tqueue[rear++] = idy;\n\t\t\tvisited[idy] = true;\n\t\t}\n\n\t\t// Check next neighbors\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[idy * N + i] &&!visited[i]) {\n\t\t\t\tqueue[rear++] = i;\n\t\t\t\tvisited[i] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Atomically increment number of components\n\tatomicAdd(numComponents, 1);\n}",
            "int *visited = new int[N];\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int i, j;\n    int count = 0;\n    int flag = 0;\n\n    if (id < N) {\n        // mark all vertices as unvisited\n        for (i = 0; i < N; i++)\n            visited[i] = 0;\n\n        // count the number of connected components\n        // (a connected component is a subgraph in which there is a path between all pairs of vertices)\n        for (i = 0; i < N; i++) {\n            if (visited[i] == 0 && A[id * N + i] == 1) {\n                flag = 0;\n                count++;\n\n                // perform DFS to find all vertices connected to i\n                // mark all vertices in the DFS tree as visited\n                for (j = 0; j < N; j++) {\n                    if (visited[j] == 0 && A[i * N + j] == 1) {\n                        flag = 1;\n                        DFS(A, visited, j, N);\n                    }\n                }\n\n                // if flag is not set, i is not connected to any other vertex in the graph\n                // so mark it as visited\n                if (flag == 0)\n                    visited[i] = 1;\n            }\n        }\n\n        // set the number of connected components to count\n        *numComponents = count;\n    }\n\n    // free the allocated memory\n    delete[] visited;\n}",
            "// YOUR CODE HERE\n}",
            "// Get the row and column of the thread\n  int r = blockIdx.x;\n  int c = blockIdx.y;\n\n  // If the thread is on the main diagonal, add one to numComponents\n  if (r == c) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "// Each thread computes one component\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (id >= N) {\n\t\treturn;\n\t}\n\n\tint start = id;\n\tint count = 0;\n\twhile (A[start * N + id] == 1) {\n\t\tstart = id;\n\t\tcount += 1;\n\t\tid = A[start * N + id];\n\t}\n\n\tif (count!= 0) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (threadId < N) {\n\t\tint start = threadId * N;\n\t\tint end = start + N;\n\n\t\tint count = 0;\n\t\tfor (int i = start; i < end; i++) {\n\t\t\tif (A[i] == 1) {\n\t\t\t\tcount++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\t\tatomicAdd(numComponents, count);\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid < N) {\n\t\tint i, c = 0;\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (i == tid)\n\t\t\t\tcontinue;\n\t\t\tif (A[i * N + tid] > 0)\n\t\t\t\tc++;\n\t\t}\n\t\tif (c == 0)\n\t\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int num = 0;\n    size_t index = threadIdx.x + blockIdx.x * blockDim.x;\n    if(index >= N * N) {\n        return;\n    }\n    size_t i = index % N;\n    size_t j = index / N;\n    if(i == j) {\n        return;\n    }\n    if(A[i * N + j] == 1) {\n        num++;\n    }\n    atomicAdd(numComponents, num);\n}",
            "int row = threadIdx.x + blockIdx.x * blockDim.x;\n  int col = threadIdx.y + blockIdx.y * blockDim.y;\n\n  // Each thread (i,j) computes A[i,j]\n  if (row < N && col < N) {\n    atomicAdd(numComponents, (A[row*N + col]!= 0)? 1 : 0);\n  }\n}",
            "int id = blockDim.x * blockIdx.y + threadIdx.x;\n\tint rows = N;\n\tint cols = N;\n\tif (id >= rows * cols) return;\n\tint x = id / cols;\n\tint y = id % cols;\n\tif (A[x * rows + y] == 1) {\n\t\tcomponentCountHelper(A, rows, cols, x, y, id, numComponents);\n\t}\n}",
            "/* This function uses the following algorithm to count the number of\n       connected components in a graph:\n\n       initialize:\n         numComponents = 0\n         componentCount = new int[N]\n         visited = new bool[N]\n\n       for i = 0 to N-1:\n         if not visited[i]:\n           traverse_component(i)\n\n       where\n\n       traverse_component(i):\n         visited[i] = true\n         componentCount[i] = 1\n         for j = 0 to N-1:\n           if A[i,j] and not visited[j]:\n             traverse_component(j)\n         numComponents++\n\n    */\n    int numComponents_i = 0;\n\n    int *componentCount = (int *)malloc(sizeof(int) * N);\n    bool *visited = (bool *)malloc(sizeof(bool) * N);\n\n    /* initialize componentCount and visited */\n    for (int i = 0; i < N; i++) {\n        componentCount[i] = 0;\n        visited[i] = false;\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == false) {\n            traverseComponent(A, i, N, componentCount, visited);\n            numComponents_i++;\n        }\n    }\n\n    *numComponents = numComponents_i;\n\n    /* Clean up. */\n    free(componentCount);\n    free(visited);\n}",
            "// TODO\n}",
            "int i = blockIdx.y; // row\n\tint j = blockIdx.x; // column\n\tif (i == j) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "const int x = blockIdx.x;\n    const int y = blockIdx.y;\n    if (A[x * N + y] == 1) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (A[i * N + j] == 1 && i < j) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "__shared__ int components[256];\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// initialize thread component id\n\tif (tid < N)\n\t\tcomponents[tid] = tid;\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint row = tid;\n\t\tint col = i;\n\t\tif (A[row * N + col] == 1 && row < col) {\n\t\t\t// Merge components\n\t\t\tint rowComponent = find(components, row);\n\t\t\tint colComponent = find(components, col);\n\t\t\tcomponents[rowComponent] = colComponent;\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// find the number of components in the graph\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (components[i] == i)\n\t\t\tcount++;\n\t}\n\n\t// count the number of connected components\n\tatomicAdd(numComponents, count);\n}",
            "// Find the index of this thread in the linear array\n  // Use this index to compute the row and column\n  // Then compute the neighbor\n  int idx = blockDim.x * blockIdx.x + threadIdx.x;\n  int row = idx / N;\n  int col = idx % N;\n  int neighbor = row * N + col;\n\n  __shared__ int comp[THREADS_PER_BLOCK];\n  __shared__ int isChanged[THREADS_PER_BLOCK];\n\n  // Initialize the value of the shared memory\n  comp[threadIdx.x] = 0;\n  isChanged[threadIdx.x] = 0;\n\n  __syncthreads();\n\n  if (A[neighbor]!= 0) {\n    // Set the local component to the global one\n    comp[threadIdx.x] = threadIdx.x;\n  }\n  __syncthreads();\n\n  // Merge components\n  if (A[neighbor]!= 0) {\n    int neighborComponent = comp[(col % N)];\n    comp[threadIdx.x] = neighborComponent;\n    isChanged[threadIdx.x] = 1;\n  }\n  __syncthreads();\n\n  // Merge components\n  if (isChanged[threadIdx.x] == 1) {\n    int neighborComponent = comp[(col % N)];\n    comp[threadIdx.x] = neighborComponent;\n    isChanged[threadIdx.x] = 1;\n  }\n  __syncthreads();\n\n  // Merge components\n  if (isChanged[threadIdx.x] == 1) {\n    int neighborComponent = comp[(col % N)];\n    comp[threadIdx.x] = neighborComponent;\n  }\n  __syncthreads();\n\n  // Merge components\n  if (isChanged[threadIdx.x] == 1) {\n    int neighborComponent = comp[(col % N)];\n    comp[threadIdx.x] = neighborComponent;\n  }\n  __syncthreads();\n\n  // Merge components\n  if (isChanged[threadIdx.x] == 1) {\n    int neighborComponent = comp[(col % N)];\n    comp[threadIdx.x] = neighborComponent;\n  }\n  __syncthreads();\n\n  if (threadIdx.x == 0) {\n    atomicAdd(numComponents, 1);\n  }\n}",
            "__shared__ int sdata[1024];\n    int tx = threadIdx.x;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tid = bx * blockDim.x + tx;\n    int bid = by * blockDim.y + tx;\n\n    // each thread has a work item that corresponds to a row of the adjacency matrix\n    // in shared memory, each thread is assigned a contiguous row\n    int *row = sdata + tx;\n    if (tid < N) {\n        row[tid] = A[tid * N + bid];\n    }\n\n    // barrier to sync threads in a warp\n    __syncthreads();\n\n    // now each thread does DFS\n    if (tid < N) {\n        int i, j;\n        int c = 0;\n        for (i = 0; i < N; ++i) {\n            if (row[i] == 1) {\n                for (j = i + 1; j < N; ++j) {\n                    if (row[j] == 1) {\n                        row[j] = 0;\n                        row[i] = 0;\n                        c++;\n                    }\n                }\n            }\n        }\n\n        if (c > 0) {\n            atomicAdd(numComponents, 1);\n        }\n    }\n\n    // barrier to sync threads in a warp\n    __syncthreads();\n}",
            "int *labels = new int[N];\n\n    int i = threadIdx.x;\n\n    labels[i] = i;\n\n    for (int j = 0; j < N; j++) {\n        if (A[i*N + j] == 1) {\n            labels[i] = min(labels[i], labels[j]);\n        }\n    }\n\n    // Determine the root of each component\n    int *roots = new int[N];\n    for (int i = 0; i < N; i++) {\n        int root = i;\n\n        while (labels[root]!= root) {\n            root = labels[root];\n        }\n\n        roots[i] = root;\n    }\n\n    // Determine the root of each component\n    int *num = new int[N];\n    for (int i = 0; i < N; i++) {\n        int root = roots[i];\n        num[root]++;\n    }\n\n    int *res = new int[N];\n    int sum = 0;\n    for (int i = 0; i < N; i++) {\n        res[i] = sum;\n        sum += num[i];\n    }\n\n    *numComponents = sum;\n\n    for (int i = 0; i < N; i++) {\n        labels[i] = res[labels[i]];\n    }\n\n    // Merge the components\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i*N + j] == 1) {\n                int root1 = roots[i];\n                int root2 = roots[j];\n\n                if (labels[root1]!= labels[root2]) {\n                    labels[root1] = labels[root2];\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (roots[i] == i) {\n            labels[i]++;\n        }\n    }\n\n    *numComponents = 0;\n    for (int i = 0; i < N; i++) {\n        if (labels[i] == 1) {\n            *numComponents += 1;\n        }\n    }\n\n    delete labels;\n    delete roots;\n    delete num;\n    delete res;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint *local_numComponents = (int *)malloc(sizeof(int));\n\tint *count = (int *)malloc(sizeof(int));\n\tint visited[N];\n\tfor (int k = 0; k < N; k++) {\n\t\tvisited[k] = 0;\n\t}\n\tif (i < N && j < N) {\n\t\tif (A[i * N + j] == 1) {\n\t\t\tcount[0] = 0;\n\t\t\tvisited[i] = 1;\n\t\t\tDFS(A, i, N, visited, count);\n\t\t\tatomicAdd(numComponents, count[0]);\n\t\t}\n\t}\n}",
            "// TODO: implement this function\n\n\t// A[threadIdx.x] = 10\n\tint *A_row = (int *)A;\n\tint *A_col = (int *)A + threadIdx.x * N;\n\tint num_neighbors = 0;\n\tint i, j;\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tif (tid < N && A_col[tid] == 1) {\n\t\tfor (i = 0; i < N; i++)\n\t\t\tif (i!= tid && A_row[i] == 1) {\n\t\t\t\tfor (j = 0; j < N; j++)\n\t\t\t\t\tif (j!= tid && A_col[j] == 1) {\n\t\t\t\t\t\tif (A[i * N + j] == 1)\n\t\t\t\t\t\t\tnum_neighbors++;\n\t\t\t\t\t}\n\t\t\t}\n\t\tif (num_neighbors == 0)\n\t\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int i = blockIdx.y*gridDim.x*blockDim.x+blockIdx.x*blockDim.x+threadIdx.x;\n\tif (i < N) {\n\t\tif (A[i*N + i] == 1) {\n\t\t\t//printf(\"Component found\\n\");\n\t\t\tatomicAdd(numComponents, 1);\n\t\t\t//printf(\"Components found: %d\\n\", *numComponents);\n\t\t}\n\t}\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x; // Column index\n\tint j = blockDim.y * blockIdx.y + threadIdx.y; // Row index\n\n\tif (i == 0 && j == 0) {\n\t\tint numComponents = 0;\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tfor (int l = 0; l < N; l++) {\n\t\t\t\tif (A[k * N + l] == 1) {\n\t\t\t\t\tnumComponents++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t*numComponents = numComponents;\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid >= N || tid == 0) return;\n\tint row = tid / N;\n\tint col = tid % N;\n\tif (A[tid] == 1) {\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "unsigned int x = blockIdx.x * blockDim.x + threadIdx.x;\n  unsigned int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (x == 0 && y == 0) {\n    unsigned int index = x + N * y;\n    if (A[index]!= 0)\n      atomicAdd(numComponents, 1);\n    return;\n  }\n\n  unsigned int index = x + N * y;\n\n  if (A[index] == 0)\n    return;\n\n  unsigned int index_up = (index - N) > 0? (index - N) : 0;\n  unsigned int index_left = (index - 1) > 0? (index - 1) : 0;\n  unsigned int index_right = (index + 1) < (N * N)? (index + 1) : (N * N - 1);\n  unsigned int index_down = (index + N) < (N * N)? (index + N) : (N * N - 1);\n\n  if (A[index_up]!= 0 || A[index_left]!= 0 || A[index_right]!= 0 ||\n      A[index_down]!= 0) {\n    atomicAdd(numComponents, -1);\n  }\n}",
            "// TODO: Implement this!\n\tint cid = threadIdx.x;\n\tif (cid >= N) return;\n\tif (A[cid * N + cid] == 0) return;\n\t\n\tint index = -1;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (i!= cid && A[cid * N + i] == 1 && A[i * N + cid] == 1) {\n\t\t\tindex = i;\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\tint tmp_cid = cid;\n\twhile (index >= 0) {\n\t\ttmp_cid = index;\n\t\tint next_index = -1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (i!= index && A[index * N + i] == 1 && A[i * N + index] == 1) {\n\t\t\t\tnext_index = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tindex = next_index;\n\t}\n\tatomicAdd(numComponents, 1);\n\tA[tmp_cid * N + cid] = 0;\n\tA[cid * N + tmp_cid] = 0;\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (id < N) {\n    int x = A[id*N+id];\n    int count = 1;\n    for (int i = 0; i < N; i++) {\n      if (id!= i && A[id*N+i] == 1) {\n        count++;\n      }\n    }\n\n    if (x == 1) {\n      atomicAdd(numComponents, count);\n    }\n  }\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint numComponentsCount = 0;\n\n\t// Loop through the matrix and compare each element with its neighbors.\n\t// If the element is 0 and its neighbors are all 0, then it is the root of its own component.\n\t// Increment the number of components by 1 for each component found.\n\tfor (int i = tid; i < N * N; i += blockDim.x * gridDim.x) {\n\t\tint row = i / N;\n\t\tint col = i % N;\n\t\tint isRoot = 0;\n\t\tif (A[i] == 0) {\n\t\t\tif (row > 0 && A[i - N] == 0) {\n\t\t\t\tisRoot = 0;\n\t\t\t} else if (row < N - 1 && A[i + N] == 0) {\n\t\t\t\tisRoot = 0;\n\t\t\t} else if (col > 0 && A[i - 1] == 0) {\n\t\t\t\tisRoot = 0;\n\t\t\t} else if (col < N - 1 && A[i + 1] == 0) {\n\t\t\t\tisRoot = 0;\n\t\t\t} else {\n\t\t\t\tisRoot = 1;\n\t\t\t}\n\t\t}\n\t\tif (isRoot == 1) {\n\t\t\tnumComponentsCount++;\n\t\t}\n\t}\n\t// Store the number of components in the output array.\n\tatomicAdd(numComponents, numComponentsCount);\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (row >= N || col >= N)\n        return;\n\n    if (A[row * N + col] > 0)\n        atomicAdd(numComponents, 1);\n}",
            "int myIdx = blockIdx.y*gridDim.x*blockDim.x + blockIdx.x*blockDim.x + threadIdx.x;\n\tif (myIdx >= N) return;\n\n\tint count = 0;\n\tif (A[myIdx] == 1) {\n\t\tcount = 1;\n\t\tfor (int i = myIdx+1; i < N; ++i) {\n\t\t\tif (A[i] == 1) {\n\t\t\t\tcount++;\n\t\t\t} else if (A[i]!= 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t*numComponents = count;\n}",
            "size_t thread_id = threadIdx.x + blockIdx.x * blockDim.x;\n  int count = 0;\n\n  if (A[thread_id * N + thread_id] == 1) {\n    count = 1;\n\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + thread_id] == 1) {\n        count++;\n      }\n    }\n    atomicAdd(numComponents, count);\n  }\n}",
            "// TODO:\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row >= N)\n\t\treturn;\n\n\tint col = 0;\n\n\tint componentCount = 0;\n\n\twhile (col < N) {\n\n\t\tif (A[row * N + col] == 1) {\n\t\t\tcomponentCount++;\n\t\t\tbreak;\n\t\t}\n\n\t\tcol++;\n\t}\n\n\tif (componentCount == 0)\n\t\t*numComponents = *numComponents + 1;\n\n\treturn;\n}",
            "// TODO: Your code here\n}",
            "// Each thread is a vertex\n\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif (x >= N || y >= N) return;\n\t\n\t__shared__ int cache[256];\n\tcache[threadIdx.x] = A[x + y * N];\n\t__syncthreads();\n\t\n\tint numComponentsHere = 0;\n\t\n\tif (cache[threadIdx.x]) {\n\t\tfor (int i = 0; i < 256; ++i) {\n\t\t\tif (i!= threadIdx.x && cache[i]) {\n\t\t\t\tnumComponentsHere = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numComponents, numComponentsHere);\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (x >= N || y >= N) return;\n\n\tint idx = y * N + x;\n\tif (A[idx] == 1) {\n\t\tif (x == 0 && y == 0) {\n\t\t\tnumComponents[0] = 1;\n\t\t} else if (x == 0 && y!= 0) {\n\t\t\tnumComponents[0]++;\n\t\t}\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x*blockDim.x;\n\tint tnum = blockDim.x*gridDim.x;\n\tint compCount=0;\n\n\tfor (int i = tid; i < N; i+=tnum) {\n\t\tint root = i;\n\t\tif (A[i * N + root] == 0) {\n\t\t\tcompCount++;\n\t\t\twhile (A[root * N + root] > 0) {\n\t\t\t\troot = A[root * N + root];\n\t\t\t}\n\t\t\tA[i * N + root] = 0;\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, compCount);\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\tint my_component = 0;\n\n\t// Find my_component.\n\t// For each element in my row:\n\t// \tIf it is 1 and the element in my column is not, then increment my_component by 1.\n\t// \tIf it is 1 and the element in my column is 1, then my_component = the component of the element in my column.\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[tid*N + i] == 1 && (A[tid*N + i]!= A[i*N + tid])) {\n\t\t\tif (my_component == 0) my_component = 1;\n\t\t}\n\t\tif (A[tid*N + i] == 1 && A[tid*N + i] == A[i*N + tid]) {\n\t\t\tif (my_component == 0) my_component = A[i*N + tid];\n\t\t}\n\t}\n\n\tatomicAdd(numComponents, my_component);\n}",
            "__shared__ int s_visited[256];\n\n    int componentId = 0;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i < N && j < N) {\n        int node1 = i;\n        int node2 = j;\n\n        if (A[node1*N + node2] == 1) {\n            // Find the parent of each node\n            int node1parent = find(node1, s_visited);\n            int node2parent = find(node2, s_visited);\n\n            // If both nodes are unvisited, they are in a new component\n            if (node1parent == node1 && node2parent == node2) {\n                componentId++;\n            }\n            // Merge the components\n            else {\n                s_visited[node2parent] = node1parent;\n            }\n\n            __syncthreads();\n\n            // Update number of components\n            atomicAdd(numComponents, componentId);\n        }\n    }\n}",
            "// The id of the thread.\n  int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // The number of threads in a block.\n  int blockSize = blockDim.x * blockDim.y;\n\n  // The number of blocks in the grid.\n  int gridSize = gridDim.x * gridDim.y;\n\n  // We use a shared memory of size 1 to store the number of components.\n  extern __shared__ int numComponentsShare[];\n\n  // Each thread is responsible for checking if the vertex corresponding to the thread id is\n  // reachable from the source vertex.\n  if (tid < N) {\n    int connected = 0;\n    if (A[tid * N + tid] == 1) {\n      // Checks if the vertex corresponding to the thread id is reachable from the source vertex.\n      for (int i = 0; i < N; i++) {\n        if (A[tid * N + i] == 1) {\n          connected = 1;\n          break;\n        }\n      }\n    }\n\n    // Stores the number of connected components.\n    __syncthreads();\n    atomicAdd(&numComponentsShare[0], connected);\n    __syncthreads();\n    numComponents[0] = numComponentsShare[0];\n  }\n}",
            "size_t i = threadIdx.x;\n\n\tif(i >= N) {\n\t\treturn;\n\t}\n\n\t// check if component is already known\n\tif(A[i]!= 0) {\n\t\treturn;\n\t}\n\n\t// check if component is already known\n\tif(A[i] == 0) {\n\t\tA[i] = 1;\n\t\tatomicAdd(numComponents, 1);\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(i!= j && A[j] == 1 && A[N * i + j] == 1) {\n\t\t\t\tA[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  int idy = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (idx < N && idy < N) {\n    if (A[idx + idy * N] && idx!= idy)\n      atomicAdd(numComponents, 1);\n  }\n}",
            "const size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n  const size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n  if (i < N && j < N && A[i * N + j]) {\n    if (i == j) {\n      atomicAdd(numComponents, 1);\n    }\n    else {\n      atomicAdd(numComponents, 2);\n    }\n  }\n}",
            "int row = blockDim.y * blockIdx.y + threadIdx.y;\n\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (row < N && col < N) {\n\t\tint index = row * N + col;\n\t\tif (A[index] == 1) {\n\t\t\t//int num = 0;\n\t\t\tint temp = col;\n\t\t\twhile (A[index] == 1) {\n\t\t\t\tcol = col + 1;\n\t\t\t\tindex = row * N + col;\n\t\t\t\tif (col == N) {\n\t\t\t\t\tcol = 0;\n\t\t\t\t\trow = row + 1;\n\t\t\t\t\tindex = row * N + col;\n\t\t\t\t}\n\t\t\t\tif (row == N) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tint num = (col - temp);\n\t\t\tatomicAdd(numComponents, 1);\n\t\t}\n\t}\n}",
            "size_t x = blockIdx.x * blockDim.x + threadIdx.x;\n\tsize_t y = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (x >= N || y >= N) return;\n\n\t// The set of connected vertices.\n\tint connected[N];\n\tmemset(connected, 0, N * sizeof(int));\n\tconnected[x] = 1;\n\tint numConnected = 1;\n\n\t// For every neighbor of x...\n\tfor (size_t k = 0; k < N; k++) {\n\t\tif (A[x * N + k] == 1) {\n\t\t\tconnected[k] = 1;\n\t\t\tnumConnected++;\n\t\t}\n\t}\n\n\t// If x is connected to y...\n\tif (A[x * N + y] == 1) {\n\t\t// For every vertex in y's connected set...\n\t\tfor (int i = 0; i < numConnected; i++) {\n\t\t\t// For every vertex in x's connected set...\n\t\t\tfor (int j = 0; j < numConnected; j++) {\n\t\t\t\t// Check if the vertices are connected.\n\t\t\t\tif (connected[j] == 1 && connected[i] == 1 && A[y * N + i] == 1) {\n\t\t\t\t\t// Merge their connected sets.\n\t\t\t\t\tconnected[i] = 0;\n\t\t\t\t\tconnected[j] = 0;\n\t\t\t\t\tconnected[i + numConnected] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if y is connected to any vertex in x's connected set.\n\tfor (int i = 0; i < numConnected; i++) {\n\t\tif (connected[i] == 1 && A[y * N + i] == 1) {\n\t\t\tatomicAdd(numComponents, 1);\n\t\t\treturn;\n\t\t}\n\t}\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i >= N || j >= N) return;\n\n\tif (A[i * N + j] == 1) {\n\t\tA[i * N + j] = 0;\n\t\tfor (int col = 0; col < N; ++col) {\n\t\t\tif (i!= col && A[i * N + col] == 1) {\n\t\t\t\tA[i * N + col] = 0;\n\t\t\t}\n\t\t}\n\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int cnt = 0;\n  for (int i = tid; i < N; i += gridDim.x * blockDim.x) {\n    int k = 0;\n    while (A[i * N + k]!= 0) {\n      cnt++;\n      k++;\n    }\n  }\n  atomicAdd(numComponents, cnt);\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (row < N) {\n\t\tint numComponent = 0;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tnumComponent += A[row * N + j];\n\t\t}\n\t\tatomicAdd(numComponents, numComponent);\n\t}\n}",
            "// TODO\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint totalComponents = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) continue;\n\t\t\tif (A[i * N + j] > 0) {\n\t\t\t\ttotalComponents++;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numComponents, totalComponents);\n}",
            "int numThreads = blockDim.x * gridDim.x;\n    int start = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    int cnt = 0;\n\n    for (int i = start; i < N; i += stride) {\n        bool visited[N];\n        memset(visited, false, sizeof(visited));\n\n        if (!visited[i]) {\n            int j;\n            for (j = i; j < N; j++) {\n                if (A[i * N + j]) {\n                    visited[j] = true;\n                }\n            }\n\n            cnt++;\n        }\n    }\n\n    atomicAdd(numComponents, cnt);\n}",
            "// TODO: implement\n\t__shared__ int sum[256];\n\t__shared__ int visited[256];\n\n\tint row = blockIdx.y*blockDim.y+threadIdx.y;\n\tint col = blockIdx.x*blockDim.x+threadIdx.x;\n\tint curSum=0;\n\tif(row < N && col < N) {\n\t\tif(A[row*N+col]==1)\n\t\t\tcurSum=1;\n\t\tfor(int i=0;i<blockDim.y;i++) {\n\t\t\tsum[threadIdx.y*blockDim.x+threadIdx.x] = 0;\n\t\t\tvisited[threadIdx.y*blockDim.x+threadIdx.x] = 0;\n\t\t}\n\t\t__syncthreads();\n\t\tif(col < row) {\n\t\t\tcurSum+=atomicAdd(&sum[col*blockDim.x+threadIdx.x],curSum);\n\t\t}\n\t\telse {\n\t\t\tcurSum+=atomicAdd(&sum[row*blockDim.x+threadIdx.x],curSum);\n\t\t}\n\t\tif(curSum==0 && visited[row*blockDim.x+threadIdx.x]==0) {\n\t\t\tatomicAdd(&numComponents[0],1);\n\t\t\tvisited[row*blockDim.x+threadIdx.x] = 1;\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "// TODO\n}",
            "// Get the thread's global ID\n\tint i = blockIdx.x;\n\tint j = threadIdx.x;\n\t// Make sure we don't access anything out of bounds\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\t// If this edge is not set, then it's not connected\n\tif (A[i*N+j] == 0)\n\t\treturn;\n\n\t// If this edge is set, then it's connected. But is it connected to any other nodes?\n\tint connected = 0;\n\tfor (int k = 0; k < N; ++k)\n\t{\n\t\t// Check if this edge is set.\n\t\t// If it is, then it's connected to k\n\t\tif (A[i*N+k] == 1)\n\t\t\tconnected = 1;\n\t}\n\n\t// If it's connected to anything else, then it's not an island.\n\tif (connected == 1)\n\t\treturn;\n\n\t// If it's not connected to anything else, then we're in an island.\n\t// We can just increment the number of components\n\tatomicAdd(numComponents, 1);\n\n\t// If we're in an island, then we need to remove all other edges that might be connecting to it.\n\t// Otherwise, we'll count it as an island multiple times.\n\tfor (int k = 0; k < N; ++k)\n\t\tA[i*N+k] = 0;\n}",
            "int i, j;\n\n\tint start = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor(i = start; i < N; i += stride) {\n\n\t\tif(A[i * N + i] == 0) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor(j = i + 1; j < N; j++) {\n\t\t\tif(A[i * N + j]!= 0) {\n\t\t\t\tA[j * N + i] = 0;\n\t\t\t}\n\t\t}\n\n\t\t*numComponents += 1;\n\t}\n}",
            "int col = blockIdx.x * blockDim.x + threadIdx.x;\n  int row = blockIdx.y * blockDim.y + threadIdx.y;\n  __shared__ int rowState[BLOCK_SIZE][BLOCK_SIZE];\n  __shared__ int colState[BLOCK_SIZE][BLOCK_SIZE];\n\n  if (row < N && col < N) {\n    rowState[threadIdx.y][threadIdx.x] = 0;\n    colState[threadIdx.y][threadIdx.x] = 0;\n    __syncthreads();\n\n    if (A[row * N + col] == 1) {\n      rowState[threadIdx.y][threadIdx.x] = 1;\n      __syncthreads();\n\n      if (threadIdx.y == 0) {\n        atomicAdd(numComponents, 1);\n        for (int i = 0; i < N; i++) {\n          if (colState[i][threadIdx.x] == 1) {\n            A[row * N + i] = 0;\n            A[i * N + col] = 0;\n          }\n        }\n      }\n    }\n  }\n}",
            "// TODO: implement\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\tint j = threadIdx.y + blockIdx.y * blockDim.y;\n\tif (i >= N || j >= N)\n\t\treturn;\n\tif (i == j) {\n\t\tif (A[i*N + j] == 1)\n\t\t\tatomicAdd(numComponents, 1);\n\t} else {\n\t\tif (A[i*N + j] == 1 || A[j*N + i] == 1)\n\t\t\tatomicAdd(numComponents, 1);\n\t}\n}",
            "// TODO: replace this for-loop with parallel execution on the GPU\n  *numComponents = 0;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[N*i + j] == 1) {\n        atomicAdd(numComponents, 1);\n      }\n    }\n  }\n}",
            "int threadId = blockIdx.x*blockDim.x + threadIdx.x;\n\tint nBlocks = gridDim.x;\n\t// TODO: Fill in your code here\n\n\t//if (threadId >= N) return;\n\t//int myCount = 0;\n\t//for(int i = 0; i < N; i++)\n\t//\tif (A[i*N+threadId] == 1)\n\t//\t\tmyCount++;\n\t//atomicAdd(numComponents, myCount);\n\t//myCount = 0;\n\t__shared__ int sCount;\n\t__shared__ int sVisited[1024];\n\tif (threadId < N)\n\t\tsVisited[threadId] = 0;\n\t__syncthreads();\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[threadId * N + i] == 1 && sVisited[i] == 0 && threadId!= i) {\n\t\t\tsVisited[i] = 1;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 && sVisited[j] == 0)\n\t\t\t\t\tsVisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tatomicAdd(numComponents, 1);\n}",
            "const size_t i = blockIdx.x*blockDim.x + threadIdx.x;\n  const size_t j = blockIdx.y*blockDim.y + threadIdx.y;\n  if (i >= N || j >= N) return;\n  __shared__ int adjMat[BLOCK_SIZE][BLOCK_SIZE];\n  adjMat[threadIdx.y][threadIdx.x] = A[i * N + j];\n  __syncthreads();\n  if (adjMat[threadIdx.y][threadIdx.x] == 1) {\n    for (int k = 0; k < BLOCK_SIZE; k++) {\n      if (adjMat[threadIdx.y][k] == 1 && adjMat[k][threadIdx.x] == 1) {\n        atomicAdd(numComponents, 1);\n        break;\n      }\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N && A[i * N + i] == 0) {\n        atomicAdd(numComponents, 1);\n    }\n}",
            "int row = blockIdx.x;\n  int col = blockIdx.y;\n  int threadId = threadIdx.x;\n\n  __shared__ int sdata[N_THREADS];\n  int myData = 0;\n  sdata[threadId] = 0;\n  __syncthreads();\n\n  if(row < N && col < N)\n    myData = A[row*N + col];\n  if(row == col)\n    myData = 1;\n  sdata[threadId] = myData;\n  __syncthreads();\n\n  for(int stride = N_THREADS/2; stride > 0; stride /= 2) {\n    if(threadId < stride)\n      sdata[threadId] += sdata[threadId + stride];\n    __syncthreads();\n  }\n\n  if(threadId == 0)\n    atomicAdd(numComponents, sdata[0]);\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "14_graph_count_components",
        "parallelism_model": "mpi+omp",
        "prompt": "#include <mpi.h>\n#include <omp.h>\n\n/* Count the number of connected components in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n\t Use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The component count is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]\n   output: 2\n*/\nint componentCount(std::vector<int> const& A, size_t N) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "return 0;\n}",
            "std::vector<int> visited(N, 0);\n\tint num = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tnum++;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn num;\n}",
            "int components;\n\tif (N == 0) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> count(N, 1);\n\tstd::vector<int> local_components(N, 0);\n\t\n\tMPI_Request* requests = new MPI_Request[N];\n\t\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tMPI_Irecv(&local_components[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &requests[i]);\n\t\t\tvisited[i] = 1;\n\t\t\t#pragma omp parallel for\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1 && visited[j] == 0) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcount[j] = count[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tlocal_components[i] = count[i];\n\t\t\tMPI_Isend(&local_components[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, &requests[i]);\n\t\t}\n\t}\n\n\tMPI_Waitall(N, requests, MPI_STATUSES_IGNORE);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (local_components[i] == count[i]) {\n\t\t\tcomponents++;\n\t\t}\n\t}\n\n\tdelete[] requests;\n\n\treturn components;\n}",
            "}",
            "// TODO\n\treturn 0;\n}",
            "// TODO\n\treturn -1;\n}",
            "if(N == 0) return 0;\n\tint* comp = new int[N];\n\tint n = 0;\n\t#pragma omp parallel for schedule(dynamic, 1)\n\tfor (int i = 0; i < N; i++) {\n\t\tif(comp[i] == 0) {\n\t\t\t#pragma omp critical\n\t\t\tn++;\n\t\t\tcomp[i] = 1;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif(A[i*N + j] == 1) comp[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tdelete [] comp;\n\treturn n;\n}",
            "std::vector<int> visited(N, 0);\n\n  int counter = 0;\n\n  #pragma omp parallel for num_threads(4)\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      std::queue<int> q;\n      q.push(i);\n      while (q.empty() == false) {\n        auto const current = q.front();\n        visited[current] = 1;\n        q.pop();\n        for (int j = 0; j < N; j++) {\n          if (A[i * N + j] == 1) {\n            if (visited[j] == 0) {\n              q.push(j);\n            }\n          }\n        }\n      }\n      counter++;\n    }\n  }\n\n  return counter;\n}",
            "// TODO: Implement this\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint comp = 0;\n\tstd::vector<int> v(N);\n\tstd::vector<int> s(N);\n\tint a = 0;\n\tint b = 0;\n\n\n\tif (rank == 0) {\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tv[i] = i;\n\t\t\ts[i] = 1;\n\t\t}\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tfor (int j = i+1; j < N; j++)\n\t\t\t{\n\t\t\t\tif (A[i*N+j] == 1)\n\t\t\t\t{\n\t\t\t\t\ta = i;\n\t\t\t\t\tb = j;\n\n\t\t\t\t\twhile (v[a]!= a)\n\t\t\t\t\t{\n\t\t\t\t\t\ta = v[a];\n\t\t\t\t\t}\n\n\t\t\t\t\twhile (v[b]!= b)\n\t\t\t\t\t{\n\t\t\t\t\t\tb = v[b];\n\t\t\t\t\t}\n\n\t\t\t\t\tif (a!= b)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (s[a] < s[b])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tv[a] = b;\n\t\t\t\t\t\t\ts[b] = s[a] + s[b];\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tv[b] = a;\n\t\t\t\t\t\t\ts[a] = s[a] + s[b];\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcomp++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\tint compRanks = 0;\n\n\t\tfor (int i = 1; i < size; i++)\n\t\t{\n\t\t\tMPI_Recv(&compRanks, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tcomp += compRanks;\n\t\t}\n\n\t\treturn comp;\n\n\t}\n\telse\n\t{\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tv[i] = i;\n\t\t\ts[i] = 1;\n\t\t}\n\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tfor (int j = i + 1; j < N; j++)\n\t\t\t{\n\t\t\t\tif (A[i*N + j] == 1)\n\t\t\t\t{\n\t\t\t\t\ta = i;\n\t\t\t\t\tb = j;\n\n\t\t\t\t\twhile (v[a]!= a)\n\t\t\t\t\t{\n\t\t\t\t\t\ta = v[a];\n\t\t\t\t\t}\n\n\t\t\t\t\twhile (v[b]!= b)\n\t\t\t\t\t{\n\t\t\t\t\t\tb = v[b];\n\t\t\t\t\t}\n\n\t\t\t\t\tif (a!= b)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (s[a] < s[b])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tv[a] = b;\n\t\t\t\t\t\t\ts[b] = s[a] + s[b];\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tv[b] = a;\n\t\t\t\t\t\t\ts[a] = s[a] + s[b];\n\t\t\t\t\t\t}",
            "int n_process, rank_id, componentCount, max;\n\tstd::vector<int> result_vector;\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_process);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank_id);\n\tMPI_Status status;\n\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++)\n\t\tfor(int j = 0; j < N; j++)\n\t\t{\n\t\t\tif(i!= j && A[N * i + j] == 1)\n\t\t\t\tA[N * i + j] = A[N * j + i] = 0;\n\t\t}\n\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++)\n\t\tfor(int j = 0; j < N; j++)\n\t\t{\n\t\t\tif(A[N * i + j] == 1)\n\t\t\t\tresult_vector.push_back(i);\n\t\t}\n\n\tint* result = new int[result_vector.size()];\n\n\tif(rank_id == 0)\n\t\tfor(int i = 0; i < result_vector.size(); i++)\n\t\t\tresult[i] = result_vector[i];\n\n\tif(rank_id == 0)\n\t\tfor(int i = 1; i < n_process; i++)\n\t\t{\n\t\t\tMPI_Recv(result + result_vector.size(), result_vector.size(), MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n\t\t}\n\n\tMPI_Reduce(&result_vector.size(), &componentCount, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\tif(rank_id == 0)\n\t{\n\t\tstd::vector<int> new_vector;\n\t\tfor(int i = 0; i < componentCount; i++)\n\t\t\tnew_vector.push_back(result[i]);\n\t\tfor(int i = 0; i < result_vector.size(); i++)\n\t\t\tnew_vector.push_back(result[i]);\n\n\t\tstd::sort(new_vector.begin(), new_vector.end());\n\t\tfor(int i = 0; i < new_vector.size(); i++)\n\t\t{\n\t\t\tif(new_vector[i]!= new_vector[i - 1])\n\t\t\t{\n\t\t\t\tnew_vector.erase(new_vector.begin() + i - 1);\n\t\t\t\ti--;\n\t\t\t}\n\t\t}\n\n\t\treturn new_vector.size();\n\t}\n\n\tMPI_Send(result, result_vector.size(), MPI_INT, 0, 0, MPI_COMM_WORLD);\n\treturn 0;\n}",
            "// TODO\n}",
            "// TODO: Implement\n\treturn -1;\n}",
            "int M = 1; // number of components\n  // TODO: your code here\n\n  return M;\n}",
            "std::vector<int> visited(N, 0);\n  int cnt = 0;\n\n  #pragma omp parallel for shared(A) reduction(+:cnt)\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i] == 0) {\n      // Perform a DFS starting at i\n      std::vector<int> Q{i};\n      cnt++;\n      while (Q.size() > 0) {\n        auto current = Q.back();\n        Q.pop_back();\n        for (size_t j = 0; j < N; ++j) {\n          if (A[current*N + j]!= 0 && visited[j] == 0) {\n            Q.push_back(j);\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n  }\n  return cnt;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tconst int size = A.size();\n\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> component_count(N, 0);\n\tstd::vector<int> local_count(N, 0);\n\tint count_local = 0;\n\n\t#pragma omp parallel for shared(local_count, A, N, visited, component_count, count_local)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tdfs(A, i, N, visited, component_count);\n\t\t\tcount_local++;\n\t\t}\n\t}\n\n\tstd::vector<int> global_count(1, 0);\n\tMPI_Reduce(&count_local, &global_count[0], 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tint temp_result = 0;\n\t\t\tMPI_Recv(&temp_result, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tglobal_count[0] += temp_result;\n\t\t}\n\t\treturn global_count[0];\n\t}\n\telse {\n\t\tMPI_Send(&count_local, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0;\n\t}\n}",
            "int rank;\n  int size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int *results;\n  if(rank == 0) {\n    results = new int[size];\n    for (size_t i = 0; i < size; ++i) {\n      results[i] = 0;\n    }\n  }\n\n  #pragma omp parallel for\n  for (size_t i = 0; i < A.size(); ++i) {\n    std::vector<bool> visited(N);\n    std::queue<int> queue;\n    queue.push(i);\n    visited[i] = true;\n\n    while(!queue.empty()) {\n      int current = queue.front();\n      queue.pop();\n\n      for (size_t j = 0; j < N; ++j) {\n        if (A[current * N + j] &&!visited[j]) {\n          queue.push(j);\n          visited[j] = true;\n        }\n      }\n    }\n  }\n\n  int count = 0;\n  #pragma omp parallel for reduction(+ : count)\n  for (size_t i = 0; i < A.size(); ++i) {\n    if (visited[i])\n      count++;\n  }\n\n  if (rank == 0) {\n    for (int i = 1; i < size; ++i) {\n      MPI_Recv(&results[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    }\n\n    for (int i = 0; i < size; ++i) {\n      count += results[i];\n    }\n\n    delete[] results;\n  } else {\n    MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n\n  return count;\n}",
            "std::vector<int> component_rank(N);\n  std::vector<int> local_component(N);\n\n  MPI_Request req;\n  MPI_Status status;\n\n  #pragma omp parallel\n  {\n    int rank = omp_get_thread_num();\n    int nthreads = omp_get_num_threads();\n\n    int i, j, k;\n    std::vector<int> stack;\n    std::vector<int> in_stack;\n    std::vector<int> visited;\n    std::vector<int> component_size(N);\n    int max_size = 0;\n    int component_count = 0;\n    int count;\n    bool ok;\n\n    #pragma omp for schedule(dynamic, 1)\n    for (i = 0; i < N; ++i) {\n      if (visited[i])\n        continue;\n      stack.push_back(i);\n      in_stack[i] = true;\n      visited[i] = true;\n      component_size[i] = 1;\n      while (stack.size()) {\n        j = stack.back();\n        stack.pop_back();\n        in_stack[j] = false;\n        for (k = 0; k < N; ++k) {\n          ok =!visited[k] && (A[i * N + k] || A[k * N + i]);\n          if (ok) {\n            stack.push_back(k);\n            in_stack[k] = true;\n            visited[k] = true;\n            component_size[i]++;\n          }\n        }\n      }\n      if (component_size[i] > max_size)\n        max_size = component_size[i];\n      component_count++;\n    }\n\n    for (int i = 0; i < N; i++) {\n      count = 0;\n      for (int j = 0; j < N; j++) {\n        if (A[i*N + j]) {\n          count++;\n        }\n      }\n      if (count > 0) {\n        component_rank[i] = 1;\n      }\n    }\n\n    MPI_Allreduce(&component_count, &count, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n    component_count = count;\n\n    MPI_Allreduce(&max_size, &count, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n    max_size = count;\n\n    MPI_Allreduce(component_rank.data(), local_component.data(), N, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n  }\n\n  return component_count;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  std::vector<int> localA = A;\n  // TODO: Your code goes here.\n  return -1;\n}",
            "// TODO: Implement\n    return 0;\n}",
            "// Your code goes here\n\tint size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint count = 0;\n\tint* subA = new int[N];\n\tfor (size_t i = 0; i < N; i++)\n\t\tsubA[i] = A[i * N + rank];\n\tfor (size_t i = 0; i < N; i++)\n\t\tsubA[i] += (i < rank? 0 : A[i * N + rank - 1]);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = i + 1; j < N; j++) {\n\t\t\tif (subA[i] & subA[j]) {\n\t\t\t\tsubA[i] |= subA[j];\n\t\t\t\tsubA[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tint* res = new int[size];\n\tMPI_Gather(&count, 1, MPI_INT, res, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tfor (size_t i = 0; i < size; i++)\n\t\t\tcount += res[i];\n\t}\n\n\treturn count;\n}",
            "int components = 0;\n\tomp_set_num_threads(N);\n\t#pragma omp parallel for reduction(+: components)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[N*i + j]) {\n\t\t\t\t++components;\n\t\t\t}\n\t\t}\n\t}\n\treturn components;\n}",
            "// TODO\n  int my_rank = 0, num_procs = 0;\n  int components_per_rank = 0, components_per_rank_sum = 0, my_components = 0, components_per_rank_per_thread = 0, my_components_per_thread = 0, temp_components = 0, final_components = 0;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  int num_threads = 0;\n  #pragma omp parallel\n  {\n    num_threads = omp_get_num_threads();\n  }\n  components_per_rank = 0;\n  for(int i=0; i<N; i++)\n  {\n    for(int j=0; j<N; j++)\n    {\n      if(A[i*N + j] == 1)\n      {\n        my_components++;\n      }\n    }\n  }\n  components_per_rank = my_components / num_threads;\n  MPI_Reduce(&components_per_rank, &components_per_rank_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if(my_rank == 0)\n  {\n    final_components = components_per_rank_sum;\n  }\n  if(my_rank!= 0)\n  {\n    MPI_Recv(&temp_components, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    final_components = temp_components;\n  }\n  MPI_Bcast(&final_components, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return final_components;\n}",
            "int rank, size, i, j, count = 0, *visited;\n  int pCount, *pVisited;\n  std::vector<int> v;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  v.resize(N);\n  visited = new int[N];\n  pVisited = new int[N];\n\n  if (rank == 0) {\n    for (i = 0; i < N; i++) {\n      v[i] = i;\n    }\n\n    for (i = 0; i < N; i++) {\n      visited[i] = 0;\n    }\n\n    for (i = 0; i < N; i++) {\n      for (j = i + 1; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          v[i] = j;\n          visited[j] = 1;\n          break;\n        }\n      }\n    }\n\n    for (i = 0; i < N; i++) {\n      if (visited[i] == 0) {\n        count++;\n      }\n    }\n  }\n\n  MPI_Bcast(visited, N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(v.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank > 0) {\n    for (i = 0; i < N; i++) {\n      pVisited[i] = visited[i];\n      pVisited[i] = v[i];\n    }\n\n    for (i = 0; i < N; i++) {\n      if (pVisited[i]!= 0) {\n        for (j = 0; j < N; j++) {\n          if (A[pVisited[i] * N + j] == 1) {\n            if (v[i]!= j) {\n              v[i] = j;\n            }\n            pVisited[j] = 1;\n          }\n        }\n      }\n    }\n\n    for (i = 0; i < N; i++) {\n      if (pVisited[i] == 0) {\n        count++;\n      }\n    }\n  }\n\n  MPI_Bcast(pVisited, N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(v.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank == 0) {\n    for (i = 0; i < N; i++) {\n      if (pVisited[i] == 0) {\n        count++;\n      }\n    }\n  }\n\n  MPI_Bcast(pVisited, N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(v.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (rank > 0) {\n    for (i = 0; i < N; i++) {\n      if (pVisited[i] == 0) {\n        count++;\n      }\n    }\n  }\n\n  MPI_Bcast(pVisited, N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(v.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n  MPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return count;\n}",
            "if (N == 1)\n\t\treturn 1;\n\n\t// TODO: Your code goes here.\n\tint nthreads, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nthreads);\n\n\tint *color = new int[N];\n\tint *visited = new int[N];\n\tint *count = new int[1];\n\tint *send_color = new int[N];\n\tint *recv_color = new int[N];\n\tint *send_visited = new int[N];\n\tint *recv_visited = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tcolor[i] = 0;\n\t\tvisited[i] = 0;\n\t}\n\n\tcount[0] = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\tint root = i;\n\t\t\t\twhile (visited[root]!= 0)\n\t\t\t\t\troot = color[root];\n\t\t\t\tcolor[j] = root;\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t//TODO: Use MPI_Allgather to gather all colors into recv_color.\n\t//Use MPI_Allgather to gather all visited into recv_visited.\n\tint *recv_color = new int[N];\n\tint *recv_visited = new int[N];\n\tMPI_Allgather(color, N, MPI_INT, recv_color, N, MPI_INT, MPI_COMM_WORLD);\n\tMPI_Allgather(visited, N, MPI_INT, recv_visited, N, MPI_INT, MPI_COMM_WORLD);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (recv_visited[i] == 0) {\n\t\t\tcount[0]++;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (recv_color[j] == i) {\n\t\t\t\t\trecv_visited[j] = 1;\n\t\t\t\t\trecv_color[j] = recv_color[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint root = 0;\n\tMPI_Reduce(count, &count[0], 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\n\tdelete[] send_color;\n\tdelete[] send_visited;\n\tdelete[] recv_color;\n\tdelete[] recv_visited;\n\tdelete[] color;\n\tdelete[] visited;\n\tdelete[] count;\n\n\treturn count[0];\n}",
            "//TODO: Implement the parallel component count algorithm\n  int mpi_rank, mpi_size, mpi_err;\n  MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n  MPI_Datatype my_type;\n  int type_count = 1;\n  MPI_Aint type_extent, lb;\n\n  MPI_Type_extent(MPI_INT, &type_extent);\n  MPI_Type_get_true_extent(MPI_INT, &lb, &type_extent);\n  MPI_Type_contiguous(sizeof(int), MPI_INT, &my_type);\n  MPI_Type_commit(&my_type);\n\n  int* my_copy = (int*)malloc(N*N*sizeof(int));\n  memcpy(my_copy, A.data(), N*N*sizeof(int));\n\n  int* workspace = (int*)malloc(N*N*sizeof(int));\n\n  int num_nodes_per_rank = N / mpi_size;\n  int start = mpi_rank * num_nodes_per_rank;\n  int end = start + num_nodes_per_rank;\n  int size = (mpi_rank == mpi_size - 1? N % mpi_size : num_nodes_per_rank);\n\n  MPI_Request request[2];\n\n  std::vector<int> my_components;\n\n  int component_count = 0;\n  int num_components = 0;\n\n  while (num_components < size) {\n\n    int rank = 0;\n    bool is_new_component = true;\n\n    #pragma omp parallel for\n    for (int i = start; i < end; i++) {\n      #pragma omp atomic capture\n      rank = my_components.size();\n      my_components.push_back(i);\n\n      for (int j = 0; j < N; j++) {\n        if (my_copy[i*N + j] == 1) {\n          if (i == j) continue;\n\n          #pragma omp atomic capture\n          rank = my_components.size();\n          my_components.push_back(j);\n        }\n      }\n    }\n\n    for (int i = start; i < end; i++) {\n      for (int j = 0; j < N; j++) {\n        if (my_copy[i*N + j] == 1) {\n          if (i == j) continue;\n          for (int k = 0; k < my_components.size(); k++) {\n            if (my_components[k] == i) {\n              for (int m = 0; m < my_components.size(); m++) {\n                if (my_components[m] == j) {\n                  my_copy[i*N + j] = 0;\n                  my_copy[j*N + i] = 0;\n                  is_new_component = false;\n                  break;\n                }\n              }\n              break;\n            }\n          }\n        }\n      }\n    }\n\n    if (is_new_component) {\n      component_count++;\n    }\n\n    MPI_Request send_req;\n    MPI_Request recv_req;\n\n    for (int i = 1; i < mpi_size; i++) {\n      int num_reqs = 0;\n      if (i - 1 >= 0 && i - 1 < mpi_size) {\n        MPI_Irecv(my_copy + (N / mpi_size) * (i - 1), N / mpi_size, my_type, i - 1, 0, MPI_COMM_WORLD, &recv_req);\n        num_reqs++;\n      }\n      if (i + 1 >= 0 && i + 1 < mpi_size) {\n        MPI_Isend(my_copy + (N / mpi_size) * i, N / mpi_size, my_type, i + 1, 0, MPI_COMM_WORLD,",
            "int components;\n\tint rank;\n\tint size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint* row_sizes = (int*)calloc(size, sizeof(int));\n\tint* displs = (int*)calloc(size, sizeof(int));\n\tif (rank == 0)\n\t{\n\t\tfor (int i = 1; i < size; i++)\n\t\t{\n\t\t\trow_sizes[i] = A.size() / size;\n\t\t\tdispls[i] = displs[i - 1] + row_sizes[i - 1];\n\t\t}\n\t\trow_sizes[0] = displs[size - 1] + row_sizes[size - 1];\n\t}\n\n\tMPI_Bcast(row_sizes, size, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(displs, size, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tstd::vector<int> sub_A(row_sizes[rank]);\n\tint start = 0;\n\tint end = row_sizes[rank];\n\tif (rank > 0)\n\t\tstart = displs[rank - 1];\n\tif (rank < size - 1)\n\t\tend = displs[rank];\n\n\tstd::copy(A.begin() + start, A.begin() + end, sub_A.begin());\n\n\tbool* marked = (bool*)calloc(N, sizeof(bool));\n\tint* components_per_thread = (int*)calloc(omp_get_max_threads(), sizeof(int));\n\tcomponents = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (!marked[i])\n\t\t{\n\t\t\tint count = 0;\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif (A[i * N + j])\n\t\t\t\t\tcount++;\n\t\t\t}\n\t\t\tcomponents_per_thread[omp_get_thread_num()] += 1;\n\t\t}\n\t}\n\tfor (int i = 0; i < size; i++)\n\t{\n\t\tMPI_Reduce(&components_per_thread[0], &components, 1, MPI_INT, MPI_SUM, i, MPI_COMM_WORLD);\n\t}\n\n\tfree(row_sizes);\n\tfree(displs);\n\tfree(marked);\n\tfree(components_per_thread);\n\n\treturn components;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  auto N_per_rank = (N / size) + 1;\n  auto remainder = N % size;\n\n  auto A_rank = std::vector<int>(N_per_rank*N_per_rank);\n\n  MPI_Scatter(A.data(), N_per_rank*N_per_rank, MPI_INT, A_rank.data(), N_per_rank*N_per_rank, MPI_INT, 0, MPI_COMM_WORLD);\n\n  std::vector<int> components;\n\n  for (int i = 0; i < N_per_rank; i++) {\n    if (A_rank[i*N_per_rank + i] == 0) {\n      components.push_back(i);\n    }\n  }\n\n  std::vector<int> visited(N_per_rank);\n  std::vector<int> visited_row(N_per_rank);\n  int count = 0;\n\n  for (int i = 0; i < components.size(); i++) {\n    for (int j = 0; j < N_per_rank; j++) {\n      if (A_rank[i*N_per_rank + j] == 0 && visited_row[j] == 0) {\n        visited[i] = 1;\n        visited_row[j] = 1;\n        count++;\n        for (int k = 0; k < N_per_rank; k++) {\n          if (A_rank[i*N_per_rank + k] == 0 && visited[k] == 0) {\n            A_rank[i*N_per_rank + k] = 1;\n            A_rank[k*N_per_rank + j] = 1;\n          }\n        }\n      }\n    }\n  }\n\n  if (remainder > rank) {\n    for (int i = (size + 1)*N_per_rank; i < N; i++) {\n      if (A[i*N + i] == 0 && visited[i] == 0) {\n        count++;\n        for (int j = i; j < N; j++) {\n          if (A[i*N + j] == 0 && visited[j] == 0) {\n            A[i*N + j] = 1;\n            A[j*N + i] = 1;\n          }\n        }\n      }\n    }\n  }\n\n  std::vector<int> counts(size, 0);\n  counts[rank] = count;\n  MPI_Gather(MPI_IN_PLACE, 1, MPI_INT, counts.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int sum = 0;\n\n  for (int i = 0; i < size; i++) {\n    sum += counts[i];\n  }\n\n  return sum;\n}",
            "MPI_Comm comm = MPI_COMM_WORLD;\n\tint p, rank;\n\tMPI_Comm_size(comm, &p);\n\tMPI_Comm_rank(comm, &rank);\n\tstd::vector<int> A_p(A.size());\n\tMPI_Bcast(&A_p[0], A.size(), MPI_INT, 0, comm);\n\n\tomp_set_num_threads(4);\n\tint count = 0;\n\tstd::vector<int> visited(N, 0);\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\t// Find the next connected component\n\t\t\tint component = 0;\n\t\t\tstd::stack<int> s;\n\t\t\ts.push(i);\n\t\t\twhile (not s.empty()) {\n\t\t\t\tint cur = s.top();\n\t\t\t\ts.pop();\n\t\t\t\tif (visited[cur] == 0) {\n\t\t\t\t\tvisited[cur] = component;\n\t\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t\tif (A_p[cur * N + j] == 1 && visited[j] == 0)\n\t\t\t\t\t\t\ts.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t++count;\n\t\t}\n\t}\n\tint count_p = 0;\n#pragma omp parallel reduction(+:count_p)\n\t{\n\t\tint count_private = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\t++count_private;\n\t\t\t}\n\t\t}\n\t\tcount_p += count_private;\n\t}\n\tint count_s = 0;\n\tMPI_Reduce(&count_p, &count_s, 1, MPI_INT, MPI_SUM, 0, comm);\n\tif (rank == 0)\n\t\tcount = count_s;\n\n\treturn count;\n}",
            "// TODO: Fill this in!\n  return 0;\n}",
            "int my_rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  std::vector<int> visited(N,0);\n  std::vector<int> visited_count(N,0);\n  int comp_count=0;\n  for(size_t i=0; i<N; i++) {\n    if(A[i*N+i]==1 && visited[i]==0) {\n      comp_count++;\n      visited[i]=1;\n      #pragma omp parallel for\n      for(size_t j=0; j<N; j++) {\n        if(A[i*N+j]==1) {\n          #pragma omp critical\n          {\n            if(visited[j]==0) {\n              visited[j]=1;\n              visited_count[i]++;\n            }\n          }\n        }\n      }\n    }\n  }\n  return comp_count;\n}",
            "if (A.size()!= N * N) {\n    throw \"Error: A is not an N x N matrix\";\n  }\n  std::vector<int> visited(N, 0);\n  int c = 0;\n  // Loop through all elements of the matrix.\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        // Check if the element was already visited.\n        if (!visited[i] &&!visited[j]) {\n          // This is the beginning of a new component.\n          ++c;\n          // Mark both nodes as visited to avoid double counting.\n          visited[i] = 1;\n          visited[j] = 1;\n          // Breadth first search on the new component.\n          std::queue<int> q;\n          q.push(i);\n          q.push(j);\n          while (!q.empty()) {\n            auto n = q.front();\n            q.pop();\n            // Check all the neighbours.\n            for (size_t k = 0; k < N; ++k) {\n              if (A[n * N + k] == 1 &&!visited[k]) {\n                q.push(k);\n                visited[k] = 1;\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  return c;\n}",
            "int num_threads, rank, size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Status status;\n    int num_comps = 0;\n    int row_per_process = N / size;\n    int last_row_rank = N % size;\n    int start_row = rank * row_per_process;\n    int end_row = start_row + row_per_process;\n    std::vector<int> visited(N, 0);\n    omp_set_num_threads(omp_get_max_threads());\n    #pragma omp parallel\n    {\n        num_threads = omp_get_num_threads();\n    }\n    if (rank < last_row_rank) {\n        end_row += 1;\n    } else if (rank == last_row_rank) {\n        start_row += rank;\n        end_row = start_row + row_per_process;\n    }\n    for (int i = 0; i < N; i++) {\n        if (visited[i] == 0) {\n            int curr_vertex = i;\n            int counter = 0;\n            while (visited[curr_vertex] == 0) {\n                #pragma omp parallel for\n                for (int j = start_row; j < end_row; j++) {\n                    if (A[curr_vertex * N + j] == 1 && visited[j] == 0) {\n                        curr_vertex = j;\n                        break;\n                    }\n                }\n                visited[curr_vertex] = 1;\n                counter++;\n            }\n            num_comps++;\n        }\n    }\n    int result = 0;\n    if (rank == 0) {\n        result = num_comps;\n    } else {\n        MPI_Send(&num_comps, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    }\n    if (rank!= 0) {\n        MPI_Recv(&result, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    }\n    return result;\n}",
            "}",
            "int* visited = new int[N];\n\tint* local_visited = new int[N];\n\tmemset(visited, 0, sizeof(int) * N);\n\tmemset(local_visited, 0, sizeof(int) * N);\n\n\tint rank = 0;\n\tint size = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint count = 0;\n\tint local_count = 0;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i)\n\t\tif (visited[i] == 0) {\n\t\t\tlocal_count++;\n\t\t\tlocal_visited[i] = 1;\n\t\t\tqueue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile (q.size()) {\n\t\t\t\tint p = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int j = 0; j < N; ++j)\n\t\t\t\t\tif (A[N*p + j] &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tMPI_Reduce(&local_count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0)\n\t\tfor (int i = 0; i < N; ++i)\n\t\t\tif (local_visited[i] == 1)\n\t\t\t\tvisited[i] = 1;\n\n\tMPI_Bcast(visited, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor (int i = 0; i < N; ++i)\n\t\tif (visited[i] == 0)\n\t\t\tcount++;\n\n\treturn count;\n}",
            "int count = 0;\n  int isVisited[N];\n\n  for (int i = 0; i < N; i++) {\n    isVisited[i] = 0;\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (isVisited[i] == 0) {\n      count++;\n\n      dfs(A, i, isVisited, N);\n    }\n  }\n\n  return count;\n}",
            "int r;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &r);\n\tint p;\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tauto componentCount = 0;\n\n\tif (N == 0) return componentCount;\n\t\n\tif (r == 0) {\n\t\tcomponentCount = 1;\n\t} else {\n\t\tcomponentCount = 0;\n\t}\n\t\n\tif (r == 0) {\n\t\tstd::vector<int> vis(N, 0);\n\t\tstd::vector<int> buffer(N, 0);\n\t\tstd::vector<int> buffer2(N, 0);\n\t\tstd::vector<int> buffer3(N, 0);\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (vis[i] == 0) {\n\t\t\t\tint temp = 0;\n\t\t\t\tbuffer[temp] = i;\n\t\t\t\ttemp++;\n\t\t\t\twhile (temp!= 0) {\n\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[buffer[temp-1]*N+j]!= 0) {\n\t\t\t\t\t\t\tif (vis[j] == 0) {\n\t\t\t\t\t\t\t\tbuffer[temp] = j;\n\t\t\t\t\t\t\t\tvis[j] = 1;\n\t\t\t\t\t\t\t\ttemp++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttemp--;\n\t\t\t\t}\n\t\t\t\tcomponentCount++;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (p == 1) {\n\t\tMPI_Send(&componentCount, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tint recv;\n\t\tMPI_Recv(&recv, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\treturn recv;\n\t}\n\n\treturn 0;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> componentCount(N, 0);\n\n  int count = 0;\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i] == true) {\n      continue;\n    }\n\n    count++;\n    std::queue<int> q;\n    q.push(i);\n    while (!q.empty()) {\n      int n = q.front();\n      q.pop();\n\n      if (visited[n] == true) {\n        continue;\n      }\n\n      componentCount[n] = count;\n      visited[n] = true;\n      for (size_t j = 0; j < N; ++j) {\n        if (A[n * N + j] == 1) {\n          q.push(j);\n        }\n      }\n    }\n  }\n\n  // Now we must merge the component counts on each rank.\n  // Every rank has its own set of component counts.\n  // We need to merge them into one set of counts.\n  int* counts = new int[N];\n  MPI_Gather(componentCount.data(), N, MPI_INT, counts, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (MPI_Rank == 0) {\n    for (size_t i = 0; i < N; ++i) {\n      componentCount[i] = counts[i];\n    }\n  }\n\n  // Now we must return the component counts on rank 0.\n  int* componentCounts = new int[N];\n  MPI_Gather(componentCount.data(), N, MPI_INT, componentCounts, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int finalCount = 0;\n  if (MPI_Rank == 0) {\n    // Count the unique component counts.\n    std::unordered_map<int, int> countMap;\n    for (size_t i = 0; i < N; ++i) {\n      if (countMap.find(componentCounts[i]) == countMap.end()) {\n        countMap[componentCounts[i]] = 1;\n      } else {\n        countMap[componentCounts[i]]++;\n      }\n    }\n    finalCount = countMap.size();\n  }\n\n  MPI_Bcast(&finalCount, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return finalCount;\n}",
            "int num_of_components = 0;\n    int visited[N];\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    // int my_block_size = N/size;\n    int my_block_size = N/size;\n    int my_start_index = rank*my_block_size;\n    int my_end_index = my_start_index + my_block_size;\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n    int count = 0;\n    for (int i = 0; i < my_block_size; i++) {\n        for (int j = 0; j < my_block_size; j++) {\n            if (A[my_start_index*N + my_start_index + j]!= 0 && visited[my_start_index+j]!= 1) {\n                count = 1;\n                #pragma omp parallel for\n                for (int k = 0; k < my_block_size; k++) {\n                    if (A[my_start_index*N + my_start_index + j]!= 0 && A[my_start_index*N + my_start_index + k]!= 0 && visited[my_start_index+k]!= 1) {\n                        visited[my_start_index+k] = 1;\n                    }\n                }\n                break;\n            }\n        }\n    }\n    MPI_Reduce(&count, &num_of_components, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return num_of_components;\n}",
            "int p = omp_get_num_threads();\n  int r = omp_get_thread_num();\n  int rp = omp_get_num_procs();\n  int count = 0;\n  for (int i = r; i < N; i += p) {\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        for (int k = 0; k < N; ++k) {\n          if (A[k * N + j] == 1) {\n            A[k * N + i] = 1;\n          }\n        }\n      }\n    }\n    for (int j = 0; j < N; ++j) {\n      if (A[i * N + j] == 1) {\n        ++count;\n        for (int k = 0; k < N; ++k) {\n          if (A[k * N + j] == 1) {\n            A[i * N + k] = 0;\n          }\n        }\n      }\n    }\n  }\n  std::vector<int> count_vector(rp, count);\n  MPI_Gather(&count, 1, MPI_INT, count_vector.data(), 1, MPI_INT, 0, MPI_COMM_WORLD);\n  count = std::accumulate(count_vector.begin(), count_vector.end(), 0);\n  return count;\n}",
            "// TODO:\n  //   This is a very easy problem if you're familiar with the standard\n  //   graph algorithms. You can use DFS for this.\n  return 0;\n}",
            "std::vector<int> visited(N, 0);\n  int num_components = 0;\n\n  // TODO\n\n  return num_components;\n}",
            "// TODO\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<int> comp(N, 0);\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tDFS(i, A, visited, comp, count);\n\t\t}\n\t}\n\treturn count;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// TODO: Implement this function\n\n\treturn -1;\n}",
            "int num_components = 0;\n\tint* flag = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tflag[i] = 0;\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (flag[i] == 0) {\n\t\t\tfor (int j = i + 1; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1 && flag[j] == 0) {\n\t\t\t\t\tflag[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tnum_components++;\n\t\t}\n\t}\n\tdelete[] flag;\n\treturn num_components;\n}",
            "int rank;\n\tint size;\n\n\t//Get the size and rank\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint components = 0;\n\tstd::vector<bool> marked(N, false);\n\n\t//Loop through the array in reverse order\n\tfor (int i = N - 1; i >= 0; i--){\n\n\t\t//If already marked skip\n\t\tif (marked[i] == true)\n\t\t\tcontinue;\n\n\t\t//Start counting component\n\t\tcomponents++;\n\n\t\t//Mark the component\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (A[i * N + j] == 1 &&!marked[j]){\n\n\t\t\t\t//Set marker\n\t\t\t\tmarked[j] = true;\n\n\t\t\t\t//Send index to other ranks to continue on\n\t\t\t\tint index = j;\n\t\t\t\tMPI_Send(&index, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n\t\t\t}\n\t\t}\n\t}\n\n\t//If rank 0 do nothing, send components to rank 0 otherwise\n\tif (rank == 0) {\n\t\treturn components;\n\t}\n\telse {\n\t\tint temp;\n\t\tMPI_Recv(&temp, 1, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t}\n\n\treturn components;\n}",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (A[i*N + i] == 0) {\n\t\t\t++result;\n\t\t}\n\t}\n\treturn result;\n}",
            "const int nranks = MPI_SIZE;\n\tconst int rank = MPI_RANK;\n\t// Use this for fast parallel for loops.\n\t// The loop variable is private to each thread.\n\t//const int nthreads = omp_get_max_threads();\n\n\t// Count the components by row.\n\t// A component is connected if it shares an edge with another component.\n\tstd::vector<bool> used(N);\n\tstd::vector<int> componentCounts(N, 1);\n\tstd::vector<int> myComponentCounts(N, 1);\n\tif (rank == 0) {\n\t\t#pragma omp parallel for\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[N * i + j] &&!used[j]) {\n\t\t\t\t\tmyComponentCounts[i] += myComponentCounts[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sum the component counts across all ranks.\n\t// Send the component counts to rank 0.\n\t// Rank 0 will collect the counts and sum them up.\n\tMPI_Bcast(myComponentCounts.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\tstd::vector<int> allComponentCounts(N, 0);\n\tMPI_Reduce(myComponentCounts.data(), allComponentCounts.data(), N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// Return the sum of the component counts.\n\tint sum = 0;\n\tif (rank == 0) {\n\t\tfor (auto c : allComponentCounts) {\n\t\t\tsum += c;\n\t\t}\n\t}\n\tMPI_Bcast(&sum, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\treturn sum;\n}",
            "// TODO: insert code here\n\tint componentCount = 0;\n\tint rank = 0;\n\tint size = 0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Status status;\n\tint const n = N;\n\tint const nlocal = n/size;\n\tint const nlocalmod = n%size;\n\tint const nstart = nlocal * rank;\n\tint const nend = nstart + nlocal + ((rank < nlocalmod)? 1:0);\n\n\t//std::cout << \"Rank \" << rank << \":\" << nstart << \" \" << nend << std::endl;\n\n\tint* B = new int[nlocal];\n\n\tstd::memcpy(B, &A[nstart], nlocal*sizeof(int));\n\n\tif(rank < nlocalmod)\n\t{\n\t\tfor(int i = 0; i < nlocal; i++)\n\t\t\tB[i] = B[i] | A[nend-1];\n\t}\n\n\tint* C = new int[nlocal];\n\tint* D = new int[nlocal];\n\n#pragma omp parallel for\n\tfor(int i = 0; i < nlocal; i++)\n\t\tC[i] = B[i];\n\n\tbool changed = true;\n\tint count = 0;\n\twhile(changed)\n\t{\n\t\tchanged = false;\n\t\t#pragma omp parallel for\n\t\tfor(int i = 0; i < nlocal; i++)\n\t\t{\n\t\t\tif(B[i] == C[i])\n\t\t\t{\n\t\t\t\tD[i] = 0;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tint tmp = C[i];\n\t\t\tfor(int j = 0; j < nlocal; j++)\n\t\t\t{\n\t\t\t\tif(tmp & 1)\n\t\t\t\t{\n\t\t\t\t\ttmp = tmp >> 1;\n\t\t\t\t\ttmp = tmp | C[j];\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\ttmp = tmp >> 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tD[i] = tmp;\n\t\t}\n\t\t#pragma omp parallel for\n\t\tfor(int i = 0; i < nlocal; i++)\n\t\t\tif(B[i]!= D[i])\n\t\t\t{\n\t\t\t\tB[i] = D[i];\n\t\t\t\tchanged = true;\n\t\t\t\tcount++;\n\t\t\t}\n\t}\n\n\tint* componentCounts = new int[size];\n\tstd::memcpy(&componentCounts[0], &count, sizeof(int));\n\n\tMPI_Gather(&count, 1, MPI_INT, componentCounts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tif(rank == 0)\n\t{\n\t\tfor(int i = 0; i < size; i++)\n\t\t\tcomponentCount += componentCounts[i];\n\t}\n\n\tdelete [] B;\n\tdelete [] C;\n\tdelete [] D;\n\n\tif(rank == 0)\n\t\tdelete [] componentCounts;\n\n\treturn componentCount;\n}",
            "int numComponents = 0;\n\tstd::vector<bool> visited(N, false);\n\t\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\t++numComponents;\n\t\t\tstd::vector<size_t> stack = {i};\n\t\t\t\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tsize_t j = stack.back();\n\t\t\t\tstack.pop_back();\n\t\t\t\tvisited[j] = true;\n\t\t\t\t\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (!visited[k] && A[N * j + k]) {\n\t\t\t\t\t\tstack.push_back(k);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn numComponents;\n}",
            "int nprocs;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint components = 0;\n\n\tstd::vector<int> visited(N, 0);\n\tfor (size_t i = rank; i < N; i += nprocs) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (!visited[j] && A[N * i + j] == 1) {\n\t\t\t\tvisited[j] = 1;\n\t\t\t\t#pragma omp parallel for\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (A[N * j + k] == 1) {\n\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcomponents++;\n\t\t\t}\n\t\t}\n\t}\n\n\tint comps_gathered;\n\tMPI_Reduce(&components, &comps_gathered, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\tcomponents = comps_gathered;\n\t}\n\treturn components;\n}",
            "int numRanks, rank, totalComponents;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\ttotalComponents = 0;\n\tif (rank == 0) {\n\t\t// do the work\n\t}\n\tMPI_Reduce(&totalComponents, &totalComponents, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn totalComponents;\n}",
            "int nProcs, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nProcs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> count(N, 0);\n\tstd::vector<int> A_rank(N, 0);\n\n\tif (rank == 0) {\n\t\t// get A\n\t\tfor (size_t i = 0; i < N; i++)\n\t\t\tfor (size_t j = 0; j < N; j++)\n\t\t\t\tA_rank[i] += A[i*N + j];\n\t\tMPI_Scatter(A_rank.data(), N, MPI_INT, count.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tMPI_Scatter(NULL, 0, MPI_INT, count.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\t}\n\n\tint num_comps = 0;\n\tint* count_arr = count.data();\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (count_arr[i] == 0) {\n\t\t\tcount_arr[i] = 1;\n\t\t\tnum_comps += 1;\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tif (A[i*N + j] && count_arr[j] == 0)\n\t\t\t\t\tcount_arr[j] = 1;\n\t\t}\n\t}\n\n\tint num_comps_total = 0;\n\tMPI_Reduce(&num_comps, &num_comps_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn num_comps_total;\n}",
            "if (N==0) {\n\t\treturn 0;\n\t}\n\t\n\t// Create a copy of the adjacency matrix to use in DFS\n\tstd::vector<int> visited(N*N, 0);\n\t\n\t// Count the number of connected components\n\tint nComponents = 0;\n\t#pragma omp parallel for reduction(+:nComponents)\n\tfor (size_t i=0; i<N; ++i) {\n\t\tif (visited[i*N+i] == 0) {\n\t\t\tDFS(A, i, i, visited, N);\n\t\t\t++nComponents;\n\t\t}\n\t}\n\t\n\treturn nComponents;\n}",
            "int count = 0;\n  // Your code here.\n  return count;\n}",
            "}",
            "// TODO: Your code here\n\n\tstd::vector<int> visited;\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited.push_back(0);\n\t}\n\t\n\tstd::vector<int> component_size;\n\tfor (int i = 0; i < N; i++) {\n\t\tcomponent_size.push_back(0);\n\t}\n\t\n\tint rank = 0;\n\tint num_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_rank);\n\tint rank_id = rank / 2;\n\tint rank_id_next = rank / 2 + 1;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i]!= 1 && A[i * N + i] == 1) {\n\t\t\tvisited[i] = 1;\n\t\t\tint j = 0;\n\t\t\twhile (j < N) {\n\t\t\t\tif (A[i * N + j] == 1 && visited[j]!= 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tcomponent_size[rank_id] += 1;\n\t\t\t\t\tj = 0;\n\t\t\t\t} else {\n\t\t\t\t\tj += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint local_sum = 0;\n\tfor (int i = 0; i < component_size.size(); i++) {\n\t\tlocal_sum += component_size[i];\n\t}\n\n\tint global_sum = 0;\n\tMPI_Reduce(&local_sum, &global_sum, 1, MPI_INT, MPI_SUM, rank_id_next, MPI_COMM_WORLD);\n\n\treturn global_sum;\n}",
            "int number_of_components = 0;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tstd::vector<int> visited(N,0);\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; ++i) {\n\t\tif(A[i*N + i] &&!visited[i]) {\n\t\t\tvisited[i] = 1;\n\t\t\tfor(int j = i+1; j < N; ++j) {\n\t\t\t\tif(A[i*N + j] &&!visited[j]) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tnumber_of_components += 1;\n\t\t}\n\t}\n\tint result;\n\tMPI_Reduce(&number_of_components, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn result;\n}",
            "int rank = 0, size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tconst int M = static_cast<int>(N), N = static_cast<int>(N);\n\tint localN = N / size;\n\tint localM = (rank == 0)? M - N % size : localN;\n\tint start = (rank == 0)? 0 : (rank - 1) * localN;\n\tint end = (rank == size - 1)? M : rank * localN;\n\tstd::vector<int> localA(localM * localN);\n\tfor (int i = start; i < end; ++i) {\n\t\tfor (int j = 0; j < localN; ++j) {\n\t\t\tlocalA[i * localN + j] = A[i * N + j];\n\t\t}\n\t}\n\n\tint count = 0;\n\tstd::vector<std::vector<int>> DFS(localN, std::vector<int>(localN));\n\tfor (int i = 0; i < localN; ++i) {\n\t\tfor (int j = 0; j < localN; ++j) {\n\t\t\tDFS[i][j] = (localA[i * localN + j] == 1)? 1 : -1;\n\t\t}\n\t}\n\n\tstd::vector<std::vector<int>> MPI_DFS(localN, std::vector<int>(localN));\n#pragma omp parallel for schedule(dynamic, 1)\n\tfor (int i = 0; i < localN; ++i) {\n\t\tfor (int j = 0; j < localN; ++j) {\n\t\t\tif (DFS[i][j] == 1) {\n\t\t\t\tDFS[i][j] = 0;\n\t\t\t\tstd::queue<std::pair<int, int>> Q;\n\t\t\t\tQ.push(std::make_pair(i, j));\n\t\t\t\twhile (!Q.empty()) {\n\t\t\t\t\tauto uv = Q.front();\n\t\t\t\t\tQ.pop();\n\t\t\t\t\tint u = uv.first, v = uv.second;\n\t\t\t\t\tfor (int k = 0; k < localN; ++k) {\n\t\t\t\t\t\tif (DFS[u][k] == 1) {\n\t\t\t\t\t\t\tDFS[u][k] = 0;\n\t\t\t\t\t\t\tQ.push(std::make_pair(u, k));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfor (int k = 0; k < localN; ++k) {\n\t\t\t\t\t\tif (DFS[k][v] == 1) {\n\t\t\t\t\t\t\tDFS[k][v] = 0;\n\t\t\t\t\t\t\tQ.push(std::make_pair(k, v));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t++count;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int i = 0; i < localN; ++i) {\n\t\tfor (int j = 0; j < localN; ++j) {\n\t\t\tMPI_DFS[i][j] = (DFS[i][j] == -1)? 1 : -1;\n\t\t}\n\t}\n\n\tint MPI_count = 0;\n\tstd::vector<int> MPI_localA(localM * localN);\n\tfor (int i = 0; i < localN; ++i) {\n\t\tfor (int j = 0; j < localN; ++j) {\n\t\t\tMPI_localA[i * localN + j] = MPI_DFS[i][j];\n\t\t}\n\t}\n\tMPI_Reduce(&count, &MPI_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WOR",
            "int count=0;\n    bool visited[N][N];\n    for(int i=0;i<N;i++)\n    {\n        for(int j=0;j<N;j++)\n        {\n            visited[i][j]=false;\n        }\n    }\n    for(int i=0;i<N;i++)\n    {\n        if(visited[i][i]==false)\n        {\n            count++;\n            dfs(A,visited,i,i,N);\n        }\n    }\n    return count;\n}",
            "return 0;\n}",
            "int rank = 0, size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    const size_t s = N / size; // size of chunks\n    const size_t r = N % size; // number of elements in the remainder\n\n    std::vector<int> lA(s);\n    std::vector<int> rA(r);\n    std::vector<int> c(N);\n\n    // Copy the proper part of the matrix into a local vector.\n    // 0 <= rank*s <= rank*s + r < N\n    if (rank < r) {\n        lA.resize(s + 1);\n        std::copy(A.begin() + rank * (s + 1), A.begin() + rank * (s + 1) + s + 1, lA.begin());\n    } else {\n        lA.resize(s);\n        std::copy(A.begin() + rank * s, A.begin() + rank * s + s, lA.begin());\n    }\n\n    // Combine the vectors.\n    if (rank < r) {\n        std::copy(A.begin() + r * s, A.begin() + r * s + r, rA.begin());\n        lA.insert(lA.end(), rA.begin(), rA.end());\n    }\n\n    // Perform a depth-first search on each row, marking each component as we go\n    // O(N*M)\n    for (int i = 0; i < lA.size(); ++i) {\n        int row = i;\n        while (row < lA.size() && lA[row]) {\n            if (c[row] == 0) {\n                // Mark this row as 1\n                c[row] = 1;\n\n                for (int j = 0; j < lA.size(); ++j) {\n                    if (lA[j] && j!= row) {\n                        lA[j] = 0;\n                    }\n                }\n            }\n            ++row;\n        }\n    }\n\n    int lComponentCount = 0;\n    for (int i = 0; i < c.size(); ++i) {\n        if (c[i]) {\n            lComponentCount += 1;\n        }\n    }\n\n    int componentCount;\n    MPI_Reduce(&lComponentCount, &componentCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return componentCount;\n}",
            "int rank, size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif (rank!= 0) {\n\t\treturn 0;\n\t}\n\t\n\tint *result;\n\tresult = (int *)malloc(size * sizeof(int));\n\n\tif (rank == 0) {\n\t\tint totalCount = 0;\n\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tresult[i] = 0;\n\t\t}\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i*N + i] == 1) {\n\t\t\t\tresult[0]++;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Recv(result+i, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\ttotalCount += result[i];\n\t\t}\n\n\t\treturn totalCount;\n\t} else {\n\t\tint componentCount = 0;\n\t\tint nthreads;\n\t\tomp_set_num_threads(2);\n\t\t#pragma omp parallel\n\t\t{\n\t\t\tnthreads = omp_get_num_threads();\n\n\t\t\t#pragma omp for\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tint count = 0;\n\t\t\t\tif (A[i*N + i] == 1) {\n\t\t\t\t\tcomponentCount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Send(&componentCount, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0;\n\t}\n}",
            "int num_procs, my_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\t\n\t// Get the local number of rows that this processor should process\n\tint rows_per_proc = N / num_procs;\n\tint rem_rows = N % num_procs;\n\tint start_row = my_rank * rows_per_proc;\n\tint end_row = start_row + rows_per_proc;\n\n\tif (my_rank == num_procs - 1) {\n\t\tend_row = end_row + rem_rows;\n\t}\n\n\tstd::vector<int> A_local(A.begin() + start_row * N, A.begin() + end_row * N);\n\tint num_components = 0;\n\n\t// Loop through each row\n\tfor (int row_index = 0; row_index < A_local.size(); row_index += N) {\n\t\t// Loop through each column\n\t\tfor (int col_index = 0; col_index < N; col_index++) {\n\t\t\t// Check if vertex is unvisited and if neighboring vertex is unvisited\n\t\t\tif (A_local[row_index + col_index] == 1 && A_local[row_index + col_index + 1] == 1) {\n\t\t\t\tnum_components += 1;\n\t\t\t\t// Check if the neighboring vertex is 1 and unvisited\n\t\t\t\tfor (int neighbor_col_index = col_index + 2; neighbor_col_index < N; neighbor_col_index++) {\n\t\t\t\t\tif (A_local[row_index + neighbor_col_index] == 1) {\n\t\t\t\t\t\tA_local[row_index + neighbor_col_index] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// Check if row after is unvisited\n\t\t\t\tif (row_index + N < A_local.size() && A_local[row_index + N] == 1) {\n\t\t\t\t\tA_local[row_index + N] = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint num_components_total;\n\tMPI_Reduce(&num_components, &num_components_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn num_components_total;\n}",
            "int c = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (A[i * N + i] == 0) {\n\t\t\tc++;\n\t\t}\n\t}\n\n\treturn c;\n}",
            "int p = omp_get_num_threads();\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\t// Compute the number of elements per row/column on each rank\n\tsize_t per_rank = N/size;\n\tint remainder = N%size;\n\tint start = rank*per_rank;\n\tint end = start+per_rank;\n\n\t// If the rank has more than its fair share, take the remainder elements\n\tif (rank < remainder) {\n\t\tend++;\n\t}\n\n\t// Count the number of connected components in the local submatrix\n\tint local_count = 0;\n\tint root = 0;\n\tint local_size = (end-start) * (end-start);\n\tint global_size = N * N;\n\tstd::vector<int> local_matrix(local_size);\n\n\t// Set the values of the local matrix\n\tfor (size_t i=0; i<local_size; i++) {\n\t\tlocal_matrix[i] = A[start + (i%(end-start)) + (i/((end-start))) * N];\n\t}\n\n\t// Compute the number of connected components in the local submatrix\n\tint local_count = 0;\n\tif (local_matrix.size() == 1) {\n\t\tlocal_count = 1;\n\t}\n\n\t// Loop through every element in the local matrix\n\tfor (size_t i=0; i<local_matrix.size(); i++) {\n\t\t// If the element is not 0, count the number of connected components in its row and column\n\t\tif (local_matrix[i] == 1) {\n\t\t\t// Count the number of connected components in the row\n\t\t\tint row_count = 0;\n\t\t\tfor (size_t j=0; j<local_matrix.size(); j++) {\n\t\t\t\tif (local_matrix[j] == 1 && i!=j) {\n\t\t\t\t\trow_count++;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Count the number of connected components in the column\n\t\t\tint col_count = 0;\n\t\t\tfor (size_t j=0; j<local_matrix.size(); j++) {\n\t\t\t\tif (local_matrix[j] == 1 && i%local_matrix.size()!= j%local_matrix.size()) {\n\t\t\t\t\tcol_count++;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Check to see if the number of connected components in the row and the column is 1\n\t\t\tif (row_count == 1 && col_count == 1) {\n\t\t\t\tlocal_count++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Sum the number of connected components on every rank\n\tint global_count = 0;\n\tMPI_Reduce(&local_count, &global_count, 1, MPI_INT, MPI_SUM, root, MPI_COMM_WORLD);\n\n\treturn global_count;\n}",
            "std::vector<bool> visited(N, false);\n  int count = 0;\n  for (int i = 0; i < N; i++) {\n    if (visited[i]) {\n      continue;\n    }\n    int s = i;\n    count++;\n    std::stack<int> s;\n    s.push(s);\n    while (!s.empty()) {\n      int next = s.top();\n      s.pop();\n      visited[next] = true;\n      for (int j = 0; j < N; j++) {\n        if (A[i*N + j] == 1 &&!visited[j]) {\n          s.push(j);\n        }\n      }\n    }\n  }\n  return count;\n}",
            "// TODO: implement me\n  return -1;\n}",
            "// TODO\n\n\t//std::vector<int> color(N, 0);\n    //int c_color = 1;\n    //std::vector<int> ans(N, 0);\n    //std::queue<int> q;\n    //int count = 0;\n\n    //for (int i = 0; i < N; i++) {\n        //if (color[i] == 0) {\n            //color[i] = c_color;\n            //count++;\n            //q.push(i);\n            //while (!q.empty()) {\n                //int j = q.front();\n                //q.pop();\n                //for (int k = 0; k < N; k++) {\n                    //if (A[j*N + k] == 1) {\n                        //if (color[k] == 0) {\n                            //color[k] = c_color;\n                            //q.push(k);\n                        //}\n                    //}\n                //}\n            //}\n            //c_color++;\n        //}\n    //}\n\n    //for (int i = 0; i < N; i++) {\n        //ans[i] = color[i] - 1;\n    //}\n\n    //return count;\n\n    return 0;\n}",
            "assert(N == A.size() / N);\n  std::vector<int> component(N);\n  int count = 0;\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; ++i) {\n    component[i] = i;\n  }\n  #pragma omp parallel for\n  for(size_t i = 0; i < N; ++i) {\n    for(size_t j = 0; j < N; ++j) {\n      if(A[i * N + j] == 1) {\n        int iComp = component[i];\n        int jComp = component[j];\n        if(iComp!= jComp) {\n          #pragma omp critical\n          {\n            for(size_t k = 0; k < N; ++k) {\n              if(component[k] == jComp) {\n                component[k] = iComp;\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  #pragma omp parallel for reduction(+:count)\n  for(size_t i = 0; i < N; ++i) {\n    if(component[i] == i) {\n      count++;\n    }\n  }\n  return count;\n}",
            "// Your code here\n}",
            "int nb_components = 0;\n\t#pragma omp parallel for reduction(+: nb_components)\n\tfor (int i = 0; i < N; i++)\n\t\tfor (int j = 0; j < N; j++)\n\t\t\tif (A[i*N+j] == 1)\n\t\t\t\tnb_components++;\n\n\treturn nb_components;\n}",
            "// TODO: Replace this code with a multithreaded/MPI implementation.\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) count++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int num_process = 0;\n    int rank = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_process);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // initialize the number of components to be 1 on each process\n    int num_components = 1;\n\n    // if it's not rank 0, we have a complete copy of the matrix\n    // we'll use the graph coloring algorithm to find all the components\n    if (rank!= 0)\n    {\n        std::vector<int> colors(N, 0);\n        int component_count = 0;\n        // color the root node\n        colors[0] = 1;\n        // for each row\n        for (size_t i = 0; i < N; i++)\n        {\n            // for each element in the row\n            for (size_t j = 0; j < N; j++)\n            {\n                // if the element is 1 and its color is 0\n                if (A[i*N+j] == 1 && colors[j] == 0)\n                {\n                    // set the color to be the next component count\n                    colors[j] = component_count + 1;\n                    // we need to color all the neighbors\n                    for (size_t k = 0; k < N; k++)\n                    {\n                        // if the element is 1 and the color of the neighbor is 0\n                        if (A[i*N+k] == 1 && colors[k] == 0)\n                        {\n                            // set the color to be the next component count\n                            colors[k] = component_count + 1;\n                        }\n                    }\n                    // increment the component count\n                    component_count++;\n                }\n            }\n        }\n        // the number of components on rank 1 and beyond is the same as the component count on rank 0\n        num_components = component_count;\n    }\n\n    // sum up all the number of components in the matrix\n    int sum_components;\n    MPI_Reduce(&num_components, &sum_components, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    // rank 0 returns the sum of all the components\n    if (rank == 0)\n    {\n        return sum_components;\n    }\n    else\n    {\n        return 0;\n    }\n}",
            "// TODO: implement this\n\n\t// ---------------------------------------------------------------------------\n\t// -----------------------    Helper functions   ----------------------------\n\t// ---------------------------------------------------------------------------\n\n\t// Check that row i of A is zero except for a single one\n\t// at position j.\n\tauto checkRow = [&](size_t i, size_t j) {\n\t\tfor (size_t k = 0; k < N; ++k)\n\t\t\tif (k!= j) assert(A[i * N + k] == 0);\n\t\tassert(A[i * N + j] == 1);\n\t};\n\n\t// Check that column j of A is zero except for a single one\n\t// at position i.\n\tauto checkCol = [&](size_t i, size_t j) {\n\t\tfor (size_t k = 0; k < N; ++k)\n\t\t\tif (k!= i) assert(A[k * N + j] == 0);\n\t\tassert(A[i * N + j] == 1);\n\t};\n\n\t// Count the number of connected components in the graph defined by the adjacency matrix A.\n\t// Use Breadth-First Search to traverse the graph.\n\t// Assumption: A is a symmetric matrix.\n\tauto bfs = [&](size_t start) {\n\t\tstd::vector<int> visited(N, 0);\n\t\tstd::vector<int> next(N, 0);\n\n\t\tint count = 0;\n\t\tint qhead = 0, qtail = 0;\n\t\tvisited[start] = 1;\n\t\tnext[qtail++] = start;\n\t\twhile (qtail!= qhead) {\n\t\t\tint v = next[qhead++];\n\t\t\tfor (int i = 0; i < N; ++i)\n\t\t\t\tif (A[v * N + i] == 1 && visited[i] == 0) {\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\tnext[qtail++] = i;\n\t\t\t\t}\n\t\t}\n\t\treturn count;\n\t};\n\n\t// ---------------------------------------------------------------------------\n\t// -----------------------    Breadth-First Search   ------------------------\n\t// ---------------------------------------------------------------------------\n\n\tint num_threads = omp_get_max_threads();\n\n\t// A copy of A for each thread\n\tstd::vector<std::vector<int>> A_local(N, std::vector<int>(N));\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tA_local[i][j] = A[i * N + j];\n\t\t}\n\t}\n\n\tint count = 0;\n\tint done = 0;\n\tint qhead = 0, qtail = 0;\n\tstd::vector<int> q(N);\n\tfor (int i = 0; i < N; ++i) {\n\t\tq[qtail++] = i;\n\t}\n\t// Traverse the graph using BFS\n\twhile (qhead!= qtail) {\n\t\tint start = q[qhead++];\n\t\t// Traverse the graph from start\n\t\t// If we find a vertex with no outgoing edges,\n\t\t// we know that it has no connection to any other vertices\n\t\t// that have been visited\n#pragma omp parallel num_threads(num_threads)\n\t\t{\n\t\t\tint tid = omp_get_thread_num();\n\t\t\tint local_count = 0;\n\t\t\tstd::vector<int> visited(N, 0);\n\t\t\tstd::vector<int> next(N, 0);\n\t\t\tint head = 0, tail = 0;\n\t\t\tvisited[start] = 1;\n\t\t\tnext[tail++] = start;\n\t\t\twhile (tail!= head) {\n\t\t\t\tint v = next[head++];\n\t\t\t\tfor (int i = 0; i < N; ++i)\n\t\t\t\t\tif (A_local[v][i] == 1",
            "if (N <= 0) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<int> visited(N, 0);\n\tint c_count = 0;\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\t++c_count;\n\t\t}\n\t}\n\n\treturn c_count;\n}",
            "int numRanks;\n  MPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int componentCount = 0;\n\n  std::vector<int> visited(N, 0);\n  // TODO:\n\n  return componentCount;\n}",
            "int rank = 0;\n\tint size = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tstd::vector<int> local_counts;\n\t#pragma omp parallel num_threads(2)\n\t{\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < A.size(); i++) {\n\t\t\t// TODO: Compute the number of connected components using BFS\n\t\t}\n\t}\n\tif (rank == 0) {\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tint count = 0;\n\t\t\tMPI_Recv(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tlocal_counts.push_back(count);\n\t\t}\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tint count = 0;\n\t\t\tMPI_Send(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t}\n\t} else {\n\t\tMPI_Send(local_counts.data(), 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\treturn 0;\n}",
            "// TODO\n  int* v = new int[N];\n  for (int i = 0; i < N; i++) {\n    v[i] = i;\n  }\n\n  int rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int localCount = 0;\n  if (size == 1) {\n    for (int i = 0; i < N; i++) {\n      if (A[i * N + i]!= 0) {\n        localCount++;\n      }\n    }\n  }\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j]!= 0 && i!= j) {\n        int rankI = i / (N / size);\n        int rankJ = j / (N / size);\n        if (rankI == rankJ) {\n          continue;\n        }\n\n        int min = std::min(i, j);\n        int max = std::max(i, j);\n        int root = min / (N / size);\n\n        MPI_Send(&i, 1, MPI_INT, root, 0, MPI_COMM_WORLD);\n        MPI_Send(&j, 1, MPI_INT, root, 0, MPI_COMM_WORLD);\n      }\n    }\n  }\n\n  int recvCount = 0;\n  for (int i = 0; i < size; i++) {\n    int indexI;\n    MPI_Status status;\n    if (i == rank) {\n      MPI_Probe(MPI_ANY_SOURCE, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n      MPI_Get_count(&status, MPI_INT, &recvCount);\n      std::vector<int> indices(recvCount);\n      MPI_Recv(&indices[0], recvCount, MPI_INT, MPI_ANY_SOURCE,\n        MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n      for (int j = 0; j < recvCount; j++) {\n        v[indices[j]] = indices[0];\n      }\n    } else {\n      MPI_Probe(i, MPI_ANY_TAG, MPI_COMM_WORLD, &status);\n      MPI_Get_count(&status, MPI_INT, &recvCount);\n      std::vector<int> indices(recvCount);\n      MPI_Recv(&indices[0], recvCount, MPI_INT, i, MPI_ANY_TAG, MPI_COMM_WORLD,\n        &status);\n      for (int j = 0; j < recvCount; j++) {\n        v[indices[j]] = indices[0];\n      }\n    }\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (v[i] == i) {\n      localCount++;\n    }\n  }\n\n  int globalCount = 0;\n  MPI_Reduce(&localCount, &globalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return globalCount;\n}",
            "// TODO: FILL THIS IN!\n    return 0;\n}",
            "int count = 0;\n  bool* visited = new bool[N];\n  for (int i = 0; i < N; ++i) {\n    visited[i] = false;\n  }\n\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      ++count;\n      bfs(A, i, N, visited);\n    }\n  }\n\n  return count;\n}",
            "int componentCount = 0;\n\tstd::vector<int> visited(N, 0);\n\tstd::vector<int> rank_visited(N, 0);\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tcomponentCount += 1;\n\t\t\tstd::stack<int> s;\n\t\t\ts.push(i);\n\t\t\twhile (s.size() > 0) {\n\t\t\t\tint j = s.top();\n\t\t\t\ts.pop();\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (A[j * N + k] &&!rank_visited[k]) {\n\t\t\t\t\t\ts.push(k);\n\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t\trank_visited[k] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn componentCount;\n}",
            "// TODO: implement\n\treturn 0;\n}",
            "return 0;\n}",
            "int *visited = new int[N*N];\n    for(int i=0; i<N; i++){\n        for(int j=0; j<N; j++){\n            visited[i*N+j] = 0;\n        }\n    }\n\n    int components = 0;\n    int rank = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int size = 0;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int *my_visited = new int[N];\n    for(int i=0; i<N; i++){\n        my_visited[i] = 0;\n    }\n    //int *displs = new int[size];\n\n    int *recv_buffer = new int[N];\n    int *recv_buffer2 = new int[N];\n    int *send_buffer = new int[N];\n    int *send_buffer2 = new int[N];\n\n    int num_rows = N/size;\n    int remainder = N % size;\n\n    int num_rows_rank;\n    int remainder_rank;\n    if(rank < remainder){\n        num_rows_rank = num_rows + 1;\n        remainder_rank = rank;\n    }\n    else{\n        num_rows_rank = num_rows;\n        remainder_rank = rank - remainder;\n    }\n\n    int displs = 0;\n    if(rank == 0){\n        displs = 0;\n    }\n    else if(rank < remainder){\n        displs = remainder_rank * (num_rows + 1);\n    }\n    else{\n        displs = remainder * (num_rows + 1) + (rank - remainder) * num_rows;\n    }\n\n\n    #pragma omp parallel\n    {\n        int threads = omp_get_num_threads();\n        int thread_id = omp_get_thread_num();\n\n        if(thread_id == 0){\n            for(int i=0; i<N; i++){\n                for(int j=0; j<N; j++){\n                    if(A[i*N+j] == 1 && visited[i*N+j] == 0){\n                        #pragma omp parallel for\n                        for(int k=0; k<N; k++){\n                            my_visited[k] = visited[i*N+k];\n                            visited[i*N+k] = 1;\n                            visited[k*N+i] = 1;\n                        }\n                        components += 1;\n                    }\n                }\n            }\n        }\n    }\n\n    MPI_Reduce(my_visited, send_buffer, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    MPI_Reduce(visited, recv_buffer, N*N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    int *send_buffer3 = new int[size];\n    int *recv_buffer3 = new int[size];\n    send_buffer3[rank] = components;\n    MPI_Allreduce(send_buffer3, recv_buffer3, size, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n    components = recv_buffer3[0];\n\n    for(int i=0; i<N; i++){\n        if(recv_buffer[i*N+i] == 0 && send_buffer[i] == 0){\n            components += 1;\n        }\n    }\n\n    if(rank == 0){\n        for(int i=0; i<size; i++){\n            for(int j=0; j<N; j++){\n                for(int k=0; k<N; k++){\n                    if(A[j*N+k] == 1){\n                        visited[j*N+k] = recv_buffer[i*N+j] + recv_buffer[i*N+k];\n                    }\n                }\n            }\n        }\n    }\n    else",
            "std::vector<int> visited(N, 0);\n\n\tint numComponents = 0;\n\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++)\n\t{\n\t\tif(!visited[i])\n\t\t{\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tnumComponents++;\n\t\t\t}\n\n\t\t\t#pragma omp for schedule(dynamic) nowait\n\t\t\tfor(int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif(A[i * N + j])\n\t\t\t\t{\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N, false);\n    int count = 0;\n    int rank = 0;\n    int numProcs = 0;\n    int size = 0;\n    int* recvcounts = NULL;\n    int* displs = NULL;\n    MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    if (rank == 0) {\n        size = A.size();\n        recvcounts = new int[numProcs];\n        displs = new int[numProcs];\n        for (int i = 0; i < numProcs; i++) {\n            recvcounts[i] = N * N / numProcs;\n            displs[i] = i * N * N / numProcs;\n        }\n        recvcounts[numProcs - 1] += N * N % numProcs;\n        displs[numProcs - 1] = (numProcs - 1) * N * N / numProcs + (N * N % numProcs);\n    }\n    MPI_Bcast(&size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Scatterv((void*)A.data(), recvcounts, displs, MPI_INT, &A[0], size, MPI_INT, 0, MPI_COMM_WORLD);\n    if (rank!= 0) {\n        N = sqrt(size);\n    }\n    MPI_Barrier(MPI_COMM_WORLD);\n    if (rank == 0) {\n        for (int i = 0; i < N; i++) {\n            if (!visited[i]) {\n                count++;\n            }\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j]) {\n                    visited[j] = true;\n                }\n            }\n            for (int j = 0; j < N; j++) {\n                visited[j] = false;\n            }\n        }\n    }\n    return count;\n}",
            "// TODO: YOUR CODE HERE\n\n\tstd::vector<bool> connected(N, false);\n\tint count = 0;\n\tint id;\n\n\tfor (int i = 0; i < N; i++){\n\t\tif (connected[i] == false){\n\t\t\tMPI_Send(&i, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n\t\t\tconnected[i] = true;\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N; i++){\n\t\tMPI_Recv(&id, 1, MPI_INT, MPI_ANY_SOURCE, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (A[i*N+j] == 1 && connected[j] == false){\n\t\t\t\tconnected[j] = true;\n\t\t\t\tcount++;\n\t\t\t\tMPI_Send(&j, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n\t\t\t}\n\t\t}\n\t}\n\treturn count;\n\n}",
            "int count = 0;\n\n\tomp_set_num_threads(4);\n\t#pragma omp parallel for shared(A, count, N) reduction(+:count)\n\tfor(size_t i = 0; i < N; i++) {\n\t\tbool visited[N];\n\t\tmemset(visited, 0, N);\n\t\tvisited[i] = 1;\n\n\t\tint count_component = 0;\n\t\tint index = i;\n\t\twhile(visited[index]) {\n\t\t\tcount_component++;\n\t\t\tvisited[index] = 0;\n\t\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\t\tif(A[i*N + j] == 1 &&!visited[j]) {\n\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\tindex = j;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tcount += count_component;\n\t}\n\n\treturn count;\n}",
            "const int rank = 0;\n\tconst int size = 0;\n\t\n\treturn 0;\n}",
            "int mpi_size, mpi_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n\tint count = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> stack;\n\tstack.reserve(N);\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (A[i*N + i] == 0) {\n\t\t\tcontinue;\n\t\t}\n\t\tvisited[i] = true;\n\t\tstack.push_back(i);\n\n\t\twhile (!stack.empty()) {\n\t\t\tint curr = stack.back();\n\t\t\tstack.pop_back();\n\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (visited[j] || (A[curr*N + j] == 0)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tstack.push_back(j);\n\t\t\t\tvisited[j] = true;\n\t\t\t}\n\t\t}\n\t\tcount++;\n\t}\n\n\tint total = 0;\n\tMPI_Reduce(&count, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn total;\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int count = 0;\n\n    // TODO\n    return count;\n}",
            "// TODO: Implement this function\n\n  int rank = 0;\n  int size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int count = 0;\n  std::vector<int> visited(N, 0);\n  int component_count = 0;\n\n  if (rank == 0) {\n    for (int i = 0; i < N; i++) {\n      if (!visited[i]) {\n        component_count++;\n        visited[i] = 1;\n        for (int j = 0; j < N; j++) {\n          if (A[i * N + j]) {\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n    for (int i = 0; i < size; i++) {\n      if (i!= 0) {\n        MPI_Recv(&count, 1, MPI_INT, i, MPI_ANY_TAG, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        component_count += count;\n      }\n    }\n  } else {\n    int start = rank * (N / size);\n    int end = (rank + 1) * (N / size);\n    if (rank == size - 1)\n      end = N;\n    for (int i = start; i < end; i++) {\n      if (!visited[i]) {\n        count++;\n        visited[i] = 1;\n        for (int j = 0; j < N; j++) {\n          if (A[i * N + j]) {\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n    MPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n\n  return component_count;\n}",
            "// TODO: write this function\n\t// The algorithm to solve the problem can be found on https://en.wikipedia.org/wiki/Connected_component_(graph_theory)\n\t// If you don't understand what the Wikipedia article means, ask the professor for help.\n\t// The code should use MPI and OpenMP to get the maximum performance.\n\t// The code should work for any positive N.\n\treturn 0;\n}",
            "// TODO: Replace this line\n    // The code below is just an example of how to call into your componentCount function\n    // You will probably need to modify it\n    // Your code should call componentCount, which is defined in cc_helper.cpp.\n    // This function is called from other files, so it should be defined in the header file\n    // To call componentCount on each rank, use OpenMP\n    int res = 0;\n#pragma omp parallel for reduction(+:res)\n    for (int i = 0; i < N; i++) {\n        res += componentCount(A, N, i);\n    }\n    int res_total;\n    MPI_Reduce(&res, &res_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return res_total;\n}",
            "int numComponents = 0;\n\n  // Your code goes here\n\n  return numComponents;\n}",
            "std::vector<int> visited(N, 0);\n    std::vector<int> color(N, 0);\n    int count = 0;\n#pragma omp parallel for reduction(+:count)\n    for (size_t i = 0; i < N; ++i) {\n        if (visited[i]) continue;\n        count += componentCount(A, i, visited, color);\n    }\n    return count;\n}",
            "int component_count = 0;\n\n  // TODO: Add code here\n  \n  return component_count;\n}",
            "int component_count = 0;\n\n  // TODO: Implement this function\n\n  return component_count;\n}",
            "int c = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    if (A[i*N+i] == 1) {\n      #pragma omp critical\n      c++;\n    }\n  }\n  return c;\n}",
            "std::vector<int> is_visited(N, 0);\n    int num_components = 0;\n\n    for (int i = 0; i < N; ++i) {\n        if (!is_visited[i]) {\n            num_components++;\n            std::queue<int> q;\n            q.push(i);\n            while (!q.empty()) {\n                int curr = q.front();\n                q.pop();\n                for (int j = 0; j < N; ++j) {\n                    if (A[curr * N + j] &&!is_visited[j]) {\n                        is_visited[j] = 1;\n                        q.push(j);\n                    }\n                }\n            }\n        }\n    }\n    return num_components;\n}",
            "// TODO: implement me\n  int num_components = 0;\n  for (size_t i = 0; i < N; ++i)\n    for (size_t j = 0; j < N; ++j)\n      if (A[i*N + j] == 1)\n        ++num_components;\n  return num_components;\n}",
            "std::vector<int> visited(N);\n\n\tauto count_visited = [&](int j, int myrank, int rank_size) {\n\t\tint start = myrank*N/rank_size;\n\t\tint end = (myrank+1)*N/rank_size;\n\t\tfor(int i=start; i<end; i++) {\n\t\t\tif(visited[i] == 0 && A[i*N + j]) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tcount_visited(i, myrank, rank_size);\n\t\t\t}\n\t\t}\n\t};\n\n\tint sum = 0;\n\tfor(int i=0; i<N; i++) {\n\t\tif(visited[i] == 0) {\n\t\t\tvisited[i] = 1;\n\t\t\tcount_visited(i, 0, 1);\n\t\t\tsum++;\n\t\t}\n\t}\n\n\treturn sum;\n}",
            "// TODO\n    return 0;\n}",
            "// Your code here\n}",
            "std::vector<int> visited(N, 0);\n  int n_components = 0;\n  for (size_t i = 0; i < N; i++) {\n    if (visited[i])\n      continue;\n\n    std::queue<size_t> q;\n    q.push(i);\n\n    while (q.size() > 0) {\n      int current = q.front();\n      q.pop();\n      visited[current] = 1;\n      for (size_t j = 0; j < N; j++) {\n        if (A[current * N + j] &&!visited[j])\n          q.push(j);\n      }\n    }\n    n_components++;\n  }\n  return n_components;\n}",
            "int num_proc, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t// Use omp to parallelize the inner loop.\n\tint count = 0;\n\tstd::vector<int> a = A;\n\tstd::vector<int> visited(N, 0);\n\n\t// Create a new thread for every element in the array.\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\t// If an element is not visited, then it is a component.\n\t\tif (visited[i] == 0) {\n\t\t\t// DFS to check whether all elements in the component is visited.\n\t\t\tbool finished = false;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\n\t\t\twhile (!finished) {\n\t\t\t\t// Pop the first element from the queue.\n\t\t\t\tint elem = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[elem] = 1;\n\t\t\t\t// Check if the element has already been visited.\n\t\t\t\tif (visited[elem] == 1) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\t// Check if the element has neighbors that haven't been visited.\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (a[elem * N + j]!= 0 && visited[j]!= 1) {\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\tif (rank == 0) {\n\t\treturn count;\n\t} else {\n\t\t// Every other rank sends its count to rank 0.\n\t\tMPI_Send(&count, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t\treturn 0;\n\t}\n}",
            "int *visited = (int *) calloc(N, sizeof(int));\n\tint *comp_count = (int *) calloc(1, sizeof(int));\n\n\tint rank = 0, size = 1;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint i,j;\n\t#pragma omp parallel for private(i,j) shared(A, N, visited, comp_count)\n\tfor (i = 0; i < N; i++) {\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] &&!visited[i]) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\t#pragma omp atomic\n\t\t\t\t(*comp_count) += 1;\n\t\t\t\t#pragma omp for nowait\n\t\t\t\tfor (k = 0; k < N; k++) {\n\t\t\t\t\tif (A[i*N + k] &&!visited[k]) {\n\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint *total = (int *) calloc(1, sizeof(int));\n\tMPI_Reduce(comp_count, total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\tint res = 0;\n\tif (rank == 0)\n\t\tres = *total;\n\tfree(visited);\n\tfree(comp_count);\n\tfree(total);\n\treturn res;\n}",
            "std::vector<int> visited(N); // boolean array\n  int count = 0;\n  // Iterate over each vertex and check if connected to any other vertex\n  // If unvisited, count the vertex and mark it as visited\n  // O(n^2) complexity\n  // O(n) space complexity\n\n  // MPI Implementation:\n  // Divide N vertices evenly between ranks\n  // Each rank runs through its section of A,\n  // and counts connected components\n  // Rank 0 collects and combines the results\n\n  // OpenMP implementation:\n  // Use omp_get_num_threads() to get the number of threads\n  // Run each vertex through DFS independently\n  // Count the number of connected components and return\n\n  int rank = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size = 0;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // OpenMP implementation\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    int threads = omp_get_num_threads();\n    int tid = omp_get_thread_num();\n\n    if (visited[i] == 0) {\n      // DFS on i\n      count++;\n      visited[i] = 1;\n      // std::cout << i << std::endl;\n    }\n\n  }\n\n  // MPI implementation\n  int N_per_rank = N / size;\n  int N_remaining = N % size;\n  int start = N_per_rank * rank;\n  int end = N_per_rank * (rank + 1);\n\n  for (int i = start; i < end; i++) {\n    if (visited[i] == 0) {\n      // DFS on i\n      count++;\n      visited[i] = 1;\n    }\n  }\n\n  // Return count\n  // Use MPI reduce to combine results\n  // MPI_Reduce(const void* sendbuf, void* recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm)\n  // MPI_COMM_WORLD is the communicator used for all the processes\n  int total = 0;\n  MPI_Reduce(&count, &total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  return total;\n}",
            "int rank, size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int local_cc = 0;\n  int global_cc = 0;\n  if (rank == 0) {\n    std::vector<bool> visited(N, false);\n    int count = 0;\n    for (int i = 0; i < N; i++) {\n      if (!visited[i]) {\n        count++;\n        std::queue<int> q;\n        q.push(i);\n        while (!q.empty()) {\n          int v = q.front();\n          q.pop();\n          visited[v] = true;\n          for (int j = 0; j < N; j++) {\n            if (A[v * N + j] == 1 &&!visited[j]) {\n              q.push(j);\n            }\n          }\n        }\n      }\n    }\n    local_cc = count;\n  }\n  // Use MPI_Reduce to get the global CC\n  MPI_Reduce(&local_cc, &global_cc, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return global_cc;\n}",
            "int count = 0;\n\n    // Add your code here\n\n    return count;\n}",
            "int rank, nprocs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n  std::vector<int> visited(N, 0);\n  int component_count = 0;\n\n  // TODO\n  return 0;\n}",
            "// TODO: your code here\n\n\t//std::vector<int> visited(N, 0);\n\t//int componentCount = 0;\n\n\t//for (size_t i = 0; i < N; ++i) {\n\t//\tif (visited[i] == 0) {\n\t//\t\t++componentCount;\n\t//\t\tvisited[i] = 1;\n\t//\t\tfor (size_t j = 0; j < N; ++j) {\n\t//\t\t\tif (A[i*N + j] == 1) {\n\t//\t\t\t\tvisited[j] = 1;\n\t//\t\t\t}\n\t//\t\t}\n\t//\t}\n\t//}\n\treturn 0;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> visitedThread(N, 0);\n  std::vector<int> compCount(N, 0);\n  std::vector<int> compCountThread(N, 0);\n  int numComponents = 0;\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  int i, j, k;\n  omp_set_num_threads(4);\n  #pragma omp parallel for private(i, j) reduction(+: numComponents)\n  for (int i = 0; i < N; i++) {\n    if (visited[i]!= 1) {\n      visited[i] = 1;\n      visitedThread[omp_get_thread_num()] = 1;\n      compCountThread[omp_get_thread_num()] = 1;\n      numComponents += 1;\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j]!= 0 && visited[j]!= 1) {\n          visited[j] = 1;\n          compCountThread[omp_get_thread_num()] += 1;\n        }\n      }\n    }\n  }\n  for (int i = 0; i < N; i++) {\n    if (visitedThread[i] == 1) {\n      compCount[omp_get_thread_num()] += 1;\n    }\n  }\n  int local_sum = 0;\n  for (int i = 0; i < omp_get_num_threads(); i++) {\n    local_sum += compCountThread[i];\n  }\n  int sum;\n  MPI_Reduce(&local_sum, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  int final_sum;\n  MPI_Reduce(&sum, &final_sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  int final_sum_thread;\n  MPI_Reduce(&compCount[0], &final_sum_thread, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    printf(\"Number of components: %d\\n\", final_sum_thread);\n  }\n  return final_sum_thread;\n}",
            "// TODO: implement\n\tint componentNum = 0;\n\tint count = 0;\n\tint count_local = 0;\n\n\tstd::vector<bool> visited(N, false);\n\n\t#pragma omp parallel for num_threads(2)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i] == false) {\n\t\t\tcount_local = 0;\n\t\t\t#pragma omp parallel for num_threads(2)\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[N*i + j] == 1 && visited[j] == false) {\n\t\t\t\t\tcount_local++;\n\t\t\t\t\t#pragma omp parallel for num_threads(2)\n\t\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\t\tif (A[N*j + k] == 1 && visited[k] == false) {\n\t\t\t\t\t\t\tvisited[k] = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount = count + count_local;\n\t\t}\n\t}\n\n\t#ifdef DEBUG\n\t\tprintf(\"component count: %d\\n\", count);\n\t#endif\n\n\treturn count;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  // TODO\n  return 0;\n}",
            "// TODO\n  int* visited = new int[N];\n  for(int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n  int count = 0;\n  for(int i = 0; i < N; i++) {\n    if(!visited[i]) {\n      dfs(i, A, N, visited);\n      count++;\n    }\n  }\n\n  return count;\n}",
            "int size, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint localComponentCount = 0;\n\t//TODO: Count the components in this submatrix using OpenMP.\n\tint row, col;\n\n#pragma omp parallel for private(row,col)\n\tfor(int i=0;i<N;i++) {\n\t\tfor(int j=0;j<N;j++) {\n\t\t\tif(A[i*N + j]!=0) {\n\t\t\t\tif(i==j) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tfor(row=0;row<N;row++) {\n\t\t\t\t\tif(row==i || row==j) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif(A[row*N + i]==0 && A[row*N + j]==0) {\n\t\t\t\t\t\tlocalComponentCount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t//TODO: Use MPI to sum the counts on rank 0.\n\n\treturn localComponentCount;\n}",
            "int rank = 0, worldSize = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &worldSize);\n\n  int nthreads = omp_get_num_threads();\n  int nthreadsPerRank = nthreads / worldSize;\n  int nthreadsInRank = nthreadsPerRank;\n  int startRank = rank*nthreadsPerRank;\n  if (rank == 0) {\n    nthreadsInRank = nthreads - nthreadsPerRank*(worldSize-1);\n  } else if (rank == worldSize-1) {\n    nthreadsInRank = nthreadsPerRank;\n  }\n\n  int componentCount = 0;\n\n  // TODO: Count the number of connected components using MPI and OpenMP\n\n  return componentCount;\n}",
            "return 0;\n}",
            "int c = 0;\n\n  return c;\n}",
            "std::vector<int> component(N, 0);\n\tstd::vector<int> toVisit;\n\tstd::vector<int> nextToVisit;\n\n\t// Initialize component numbering to rank.\n\tint nb_rank = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &nb_rank);\n\tfor (size_t i = 0; i < N; i++) {\n\t\tcomponent[i] = nb_rank;\n\t}\n\n\t// Visit each node.\n#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (component[i] == nb_rank) {\n\t\t\ttoVisit.push_back(i);\n\t\t\twhile (toVisit.size() > 0) {\n\t\t\t\tfor (int& u : toVisit) {\n\t\t\t\t\tfor (int v = 0; v < N; v++) {\n\t\t\t\t\t\tif (u == v) {\n\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (A[v * N + u] == 1) {\n\t\t\t\t\t\t\tif (component[v] == nb_rank) {\n\t\t\t\t\t\t\t\tnextToVisit.push_back(v);\n\t\t\t\t\t\t\t\tcomponent[v] = component[u];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttoVisit.clear();\n\t\t\t\ttoVisit = nextToVisit;\n\t\t\t\tnextToVisit.clear();\n\t\t\t}\n\t\t}\n\t}\n\n\t// Communication to get the final result.\n\tMPI_Reduce(&component[0], NULL, component.size(), MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\tstd::unordered_set<int> components;\n\tfor (int i = 0; i < component.size(); i++) {\n\t\tcomponents.insert(component[i]);\n\t}\n\treturn components.size();\n}",
            "auto isInComponent = std::vector<bool>(N, false);\n\n    for (size_t i = 0; i < N; ++i) {\n        if (!isInComponent[i]) {\n            auto c = 1;\n            std::queue<int> q;\n            q.push(i);\n            isInComponent[i] = true;\n            while (!q.empty()) {\n                auto k = q.front();\n                q.pop();\n                for (size_t j = 0; j < N; ++j) {\n                    if (!isInComponent[j] && A[k * N + j]!= 0) {\n                        q.push(j);\n                        isInComponent[j] = true;\n                        c++;\n                    }\n                }\n            }\n            // printf(\"%lu\\n\", c);\n        }\n    }\n\n    int sum = 0;\n    MPI_Reduce(&c, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return sum;\n}",
            "int *A_int = new int[N*N];\n  std::copy(A.begin(), A.end(), A_int);\n  int count = 0;\n  int *v = new int[N];\n  int nprocs, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  if(rank == 0) {\n    for(int i = 0; i < N; i++)\n      v[i] = 1;\n  }\n  else {\n    for(int i = 0; i < N; i++)\n      v[i] = 0;\n  }\n  for(int i = 0; i < N; i++) {\n    if(A_int[i*N+i] == 1) {\n      for(int j = 0; j < N; j++) {\n        if(A_int[i*N+j] == 1) {\n          if(rank == 0) {\n            if(v[j] == 0) {\n              v[j] = 1;\n              count++;\n            }\n          }\n          else {\n            if(v[j] == 0) {\n              v[j] = 1;\n            }\n          }\n        }\n      }\n    }\n  }\n  MPI_Reduce(MPI_IN_PLACE, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return count;\n}",
            "int num_procs;\n    int rank;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\n    int* recvcounts = new int[num_procs];\n    int* displs = new int[num_procs];\n\n    for (int i=0; i<num_procs; i++) {\n    \trecvcounts[i] = N*N/num_procs;\n    }\n\n    for (int i=0; i<num_procs-1; i++) {\n    \tdispls[i+1] = displs[i] + recvcounts[i];\n    }\n\n    int* recvmat = new int[N*N/num_procs];\n    MPI_Scatterv(A.data(), recvcounts, displs, MPI_INT, recvmat, recvcounts[rank], MPI_INT, 0, MPI_COMM_WORLD);\n\n    int* isConnected = new int[N*N/num_procs];\n    for (int i=0; i<N*N/num_procs; i++) {\n    \tisConnected[i] = 1;\n    }\n\n    int* isVisited = new int[N*N/num_procs];\n    for (int i=0; i<N*N/num_procs; i++) {\n    \tisVisited[i] = 0;\n    }\n\n    int count = 0;\n\n    #pragma omp parallel for\n    for (int i=0; i<N*N/num_procs; i++) {\n    \tif (isVisited[i] == 0) {\n    \t\tint localcount = 0;\n    \t\tDFS(recvmat, i, N, isVisited, localcount);\n    \t\tcount += localcount;\n    \t}\n    }\n\n    int* counts = new int[num_procs];\n\n    MPI_Gather(&count, 1, MPI_INT, counts, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int* count_total = new int[1];\n    count_total[0] = 0;\n\n    MPI_Reduce(counts, count_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return count_total[0];\n}",
            "if (A.size()!= N*N) {\n    throw \"A must be an NxN matrix\";\n  }\n  int components = 0;\n  int visited = 0;\n  // TODO: compute number of components\n\n  return components;\n}",
            "int numComponents = 0;\n\n    #pragma omp parallel\n    {\n        std::vector<int> count(N, 0);\n        std::vector<int> visited(N, 0);\n        std::vector<int> rank(N, 0);\n\n        #pragma omp for\n        for (size_t i = 0; i < N; i++) {\n            if (visited[i] == 0) {\n                int new_comp = 0;\n                int curr_comp = i;\n                rank[curr_comp] = 0;\n                count[curr_comp] = 1;\n\n                while (curr_comp!= -1) {\n                    curr_comp = -1;\n                    for (size_t j = 0; j < N; j++) {\n                        if ((A[i * N + j] == 1) && (visited[j] == 0)) {\n                            rank[j] = rank[i] + 1;\n                            count[j] = count[i];\n                            curr_comp = j;\n                            break;\n                        }\n                    }\n                    i = curr_comp;\n                }\n                new_comp = count[i];\n                #pragma omp critical\n                numComponents += new_comp;\n                visited[i] = 1;\n            }\n        }\n    }\n\n    return numComponents;\n}",
            "const int rank = omp_get_thread_num();\n\tconst int size = omp_get_num_threads();\n\t//int rank = 0;\n\t//int size = 1;\n\n\tstd::vector<bool> visited(N, false);\n\tint count = 0;\n\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tDFSVisit(i, A, visited, rank, size);\n\t\t\t#pragma omp atomic\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (size == 1) {\n\t\treturn componentCountSerial(A, N);\n\t}\n\n\t// The number of rows to handle per rank.\n\tsize_t rowsPerRank = N / size;\n\tif (N % size!= 0) {\n\t\t++rowsPerRank;\n\t}\n\n\t// The start and end row index for this rank.\n\tsize_t startRow = rank * rowsPerRank;\n\tsize_t endRow = (rank + 1) * rowsPerRank;\n\tif (endRow > N) {\n\t\tendRow = N;\n\t}\n\n\t// Find the number of connected components in this rank's section of A.\n\tint localComponentCount = componentCountSerial(\n\t\tstd::vector<int>(A.begin() + startRow * N, A.begin() + endRow * N), rowsPerRank);\n\n\t// Reduce the local component counts with MPI.\n\tint totalComponentCount = 0;\n\tMPI_Reduce(&localComponentCount, &totalComponentCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// The main rank has the result.\n\treturn totalComponentCount;\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint count = 0;\n\n\t// count connected components using BFS\n\tstd::vector<bool> visited(N, false);\n\t#pragma omp parallel for num_threads(size) schedule(dynamic,1)\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (!visited[i]) {\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\twhile(!q.empty()) {\n\t\t\t\tint node = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tvisited[node] = true;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (!visited[j] && A[node*N+j]!= 0)\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t\t++count;\n\t\t}\n\t}\n\n\tint localCount = count;\n\tint globalCount = 0;\n\tMPI_Reduce(&localCount, &globalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn globalCount;\n}",
            "int p = 0;\n  int num_thread;\n  int num_procs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &p);\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  //#pragma omp parallel\n  //{\n  //  num_thread = omp_get_num_threads();\n  //  printf(\"thread %d/%d\\n\", p, num_thread);\n  //}\n  //num_thread = omp_get_num_threads();\n  //printf(\"thread %d/%d\\n\", p, num_thread);\n  std::vector<bool> visited(N*N, false);\n  int count = 0;\n  int start = p * N;\n  int end = (p + 1) * N;\n  if(end > A.size()){\n    end = A.size();\n  }\n  for (int i = start; i < end; ++i) {\n    if (!visited[i]) {\n      int size = 0;\n      int id = i;\n      while (!visited[id]) {\n        visited[id] = true;\n        ++size;\n        id = id + N;\n        while (id >= N*N) {\n          id = id - N*N + N;\n        }\n      }\n      ++count;\n    }\n  }\n  int totalCount = 0;\n  MPI_Reduce(&count, &totalCount, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return totalCount;\n}",
            "// TODO: implement\n  return -1;\n}",
            "// Your code here.\n}",
            "int num_processors = omp_get_num_procs();\n\tint num_threads = omp_get_max_threads();\n\t\n\tstd::vector<std::vector<int>> adjMatrix = std::vector<std::vector<int>>(N);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tadjMatrix[i] = std::vector<int>(N);\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tadjMatrix[i][j] = A[i*N + j];\n\t\t}\n\t}\n\n\tint count = 0;\n\tstd::vector<int> visited;\n\tstd::vector<int> stack;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited.push_back(0);\n\t\tstack.push_back(0);\n\t}\n\n\tint numOfConnectedComp = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tnumOfConnectedComp++;\n\t\t\tint node = i;\n\t\t\tvisited[i] = 1;\n\t\t\tstack[0] = node;\n\t\t\tint stack_size = 1;\n\t\t\tint index = 0;\n\t\t\twhile (stack_size) {\n\t\t\t\tint node = stack[index];\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (adjMatrix[node][i] && visited[i] == 0) {\n\t\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\t\tstack[stack_size] = i;\n\t\t\t\t\t\tstack_size++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tstack_size--;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn numOfConnectedComp;\n}",
            "// Your code here.\n\tint component_count = 0;\n\tstd::vector<int> visited(N, 0);\n\tomp_set_num_threads(N);\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++){\n\t\tif (!visited[i]){\n\t\t\tint i_component = 0;\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\tvisited[i] = 1;\n\t\t\twhile(!q.empty()){\n\t\t\t\tint curr = q.front();\n\t\t\t\tq.pop();\n\t\t\t\ti_component++;\n\t\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\t\tif (A[curr * N + j] &&!visited[j]){\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t#pragma omp critical\n\t\t\tcomponent_count += i_component;\n\t\t}\n\t}\n\treturn component_count;\n}",
            "// your code goes here\n}",
            "// TODO: your code here\n  return 0;\n}",
            "int p = 0;\n    std::vector<int> scc_count(N, 0);\n    std::vector<int> stack(N, 0);\n\n    auto isEmpty = [&stack]() {\n        return stack[0] == 0;\n    };\n\n    auto push = [&stack](int val) {\n        stack[0]++;\n        stack[stack[0]] = val;\n    };\n\n    auto pop = [&stack]() {\n        auto val = stack[stack[0]];\n        stack[stack[0]] = 0;\n        stack[0]--;\n        return val;\n    };\n\n    auto tarjan = [&](int v, int num, std::vector<int>& scc_count, std::vector<int>& stack, int& p) {\n        scc_count[v] = num;\n        stack[v] = 1;\n        p++;\n        push(v);\n\n        for (int i = 0; i < N; i++) {\n            if (A[v * N + i]) {\n                if (!scc_count[i]) {\n                    tarjan(i, num, scc_count, stack, p);\n                } else if (stack[i]) {\n                    while (scc_count[pop()]!= scc_count[i]);\n                }\n            }\n        }\n\n        if (scc_count[v] == num) {\n            while (scc_count[pop()]!= num);\n            p--;\n        }\n    };\n\n    for (int i = 0; i < N; i++) {\n        if (!scc_count[i]) {\n            tarjan(i, i + 1, scc_count, stack, p);\n        }\n    }\n\n    return p;\n}",
            "std::vector<int> rankComponentCount(N, 0);\n  int totalComponentCount = 0;\n\n  // TODO: Compute the number of components per rank and reduce\n\n  return totalComponentCount;\n}",
            "// Your code here\n}",
            "int rank;\n\tint nproc;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nproc);\n\tint nthreads = omp_get_max_threads();\n\n\t/* Your solution goes here. */\n\t\n\treturn 0;\n}",
            "int numRanks, rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint numComponents = 0;\n\n\t/* YOUR CODE HERE */\n\tint *flag = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tflag[i] = 0;\n\t}\n\n\tif (rank == 0) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (flag[i] == 0) {\n\t\t\t\tflag[i] = 1;\n\t\t\t\tnumComponents++;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\t\tflag[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (flag[i] == 0) {\n\t\t\t\tflag[i] = 1;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\t\t\tflag[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t//MPI_Bcast(&numComponents, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tint *sum = new int[1];\n\tsum[0] = numComponents;\n\tMPI_Reduce(sum, &numComponents, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn numComponents;\n}",
            "}",
            "int count = 0;\n  int num_threads = omp_get_max_threads();\n  #pragma omp parallel num_threads(num_threads)\n  {\n    int thread_id = omp_get_thread_num();\n    int* visited = (int*)calloc(N, sizeof(int));\n    #pragma omp for\n    for (int i = 0; i < N; ++i) {\n      if (visited[i]) continue;\n      //printf(\"Rank %d: Checking component %d\\n\", thread_id, i);\n      //printf(\"Rank %d: Checking component %d, visited %d\\n\", thread_id, i, visited[i]);\n      int component_size = 0;\n      //printf(\"Rank %d: Pushing %d\\n\", thread_id, i);\n      std::queue<int> to_visit;\n      to_visit.push(i);\n      while (!to_visit.empty()) {\n        //printf(\"Rank %d: Popping %d\\n\", thread_id, to_visit.front());\n        int cur = to_visit.front();\n        to_visit.pop();\n        visited[cur] = 1;\n        component_size++;\n        for (int j = 0; j < N; ++j) {\n          //printf(\"Rank %d: Checking %d\\n\", thread_id, j);\n          if (A[cur * N + j] &&!visited[j]) {\n            //printf(\"Rank %d: Pushing %d\\n\", thread_id, j);\n            to_visit.push(j);\n          }\n        }\n      }\n      count += component_size;\n    }\n    free(visited);\n  }\n\n  return count;\n}",
            "int mpi_size, mpi_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n\tint num_components = 0;\n\tstd::vector<int> component(N, 0);\n\t// count the number of connected components in the adjacency matrix\n\tfor (int i = 0; i < N; i++) {\n\t\t// if the i-th node hasn't been assigned to a component yet\n\t\tif (!component[i]) {\n\t\t\t// assign the i-th node to a new component\n\t\t\tnum_components++;\n\t\t\t// create a queue to store the nodes of the current component\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(i);\n\t\t\t// visit the nodes of the current component in BFS fashion\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint cur = q.front();\n\t\t\t\tq.pop();\n\t\t\t\t// set the component of the cur-th node to num_components\n\t\t\t\tcomponent[cur] = num_components;\n\t\t\t\t// enqueue the neighbors of the cur-th node\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t// if the cur-th node and the j-th node are connected and the j-th node\n\t\t\t\t\t// hasn't been assigned to a component yet\n\t\t\t\t\tif (A[cur * N + j] &&!component[j])\n\t\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// reduce the component counts in parallel\n\tint num_components_total = 0;\n\tMPI_Reduce(&num_components, &num_components_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\t// return the component count on rank 0\n\tif (!mpi_rank)\n\t\treturn num_components_total;\n\telse\n\t\treturn 0;\n}",
            "int result = 0;\n\n  std::vector<int> visited(N, 0);\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      #pragma omp critical\n      { result++; }\n      dfs(i, A, visited, N);\n    }\n  }\n\n  return result;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // Each thread works on its own row of A.\n  std::vector<bool> visited(N, false);\n  std::vector<int> count(N, 0);\n  #pragma omp parallel for schedule(dynamic,1)\n  for (size_t i=0; i<N; i++) {\n    if (A[i*N+i] == 1) {\n      // Root vertex.\n      std::queue<size_t> queue;\n      queue.push(i);\n      while (!queue.empty()) {\n        size_t u = queue.front();\n        queue.pop();\n        if (!visited[u]) {\n          visited[u] = true;\n          count[i]++;\n          for (size_t v=0; v<N; v++) {\n            if (A[u*N+v] == 1) {\n              queue.push(v);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // Reduce the counts in parallel.\n  std::vector<int> counts(N, 0);\n  MPI_Reduce(count.data(), counts.data(), N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    return std::accumulate(counts.begin(), counts.end(), 0);\n  } else {\n    return -1;\n  }\n}",
            "int rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint numComponents = 0;\n\tif (rank == 0) {\n\t\tnumComponents = 0;\n\t}\n\n\tMPI_Bcast(&numComponents, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tstd::vector<int> counts(N);\n\tstd::vector<int> flags(N);\n\n\tint count = 0;\n\tint localCount = 0;\n\tint index = rank * N;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tcounts[i] = i;\n\t\tflags[i] = 0;\n\t}\n\n\tfor (size_t i = index; i < N; i++) {\n\t\tif (A[i] == 1) {\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tif (count > 0) {\n\t\tlocalCount = floodFill(A, index, N, counts, flags);\n\t}\n\n\tMPI_Reduce(&localCount, &numComponents, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\treturn numComponents;\n}",
            "std::vector<bool> visited(N);\n  std::vector<int> rank(N);\n\n  // set every value of rank to be the rank of the current process\n  int myRank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n  for (size_t i = 0; i < N; i++) {\n    rank[i] = myRank;\n  }\n\n  int count = 0;\n\n  /*\n  \t#pragma omp parallel for\n  \tfor (int i = 0; i < N; i++) {\n  \t\tstd::cout << \"Rank \" << myRank << \" working on row \" << i << \"\\n\";\n  \t\tfor (int j = 0; j < N; j++) {\n  \t\t\tif (A[N * i + j] == 1) {\n  \t\t\t\tcount++;\n  \t\t\t}\n  \t\t}\n  \t}\n  */\n\n  // create MPI_Comm group to communicate\n  MPI_Comm myComm;\n  MPI_Comm_split(MPI_COMM_WORLD, 0, 0, &myComm);\n\n  // create 2-D grid\n  int P;\n  MPI_Comm_size(myComm, &P);\n  int myP;\n  MPI_Comm_rank(myComm, &myP);\n  int X = sqrt(P);\n  int Y = P / X;\n  int myX = myP % X;\n  int myY = myP / X;\n  std::cout << \"Rank \" << myP << \" has X: \" << myX << \" Y: \" << myY << \"\\n\";\n\n  // get my neighbors\n  std::vector<int> neighbors;\n  if (myX > 0) {\n    neighbors.push_back(myP - 1);\n  }\n  if (myX < X - 1) {\n    neighbors.push_back(myP + 1);\n  }\n  if (myY > 0) {\n    neighbors.push_back(myP - X);\n  }\n  if (myY < Y - 1) {\n    neighbors.push_back(myP + X);\n  }\n\n  int numNeighbors = neighbors.size();\n  std::vector<int> recvCounts(numNeighbors);\n  std::vector<int> displs(numNeighbors);\n  int count = 0;\n  for (int i = 0; i < numNeighbors; i++) {\n    displs[i] = count;\n    recvCounts[i] = N / X;\n    count += recvCounts[i];\n  }\n  std::vector<int> sendcounts(numNeighbors);\n  for (int i = 0; i < numNeighbors; i++) {\n    sendcounts[i] = N / X;\n  }\n  std::vector<int> recvBuf(N / X);\n  std::vector<int> sendBuf(N / X);\n\n  // now we start working on the problem\n  for (int i = myY * N / X; i < myY * N / X + N / X; i++) {\n    // get all the nodes in this row\n    for (int j = 0; j < N / X; j++) {\n      sendBuf[j] = A[i * N + j + myX * N / X];\n    }\n    // send the data to my neighbors\n    for (int k = 0; k < numNeighbors; k++) {\n      MPI_Send(&sendBuf[0], sendcounts[k], MPI_INT, neighbors[k], 0, myComm);\n    }\n    // receive the data from my neighbors\n    for (int k = 0; k < numNeighbors; k++) {\n      MPI_Recv(&recvBuf[0], recvCounts[k], MPI_INT, neighbors[k], 0, myComm, MPI_STATUS_IGNORE);\n      for (int l = 0; l < N / X; l++) {\n        if",
            "std::vector<int> visited(N,0);\n  int count = 0;\n  for (int i = 0; i < N; ++i) {\n    if (!visited[i]) {\n      dfs(i, A, visited, N);\n      ++count;\n    }\n  }\n  return count;\n}",
            "// Your code goes here\n\n  int count = 0;\n  std::vector<bool> visited(N, false);\n\n#pragma omp parallel for reduction(+:count)\n  for(int i = 0; i < N; i++) {\n    if(!visited[i]) {\n      int j = i;\n      while(true) {\n        visited[j] = true;\n        j = 0;\n        for(int k = 0; k < N; k++) {\n          if(A[i*N + k] &&!visited[k]) {\n            j = k;\n            break;\n          }\n        }\n        if(j == 0) {\n          break;\n        }\n      }\n      count++;\n    }\n  }\n  return count;\n}",
            "int totalNumComponents = 0;\n  std::vector<int> isVisited(N);\n\n  //TODO: implement\n  return totalNumComponents;\n}",
            "int my_component_count = 0;\n    int connected_components = 0;\n\n    #pragma omp parallel\n    {\n        std::vector<int> visited(N, 0);\n        #pragma omp for\n        for(size_t i = 0; i < N; i++)\n        {\n            if(!visited[i])\n            {\n                #pragma omp atomic\n                my_component_count++;\n                #pragma omp master\n                {\n                    connected_components++;\n                }\n\n                std::queue<int> q;\n                q.push(i);\n                visited[i] = 1;\n                while(!q.empty())\n                {\n                    int u = q.front();\n                    q.pop();\n                    for(size_t j = 0; j < N; j++)\n                    {\n                        if(!visited[j] && A[u * N + j])\n                        {\n                            q.push(j);\n                            visited[j] = 1;\n                        }\n                    }\n                }\n            }\n        }\n\n        #pragma omp master\n        {\n            int temp;\n            MPI_Reduce(&my_component_count, &temp, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n            my_component_count = temp;\n            MPI_Bcast(&my_component_count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        }\n    }\n    return my_component_count;\n}",
            "int num_of_threads;\n  #pragma omp parallel\n  {\n    num_of_threads = omp_get_num_threads();\n  }\n\n  int num_of_ranks;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_of_ranks);\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int count = 0;\n  int count_per_thread = 0;\n\n  if(rank == 0) {\n    for(size_t i = 0; i < N; i++) {\n      for(size_t j = 0; j < N; j++) {\n        if(A[i*N + j] == 1) {\n          #pragma omp parallel\n          {\n            #pragma omp for\n            for(size_t k = 0; k < N; k++) {\n              if(A[j*N + k] == 1) {\n                A[i*N + k] = 1;\n              }\n            }\n            #pragma omp atomic\n            count_per_thread++;\n          }\n        }\n      }\n    }\n  }\n  else {\n    #pragma omp parallel\n    {\n      #pragma omp for\n      for(size_t i = 0; i < N; i++) {\n        for(size_t j = 0; j < N; j++) {\n          if(A[i*N + j] == 1) {\n            #pragma omp for\n            for(size_t k = 0; k < N; k++) {\n              if(A[j*N + k] == 1) {\n                A[i*N + k] = 1;\n              }\n            }\n            #pragma omp atomic\n            count_per_thread++;\n          }\n        }\n      }\n    }\n  }\n\n  MPI_Reduce(&count_per_thread, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  if(rank == 0) {\n    count -= N; //subtract the number of edges\n    count = count/2; //divide by 2 since each edge is counted twice\n  }\n\n  return count;\n}",
            "// your code goes here\n\n\treturn 0;\n}",
            "int *visited;\n\tvisited = (int *) malloc(N * sizeof(int));\n\tint count = 0;\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++)\n\t\tvisited[i] = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited[i] == 0) {\n\t\t\tcount++;\n\t\t\t#pragma omp parallel for\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tvisited[j] = 1;\n\t\t}\n\t}\n\treturn count;\n}",
            "// TODO: implement\n}",
            "// TODO: your code here\n    int componentCount = 0;\n    #pragma omp parallel for reduction(+:componentCount)\n    for(size_t i = 0; i < N; ++i){\n      for(size_t j = 0; j < N; ++j){\n        if(A[i * N + j] == 1 && i!= j){\n          componentCount++;\n        }\n      }\n    }\n    return componentCount;\n}",
            "int num_of_components = 0;\n\n    // TODO\n\n    return num_of_components;\n}",
            "std::vector<int> visited(N, 0); // 1 iff this vertex has been visited\n\tint count = 0;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (!visited[i]) {\n\t\t\tstd::vector<int> q = {i};\n\t\t\tvisited[i] = 1;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tsize_t u = q.back();\n\t\t\t\tq.pop_back();\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[u * N + j] &&!visited[j]) {\n\t\t\t\t\t\tq.push_back(j);\n\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\treturn count;\n}",
            "return 0;\n}",
            "int total_count = 0;\n  int rank_count = 0;\n  std::vector<bool> visited(N, false);\n  int rank = omp_get_num_threads();\n  int num_threads = omp_get_max_threads();\n  int count = 0;\n  for (int i = 0; i < N; ++i) {\n#pragma omp parallel\n    {\n#pragma omp for schedule(dynamic)\n      for (int j = 0; j < N; ++j) {\n        if (A[i * N + j] == 1 &&!visited[j] && i < j) {\n          bool visit = false;\n#pragma omp atomic capture\n          {\n            visit =!visited[i];\n            visited[i] = true;\n          }\n          if (visit) {\n            ++count;\n            dfs_helper(A, visited, j, N);\n          }\n        }\n      }\n    }\n  }\n  int total = 0;\n#pragma omp parallel\n  {\n    int count_t;\n#pragma omp atomic capture\n    {\n      count_t = count;\n      count = 0;\n    }\n    total_count += count_t;\n  }\n\n  MPI_Reduce(&total_count, &rank_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    printf(\"count = %d, rank_count = %d\\n\", total_count, rank_count);\n    return rank_count;\n  } else {\n    return rank_count;\n  }\n}",
            "// YOUR CODE HERE\n\n  // Check that the graph is valid\n  for (int i=0; i<N; i++)\n    for (int j=0; j<N; j++)\n      assert(A[i*N + j]==0 || A[i*N + j]==1);\n\n  // Initialize the component vector\n  std::vector<int> component(N);\n  for (int i=0; i<N; i++) component[i] = i;\n\n  #pragma omp parallel\n  {\n    // Initialize the rank's local copy of the component vector\n    #pragma omp for\n    for (int i=0; i<N; i++) component[i] = i;\n\n    #pragma omp for\n    for (int i=0; i<N; i++)\n      for (int j=i+1; j<N; j++)\n        if (A[i*N + j])\n          if (component[i]!= component[j]) {\n            if (component[i] > component[j])\n              component[i] = component[j];\n            else\n              component[j] = component[i];\n          }\n\n    // Merge the local component vector into the global\n    // component vector\n    #pragma omp single\n    {\n      #pragma omp taskloop\n      for (int i=0; i<N; i++)\n        if (component[i]!= i)\n          component[component[i]] = i;\n    }\n  }\n\n  // Count the number of components in the global component vector\n  int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for (int i=0; i<N; i++)\n    if (component[i] == i) count++;\n\n  // Send the local component vector to the root rank\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int count_local = 0;\n  if (rank == 0) {\n    for (int i=0; i<N; i++)\n      if (component[i] == i) count_local++;\n  }\n  MPI_Bcast(&count_local, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  // Add the number of components found locally on the root rank\n  if (rank!= 0) {\n    MPI_Bcast(&count_local, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  } else {\n    count += count_local;\n  }\n\n  return count;\n}",
            "// TODO: your code here\n  return 0;\n}",
            "// TODO: Your code here\n  int rank = 0;\n  int nprocs = 0;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n\n  // Divide the matrix into rows\n  // rank 0 : 0 - nRows/nprocs\n  // rank 1 : nRows/nprocs - 2*nRows/nprocs\n  //...\n  // rank (nprocs-1) : (nprocs-1)*nRows/nprocs - nRows\n  int nRows = N;\n  int nRowsPerRank = nRows / nprocs;\n  int rankOffset = rank * nRowsPerRank;\n  int nRowsLocal = std::min(nRows - rankOffset, nRowsPerRank);\n\n  // Count the number of connected components in the submatrix of rank 0\n  int countRank0 = 0;\n  if (rank == 0) {\n    std::vector<bool> visited(nRows, false);\n    for (int i = 0; i < nRows; ++i) {\n      // If not visited and adjacent to unvisited\n      if (!visited[i] && A[i*nRows + i] == 1) {\n        ++countRank0;\n\n        // Depth-first search\n        std::vector<int> neighbors;\n        neighbors.push_back(i);\n        while (!neighbors.empty()) {\n          int node = neighbors.back();\n          neighbors.pop_back();\n          visited[node] = true;\n\n          for (int j = 0; j < nRows; ++j) {\n            if (A[i*nRows + j] == 1 &&!visited[j]) {\n              neighbors.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // Count the number of connected components in the submatrix of other ranks\n  int countRankOther = 0;\n  if (rank!= 0) {\n    // All other ranks have the same number of columns\n    std::vector<bool> visited(nRowsLocal, false);\n    for (int i = 0; i < nRowsLocal; ++i) {\n      if (!visited[i] && A[rankOffset*nRows + i] == 1) {\n        ++countRankOther;\n\n        // Depth-first search\n        std::vector<int> neighbors;\n        neighbors.push_back(i);\n        while (!neighbors.empty()) {\n          int node = neighbors.back();\n          neighbors.pop_back();\n          visited[node] = true;\n\n          for (int j = 0; j < nRowsLocal; ++j) {\n            if (A[rankOffset*nRows + j] == 1 &&!visited[j]) {\n              neighbors.push_back(j);\n            }\n          }\n        }\n      }\n    }\n  }\n\n  // Gather the number of connected components from all ranks\n  int count = 0;\n  MPI_Gather(&countRank0, 1, MPI_INT, &count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    for (int i = 1; i < nprocs; ++i) {\n      MPI_Status status;\n      MPI_Recv(&count, 1, MPI_INT, i, 0, MPI_COMM_WORLD, &status);\n      count += countRankOther;\n    }\n  }\n\n  return count;\n}",
            "int world_rank;\n    int world_size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n    int* components = new int[N];\n    int* temp_components = new int[N];\n    int* sendbuf = new int[N];\n    int* recvbuf = new int[N];\n    int* count = new int[world_size];\n    int* displs = new int[world_size];\n    int* temp_displs = new int[world_size];\n    int* temp_count = new int[world_size];\n    int* temp_sendbuf = new int[N];\n    int* temp_recvbuf = new int[N];\n    // std::fill(components, components + N, 1);\n    // std::fill(sendbuf, sendbuf + N, 1);\n    int temp_count_num = 0;\n    int count_num = 0;\n    int temp_displs_num = 0;\n    int displs_num = 0;\n    std::fill(count, count + world_size, 0);\n    std::fill(displs, displs + world_size, 0);\n    std::fill(temp_count, temp_count + world_size, 0);\n    std::fill(temp_displs, temp_displs + world_size, 0);\n    std::fill(temp_components, temp_components + N, 0);\n    std::fill(temp_sendbuf, temp_sendbuf + N, 0);\n    std::fill(temp_recvbuf, temp_recvbuf + N, 0);\n    std::fill(sendbuf, sendbuf + N, 1);\n    std::fill(recvbuf, recvbuf + N, 1);\n    for (int i = 0; i < N; i++){\n        components[i] = i;\n    }\n    std::cout<<\"world size: \"<<world_size<<std::endl;\n    if (world_rank == 0){\n        // std::cout<<\"rank 0 \"<<std::endl;\n        // for (int i = 0; i < N; i++){\n        //     std::cout<<recvbuf[i]<<std::endl;\n        // }\n    }\n    // for (int i = 0; i < N; i++){\n    //     std::cout<<\"i: \"<<i<<std::endl;\n    // }\n    for (int i = 0; i < N; i++){\n        if (world_rank == 0){\n            for (int j = 0; j < N; j++){\n                if (i!= j){\n                    if (A[i * N + j]!= 0){\n                        count[j / world_size] += 1;\n                    }\n                }\n            }\n        }\n        if (world_rank!= 0){\n            for (int j = 0; j < N; j++){\n                if (i!= j){\n                    if (A[i * N + j]!= 0){\n                        temp_count[j / world_size] += 1;\n                    }\n                }\n            }\n        }\n    }\n    // std::cout<<\"count: \"<<count_num<<std::endl;\n    // for (int i = 0; i < world_size; i++){\n    //     std::cout<<count[i]<<std::endl;\n    // }\n    // std::cout<<\"temp_count: \"<<temp_count_num<<std::endl;\n    // for (int i = 0; i < world_size; i++){\n    //     std::cout<<temp_count[i]<<std::endl;\n    // }\n    for (int i = 0; i < world_size; i++){\n        displs[i] += count[i];\n        temp_displs[i] += temp_count[i];\n    }\n    if (world_rank == 0){\n        for (int i = 0; i < world_size; i++){\n            displs[i] -= 1;",
            "// Create a vector of 1s\n  std::vector<int> v(N);\n  std::fill(v.begin(), v.end(), 1);\n\n  // Replace with your implementation\n  return 0;\n}",
            "int world_size;\n\tint world_rank;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n\n\tif (world_rank == 0)\n\t\tstd::cout << \"Component Count:\\n\";\n\n\tint component_count = 0;\n\n\tif (world_size == 1) {\n\t\tstd::cout << \"1 Rank: \";\n\t\t#pragma omp parallel for reduction(+:component_count)\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tbool visited[N];\n\t\t\tfor (size_t j = 0; j < N; j++)\n\t\t\t\tvisited[j] = false;\n\t\t\tif (!visited[i]) {\n\t\t\t\tint s = i;\n\t\t\t\tvisited[i] = true;\n\t\t\t\twhile (s!= -1) {\n\t\t\t\t\tfor (size_t j = 0; j < N; j++)\n\t\t\t\t\t\tif (A[s * N + j] == 1 &&!visited[j]) {\n\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t\ts = j;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t} else\n\t\t\t\t\t\t\ts = -1;\n\t\t\t\t}\n\t\t\t\tcomponent_count++;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (world_rank == 0) {\n\t\t\tfor (int i = 1; i < world_size; i++) {\n\t\t\t\tint start_i = (i * N) / world_size;\n\t\t\t\tint end_i = (((i + 1) * N) / world_size) - 1;\n\t\t\t\tint dis[world_size];\n\t\t\t\tfor (int j = 0; j < world_size; j++) {\n\t\t\t\t\tint start_j = (j * N) / world_size;\n\t\t\t\t\tint end_j = (((j + 1) * N) / world_size) - 1;\n\t\t\t\t\tdis[j] = 0;\n\t\t\t\t\tfor (int k = start_j; k <= end_j; k++)\n\t\t\t\t\t\tif (A[k * N + start_i] == 1)\n\t\t\t\t\t\t\tdis[j]++;\n\t\t\t\t}\n\n\t\t\t\tint sender = 0;\n\t\t\t\tfor (int j = 0; j < world_size; j++)\n\t\t\t\t\tif (dis[sender] < dis[j])\n\t\t\t\t\t\tsender = j;\n\n\t\t\t\tfor (int j = start_i; j <= end_i; j++)\n\t\t\t\t\tif (A[sender * N + j] == 1) {\n\t\t\t\t\t\tfor (int k = 0; k < world_size; k++) {\n\t\t\t\t\t\t\tif (k!= sender) {\n\t\t\t\t\t\t\t\tint start_k = (k * N) / world_size;\n\t\t\t\t\t\t\t\tint end_k = (((k + 1) * N) / world_size) - 1;\n\t\t\t\t\t\t\t\tfor (int l = start_k; l <= end_k; l++)\n\t\t\t\t\t\t\t\t\tif (A[l * N + j] == 1)\n\t\t\t\t\t\t\t\t\t\tA[l * N + j] = 0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tint start_i = (world_rank * N) / world_size;\n\t\t\tint end_i = (((world_rank + 1) * N) / world_size) - 1;\n\t\t\tfor (int i = start_i; i <= end_i; i++) {",
            "int count = 0;\n\t#pragma omp parallel for reduction(+:count)\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[i * N + i] == 1) {\n\t\t\t++count;\n\t\t}\n\t}\n\treturn count;\n}",
            "int *compCnt = new int[N]; // the number of components in the subgraph for this processor\n\tint *counts = new int[N]; // the number of components in the subgraph for all processors\n\tint *displs = new int[N]; // the starting index of each processor's subgraph in the global array\n\tint *gathered = new int[N]; // array that holds the values that each processor will gather\n\t\n\t// Initialize all counts to 0\n\tfor (int i = 0; i < N; i++) {\n\t\tcompCnt[i] = 0;\n\t}\n\t\n\t// Loop through the rows of A and check if there are any 1's in each row\n\t// If there are, then the component count for that row is 1\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N + j] == 1) {\n\t\t\t\tcompCnt[i] = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Initialize displs to 0\n\tfor (int i = 0; i < N; i++) {\n\t\tdispls[i] = 0;\n\t}\n\t\n\t// Calculate the number of components in each processor's subgraph\n\tMPI_Gather(compCnt, N, MPI_INT, counts, N, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\t// Gather the counts into the global array gathered\n\tMPI_Gatherv(compCnt, N, MPI_INT, gathered, counts, displs, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\t// Loop through the values in gathered and check for connected components\n\tint count = 0;\n\tif (counts[0] > 0) {\n\t\tcount = 1;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (gathered[i*N + j] == 1) {\n\t\t\t\t\tcount++;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Send the number of components back to rank 0\n\tMPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\n\tdelete compCnt;\n\tdelete counts;\n\tdelete displs;\n\tdelete gathered;\n\t\n\treturn count;\n}",
            "int count = 0;\n  std::vector<bool> visited(N);\n  std::vector<int> components(N);\n\n  auto dfs = [&](size_t i) {\n    if (visited[i]) return;\n    visited[i] = true;\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N+j] == 1) {\n        dfs(j);\n      }\n    }\n  };\n\n  for (size_t i = 0; i < N; ++i) {\n    if (visited[i]) continue;\n    count++;\n    dfs(i);\n  }\n  return count;\n}",
            "return 0;\n}",
            "int count = 0;\n  int rank = 0;\n  int num_processes = 0;\n  int num_threads = 0;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  #pragma omp parallel\n  {\n    num_threads = omp_get_num_threads();\n    printf(\"Num threads: %d\\n\", num_threads);\n  }\n\n  std::vector<int> local_components = A;\n  std::vector<int> components = A;\n\n  #pragma omp parallel\n  {\n    int id, size;\n    id = omp_get_thread_num();\n    size = omp_get_num_threads();\n    printf(\"Thread %d of %d\\n\", id, size);\n\n    int start = rank * (int)N / num_processes;\n    int stop = (rank + 1) * (int)N / num_processes;\n\n    for (int i = start; i < stop; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          if (i!= j) {\n            int min = i;\n            int max = j;\n            if (i > j) {\n              min = j;\n              max = i;\n            }\n            for (int k = min; k <= max; k++) {\n              local_components[i * N + k] = 0;\n              local_components[k * N + i] = 0;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  MPI_Reduce(local_components.data(), components.data(), N * N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (components[i * N + j] == 1) {\n        count++;\n      }\n    }\n  }\n\n  return count;\n}",
            "int comm_size, my_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &comm_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n  // TODO: replace this code with MPI and OpenMP parallelism\n  if (my_rank == 0) {\n\n    std::vector<int> visited(N, 0);\n    int count = 0;\n\n    for (size_t i = 0; i < N; i++) {\n      if (!visited[i]) {\n        count++;\n        visited[i] = 1;\n        for (size_t j = i + 1; j < N; j++) {\n          if (A[i * N + j]) {\n            visited[j] = 1;\n          }\n        }\n      }\n    }\n\n    int sum = 0;\n    MPI_Reduce(&count, &sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n    return sum;\n  }\n\n  return 0;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // Make a copy of the graph\n  std::vector<int> B = A;\n\n  // Each process computes a set of components\n  std::set<int> components;\n  for (size_t i = rank * (N / size); i < (rank + 1) * (N / size); ++i) {\n    components.insert(i);\n  }\n\n  // Merge the component sets of each process\n  for (size_t i = 0; i < N; ++i) {\n    if (A[i]!= 0) {\n      for (size_t j = i + 1; j < N; ++j) {\n        if (A[j]!= 0 && A[j]!= i + 1 && A[j]!= i) {\n          // if (A[i] == A[j]) {\n          //   continue;\n          // }\n          components.insert(std::min(A[i], A[j]));\n        }\n      }\n    }\n  }\n\n  // Gather the sets\n  std::vector<std::set<int>> componentsList(size);\n  MPI_Gather(&components, components.size(), MPI_INT, componentsList.data(),\n             components.size(), MPI_INT, 0, MPI_COMM_WORLD);\n\n  // Print the sets\n  // for (size_t i = 0; i < componentsList.size(); ++i) {\n  //   std::cout << i << \": \";\n  //   for (auto const& comp : componentsList[i]) {\n  //     std::cout << comp << \" \";\n  //   }\n  //   std::cout << \"\\n\";\n  // }\n\n  // Merge the sets\n  std::set<int> allComponents;\n  if (rank == 0) {\n    for (auto const& compSet : componentsList) {\n      for (auto const& comp : compSet) {\n        allComponents.insert(comp);\n      }\n    }\n  }\n\n  // Print the set\n  // for (auto const& comp : allComponents) {\n  //   std::cout << comp << \" \";\n  // }\n  // std::cout << \"\\n\";\n\n  return allComponents.size();\n}",
            "// Your code here\n\t// You will need to implement an algorithm to solve this problem\n\t// You may use an extra data structure to keep track of which nodes have already been visited\n\t// You may use an extra data structure to keep track of connected components\n\t// You may use an extra data structure to keep track of the component count\n\t// You may use any STL container or library function that you would like\n\n\t// The following is only for testing your solution. Please do not modify.\n\n\t// To test your solution, we will compare your output to a correct solution computed\n\t// using a sequential version of your algorithm.\n\t// Note: the sequential version may use extra data structures\n\t//       to improve the running time of the algorithm.\n\n\t// You will receive a score equal to the number of correct outputs\n\t// divided by the number of test cases.\n\t// Note: if your algorithm is correct, but takes a long time on one of the test cases,\n\t//       you will only receive a partial credit for that test case.\n\n\tint correctCount = 0;\n\tint count = 0;\n\tint N_int = N;\n\tint **AdjacencyMatrix;\n\tint **AdjacencyMatrix_copy;\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tAdjacencyMatrix = (int **) malloc(N_int * sizeof(int *));\n\tAdjacencyMatrix_copy = (int **) malloc(N_int * sizeof(int *));\n\n\tfor (int i = 0; i < N_int; i++)\n\t{\n\t\tAdjacencyMatrix[i] = (int *) malloc(N_int * sizeof(int));\n\t\tAdjacencyMatrix_copy[i] = (int *) malloc(N_int * sizeof(int));\n\t}\n\n\tfor (int i = 0; i < N_int; i++)\n\t{\n\t\tfor (int j = 0; j < N_int; j++)\n\t\t{\n\t\t\tAdjacencyMatrix[i][j] = A[i * N_int + j];\n\t\t}\n\t}\n\n\tfor (int i = 0; i < N_int; i++)\n\t{\n\t\tfor (int j = 0; j < N_int; j++)\n\t\t{\n\t\t\tAdjacencyMatrix_copy[i][j] = AdjacencyMatrix[i][j];\n\t\t}\n\t}\n\n\tint row, col;\n\tint num_of_vertices;\n\tbool **visited;\n\tint *visited_copy;\n\tint *component_count;\n\tint *component_count_copy;\n\tint component_count_result;\n\tint rank_result;\n\n\tif (rank == 0)\n\t{\n\t\trow = 0;\n\t\tcol = 0;\n\t\tnum_of_vertices = N_int;\n\t\tvisited = (bool **) malloc(N_int * sizeof(bool *));\n\t\tvisited_copy = (int *) malloc(N_int * sizeof(int));\n\t\tcomponent_count = (int *) malloc(N_int * sizeof(int));\n\t\tcomponent_count_copy = (int *) malloc(N_int * sizeof(int));\n\n\t\tfor (int i = 0; i < N_int; i++)\n\t\t{\n\t\t\tvisited[i] = (bool *) malloc(N_int * sizeof(bool));\n\t\t\tvisited_copy[i] = 0;\n\t\t\tcomponent_count[i] = 0;\n\t\t\tcomponent_count_copy[i] = 0;\n\t\t}\n\t}\n\n\tMPI_Bcast(&row, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&col, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&num_of_vertices, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&visited_copy, N_int, MPI_",
            "int count = 0;\n\tint component = 0;\n\n\tstd::vector<int> visited(N);\n\n#pragma omp parallel\n\t{\n#pragma omp for schedule(dynamic, 10)\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (visited[i] == 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t++component;\n\t\t\tcountDFS(A, visited, i, component);\n\t\t}\n#pragma omp critical\n\t\t{\n\t\t\tcount += component;\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int *A_ptr = A.data();\n\tint *visited = new int[N];\n\n\t//initially, everything is unvisited.\n\tfor (size_t i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\tint num_components = 0;\n\n\t//traverse every element in the matrix\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A_ptr[i*N + j] == 1 && visited[i] == 0) {\n\t\t\t\t//visit this node and check if it is connected to any other nodes\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tnum_components++;\n\t\t\t\tfor (size_t k = 0; k < N; k++) {\n\t\t\t\t\tif (A_ptr[i*N + k] == 1 && visited[k] == 0) {\n\t\t\t\t\t\tvisited[k] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] visited;\n\treturn num_components;\n}",
            "std::vector<int> C(N*N, 0);\n    for(int i = 0; i < N; i++) {\n        C[i] = i;\n    }\n\n    for(int i = 0; i < N; i++) {\n        for(int j = 0; j < N; j++) {\n            if(A[i*N+j] == 1 && C[i*N+j]!= i) {\n                C[i*N+j] = C[i];\n            }\n        }\n    }\n\n    int count = 0;\n    for(int i = 0; i < N; i++) {\n        if(C[i] == i) {\n            count++;\n        }\n    }\n\n    return count;\n}",
            "// TODO: Your code here\n    return 0;\n}",
            "int* color = new int[N];\n    for (size_t i = 0; i < N; i++)\n        color[i] = 0;\n\n    int rank = 0;\n    int size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    // Number of vertices on each rank\n    int n_vertex = N / size;\n    int extra_vertex = N % size;\n    int* offsets = new int[size];\n    for (int i = 0; i < size; i++) {\n        offsets[i] = n_vertex + (i < extra_vertex? 1 : 0);\n    }\n\n    // Initialize the color array\n    for (int i = 0; i < offsets[rank]; i++) {\n        color[i] = -1;\n    }\n\n    int* count = new int[size];\n\n    // Go through each row of the adjacency matrix\n    // and set the color of each vertex if it has not been colored already.\n    for (int i = 0; i < N; i++) {\n        if (color[i] == -1) {\n            color[i] = 1;\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j] == 1 && color[j]!= 1 && color[j]!= -1) {\n                    color[j] = 1;\n                }\n            }\n        }\n    }\n\n    // Count the number of vertices in each rank\n    for (int i = 0; i < N; i++) {\n        if (color[i] == 1)\n            count[rank]++;\n    }\n\n    int c = 0;\n    MPI_Reduce(&count[rank], &c, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return c;\n}",
            "// TODO\n  int my_size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &my_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int* A_buffer;\n  int* component;\n\n  MPI_Request request;\n  int index = 0;\n  int counter = 0;\n\n  // The following code is for parallel computing in MPI\n  // It will be the first task of our team\n  if (rank == 0) {\n\n    component = (int *)malloc(N * N * sizeof(int));\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        component[i * N + j] = 0;\n      }\n    }\n\n    for (int i = 1; i < my_size; i++) {\n      MPI_Irecv(component, N * N, MPI_INT, i, 1, MPI_COMM_WORLD, &request);\n      MPI_Wait(&request, MPI_STATUS_IGNORE);\n    }\n\n    MPI_Irecv(component, N * N, MPI_INT, 0, 1, MPI_COMM_WORLD, &request);\n    MPI_Wait(&request, MPI_STATUS_IGNORE);\n\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 && component[i * N + j] == 0) {\n          counter++;\n          component[i * N + j] = 1;\n          // use openmp to do the following DFS\n          #pragma omp parallel for\n          for (int x = i - 1; x <= i + 1; x++) {\n            for (int y = j - 1; y <= j + 1; y++) {\n              if (x < 0 || y < 0 || x >= N || y >= N) continue;\n              if (component[x * N + y] == 1) continue;\n              if (A[x * N + y] == 1) {\n                component[x * N + y] = 1;\n              }\n            }\n          }\n        }\n      }\n    }\n    MPI_Send(component, N * N, MPI_INT, 0, 1, MPI_COMM_WORLD);\n  }\n\n  // The following codes are for every other rank\n  // It will be the other tasks of our team\n  else {\n\n    component = (int *)malloc(N * N * sizeof(int));\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        component[i * N + j] = 0;\n      }\n    }\n    MPI_Send(component, N * N, MPI_INT, 0, 1, MPI_COMM_WORLD);\n\n    MPI_Irecv(component, N * N, MPI_INT, 0, 1, MPI_COMM_WORLD, &request);\n    MPI_Wait(&request, MPI_STATUS_IGNORE);\n\n    for (int i = 0; i < N; i++) {\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 && component[i * N + j] == 0) {\n          counter++;\n          component[i * N + j] = 1;\n          // use openmp to do the following DFS\n          #pragma omp parallel for\n          for (int x = i - 1; x <= i + 1; x++) {\n            for (int y = j - 1; y <= j + 1; y++) {\n              if (x < 0 || y < 0 || x >= N || y >= N) continue;\n              if (component[x * N + y] == 1) continue;\n              if (A[x * N + y] == 1) {\n                component[x * N + y] = 1;",
            "int count = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        int *temp = new int[N];\n        std::fill(temp, temp + N, 0);\n        temp[i] = 1;\n\n        int *temp2 = new int[N];\n        std::fill(temp2, temp2 + N, 0);\n        temp2[i] = 1;\n\n        int *color = new int[N];\n        std::fill(color, color + N, 0);\n\n        std::stack<int> s;\n\n        for (int j = 0; j < N; ++j) {\n            if (temp[j] == 0) {\n                s.push(j);\n\n                while (!s.empty()) {\n                    int t = s.top();\n                    s.pop();\n\n                    for (int k = 0; k < N; ++k) {\n                        if (A[t*N + k] && temp[k] == 0 && temp2[k] == 0) {\n                            s.push(k);\n                            temp2[k] = 1;\n                        }\n                    }\n\n                    if (temp[t] == 0) {\n                        temp[t] = 1;\n                        ++count;\n                    }\n                }\n\n                for (int k = 0; k < N; ++k) {\n                    if (A[j*N + k] && temp[k] == 0 && temp2[k] == 0) {\n                        s.push(k);\n                        temp2[k] = 1;\n                    }\n                }\n\n                if (temp[j] == 0) {\n                    temp[j] = 1;\n                    ++count;\n                }\n\n                while (!s.empty()) {\n                    int t = s.top();\n                    s.pop();\n\n                    for (int k = 0; k < N; ++k) {\n                        if (A[t*N + k] && temp[k] == 0 && temp2[k] == 0) {\n                            s.push(k);\n                            temp2[k] = 1;\n                        }\n                    }\n\n                    if (temp[t] == 0) {\n                        temp[t] = 1;\n                        ++count;\n                    }\n                }\n            }\n        }\n    }\n\n    return count;\n}",
            "int* visited = new int[N];\n\n  for (int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n\n  int* count = new int;\n  *count = 0;\n\n  for (int i = 0; i < N; i++) {\n    if (visited[i] == 0) {\n      if (A[i] == 1) {\n        #pragma omp parallel num_threads(2)\n        {\n          #pragma omp for\n          for (int j = i; j < N; j++) {\n            if (A[j] == 1) {\n              visited[j] = 1;\n            }\n          }\n        }\n      }\n      (*count)++;\n    }\n  }\n\n  return *count;\n}",
            "if (A.size()!= N*N)\n\t{\n\t\treturn -1;\n\t}\n\n\tint mpi_size, mpi_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n\n\tif (mpi_rank == 0)\n\t{\n\t\tstd::vector<int> rank_0_counts;\n\n\t\tfor (int i = 0; i < mpi_size - 1; i++)\n\t\t{\n\t\t\tMPI_Status status;\n\t\t\tint temp;\n\t\t\tMPI_Recv(&temp, 1, MPI_INT, i + 1, 0, MPI_COMM_WORLD, &status);\n\t\t\trank_0_counts.push_back(temp);\n\t\t}\n\n\t\tint result = 0;\n\t\tfor (int i = 0; i < mpi_size - 1; i++)\n\t\t{\n\t\t\tresult += rank_0_counts[i];\n\t\t}\n\n\t\treturn result;\n\t}\n\telse\n\t{\n\t\tstd::vector<bool> seen(N, false);\n\t\tstd::vector<bool> front(N, false);\n\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif (A[i * N + j] == 1 &&!seen[j])\n\t\t\t\t{\n\t\t\t\t\tseen[j] = true;\n\t\t\t\t\tfront[j] = true;\n\t\t\t\t\tBFS(i, j, A, N, seen, front);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMPI_Send(&seen.size(), 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n}",
            "int local_component_count = 0;\n\tstd::vector<bool> visited(N, false);\n\t#pragma omp parallel for\n\tfor (int row = 0; row < N; row++) {\n\t\tif (!visited[row]) {\n\t\t\tlocal_component_count++;\n\t\t\tstd::vector<bool> is_visited(N, false);\n\t\t\tstd::queue<int> q;\n\t\t\tq.push(row);\n\t\t\tis_visited[row] = true;\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint current = q.front();\n\t\t\t\tq.pop();\n\t\t\t\tfor (int col = 0; col < N; col++) {\n\t\t\t\t\tif (!is_visited[col] && A[current*N + col]) {\n\t\t\t\t\t\tq.push(col);\n\t\t\t\t\t\tis_visited[col] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint total_component_count = 0;\n\tMPI_Reduce(&local_component_count, &total_component_count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn total_component_count;\n}",
            "int count = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn count;\n}",
            "int totalComponents = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint numComponents = 0;\n\n\t\t#pragma omp for nowait\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[i * N + i] == 0) continue;\n\n\t\t\t// Use a \"visited\" array to track which nodes we've already seen\n\t\t\t// We can do this since A is square\n\t\t\tstd::vector<bool> visited(N);\n\n\t\t\t// Start at node i, and explore all the connected nodes\n\t\t\t// Use the Breadth First Search algorithm\n\t\t\tstd::deque<int> q;\n\t\t\tq.push_back(i);\n\t\t\tvisited[i] = true;\n\n\t\t\twhile (!q.empty()) {\n\t\t\t\tint cur = q.front();\n\t\t\t\tq.pop_front();\n\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[cur * N + j]!= 0 &&!visited[j]) {\n\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\tq.push_back(j);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t++numComponents;\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\ttotalComponents += numComponents;\n\t\t}\n\t}\n\n\treturn totalComponents;\n}",
            "// TODO: your code here\n\tint count = 0;\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tif(rank == 0){\n\t\tcount = A[0];\n\t}\n\tMPI_Reduce(&count, &count, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\treturn count;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> component(N, -1);\n  int count = 0;\n  // TODO: parallelize this loop (hint: omp parallel for)\n  for (int i = 0; i < N; i++) {\n    if (!visited[i]) {\n      count++;\n      std::queue<int> q;\n      q.push(i);\n      while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        for (int u = 0; u < N; u++) {\n          if (A[v * N + u]!= 0 &&!visited[u]) {\n            visited[u] = true;\n            q.push(u);\n            component[u] = count;\n          }\n        }\n      }\n    }\n  }\n\n  // reduce component counts\n  std::vector<int> comps(N, -1);\n  MPI_Reduce(component.data(), comps.data(), N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  // print component counts\n  if (0 == MPI_COMM_WORLD.Get_rank()) {\n    std::cout << \"Component counts: \" << std::endl;\n    for (int i = 0; i < N; i++)\n      std::cout << comps[i] << \" \";\n    std::cout << std::endl;\n  }\n\n  // count the number of unique components\n  count = 0;\n  // TODO: parallelize this loop (hint: omp parallel for reduction(+:count))\n  for (int i = 0; i < N; i++)\n    if (comps[i] >= 0) count++;\n\n  return count;\n}",
            "int rank = 0, nproc = 1;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &nproc);\n  std::vector<int> visited(N);\n  std::fill(visited.begin(), visited.end(), 0);\n  int count = 0;\n  #pragma omp parallel for reduction(+:count)\n  for(size_t i = 0; i < N; ++i) {\n    if(visited[i] == 0) {\n      ++count;\n      bool done = false;\n      size_t j = 0;\n      std::queue<size_t> q;\n      q.push(i);\n      visited[i] = 1;\n      while(!done) {\n        if(q.empty()) done = true;\n        else {\n          i = q.front(); q.pop();\n          for(j = 0; j < N; ++j) {\n            if(A[i * N + j] == 1 && visited[j] == 0) {\n              q.push(j);\n              visited[j] = 1;\n            }\n          }\n        }\n      }\n    }\n  }\n  int* counts = new int[nproc];\n  counts[rank] = count;\n  MPI_Reduce(counts, counts, nproc, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return counts[0];\n}",
            "const int myRank = MPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n    // count the connected components in this block\n    std::vector<int> cc_count;\n    cc_count.resize(N, 0);\n\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (A[i * N + j] == 1) {\n                cc_count[i]++;\n                cc_count[j]++;\n            }\n        }\n    }\n\n    // compute the total number of connected components\n    int cc_count_total;\n    MPI_Reduce(&cc_count, &cc_count_total, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    // return the total number of connected components\n    return cc_count_total;\n}",
            "// TODO: Implement the algorithm\n\treturn 0;\n}",
            "std::vector<bool> visited(N, false);\n\tint count = 0;\n\n\t// Your solution goes here!\n\treturn count;\n}",
            "int count = 0;\n\tstd::vector<bool> visited(N, false);\n\n\t// Traverse the graph in parallel and count the connected components\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (visited[i]) {\n\t\t\tcontinue;\n\t\t}\n\t\tstd::queue<int> q;\n\t\tq.push(i);\n\t\tvisited[i] = true;\n\t\twhile (!q.empty()) {\n\t\t\tauto u = q.front();\n\t\t\tq.pop();\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A[N*u + j] &&!visited[j]) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcount++;\n\t}\n\n\t// Combine the counts from all the ranks\n\tint count_total = 0;\n\t#pragma omp parallel for reduction(+:count_total)\n\tfor (int i = 0; i < count; i++) {\n\t\tcount_total += count;\n\t}\n\treturn count_total;\n}",
            "// TODO: implement\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tint *temp, *recv;\n\tint *A_data = &A[0];\n\n\tif(rank == 0) {\n\t\ttemp = new int[N * N];\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\ttemp[i*N + j] = A_data[i*N + j];\n\t\t\t}\n\t\t}\n\t\trecv = new int[N * N];\n\t\tfor(int i = 1; i < size; ++i) {\n\t\t\tMPI_Recv(recv, N * N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tfor(int k = 0; k < N; ++k) {\n\t\t\t\t\tif(recv[j*N + k] > 0) {\n\t\t\t\t\t\ttemp[j*N + k] = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint count = 0;\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tif(temp[i*N + j] == 1) {\n\t\t\t\t\tcount++;\n\t\t\t\t\ttemp[i*N + j] = 0;\n\t\t\t\t\tfor(int k = 0; k < N; ++k) {\n\t\t\t\t\t\tif(temp[i*N + k] > 0) {\n\t\t\t\t\t\t\ttemp[i*N + k] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif(temp[k*N + j] > 0) {\n\t\t\t\t\t\t\ttemp[k*N + j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tif(temp[i*N + j] == 1) {\n\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tstd::cout << \"Result: \" << count << std::endl;\n\t\tdelete[] temp;\n\t\tdelete[] recv;\n\t} else {\n\t\tMPI_Send(A_data, N * N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n  return 0;\n}",
            "int num_proc, my_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n\n\tconst int NUM_THREADS = 4;\n\tomp_set_num_threads(NUM_THREADS);\n\n\tint num_components = 0;\n\tint rank_components[N];\n\tint adjacency[N][N];\n\n\t// If on rank 0, add each component to its own vector.\n\tif(my_rank == 0) {\n\t\tstd::vector<int> components[N];\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif(A[N*i + j] == 1) {\n\t\t\t\t\tcomponents[i].push_back(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Sort the components.\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tstd::sort(components[i].begin(), components[i].end());\n\t\t}\n\n\t\t// Add each component to its own vector.\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(components[i].size()!= 0) {\n\t\t\t\tnum_components++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Broadcast the number of components to all other ranks.\n\tMPI_Bcast(&num_components, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// Each rank receives its portion of the adjacency matrix and counts the number\n\t// of components.\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tMPI_Bcast(&A[N*i + j], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t\t\tadjacency[i][j] = A[N*i + j];\n\t\t}\n\n\t\trank_components[i] = 0;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(adjacency[i][j] == 1) {\n\t\t\t\trank_components[i]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Reduce the number of components across all ranks.\n\tMPI_Reduce(rank_components, NULL, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\treturn num_components;\n}",
            "std::vector<bool> seen(N);\n    int count = 0;\n#pragma omp parallel for num_threads(4)\n    for(size_t i=0; i<N; i++) {\n        if(!seen[i]) {\n            bool local = true;\n            seen[i] = true;\n            for(size_t j=i+1; j<N; j++) {\n                if(A[i*N+j] == 1) {\n                    seen[j] = true;\n                }\n            }\n#pragma omp atomic\n            count++;\n        }\n    }\n    return count;\n}",
            "// your code here\n\n\tint rank, size;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint *A_rank = new int[N*N];\n\n\tint *A_rank_flag = new int[N*N];\n\n\tint *A_rank_send = new int[N*N];\n\n\tint *A_rank_recv = new int[N*N];\n\n\tint *A_rank_recv_flag = new int[N*N];\n\n\tfor (size_t i = 0; i < N*N; i++){\n\t\tA_rank[i] = A[i];\n\t}\n\n\tint componentCount_rank = 0;\n\n\tint count = 0;\n\n\tfor (size_t i = 0; i < N; i++){\n\t\tfor (size_t j = 0; j < N; j++){\n\t\t\tif (A_rank[i*N+j] == 1){\n\t\t\t\tcomponentCount_rank++;\n\t\t\t\tA_rank_flag[i*N+j] = 1;\n\t\t\t}\n\t\t\telse{\n\t\t\t\tA_rank_flag[i*N+j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Bcast(&componentCount_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor (size_t i = 0; i < N; i++){\n\t\tfor (size_t j = 0; j < N; j++){\n\t\t\tif (A_rank[i*N+j] == 0){\n\t\t\t\tA_rank_send[i*N+j] = 0;\n\t\t\t}\n\t\t\telse{\n\t\t\t\tA_rank_send[i*N+j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tint *A_rank_recv_flag_copy = new int[N*N];\n\n\tfor (size_t i = 0; i < N; i++){\n\t\tfor (size_t j = 0; j < N; j++){\n\t\t\tA_rank_recv_flag[i*N+j] = 1;\n\t\t\tA_rank_recv_flag_copy[i*N+j] = 1;\n\t\t}\n\t}\n\n\twhile (count!= N*N){\n\n\t\tMPI_Request request;\n\t\tMPI_Status status;\n\n\t\tfor (int i = 1; i < size; i++){\n\t\t\tMPI_Send(A_rank_send, N*N, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++){\n\t\t\tMPI_Irecv(A_rank_recv, N*N, MPI_INT, i, 0, MPI_COMM_WORLD, &request);\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++){\n\t\t\tMPI_Wait(&request, &status);\n\t\t}\n\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tif (A_rank[i*N+j] == 1){\n\t\t\t\t\tif (A_rank_recv[i*N+j] == 1 && A_rank_flag[i*N+j] == 1){\n\t\t\t\t\t\tcomponentCount_rank++;\n\t\t\t\t\t\tA_rank_recv_flag[i*N+j] = 0;\n\t\t\t\t\t}\n\t\t\t\t\telse{\n\t\t\t\t\t\tA_rank_recv_flag[i*N+j] = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (int i =",
            "// Your code here\n  int num_of_components = 0;\n\n  #pragma omp parallel for shared(A, num_of_components, N)\n  for (int i = 0; i < N; i++) {\n    #pragma omp critical\n    {\n      // if (visited[i]) {\n      //   continue;\n      // }\n      // visited[i] = 1;\n      std::vector<bool> visited(N, 0);\n      std::vector<int> s;\n      s.push_back(i);\n      while (!s.empty()) {\n        int p = s.back();\n        s.pop_back();\n        if (visited[p]) {\n          continue;\n        }\n        visited[p] = 1;\n        num_of_components++;\n        for (int j = 0; j < N; j++) {\n          if (A[p * N + j]) {\n            s.push_back(j);\n          }\n        }\n      }\n    }\n  }\n  return num_of_components;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "kokkos",
        "prompt": "#include <Kokkos_Core.hpp>\n\n/* Return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix.\n   Use Kokkos to compute in parallel. Assume Kokkos has already been initialized.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(Kokkos::View<const int**> &A, size_t N, int source, int dest) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// TODO\n  // Create two views of length N that will hold the number of steps to reach each vertex:\n  // - pathLength: how many steps to reach each vertex\n  // - queue: which vertexes to check next\n  Kokkos::View<int*> pathLength(\"pathLength\", N);\n  Kokkos::View<int*> queue(\"queue\", N);\n\n  // Initialize queue with source vertexes and pathLength with 0\n  Kokkos::parallel_for(\"Init\", 1, KOKKOS_LAMBDA(const int&) {\n    pathLength(source) = 0;\n    queue(source) = 1;\n  });\n\n  // TODO\n  // Loop while queue is not empty\n  Kokkos::View<int*> queueEnd(\"queueEnd\", 1);\n  Kokkos::parallel_reduce(\"Update\", 1, KOKKOS_LAMBDA(const int&, int& end) {\n    end = 0;\n  }, Kokkos::Sum<int>(queueEnd));\n  while (queueEnd[0] > 0) {\n    Kokkos::parallel_for(\"Loop\", 1, KOKKOS_LAMBDA(const int&) {\n      // TODO\n      // Loop over all vertexes in the queue and find all unvisited neighbors\n      // - add unvisited neighbors to queue\n      // - set pathLength for unvisited neighbors to be 1 + pathLength for current vertex\n    });\n    Kokkos::parallel_reduce(\"Update\", 1, KOKKOS_LAMBDA(const int&, int& end) {\n      end = 0;\n    }, Kokkos::Sum<int>(queueEnd));\n  }\n\n  // TODO\n  // Return path length from source to dest\n  int length = 0;\n  return length;\n}",
            "// Kokkos::View<int*, Kokkos::HostSpace> dist(Kokkos::ViewAllocateWithoutInitializing(\"dist\"), N);\n  Kokkos::View<int*, Kokkos::HostSpace> dist(\"dist\", N);\n  // Kokkos::View<int*, Kokkos::HostSpace> parent(Kokkos::ViewAllocateWithoutInitializing(\"parent\"), N);\n  Kokkos::View<int*, Kokkos::HostSpace> parent(\"parent\", N);\n  // Kokkos::View<bool*, Kokkos::HostSpace> visited(Kokkos::ViewAllocateWithoutInitializing(\"visited\"), N);\n  Kokkos::View<bool*, Kokkos::HostSpace> visited(\"visited\", N);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n    KOKKOS_LAMBDA (int i) {\n    dist(i) = 0;\n    parent(i) = -1;\n    visited(i) = false;\n  });\n\n  Kokkos::single(Kokkos::DefaultHostExecutionSpace(),\n    KOKKOS_LAMBDA (int i) {\n    dist(source) = 0;\n    parent(source) = -1;\n    visited(source) = true;\n  });\n\n  bool found = false;\n\n  int count = 0;\n  while(!found) {\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n      KOKKOS_LAMBDA (int i) {\n      for(int j=0; j<N; j++) {\n        if(A(i, j) == 1 && dist(i)!= -1) {\n          if(dist(j) == -1 || dist(i) + 1 < dist(j)) {\n            dist(j) = dist(i) + 1;\n            parent(j) = i;\n          }\n        }\n      }\n    });\n    // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n    //   KOKKOS_LAMBDA (int i) {\n    //   if(parent(i)!= -1) {\n    //     printf(\"i = %d, parent = %d\\n\", i, parent(i));\n    //   }\n    // });\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>(0, N),\n      KOKKOS_LAMBDA (int i) {\n      if(parent(i)!= -1 &&!visited(i)) {\n        visited(i) = true;\n      }\n    });\n    if(visited(dest)) {\n      found = true;\n    }\n    // printf(\"count %d\\n\", count++);\n    Kokkos::DefaultHostExecutionSpace::fence();\n  }\n\n  Kokkos::single(Kokkos::DefaultHostExecutionSpace(),\n    KOKKOS_LAMBDA (int i) {\n    printf(\"parent of %d is %d\\n\", dest, parent(dest));\n  });\n\n  Kokkos::single(Kokkos::DefaultHostExecutionSpace(),\n    KOKKOS_LAMBDA (int i) {\n    int curr = dest;\n    while(curr!= source) {\n      printf(\"curr = %d, parent = %d\\n\", curr, parent(curr));\n      curr = parent(curr);\n    }\n  });\n\n  Kokkos::single(Kokkos::DefaultHostExecutionSpace(),\n    KOKKOS_LAMBDA (int i) {\n    printf(\"final dist = %d\\n\", dist(dest));\n  });\n\n  int result = dist(dest);\n\n  // deallocate views\n  // dist.~View();\n  // parent.~View();\n  // visited.~View();\n\n  return result;\n}",
            "using Kokkos::View;\n\tusing Kokkos::All;\n\tusing Kokkos::RangePolicy;\n\tusing Kokkos::parallel_for;\n\tusing Kokkos::atomic_fetch_add;\n\n\tKokkos::DefaultExecutionSpace kokkosExecSpace;\n\tKokkos::DefaultHostExecutionSpace kokkosHostExecSpace;\n\n\t// TODO: Your code goes here\n\t\n\treturn -1; // replace this line\n}",
            "/* Create a Kokkos View for the result.\n\t   Initialize all values to -1.\n\t   Use the Kokkos BreadthFirstSearch graph algorithm to find the shortest path length.\n\t   If the path length to the destination is not found, return -1.\n\t   Otherwise, return the path length.\n\t*/\n\n\tKokkos::View<int*> result(\"Result\", N);\n\tKokkos::deep_copy(result, -1);\n\n\ttypedef Kokkos::View<int*> graph_type;\n\ttypedef typename graph_type::HostMirror host_type;\n\tgraph_type graph(\"graph\", N);\n\thost_type host_graph = Kokkos::create_mirror_view(graph);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::HostSpace::execution_space>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\t\t\t\t\t\t host_graph(i) = i;\n\t\t\t\t\t\t });\n\tKokkos::deep_copy(graph, host_graph);\n\n\tint found = -1;\n\tKokkos::BreadthFirstSearch<Kokkos::DefaultExecutionSpace, graph_type> bfs(graph, N);\n\tfound = bfs.bfs(source, result, dest);\n\n\thost_type host_result = Kokkos::create_mirror_view(result);\n\tKokkos::deep_copy(host_result, result);\n\n\tif (found == -1) return -1;\n\n\tint length = 0;\n\tfor (int i = dest; i!= source; i = host_result(i)) length++;\n\treturn length;\n}",
            "// TODO: Implement\n    return 0;\n}",
            "/*\n  Your code here!\n  */\n  return -1;\n}",
            "// TODO\n\treturn 0;\n}",
            "using namespace Kokkos;\n\n\t// TODO: Your code here\n\tint *distances = new int [N];\n\tfor (int i=0; i<N; i++) {\n\t\tdistances[i] = -1;\n\t}\n\tdistances[source] = 0;\n\n\tView<int*,Kokkos::HostSpace> distances_view(\"distances\", N);\n\tparallel_for (N, KOKKOS_LAMBDA (const int& i) {\n\t\tdistances_view(i) = distances[i];\n\t});\n\n\tint *queue = new int [N];\n\tint front = 0, rear = 0;\n\tqueue[rear++] = source;\n\twhile (front < rear) {\n\t\tint curr = queue[front++];\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tif (A(curr, i) == 1 && distances_view(i) == -1) {\n\t\t\t\tdistances_view(i) = distances_view(curr) + 1;\n\t\t\t\tqueue[rear++] = i;\n\t\t\t}\n\t\t}\n\t}\n\n\tView<int*,Kokkos::HostSpace> distances_view_copy(\"distances\", N);\n\tdeep_copy(distances_view_copy, distances_view);\n\tint result = distances_view_copy(dest);\n\tdelete[] distances;\n\tdelete[] queue;\n\n\treturn result;\n}",
            "// TODO: Your code here\n\n\treturn -1;\n}",
            "Kokkos::View<int*> dist(Kokkos::ViewAllocateWithoutInitializing(\"dist\"), N);\n\n\tKokkos::parallel_for(\"Init dist\", Kokkos::RangePolicy<Kokkos::Serial>(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tdist(i) = A(source, i);\n\t});\n\n\tfor (int i = 0; i < N; i++) {\n\t\tKokkos::parallel_for(\"Spl\", Kokkos::RangePolicy<Kokkos::Serial>(0, N), KOKKOS_LAMBDA(const int j) {\n\t\t\tif (A(j, source)!= -1) {\n\t\t\t\tdist(j) = std::min(dist(j), dist(source) + A(j, source));\n\t\t\t}\n\t\t});\n\t}\n\n\treturn dist(dest);\n}",
            "int maxPathLength = -1;\n\tKokkos::View<int*> d(\"distance\", N);\n\tKokkos::View<int*> p(\"parent\", N);\n\tfor (int i=0; i<N; i++) {\n\t\td(i) = -1;\n\t\tp(i) = -1;\n\t}\n\n\tKokkos::parallel_for(\"bfs\", N, KOKKOS_LAMBDA(const int i) {\n\t\tif (i==source) {\n\t\t\td(i) = 0;\n\t\t\tp(i) = i;\n\t\t} else {\n\t\t\td(i) = -1;\n\t\t\tp(i) = -1;\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(\"bfs\", N, KOKKOS_LAMBDA(const int i) {\n\t\tfor (int j=0; j<N; j++) {\n\t\t\tif (A(i, j) && d(i)>=0 && (d(j)<0 || d(j)>d(i)+1)) {\n\t\t\t\td(j) = d(i) + 1;\n\t\t\t\tp(j) = i;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tif (d(dest) >= 0) {\n\t\tint cur = dest;\n\t\twhile (cur!= source) {\n\t\t\tif (cur < 0) {\n\t\t\t\tmaxPathLength = -1;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tmaxPathLength = d(cur);\n\t\t\t\tcur = p(cur);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn maxPathLength;\n}",
            "/*\n\t   Your code goes here - replace the following \n\t   dummy return value with your implementation.\n\t*/\n\tKokkos::View<int*> dist(\"dist\", N);\n\tKokkos::View<bool*> is_visited(\"is_visited\", N);\n\t\n\tKokkos::deep_copy(dist, -1);\n\tKokkos::deep_copy(is_visited, 0);\n\t\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (const int i) {\n\t\tif(A(source, i))\n\t\t\tdist(i) = 1;\n\t});\n\t\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (const int i) {\n\t\tis_visited(i) = 1;\n\t});\n\t\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA (const int i) {\n\t\tint cur = i;\n\t\tint cur_dist = dist(i);\n\t\tint new_dist = 0;\n\t\twhile(cur!= -1 && cur!= source) {\n\t\t\tnew_dist = cur_dist + 1;\n\t\t\tif(cur == dest) {\n\t\t\t\tdist(i) = new_dist;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tif(A(cur, j) && new_dist < dist(j)) {\n\t\t\t\t\tdist(j) = new_dist;\n\t\t\t\t\tis_visited(j) = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tfor(int j = 0; j < N; ++j) {\n\t\t\t\tif(A(cur, j) && dist(j) == new_dist && is_visited(j)) {\n\t\t\t\t\tcur = j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\tcur_dist = dist(cur);\n\t\t}\n\t});\n\t\n\treturn dist(dest);\n}",
            "typedef Kokkos::View<int*> view_type;\n\tview_type dist(\"dist\", N);\n\tKokkos::parallel_for(\"init\", 1, KOKKOS_LAMBDA(const int) {\n\t\tdist(source) = 0;\n\t});\n\n\twhile (true) {\n\t\tint changed = 0;\n\t\tKokkos::parallel_reduce(\"step\", 1, KOKKOS_LAMBDA(const int, int& ch) {\n\t\t\tint local_changed = 0;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tint old = dist(j);\n\t\t\t\t\tdist(j) = std::min(dist(j), dist(i) + A(i, j));\n\t\t\t\t\tif (dist(j)!= old) {\n\t\t\t\t\t\tlocal_changed = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tch += local_changed;\n\t\t}, Kokkos::Sum<int>(changed));\n\t\tif (changed == 0) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tKokkos::View<int, Kokkos::HostSpace> dist_host = Kokkos::create_mirror_view(dist);\n\tKokkos::deep_copy(dist_host, dist);\n\treturn dist_host(dest);\n}",
            "/* \n     * TODO: Implement me \n     * Hints:\n     * - Use Kokkos::View to create a 1D array of size N with default value 0\n     * - Use Kokkos::parallel_for to parallelize the loop\n     * - Use Kokkos::atomic_compare_exchange to atomically update the value of a View\n     * - Kokkos::atomic_compare_exchange takes the following form:\n     *     atomic_compare_exchange(expected_val, new_val);\n     *   where expected_val is a const reference to a View, and new_val is a View (it will be updated in place)\n     */\n}",
            "// Create a View with the same shape as the input matrix but using a layout that is more cache-friendly for kokkos\n    Kokkos::View<int**, Kokkos::LayoutLeft, Kokkos::HostSpace> dist(\"dist\", N, N);\n\n    // Use the Kokkos initialization method to set all values of dist to INF\n    // See: https://kokkos.readthedocs.io/en/latest/api/kokkos/initialize.html#kokkos-initialization\n    Kokkos::deep_copy(dist, std::numeric_limits<int>::max());\n\n    // Set the distance from source to source to 0\n    dist(source, source) = 0;\n\n    // Compute the shortest paths to each vertex from the source vertex\n    Kokkos::parallel_for(\n        \"BFS\",\n        Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Static>>(0, N),\n        KOKKOS_LAMBDA(int u) {\n            // Loop over all neighbors of u\n            for (int v = 0; v < N; ++v) {\n                // If the distance from the source to v is shorter than the previously computed distance, update the distance\n                if (A(u, v) && dist(u, v) > dist(u, source) + 1) {\n                    dist(u, v) = dist(u, source) + 1;\n                }\n            }\n        });\n\n    // Sync to make sure that the result is computed\n    Kokkos::fence();\n\n    // Return the distance from source to dest\n    return dist(dest, source);\n}",
            "// Allocate a Kokkos view for the distance matrix.\n\t// Distance is the length of the shortest path from the source.\n\t// The starting value is the shortest path to reach the source itself.\n\t// If the source is the destination, the value is 0.\n\t// If the source is unreachable, the value is -1.\n\tKokkos::View<int**> distance(\"distance\", N, N);\n\tKokkos::parallel_for(\"shortestPathLength1\", N, KOKKOS_LAMBDA (const int& i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\tdistance(i, j) = 0;\n\t\t\t} else if (i == source) {\n\t\t\t\tdistance(i, j) = A(i, j);\n\t\t\t} else {\n\t\t\t\tdistance(i, j) = -1;\n\t\t\t}\n\t\t}\n\t});\n\n\t// Update the distance matrix.\n\tKokkos::parallel_for(\"shortestPathLength2\", N, KOKKOS_LAMBDA (const int& k) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (distance(i, j) < 0 && i!= j && A(i, k) > 0 && distance(k, j) > 0) {\n\t\t\t\t\tdistance(i, j) = distance(k, j) + A(i, k);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\tint distanceToDest = 0;\n\tKokkos::parallel_reduce(\"shortestPathLength3\", N, KOKKOS_LAMBDA (const int& i, int& value) {\n\t\tif (distance(i, dest) > 0 && distance(i, dest) < distanceToDest) {\n\t\t\tdistanceToDest = distance(i, dest);\n\t\t}\n\t}, distanceToDest);\n\treturn distanceToDest;\n}",
            "// Initialize BFS queue\n\tKokkos::View<int*> bfsQueue(\"bfsQueue\", N);\n\tKokkos::View<int*> bfsQueueLength(\"bfsQueueLength\", 1);\n\tbfsQueueLength(0) = 0;\n\n\tKokkos::View<int*> distances(\"distances\", N);\n\tKokkos::View<bool*> distancesInitialized(\"distancesInitialized\", N);\n\tKokkos::deep_copy(distancesInitialized, false);\n\tKokkos::deep_copy(distances, -1);\n\tKokkos::deep_copy(bfsQueue, -1);\n\tbfsQueue(0) = source;\n\tbfsQueueLength(0) = 1;\n\tdistances(source) = 0;\n\tdistancesInitialized(source) = true;\n\n\t// Iterate BFS queue\n\tKokkos::fence();\n\twhile (bfsQueueLength(0) > 0) {\n\t\tint levelLength = bfsQueueLength(0);\n\t\tfor (int i = 0; i < levelLength; i++) {\n\t\t\t// Pop vertex from the queue\n\t\t\tint vertex = bfsQueue(i);\n\t\t\tbfsQueue(i) = -1;\n\n\t\t\t// Check all neighbors\n\t\t\tfor (int neighbor = 0; neighbor < N; neighbor++) {\n\t\t\t\t// If neighbor is not connected to vertex, continue\n\t\t\t\tif (A(vertex, neighbor)!= 1) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// If neighbor already has distance set, continue\n\t\t\t\tif (distancesInitialized(neighbor) == true) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t// Otherwise, set distance to vertex's distance + 1, and append to queue\n\t\t\t\tdistances(neighbor) = distances(vertex) + 1;\n\t\t\t\tbfsQueue(bfsQueueLength(0)) = neighbor;\n\t\t\t\tbfsQueueLength(0) += 1;\n\t\t\t\tdistancesInitialized(neighbor) = true;\n\t\t\t}\n\t\t}\n\n\t\t// Reduce BFS queue\n\t\tKokkos::fence();\n\t\tint nextLevelLength = 0;\n\t\tfor (int i = 0; i < levelLength; i++) {\n\t\t\tif (bfsQueue(i)!= -1) {\n\t\t\t\tbfsQueue(nextLevelLength) = bfsQueue(i);\n\t\t\t\tnextLevelLength += 1;\n\t\t\t}\n\t\t}\n\t\tbfsQueueLength(0) = nextLevelLength;\n\t\tKokkos::fence();\n\t}\n\n\treturn distances(dest);\n}",
            "// TODO: implement\n\n  return 0;\n}",
            "using DeviceType = Kokkos::Device<Kokkos::Cuda, Kokkos::CudaSpace>;\n\n  Kokkos::View<int*> distances(\"distances\", N);\n  Kokkos::View<bool*> processed(\"processed\", N);\n\n  // Set all distances to infinity and mark all nodes as unprocessed.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int node) {\n    distances(node) = std::numeric_limits<int>::max();\n    processed(node) = false;\n  });\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int node) {\n    if (node == source) {\n      distances(node) = 0;\n      processed(node) = true;\n    }\n  });\n\n  // Run Dijkstra's algorithm until all nodes have been processed.\n  bool all_nodes_processed = false;\n  while (!all_nodes_processed) {\n    all_nodes_processed = true;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int node) {\n      if (processed(node)) return;\n\n      // Look at all the neighbors of the current node.\n      for (int neighbor = 0; neighbor < N; ++neighbor) {\n        if (A(node, neighbor) == 0) continue;\n\n        int alternate_distance = distances(node) + 1;\n        if (alternate_distance < distances(neighbor)) {\n          distances(neighbor) = alternate_distance;\n          processed(neighbor) = false;\n          all_nodes_processed = false;\n        }\n      }\n    });\n\n    // Mark this node as processed.\n    Kokkos::single(Kokkos::PerThread(DeviceType()), [&] () {\n      processed(source) = true;\n    });\n  }\n\n  return distances(dest);\n}",
            "using namespace Kokkos;\n  typedef View<int*,HostSpace> HostViewInt;\n  typedef View<int**,HostSpace> HostViewInt2;\n  typedef View<int**,DeviceSpace> DeviceViewInt2;\n  HostViewInt2 A_h(A);\n  HostViewInt2 B_h(N);\n  DeviceViewInt2 B_d(N);\n\n  for (int i=0; i<N; i++) {\n    B_h(i,i) = 0;\n    for (int j=i+1; j<N; j++) {\n      B_h(i,j) = B_h(j,i) = A_h(i,j);\n    }\n  }\n\n  B_d = B_h;\n\n  int *s_d = (int*)malloc(N*sizeof(int));\n  for (int i=0; i<N; i++) s_d[i] = 0;\n  s_d[source] = 1;\n\n  typedef View<int*,DeviceSpace> DeviceViewInt;\n  DeviceViewInt s_dv(s_d, N);\n\n  typedef RangePolicy<DeviceSpace> RangePolicyType;\n  typedef Cuda exec_space;\n  typedef Kokkos::Schedule<Kokkos::ScheduleType::Dynamic> ScheduleType;\n  typedef Kokkos::UniformMemoryPool<Kokkos::Cuda> MemoryPoolType;\n  typedef Kokkos::MemoryTraits<Kokkos::Unmanaged> MemoryTraitsType;\n  typedef Kokkos::MemoryPool<MemoryPoolType> MemoryPoolHandleType;\n\n  // CUDA malloc can sometimes fail, so we need to make sure that we keep trying until it succeeds.\n  bool success = false;\n  while (!success) {\n    try {\n      MemoryPoolHandleType memoryPool(Kokkos::CudaSpace::required_allocation_size(N*sizeof(int)));\n      auto m_dv = Kokkos::create_mirror_view_and_copy(Kokkos::CudaSpace(), s_dv);\n      Kokkos::parallel_for(\"shortestPathLength\",\n                           RangePolicyType(exec_space(), 0, N),\n                           KOKKOS_LAMBDA(const int &i) {\n                             s_dv[i] = 0;\n                           });\n      Kokkos::fence();\n      Kokkos::parallel_for(\"shortestPathLength\",\n                           RangePolicyType(exec_space(), 0, N),\n                           KOKKOS_LAMBDA(const int &i) {\n                             int minDistance = 1<<30;\n                             for (int j=0; j<N; j++) {\n                               if (B_d(i, j)) {\n                                 minDistance = min(minDistance, s_dv[j]);\n                               }\n                             }\n                             s_dv[i] = minDistance + 1;\n                           });\n      Kokkos::fence();\n      Kokkos::deep_copy(m_dv, s_dv);\n      Kokkos::fence();\n      success = true;\n    } catch(const Kokkos::Cuda::bad_alloc &e) {\n      std::cerr << e.what() << std::endl;\n    }\n  }\n  free(s_d);\n  return m_dv(dest)-1;\n}",
            "// Your code here\n}",
            "if (source == dest) return 0;\n\n    // TODO: use Kokkos to implement shortest path\n    int length = -1;\n    int* prev = (int*)malloc(sizeof(int)*N);\n    int* queue = (int*)malloc(sizeof(int)*N);\n\n    prev[source] = -1;\n    queue[0] = source;\n\n    int cur_len = 0;\n    int count = 1;\n    while (count > 0) {\n        for (int i = 0; i < count; i++) {\n            int cur = queue[i];\n            for (int j = 0; j < N; j++) {\n                if (A(cur, j) == 1 && prev[j] == -1) {\n                    prev[j] = cur;\n                    queue[count] = j;\n                    count++;\n                }\n            }\n        }\n        cur_len++;\n        count = 0;\n    }\n\n    int cur = dest;\n    while (prev[cur]!= -1) {\n        cur = prev[cur];\n    }\n\n    length = cur_len;\n\n    free(prev);\n    free(queue);\n\n    return length;\n}",
            "// Fill in this function\n\t// If you need to use the value of a variable in Kokkos, use the Kokkos::HostSpace::execution_space()\n\t// namespace to get the correct execution space.\n\t// Example:\n\t//  int x = A(0,0); // x is 0\n\t//  int y = Kokkos::HostSpace::execution_space::shfl(x, 0);\n\n\treturn -1; // should never reach this point\n}",
            "Kokkos::View<bool**> visited(\"visited\", N, N);\n  Kokkos::View<int**> dist(\"dist\", N, N);\n\n  Kokkos::parallel_for(\"init_visited\", Kokkos::RangePolicy<Kokkos::MDRangePolicy<Kokkos::Rank<2>>>(Kokkos::MDRangePolicy<Kokkos::Rank<2>>::all(visited.extent(0), visited.extent(1))))(\n  [=] (const int i, const int j) {\n    visited(i,j) = false;\n  });\n\n  Kokkos::parallel_for(\"init_dist\", Kokkos::RangePolicy<Kokkos::MDRangePolicy<Kokkos::Rank<2>>>(Kokkos::MDRangePolicy<Kokkos::Rank<2>>::all(dist.extent(0), dist.extent(1))))(\n  [=] (const int i, const int j) {\n    dist(i,j) = 0;\n  });\n\n  Kokkos::parallel_for(\"breadthFirstSearch\", Kokkos::RangePolicy<Kokkos::MDRangePolicy<Kokkos::Rank<2>>>(Kokkos::MDRangePolicy<Kokkos::Rank<2>>::all(dist.extent(0), dist.extent(1))))(\n  [=] (const int i, const int j) {\n    if(i == source) {\n      dist(i,j) = 1;\n      visited(i,j) = true;\n    }\n  });\n\n  int shortestPath = 0;\n  bool finished = false;\n  while(!finished) {\n    Kokkos::parallel_for(\"bfs_outer_loop\", Kokkos::RangePolicy<Kokkos::MDRangePolicy<Kokkos::Rank<2>>>(Kokkos::MDRangePolicy<Kokkos::Rank<2>>::all(dist.extent(0), dist.extent(1))))(\n    [=] (const int i, const int j) {\n      if(!visited(i,j)) {\n        for(int k = 0; k < dist.extent(0); ++k) {\n          if(visited(k,j) && A(i, k) == 1 && dist(k,j) + 1 > dist(i,j)) {\n            dist(i,j) = dist(k,j) + 1;\n            visited(i,j) = true;\n            break;\n          }\n        }\n      }\n    });\n\n    shortestPath = 0;\n    Kokkos::parallel_reduce(\"reduce\", Kokkos::RangePolicy<Kokkos::MDRangePolicy<Kokkos::Rank<2>>>(Kokkos::MDRangePolicy<Kokkos::Rank<2>>::all(dist.extent(0), dist.extent(1))))(\n    [=] (const int i, const int j, int& pathLength) {\n      if(i == dest) {\n        pathLength = std::max(pathLength, dist(i,j));\n      }\n    },\n    Kokkos::RangePolicy<Kokkos::ReducePolicy<Kokkos::Rank<2>>>(Kokkos::ReducePolicy<Kokkos::Rank<2>>::keep(shortestPath)));\n\n    if(shortestPath > 0) {\n      finished = true;\n    }\n  }\n\n  return shortestPath;\n}",
            "// TODO\n\n    int answer = 0;\n    // return answer;\n\n    return answer;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\n  // Allocate host array to hold the results\n  int* host_results = new int[N];\n\n  // Create device array and fill it with the results\n  Kokkos::View<int*, Kokkos::MemoryTraits<Kokkos::Unmanaged> > results(\"Results\", N);\n  Kokkos::parallel_for(\"shortest_path_length\", Kokkos::RangePolicy<ExecutionSpace>(0, N), KOKKOS_LAMBDA (const int i) {\n      results(i) = shortestPathLength(A, N, source, dest, i);\n  });\n\n  // Copy back the results to the host\n  Kokkos::deep_copy(host_results, results);\n\n  // Find the minimum\n  int min = host_results[0];\n  for (int i = 1; i < N; i++) {\n    if (host_results[i] < min) {\n      min = host_results[i];\n    }\n  }\n\n  delete[] host_results;\n\n  return min;\n}",
            "// TODO: Your code goes here\n  return 0;\n}",
            "// TODO: Your code here\n\n\n\treturn -1;\n}",
            "// TODO: Implement me!\n\tKokkos::View<int*> D(\"distance\", N);\n\tKokkos::View<int*> P(\"previous\", N);\n\tKokkos::parallel_for(\"initialize\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tD(i) = -1;\n\t\tP(i) = -1;\n\t});\n\tKokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(i == j) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(A(i, j) == 1) {\n\t\t\t\tD(j) = 1;\n\t\t\t\tP(j) = i;\n\t\t\t}\n\t\t}\n\t});\n\tint current = source;\n\tint len = 0;\n\twhile(current!= -1) {\n\t\tint prev = P(current);\n\t\tif(prev == dest) {\n\t\t\treturn len;\n\t\t}\n\t\tcurrent = prev;\n\t\tlen++;\n\t}\n\treturn -1;\n}",
            "// TODO: Your code here\n\tint *s=new int[N+1];\n\tint *q=new int[N+1];\n\tfor(int i=0;i<N+1;i++)\n\t{\n\t\ts[i]=0;\n\t\tq[i]=0;\n\t}\n\ts[source]=1;\n\tq[source]=1;\n\tint n=0;\n\twhile(n<N)\n\t{\n\t\tfor(int i=0;i<N;i++)\n\t\t{\n\t\t\tif(s[i]==1 && q[i]==0)\n\t\t\t{\n\t\t\t\tq[i]=1;\n\t\t\t\tfor(int j=0;j<N;j++)\n\t\t\t\t{\n\t\t\t\t\tif(A(i,j)==1)\n\t\t\t\t\t{\n\t\t\t\t\t\tif(s[j]==0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\ts[j]=1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i=0;i<N;i++)\n\t\t{\n\t\t\tif(s[i]==1 && q[i]==1)\n\t\t\t{\n\t\t\t\ts[i]=0;\n\t\t\t\tq[i]=0;\n\t\t\t\tn++;\n\t\t\t}\n\t\t}\n\t}\n\tint ans=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tif(s[i]==1 && i==dest)\n\t\t{\n\t\t\tans++;\n\t\t}\n\t}\n\treturn ans;\n}",
            "// You may wish to use Kokkos's dynamic scheduling features to enable parallelism on the CPU\n  // Kokkos::parallel_for(...)\n  return 1;\n}",
            "typedef Kokkos::View<int*> view_type;\n  int result = -1;\n  view_type dist(Kokkos::ViewAllocateWithoutInitializing(\"dist\"), N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(int src) {\n    dist(src) = (src == source)? 0 : INT_MAX;\n  });\n\n  // TODO: Implement BFS in Kokkos to find shortest path length\n\n  return result;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\n\t// Compute the shortest path from source to dest in A.\n\n\t// Create a 1D view to hold the shortest path length.\n\tKokkos::View<int*, execution_space> shortestPath(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"shortestPath\"), N);\n\n\t// Initialize shortestPath so that shortestPath[i] is the shortest path from source to i.\n\n\n\t// Use a parallel_for loop to compute shortestPath[i] from shortestPath[A[i][j]] for all j.\n\n\t// Return shortestPath[dest].\n\n\treturn 0;\n}",
            "using Matrix = Kokkos::View<const int**>;\n  using Queue = Kokkos::View<int*>;\n  using Map = typename Kokkos::RangePolicy<>::member_type;\n\n  // TODO: use Kokkos to parallelize this algorithm.\n  // You may not use any other library to parallelize this algorithm.\n  // You may not use global variables (e.g., static variables) in this function.\n\n  // 1. Use Kokkos::parallel_for to initialize the BFS queue.\n  //\n  // 2. Use Kokkos::parallel_reduce to perform BFS in the queue.\n  //    Note that this should be a reduction to a single value, the length of the shortest path.\n  //\n  // 3. Return the length of the shortest path from source to dest.\n\n  // TODO: add a BFS queue.\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n    KOKKOS_LAMBDA(const int& i) {\n      // TODO: initialize the BFS queue.\n    });\n\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(0, N),\n    KOKKOS_LAMBDA(const int& i, int& sum) {\n      // TODO: Perform BFS.\n      // sum is used to accumulate the length of the shortest path from source to dest.\n      // Use atomic add to update the sum.\n    },\n    Kokkos::Sum<int>(sum));\n\n  // TODO: return the length of the shortest path from source to dest.\n}",
            "Kokkos::View<int*> queue(\"queue\", N);\n\tKokkos::View<int*> level(\"level\", N);\n\tKokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::deep_copy(queue, -1);\n\tKokkos::deep_copy(level, -1);\n\tKokkos::deep_copy(visited, false);\n\n\tKokkos::View<int*> level_host(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"level_host\"), N);\n\tKokkos::View<bool*> visited_host(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"visited_host\"), N);\n\n\tKokkos::parallel_for(\n\t\t\"breadthFirstSearch\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tif (i == source) {\n\t\t\t\tqueue[0] = i;\n\t\t\t\tlevel[i] = 0;\n\t\t\t\tvisited[i] = true;\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::parallel_for(\n\t\t\"breadthFirstSearch\",\n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA(const int level_idx) {\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (queue[i] == -1) break;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(queue[i], j)) {\n\t\t\t\t\t\tif (!visited[j]) {\n\t\t\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\t\t\tlevel[j] = level_idx + 1;\n\t\t\t\t\t\t\tqueue[i+1] = j;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t);\n\n\tKokkos::deep_copy(level_host, level);\n\tKokkos::deep_copy(visited_host, visited);\n\n\tint shortestPath = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (visited_host[i]) {\n\t\t\tshortestPath = i;\n\t\t}\n\t}\n\n\treturn level_host[shortestPath];\n}",
            "using Kokkos::Experimental::UniqueToken;\n\tusing Kokkos::Experimental::UniqueTokenScope;\n\n\t// The kokkos view where the path lengths are stored.\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> path_lengths(\"path_lengths\", N);\n\t// The kokkos view where the token scope of the atomic is stored.\n\tKokkos::View<UniqueTokenScope*, Kokkos::LayoutRight, Kokkos::HostSpace> token_scope(\"token_scope\", N);\n\n\t// Create the token scope on the CPU\n\tUniqueTokenScope* token_scope_host = new UniqueTokenScope[N];\n\n\t// Copy the token scope on to the device\n\tKokkos::deep_copy(token_scope, token_scope_host);\n\n\t// Create the atomic that uses the token scope\n\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::UniqueTokenScope> token_type(token_scope, 0);\n\tKokkos::Experimental::UniqueToken<Kokkos::Experimental::UniqueTokenScope>* token = &token_type;\n\n\t// The kernel that does the work.\n\tKokkos::parallel_for(\"shortest_path_length_parallel_for\", N, KOKKOS_LAMBDA(int i) {\n\t\tif (i == source) {\n\t\t\tpath_lengths(i) = 0;\n\t\t\ttoken->acquire();\n\t\t}\n\t\telse {\n\t\t\tpath_lengths(i) = INT_MAX;\n\t\t}\n\t});\n\n\t// The loop over all the nodes\n\tfor (int i = 0; i < N; ++i) {\n\t\t// Check to see if the node is a leaf node and is a destination\n\t\tif (A(dest, i) == 0 && i!= source) {\n\t\t\tbreak;\n\t\t}\n\n\t\t// We are still interested in this destination\n\t\tif (i!= source) {\n\t\t\t// Loop over all the other nodes\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t// If the node is not a leaf node and we haven't already computed the path\n\t\t\t\t// length to it then compute it.\n\t\t\t\tif (A(i, j)!= 0 && path_lengths(j) > path_lengths(i) + A(i, j)) {\n\t\t\t\t\t// If we are able to get the token\n\t\t\t\t\tif (token->try_acquire()) {\n\t\t\t\t\t\tpath_lengths(j) = path_lengths(i) + A(i, j);\n\t\t\t\t\t\ttoken->release();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint shortest_path_length = path_lengths(dest);\n\n\t// Clean up\n\tdelete[] token_scope_host;\n\n\treturn shortest_path_length;\n}",
            "// TODO: write code here\n  Kokkos::View<int**> p(\"p\", N, N);\n  Kokkos::View<int*> d(\"d\", N);\n  Kokkos::View<int*> color(\"c\", N);\n  int* d_p = p.data();\n  int* d_d = d.data();\n  int* d_color = color.data();\n\n  auto parallel_for_range = Kokkos::RangePolicy<Kokkos::Cuda>(0, N);\n  auto parallel_for_work = Kokkos::TeamPolicy<Kokkos::Cuda>(1, N);\n  Kokkos::parallel_for(\"init\", parallel_for_range, KOKKOS_LAMBDA(const int& i) {\n      p(i, i) = 0;\n      d(i) = 0;\n      color(i) = 0;\n  });\n\n  Kokkos::parallel_for(\"shortestPath\", parallel_for_work, KOKKOS_LAMBDA(const Kokkos::TeamPolicy<Kokkos::Cuda>::member_type& team) {\n      int tid = team.league_rank() * team.team_size() + team.team_rank();\n\n      for (int i = tid; i < N; i += team.team_size() * team.league_size()) {\n          int m = 0;\n          int m1 = 0;\n          int m2 = 0;\n          int m3 = 0;\n          int m4 = 0;\n\n          if (color(i) == 0 && i!= source) {\n              d(i) = -1;\n              m = 1;\n          }\n\n          if (A(source, i) == 1) {\n              p(source, i) = 1;\n              d(i) = 1;\n              m1 = 1;\n          }\n\n          if (A(dest, i) == 1) {\n              p(dest, i) = 1;\n              d(i) = 1;\n              m2 = 1;\n          }\n\n          for (int j = 0; j < N; j++) {\n              if (A(i, j) == 1) {\n                  p(i, j) = 1;\n                  m3 = 1;\n              }\n          }\n\n          if (i == dest) {\n              p(i, dest) = 1;\n              d(i) = 1;\n              m4 = 1;\n          }\n\n          if (i == source) {\n              color(i) = 1;\n          }\n\n          Kokkos::single(Kokkos::PerTeam(team), [&] () {\n              if (m == 1 || m1 == 1 || m2 == 1 || m3 == 1 || m4 == 1) {\n                  color(i) = 1;\n              }\n          });\n      }\n  });\n\n  Kokkos::parallel_for(\"main\", parallel_for_range, KOKKOS_LAMBDA(const int& i) {\n      for (int j = 0; j < N; j++) {\n          for (int k = 0; k < N; k++) {\n              if (A(j, k) == 1) {\n                  if (p(j, i) == 1 && p(i, k) == 1) {\n                      p(j, k) = 1;\n                  }\n              }\n          }\n      }\n  });\n\n  Kokkos::parallel_for(\"update\", parallel_for_range, KOKKOS_LAMBDA(const int& i) {\n      int m = 0;\n\n      for (int j = 0; j < N; j++) {\n          if (p(j, i) == 1) {\n              m = 1;\n              d(j) = d(j) + d(i);\n          }\n      }\n\n      Kokkos::single(Kokkos::PerTeam(team), [&] () {\n          if (m == 1) {\n              color(i) = 1;\n          }\n      });",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<bool*> s(\"s\", N);\n  Kokkos::View<int*> prev(\"prev\", N);\n  Kokkos::View<int*> Q(\"Q\", N);\n  Kokkos::View<int*> temp(\"temp\", 1);\n\n  int *d = dist.data();\n  bool *q = s.data();\n  int *p = prev.data();\n  int *t = temp.data();\n\n  // Initialize\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    d[i] = 0;\n    q[i] = false;\n    p[i] = -1;\n  });\n\n  // BFS\n  int Qend = 0;\n  int Qstart = 0;\n\n  d[source] = 0;\n  q[source] = true;\n  Q[Qend++] = source;\n\n  while (Qstart < Qend) {\n    int u = Q[Qstart++];\n    for (int i = 0; i < N; i++) {\n      if (A(u, i) == 1 && q[i] == false) {\n        d[i] = d[u] + 1;\n        q[i] = true;\n        p[i] = u;\n        Q[Qend++] = i;\n      }\n    }\n  }\n\n  int* path = new int[N];\n  int depth = 0;\n  int cur = dest;\n  while (cur!= -1) {\n    path[depth++] = cur;\n    cur = p[cur];\n  }\n\n  // print the path\n  std::cout << \"Path: [\";\n  for (int i = depth - 1; i >= 0; i--) {\n    std::cout << path[i];\n    if (i!= 0) std::cout << \", \";\n  }\n  std::cout << \"]\\n\";\n\n  delete[] path;\n\n  Kokkos::deep_copy(t, &Qend);\n  return d[dest];\n}",
            "if (source == dest) {\n    return 0;\n  }\n\n  Kokkos::View<int*> distances(\"distances\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int i) {\n    if (i == source) {\n      distances(i) = 0;\n    } else {\n      distances(i) = INT_MAX;\n    }\n  });\n\n  Kokkos::fence();\n\n  // TODO: your code here\n  // you can use Kokkos's parallel_for and parallel_reduce algorithms\n\n  return distances(dest);\n}",
            "// TODO\n}",
            "using view_t = Kokkos::View<const int**>;\n\tview_t A_host;\n\tKokkos::deep_copy(A_host, A);\n\n\t// TODO: your code here\n\treturn 0;\n}",
            "Kokkos::View<bool**> visited(\"visited\", N, N);\n  Kokkos::View<int**> distance(\"distance\", N, N);\n\n  Kokkos::parallel_for(\n    \"init\", N, KOKKOS_LAMBDA(int i) {\n      for (int j = 0; j < N; ++j) {\n        visited(i,j) = false;\n        distance(i,j) = -1;\n      }\n    }\n  );\n  Kokkos::fence();\n\n  Kokkos::parallel_for(\n    \"bfs\", N, KOKKOS_LAMBDA(int i) {\n      visited(i, source) = true;\n      distance(i, source) = 0;\n    }\n  );\n  Kokkos::fence();\n\n  Kokkos::parallel_for(\n    \"bfs\", N, KOKKOS_LAMBDA(int k) {\n      for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n          if (!visited(i,j) && distance(i,k)!= -1 && distance(k,j)!= -1) {\n            visited(i,j) = true;\n            distance(i,j) = distance(i,k) + distance(k,j);\n          }\n        }\n      }\n    }\n  );\n  Kokkos::fence();\n\n  int length = -1;\n  for (int i = 0; i < N; ++i) {\n    if (visited(i, dest)) {\n      length = distance(i, dest);\n      break;\n    }\n  }\n\n  return length;\n}",
            "int pathLength = -1;\n\n\tKokkos::parallel_for(\"shortestPathLength\", Kokkos::RangePolicy<Kokkos::ExecPolicy::vec>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t\tif (i == source) {\n\t\t\tpathLength = 0;\n\t\t}\n\t});\n\n\tKokkos::parallel_for(\"shortestPathLength\", Kokkos::RangePolicy<Kokkos::ExecPolicy::vec>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t\tif (i == source) {\n\t\t\tpathLength = 0;\n\t\t}\n\t});\n\n\t// TODO: Implement the shortest path algorithm\n\tKokkos::parallel_for(\"shortestPathLength\", Kokkos::RangePolicy<Kokkos::ExecPolicy::vec>(0, N), KOKKOS_LAMBDA(const int& i) {\n\t\tif (i == source) {\n\t\t\tpathLength = 0;\n\t\t}\n\t});\n\n\n\tKokkos::fence();\n\n\treturn pathLength;\n}",
            "// TODO: replace this with your own implementation\n  return -1;\n}",
            "// TODO: Your code goes here!\n\n  return 0;\n}",
            "// TODO\n  return 0;\n}",
            "/* TODO: Fill this in with your solution! */\n\n  /* Some hints:\n   * - Remember that a 2D Kokkos View is laid out in memory as if it were a linear array,\n   *   so accessing a(i,j) in Kokkos corresponds to a(i*N + j) in C.\n   * - Look up the documentation for the Kokkos::parallel_for and Kokkos::RangePolicy classes\n   *   to figure out how to parallelize over subsets of the array.\n   */\n\n  return 0;\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\n  // Add Kokkos parallel for loop here\n  //\n  // You'll need to use the following data structures:\n  //    1. A Kokkos view to store the shortest paths.\n  //    2. A Kokkos view to store whether a node has been visited.\n  //    3. A Kokkos view to store the number of shortest paths that have been found.\n\n  // Shortest paths from source to all other nodes\n  Kokkos::View<int*> shortestPath(Kokkos::ViewAllocateWithoutInitializing(\"shortest path\"), N);\n\n  // Whether or not a node has been visited\n  Kokkos::View<bool*> visited(Kokkos::ViewAllocateWithoutInitializing(\"visited\"), N);\n\n  // Number of shortest paths\n  Kokkos::View<int> n(Kokkos::ViewAllocateWithoutInitializing(\"n\"), 1);\n\n  // initialize the shortest path and visited arrays\n  Kokkos::deep_copy(shortestPath, 99999999);\n  Kokkos::deep_copy(visited, false);\n  Kokkos::deep_copy(n, 0);\n\n  // set the initial shortest path\n  Kokkos::parallel_for(Kokkos::RangePolicy<ExecutionSpace>(0, N), [=] (int i) {\n    if(i == source)\n      shortestPath(i) = 0;\n    else\n      shortestPath(i) = -1;\n  });\n\n  // Kokkos parallel for loop here\n\n  // copy the shortest path and visited arrays back to the host\n  int* h_shortestPath = (int*)malloc(sizeof(int)*N);\n  bool* h_visited = (bool*)malloc(sizeof(bool)*N);\n  int h_n;\n  Kokkos::deep_copy(h_shortestPath, shortestPath);\n  Kokkos::deep_copy(h_visited, visited);\n  Kokkos::deep_copy(h_n, n);\n\n  // find the shortest path between the source and dest\n  int length = -1;\n  for(int i=0; i<N; i++){\n    if(h_shortestPath[dest]!= -1){\n      length = h_shortestPath[dest];\n      break;\n    }\n    if(h_visited[dest]){\n      break;\n    }\n    for(int j=0; j<N; j++){\n      if(!h_visited[j] && h_shortestPath[j]!=-1 && h_shortestPath[j] < h_shortestPath[dest]){\n        h_shortestPath[dest] = h_shortestPath[j];\n        h_visited[dest] = true;\n      }\n    }\n  }\n\n  // clean up\n  free(h_shortestPath);\n  free(h_visited);\n\n  return length;\n}",
            "// Your code goes here!\n  return -1;\n}",
            "using namespace Kokkos;\n\n  // TODO: Fill this in.\n  return 0;\n}",
            "using exec_space = Kokkos::DefaultExecutionSpace;\n\n\tusing distance_view_t = Kokkos::View<int*, exec_space>;\n\tusing bool_view_t = Kokkos::View<bool*, exec_space>;\n\n\tdistance_view_t distance(\"distance\", N);\n\tbool_view_t processed(\"processed\", N);\n\n\tKokkos::deep_copy(processed, false);\n\tKokkos::deep_copy(distance, std::numeric_limits<int>::max());\n\tdistance(source) = 0;\n\n\tKokkos::fence();\n\n\tKokkos::parallel_for(N, [=](int i) {\n\t\tif (i == source) {\n\t\t\tprocessed(i) = true;\n\t\t}\n\t});\n\n\tKokkos::fence();\n\n\tbool changed;\n\tdo {\n\t\tchanged = false;\n\t\tKokkos::parallel_for(N, [=](int i) {\n\t\t\tif (processed(i)) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A(i, j) == 1) {\n\t\t\t\t\t\tint alt = distance(i) + 1;\n\t\t\t\t\t\tif (alt < distance(j)) {\n\t\t\t\t\t\t\tdistance(j) = alt;\n\t\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} while (changed);\n\n\tKokkos::fence();\n\n\treturn distance(dest);\n}",
            "// Replace this with your code\n  Kokkos::View<int**> distances(\"distances\", N, N);\n  Kokkos::deep_copy(distances, -1);\n\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic>>>(0, N),\n      KOKKOS_LAMBDA(const int& i) {\n        // Set up the initial work.\n        if (A(i, source)!= 0) {\n          distances(i, 0) = 1;\n        }\n      });\n\n  Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic>>>(0, N),\n      KOKKOS_LAMBDA(const int& i) {\n        // Each team is responsible for a single level.\n        for (int j = 1; j < N; ++j) {\n          // Visit each vertex in the graph and see if they can find a new path to the next level.\n          for (int k = 0; k < N; ++k) {\n            // If you can reach vertex k from vertex i in j - 1 steps, can you reach it in j steps?\n            if (distances(i, j - 1)!= -1 && A(k, i)!= 0) {\n              // If so, set the distance and the next step.\n              if (distances(k, j - 1) == -1 || distances(k, j - 1) > distances(i, j - 1) + 1) {\n                distances(k, j) = distances(i, j - 1) + 1;\n              }\n            }\n          }\n        }\n      });\n\n  // Check if the destination can be reached from the source.\n  if (distances(dest, N - 1) == -1) {\n    // It cannot.\n    return -1;\n  }\n\n  // It can.\n  return distances(dest, N - 1);\n}",
            "Kokkos::View<int**> dist(\"Dist\", N, N);\n    Kokkos::View<int*> queue(\"Queue\", N);\n    Kokkos::View<bool*> visited(\"Visited\", N);\n    auto dist_h = Kokkos::create_mirror_view(dist);\n    auto queue_h = Kokkos::create_mirror_view(queue);\n    auto visited_h = Kokkos::create_mirror_view(visited);\n    Kokkos::deep_copy(queue_h, source);\n    Kokkos::deep_copy(visited_h, 0);\n    Kokkos::deep_copy(dist_h, 0);\n    Kokkos::deep_copy(dist, dist_h);\n    dist(source, source) = 0;\n    auto queue_begin = queue_h.data();\n    auto queue_end = queue_h.data() + N;\n    auto visited_begin = visited_h.data();\n    auto visited_end = visited_h.data() + N;\n\n    int pathLength = 0;\n    while (queue_begin!= queue_end) {\n        auto i = *queue_begin;\n        queue_begin++;\n        for (int j = 0; j < N; j++) {\n            if (A(i, j) == 0) continue;\n            if (visited_h[j]) continue;\n            visited_h[j] = true;\n            dist_h(j, j) = dist_h(i, i) + 1;\n            queue_h(j) = j;\n        }\n    }\n    Kokkos::deep_copy(visited, visited_h);\n    Kokkos::deep_copy(dist, dist_h);\n\n    pathLength = dist(dest, dest);\n\n    return pathLength;\n}",
            "typedef Kokkos::View<int**> view_t;\n  view_t dist_view(\"distance_view\", N, N);\n  Kokkos::deep_copy(dist_view, -1);\n  Kokkos::deep_copy(dist_view(source, dest), 0);\n  Kokkos::fence();\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N), [&](int i) {\n    for (int k = 0; k < N; k++) {\n      for (int j = 0; j < N; j++) {\n        if (A(i, k) > 0 && dist_view(k, j) >= 0) {\n          dist_view(i, j) = 1 + dist_view(k, j);\n        }\n      }\n    }\n  });\n\n  int ans = -1;\n  for (int i = 0; i < N; i++) {\n    ans = std::max(ans, dist_view(source, i));\n  }\n  return ans;\n}",
            "// Your code here\n  const Kokkos::View<int*> lengths(\"lengths\", N);\n  Kokkos::parallel_for(\"BFS\", Kokkos::RangePolicy<>(0, N), KOKKOS_LAMBDA(const int& src) {\n    lengths(src) = -1;\n  });\n\n  // TODO:\n  // 1. Modify lengths to have the shortest length from source to each vertex\n  // 2. Modify the return statement below to return the value in lengths[dest]\n  return 0;\n}",
            "using view_t = Kokkos::View<int**>;\n  view_t levels(\"levels\", N, N);\n  view_t done(\"done\", N, N);\n\n  // Setup level and done views\n  Kokkos::parallel_for(\"setup\", Kokkos::RangePolicy<>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      for (int j = 0; j < N; ++j) {\n        levels(i, j) = 0;\n        done(i, j) = 0;\n      }\n    }\n  );\n\n  int length = 0;\n\n  // Perform BFS\n  // The parallel_for lambda function must be a struct in order for Kokkos to capture the\n  // variables 'levels', 'done', and 'length'.\n  struct {\n    view_t levels;\n    view_t done;\n    int length;\n\n    KOKKOS_INLINE_FUNCTION\n    void operator()(const int& i) const {\n      if (i == source) {\n        levels(i, 0) = 1;\n      }\n\n      for (int level = 0; level <= length; ++level) {\n        for (int j = 0; j < N; ++j) {\n          if (levels(i, level) == 1 && done(i, level) == 0) {\n            done(i, level) = 1;\n            if (j == dest) {\n              // Store final level\n              length = level;\n            }\n            else {\n              for (int k = 0; k < N; ++k) {\n                if (A(i, k) == 1 && done(k, level + 1) == 0) {\n                  levels(k, level + 1) = 1;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  } bfs;\n\n  bfs.levels = levels;\n  bfs.done = done;\n  bfs.length = length;\n\n  Kokkos::parallel_for(\"BFS\", Kokkos::RangePolicy<>(0, N), bfs);\n\n  return length;\n}",
            "// TODO\n\treturn 0;\n}",
            "// TODO: use Kokkos to compute the length of the shortest path\n\n\treturn -1;\n}",
            "int num_threads = omp_get_max_threads();\n\n    /* TODO: Your code goes here */\n    if (source == dest) return 0;\n\n    Kokkos::View<int**, Kokkos::LayoutRight, Kokkos::HostSpace, Kokkos::MemoryUnmanaged> dist(\"dist\", N, num_threads);\n    Kokkos::View<bool**, Kokkos::LayoutRight, Kokkos::HostSpace, Kokkos::MemoryUnmanaged> visited(\"visited\", N, num_threads);\n    Kokkos::View<int**, Kokkos::LayoutRight, Kokkos::HostSpace, Kokkos::MemoryUnmanaged> predecessor(\"predecessor\", N, num_threads);\n\n    Kokkos::parallel_for(\"Initialize memory\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < num_threads; j++) {\n            visited(i, j) = false;\n            dist(i, j) = INF;\n            predecessor(i, j) = INF;\n        }\n    });\n\n    Kokkos::parallel_for(\"Initialize memory\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, num_threads), KOKKOS_LAMBDA(const int i) {\n        dist(source, i) = 0;\n    });\n\n    bool has_changed = true;\n    Kokkos::View<bool, Kokkos::LayoutRight, Kokkos::HostSpace, Kokkos::MemoryUnmanaged> has_changed_view(\"has_changed\", num_threads);\n    while (has_changed) {\n        has_changed = false;\n        Kokkos::parallel_for(\"BFS loop\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, N), KOKKOS_LAMBDA(const int i) {\n            for (int j = 0; j < num_threads; j++) {\n                if (!visited(i, j) && dist(i, j)!= INF) {\n                    visited(i, j) = true;\n                    for (int k = 0; k < N; k++) {\n                        if (!visited(k, j) && dist(k, j) > dist(i, j) + A(i, k)) {\n                            dist(k, j) = dist(i, j) + A(i, k);\n                            predecessor(k, j) = i;\n                        }\n                    }\n                }\n            }\n        });\n        Kokkos::parallel_for(\"Check for changes\", Kokkos::RangePolicy<Kokkos::OpenMP>(0, num_threads), KOKKOS_LAMBDA(const int i) {\n            has_changed_view(i) = false;\n            for (int j = 0; j < N; j++) {\n                if (dist(j, i) < dist(dest, i)) {\n                    dist(j, i) = dist(dest, i);\n                    predecessor(j, i) = predecessor(dest, i);\n                    has_changed_view(i) = true;\n                }\n            }\n        });\n        has_changed = Kokkos::any(has_changed_view);\n    }\n\n    return dist(dest, 0);\n}",
            "using ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\tusing TeamPolicy = Kokkos::TeamPolicy<ExecutionSpace>;\n\tusing MemberType = typename TeamPolicy::member_type;\n\tKokkos::View<int*, ExecutionSpace> path_lengths(\"path_lengths\", N);\n\n\tint team_size = 256;\n\tint team_num = ceil(N/team_size);\n\n\t// Kokkos parallel code:\n\tKokkos::parallel_for(\"shortestPathLength\", TeamPolicy(team_num, team_size), KOKKOS_LAMBDA(MemberType& thread){\n\t\tint start_index = thread.league_rank()*team_size;\n\t\tint end_index = KOKKOS_MIN(start_index+team_size, N);\n\t\tfor (int i = start_index; i < end_index; i++) {\n\t\t\tif (i == source) {\n\t\t\t\tpath_lengths(i) = 0;\n\t\t\t} else {\n\t\t\t\tpath_lengths(i) = -1;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint num_updated = 0;\n\twhile (num_updated < N) {\n\t\tnum_updated = 0;\n\t\tKokkos::parallel_for(\"shortestPathLength\", TeamPolicy(team_num, team_size), KOKKOS_LAMBDA(MemberType& thread){\n\t\t\tint start_index = thread.league_rank()*team_size;\n\t\t\tint end_index = KOKKOS_MIN(start_index+team_size, N);\n\t\t\tfor (int i = start_index; i < end_index; i++) {\n\t\t\t\tif (path_lengths(i) == -1) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j) == 1 && path_lengths(j) < 0) {\n\t\t\t\t\t\tpath_lengths(j) = path_lengths(i) + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\t\tKokkos::parallel_for(\"shortestPathLength\", TeamPolicy(team_num, team_size), KOKKOS_LAMBDA(MemberType& thread){\n\t\t\tint start_index = thread.league_rank()*team_size;\n\t\t\tint end_index = KOKKOS_MIN(start_index+team_size, N);\n\t\t\tfor (int i = start_index; i < end_index; i++) {\n\t\t\t\tif (path_lengths(i) >= 0) {\n\t\t\t\t\tnum_updated += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\t}\n\n\tint shortest_path_length = -1;\n\tKokkos::parallel_reduce(\"shortestPathLength\", Kokkos::RangePolicy<ExecutionSpace>(0, N), KOKKOS_LAMBDA(int i, int& local_shortest_path_length){\n\t\tif (path_lengths(i) >= 0 && (shortest_path_length == -1 || path_lengths(i) < shortest_path_length)) {\n\t\t\tshortest_path_length = path_lengths(i);\n\t\t}\n\t}, Kokkos::Min<int>());\n\tKokkos::fence();\n\treturn shortest_path_length;\n}",
            "// your code here\n\tint *pathLength = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tpathLength[i] = -1;\n\t}\n\tpathLength[source] = 0;\n\tKokkos::View<bool**> seen(\"seen\", N, N);\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tseen(i, j) = false;\n\t\t}\n\t}\n\tKokkos::View<int**> minPathLength(\"minPathLength\", N, N);\n\tKokkos::deep_copy(minPathLength, pathLength);\n\tKokkos::View<int*> currentPathLength(\"currentPathLength\", N);\n\tKokkos::deep_copy(currentPathLength, pathLength);\n\tKokkos::View<int*> currentPath(\"currentPath\", N);\n\tKokkos::deep_copy(currentPath, pathLength);\n\tKokkos::View<int*> nextPath(\"nextPath\", N);\n\tKokkos::deep_copy(nextPath, pathLength);\n\n\t// Fill currentPathLength and currentPath here\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A(source, i) == 1) {\n\t\t\tcurrentPathLength[i] = 1;\n\t\t\tcurrentPath[i] = source;\n\t\t}\n\t}\n\tint maxPathLength = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (currentPathLength[i] > maxPathLength) {\n\t\t\tmaxPathLength = currentPathLength[i];\n\t\t}\n\t}\n\n\t// Perform BFS here\n\tfor (int distance = 0; distance < maxPathLength; distance++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (currentPathLength[j] == distance && A(j, i) == 1) {\n\t\t\t\t\tif (currentPathLength[i] < distance + 1) {\n\t\t\t\t\t\tcurrentPathLength[i] = distance + 1;\n\t\t\t\t\t\tcurrentPath[i] = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (int i = 0; i < N; i++) {\n\t\tif (currentPathLength[i] > maxPathLength) {\n\t\t\tmaxPathLength = currentPathLength[i];\n\t\t}\n\t}\n\n\t// Perform Dijkstra here\n\tfor (int i = 0; i < N; i++) {\n\t\tif (minPathLength(source, i) == -1) {\n\t\t\tminPathLength(source, i) = currentPathLength[i];\n\t\t\tnextPath[i] = currentPath[i];\n\t\t} else {\n\t\t\tif (currentPathLength[i] < minPathLength(source, i)) {\n\t\t\t\tminPathLength(source, i) = currentPathLength[i];\n\t\t\t\tnextPath[i] = currentPath[i];\n\t\t\t}\n\t\t}\n\t}\n\twhile (seen(source, dest) == false) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tseen(source, i) = true;\n\t\t\tseen(i, dest) = true;\n\t\t\tif (nextPath[i]!= -1) {\n\t\t\t\tif (minPathLength(source, nextPath[i])!= -1) {\n\t\t\t\t\tif (minPathLength(source, nextPath[i]) + 1 < minPathLength(source, i)) {\n\t\t\t\t\t\tminPathLength(source, i) = minPathLength(source, nextPath[i]) + 1;\n\t\t\t\t\t\tseen(nextPath[i], dest) = false;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint",
            "typedef Kokkos::View<int**> view_type;\n  typedef Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace> range_policy_type;\n  typedef Kokkos::MDRangePolicy<Kokkos::Rank<2>,Kokkos::DefaultHostExecutionSpace> mdrange_policy_type;\n\n  int num_shortest_paths = 0;\n\n  // TODO: Initialize the matrix B with N rows and N columns. Set B[i][j] = 0 for all i, j.\n  view_type B(\"B\", N, N);\n  // TODO: Run the code below to initialize the matrix B\n  Kokkos::parallel_for(\"InitializeB\", range_policy_type(0, N),\n\t  KOKKOS_LAMBDA(int i) {\n\t\t  for(int j = 0; j < N; ++j){\n\t\t\t  B(i, j) = 0;\n\t\t  }\n\t  });\n\n  // TODO: Run the code below to update B to find the shortest path from source to dest\n  // 1) B[source][source] = 0\n  B(source, source) = 0;\n  // 2) B[source][i] = A[source][i] for all i!= source\n  Kokkos::parallel_for(\"UpdateB\", range_policy_type(0, N),\n\t  KOKKOS_LAMBDA(int i) {\n\t\t  if (i!= source) {\n\t\t\t  B(source, i) = A(source, i);\n\t\t  }\n\t  });\n  // 3) B[i][j] = A[i][j] + min(B[i][k] + B[k][j]) for all i!= source, j!= source, k!= source\n  Kokkos::parallel_for(\"UpdateB\", mdrange_policy_type({0,0}, {N,N}, {1,1}),\n\t  KOKKOS_LAMBDA(int i, int j) {\n\t\t  if (i!= source && j!= source) {\n\t\t\t  int min = INT_MAX;\n\t\t\t  for(int k = 0; k < N; ++k){\n\t\t\t\t  if(B(i, k) + B(k, j) < min){\n\t\t\t\t\t  min = B(i, k) + B(k, j);\n\t\t\t\t  }\n\t\t\t  }\n\t\t\t  B(i, j) = min + A(i, j);\n\t\t  }\n\t  });\n\n  num_shortest_paths = B(source, dest);\n\n  return num_shortest_paths;\n}",
            "// Initialize the distance vector:\n  // d[i] = the shortest distance from source to node i, or -1 if not reachable\n  Kokkos::View<int*> d(\"distance vector\", N);\n  Kokkos::deep_copy(d, -1);\n  d(source) = 0; // Initial distance to source is 0\n\n  // Kokkos::parallel_for to compute the shortest distances:\n  //\n  // For each iteration of the loop, the value of d is updated according to the\n  // following recurrence:\n  // d[i] = min(d[i], d[j] + A[j][i])\n  // where j is a neighbor of i, and d[j] > 0\n  //\n  // This is the \"Dijkstra's algorithm\" for shortest paths, using a binary heap.\n  Kokkos::parallel_for(\n      \"shortest paths\",\n      Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Schedule<Kokkos::Dynamic> > >(0, N, 1),\n      KOKKOS_LAMBDA (const int& i) {\n        // TODO: implement\n      });\n\n  Kokkos::fence();\n  return d(dest);\n}",
            "// TODO: use Kokkos to implement BFS\n\n\n\treturn 0;\n}",
            "Kokkos::View<int*> V(\"V\", N);\n\tKokkos::parallel_for(\"Initialization\", N, KOKKOS_LAMBDA(const size_t i) {\n\t\tV(i) = 0;\n\t});\n\tint count = 1;\n\tKokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const size_t i) {\n\t\tif (i!= source) {\n\t\t\tV(i) = -1;\n\t\t}\n\t});\n\tV(source) = 0;\n\tint *V_host = new int[N];\n\tKokkos::deep_copy(V_host, V);\n\twhile (count <= N) {\n\t\tcount = 0;\n\t\tKokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const size_t i) {\n\t\t\tif (V_host[i] >= 0) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(i, j) && (V_host[j] < 0)) {\n\t\t\t\t\t\tV_host[j] = V_host[i] + 1;\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\tdelete[] V_host;\n\treturn V(dest);\n}",
            "Kokkos::View<int**> dist(\"dist\", N, N);\n  Kokkos::View<int**> pred(\"pred\", N, N);\n  Kokkos::View<int**> color(\"color\", N, N);\n\n  // Initialize dist to -1\n  Kokkos::deep_copy(dist, -1);\n  // Initialize color to 0\n  Kokkos::deep_copy(color, 0);\n\n  Kokkos::deep_copy(dist(source, source), 0);\n\n  Kokkos::parallel_for(\"breadth_first_search_color\", N, KOKKOS_LAMBDA (const int& i) {\n    Kokkos::parallel_for(\"breadth_first_search_color2\", N, KOKKOS_LAMBDA (const int& j) {\n      pred(i, j) = -1;\n    });\n  });\n\n  Kokkos::parallel_for(\"breadth_first_search\", N, KOKKOS_LAMBDA (const int& i) {\n    Kokkos::parallel_for(\"breadth_first_search2\", N, KOKKOS_LAMBDA (const int& j) {\n      if (j == source && i == source) {\n        color(i, j) = 1;\n      } else if (A(i, j) == 1) {\n        color(i, j) = 1;\n      }\n    });\n  });\n\n  Kokkos::parallel_for(\"breadth_first_search_loop\", N, KOKKOS_LAMBDA (const int& i) {\n    Kokkos::parallel_for(\"breadth_first_search_loop2\", N, KOKKOS_LAMBDA (const int& j) {\n      if (color(i, j) == 1) {\n        if (j!= source) {\n          dist(i, j) = dist(i, source) + 1;\n        }\n\n        Kokkos::parallel_for(\"breadth_first_search_loop3\", N, KOKKOS_LAMBDA (const int& k) {\n          if (A(j, k) == 1) {\n            if (i == k) {\n              pred(i, k) = j;\n            } else {\n              color(i, k) = 1;\n            }\n          }\n        });\n      }\n    });\n  });\n\n  // This block should compute the shortest path length from source to dest.\n\n\n  return 0;\n}",
            "/* BEGIN CODE SKELETON */\n\n  // 1. Declare and initialize Kokkos variables\n  Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> next(\"next\", N);\n  Kokkos::View<bool*> in_queue(\"in_queue\", N);\n  Kokkos::View<int*> queue(\"queue\", N);\n  int queue_head = -1;\n  int queue_tail = -1;\n\n  // 2. Initialize variables\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      dist(i) = -1;\n      next(i) = -1;\n      in_queue(i) = false;\n    });\n\n  Kokkos::fence();\n\n  // 3. Setup the queue\n  queue(++queue_tail) = source;\n  in_queue(source) = true;\n  dist(source) = 0;\n\n  Kokkos::fence();\n\n  // 4. BFS Loop\n  while (queue_head!= queue_tail) {\n    int u = queue(++queue_head);\n    Kokkos::parallel_for(Kokkos::RangePolicy<>(0, N),\n      KOKKOS_LAMBDA(int v) {\n        // 4a. Skip if v has been visited\n        if (dist(v)!= -1) {\n          return;\n        }\n\n        // 4b. Skip if there is no edge from u to v\n        if (A(u, v) == 0) {\n          return;\n        }\n\n        // 4c. Set the distance of v to be one more than that of u\n        dist(v) = dist(u) + 1;\n        next(v) = u;\n\n        // 4d. Add v to the queue if it's not already there\n        if (!in_queue(v)) {\n          queue(++queue_tail) = v;\n          in_queue(v) = true;\n        }\n      });\n\n    // 4e. Remove u from the queue\n    in_queue(u) = false;\n  }\n\n  Kokkos::fence();\n\n  // 5. Return the length of the shortest path\n  int shortestPathLength = dist(dest);\n  return shortestPathLength;\n\n  /* END CODE SKELETON */\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n\tKokkos::View<int*> prev(\"prev\", N);\n\tKokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::View<bool*> in_queue(\"in_queue\", N);\n\tKokkos::View<int*> queue(\"queue\", N);\n\n\tKokkos::deep_copy(dist, -1);\n\tKokkos::deep_copy(prev, -1);\n\tKokkos::deep_copy(visited, 0);\n\tKokkos::deep_copy(in_queue, 0);\n\tKokkos::deep_copy(queue, 0);\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<>(0, N), [=](int v) {\n\t\tint cur_min = -1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited(i)) continue;\n\t\t\tint new_distance = dist(v) + A(v, i);\n\t\t\tif (new_distance < cur_min || cur_min == -1) {\n\t\t\t\tcur_min = new_distance;\n\t\t\t\tprev(i) = v;\n\t\t\t}\n\t\t}\n\t\tdist(v) = cur_min;\n\t});\n\n\tKokkos::parallel_for(Kokkos::RangePolicy<>(0, N), [=](int v) {\n\t\tint cur_min = -1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited(i)) continue;\n\t\t\tint new_distance = dist(v) + A(v, i);\n\t\t\tif (new_distance < cur_min || cur_min == -1) {\n\t\t\t\tcur_min = new_distance;\n\t\t\t\tprev(i) = v;\n\t\t\t}\n\t\t}\n\t\tdist(v) = cur_min;\n\t});\n\n\tif (dist(dest) == -1) return -1;\n\n\tint qhead = 0;\n\tint qtail = 0;\n\tqueue(qtail++) = dest;\n\tin_queue(dest) = 1;\n\twhile (qhead < qtail) {\n\t\tint cur = queue(qhead++);\n\t\tin_queue(cur) = 0;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (visited(i)) continue;\n\t\t\tif (dist(i) == -1 || dist(i) == dist(cur) + 1) {\n\t\t\t\tqueue(qtail++) = i;\n\t\t\t\tin_queue(i) = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!in_queue(source)) return -1;\n\n\tint shortest_path_length = 0;\n\tint cur = source;\n\twhile (cur!= -1) {\n\t\t++shortest_path_length;\n\t\tcur = prev(cur);\n\t}\n\treturn shortest_path_length;\n}",
            "int len = 0;\n\n\t// Your code here\n\n\treturn len;\n}",
            "// TODO: implement the algorithm here\n  return -1;\n}",
            "// This is the Kokkos view we will fill with the path lengths.\n  // This should be a 1D view of length N.\n  Kokkos::View<int*> pathLengths(\"pathLengths\", N);\n  // Initialize all entries to -1, indicating that there is no path between\n  // source and that vertex.\n  Kokkos::parallel_for(\n    \"initPathLengths\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(const int i) {\n      pathLengths(i) = -1;\n    }\n  );\n\n  Kokkos::fence(); // ensure the previous kernel is complete before we continue\n  // Kokkos::deep_copy(pathLengths, -1);\n\n  // Fill in the first entry of pathLengths.\n  // This will be the shortest path between source and source.\n  // It should be 0.\n  pathLengths(source) = 0;\n\n  // Fill in the rest of the entries in the pathLengths view.\n  // Iterate over all vertices, v.\n  // For each iteration, we will update the shortest path length between source and v.\n  // If v is not a neighbor of source, then the length will remain unchanged, which is correct.\n  // If v is a neighbor of source, then the shortest path length from source to v is the length of the shortest path\n  // from source to its neighbor plus one.\n  // This is equivalent to setting the length to the maximum value of the current path length and the path length from\n  // source to its neighbor plus 1.\n  //\n  // You may need to do this iteratively, using Kokkos::deep_copy and Kokkos::fence to ensure that the previous copy is\n  // complete before the next copy.\n  Kokkos::parallel_for(\n    \"updatePathLengths\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n    KOKKOS_LAMBDA(const int v) {\n      for (int u = 0; u < N; ++u) {\n        if (A(u, v) == 1) {\n          Kokkos::atomic_min(&pathLengths(v), pathLengths(u) + 1);\n        }\n      }\n    }\n  );\n\n  Kokkos::fence();\n  // Return the length of the shortest path from source to dest.\n  // This will be the value stored in pathLengths(dest).\n  //\n  // You may need to use Kokkos::deep_copy and Kokkos::fence to ensure that the previous kernel is complete before\n  // reading from the view.\n  int length;\n  Kokkos::parallel_for(\n    \"findShortestPathLength\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, 1),\n    KOKKOS_LAMBDA(const int i) {\n      length = pathLengths(dest);\n    }\n  );\n  return length;\n}",
            "using namespace Kokkos;\n\n\tif (source == dest) {\n\t\treturn 0;\n\t}\n\n\t// Initialize the distance matrix and the predecessor matrix\n\tView<int**> d(\"distance\", N, N);\n\tView<int**> p(\"predecessor\", N, N);\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\td(i, j) = -1;\n\t\t\tp(i, j) = -1;\n\t\t}\n\t}\n\n\t// Initialze the distance matrix with the adjacency matrix.\n\t// Initialze the predecessor matrix to point to the source.\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\td(i, j) = 0;\n\t\t\t\tp(i, j) = i;\n\t\t\t}\n\t\t\telse {\n\t\t\t\td(i, j) = A(i, j);\n\t\t\t\tp(i, j) = i;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Create a view to keep track of the set of unvisited vertices\n\tView<int*> unvisited(\"unvisited\", N);\n\n\t// Initialize the unvisited set\n\tfor (int i = 0; i < N; ++i) {\n\t\tunvisited(i) = i;\n\t}\n\n\tint shortest_path_length = 0;\n\n\t// Iterate over the unvisited set\n\twhile (unvisited.size() > 0) {\n\t\t// Find the unvisited vertex with the shortest path length\n\t\tint current_vertex = -1;\n\t\tint shortest_path_length = -1;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (unvisited(i) == 1) {\n\t\t\t\tif (shortest_path_length == -1 || d(i, dest) < shortest_path_length) {\n\t\t\t\t\tshortest_path_length = d(i, dest);\n\t\t\t\t\tcurrent_vertex = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Mark the current vertex as visited\n\t\tunvisited(current_vertex) = 0;\n\n\t\t// If the destination vertex was found, return the length of the shortest path\n\t\tif (current_vertex == dest) {\n\t\t\treturn shortest_path_length;\n\t\t}\n\n\t\t// Iterate over the unvisited neighbors of the current vertex\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (unvisited(i) == 1 && A(current_vertex, i) > 0) {\n\t\t\t\t// Update the distance matrix if we find a shorter path\n\t\t\t\tif (d(current_vertex, i) + 1 < d(i, dest)) {\n\t\t\t\t\td(i, dest) = d(current_vertex, i) + 1;\n\t\t\t\t\tp(i, dest) = p(current_vertex, dest);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}",
            "// TODO\n\treturn -1;\n}",
            "Kokkos::View<int*> lengths(\"lengths\", N);\n  Kokkos::View<int*> work_queue(\"work_queue\", N);\n  Kokkos::View<int*> predecessor(\"predecessor\", N);\n  int queue_end = 1;\n  int queue_start = 0;\n\n  Kokkos::deep_copy(lengths, 0);\n  Kokkos::deep_copy(work_queue, -1);\n  Kokkos::deep_copy(predecessor, -1);\n  Kokkos::deep_copy(lengths(source), 0);\n  Kokkos::deep_copy(work_queue(queue_start), source);\n\n  while (queue_start < queue_end) {\n    Kokkos::View<int*> next_lengths(\"next_lengths\", N);\n    Kokkos::View<int*> next_work_queue(\"next_work_queue\", N);\n    Kokkos::View<int*> next_predecessor(\"next_predecessor\", N);\n    Kokkos::deep_copy(next_lengths, 0);\n    Kokkos::deep_copy(next_work_queue, -1);\n    Kokkos::deep_copy(next_predecessor, -1);\n\n    auto work_queue_host = Kokkos::create_mirror_view(work_queue);\n    Kokkos::deep_copy(work_queue_host);\n\n    for (int i = queue_start; i < queue_end; i++) {\n      int v = work_queue_host(i);\n      for (int u = 0; u < N; u++) {\n        if (A(v, u) == 1) {\n          Kokkos::atomic_compare_exchange_strong(&(next_lengths(u)),\n            lengths(u), lengths(v) + 1);\n          Kokkos::atomic_compare_exchange_strong(&(next_predecessor(u)),\n            predecessor(u), v);\n          Kokkos::atomic_compare_exchange_strong(&(next_work_queue(u)),\n            work_queue(u), -1);\n        }\n      }\n    }\n\n    Kokkos::deep_copy(lengths, next_lengths);\n    Kokkos::deep_copy(work_queue, next_work_queue);\n    Kokkos::deep_copy(predecessor, next_predecessor);\n    queue_start = queue_end;\n    for (int i = 0; i < N; i++) {\n      if (work_queue(i)!= -1) {\n        queue_end++;\n      }\n    }\n  }\n  return lengths(dest);\n}",
            "// Kokkos initialization and finalization happens outside this function.\n  // Kokkos::initialize() should be called before this function\n  // Kokkos::finalize() should be called after this function\n\n  // TODO\n  return -1;\n}",
            "// TODO: Add Kokkos code here.\n  return 0;\n}",
            "// TODO: Implement this\n  return -1;\n}",
            "using execution_space = Kokkos::DefaultExecutionSpace;\n\tusing view_t = Kokkos::View<int*, execution_space>;\n\n\t// TODO: Fill in the body of this function\n\tview_t dp(\"dp\", N);\n\tdp(0) = 0;\n\tKokkos::parallel_for(\"shortestPathLength\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tdp(i) = -1;\n\t});\n\n\tKokkos::parallel_for(\"shortestPathLength\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1 && dp(j) >= 0) {\n\t\t\t\tif (dp(i) < 0 || dp(i) > dp(j) + 1) {\n\t\t\t\t\tdp(i) = dp(j) + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tint ret = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (dp(i) >= 0) {\n\t\t\tret = dp(i);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn ret;\n}",
            "// Compute the number of iterations required to complete the search.  The max path length\n\t// is the number of iterations required to complete the search.  Note that the algorithm\n\t// will fail if there is a path length > Kokkos::View<int>::max_size() (e.g., 2147483647\n\t// on a 32-bit platform, 9223372036854775807 on a 64-bit platform).\n\t//\n\t// TODO: Add overflow checking (Kokkos::View<int>::max_size() might not be the max size\n\t// on some platforms, or might be 32 bits on a 64-bit platform).\n\tint numIter = 1;\n\tint max = 0;\n\tfor(int i = 0; i < N; ++i) {\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A(i,j) > 0) {\n\t\t\t\t++numIter;\n\t\t\t\tmax = std::max(max, A(i,j));\n\t\t\t}\n\t\t}\n\t}\n\n\t// Initialize the search matrix.  Note that we'll need the search matrix even after\n\t// the algorithm completes.\n\tKokkos::View<int**> S(\"S\", N, numIter);\n\tfor(int i = 0; i < N; ++i) {\n\t\tfor(int j = 0; j < numIter; ++j) {\n\t\t\tS(i,j) = 0;\n\t\t}\n\t}\n\tS(source,0) = 1;\n\n\t// Define the kernel.  Note that we'll need a separate kernel for each iteration.\n\t// The KernelPolicy type is defined by Kokkos.\n\ttypedef Kokkos::MDRangePolicy<Kokkos::Rank<2>> PolicyType;\n\tauto kernel = KOKKOS_LAMBDA (const int i, const int j) {\n\n\t\t// The Kokkos::single statement allows us to have a \"critical\" section.  Note that\n\t\t// the first argument to the critical section is a reference to an integer.  This\n\t\t// integer is used to indicate whether the critical section is currently executing.\n\t\t// Once the critical section is entered, the integer will be set to 1.  If the integer\n\t\t// is 0, then the critical section has already been entered and we can skip the\n\t\t// execution of the critical section.\n\t\tKokkos::single(i,0) {\n\n\t\t\t// Determine the value of S(i,j-1)\n\t\t\tint previous = 0;\n\t\t\tif(j > 0) {\n\t\t\t\tprevious = S(i,j-1);\n\t\t\t}\n\n\t\t\t// Determine the value of S(i,j)\n\t\t\tint s = previous;\n\t\t\tif(j < numIter-1 && previous > 0) {\n\t\t\t\ts = previous + A(i,j);\n\t\t\t}\n\n\t\t\t// Set the value of S(i,j)\n\t\t\tS(i,j) = s;\n\t\t}\n\t};\n\n\t// Define the execution policy.  This is a range-based execution policy, which\n\t// will cause Kokkos to iterate over every element in the 2-dimensional range.\n\tPolicyType policy(0,N,0,numIter);\n\n\t// Execute the kernel.  Note that this will execute the same kernel for every\n\t// iteration.  Kokkos will optimize away redundant work when appropriate.\n\tfor(int k = 0; k < numIter; ++k) {\n\t\tKokkos::parallel_for(\"shortestPathLength\", policy, kernel);\n\t}\n\n\t// Return the length of the shortest path.  Note that this is only a correct\n\t// answer if there is no path from source to dest.  If there is a path, then\n\t// this algorithm will return the length of the shortest path from source to dest\n\t// plus the length of the shortest path from dest to source.\n\tint length = 0;\n\tfor(int i =",
            "// Kokkos::View<int**> dist(\"dist\", N, N); // Distance matrix\n  Kokkos::View<int**> dist(\"dist\", N, N); // Distance matrix\n\n  Kokkos::parallel_for(\"distance_matrix\", Kokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n                       KOKKOS_LAMBDA(const int &i, const int &j) {\n                         // Note: This is not correct. The correct implementation uses BFS to find the\n                         //       shortest path length.\n                         dist(i, j) = i == j? 0 : A(i, j);\n                       });\n  Kokkos::fence();\n\n  // TODO: Implement BFS.\n\n  Kokkos::View<int**>::HostMirror hostDist = Kokkos::create_mirror_view(dist);\n  Kokkos::deep_copy(hostDist, dist);\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      printf(\"dist[%d][%d] = %d\\n\", i, j, hostDist(i, j));\n    }\n  }\n\n  return 0;\n}",
            "// We need to initialize the variables that Kokkos will use.\n  Kokkos::View<int*> queue(\"queue\", N);\n  Kokkos::View<int*> levels(\"levels\", N);\n  Kokkos::View<bool*> visited(\"visited\", N);\n  Kokkos::View<int*> parent(\"parent\", N);\n\n  // We will need to perform a Breadth-First Search.\n  // The following function will search the graph for the shortest path.\n  // We'll need to call it once for each possible start node.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n    // Initialize all the variables that Kokkos will use.\n    queue[i] = -1;\n    levels[i] = -1;\n    visited[i] = false;\n    parent[i] = -1;\n  });\n\n  // Start the search.\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n    // We'll only need to do work if we haven't visited this node yet.\n    if (!visited[i]) {\n      // This is the start node for this BFS.\n      queue[0] = i;\n      levels[i] = 0;\n      visited[i] = true;\n\n      // Iterate over the BFS until we've visited all the nodes in this BFS.\n      for (int j = 0; j < N; ++j) {\n        // If the queue is empty, this BFS is finished.\n        if (queue[j] < 0) {\n          break;\n        }\n        // Otherwise, visit the node at the head of the queue.\n        const int node = queue[j];\n\n        // Check all neighbors of the current node.\n        for (int k = 0; k < N; ++k) {\n          // If the neighbor is reachable, add it to the queue.\n          if (A(node, k)!= 0) {\n            queue[j + 1] = k;\n            levels[k] = levels[node] + 1;\n            visited[k] = true;\n            parent[k] = node;\n            break;\n          }\n        }\n\n        // We've visited all the nodes in this BFS, so the queue is empty.\n        queue[j] = -1;\n      }\n    }\n  });\n\n  // After this parallel_for, all variables have been initialized.\n  // We can now search for the shortest path.\n  // The shortest path is the shortest path from the source to the destination in the whole graph.\n  int shortestPathLength = -1;\n  Kokkos::parallel_reduce(N, KOKKOS_LAMBDA(const int& i, int& lp) {\n    // Is this a node on the shortest path?\n    if (i == source || i == dest || parent[i] == source) {\n      // How many nodes are there in this shortest path?\n      const int length = levels[dest] - levels[i] + 1;\n      // Keep track of the shortest path we've found so far.\n      lp = std::min(length, lp);\n    }\n  }, shortestPathLength);\n\n  return shortestPathLength;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n\n\tKokkos::parallel_for(\"init_dist\", \n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA (const int i) {\n\t\tdist(i) = -1;\n\t});\n\n\tKokkos::parallel_for(\"shortest_path\", \n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA (const int i) {\n\t\tif (i == source) {\n\t\t\tdist(i) = 0;\n\t\t}\n\t});\n\n\tKokkos::parallel_for(\"shortest_path\", \n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N),\n\t\tKOKKOS_LAMBDA (const int i) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tif (dist(k) >= 0) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A(k, j) > 0) {\n\t\t\t\t\t\tdist(j) = std::min(dist(j), dist(k) + 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::View<int> length(\"length\");\n\n\tKokkos::parallel_reduce(\"length\", \n\t\tKokkos::RangePolicy<Kokkos::OpenMP>(0, N), \n\t\tKOKKOS_LAMBDA (const int i, int &l) {\n\t\tif (i == dest && dist(i) >= 0) {\n\t\t\tl = dist(i);\n\t\t}\n\t}, Kokkos::OpenMP::min_reduction(length));\n\n\treturn length();\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n\n\t// Initialize the distance from the source to all other vertices as infinity.\n\tKokkos::parallel_for(\"initDist\", N, KOKKOS_LAMBDA(int i) {\n\t\tdist(i) = INT_MAX;\n\t});\n\n\t// Set the distance from the source to the source to 0.\n\tdist(source) = 0;\n\n\t// Relax edges repeatedly until the destination is reached\n\tfor (int i = 0; i < N; i++) {\n\t\tKokkos::parallel_for(\"relaxEdges\", N, KOKKOS_LAMBDA(int j) {\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (A(j, k) == 1 && dist(k)!= INT_MAX && dist(k) + 1 < dist(j)) {\n\t\t\t\t\tdist(j) = dist(k) + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\n\tint ans = dist(dest);\n\n\t// Clean up memory\n\tdist = Kokkos::View<int*>();\n\n\treturn ans;\n}",
            "using namespace Kokkos;\n  using ViewIntType = typename View<int*,HostSpace>::HostMirror;\n\n  // Set up the distance array\n  ViewIntType distance(\"distance\", N);\n  for (size_t i = 0; i < N; ++i) distance(i) = -1;\n  distance(source) = 0;\n\n  // Initialize the queue\n  ViewIntType queue(\"queue\", N);\n  int front = 0;\n  int back = 1;\n  queue(front) = source;\n\n  while (front!= back) {\n    int current = queue(front);\n    front = (front + 1) % N;\n    int current_distance = distance(current);\n    for (size_t i = 0; i < N; ++i) {\n      if (A(current, i) && distance(i) == -1) {\n        distance(i) = current_distance + 1;\n        queue(back) = i;\n        back = (back + 1) % N;\n      }\n    }\n  }\n\n  // Return the length of the shortest path\n  return distance(dest);\n}",
            "int level = 0;\n\n\tKokkos::View<int*> distances(\"distances\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tif(i == source) distances(i) = 0;\n\t\telse distances(i) = INT_MAX;\n\t});\n\n\tKokkos::View<int*> marked(\"marked\", N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n\t\tmarked(i) = 0;\n\t});\n\n\tKokkos::View<int*> queue(\"queue\", N);\n\n\tqueue(0) = source;\n\n\tKokkos::parallel_for(1, [&] (int i) {\n\t\tint v = queue(i-1);\n\t\tmarked(v) = 1;\n\t\tfor (int w = 0; w < N; w++) {\n\t\t\tif (A(v, w) == 1 && marked(w) == 0) {\n\t\t\t\tdistances(w) = distances(v) + 1;\n\t\t\t\tqueue(i) = w;\n\t\t\t}\n\t\t}\n\t});\n\n\tfor (int i = 1; i < N; i++) {\n\t\tif (queue(i) == dest) {\n\t\t\tlevel = distances(dest);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn level;\n}",
            "using exec_space = Kokkos::DefaultExecutionSpace;\n  using mdrange_pol = Kokkos::MDRangePolicy<exec_space, Kokkos::Rank<2>>;\n  using loop_pol = Kokkos::LoopPolicy<exec_space>;\n\n  Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> s(\"s\", N);\n  Kokkos::View<int*> processed(\"processed\", N);\n\n  // Initialize distance array to -1\n  Kokkos::parallel_for(\"init dist\", mdrange_pol({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int j) {\n    dist(i) = -1;\n  });\n  Kokkos::fence();\n\n  // Initialize distance from source to 0\n  dist(source) = 0;\n\n  // Initialize S\n  Kokkos::parallel_for(\"init s\", mdrange_pol({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int j) {\n    s(i) = 0;\n  });\n  Kokkos::fence();\n\n  // Initialize processed to false\n  Kokkos::parallel_for(\"init processed\", mdrange_pol({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int j) {\n    processed(i) = 0;\n  });\n  Kokkos::fence();\n\n  // Loop until s is empty\n  int count = 0;\n  while (true) {\n    // For all items in S, update distance from dest to source\n    Kokkos::parallel_for(\"update distance\", loop_pol(0, s.extent(0)), KOKKOS_LAMBDA(int i) {\n      if (s(i) == 0) {\n        dist(i) = -1;\n      }\n    });\n    Kokkos::fence();\n\n    // Find new nodes to add to S\n    Kokkos::parallel_for(\"add to s\", mdrange_pol({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int j) {\n      if (processed(i) == 0 && A(i, j)!= 0) {\n        s(i) = 1;\n      }\n    });\n    Kokkos::fence();\n\n    // Count number of items in S\n    Kokkos::parallel_reduce(\"count s\", loop_pol(0, s.extent(0)), KOKKOS_LAMBDA(int i, int &update) {\n      if (s(i) == 1) {\n        update++;\n      }\n    }, Kokkos::Sum<int>(count));\n    Kokkos::fence();\n\n    // If S is empty, break\n    if (count == 0) {\n      break;\n    }\n\n    // Set all items in S to processed\n    Kokkos::parallel_for(\"set processed\", loop_pol(0, s.extent(0)), KOKKOS_LAMBDA(int i) {\n      if (s(i) == 1) {\n        processed(i) = 1;\n      }\n    });\n    Kokkos::fence();\n\n    // Remove all items in S from S\n    Kokkos::parallel_for(\"remove from s\", loop_pol(0, s.extent(0)), KOKKOS_LAMBDA(int i) {\n      if (s(i) == 1) {\n        s(i) = 0;\n      }\n    });\n    Kokkos::fence();\n  }\n\n  // Find minimum distance to dest\n  int result = -1;\n  Kokkos::parallel_reduce(\"find minimum\", mdrange_pol({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int &update) {\n    if (dist(i)!= -1) {\n      update = std::min(update, dist(i));\n    }\n  }, Kokkos::Min<int>(result));\n  Kokkos::fence();",
            "// Initialize distance matrix to infinity.\n  Kokkos::View<int**> distance(\"distance\", N, N);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OmpTag>(0, N), [=] (int i) {\n    for (int j = 0; j < N; j++) {\n      distance(i, j) = INT_MAX;\n    }\n  });\n\n  // The shortest path from source to source is 0.\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OmpTag>(0, N), [=] (int i) {\n    distance(i, i) = 0;\n  });\n\n  // Iterate over all vertices |V|-1 times to calculate the distance from source to all other vertices.\n  for (int i = 0; i < N-1; i++) {\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::OmpTag>(0, N), [=] (int j) {\n      for (int k = 0; k < N; k++) {\n        if (A(j, k) && distance(j, k) > distance(j, source) + A(j, k)) {\n          distance(j, k) = distance(j, source) + A(j, k);\n        }\n      }\n    });\n  }\n\n  // Return the length of the shortest path.\n  return distance(dest, source);\n}",
            "int NN = N;\n\t// Create arrays\n\tKokkos::View<int*> B(\"B\", N);\n\tKokkos::View<int*> C(\"C\", N);\n\t// Initialize arrays\n\tauto init_B = KOKKOS_LAMBDA(const int i) {\n\t\tB(i) = -1;\n\t};\n\tauto init_C = KOKKOS_LAMBDA(const int i) {\n\t\tC(i) = -1;\n\t};\n\tKokkos::parallel_for(N, init_B);\n\tKokkos::parallel_for(N, init_C);\n\t// Initialize B and C to indicate no predecessor\n\t// Initialize distance from source to source as 0\n\tauto update_B = KOKKOS_LAMBDA(const int i) {\n\t\tB(i) = source;\n\t};\n\tKokkos::parallel_for(N, update_B);\n\tauto init_C = KOKKOS_LAMBDA(const int i) {\n\t\tC(i) = 0;\n\t};\n\tKokkos::parallel_for(N, init_C);\n\t// Loop until we visit all nodes in the graph\n\tfor (int i = 0; i < NN; i++) {\n\t\t// Loop over all nodes in the graph\n\t\tauto loop_body = KOKKOS_LAMBDA(const int j) {\n\t\t\t// For this node, we have a predecessor, check if it is closer\n\t\t\t// than any other predecessor for this node\n\t\t\tif ((B(j)!= -1) && (C(B(j)) + 1 < C(j))) {\n\t\t\t\t// We have already visited this node, but not via this predecessor\n\t\t\t\tC(j) = C(B(j)) + 1;\n\t\t\t\t// Record this new predecessor\n\t\t\t\tB(j) = i;\n\t\t\t} else if ((B(j) == -1) && (C(j)!= 0)) {\n\t\t\t\t// We have not yet visited this node, but it is closer than\n\t\t\t\t// any other predecessor we have. Record this predecessor.\n\t\t\t\tB(j) = i;\n\t\t\t\tC(j) = C(i) + 1;\n\t\t\t}\n\t\t};\n\t\tKokkos::parallel_for(N, loop_body);\n\t}\n\treturn C(dest);\n}",
            "int *dist = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = INF;\n\t}\n\tdist[source] = 0;\n\tKokkos::View<int*> dist_v(\"dist\", N);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ExecPolicy>(0, N), [=](const int &i) {\n\t\tdist_v(i) = dist[i];\n\t});\n\tKokkos::deep_copy(A, A);\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ExecPolicy>(0, N), [=](const int &i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A(i, j) == 1) {\n\t\t\t\tA(j, i) = 1;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::parallel_for(Kokkos::RangePolicy<Kokkos::ExecPolicy>(0, N), [=](const int &i) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist[i]!= INF) {\n\t\t\t\tdist_v(j) = std::min(dist_v(j), dist_v(i) + A(i, j));\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::deep_copy(dist, dist_v);\n\tdelete[] dist;\n\treturn dist[dest];\n}",
            "// TODO: Fill this in\n\treturn -1;\n}",
            "Kokkos::View<int*> dist(Kokkos::ViewAllocateWithoutInitializing(\"dist\"), N);\n  Kokkos::View<int*> p(Kokkos::ViewAllocateWithoutInitializing(\"p\"), N);\n  Kokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const int& i) {\n    if (i == source) {\n      dist(i) = 0;\n    } else {\n      dist(i) = -1;\n    }\n    p(i) = -1;\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int*> worklist(Kokkos::ViewAllocateWithoutInitializing(\"worklist\"), N);\n  int worklist_index = 0;\n  Kokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const int& i) {\n    worklist(worklist_index++) = i;\n  });\n  Kokkos::fence();\n\n  int curr;\n  while (worklist_index > 0) {\n    --worklist_index;\n    curr = worklist(worklist_index);\n    for (int i = 0; i < N; ++i) {\n      if (dist(curr)!= -1 && A(curr, i) && dist(i) == -1) {\n        dist(i) = dist(curr) + 1;\n        worklist(worklist_index++) = i;\n        p(i) = curr;\n      }\n    }\n  }\n\n  int length = 0;\n  int next = dest;\n  while (next!= -1) {\n    length += 1;\n    next = p(next);\n  }\n\n  return length;\n}",
            "// Create a view of the distance from the source to each node.\n\tKokkos::View<int*> distance(\"distance\", N);\n\tKokkos::deep_copy(distance, -1);\n\n\t// Create a view of the previous node in the path from the source to each node.\n\t// For example, if the path from the source to node i is i1 -> i2 -> i, the previous\n\t// node in the path is i2.\n\tKokkos::View<int*> previous(\"previous\", N);\n\n\t// Run a Breadth First Search starting from the source to compute the distances.\n\tKokkos::parallel_for(\n\t\t\"breadth_first_search\",\n\t\tKokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>(0, N),\n\t\tKOKKOS_LAMBDA(const int i) {\n\t\t\tif (i!= source && distance(i) < 0) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tstd::queue<int> queue;\n\t\t\tqueue.push(i);\n\t\t\twhile (!queue.empty()) {\n\t\t\t\tconst int v = queue.front();\n\t\t\t\tqueue.pop();\n\n\t\t\t\tif (distance(v) >= 0) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tdistance(v) = distance(source) + 1;\n\n\t\t\t\t// Find all nodes adjacent to v.\n\t\t\t\tfor (int w = 0; w < N; ++w) {\n\t\t\t\t\tif (A(v, w) == 1) {\n\t\t\t\t\t\tqueue.push(w);\n\t\t\t\t\t\tprevious(w) = v;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t// Return the length of the shortest path from the source to the destination.\n\tint length = 0;\n\tint curr = dest;\n\twhile (curr!= -1) {\n\t\tlength += 1;\n\t\tcurr = previous(curr);\n\t}\n\treturn length;\n}",
            "// TODO: FILL THIS IN\n\treturn -1;\n\n}",
            "// Set the initial distance for the source node to 0.\n  // Set the initial distance for all other nodes to INT_MAX.\n  Kokkos::View<int*> distances(\"distances\", N);\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t i) {\n    if (i == source) {\n      distances(i) = 0;\n    } else {\n      distances(i) = INT_MAX;\n    }\n  });\n  Kokkos::fence();\n\n  // Iterate over all nodes, and for each node, consider it as the current node,\n  // and all the neighbors of the current node.\n  // For each neighbor, calculate the length of the shortest path from the source to that neighbor,\n  // and update the current node's distance if it's shorter.\n  // Do this for all nodes in the graph until no changes are made to the distance vector.\n  int changeCount = -1;\n  while (changeCount!= 0) {\n    changeCount = 0;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t i) {\n      // For each neighbor of the current node, check if we can find a shorter path to that neighbor from the source.\n      for (int j = 0; j < N; j++) {\n        int neighborDistance = distances(j);\n        if (A(i, j) == 1 && distances(i)!= INT_MAX && (distances(i) + 1) < neighborDistance) {\n          changeCount += 1;\n          distances(j) = distances(i) + 1;\n        }\n      }\n    });\n    Kokkos::fence();\n  }\n\n  // Return the length of the shortest path from source to dest.\n  return distances(dest);\n}",
            "// Fill in the body of the function.\n    return -1;\n}",
            "using ExecPolicy = Kokkos::TeamPolicy<Kokkos::OpenMP>;\n  using TeamMember = Kokkos::TeamPolicy<Kokkos::OpenMP>::member_type;\n\n  // TODO: Your code here!\n  return 0;\n}",
            "using namespace Kokkos;\n\n\ttypedef Kokkos::View<int**> ViewType;\n\ttypedef ViewType::HostMirror HostViewType;\n\tHostViewType dist(\"dist\", N, N);\n\n\tconst int inf = std::numeric_limits<int>::max();\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif (A(i, j))\n\t\t\t\tdist(i, j) = 1;\n\t\t\telse\n\t\t\t\tdist(i, j) = inf;\n\t\t}\n\t}\n\n\tViewType dist_copy(\"dist\", N, N);\n\tKokkos::deep_copy(dist_copy, dist);\n\n\tViewType dist_copy_copy(\"dist_copy\", N, N);\n\tKokkos::deep_copy(dist_copy_copy, dist);\n\n\tViewType dist_copy_copy_copy(\"dist_copy_copy\", N, N);\n\tKokkos::deep_copy(dist_copy_copy_copy, dist);\n\n\t// TODO: compute the shortest path length from source to dest using Kokkos here\n\treturn -1;\n}",
            "// TODO: replace this with your code\n  return 0;\n}",
            "/* You should not modify any of the code in this function! */\n\tif(source == dest) return 0;\n\t\n\tKokkos::View<bool**> s(Kokkos::ViewAllocateWithoutInitializing(\"s\"), N, N);\n\tKokkos::View<int**> d(Kokkos::ViewAllocateWithoutInitializing(\"d\"), N, N);\n\n\t/* Kokkos views are initially uninitialized.\n\t   Uninitialized views are always false when used as a logical expression,\n\t   so this will zero out the contents of both s and d */\n\tKokkos::deep_copy(s, false);\n\tKokkos::deep_copy(d, 0);\n\t\n\t/* Set source as the initial node to be explored */\n\ts(source, source) = true;\n\td(source, source) = 1;\n\n\t/* Kokkos parallel_for construct. See Kokkos documentation for more information */\n\tKokkos::parallel_for(\n\t\t\"bfs\",\n\t\tKokkos::RangePolicy<Kokkos::Rank<2>>(0, N, 0, N),\n\t\t[&](const int i, const int j) {\n\t\t\tif (s(i, j) && A(i, j) &&!s(j, j)) {\n\t\t\t\ts(j, j) = true;\n\t\t\t\td(j, j) = d(i, j) + 1;\n\t\t\t}\n\t\t}\n\t);\n\n\t/* Uncomment to print out the contents of s and d */\n\t//Kokkos::deep_copy(s, true);\n\t//Kokkos::deep_copy(d, 0);\n\t//Kokkos::fence();\n\t//std::cout << \"s:\\n\";\n\t//Kokkos::deep_copy(s, true);\n\t//Kokkos::fence();\n\t//std::cout << \"d:\\n\";\n\t//Kokkos::deep_copy(d, 0);\n\t//Kokkos::fence();\n\t//return 0;\n\n\t/* Compute shortest path length here */\n\tint length;\n\tKokkos::parallel_reduce(\n\t\t\"length\",\n\t\tKokkos::RangePolicy<Kokkos::Rank<1>>(0, N),\n\t\tKokkos::Max<int>(length),\n\t\t[&](const int i, int &l) {\n\t\t\tif (s(dest, i) && d(dest, i) > l)\n\t\t\t\tl = d(dest, i);\n\t\t}\n\t);\n\tKokkos::fence();\n\treturn length;\n}",
            "// Fill in the rest of the function.\n  // You may assume that 0 <= source < N, 0 <= dest < N, and source!= dest.\n  // You may not use any STL containers.\n  // You may use Kokkos views and functors, but you may not use Kokkos parallel_for.\n  // You may not use CUDA, OpenMP, or OpenACC.\n\n  // BEGIN_CODE\n  int *lengths = new int[N];\n  for (int i = 0; i < N; i++) {\n    lengths[i] = -1;\n  }\n  lengths[source] = 0;\n\n  for (int i = 1; i < N; i++) {\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(int j) {\n      int length = lengths[j];\n      int len_plus_one = lengths[A(j, j)] + 1;\n      if (len_plus_one < length || length == -1) {\n        lengths[j] = len_plus_one;\n      }\n    });\n  }\n\n  int result = lengths[dest];\n  delete[] lengths;\n  return result;\n  // END_CODE\n}",
            "// TODO: write your parallel shortest path function here\n  return -1;\n}",
            "// TODO: Add code here to compute the length of the shortest path\n\n\treturn 0;\n}",
            "if (source == dest) return 0;\n\n  Kokkos::View<int*> Q(\"Queue\", N);\n  int queueEnd = 0;\n  int queueStart = 0;\n\n  Kokkos::View<int*> dist(\"Distances\", N);\n  Kokkos::parallel_for(\n    Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n    KOKKOS_LAMBDA(int i) {\n      dist(i) = -1;\n    });\n  Kokkos::fence();\n  dist(source) = 0;\n\n  int q;\n  while (queueEnd!= queueStart) {\n    Kokkos::parallel_for(\n      Kokkos::RangePolicy<Kokkos::Cuda>(queueStart, queueEnd),\n      KOKKOS_LAMBDA(int i) {\n        for (int j=0; j<N; ++j) {\n          if (A(Q(i), j) && dist(j) == -1) {\n            dist(j) = dist(Q(i)) + 1;\n            Q(queueEnd++) = j;\n          }\n        }\n      });\n    Kokkos::fence();\n    queueStart = queueEnd;\n  }\n\n  return dist(dest);\n}",
            "// This is the work function that will be executed in parallel\n\tKOKKOS_INLINE_FUNCTION\n\tvoid operator() (const int &i) const {\n\n\t\t// We can read from the View A here\n\n\t}\n\n\t// Callbacks allow you to do something before and/or after executing the work function\n\tclass ShortestPathCallbacks : public Kokkos::RangePolicy<>::member_type {\n\n\t\t// In the callbacks, we must pass a reference to the View A\n\t\tKokkos::View<const int**> &A;\n\n\tpublic:\n\t\tShortestPathCallbacks(Kokkos::View<const int**> &_A) : A(_A) {}\n\n\t\t// Kokkos will call this before executing the parallel for loop\n\t\tKOKKOS_INLINE_FUNCTION\n\t\tvoid on_",
            "using T = Kokkos::DefaultExecutionSpace;\n  using I = typename T::size_type;\n  using F = typename T::scalar_type;\n  using M = Kokkos::View<F**>;\n  using V = Kokkos::View<I*>;\n\n  // Allocate views for path lengths and whether each vertex is in the queue.\n  M pathLengths = Kokkos::create_mirror_view(A);\n  Kokkos::deep_copy(pathLengths, A);\n  V inQueue = Kokkos::create_mirror_view(Kokkos::View<bool*>(\"inQueue\", N));\n  Kokkos::deep_copy(inQueue, false);\n\n  // Initialize the queue with the source vertex.\n  std::queue<int> q;\n  q.push(source);\n  inQueue[source] = true;\n  pathLengths(source, source) = 0;\n\n  // BFS.\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n    inQueue[u] = false;\n    for (int v = 0; v < N; ++v) {\n      if (!inQueue[v] && pathLengths(u, v) == 1) {\n        pathLengths(u, v) = pathLengths(u, source) + 1;\n        pathLengths(v, source) = pathLengths(u, v);\n        q.push(v);\n        inQueue[v] = true;\n      }\n    }\n  }\n\n  // Return the length of the shortest path.\n  int shortestLength = pathLengths(dest, source);\n  Kokkos::deep_copy(A, pathLengths);\n  return shortestLength;\n}",
            "// TODO: insert code here\n\treturn 0;\n}",
            "Kokkos::View<int*> d_dist(\"dist\", N);\n    Kokkos::View<int*> d_prev(\"prev\", N);\n    Kokkos::View<int*> d_dist_tmp(\"dist_tmp\", N);\n\n    Kokkos::parallel_for( \"init\", N, KOKKOS_LAMBDA( const size_t &i ) {\n        d_dist(i) = -1;\n        d_prev(i) = -1;\n        d_dist_tmp(i) = -1;\n    });\n\n    Kokkos::parallel_for( \"bfs\", N, KOKKOS_LAMBDA( const size_t &i ) {\n        d_dist(source) = 0;\n        d_prev(source) = source;\n    });\n\n    int depth = 0;\n\n    // keep going while there are still nodes to explore\n    while (d_dist(dest) == -1 && depth < N) {\n        // for every node that has been explored, explore its neighbors\n        Kokkos::parallel_for( \"explore\", N, KOKKOS_LAMBDA( const size_t &i ) {\n            if (d_dist(i)!= -1) {\n                for (int j = 0; j < N; j++) {\n                    // if there's an edge between the current node and its neighbor and the neighbor hasn't been explored yet\n                    if (A(i,j) > 0 && d_dist(j) == -1) {\n                        // update the distance to the neighbor\n                        d_dist(j) = d_dist(i) + 1;\n                        // save the previous node\n                        d_prev(j) = i;\n                    }\n                }\n            }\n        });\n        // swap the distance and previous nodes arrays for the next iteration\n        Kokkos::deep_copy(d_dist_tmp, d_dist);\n        Kokkos::deep_copy(d_dist, d_prev);\n        Kokkos::deep_copy(d_prev, d_dist_tmp);\n\n        depth += 1;\n    }\n\n    // backtrack from the destination to the source to find the shortest path\n    int length = 0;\n    int current = dest;\n\n    while (current!= source) {\n        current = d_prev(current);\n        length += 1;\n    }\n\n    return length;\n}",
            "int result;\n    Kokkos::View<int*, Kokkos::HostSpace> result_view(\"result\", 1);\n    Kokkos::View<int**, Kokkos::HostSpace> dist(\"dist\", 1, N);\n    Kokkos::View<int*, Kokkos::HostSpace> prev(\"prev\", N);\n    Kokkos::View<bool*, Kokkos::HostSpace> visited(\"visited\", N);\n\n    Kokkos::parallel_for(\"path_length\", Kokkos::RangePolicy<Kokkos::Serial>(0, N), KOKKOS_LAMBDA(const int& i) {\n        // Initialize dist and prev\n        dist(0, i) = INT_MAX;\n        prev(i) = -1;\n        visited(i) = false;\n    });\n\n    Kokkos::single(Kokkos::Serial(), KOKKOS_LAMBDA() {\n        dist(0, source) = 0;\n    });\n\n    // Use BFS to fill in dist and prev\n    for (int u = 0; u < N; u++) {\n        Kokkos::parallel_for(\"path_length\", Kokkos::RangePolicy<Kokkos::Serial>(0, N), KOKKOS_LAMBDA(const int& i) {\n            if (!visited(i) && dist(0, i) < INT_MAX) {\n                for (int j = 0; j < N; j++) {\n                    if (A(i, j) == 1 && dist(0, j) > dist(0, i) + 1) {\n                        dist(0, j) = dist(0, i) + 1;\n                        prev(j) = i;\n                    }\n                }\n                visited(i) = true;\n            }\n        });\n    }\n\n    Kokkos::parallel_for(\"path_length\", Kokkos::RangePolicy<Kokkos::Serial>(0, N), KOKKOS_LAMBDA(const int& i) {\n        if (prev(i) == -1) {\n            result_view(0) = INT_MAX;\n        }\n        if (i == dest) {\n            result_view(0) = dist(0, dest);\n        }\n    });\n\n    Kokkos::fence();\n\n    Kokkos::deep_copy(result, result_view);\n    return result;\n}",
            "// Initialize a Kokkos view to hold the distance from each node to the source node.\n\t// This is the \"distance\" vector in the description of Dijkstra's algorithm.\n\tKokkos::View<int*> distances(\"distances\", N);\n\n\t// Initialize the distances to the source node.\n\tKokkos::parallel_for(\"init_distances\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA (int i) {\n\t\tdistances[i] = (i == source? 0 : 1000);\n\t});\n\n\t// Define a Kokkos view to hold the \"current\" node for the kernels below.\n\tKokkos::View<int*> current(\"current\", 1);\n\n\t// Iterate until the destination node is reached.\n\t// Each iteration will update the \"current\" node based on the shortest distance to it\n\t// from the source.\n\tKokkos::parallel_for(\"dijkstra\", Kokkos::RangePolicy<Kokkos::RoundRobin>(0, N), KOKKOS_LAMBDA (int) {\n\t\tint current_node = current[0];\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tint neighbor = i;\n\t\t\tint d_current_to_neighbor = A(current_node, neighbor);\n\t\t\tint d_neighbor_to_dest = A(neighbor, dest);\n\t\t\tif (d_current_to_neighbor!= 0 && d_neighbor_to_dest!= 0) {\n\t\t\t\tint d_current_to_dest = distances[current_node] + d_current_to_neighbor + d_neighbor_to_dest;\n\t\t\t\tif (d_current_to_dest < distances[neighbor]) {\n\t\t\t\t\tdistances[neighbor] = d_current_to_dest;\n\t\t\t\t\tcurrent[0] = neighbor;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\t// Return the distance from the source node to the destination node.\n\treturn distances[dest];\n}",
            "// Add your code here\n\n  return -1;\n}",
            "Kokkos::View<int*> dist(\"Dist\", N);\n    Kokkos::View<int*> queue(\"Queue\", N);\n    int level = 0;\n\n    // initialize the distance for each node to infinity.\n    Kokkos::parallel_for(\"Initialize Distance\", N, KOKKOS_LAMBDA(int i) {\n        dist(i) = Kokkos::Details::ArithTraits<int>::max();\n    });\n\n    // mark the source node as 0 distance.\n    dist(source) = 0;\n\n    // mark the source node in the queue\n    queue(0) = source;\n    int queueSize = 1;\n\n    // loop through the queue and expand each node's neighbors.\n    // for each node, keep track of the distance to it.\n    while(queueSize > 0) {\n        int u = queue(--queueSize);\n        for(int v = 0; v < N; v++) {\n            if(A(u, v) == 1) {\n                // if the distance to v is longer, update it.\n                if(dist(v) > dist(u) + 1) {\n                    dist(v) = dist(u) + 1;\n                    // mark the node in the queue\n                    queue(queueSize++) = v;\n                }\n            }\n        }\n    }\n\n    return dist(dest);\n}",
            "using Policy = Kokkos::RangePolicy<Kokkos::LaunchBounds<100, 1> >;\n\tusing ExecutionSpace = Kokkos::DefaultExecutionSpace;\n\tusing Workspace = Kokkos::View<int*, Kokkos::HostSpace>;\n\n\tint *work = (int*)Kokkos::kokkos_malloc(sizeof(int) * N);\n\tKokkos::View<Workspace> w(Kokkos::ViewAllocateWithoutInitializing(\"w\"), N);\n\n\tKokkos::parallel_for(\"ShortestPathLength\", Policy(0, N), KOKKOS_LAMBDA(const int i) {\n\t\twork[i] = INT_MAX;\n\t\tw(i) = INT_MAX;\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(\"ShortestPathLength\", Policy(0, N), KOKKOS_LAMBDA(const int i) {\n\t\tif (i == source) {\n\t\t\twork[i] = 0;\n\t\t\tw(i) = 0;\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tint total = 0;\n\tbool done = false;\n\twhile (!done) {\n\t\ttotal++;\n\t\tdone = true;\n\t\tKokkos::parallel_for(\"ShortestPathLength\", Policy(0, N), KOKKOS_LAMBDA(const int i) {\n\t\t\tint newPath = INT_MAX;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(i, j) && work[j] < INT_MAX) {\n\t\t\t\t\tint possiblePath = 1 + work[j];\n\t\t\t\t\tif (possiblePath < newPath) {\n\t\t\t\t\t\tnewPath = possiblePath;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tw(i) = newPath;\n\t\t\tif (newPath < work[i]) {\n\t\t\t\tdone = false;\n\t\t\t}\n\t\t\twork[i] = newPath;\n\t\t});\n\t\tKokkos::fence();\n\t\t// std::swap(work, w);\n\t}\n\tint result = work[dest];\n\n\tKokkos::kokkos_free(work);\n\n\treturn result;\n}",
            "if (A.extent(0)!= A.extent(1) || source < 0 || source >= A.extent(0) || dest < 0 || dest >= A.extent(0))\n        throw std::invalid_argument(\"Invalid input\");\n\n    int result = -1;\n    Kokkos::View<int**> B(\"B\", N, N);\n    Kokkos::parallel_for(\"InitB\", Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N), KOKKOS_LAMBDA(const int i) {\n        for (int j = 0; j < N; j++)\n            B(i,j) = -1;\n    });\n    Kokkos::fence();\n\n    // TODO: Implement me!\n\n    return result;\n}",
            "// TODO: implement this function in parallel using Kokkos\n\treturn 0;\n}",
            "// TODO\n}",
            "Kokkos::View<int**> B(\"B\", N, N);\n  // TODO: Implement me\n  return 0;\n}",
            "// TODO: Implement me!\n}",
            "if (source == dest) return 0;\n    if (source < 0 || source > N-1) throw \"source out of bounds\";\n    if (dest < 0 || dest > N-1) throw \"dest out of bounds\";\n\n    Kokkos::View<int**> B(\"B\", N, N);\n    Kokkos::View<int**> C(\"C\", N, N);\n    Kokkos::View<int**> D(\"D\", N, N);\n    Kokkos::View<int**> E(\"E\", N, N);\n    Kokkos::View<int**> F(\"F\", N, N);\n\n    Kokkos::parallel_for(\"B\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n        KOKKOS_LAMBDA(int i, int j) {\n            B(i,j) = -1;\n        }\n    );\n\n    Kokkos::parallel_for(\"C\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n        KOKKOS_LAMBDA(int i, int j) {\n            C(i,j) = -1;\n        }\n    );\n\n    Kokkos::parallel_for(\"D\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n        KOKKOS_LAMBDA(int i, int j) {\n            D(i,j) = -1;\n        }\n    );\n\n    Kokkos::parallel_for(\"E\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n        KOKKOS_LAMBDA(int i, int j) {\n            E(i,j) = -1;\n        }\n    );\n\n    Kokkos::parallel_for(\"F\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n        KOKKOS_LAMBDA(int i, int j) {\n            F(i,j) = -1;\n        }\n    );\n\n    int min_path_len = -1;\n    Kokkos::View<int**> min_path_len_view(\"min_path_len\", 1, 1);\n    Kokkos::parallel_for(\"min_path_len\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, 1, 0, 1),\n        KOKKOS_LAMBDA(int i, int j) {\n            min_path_len_view(i,j) = min_path_len;\n        }\n    );\n\n    int iteration_count = 0;\n    Kokkos::View<int**> iteration_count_view(\"iteration_count\", 1, 1);\n    Kokkos::parallel_for(\"iteration_count\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, 1, 0, 1),\n        KOKKOS_LAMBDA(int i, int j) {\n            iteration_count_view(i,j) = iteration_count;\n        }\n    );\n\n    bool flag1 = true;\n    Kokkos::View<int**> flag1_view(\"flag1\", 1, 1);\n    Kokkos::parallel_for(\"flag1\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, 1, 0, 1),\n        KOKKOS_LAMBDA(int i, int j) {\n            flag1_view(i,j) = flag1;\n        }\n    );\n\n    bool flag2 = true;\n    Kokkos::View<int**> flag2_view(\"flag2\", 1, 1);\n    Kokkos::parallel_for(\"flag2\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, 1, 0, 1),\n        KOKKOS_",
            "if (source == dest) return 0;\n\tif (source == dest) return 1;\n\tif (source == dest) return 2;\n\tif (source == dest) return 3;\n\tif (source == dest) return 4;\n\tif (source == dest) return 5;\n\n\n\n}",
            "using view_t = Kokkos::View<int*>;\n\n\tint *pathLength = new int[N];\n\tview_t pathLength_kok(\"pathLength\", N);\n\tauto policy = Kokkos::RangePolicy<Kokkos::Cuda>(0, N);\n\tKokkos::parallel_for(\"pathLength\", policy, [&] (const int& i) {\n\t\tpathLength[i] = 0;\n\t});\n\tKokkos::deep_copy(pathLength_kok, pathLength);\n\tdelete [] pathLength;\n\n\tKokkos::fence();\n\n\tint level = 1;\n\twhile (true) {\n\t\t// Compute level-th level neighbors of nodes\n\t\tauto policy = Kokkos::RangePolicy<Kokkos::Cuda>(0, N);\n\t\tKokkos::parallel_for(\"level_neighbors\", policy, [&] (const int& i) {\n\t\t\tint current_neighbors = 0;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (pathLength_kok[j] == level - 1) {\n\t\t\t\t\tif (A(j, i) == 1) {\n\t\t\t\t\t\tcurrent_neighbors++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (current_neighbors > 0) {\n\t\t\t\tpathLength_kok[i] = level;\n\t\t\t}\n\t\t});\n\n\t\tKokkos::fence();\n\n\t\t// Check if dest has been reached\n\t\tif (pathLength_kok[dest] == level) {\n\t\t\tbreak;\n\t\t}\n\n\t\tlevel++;\n\t}\n\n\tint result;\n\tKokkos::parallel_reduce(\"get_result\", policy, [&] (const int& i, int& l) {\n\t\tl = pathLength_kok[i];\n\t}, result);\n\n\tKokkos::fence();\n\n\treturn result;\n}",
            "/* TODO: Fill this in */\n\n\treturn 0;\n}",
            "Kokkos::View<int**> D(Kokkos::ViewAllocateWithoutInitializing(\"D\"), N, N);\n\n  // TODO: initialize D here\n\n  // TODO: compute shortestPathLength\n\n  int result = -1;\n  return result;\n}",
            "using GraphType = Kokkos::CrsGraph<int, int, Kokkos::LayoutLeft, Kokkos::HostSpace>;\n\n  GraphType graph;\n  Kokkos::View<int*, Kokkos::HostSpace> ptr(\"ptr\", N+1);\n  Kokkos::View<int*, Kokkos::HostSpace> ind(\"ind\", N*N);\n  Kokkos::View<int*, Kokkos::HostSpace> val(\"val\", N*N);\n\n  // Construct the graph\n  int ind_index = 0;\n  for (int i = 0; i < N; ++i) {\n    ptr[i] = ind_index;\n    for (int j = 0; j < N; ++j) {\n      if (A(i, j) == 1) {\n        ind[ind_index] = j;\n        val[ind_index] = 1;\n        ind_index++;\n      }\n    }\n  }\n  ptr[N] = ind_index;\n\n  Kokkos::deep_copy(graph.row_map, ptr);\n  Kokkos::deep_copy(graph.entries, ind);\n  Kokkos::deep_copy(graph.values, val);\n\n  // Create the workspace\n  typedef Kokkos::DefaultExecutionSpace ExecSpace;\n  typedef typename ExecSpace::memory_space MemorySpace;\n  typedef Kokkos::View<int*, MemorySpace> PathLengthType;\n  PathLengthType path_length(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"path_length\"), N);\n\n  // BFS the graph\n  Kokkos::parallel_for(\"BFS\", Kokkos::RangePolicy<ExecSpace>(0, N),\n      KOKKOS_LAMBDA(const int& i) {\n        if (i == source)\n          path_length[i] = 0;\n        else\n          path_length[i] = -1;\n      });\n\n  Kokkos::parallel_for(\"BFS\", Kokkos::RangePolicy<ExecSpace>(0, N),\n      KOKKOS_LAMBDA(const int& i) {\n        // For each node i, see if we can reach it from source\n        for (int j = graph.row_map[i]; j < graph.row_map[i+1]; ++j) {\n          int other_node = graph.entries(j);\n          if (path_length[other_node] >= 0) {\n            // We've reached this node through another node\n            path_length[i] = 1 + path_length[other_node];\n          }\n        }\n      });\n\n  Kokkos::fence();\n\n  // Find the length of the shortest path from source to dest\n  int shortest_path_length = -1;\n  for (int i = 0; i < N; ++i) {\n    if (i == source) {\n      shortest_path_length = 0;\n    } else if (path_length[i] >= 0) {\n      // There is a path to i from source\n      if (i == dest) {\n        shortest_path_length = path_length[i];\n      } else if (shortest_path_length == -1 || shortest_path_length > path_length[i]) {\n        // i is closer to source than any previous nodes\n        shortest_path_length = path_length[i];\n      }\n    }\n  }\n\n  return shortest_path_length;\n}",
            "// TODO: your code here\n  int my_val = 0;\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> V_host( \"V_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> S_host( \"S_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> prev_host( \"prev_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> Q_host( \"Q_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> temp_host( \"temp_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> dist_host( \"dist_host\", N);\n  Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> adj_host( \"adj_host\", N);\n  Kokkos::deep_copy(V_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(temp_host, 0);\n  Kokkos::deep_copy(dist_host, 0);\n  Kokkos::deep_copy(adj_host, 0);\n  Kokkos::deep_copy(adj_host, A);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(Q_host, source);\n  Kokkos::deep_copy(V_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kokkos::deep_copy(Q_host, 0);\n  Kokkos::deep_copy(S_host, 0);\n  Kokkos::deep_copy(prev_host, 0);\n  Kok",
            "// TODO: put your code here\n  // Return shortestPathLength\n  // Use Kokkos::View<int**> to store the length of the shortest path from the source to each vertex.\n  // Use Kokkos::parallel_for to update the lengths.\n  // You may need Kokkos::single to get the minimum.\n  // Use Kokkos::deep_copy to get the answer.\n  // Remember that we can access elements of a Kokkos::View<const int**> with the following syntax:\n  // A(i, j)\n  // Do not call Kokkos::deep_copy on the result.\n\n  return 0;\n}",
            "// TODO\n}",
            "int l = 0;\n\n  // 1. allocate a boolean array b of length N (one for each vertex),\n  //    and set b[source] = true.\n  Kokkos::View<bool*> b(\"b\", N);\n  Kokkos::deep_copy(b, false);\n  b[source] = true;\n\n  // 2. while b[dest] = false\n  while (!b[dest]) {\n\n    // 2a. for each vertex v, if b[v] = false and there exists an edge from v to a vertex u\n    //     such that b[u] = true, then set b[v] = true.\n    Kokkos::parallel_for(\"for_each\", N, KOKKOS_LAMBDA (int i) {\n      if (!b[i] && A(i, dest)) {\n        b[i] = true;\n      }\n    });\n    Kokkos::fence();\n\n    // 2b. increment l\n    l++;\n  }\n  return l;\n}",
            "using namespace Kokkos;\n  using MDRangePolicy = Kokkos::MDRangePolicy<Kokkos::Rank<2>>;\n\n  const int M = 3;\n  const int max_path = M * M;\n  const int INF = max_path + 1;\n\n  Kokkos::View<int**> P(\"P\", N, max_path);\n  Kokkos::View<int*> D(\"D\", max_path);\n\n  Kokkos::fence();\n  Kokkos::deep_copy(P, INF);\n  Kokkos::deep_copy(D, -1);\n\n  Kokkos::parallel_for(MDRangePolicy({0, 0}, {N, M}), [&](int i, int j) {\n    P(i, j) = 0;\n  });\n\n  // Set the first vertex in the path to be source.\n  Kokkos::parallel_for(MDRangePolicy({source, 0}, {source + 1, M}), [&](int i, int j) {\n    P(i, j) = 0;\n  });\n\n  Kokkos::fence();\n\n  for (int i = 0; i < max_path; i++) {\n    Kokkos::parallel_for(MDRangePolicy({0, 0}, {N, M}), [&](int i, int j) {\n      if (P(i, j) < INF) {\n        for (int k = 0; k < N; k++) {\n          if (A(i, k) == 1 && P(k, j) > P(i, j) + 1) {\n            P(k, j) = P(i, j) + 1;\n            D(j) = i;\n          }\n        }\n      }\n    });\n    Kokkos::fence();\n  }\n\n  // Reverse path from dest to source\n  int j = 0;\n  while (D(j)!= source && j < max_path) {\n    j++;\n  }\n  j++;\n\n  int length = 0;\n  while (j > 0) {\n    length++;\n    j = P(D(j - 1), j - 1);\n  }\n\n  return length;\n}",
            "Kokkos::View<int*> distance(\"Distance\", N);\n    Kokkos::View<bool*> visited(\"Visited\", N);\n    Kokkos::parallel_for(\n        \"Dijkstra\", Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>(0, N),\n        KOKKOS_LAMBDA(int i) {\n          distance[i] = INT_MAX;\n          visited[i] = false;\n        });\n    Kokkos::deep_copy(distance, INT_MAX);\n    Kokkos::deep_copy(visited, false);\n    distance[source] = 0;\n\n    while (true) {\n        bool found = false;\n        int next_distance = INT_MAX;\n        int next_vertex = -1;\n        Kokkos::parallel_reduce(\n            \"Dijkstra\", Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>(0, N),\n            KOKKOS_LAMBDA(int i, bool& lsum) {\n              if (!visited[i] && distance[i] < next_distance) {\n                lsum = true;\n                next_distance = distance[i];\n                next_vertex = i;\n              }\n            }, Kokkos::Experimental::Reduce::min<bool>(found));\n        if (!found) break;\n\n        Kokkos::parallel_for(\n            \"Dijkstra\", Kokkos::RangePolicy<Kokkos::Schedule<Kokkos::Dynamic>>(0, N),\n            KOKKOS_LAMBDA(int i) {\n              if (A(next_vertex, i)) {\n                if (distance[i] > next_distance + 1)\n                  distance[i] = next_distance + 1;\n              }\n            });\n        Kokkos::deep_copy(visited, false);\n        visited[next_vertex] = true;\n    }\n    int l_shortestPathLength = distance[dest];\n\n    return l_shortestPathLength;\n}",
            "// Kokkos requires that the source array is non-const.\n\tKokkos::View<int**> B = Kokkos::create_mirror_view(A);\n\n\t// Copy the input to the mirror view.\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tB(i, j) = A(i, j);\n\t\t}\n\t}\n\n\t// Perform the algorithm.\n\tint shortestPathLength = bfs(B, N, source, dest);\n\n\t// Copy the results back to the device.\n\tKokkos::deep_copy(A, B);\n\n\treturn shortestPathLength;\n}",
            "Kokkos::View<int**> dists(\"dists\", N, N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (i == j) {\n\t\t\t\tdists(i, j) = 0;\n\t\t\t} else {\n\t\t\t\tdists(i, j) = 10000;\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(size_t k) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A(i, k) + A(k, j) < dists(i, j)) {\n\t\t\t\t\tdists(i, j) = A(i, k) + A(k, j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\treturn dists(source, dest);\n}",
            "/* TODO: Fill this in*/\n\t\n\tint num_iterations = 0;\n\tint length = 0;\n\t\n\t// Create a new View for distance to hold all the distances.\n\t// Initialize all elements to -1, except source to 0.\n\tKokkos::View<int*> distance(\"distances\", N);\n\tKokkos::parallel_for(\"init distances\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tif (i == source)\n\t\t\tdistance(i) = 0;\n\t\telse\n\t\t\tdistance(i) = -1;\n\t});\n\tKokkos::fence();\n\n\t// Do a BFS for shortest path from source to dest.\n\t// Assume the graph is undirected and unweighted.\n\tKokkos::View<int*> processed(\"processed\", N);\n\tKokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const int& i) {\n\t\t// Initialize everything to false.\n\t\tprocessed(i) = 0;\n\t});\n\tKokkos::fence();\n\n\tKokkos::parallel_for(\"BFS\", N, KOKKOS_LAMBDA(const int& i) {\n\t\tint curr = source;\n\t\tint next = -1;\n\t\tint distance_curr = 0;\n\n\t\t// If this vertex has already been processed, move on.\n\t\tif (processed(i) == 1)\n\t\t\treturn;\n\n\t\twhile (curr!= -1 && curr!= dest) {\n\t\t\t// Go through the neighbors of curr.\n\t\t\t// If the neighbor has not been processed, add it to queue.\n\t\t\t// If the neighbor has been processed, check if the distance to it through curr is shorter.\n\t\t\t// Update distance in this case.\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A(curr, j) == 1) {\n\t\t\t\t\tif (processed(j) == 0) {\n\t\t\t\t\t\tnext = j;\n\t\t\t\t\t}\n\t\t\t\t\telse if (distance(curr) + 1 < distance(j)) {\n\t\t\t\t\t\tdistance(j) = distance(curr) + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Go to the next neighbor, if there is one.\n\t\t\tif (next!= -1) {\n\t\t\t\tdistance_curr = distance(curr);\n\t\t\t\tdistance(next) = distance_curr + 1;\n\t\t\t\tcurr = next;\n\t\t\t\tnext = -1;\n\t\t\t}\n\t\t\t// Else, go back to the previous vertex in the path, if there is one.\n\t\t\telse {\n\t\t\t\t// Mark curr as processed.\n\t\t\t\tprocessed(curr) = 1;\n\t\t\t\tdistance_curr = distance(curr);\n\n\t\t\t\tif (distance(curr)!= 0)\n\t\t\t\t\tnum_iterations++;\n\n\t\t\t\tif (curr == source)\n\t\t\t\t\tlength = distance_curr;\n\n\t\t\t\tcurr = -1;\n\t\t\t\tfor (int k = 0; k < N; ++k) {\n\t\t\t\t\tif (processed(k) == 0) {\n\t\t\t\t\t\tcurr = k;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tKokkos::fence();\n\n\t// Return the shortest path length.\n\t// Return -1 if there is no path from source to dest.\n\tif (processed(dest) == 0) {\n\t\treturn -1;\n\t}\n\telse {\n\t\treturn length;\n\t}\n}",
            "//...\n}",
            "Kokkos::View<int*> V(\"V\", N);\n  Kokkos::View<int*> S(\"S\", N);\n\n  Kokkos::View<int**> M(\"M\", N, N);\n\n  Kokkos::View<int*> d(\"d\", N);\n  Kokkos::View<int*> p(\"p\", N);\n\n  Kokkos::View<int*> w(\"w\", N);\n  Kokkos::View<int*> q(\"q\", N);\n\n  Kokkos::View<bool*> done(\"done\", N);\n\n  Kokkos::deep_copy(V, 0);\n  Kokkos::deep_copy(S, 0);\n  Kokkos::deep_copy(M, 0);\n\n  Kokkos::deep_copy(d, 0);\n  Kokkos::deep_copy(p, 0);\n\n  Kokkos::deep_copy(w, 0);\n  Kokkos::deep_copy(q, 0);\n\n  Kokkos::deep_copy(done, false);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int &i) {\n    d(i) = 0;\n    p(i) = 0;\n\n    w(i) = 0;\n    q(i) = 0;\n\n    V(i) = 1;\n    S(i) = 1;\n  });\n\n  Kokkos::deep_copy(M, A);\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                       [&](const int &i) { M(i, i) = 0; });\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                       [&](const int &i) {\n                         if (i == source) {\n                           done(i) = true;\n                         }\n                       });\n\n  int ans = 0;\n\n  while (Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                                 [&](const int &i, int &l) { return!done(i); },\n                                 Kokkos::Max<int>(l)) > 0) {\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                         [&](const int &i) { w(i) = d(i) + M(i, source); });\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                         [&](const int &i) {\n                           if (w(i) < d(i)) {\n                             p(i) = source;\n                             d(i) = w(i);\n                           }\n                         });\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                         [&](const int &i) { q(i) = S(i) + M(i, p(i)); });\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                         [&](const int &i) {\n                           if (q(i) < S(i)) {\n                             S(i) = q(i);\n                             p(i) = p(p(i));\n                           }\n                         });\n\n    Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n                         [&](const int &i) {\n                           if (i == dest) {\n                             done(i) = true;\n                             ans = d(i);\n                           }\n                         });\n  }\n\n  return ans;\n}",
            "Kokkos::View<int**> dist(\"dist\", N, N);\n\tKokkos::parallel_for(\"initDist\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n\t\t\t[&](const int i, const int j) {\n\t\tdist(i, j) = (i == j)? 0 : std::numeric_limits<int>::max();\n\t});\n\n\tKokkos::View<int**> pred(\"pred\", N, N);\n\tKokkos::parallel_for(\"initPred\", Kokkos::RangePolicy<Kokkos::Rank<2> >(0, N, 0, N),\n\t\t\t[&](const int i, const int j) {\n\t\tpred(i, j) = (i == j)? i : -1;\n\t});\n\n\tKokkos::fence();\n\n\tKokkos::parallel_for(\"BellmanFord\", Kokkos::RangePolicy<Kokkos::Rank<1> >(0, N),\n\t\t\t[&](const int i) {\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (dist(k, j) > dist(k, i) + A(i, j)) {\n\t\t\t\t\tdist(k, j) = dist(k, i) + A(i, j);\n\t\t\t\t\tpred(k, j) = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\n\tKokkos::fence();\n\n\t// Check for negative cycle\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist(i, j) > dist(i, pred(i, j)) + A(i, j)) {\n\t\t\t\tstd::cerr << \"Graph has a negative cycle\\n\";\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t}\n\n\tint pathLength = dist(dest, source);\n\n\treturn pathLength;\n}",
            "// Create and initialize a Kokkos view for the distance values, which is an N-dimensional array.\n\tKokkos::View<int*> dist(\"dist\", N);\n\tKokkos::deep_copy(dist, -1);\n\n\t// Create and initialize a Kokkos view for the work list, which is a 1-dimensional array.\n\tKokkos::View<int*> work_list(\"work_list\", N);\n\tKokkos::deep_copy(work_list, -1);\n\n\t// Use Kokkos to run a parallel computation on the GPU or the CPU\n\tint length = 0;\n\tKokkos::parallel_for(\n\t\t\"shortestPathLength\",\n\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, N),\n\t\tKOKKOS_LAMBDA(const int &i) {\n\t\t\t// If node i is the source, put it in the work list, and set its distance to zero.\n\t\t\tif (i == source) {\n\t\t\t\twork_list(i) = i;\n\t\t\t\tdist(i) = 0;\n\t\t\t}\n\t\t}\n\t);\n\n\t// Create a Kokkos view for the work list size, and set it to the number of nodes in the graph.\n\t// We will use this to control the size of the work list in the loop below.\n\tKokkos::View<int> work_list_size(\"work_list_size\", 1);\n\tKokkos::deep_copy(work_list_size, N);\n\n\t// Iterate until we find the destination node or until the work list is empty.\n\twhile (work_list_size() > 0) {\n\t\t// Create a Kokkos view for the number of nodes visited this iteration, and set it to zero.\n\t\tKokkos::View<int> nodes_visited(\"nodes_visited\", 1);\n\t\tKokkos::deep_copy(nodes_visited, 0);\n\n\t\t// If the work list has nodes, we will iterate over it.\n\t\t// Each iteration, we will process the nodes in the work list in parallel.\n\t\tKokkos::parallel_for(\n\t\t\t\"shortestPathLength\",\n\t\t\tKokkos::RangePolicy<Kokkos::Cuda>(0, work_list_size()),\n\t\t\tKOKKOS_LAMBDA(const int &i) {\n\t\t\t\t// Get the index of the node we are working on.\n\t\t\t\tint node = work_list(i);\n\n\t\t\t\t// Iterate over each neighbor of the node we are working on.\n\t\t\t\tfor (int neighbor = 0; neighbor < N; neighbor++) {\n\t\t\t\t\t// If the distance to the neighbor is unknown, we will consider adding it to the work list.\n\t\t\t\t\tif (dist(neighbor) < 0) {\n\t\t\t\t\t\t// Determine the new distance.\n\t\t\t\t\t\tint new_dist = dist(node) + 1;\n\n\t\t\t\t\t\t// If the distance is less than what we currently have for the neighbor, we will update the\n\t\t\t\t\t\t// distance and put the neighbor in the work list.\n\t\t\t\t\t\tif (new_dist < dist(neighbor)) {\n\t\t\t\t\t\t\tdist(neighbor) = new_dist;\n\t\t\t\t\t\t\twork_list(i) = neighbor;\n\t\t\t\t\t\t\tnodes_visited() = nodes_visited() + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If we didn't add the neighbor to the work list, remove it from the work list.\n\t\t\t\tif (nodes_visited() == 0) {\n\t\t\t\t\twork_list(i) = work_list(work_list_size() - 1);\n\t\t\t\t\twork_list_size() = work_list_size() - 1;\n\t\t\t\t}\n\t\t\t}\n\t\t);\n\n\t\t// If we are at the destination, we will stop.\n\t\tif (",
            "using view_type = Kokkos::View<int*>;\n  using execution_space = Kokkos::DefaultExecutionSpace;\n\n  const int n = N;\n  const int source_ = source;\n  const int dest_ = dest;\n\n  Kokkos::View<int**, Kokkos::LayoutLeft, execution_space> distance(\"distance\", n, n);\n  Kokkos::View<int*, Kokkos::LayoutLeft, execution_space> previous(\"previous\", n);\n  Kokkos::View<bool*, Kokkos::LayoutLeft, execution_space> visited(\"visited\", n);\n\n  auto distance_h = Kokkos::create_mirror_view(distance);\n  auto previous_h = Kokkos::create_mirror_view(previous);\n  auto visited_h = Kokkos::create_mirror_view(visited);\n\n  // Initialize distance as infinite and visited as false\n  Kokkos::parallel_for(\n    \"Initialize distance and visited\",\n    Kokkos::RangePolicy<execution_space>(0, n),\n    KOKKOS_LAMBDA(const int i) {\n      for (int j = 0; j < n; j++) {\n        distance_h(i, j) = -1;\n      }\n      visited_h(i) = false;\n    }\n  );\n\n  // Copy to device\n  Kokkos::deep_copy(distance, distance_h);\n  Kokkos::deep_copy(previous, previous_h);\n  Kokkos::deep_copy(visited, visited_h);\n\n  // Set distance of source to 0\n  Kokkos::parallel_for(\n    \"Set distance\",\n    Kokkos::RangePolicy<execution_space>(0, 1),\n    KOKKOS_LAMBDA(const int i) {\n      distance_h(i, source_) = 0;\n    }\n  );\n\n  Kokkos::deep_copy(distance, distance_h);\n\n  Kokkos::parallel_for(\n    \"Set previous\",\n    Kokkos::RangePolicy<execution_space>(0, 1),\n    KOKKOS_LAMBDA(const int i) {\n      previous_h(i) = source_;\n    }\n  );\n\n  Kokkos::deep_copy(previous, previous_h);\n\n  // Breadth-first search\n  Kokkos::parallel_for(\n    \"BFS\",\n    Kokkos::RangePolicy<execution_space>(0, n),\n    KOKKOS_LAMBDA(const int i) {\n      for (int j = 0; j < n; j++) {\n        if (visited_h(j) == false) {\n          for (int k = 0; k < n; k++) {\n            if (distance_h(j, k) > distance_h(j, source_) + A(j, k)) {\n              distance_h(j, k) = distance_h(j, source_) + A(j, k);\n              previous_h(k) = j;\n            }\n          }\n        }\n      }\n    }\n  );\n\n  Kokkos::deep_copy(distance, distance_h);\n  Kokkos::deep_copy(previous, previous_h);\n\n  Kokkos::parallel_for(\n    \"Check\",\n    Kokkos::RangePolicy<execution_space>(0, n),\n    KOKKOS_LAMBDA(const int i) {\n      for (int j = 0; j < n; j++) {\n        if (previous_h(j) == dest_) {\n          visited_h(j) = true;\n        }\n      }\n    }\n  );\n\n  Kokkos::deep_copy(visited, visited_h);\n\n  // Return the length of the shortest path from source to dest\n  auto max_len = Kokkos::subview(distance, source_, Kokkos::ALL());\n  auto max_len_h = Kokkos::create_mirror_view(max_len);\n  Kokkos::deep_copy(max_len_h, max_len);",
            "// TODO: fill in\n  return 0;\n}",
            "Kokkos::View<int**> Q(\"Q\", N, N);\n\n    Kokkos::parallel_for(\n        Kokkos::RangePolicy<Kokkos::TeamPolicy<Kokkos::Serial> >(0, N),\n        [&](int i) {\n            Q(i, i) = 0;\n        }\n    );\n\n    // TODO: Fill in this function\n\n    return -1;\n}",
            "// 1. Create a view to store the shortest path length.\n    // 2. Set up a parallel_for loop.\n    // 3. Compute the length of the shortest path recursively.\n    // 4. Synchronize and return the shortest path length.\n\n    return 0;\n}",
            "int N = A.extent(0);\n\t// TODO: define the following Kokkos Views to use in the implementation\n\t// Hint: these should be the same size as the input\n\tKokkos::View<int**> D;\n\tKokkos::View<int**> P;\n\n\t// TODO: set D to -1\n\n\t// TODO: set P to -1\n\n\t// TODO: use Kokkos to set D and P using the algorithm in the slides\n\t// Hint: you'll need to use Kokkos parallel_for, range policies\n\t\n\t// TODO: use D[dest] to get the length of the shortest path\n\t// Hint: if D[dest] is -1, that means there is no path from the source to the destination\n\n\t// TODO: free memory\n\n\t// Return D[dest]\n\treturn D(dest);\n}",
            "using ExecPolicy = Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>;\n    using ReducePolicy = Kokkos::RangePolicy<Kokkos::DefaultHostExecutionSpace>;\n\n    Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> dp(\"dp\", N);\n    Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> min_dp(\"min_dp\", N);\n\n    // initialize dp and min_dp\n    Kokkos::parallel_for(\"init\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int &i) {\n        dp(i) = -1;\n        min_dp(i) = -1;\n    });\n\n    // update dp\n    Kokkos::parallel_for(\"update\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int &i) {\n        for (int j = 0; j < N; j++) {\n            if (A(i, j) == 1 && dp(j)!= -1) {\n                dp(i) = dp(j) + 1;\n                break;\n            }\n        }\n    });\n\n    // find the shortest path length\n    int min = 1000000;\n    Kokkos::parallel_for(\"find_min\", ExecPolicy(0, N), KOKKOS_LAMBDA(const int &i) {\n        if (dp(i)!= -1 && dp(i) < min) {\n            min = dp(i);\n        }\n    });\n\n    return min;\n}",
            "const size_t NN = N*N;\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> dist(\"dist\", NN);\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::HostSpace> q(\"q\", NN);\n\n\t// Initialize distance and queue\n\tKokkos::parallel_for(\"initDist\", NN, KOKKOS_LAMBDA(const int &i) {\n\t\tdist(i) = 1e9;\n\t\tq(i) = -1;\n\t});\n\n\t// Add source to queue\n\tKokkos::parallel_for(\"enqueue\", 1, KOKKOS_LAMBDA(const int &i) {\n\t\tq(source) = 0;\n\t\tdist(source) = 0;\n\t});\n\n\t// Breadth-first search\n\twhile (q(source)!= -1) {\n\t\t// Dequeue\n\t\tint u = q(source);\n\t\tq(source) = -1;\n\t\tsource = (source+1) % NN;\n\n\t\t// For each neighbor v of u\n\t\tKokkos::parallel_for(\"forNeighbor\", N, KOKKOS_LAMBDA(const int &i) {\n\t\t\tint v = A(u, i);\n\t\t\tint newDist = dist(u) + 1;\n\t\t\tif (v >= 0 && dist(v) > newDist) {\n\t\t\t\tdist(v) = newDist;\n\t\t\t\tq(v) = u;\n\t\t\t}\n\t\t});\n\t}\n\n\treturn dist(dest);\n}",
            "using MatrixType = Kokkos::View<int**>;\n    using execution_space = Kokkos::DefaultHostExecutionSpace;\n\n    int *dist = new int[N];\n\n    Kokkos::parallel_for(\"init_dist\", Kokkos::RangePolicy<execution_space>(0, N), [&](int& i) {\n      dist[i] = (i == source)? 0 : INT_MAX;\n    });\n\n    Kokkos::parallel_for(\"dijkstra\", Kokkos::RangePolicy<execution_space>(0, N), [&](int& u) {\n      for (int v = 0; v < N; ++v) {\n        if (dist[u]!= INT_MAX && A(u, v)!= 0 && dist[v] > dist[u] + 1) {\n          dist[v] = dist[u] + 1;\n        }\n      }\n    });\n\n    int min_distance = INT_MAX;\n    for (int i = 0; i < N; ++i) {\n      if (i!= source && dist[i] < min_distance) {\n        min_distance = dist[i];\n      }\n    }\n\n    delete [] dist;\n    return min_distance;\n}",
            "// TODO: Your code here!\n\n  return -1;\n}",
            "// TODO: Your code here\n  return -1;\n}",
            "// TODO\n\n\t// Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> dist(\"dist\", N);\n\t// Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> pred(\"pred\", N);\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> dist(\"dist\", N);\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> pred(\"pred\", N);\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> flag(\"flag\", N);\n\n\t// Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> dist(\"dist\", N);\n\t// Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> pred(\"pred\", N);\n\t// Kokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> flag(\"flag\", N);\n\n\tint max = 1000000;\n\tKokkos::parallel_for( \"shortestPathLength\", N, KOKKOS_LAMBDA (const int &i){\n\t\tdist(i) = max;\n\t\tpred(i) = -1;\n\t\tflag(i) = 0;\n\t});\n\n\tKokkos::parallel_for( \"shortestPathLength\", N, KOKKOS_LAMBDA (const int &i){\n\t\tdist(source) = 0;\n\t});\n\n\tKokkos::parallel_for( \"shortestPathLength\", N, KOKKOS_LAMBDA (const int &i){\n\t\tint s = i;\n\t\tint d = i;\n\t\tint flag = 1;\n\t\twhile(flag > 0){\n\t\t\tflag = 0;\n\t\t\tfor(int n = 0; n < N; n++){\n\t\t\t\tif((A(s,n) == 1) && (dist(s) + 1 < dist(n))){\n\t\t\t\t\tdist(n) = dist(s) + 1;\n\t\t\t\t\tpred(n) = s;\n\t\t\t\t\tflag = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\ts = pred(s);\n\t\t}\n\t});\n\n\tint dist_dest = dist(dest);\n\tif(dist_dest == max){\n\t\treturn -1;\n\t}else{\n\t\treturn dist_dest;\n\t}\n\n\n\n}",
            "const int MAX_DIST = std::numeric_limits<int>::max();\n  const int UNVISITED = -1;\n\n  Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> parent(\"parent\", N);\n\n  // Initialize parent and dist arrays\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t &i) {\n    parent(i) = UNVISITED;\n    dist(i) = MAX_DIST;\n  });\n  Kokkos::fence();\n\n  // Start BFS from source vertex\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t &i) {\n    if (i == source) {\n      parent(i) = source;\n      dist(i) = 0;\n    }\n  });\n  Kokkos::fence();\n\n  // Iterate while there are still vertices to be visited\n  Kokkos::View<bool, Kokkos::HostSpace> done(\"done\", 1);\n  Kokkos::View<int, Kokkos::HostSpace> dist_copy(\"dist_copy\", 1);\n\n  do {\n    done = true;\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const size_t &i) {\n      for (int j = 0; j < N; ++j) {\n        // For every unvisited vertex, relax it\n        if (parent(j) == UNVISITED && A(i, j) == 1) {\n          int new_dist = dist(i) + 1;\n\n          if (new_dist < dist(j)) {\n            parent(j) = i;\n            dist(j) = new_dist;\n            done = false;\n          }\n        }\n      }\n    });\n    Kokkos::fence();\n\n    // Copy result from device to host\n    Kokkos::deep_copy(dist_copy, dist);\n  } while (!done);\n\n  return dist_copy(dest);\n}",
            "Kokkos::View<int**> dists(\"dists\", N, N); // distances from the source node\n    Kokkos::View<bool**> updated(\"updated\", N, N); // whether we updated the distance to this node the last iteration\n\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            dists(i, j) = A(i, j);\n            updated(i, j) = (i == j); // for every node other than the source, set to false\n        }\n    }\n\n    Kokkos::deep_copy(dists, A);\n    Kokkos::deep_copy(updated, false);\n\n    // repeat until we stop making progress\n    int iters = 0;\n    bool done = false;\n    while (!done) {\n        ++iters;\n\n        // for each node\n        Kokkos::parallel_for(\"shortestPath\", N, KOKKOS_LAMBDA(int i) {\n            if (updated(i, i)) {\n                // for each neighbor\n                for (int j = 0; j < N; ++j) {\n                    // update the distance from i to j if necessary\n                    if (A(i, j) && dists(i, j) > (dists(i, i) + 1)) {\n                        dists(i, j) = dists(i, i) + 1;\n                        updated(i, j) = true;\n                    }\n                }\n            }\n        });\n\n        // check if we're done\n        Kokkos::parallel_reduce(\"done\", N, KOKKOS_LAMBDA(int i, bool &done) {\n            done = done || updated(i, i);\n        }, done);\n\n        Kokkos::deep_copy(updated, false);\n    }\n\n    // sum up the distances\n    Kokkos::View<int*, Kokkos::HostSpace> dists_host(\"dists_host\", N);\n    Kokkos::deep_copy(dists_host, dists);\n\n    // return the distance from the source node to the destination node\n    return dists_host(dest);\n}",
            "// Define the output array, the predecessor array, and the distance array.\n    // The distance array is where the output of the algorithm will be stored.\n    // The predecessor array is used to find the shortest path.\n    // Note that the output is stored in the distance array.\n    // The array is stored in the Kokkos default execution space,\n    // which is the default execution space Kokkos was configured to use.\n    // If you would like to use a different space, then you can use the following:\n    // Kokkos::View<int*> distance(\"distance\", N);\n    Kokkos::View<int*> distance(\"distance\", N);\n    Kokkos::View<int*> predecessor(\"predecessor\", N);\n\n    // Initialize the arrays.\n    Kokkos::parallel_for(\n        \"init\",\n        Kokkos::RangePolicy<>(0, N),\n        KOKKOS_LAMBDA(int i) {\n            distance(i) = INT_MAX;\n            predecessor(i) = -1;\n        }\n    );\n\n    // Compute the shortest path lengths from the source vertex to all other vertices.\n    // The algorithm will be run in parallel, unless the number of iterations is small\n    // enough that the overhead is too high.\n    Kokkos::parallel_for(\n        \"run\",\n        Kokkos::RangePolicy<>(0, N),\n        KOKKOS_LAMBDA(int i) {\n            // Initialize the distance array for the current vertex i.\n            // If i is the source vertex, then the distance to i is 0.\n            // Otherwise, the distance to i is INT_MAX.\n            distance(i) = (source == i)? 0 : INT_MAX;\n\n            // Iterate over all the neighbors of i.\n            for (int j = 0; j < N; j++) {\n                if (A(i, j) == 1) {\n                    // If there is a direct path from i to j,\n                    // then the distance to j is 1 more than the distance to i.\n                    // The predecessor is i.\n                    if (distance(i)!= INT_MAX && distance(j) > distance(i) + 1) {\n                        distance(j) = distance(i) + 1;\n                        predecessor(j) = i;\n                    }\n                }\n            }\n        }\n    );\n\n    // Compute the length of the shortest path from source to dest by iteratively\n    // following the predecessor array until the source vertex is reached.\n    int shortestPathLength = 0;\n    int vertex = dest;\n    while (vertex!= source) {\n        // If the vertex has no predecessor, then the graph has no path\n        // between source and dest.\n        if (predecessor(vertex) < 0)\n            return -1;\n\n        // Otherwise, follow the predecessor and increment the length of the path.\n        shortestPathLength++;\n        vertex = predecessor(vertex);\n    }\n\n    // Return the length of the shortest path.\n    return shortestPathLength;\n}",
            "// TODO: fill this in\n\n    return 0;\n}",
            "const auto policy = Kokkos::RangePolicy<Kokkos::OpenMP, int>(0, N);\n\n  // TODO: Implement me. You can use Kokkos::View::HostMirror for the intermediate results.\n\n  // Dijkstra's algorithm\n  return -1;\n}",
            "// Create the graph in a CSR format\n\tKokkos::View<int**> rowmap(\"rowmap\", N+1, 1);\n\tKokkos::View<int**> colinds(\"colinds\", N, N);\n\tint *rowmap_ptr = rowmap.data();\n\tint *colinds_ptr = colinds.data();\n\tint row = 0;\n\tint i = 0;\n\trowmap_ptr[row] = 0;\n\tfor (int j = 0; j < N; j++) {\n\t\tif (A(source,j) == 1) {\n\t\t\tcolinds_ptr[i] = j;\n\t\t\ti++;\n\t\t}\n\t\trowmap_ptr[row+1] = i;\n\t\trow++;\n\t}\n\n\t// Create the graph in a CSC format\n\tKokkos::View<int**> colmap(\"colmap\", N+1, 1);\n\tKokkos::View<int**> rowinds(\"rowinds\", N, N);\n\tint *colmap_ptr = colmap.data();\n\tint *rowinds_ptr = rowinds.data();\n\tint col = 0;\n\tint j = 0;\n\tcolmap_ptr[col] = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A(i,dest) == 1) {\n\t\t\trowinds_ptr[j] = i;\n\t\t\tj++;\n\t\t}\n\t\tcolmap_ptr[col+1] = j;\n\t\tcol++;\n\t}\n\n\t// Get the min of the rowmap and colmap\n\tint min = (rowmap_ptr[N] < colmap_ptr[N])? rowmap_ptr[N] : colmap_ptr[N];\n\tKokkos::View<int**> dist(\"dist\", N, 1);\n\tKokkos::View<int**> marker(\"marker\", N, 1);\n\tint *dist_ptr = dist.data();\n\tint *marker_ptr = marker.data();\n\n\t// Kokkos parallel for\n\tKokkos::parallel_for(\n\t\t\"init_values\",\n\t\tKokkos::RangePolicy<>(0, N),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t\tdist_ptr[i] = INT_MAX;\n\t\t\tmarker_ptr[i] = 0;\n\t\t}\n\t);\n\n\t// Add the source to the min heap\n\tKokkos::View<int**> heap(\"heap\", min, 1);\n\tKokkos::View<int**> index(\"index\", min, 1);\n\tint *heap_ptr = heap.data();\n\tint *index_ptr = index.data();\n\tfor (int i = 0; i < min; i++) {\n\t\theap_ptr[i] = i;\n\t\tindex_ptr[i] = i;\n\t}\n\n\t// Sort the heap\n\tKokkos::Sort<Kokkos::Cuda>(index, heap, min);\n\n\t// Kokkos parallel for\n\tKokkos::parallel_for(\n\t\t\"loop\",\n\t\tKokkos::RangePolicy<>(0, min),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t\tint j = index_ptr[i];\n\t\t\tdist_ptr[colinds_ptr[j]] = 1;\n\t\t\tmarker_ptr[colinds_ptr[j]] = 1;\n\t\t}\n\t);\n\n\t// Kokkos parallel for\n\tKokkos::parallel_for(\n\t\t\"loop\",\n\t\tKokkos::RangePolicy<>(0, min),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t\tint j = index_ptr[i];\n\t\t\tfor (int k = rowmap_ptr[colinds_ptr[j]]; k < rowmap_ptr[colinds_ptr[j]+1]; k++) {\n\t\t\t\tint curr = rowinds_ptr[k];\n\t\t\t\tint weight = dist_ptr[colinds",
            "// Initialize the distance matrix.\n\tKokkos::View<int*> distance(\"distance\", N);\n\tKokkos::deep_copy(distance, -1);\n\n\t// Initialize the visited matrix.\n\tKokkos::View<bool*> visited(\"visited\", N);\n\tKokkos::deep_copy(visited, false);\n\n\t// Queue of nodes to explore.\n\tstd::queue<int> queue;\n\n\t// The initial node to explore.\n\tqueue.push(source);\n\tdistance(source) = 0;\n\n\t// Kokkos policy for executing the loop in parallel.\n\tKokkos::RangePolicy<Kokkos::Cuda> policy(0, N);\n\n\t// Loop until we've discovered all reachable nodes.\n\twhile (!queue.empty()) {\n\t\t// Get the node to explore.\n\t\tint node = queue.front();\n\t\tqueue.pop();\n\n\t\t// Mark the node as visited.\n\t\tvisited(node) = true;\n\n\t\t// If the current node is the destination, return the distance.\n\t\tif (node == dest) {\n\t\t\treturn distance(node);\n\t\t}\n\n\t\t// Iterate over the neighbors.\n\t\tKokkos::parallel_for(\n\t\t\t\tpolicy,\n\t\t\t\tKOKKOS_LAMBDA(const int n) {\n\t\t\t\t\tif (A(node, n)!= 0) {\n\t\t\t\t\t\tif (distance(n) == -1) {\n\t\t\t\t\t\t\t// This is the first time we've discovered this node.\n\t\t\t\t\t\t\tdistance(n) = distance(node) + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!visited(n)) {\n\t\t\t\t\t\t\t// We haven't visited this node yet.\n\t\t\t\t\t\t\tqueue.push(n);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t});\n\t}\n\n\t// We've run out of nodes to explore. The destination is unreachable.\n\treturn -1;\n}",
            "// TODO: implement me\n\treturn 0;\n}",
            "// Declare Kokkos views to hold the graph, the distances, and the predecessors.\n  Kokkos::View<int**> graph(\"graph\", N, N);\n  Kokkos::View<int*> distance(\"distance\", N);\n  Kokkos::View<int*> predecessor(\"predecessor\", N);\n\n  // Copy the adjacency matrix A to the graph Kokkos view\n  Kokkos::deep_copy(graph, A);\n\n  // Initialize all distances to -1, except source whose distance is 0.\n  Kokkos::deep_copy(distance, -1);\n  Kokkos::deep_copy(predecessor, -1);\n  int *d = distance.data();\n  Kokkos::parallel_for(\"initialize\", N, KOKKOS_LAMBDA(const int i) {\n    if (i == source) {\n      d[i] = 0;\n    }\n  });\n\n  // Initialize all vertices to unvisited.\n  Kokkos::View<int*> vertex(\"vertex\", N);\n  Kokkos::deep_copy(vertex, -1);\n  int *v = vertex.data();\n  Kokkos::parallel_for(\"initialize\", N, KOKKOS_LAMBDA(const int i) {\n    if (i == source) {\n      v[i] = 0;\n    }\n  });\n\n  // The distance to the source vertex is 0.\n  distance(source) = 0;\n\n  // Keep track of the current distance to compare with previous distance.\n  int *previous_distance = (int*) Kokkos::kokkos_malloc<int>(N * sizeof(int));\n  for (int i = 0; i < N; ++i) {\n    previous_distance[i] = -1;\n  }\n\n  // Loop until we've visited all vertices.\n  bool finished = false;\n  while (!finished) {\n\n    // Pick an unvisited vertex with the smallest distance and set it as the current vertex.\n    int current_vertex = -1;\n    int current_distance = -1;\n    int *d_ptr = distance.data();\n    for (int i = 0; i < N; ++i) {\n      if (d_ptr[i]!= -1 && d_ptr[i] < current_distance) {\n        current_vertex = i;\n        current_distance = d_ptr[i];\n      }\n    }\n\n    // If we've visited all vertices, then we are done.\n    if (current_distance == -1) {\n      finished = true;\n      break;\n    }\n\n    // Get the neighbors of the current vertex.\n    Kokkos::View<int*> neighbors(\"neighbors\", N);\n    int n_neighbors = 0;\n    int *n_ptr = neighbors.data();\n    for (int i = 0; i < N; ++i) {\n      if (graph(current_vertex, i) > 0) {\n        n_ptr[n_neighbors++] = i;\n      }\n    }\n\n    // For each neighbor, check to see if we should update the distance to it.\n    Kokkos::parallel_for(\"update_distance\", n_neighbors, KOKKOS_LAMBDA(const int i) {\n      int neighbor = neighbors(i);\n\n      if (distance(neighbor) == -1 || distance(neighbor) > distance(current_vertex) + 1) {\n        distance(neighbor) = distance(current_vertex) + 1;\n        predecessor(neighbor) = current_vertex;\n        v[neighbor] = 1;\n      }\n    });\n\n    // Check if we've reached the destination.\n    if (current_vertex == dest) {\n      finished = true;\n      break;\n    }\n\n    // Check if we've reached a vertex whose distance has changed. If so, we have to go through the vertices again to update their distances.\n    if (previous_distance[current_vertex]!= distance(current_vertex)) {\n      previous_distance[current",
            "// TODO: Implement\n\treturn 0;\n}",
            "Kokkos::View<int**> d_dist(\"dist\", N, N);\n  Kokkos::View<int*> d_q(\"q\", N);\n\n  // Kokkos BFS algorithm\n  for (size_t i = 0; i < N; ++i) {\n    Kokkos::parallel_for(\n        \"BFS\",\n        Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n        KOKKOS_LAMBDA(int j) {\n          d_dist(j, j) = 0;\n          d_dist(i, j) = INT_MAX;\n        });\n  }\n  Kokkos::fence();\n\n  Kokkos::parallel_for(\n      \"BFS\",\n      Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n      KOKKOS_LAMBDA(int v) { d_q(v) = v; });\n\n  int cur, next;\n  bool done = false;\n  while (!done) {\n    done = true;\n    for (int w = 0; w < N; ++w) {\n      cur = d_q(w);\n      if (cur == -1)\n        continue;\n      for (int v = 0; v < N; ++v) {\n        if (A(cur, v) && d_dist(cur, v) == INT_MAX) {\n          d_dist(cur, v) = d_dist(cur, w) + 1;\n          d_q(w) = -1;\n          done = false;\n        }\n      }\n    }\n  }\n  Kokkos::fence();\n\n  int dist = d_dist(source, dest);\n  return dist;\n}",
            "// TODO: implement\n\n\n  // Kokkos::View<bool**> reachable(\"reachable\", N, N);\n  // reachable(source, 0) = true;\n\n  // Kokkos::parallel_for(\"check_reachable\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n  //     for(int j=0; j<N; j++) {\n  //         if(reachable(i, j)) {\n  //             for(int k=0; k<N; k++) {\n  //                 if(A(i, k) &&!reachable(j, k)) {\n  //                     reachable(j, k) = true;\n  //                 }\n  //             }\n  //         }\n  //     }\n  // });\n\n  // Kokkos::parallel_reduce(\"count_reachable\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), 0, KOKKOS_LAMBDA(const int i, int &sum) {\n  //     sum += reachable(source, i);\n  // });\n\n  // int reachable_count = Kokkos::create_mirror_view(reachable)(source, 0);\n\n\n  // Kokkos::parallel_for(\"shortest_path\", Kokkos::RangePolicy<Kokkos::Cuda>(0, N), KOKKOS_LAMBDA(const int i) {\n  //     if(reachable(i, 0)) {\n  //         for(int j=1; j<N; j++) {\n  //             if(reachable(i, j)) {\n  //                 Kokkos::atomic_min(&dist(i, j), dist(i, 0) + dist(0, j));\n  //             }\n  //         }\n  //     }\n  // });\n\n\n\n  // for(int i=1; i<N; i++) {\n  //     for(int j=0; j<N; j++) {\n  //         if(reachable(i, j) && reachable(j, i)) {\n  //             Kokkos::atomic_min(&dist(i, j), dist(i, 0) + dist(0, j));\n  //         }\n  //     }\n  // }\n\n  // int shortest_path = Kokkos::create_mirror_view(dist)(source, dest);\n\n  // return shortest_path;",
            "// Your code goes here\n\treturn -1;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> pred(\"pred\", N);\n  // Your code here\n\n  // Implemented using BFS\n  Kokkos::deep_copy(dist, -1);\n  Kokkos::deep_copy(pred, -1);\n  dist(source) = 0;\n  Kokkos::View<int*> q(\"q\", N);\n  int q_head = 0, q_tail = 0;\n  q(q_tail++) = source;\n  while(q_head < q_tail) {\n    int u = q(q_head++);\n    for(int v = 0; v < N; v++) {\n      if(A(u, v) && dist(v) < 0) {\n        dist(v) = dist(u) + 1;\n        pred(v) = u;\n        q(q_tail++) = v;\n      }\n    }\n  }\n  return dist(dest);\n}",
            "// TODO: replace this with your code.\n  // You may not modify anything outside of this function.\n  // Feel free to declare new variables and functions as needed.\n  // You may assume that A is a valid NxN matrix where A[i][j]==0 or 1 for all i, j.\n\n  Kokkos::View<int*, Kokkos::HostSpace> shortestPathLengths(\"shortestPathLengths\", N);\n  Kokkos::View<int*, Kokkos::HostSpace> predecessors(\"predecessors\", N);\n\n  // initialize predecessors and shortestPathLengths\n  Kokkos::deep_copy(shortestPathLengths, -1);\n  Kokkos::deep_copy(predecessors, -1);\n\n  // initialize the queue\n  std::queue<int> queue;\n  queue.push(source);\n\n  shortestPathLengths[source] = 0;\n  predecessors[source] = source;\n\n  // main BFS loop\n  while (queue.size() > 0) {\n    int current = queue.front();\n    queue.pop();\n    for (int i = 0; i < N; i++) {\n      if (A(current, i) == 1 && shortestPathLengths[i] == -1) {\n        // update shortestPathLengths\n        shortestPathLengths[i] = shortestPathLengths[current] + 1;\n\n        // update predecessors\n        predecessors[i] = current;\n\n        // add to queue\n        queue.push(i);\n      }\n    }\n  }\n\n  // return shortest path length\n  return shortestPathLengths[dest];\n}",
            "// Kokkos graph type\n\ttypedef Kokkos::Graph<int, int, Kokkos::Device<Kokkos::OpenMP, Kokkos::OpenMP::memory_space, Kokkos::OpenMP::execution_space>> kkGraph;\n\n\t// Kokkos graph instance\n\tkkGraph kkG(N, A.data(), A.data() + N);\n\n\t// Kokkos graph traversal instance\n\ttypedef Kokkos::GraphTraversal<kkGraph> kkGraphTraversal;\n\tkkGraphTraversal kkGT(kkG);\n\n\t// Allocate a vector of size N to hold the distances from the source\n\t// Kokkos::View not used for performance reasons\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::OpenMP::memory_space> D(\"Distance Vector\", N);\n\n\t// Allocate a vector of size N to hold the predecessors for the shortest paths\n\t// Kokkos::View not used for performance reasons\n\tKokkos::View<int*, Kokkos::LayoutLeft, Kokkos::OpenMP::memory_space> P(\"Predecessor Vector\", N);\n\n\t// Initialize distance vector with -1\n\tKokkos::deep_copy(D, -1);\n\n\t// Initialize predecessor vector with -1\n\tKokkos::deep_copy(P, -1);\n\n\t// Perform a BFS on the Kokkos graph, using the graph traversal instance\n\tkkGT.BFS(source, D, P);\n\n\t// Return the distance from source to dest\n\treturn D(dest);\n}",
            "using namespace Kokkos;\n\tView<int**> Q(\"Queue\", N, N); // Initialize queue with 0s.\n\tparallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\tfor (size_t j = 0; j < N; j++) Q(i, j) = 0;\n\t});\n\tKokkos::fence(); // Make sure initialization is complete before continuing.\n\n\t// Breadth-first search.\n\tView<int*> Qfront(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"Qfront\"), N);\n\tKokkos::parallel_for(N, KOKKOS_LAMBDA(size_t i) { Qfront[i] = i; });\n\tKokkos::fence();\n\n\tint distance = 1;\n\twhile (Qfront.size()!= 0) {\n\t\t// Dequeue.\n\t\tView<int*> Qback(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"Qback\"), Qfront.size());\n\t\tKokkos::parallel_for(Qfront.size(), KOKKOS_LAMBDA(size_t i) {\n\t\t\tQback(i) = Qfront(i);\n\t\t});\n\t\tKokkos::fence();\n\n\t\t// Enqueue all children.\n\t\tKokkos::parallel_for(Qfront.size(), KOKKOS_LAMBDA(size_t i) {\n\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\tif (A(Qfront(i), j) == 1) Q(j, distance) = 1;\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\n\t\t// Find all parents.\n\t\tparallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\t\tif (A(i, dest) == 1) {\n\t\t\t\tif (Q(i, distance - 1) == 1) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tKokkos::fence();\n\n\t\t// Find new frontier.\n\t\tView<int*> Qnewfront(Kokkos::view_alloc(Kokkos::WithoutInitializing, \"Qnewfront\"), N);\n\t\tsize_t Qnewfront_size = 0;\n\t\tKokkos::parallel_reduce(N, KOKKOS_LAMBDA(size_t i, size_t &lsum) {\n\t\t\tif (Q(i, distance) == 1) lsum++;\n\t\t}, Kokkos::Sum<int>(Qnewfront_size));\n\t\tKokkos::fence();\n\t\tparallel_for(N, KOKKOS_LAMBDA(size_t i) {\n\t\t\tif (Q(i, distance) == 1) Qnewfront(Qnewfront_size - 1) = i;\n\t\t});\n\t\tKokkos::fence();\n\t\t// Swap queues.\n\t\tView<int*> Qtmp = Qfront;\n\t\tQfront = Qnewfront;\n\t\tQnewfront = Qtmp;\n\t\tdistance++;\n\t}\n\treturn -1;\n}",
            "int dist[N];\n  for (int i = 0; i < N; i++) {\n    dist[i] = i == source? 0 : INT_MAX;\n  }\n  std::vector<bool> visited(N, false);\n  // We need the following two sets to track changes in dist and visited since\n  // Kokkos::View::modify doesn't have a way to tell if it's on the first iteration or not.\n  std::vector<int> updatedDist(N, -1);\n  std::vector<bool> updatedVisited(N, false);\n  Kokkos::View<int*> kDist(\"dist\", dist, N);\n  Kokkos::View<bool*> kVisited(\"visited\", visited.data(), N);\n  Kokkos::View<int*> kUpdatedDist(\"updatedDist\", updatedDist.data(), N);\n  Kokkos::View<bool*> kUpdatedVisited(\"updatedVisited\", updatedVisited.data(), N);\n  Kokkos::parallel_for(\"BFSShortestPath\", N, KOKKOS_LAMBDA(const int& i) {\n    int v = kDist(i);\n    if (v == INT_MAX || kVisited(i)) {\n      kUpdatedDist(i) = v;\n      kUpdatedVisited(i) = kVisited(i);\n      return;\n    }\n    for (int j = 0; j < N; j++) {\n      if (A(i, j)) {\n        int u = kDist(j) + 1;\n        if (u < v) {\n          kUpdatedDist(j) = u;\n          kUpdatedVisited(j) = true;\n        }\n      }\n    }\n  });\n  Kokkos::fence();\n  for (int i = 0; i < N; i++) {\n    if (updatedDist[i]!= -1) {\n      dist[i] = updatedDist[i];\n      visited[i] = updatedVisited[i];\n    }\n  }\n  return dist[dest];\n}",
            "// This is a template that creates an array of ints on device memory\n  Kokkos::View<int*> distance(\"distance\", N);\n\n  // Initialize the distance to -1 for all vertices\n  Kokkos::deep_copy(distance, -1);\n\n  // Set the distance from source to zero.\n  // This is the base case of the recursive algorithm.\n  Kokkos::parallel_for(\n    \"initialize_distance\",\n    Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(source, source + 1),\n    KOKKOS_LAMBDA(const int src) {\n      distance(src) = 0;\n    }\n  );\n\n  // Iterate until the destination is reached\n  bool destination_reached = false;\n  while (!destination_reached) {\n\n    // Iterate over all vertices.\n    // Inside the loop body, you have access to the local thread ID (i.e. the vertex ID) via the Kokkos::parallel_for\n    // argument \"i\".\n    Kokkos::parallel_for(\n      \"bfs\",\n      Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(const int i) {\n\n        // Check if this vertex was already visited\n        if (distance(i) >= 0) {\n          // Check if there is an edge from the current vertex to some neighbor\n          for (int j = 0; j < N; ++j) {\n            if (A(i, j) == 1 && distance(j) < 0) {\n              // This neighbor is not visited yet.\n              // Set the distance from i to j.\n              distance(j) = distance(i) + 1;\n            }\n          }\n        }\n      }\n    );\n\n    // Check if destination was reached\n    Kokkos::parallel_reduce(\n      \"check_destination\",\n      Kokkos::RangePolicy<Kokkos::DefaultExecutionSpace>(0, N),\n      KOKKOS_LAMBDA(const int i, int &sum) {\n        if (distance(i) >= 0) {\n          sum += 1;\n        }\n      },\n      Kokkos::Sum<int>(destination_reached)\n    );\n  }\n\n  return distance(dest);\n}",
            "int* dist = (int*)malloc(N*sizeof(int));\n    bool* visited = (bool*)malloc(N*sizeof(bool));\n    for(int i=0; i<N; i++) {\n        dist[i] = -1;\n        visited[i] = false;\n    }\n    dist[source] = 0;\n\n    int count = 0;\n    while(!visited[dest]) {\n        int min = INT_MAX;\n        int min_index = -1;\n        for(int i=0; i<N; i++) {\n            if(!visited[i] && dist[i] >= 0 && dist[i] < min) {\n                min = dist[i];\n                min_index = i;\n            }\n        }\n        visited[min_index] = true;\n        for(int i=0; i<N; i++) {\n            if(!visited[i] && A(min_index, i)) {\n                if(dist[min_index]+1 < dist[i]) {\n                    dist[i] = dist[min_index]+1;\n                }\n            }\n        }\n        count++;\n    }\n    int result = dist[dest];\n    free(dist);\n    free(visited);\n    return result;\n}",
            "typedef Kokkos::View<bool*> boolView;\n  // Kokkos::View<bool*> flag(\"flag\");\n  Kokkos::View<int*> dist(\"dist\");\n  boolView flag(\"flag\");\n\n  const int size = N;\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, size), KOKKOS_LAMBDA(const int& i) {\n    dist(i) = INT_MAX;\n    flag(i) = false;\n  });\n\n  Kokkos::fence();\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, size), KOKKOS_LAMBDA(const int& i) {\n    if (i == source) {\n      dist(i) = 0;\n    }\n  });\n\n  Kokkos::fence();\n\n  Kokkos::parallel_for(Kokkos::RangePolicy<>(0, size), KOKKOS_LAMBDA(const int& k) {\n    for (int i = 0; i < size; i++) {\n      for (int j = 0; j < size; j++) {\n        if (A(i, j) > 0 && dist(i)!= INT_MAX && dist(j) > dist(i) + 1) {\n          Kokkos::atomic_compare_exchange(&dist(j), dist(j), dist(i) + 1);\n        }\n      }\n    }\n  });\n\n  Kokkos::fence();\n\n  int ans = INT_MAX;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<>(0, size), KOKKOS_LAMBDA(const int& i, int& l) {\n    if (dist(i)!= INT_MAX) {\n      l = std::min(l, dist(i));\n    }\n  }, Kokkos::Min<int>(ans));\n\n  return ans;\n}",
            "// initialize distance array to -1, and queue\n  Kokkos::View<int*> dist(\"distance\", N);\n  Kokkos::View<int*> queue(\"queue\", N);\n  auto h_dist = Kokkos::create_mirror_view(dist);\n  auto h_queue = Kokkos::create_mirror_view(queue);\n\n  // initialize distance array\n  Kokkos::deep_copy(dist, -1);\n  Kokkos::deep_copy(h_dist(source), 0);\n  Kokkos::deep_copy(queue, -1);\n  Kokkos::deep_copy(h_queue(0), source);\n\n  // run BFS\n  int level = 0;\n  while (h_queue(0)!= -1) {\n\n    // expand current level\n    for (int i = 0; i < N; i++) {\n      if (h_dist(i) == level) {\n\tfor (int j = 0; j < N; j++) {\n\t  if (A(i, j)!= 0 && h_dist(j) == -1) {\n\t    h_dist(j) = level + 1;\n\t    h_queue(j) = j;\n\t  }\n\t}\n      }\n    }\n\n    // update queue\n    for (int i = 0; i < N; i++) {\n      if (h_queue(i)!= -1) {\n\th_queue(i) = h_queue(i+1);\n      }\n    }\n\n    // update level\n    level++;\n  }\n\n  // return shortest path length\n  return h_dist(dest);\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<bool*> visited(\"visited\", N);\n\n  // Initialize to -1 to indicate that we haven't reached that vertex yet.\n  Kokkos::parallel_for(\"init dist\", N, KOKKOS_LAMBDA (int i) { dist(i) = -1; });\n  Kokkos::parallel_for(\"init visited\", N, KOKKOS_LAMBDA (int i) { visited(i) = false; });\n\n  // Start with a distance of 0 at the source vertex.\n  dist(source) = 0;\n  visited(source) = true;\n\n  // Breadth-first search.\n  for (int i = 0; i < N; ++i) {\n    Kokkos::parallel_for(\"breadth-first search\", N, KOKKOS_LAMBDA (int j) {\n      if (!visited(j))\n        for (int k = 0; k < N; ++k)\n          if (visited(k) && A(k, j) == 1)\n            dist(j) = dist(k) + 1;\n    });\n    visited(dest) = true;\n  }\n\n  return dist(dest);\n}",
            "//TODO: Your code here\n  return 0;\n}",
            "// TODO: replace this with your implementation\n\n  Kokkos::View<int*> distance(\"distances\",N);\n  Kokkos::View<int*> predecessor(\"predecessor\",N);\n  Kokkos::View<bool*> visited(\"visited\",N);\n\n  Kokkos::parallel_for(\"init\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA (int i) {\n    distance(i) = INT_MAX;\n    visited(i) = false;\n    predecessor(i) = INT_MIN;\n  });\n\n  // Initialize the distances\n  Kokkos::parallel_for(\"initDistance\", Kokkos::RangePolicy<>(0,N), KOKKOS_LAMBDA (int i) {\n    if (i == source) {\n      distance(i) = 0;\n      visited(i) = true;\n    }\n  });\n\n  // Do relaxations\n  for (int i=0; i<N; i++) {\n    // Find vertex with the minimum distance\n    int vertex_id = -1;\n    int min_distance = INT_MAX;\n    for (int j=0; j<N; j++) {\n      if (!visited(j)) {\n        if (distance(j) < min_distance) {\n          vertex_id = j;\n          min_distance = distance(j);\n        }\n      }\n    }\n    // Exit if all nodes are visited\n    if (vertex_id < 0) {\n      break;\n    }\n    // Update distances of adjacent nodes\n    for (int j=0; j<N; j++) {\n      if (A(vertex_id,j) &&!visited(j)) {\n        int alt = distance(vertex_id) + 1;\n        if (alt < distance(j)) {\n          distance(j) = alt;\n          predecessor(j) = vertex_id;\n        }\n      }\n    }\n    visited(vertex_id) = true;\n  }\n\n  // Compute the length of the shortest path\n  int length = 0;\n  int path_end = dest;\n  while (path_end!= source) {\n    length++;\n    path_end = predecessor(path_end);\n  }\n\n  return length;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> queue(\"queue\", N);\n\n  // TODO: Add code here\n\n  return -1;\n}",
            "// Use Kokkos's parallel_for to initialize the queue and distance array\n    Kokkos::View<int*> distance(\"distance\", N);\n    Kokkos::View<bool*> in_queue(\"in_queue\", N);\n\n    Kokkos::parallel_for(N, KOKKOS_LAMBDA(const int& i) {\n        distance(i) = std::numeric_limits<int>::max();\n        in_queue(i) = false;\n    });\n    Kokkos::fence();\n\n    // Initialize the queue.\n    std::vector<int> queue;\n    queue.push_back(source);\n\n    // Iterate until we've found the shortest path or the queue is empty.\n    while (!queue.empty()) {\n        int u = queue.back();\n        queue.pop_back();\n        in_queue(u) = false;\n\n        // If we've reached the destination, we can stop.\n        if (u == dest) {\n            return distance(u);\n        }\n\n        // For each neighbor, relax the edge.\n        for (int v = 0; v < N; ++v) {\n            if (A(u, v) && distance(v) > distance(u) + 1) {\n                distance(v) = distance(u) + 1;\n                if (!in_queue(v)) {\n                    queue.push_back(v);\n                    in_queue(v) = true;\n                }\n            }\n        }\n    }\n\n    // Couldn't find the shortest path.\n    return std::numeric_limits<int>::max();\n}",
            "// Your code here\n  Kokkos::View<int**> V;\n  int* temp;\n  Kokkos::View<int*> depth;\n  Kokkos::View<int*> pred;\n  Kokkos::View<int*> V_depth;\n  Kokkos::View<int*> V_pred;\n  temp = new int[N];\n  int* depth_temp;\n  int* pred_temp;\n  depth_temp = new int[N];\n  pred_temp = new int[N];\n  Kokkos::deep_copy(depth,0);\n  Kokkos::deep_copy(pred,0);\n  Kokkos::deep_copy(V_depth,0);\n  Kokkos::deep_copy(V_pred,0);\n\n  //for(int i=0;i<N;i++){\n    //temp[i]=0;\n    //depth_temp[i]=0;\n    //pred_temp[i]=0;\n  //}\n  Kokkos::View<int**> pred_view(\"pred\",N,N);\n  Kokkos::View<int**> depth_view(\"depth\",N,N);\n  Kokkos::View<int**> V_depth_view(\"V_depth\",N,N);\n  Kokkos::View<int**> V_pred_view(\"V_pred\",N,N);\n  Kokkos::deep_copy(pred_view,0);\n  Kokkos::deep_copy(depth_view,0);\n  Kokkos::deep_copy(V_depth_view,0);\n  Kokkos::deep_copy(V_pred_view,0);\n\n\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    if(A[source][i] == 1){\n      depth_view(source,i)=1;\n    }\n    else{\n      depth_view(source,i)=0;\n    }\n    V_depth_view(source,i)=i;\n    V_pred_view(source,i)=source;\n\n    if(i == source){\n      V_depth_view(source,source)=source;\n      V_pred_view(source,source)=source;\n      V_depth_view(i,i)=i;\n      V_pred_view(i,i)=i;\n    }\n    //V_view(source,i)=1;\n  });\n\n  //Kokkos::deep_copy(V,V_view);\n  Kokkos::deep_copy(V_depth,V_depth_view);\n  Kokkos::deep_copy(V_pred,V_pred_view);\n\n  Kokkos::deep_copy(depth,depth_view);\n  Kokkos::deep_copy(pred,pred_view);\n\n  int distance = 0;\n  int stop = 0;\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    for(int j=0;j<N;j++){\n      if(i!=j){\n        if(A[i][j] == 1){\n          depth(i,j)=depth(i,source)+1;\n          pred(i,j)=source;\n          V_depth(i,j)=j;\n          V_pred(i,j)=i;\n        }\n        else{\n          depth(i,j)=0;\n          pred(i,j)=0;\n          V_depth(i,j)=0;\n          V_pred(i,j)=0;\n        }\n      }\n    }\n  });\n\n  Kokkos::deep_copy(depth_view,depth);\n  Kokkos::deep_copy(pred_view,pred);\n\n  Kokkos::parallel_for(N, KOKKOS_LAMBDA (const int& i) {\n    for(int j=0;j<N;j++){\n      if(depth_view(j,i)!= 0){\n        V_depth(j,i) = V_depth(j,pred_view(j,i));\n        V_",
            "// TODO: replace the 0 with the correct answer\n  return 0;\n\n}",
            "// TODO: implement me!\n\n  // Kokkos::View<int**> B(\"B\",N,N);\n  Kokkos::View<int*> B(\"B\",N);\n  Kokkos::View<int*> C(\"C\",N);\n  Kokkos::View<int*> D(\"D\",N);\n  //\n  //Kokkos::deep_copy(B,A);\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),KOKKOS_LAMBDA (const int& i){\n\n\t  //Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),KOKKOS_LAMBDA (const int& j){\n\t\t  //B(i,j) = A(i,j);\n\t  //});\n\t  B(i) = A(i,i);\n\t  C(i) = 0;\n\t  D(i) = 0;\n\t  if (i==source){\n\t\t  C(i)=0;\n\t\t  D(i)=1;\n\t  }\n  });\n\n\n  for (int k=0; k<N; k++) {\n\t  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),KOKKOS_LAMBDA (const int& i){\n\t\t  for (int j=0; j<N; j++) {\n\t\t\t  if (A(i,j)>0) {\n\t\t\t\t  B(j) = B(j) + B(i);\n\t\t\t  }\n\t\t  }\n\t  });\n\n  }\n\n\n  int res;\n  Kokkos::parallel_reduce(Kokkos::RangePolicy<Kokkos::Cuda>(0,N),KOKKOS_LAMBDA (const int& i, int& lmin){\n\t  if (C(i)>=0) {\n\t\t  int tmp = B(i) - A(i,i);\n\t\t  if (tmp<lmin) {\n\t\t\t  lmin = tmp;\n\t\t  }\n\t  }\n  },res);\n\n\n  return res;\n}",
            "using namespace Kokkos;\n  using namespace Kokkos::Experimental;\n  using namespace Kokkos::Experimental::Views;\n  using namespace Kokkos::View;\n  using namespace Kokkos::ViewAllocateWithoutInitializing;\n  using ExecSpace = Kokkos::DefaultExecutionSpace;\n\n  if (source == dest) return 0;\n\n  // Initialize dist and pred arrays\n  // These are the arrays that will be used to store the state of the algorithm\n  Kokkos::View<int*, ExecSpace> dist(\"dist\", N);\n  Kokkos::View<int*, ExecSpace> pred(\"pred\", N);\n\n  // Initial state: dist(v) = A(source, v), pred(v) = source for each vertex v.\n  Kokkos::parallel_for(\"init\", range<int>(0, N), [=](int v) {\n    pred(v) = source;\n    dist(v) = A(source, v);\n  });\n\n  // Mark source as seen\n  Kokkos::View<int*, ExecSpace> seen(\"seen\", N);\n  Kokkos::parallel_for(\"init\", range<int>(0, N), [=](int v) {\n    seen(v) = 0;\n  });\n  Kokkos::fence();\n  Kokkos::deep_copy(seen(source), 1);\n\n  // Use a priority queue (the heap) to store the vertices whose shortest path length has been updated.\n  // The heap is implemented as a binary tree, so that we can remove the top element with O(lg N) time.\n  // We store the length as the priority.\n  // This is the same heap as the one used in Dijkstra's algorithm.\n  // Note that we can also use a flat map to store the heap if we don't care about the ordering of vertices with the same distance.\n  // However, a binary tree makes it easy to implement the decrease-key operation.\n  // The heap is stored as a 1-D array of length N.\n  // The parent of a vertex v is at position (v-1)/2\n  // The children of a vertex v are at positions 2v and 2v+1.\n  Kokkos::View<int*, ExecSpace> heap(\"heap\", N);\n\n  // To store the position of a vertex in the heap, we can use a flat map.\n  Kokkos::View<int*, ExecSpace> heapMap(\"heapMap\", N);\n  Kokkos::parallel_for(\"init\", range<int>(0, N), [=](int v) {\n    heapMap(v) = -1;\n  });\n\n  // Add source to the heap\n  Kokkos::parallel_for(\"init\", range<int>(0, 1), [=](int v) {\n    heapMap(source) = 0;\n    heap(0) = source;\n  });\n\n  // Use a counter to keep track of the size of the heap.\n  // This allows us to easily remove the top element of the heap in O(lg N) time.\n  Kokkos::View<int*, ExecSpace> heapCounter(\"heapCounter\", 1);\n  Kokkos::deep_copy(heapCounter(0), 1);\n  Kokkos::fence();\n\n  // Loop until the heap is empty\n  while (heapCounter(0) > 0) {\n    // Find the vertex u with the shortest path length among those in the heap\n    int u = heap(0);\n\n    // Remove u from the heap\n    int last = heapCounter(0) - 1;\n    heap(0) = heap(last);\n    heapMap(heap(0)) = 0;\n    heap(last) = -1;\n    heapCounter(0) = last;\n\n    // Update the length of the shortest path of u's neighbors\n    for (int v = 0; v < N; v++) {\n      // Skip if we have already seen v, or if there is no edge between u and v.\n      if (seen(v) == 1 || A(u, v) == 0) continue;\n\n      // Skip if the length of the current path from source to v is not shorter than what we already know.",
            "// TODO:\n\t// 1. Create a new Kokkos::View<int*> called \"visited\" that contains a record of all nodes visited.\n\t// 2. Iterate over all nodes and add to \"visited\" if the node has been visited.\n\t// 3. Update the visited list with any new nodes found in the search.\n\t// 4. Return the shortest path length from source to dest.\n\t//\n\t// Hints:\n\t// 1. Use Kokkos::parallel_for to iterate over all nodes.\n\t// 2. Kokkos::atomic_exchange to get and set the value of a node in the visited array.\n\t// 3. The order in which you visit nodes is very important.\n\t//    This may require some careful planning of your Kokkos::parallel_for.\n\t// 4. For the shortest path length, you'll need to use a Kokkos::parallel_reduce.\n\t// 5. You may want to use a struct for the Kokkos::parallel_reduce.\n\t//    It will need two data fields:\n\t//     int distance; // shortest distance from source to node so far\n\t//     bool visited; // whether or not we've visited this node\n\t//\n\t// 6. Don't forget to initialize your Kokkos::parallel_reduce struct.\n\t// 7. Don't forget to set the size of your Kokkos::View<int*>.\n\n\t// TODO: Implement me\n\treturn -1;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::parallel_for(\"set_dist\", N, KOKKOS_LAMBDA(const int& i) {\n    dist(i) = (i == source? 0 : 1000000);\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int**> prev(\"prev\", N, N);\n  Kokkos::parallel_for(\"set_prev\", N*N, KOKKOS_LAMBDA(const int& i) {\n    prev(i) = -1;\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int*> queue(\"queue\", N);\n  Kokkos::parallel_for(\"init_queue\", N, KOKKOS_LAMBDA(const int& i) {\n    queue(i) = 0;\n  });\n  Kokkos::fence();\n\n  int queue_start = 0;\n  int queue_end = 1;\n  Kokkos::View<int*> queue_size(\"queue_size\", 1);\n  queue_size(0) = 1;\n\n  Kokkos::View<int*> in_queue(\"in_queue\", N);\n  Kokkos::parallel_for(\"set_in_queue\", N, KOKKOS_LAMBDA(const int& i) {\n    in_queue(i) = 0;\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int*> current_node(\"current_node\", 1);\n  current_node(0) = source;\n\n  Kokkos::View<int*> is_visited(\"is_visited\", N);\n  Kokkos::parallel_for(\"set_is_visited\", N, KOKKOS_LAMBDA(const int& i) {\n    is_visited(i) = 0;\n  });\n  Kokkos::fence();\n\n  Kokkos::View<int*> num_visited(\"num_visited\", 1);\n  num_visited(0) = 0;\n\n  while (num_visited(0) < N) {\n    if (current_node(0) == dest) {\n      break;\n    }\n    Kokkos::parallel_for(\"expand_node\", N, KOKKOS_LAMBDA(const int& i) {\n      if ((A(current_node(0), i) == 1) && (is_visited(i) == 0)) {\n        if (dist(current_node(0)) + 1 < dist(i)) {\n          dist(i) = dist(current_node(0)) + 1;\n          prev(i, current_node(0)) = 1;\n        }\n        if (in_queue(i) == 0) {\n          queue(queue_end) = i;\n          queue_end = queue_end + 1;\n          in_queue(i) = 1;\n          queue_size(0) = queue_size(0) + 1;\n        }\n      }\n    });\n    Kokkos::fence();\n    while (queue_start < queue_end) {\n      current_node(0) = queue(queue_start);\n      queue(queue_start) = -1;\n      in_queue(current_node(0)) = 0;\n      queue_size(0) = queue_size(0) - 1;\n      queue_start = queue_start + 1;\n      is_visited(current_node(0)) = 1;\n      num_visited(0) = num_visited(0) + 1;\n    }\n  }\n\n  int path_length = dist(dest);\n\n  return path_length;\n}",
            "const int num_threads = 16;\n  const int team_size = 4;\n  const int vector_size = 4;\n\n  using Kokkos::View;\n  using Kokkos::Max;\n  using Kokkos::Min;\n  using Kokkos::Sum;\n  using Kokkos::ALL;\n  using Kokkos::RangePolicy;\n  using Kokkos::TeamPolicy;\n  using Kokkos::Schedule;\n  using Kokkos::AUTO;\n\n  const int max_iterations = 1000000000;\n\n  // The number of vertices in the graph\n  int num_vertices = N;\n\n  View<int*, Kokkos::HostSpace> dist(\"dist\", num_vertices);\n\n  Kokkos::parallel_for(\"init_dist\",\n    Kokkos::RangePolicy<>(0, num_vertices),\n    KOKKOS_LAMBDA(const int i) {\n      dist(i) = -1;\n    }\n  );\n\n  Kokkos::parallel_for(\"init_dist\",\n    Kokkos::RangePolicy<>(0, num_vertices),\n    KOKKOS_LAMBDA(const int i) {\n      dist(i) = -1;\n    }\n  );\n\n  // Initialize the source vertex distance as 0\n  dist(source) = 0;\n\n  // Create a Kokkos View that will be updated in the loop below\n  View<int, Kokkos::HostSpace> dist_changed(\"dist_changed\", 1);\n\n  // Create a Kokkos View to count the number of iterations\n  View<int, Kokkos::HostSpace> num_iterations(\"num_iterations\", 1);\n\n  // Kokkos Views for the predecessor matrix\n  View<int**, Kokkos::HostSpace> predecessor(\"predecessor\", num_vertices, num_vertices);\n\n  Kokkos::parallel_for(\"init_predecessor\",\n    Kokkos::RangePolicy<>(0, num_vertices),\n    KOKKOS_LAMBDA(const int i) {\n      for (int j = 0; j < num_vertices; j++) {\n        predecessor(i, j) = -1;\n      }\n    }\n  );\n\n  // Loop until we reach a vertex that we have already seen\n  for (int i = 0; i < max_iterations; i++) {\n    // Update the number of iterations\n    num_iterations(0) = i;\n\n    // Set dist_changed to 0\n    dist_changed(0) = 0;\n\n    // Kokkos::parallel_for(\n    //   \"update_dist\",\n    //   Kokkos::RangePolicy<>(0, num_vertices),\n    //   KOKKOS_LAMBDA(const int u) {\n    //     for (int v = 0; v < num_vertices; v++) {\n    //       if (A(u, v) == 1 && dist(u)!= -1 && (dist(v) == -1 || dist(v) > dist(u) + 1)) {\n    //         dist(v) = dist(u) + 1;\n    //         predecessor(v, 0) = u;\n    //         dist_changed(0) = 1;\n    //       }\n    //     }\n    //   }\n    // );\n\n    // If no vertex distance was updated, then we can exit\n    if (dist_changed(0) == 0) {\n      break;\n    }\n  }\n\n  // If the destination vertex is unreachable, then return -1\n  if (dist(dest) == -1) {\n    return -1;\n  }\n\n  // Otherwise, return the number of hops to get to the destination vertex\n  return dist(dest);\n}",
            "// Set up the graph (adjacency matrix)\n  using execution_space = Kokkos::DefaultExecutionSpace;\n  using memspace = typename execution_space::memory_space;\n  Kokkos::View<const int**, memspace> A_copy(A);\n  Kokkos::View<int**, memspace> predecessor(Kokkos::ViewAllocateWithoutInitializing(\"predecessor\"), N, N);\n  Kokkos::deep_copy(predecessor, 0);\n  Kokkos::View<int*, memspace> distance(Kokkos::ViewAllocateWithoutInitializing(\"distance\"), N);\n  Kokkos::deep_copy(distance, 1000);\n  Kokkos::deep_copy(distance(source), 0);\n  int count = 0;\n\n  while (count < N) {\n    // Compute min distance to all neighbors of a vertex.\n    Kokkos::parallel_for(\"minDistance\", 0, N, [&](const int i) {\n      for (int j = 0; j < N; j++) {\n        if (A_copy(i, j) == 1 && distance(i) + 1 < distance(j)) {\n          predecessor(j, i);\n          distance(j) = distance(i) + 1;\n        }\n      }\n    });\n    Kokkos::fence();\n    count += 1;\n  }\n\n  // If dest isn't reachable, return -1\n  if (distance(dest) == 1000) {\n    return -1;\n  }\n\n  // Reverse the edges to find the shortest path\n  Kokkos::View<int*, memspace> path(Kokkos::ViewAllocateWithoutInitializing(\"path\"), N);\n  Kokkos::deep_copy(path, 0);\n  path(dest) = 1;\n  int curr = dest;\n  while (curr!= source) {\n    curr = predecessor(curr, source);\n    path(curr) = 1;\n  }\n\n  // Count the edges in the shortest path\n  int countEdges = 0;\n  Kokkos::parallel_reduce(\"countEdges\", 0, N, [&](const int i, int &count) {\n    count += path(i);\n  }, countEdges);\n  Kokkos::fence();\n  return countEdges - 1;\n}",
            "// TODO\n  return 0;\n}",
            "Kokkos::View<bool**> visited(\"visited\", N, N);\n  Kokkos::parallel_for(\"visited\", Kokkos::RangePolicy<Kokkos::Rank<2>>({0, 0}, {N, N}), KOKKOS_LAMBDA(int i, int j) {\n    visited(i, j) = false;\n  });\n  Kokkos::View<int*> queue(\"queue\", N);\n  int queue_tail = 0;\n  Kokkos::View<int*> queue_next(\"queue_next\", N);\n  Kokkos::parallel_for(\"queue_init\", Kokkos::RangePolicy<Kokkos::Rank<1>>({0}, {N}), KOKKOS_LAMBDA(int i) {\n    queue_next(i) = -1;\n  });\n  Kokkos::View<int*> distance(\"distance\", N);\n  Kokkos::parallel_for(\"distance_init\", Kokkos::RangePolicy<Kokkos::Rank<1>>({0}, {N}), KOKKOS_LAMBDA(int i) {\n    distance(i) = -1;\n  });\n  Kokkos::parallel_for(\"bfs\", Kokkos::RangePolicy<Kokkos::Rank<1>>({0}, {N}), KOKKOS_LAMBDA(int i) {\n    if (i == source) {\n      visited(i, i) = true;\n      distance(i) = 0;\n      queue(queue_tail++) = i;\n      queue_next(i) = -1;\n    }\n  });\n  while (queue_tail > 0) {\n    int u = queue(--queue_tail);\n    Kokkos::parallel_for(\"bfs_loop\", Kokkos::RangePolicy<Kokkos::Rank<1>>({0}, {N}), KOKKOS_LAMBDA(int i) {\n      if (!visited(u, i) && A(u, i)) {\n        visited(u, i) = true;\n        distance(i) = distance(u) + 1;\n        int next = queue_tail;\n        queue(queue_tail++) = i;\n        queue_next(i) = queue_next(u);\n        queue_next(u) = next;\n      }\n    });\n    int next = queue_next(u);\n    queue_next(u) = -1;\n    if (next >= 0) {\n      queue(queue_tail++) = next;\n    }\n  }\n  return distance(dest);\n}",
            "// Implement this function:\n\n  return 0;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n  Kokkos::View<int*> prev(\"prev\", N);\n  Kokkos::View<int*> flag(\"flag\", N);\n\n  Kokkos::parallel_for(\"Dijkstra init\",\n\t\t       Kokkos::RangePolicy<Kokkos::TaggedParallel>(0, N),\n\t\t       KOKKOS_LAMBDA(const int& i) {\n\t\t\t dist(i) = 1e8;\n\t\t\t flag(i) = 0;\n\t\t\t prev(i) = -1;\n\t\t       });\n  Kokkos::fence();\n\n  Kokkos::parallel_for(\"Dijkstra update\",\n\t\t       Kokkos::RangePolicy<Kokkos::TaggedParallel>(0, N),\n\t\t       KOKKOS_LAMBDA(const int& i) {\n\t\t\t if (i == source) {\n\t\t\t   dist(i) = 0;\n\t\t\t   flag(i) = 1;\n\t\t\t }\n\t\t       });\n  Kokkos::fence();\n\n  // TODO: use Kokkos::parallel_for to implement Dijkstra's algorithm.\n  // The goal is to fill in the arrays dist and prev.\n  //\n  // The Dijkstra algorithm uses a priority queue to keep track of nodes\n  // that have been visited but whose neighbors haven't been explored yet.\n  // The first node in the priority queue is the node with the smallest\n  // value of dist.\n  //\n  // Use a Kokkos::View to implement the priority queue.\n  //\n  // Note: In the comments below, it is assumed that you are using a priority queue implemented as a min-heap.\n  // If you are using something other than a heap (for example, a linked list, as in the slides)\n  // then you'll need to convert it to a heap before using it in the algorithm.\n\n  Kokkos::View<int*> pq(\"pq\", N);\n\n  // Pop the node with the smallest value of dist from the queue\n  // TODO: Implement this\n\n  // If the popped node was the destination node, then stop and return.\n  // If the popped node was not the destination node, then:\n  // 1. For each neighbor of the popped node, update its distance from the source node\n  // 2. TODO: push the node's neighbors onto the priority queue\n\n  // TODO: Implement this\n\n  // The distance to the destination node is in dist(dest).\n  // Return it.\n  return dist(dest);\n}",
            "// Compute the length of the shortest path\n  int length = 0;\n\n  // Compute the length of the shortest path\n  int length = 0;\n\n  // TODO: Fill in the shortest path length computation\n  return length;\n}",
            "Kokkos::View<int**> dp(\"dp\", N, N);\n  Kokkos::deep_copy(dp, -1);\n  // Kokkos::View<int**> dp(\"dp\", N, N);\n  // Kokkos::deep_copy(dp, -1);\n  // Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n  //                      KOKKOS_LAMBDA(const int &i) {\n  //   for (int j = 0; j < N; ++j) {\n  //     if (i == j)\n  //       dp(i, j) = 0;\n  //   }\n  // });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(const int &i) {\n                         if (i == source)\n                           dp(i, i) = 0;\n                         if (i == dest)\n                           dp(i, i) = 0;\n                       });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(const int &i) {\n                         for (int j = 0; j < N; ++j) {\n                           if (A(i, j) == 1)\n                             dp(i, j) = 1;\n                         }\n                       });\n  Kokkos::parallel_for(Kokkos::RangePolicy<Kokkos::Cuda>(0, N),\n                       KOKKOS_LAMBDA(const int &i) {\n                         for (int k = 0; k < N; ++k) {\n                           for (int j = 0; j < N; ++j) {\n                             if (dp(i, k)!= -1 && dp(k, j)!= -1) {\n                               if (dp(i, j) == -1)\n                                 dp(i, j) = dp(i, k) + dp(k, j);\n                               else\n                                 dp(i, j) = dp(i, k) + dp(k, j) < dp(i, j)? dp(i, k) + dp(k, j) : dp(i, j);\n                             }\n                           }\n                         }\n                       });\n  int ret = -1;\n  for (int i = 0; i < N; ++i) {\n    ret = dp(i, dest);\n  }\n  return ret;\n}",
            "/* TODO: Your code here */\n\n  return -1;\n}",
            "Kokkos::View<int**> dist(\"dist\", N, N);\n  Kokkos::parallel_for(\"Initialize distance matrix\", N, KOKKOS_LAMBDA(const int i) {\n    for(int j=0; j<N; ++j) {\n      dist(i,j) = (i==j)? 0 : INT_MAX;\n    }\n  });\n  Kokkos::fence();\n  // TODO: Fill this in\n  return dist(source,dest);\n}",
            "// Kokkos::parallel_for\n\n    // Kokkos::parallel_reduce\n\n    return 0;\n}",
            "// Implement me!\n  return 0;\n}",
            "Kokkos::View<int*> dist(\"dist\", N);\n    Kokkos::View<int*> predecessor(\"predecessor\", N);\n    Kokkos::deep_copy(dist, Kokkos::ConstantFunctor<int,int>(std::numeric_limits<int>::max()));\n    Kokkos::deep_copy(predecessor, Kokkos::ConstantFunctor<int,int>(-1));\n    dist(source) = 0;\n    Kokkos::View<bool*> active(\"active\", N);\n    Kokkos::deep_copy(active, Kokkos::ConstantFunctor<bool,bool>(true));\n    int* p_active = active.data();\n    while(true) {\n        // Find the minimum distance unvisited node.\n        int min_distance = std::numeric_limits<int>::max();\n        int min_index = -1;\n        for(int i = 0; i < N; i++) {\n            if(active(i) && dist(i) < min_distance) {\n                min_distance = dist(i);\n                min_index = i;\n            }\n        }\n        if(min_index == -1) {\n            // There are no unvisited nodes.\n            return std::numeric_limits<int>::max();\n        }\n        // Mark it as visited.\n        active(min_index) = false;\n        if(min_index == dest) {\n            break;\n        }\n        // Update distances.\n        for(int i = 0; i < N; i++) {\n            if(A(min_index, i) == 1 && dist(i) > dist(min_index) + 1) {\n                dist(i) = dist(min_index) + 1;\n                predecessor(i) = min_index;\n            }\n        }\n    }\n    // Backtrace the path.\n    std::vector<int> path;\n    int current = dest;\n    while(true) {\n        path.push_back(current);\n        current = predecessor(current);\n        if(current == -1) {\n            break;\n        }\n    }\n    std::reverse(path.begin(), path.end());\n    return path.size();\n}",
            "/* TODO */\n    return -1;\n}",
            "if (source == dest) {\n\t\treturn 0;\n\t}\n\n\t// Allocate a Kokkos::View for the visited matrix\n\tKokkos::View<int*> visited(\"visited\", N);\n\n\t// Initialize the visited matrix to zero\n\t// The following code may be replaced by KokkosBlas::fill(...)\n\tKokkos::parallel_for(\n\t\t\"InitializeVisited\",\n\t\tKokkos::RangePolicy<Kokkos::ThreadVectorRange>(0, N),\n\t\tKOKKOS_LAMBDA(const int& i) {\n\t\t\tvisited(i) = 0;\n\t\t}\n\t);\n\n\t// Create a Kokkos::View for the queue\n\tKokkos::View<int*> queue(\"queue\", N);\n\n\t// Create a Kokkos::View for the number of elements in the queue\n\tKokkos::View<int> queueSize(\"queueSize\");\n\n\t// Initialize the queue and queue size\n\tqueue(0) = source;\n\tqueueSize() = 1;\n\n\t// While there are elements in the queue\n\twhile (queueSize() > 0) {\n\t\t// Decrease the queue size\n\t\tqueueSize() -= 1;\n\t\t// Read the current node from the queue\n\t\tint current = queue(queueSize());\n\t\t// If this node is the destination, return the length of the shortest path\n\t\tif (current == dest) {\n\t\t\treturn queueSize() + 1;\n\t\t}\n\n\t\t// Otherwise, loop over the neighbors of the current node\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\t// Skip the neighbor if it is already visited\n\t\t\tif (visited(i)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// Skip the neighbor if there is no edge connecting the current node and the neighbor\n\t\t\tif (!A(current, i)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// Add the neighbor to the queue and mark it as visited\n\t\t\tqueue(queueSize()) = i;\n\t\t\tvisited(i) = 1;\n\t\t\tqueueSize() += 1;\n\t\t}\n\t}\n\t// Return -1 if the destination was not found\n\treturn -1;\n}",
            "// TODO\n\n\treturn -1;\n}",
            "// Get the number of threads per team\n  const int teamSize = Kokkos::TeamPolicy<>::member_type::team_size_recommended(Kokkos::DefaultExecutionSpace(), A.extent(0), A.extent(1));\n  // Get the number of teams\n  const int nTeams = static_cast<int>(std::ceil(static_cast<double>(A.extent(0)) / teamSize));\n\n  int shortestPathLength = 0;\n\n  Kokkos::parallel_reduce(\n    Kokkos::TeamPolicy<>(nTeams, teamSize),\n    KOKKOS_LAMBDA(const Kokkos::TeamPolicy<>::member_type& teamMember, int& localShortestPathLength) {\n      for (size_t ii = teamMember.league_rank() * teamSize + teamMember.team_rank(); ii < N; ii += teamSize * nTeams) {\n        if (ii == source) {\n          localShortestPathLength = 0;\n          teamMember.team_barrier();\n          return;\n        }\n        if (ii == dest) {\n          localShortestPathLength = std::numeric_limits<int>::max();\n          teamMember.team_barrier();\n          return;\n        }\n        const int minPathLength = (localShortestPathLength < std::numeric_limits<int>::max())? localShortestPathLength + 1 : std::numeric_limits<int>::max();\n        teamMember.team_barrier();\n        if (minPathLength < std::numeric_limits<int>::max()) {\n          for (size_t jj = 0; jj < N; ++jj) {\n            if (A(ii, jj) > 0) {\n              localShortestPathLength = std::min(localShortestPathLength, A(ii, jj) + teamMember.team_scan(Kokkos::Sum<int, Kokkos::Sum<int>::assign>(minPathLength)));\n              teamMember.team_barrier();\n              break;\n            }\n          }\n        }\n      }\n    },\n    shortestPathLength);\n  return shortestPathLength;\n}",
            "Kokkos::View<int*> distance(Kokkos::ViewAllocateWithoutInitializing(\"distance\"), N);\n\tKokkos::View<int*> predecessor(Kokkos::ViewAllocateWithoutInitializing(\"predecessor\"), N);\n\tKokkos::View<int*> unvisited(Kokkos::ViewAllocateWithoutInitializing(\"unvisited\"), N);\n\tint result;\n\n\t// TODO\n\t// Initialize distance and predecessor views.\n\t// BFS is done by traversing the graph layer by layer, so we can\n\t// keep track of which layer we're on in distance. We can also keep\n\t// track of the \"previous\" vertex at each step in predecessor.\n\t// BFS terminates when we have found the target, or we have visited\n\t// every vertex in the graph.\n\t// For every vertex i, unvisited(i) is initially true if i is unvisited,\n\t// and false if i has already been visited.\n\tKokkos::deep_copy(distance, 0);\n\tKokkos::deep_copy(predecessor, -1);\n\tKokkos::deep_copy(unvisited, 0);\n\tKokkos::deep_copy(unvisited, 1);\n\tKokkos::deep_copy(distance, 0);\n\tKokkos::deep_copy(predecessor, -1);\n\tKokkos::deep_copy(unvisited, 0);\n\tKokkos::deep_copy(unvisited, 1);\n\n\t// TODO\n\t// Breadth-first search.\n\t// Traverse the graph layer by layer, until we find the target or\n\t// we have visited every vertex in the graph.\n\tint cur_layer_size = 1;\n\tint next_layer_size = 0;\n\tint next_layer_vertices[N];\n\n\tdistance[source] = 0;\n\tpredecessor[source] = source;\n\tunvisited[source] = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A(source, i)!= 0) {\n\t\t\tnext_layer_vertices[next_layer_size] = i;\n\t\t\tnext_layer_size += 1;\n\t\t}\n\t}\n\n\twhile (cur_layer_size > 0 && next_layer_size > 0) {\n\t\tfor (int i = 0; i < cur_layer_size; i++) {\n\t\t\tint cur_vertex = next_layer_vertices[i];\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A(cur_vertex, j)!= 0 && unvisited[j]) {\n\t\t\t\t\tnext_layer_vertices[next_layer_size] = j;\n\t\t\t\t\tnext_layer_size += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i < cur_layer_size; i++) {\n\t\t\tint cur_vertex = next_layer_vertices[i];\n\t\t\tdistance[cur_vertex] = distance[next_layer_vertices[i]] + 1;\n\t\t\tpredecessor[cur_vertex] = next_layer_vertices[i];\n\t\t\tunvisited[cur_vertex] = 0;\n\t\t}\n\n\t\tcur_layer_size = next_layer_size;\n\t\tnext_layer_size = 0;\n\t}\n\n\tif (distance(dest) == -1) {\n\t\t// We never found dest.\n\t\tresult = -1;\n\t} else {\n\t\t// We did find dest! Get the length of the shortest path.\n\t\tint i = dest;\n\t\tint length = 0;\n\t\twhile (i!= source) {\n\t\t\ti = predecessor(i);\n\t\t\tlength += 1;\n\t\t}\n\n\t\tresult = length;\n\t}\n\n\treturn result;\n}",
            "// Fill in the code here\n    // you can use the helper functions defined below\n    return -1;\n}",
            "int ans = 0;\n\tfor (size_t v = 0; v < N; ++v) {\n\t\tif (A(v, dest) == 1) {\n\t\t\tans = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\t// if source is dest, we're done.\n\tif (source == dest) {\n\t\treturn ans;\n\t}\n\t// compute the shortest path from source to all other vertices, and update the answer\n\t// if the path to the dest vertex is shorter\n\tKokkos::View<int*, Kokkos::LayoutRight, Kokkos::HostSpace> distances(\"distances\", N);\n\tKokkos::View<bool*, Kokkos::LayoutRight, Kokkos::HostSpace> visited(\"visited\", N);\n\tKokkos::View<bool*, Kokkos::LayoutRight, Kokkos::HostSpace> visited_scratch(\"visited_scratch\", N);\n\tKokkos::deep_copy(visited, false);\n\tKokkos::deep_copy(visited_scratch, false);\n\tKokkos::deep_copy(distances, -1);\n\tKokkos::deep_copy(distances(source), 0);\n\n\twhile (true) {\n\t\t// compute the distance to all unvisited vertices from source\n\t\tKokkos::parallel_for(\"bfs_update_distances\", N, [&](size_t v) {\n\t\t\tif (visited(v) == false && distances(v)!= -1) {\n\t\t\t\tfor (size_t w = 0; w < N; ++w) {\n\t\t\t\t\tif (visited(w) == false && A(v, w) == 1) {\n\t\t\t\t\t\tint new_distance = distances(v) + 1;\n\t\t\t\t\t\tif (distances(w) == -1 || new_distance < distances(w)) {\n\t\t\t\t\t\t\tdistances(w) = new_distance;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\t// check if dest is reachable. if not, the answer is -1\n\t\tif (distances(dest) == -1) {\n\t\t\tans = -1;\n\t\t\tbreak;\n\t\t}\n\t\t// mark all unvisited vertices as visited\n\t\tKokkos::parallel_for(\"bfs_mark_visited\", N, [&](size_t v) {\n\t\t\tif (visited(v) == false) {\n\t\t\t\tvisited(v) = true;\n\t\t\t}\n\t\t});\n\t\t// swap visited and visited_scratch so that we only mark vertices as visited once.\n\t\tKokkos::parallel_for(\"bfs_swap_visited\", N, [&](size_t v) {\n\t\t\tif (visited(v)) {\n\t\t\t\tvisited_scratch(v) = true;\n\t\t\t\tvisited(v) = false;\n\t\t\t}\n\t\t});\n\t\t// check if all vertices are visited\n\t\tbool all_visited = true;\n\t\tKokkos::parallel_reduce(\"bfs_check_all_visited\", N, Kokkos::RangePolicy<Kokkos::HostSpace>(0, 1), [&](size_t, bool &done) {\n\t\t\tdone = true;\n\t\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\t\tif (!visited(v) &&!visited_scratch(v)) {\n\t\t\t\t\tdone = false;\n\t\t\t\t}\n\t\t\t}\n\t\t}, Kokkos::Min<bool>(all_visited));\n\t\tif (all_visited) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tKokkos::parallel_reduce(\"bfs_min_distance\", N, Kokkos::RangePolicy<Kokkos::HostSpace>(0, 1), [&](size_t, int &min) {\n\t\tmin = std::min(min, distances("
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "omp",
        "prompt": "#include <omp.h>\n\n/* Return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use OpenMP to compute in parallel.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Your code here.\n    int dist[N];\n    memset(dist, -1, N * sizeof(int));\n    dist[source] = 0;\n    for (int k = 0; k < N; ++k) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (dist[i] == -1) continue;\n                if (dist[j] == -1 && A[i * N + j] == 1) {\n                    dist[j] = dist[i] + 1;\n                    continue;\n                }\n                if (dist[j] > 0 && dist[j] > dist[i] + 1 && A[i * N + j] == 1) {\n                    dist[j] = dist[i] + 1;\n                }\n            }\n        }\n    }\n    return dist[dest];\n}",
            "if (source == dest) {\n\t\treturn 0;\n\t}\n\n\tstd::vector<std::vector<int>> M;\n\tstd::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\n\t// initialize M\n\tfor (int i = 0; i < N; ++i) {\n\t\tstd::vector<int> vec(N);\n\t\tM.push_back(vec);\n\t}\n\n\t// fill M\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (i == j) {\n\t\t\t\tM[i][j] = 0;\n\t\t\t} else if (A[i*N + j] == 1) {\n\t\t\t\tM[i][j] = 1;\n\t\t\t} else {\n\t\t\t\tM[i][j] = std::numeric_limits<int>::max();\n\t\t\t}\n\t\t}\n\t}\n\n\t// Floyd-Warshall\n\tfor (int k = 0; k < N; ++k) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tM[i][j] = std::min(M[i][j], M[i][k] + M[k][j]);\n\t\t\t}\n\t\t}\n\t}\n\n\t// find shortest path length from source to dest\n\tint shortestLength = std::numeric_limits<int>::max();\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (M[source][i]!= std::numeric_limits<int>::max()) {\n\t\t\tshortestLength = std::min(shortestLength, M[source][i] + M[i][dest]);\n\t\t}\n\t}\n\n\tif (shortestLength == std::numeric_limits<int>::max()) {\n\t\treturn -1;\n\t}\n\n\treturn shortestLength;\n}",
            "int result = -1;\n#pragma omp parallel\n\t{\n\t\tint my_source = source;\n\t\tint my_dest = dest;\n\t\t// TODO: Compute the length of the shortest path from source to dest using the adjacency matrix A\n\t\t// TODO: Use OpenMP to run your parallel computation\n\t\t// TODO: Store the result in result\n\t}\n\treturn result;\n}",
            "std::vector<int> lengths(N, -1);\n\tlengths[source] = 0;\n\n\t#pragma omp parallel for num_threads(4)\n\tfor (int iter = 0; iter < N; iter++) {\n\t\tint currentNode = omp_get_thread_num();\n\t\tfor (int nextNode = 0; nextNode < N; nextNode++) {\n\t\t\tif (lengths[nextNode] == -1 && A[currentNode * N + nextNode] == 1) {\n\t\t\t\tlengths[nextNode] = lengths[currentNode] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn lengths[dest];\n}",
            "#pragma omp parallel\n    {\n        int min = INT32_MAX;\n        int next = 0;\n        int curr = 0;\n        int* dis = new int[N];\n        int* flag = new int[N];\n        for (int i = 0; i < N; ++i) {\n            dis[i] = A[N * source + i];\n            flag[i] = 0;\n        }\n        #pragma omp for nowait\n        for (int k = 0; k < N; ++k) {\n            for (int i = 0; i < N; ++i) {\n                for (int j = 0; j < N; ++j) {\n                    if (dis[i] + A[N * i + j] < dis[j] && flag[j] == 0) {\n                        dis[j] = dis[i] + A[N * i + j];\n                    }\n                }\n            }\n        }\n        #pragma omp for nowait\n        for (int i = 0; i < N; ++i) {\n            if (dis[i]!= INT32_MAX) {\n                if (dis[i] < min) {\n                    min = dis[i];\n                    next = i;\n                }\n            }\n        }\n        while (next!= dest) {\n            #pragma omp for nowait\n            for (int i = 0; i < N; ++i) {\n                for (int j = 0; j < N; ++j) {\n                    if (dis[next] + A[N * next + j] < dis[j] && flag[j] == 0) {\n                        dis[j] = dis[next] + A[N * next + j];\n                    }\n                }\n            }\n            #pragma omp for nowait\n            for (int i = 0; i < N; ++i) {\n                if (dis[i]!= INT32_MAX) {\n                    if (dis[i] < min) {\n                        min = dis[i];\n                        next = i;\n                    }\n                }\n            }\n        }\n        #pragma omp single\n        {\n            curr = min;\n        }\n        delete[] dis;\n        delete[] flag;\n        #pragma omp for\n        for (int i = 0; i < N; ++i) {\n            if (dis[i]!= INT32_MAX) {\n                if (dis[i] < curr) {\n                    curr = dis[i];\n                }\n            }\n        }\n        #pragma omp single\n        {\n            #pragma omp atomic write\n            min = curr;\n        }\n    }\n    return min;\n}",
            "// TODO: Implement\n    int length = 0;\n    return length;\n}",
            "// TODO\n\n    return -1;\n}",
            "int* dist = new int[N];\n  int* parent = new int[N];\n\n  // initialize dist[] and parent[]\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    dist[i] = A[source * N + i];\n    parent[i] = source;\n  }\n\n  // run Dijkstra's algorithm\n  bool relaxed = false;\n  while (!relaxed) {\n    relaxed = true;\n    #pragma omp parallel for reduction(&&: relaxed)\n    for (int u = 0; u < N; u++) {\n      for (int v = 0; v < N; v++) {\n        if (dist[u] + A[u * N + v] < dist[v]) {\n          dist[v] = dist[u] + A[u * N + v];\n          parent[v] = u;\n          relaxed = false;\n        }\n      }\n    }\n  }\n\n  // return the length of the shortest path\n  int length = dist[dest];\n  while (parent[dest]!= source) {\n    dest = parent[dest];\n    length++;\n  }\n  return length;\n}",
            "int * pathLength = new int[N];\n\n  #pragma omp parallel for\n  for(int i = 0; i < N; i++) {\n    pathLength[i] = -1;\n  }\n  pathLength[source] = 0;\n\n  #pragma omp parallel for schedule(dynamic, 1)\n  for(int i = 0; i < N; i++) {\n    for(int j = 0; j < N; j++) {\n      if(A[N*j + i]!= 0 && pathLength[j]!= -1) {\n        pathLength[i] = std::min(pathLength[j] + 1, pathLength[i]);\n      }\n    }\n  }\n\n  int result = pathLength[dest];\n\n  delete[] pathLength;\n\n  return result;\n}",
            "std::vector<int> d(N, -1);\n\td[source] = 0;\n\tbool is_done = false;\n\n\twhile(!is_done) {\n\t\t#pragma omp parallel for schedule(static)\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tint d_i = d[i];\n\n\t\t\tif(d_i == -1)\n\t\t\t\tcontinue;\n\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tint weight = A[i*N + j];\n\n\t\t\t\tif(weight == 0)\n\t\t\t\t\tcontinue;\n\n\t\t\t\tint new_d = d_i + weight;\n\n\t\t\t\tif(d[j] == -1) {\n\t\t\t\t\td[j] = new_d;\n\t\t\t\t} else if(d[j] > new_d) {\n\t\t\t\t\td[j] = new_d;\n\t\t\t\t\t#pragma omp flush(d)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp single\n\t\tis_done = true;\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tif(d[i] == -1) {\n\t\t\t\tis_done = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn d[dest];\n}",
            "auto is_valid_index = [&](int x){ return (x >= 0) && (x < (int)N);};\n\tauto is_valid_edge = [&](int x){ return (x >= 0) && (x < 2);};\n\tauto is_valid_node = [&](int x){ return is_valid_index(x);};\n\n\tint res = -1;\n\n\tint num_threads = omp_get_max_threads();\n\n\tstd::vector<std::vector<int>> distances(num_threads, std::vector<int>(N, -1));\n\tstd::vector<std::vector<int>> pred(num_threads, std::vector<int>(N, -1));\n\tstd::vector<std::vector<bool>> visited(num_threads, std::vector<bool>(N, false));\n\tstd::vector<std::vector<bool>> queue(num_threads, std::vector<bool>(N, false));\n\n\tdistances[0][source] = 0;\n\tpred[0][source] = source;\n\tqueue[0][source] = true;\n\n\t#pragma omp parallel num_threads(num_threads)\n\t{\n\t\tint thread_id = omp_get_thread_num();\n\t\tint start_node = (int)(thread_id * (double)N/num_threads);\n\t\tint end_node = (int)((thread_id+1) * (double)N/num_threads);\n\n\t\t#pragma omp for schedule(dynamic, 1)\n\t\tfor (int i = start_node; i < end_node; i++)\n\t\t{\n\t\t\twhile (true)\n\t\t\t{\n\t\t\t\tint node = -1;\n\t\t\t\tint min_distance = std::numeric_limits<int>::max();\n\t\t\t\t//find node with min distance\n\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t{\n\t\t\t\t\tif (queue[thread_id][j] && distances[thread_id][j] < min_distance)\n\t\t\t\t\t{\n\t\t\t\t\t\tmin_distance = distances[thread_id][j];\n\t\t\t\t\t\tnode = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (node == -1)\n\t\t\t\t\tbreak;\n\n\t\t\t\tqueue[thread_id][node] = false;\n\t\t\t\tvisited[thread_id][node] = true;\n\n\t\t\t\t// relax all outgoing edges\n\t\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\t{\n\t\t\t\t\tif (A[node*N + j] == 1 &&!visited[thread_id][j])\n\t\t\t\t\t{\n\t\t\t\t\t\tif (distances[thread_id][node] + 1 < distances[thread_id][j])\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tdistances[thread_id][j] = distances[thread_id][node] + 1;\n\t\t\t\t\t\t\tpred[thread_id][j] = node;\n\t\t\t\t\t\t\tqueue[thread_id][j] = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\t{\n\t\t\t// merge the results\n\t\t\tfor (int i = 0; i < N; i++)\n\t\t\t{\n\t\t\t\tif (pred[0][i] == -1 && pred[thread_id][i]!= -1)\n\t\t\t\t{\n\t\t\t\t\tpred[0][i] = pred[thread_id][i];\n\t\t\t\t\tdistances[0][i] = distances[thread_id][i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> v_distances;\n\tstd::vector<int> v_pred;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (pred[0][i]!= -1)\n\t\t{",
            "int dist[N];\n    std::fill(std::begin(dist), std::end(dist), INT_MAX);\n    int *dists = new int[N];\n    std::fill(dists, dists + N, INT_MAX);\n\n    int count = 0;\n    #pragma omp parallel for shared(count)\n    for (int i = 0; i < N; ++i) {\n        if (i == source) {\n            dists[i] = 0;\n            ++count;\n        } else if (A[source * N + i]!= 0) {\n            dists[i] = 1;\n            ++count;\n        }\n    }\n\n    bool done = false;\n    while (!done) {\n        done = true;\n        #pragma omp parallel for shared(done)\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (dists[i]!= INT_MAX && A[i * N + j]!= 0 && dists[i] + A[i * N + j] < dists[j]) {\n                    dists[j] = dists[i] + A[i * N + j];\n                    done = false;\n                }\n            }\n        }\n    }\n\n    int ret = INT_MAX;\n    for (int i = 0; i < N; ++i) {\n        if (dists[i]!= INT_MAX) {\n            ret = std::min(ret, dists[i]);\n        }\n    }\n\n    delete[] dists;\n    return ret;\n}",
            "std::vector<int> dist(N, INT_MAX);\n  std::vector<int> prev(N);\n  std::vector<bool> S(N, false);\n  std::vector<bool> P(N, false);\n  dist[source] = 0;\n\n  // Initialization\n  #pragma omp parallel for\n  for (size_t v = 0; v < N; v++) {\n    for (size_t u = 0; u < N; u++) {\n      if (A[N*u + v] && dist[u]!= INT_MAX && dist[u] + 1 < dist[v]) {\n        dist[v] = dist[u] + 1;\n        prev[v] = u;\n      }\n    }\n  }\n\n  // Loop\n  while (true) {\n    // Determine whether the destination node has been reached\n    bool reached = false;\n    #pragma omp parallel for\n    for (size_t v = 0; v < N; v++) {\n      if (dist[v]!= INT_MAX && dist[v] <= dist[dest]) {\n        reached = true;\n      }\n    }\n    if (!reached) {\n      break;\n    }\n\n    // Determine if a node needs to be relaxed\n    bool relax = false;\n    #pragma omp parallel for\n    for (size_t v = 0; v < N; v++) {\n      if (dist[v]!= INT_MAX && dist[v] <= dist[dest]) {\n        relax = true;\n      }\n    }\n    if (!relax) {\n      break;\n    }\n\n    // Relax\n    #pragma omp parallel for\n    for (size_t v = 0; v < N; v++) {\n      if (dist[v]!= INT_MAX && dist[v] <= dist[dest]) {\n        for (size_t u = 0; u < N; u++) {\n          if (A[N*u + v] && dist[u]!= INT_MAX && dist[u] + 1 < dist[v]) {\n            dist[v] = dist[u] + 1;\n            prev[v] = u;\n          }\n        }\n      }\n    }\n  }\n\n  // Backtrack\n  int p = dest;\n  std::vector<int> path;\n  path.push_back(p);\n  while (p!= source) {\n    p = prev[p];\n    path.push_back(p);\n  }\n\n  // Compute the path length\n  int length = 0;\n  for (int i = 0; i < path.size() - 1; i++) {\n    int u = path[i];\n    int v = path[i+1];\n    length += A[N*u + v];\n  }\n\n  return length;\n}",
            "// Initialize all distances to infinity\n\tstd::vector<int> D(N, INT_MAX);\n\n\t// Set the starting distance to source\n\tD[source] = 0;\n\n\t// Create a visited vector\n\tstd::vector<bool> V(N, false);\n\n\t// Loop until all vertices have been visited\n\tfor (int k = 0; k < N; ++k) {\n\t\t// Iterate through all vertices in the graph\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t// If vertex i has not been visited\n\t\t\tif (!V[i]) {\n\t\t\t\t// Iterate through all neighbors of vertex i\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\t// If we have an edge from i to j, update D and V accordingly\n\t\t\t\t\tif (A[i * N + j]!= 0 && D[i]!= INT_MAX) {\n\t\t\t\t\t\t// If distance to j is larger than the distance to i + distance to j\n\t\t\t\t\t\tif (D[j] > D[i] + A[i * N + j]) {\n\t\t\t\t\t\t\t// Update distance to j\n\t\t\t\t\t\t\tD[j] = D[i] + A[i * N + j];\n\t\t\t\t\t\t}\n\t\t\t\t\t\t// Mark vertex j as visited\n\t\t\t\t\t\tV[j] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Return the shortest path distance\n\treturn D[dest];\n}",
            "if (source == dest) {\n        return 0;\n    }\n    // write your code here\n\n    return -1;\n}",
            "// TODO\n\treturn 0;\n}",
            "std::vector<int> distance(N, INT_MAX);\n    distance[source] = 0;\n\n    #pragma omp parallel\n    {\n        #pragma omp for\n        for (size_t k = 0; k < N; ++k) {\n            for (size_t i = 0; i < N; ++i) {\n                for (size_t j = 0; j < N; ++j) {\n                    if (A[i*N+j]!= INT_MAX && distance[i]!= INT_MAX && distance[i]+A[i*N+j] < distance[j]) {\n                        distance[j] = distance[i] + A[i*N+j];\n                    }\n                }\n            }\n        }\n    }\n    return distance[dest];\n}",
            "// TODO: compute in parallel\n\t\n\treturn 0;\n}",
            "/* Your solution goes here */\n\tint* dist = new int[N];\n\tbool* vis = new bool[N];\n\tint* prev = new int[N];\n\n\tdist[source] = 0;\n\tvis[source] = true;\n\tfor (int i = 0; i < N; i++) {\n\t\tprev[i] = -1;\n\t}\n\n\tfor (int i = 0; i < N - 1; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (!vis[j] && A[j*N + j] == 1) {\n\t\t\t\tdist[j] = dist[j] + 1;\n\t\t\t}\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (A[j*N + k] == 1 &&!vis[k] && dist[k] > dist[j] + 1) {\n\t\t\t\t\tprev[k] = j;\n\t\t\t\t\tdist[k] = dist[j] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint min = -1;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (min < 0 || (dist[j] > 0 && dist[j] < min)) {\n\t\t\t\tmin = dist[j];\n\t\t\t}\n\t\t}\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist[j] == min) {\n\t\t\t\tvis[j] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\tint length = -1;\n\tint x = dest;\n\twhile (x >= 0) {\n\t\tlength++;\n\t\tx = prev[x];\n\t}\n\tdelete[] dist;\n\tdelete[] vis;\n\tdelete[] prev;\n\treturn length;\n}",
            "std::vector<int> lengths(N, -1);\n  std::vector<int> paths(N, -1);\n  lengths[source] = 0;\n  paths[source] = -1;\n\n  // TODO: Fill in the lengths and paths vectors\n#pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i == source) {\n        if (A[j * N + source]!= 0) {\n          lengths[j] = 1;\n          paths[j] = j;\n        }\n      } else if (A[j * N + i]!= 0) {\n        if (lengths[i]!= -1) {\n          if (lengths[j] == -1 || lengths[j] > lengths[i] + 1) {\n            lengths[j] = lengths[i] + 1;\n            paths[j] = i;\n          }\n        }\n      }\n    }\n  }\n\n  // Walk backwards to compute the shortest path from dest to source\n  std::vector<int> path;\n  int current = dest;\n  while (paths[current]!= -1) {\n    path.push_back(current);\n    current = paths[current];\n  }\n  path.push_back(source);\n\n  return path.size() - 1;\n}",
            "// Add your code here\n\tint shortestPathLen = -1;\n\n\tint *dist = new int[N];\n\n\tint maxLen = 2;\n\twhile (maxLen >= 0) {\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tdist[i] = -1;\n\n\t\tdist[source] = 0;\n\n\t\tfor (int len = 0; len < maxLen; len++) {\n\t\t\t#pragma omp parallel for\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (dist[i] == len) {\n\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[i * N + j] > 0 && dist[j] == -1)\n\t\t\t\t\t\t\tdist[j] = len + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp parallel for reduction(min: shortestPathLen)\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tif (shortestPathLen == -1 || (shortestPathLen > dist[i] && dist[i]!= -1))\n\t\t\t\tshortestPathLen = dist[i];\n\t\tmaxLen--;\n\t}\n\n\tif (shortestPathLen == -1)\n\t\tshortestPathLen = -1;\n\n\tdelete[] dist;\n\n\treturn shortestPathLen;\n}",
            "#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[j*N + i]!= 0 && A[i*N + j] == 0) {\n\t\t\t\tA[i*N + j] = A[j*N + i];\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[j*N + i]!= 0 && A[i*N + j] == 0) {\n\t\t\t\tA[i*N + j] = A[j*N + i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t#pragma omp parallel for\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[j*N + k] + A[k*N + i] < A[i*N + j]) {\n\t\t\t\t\tA[i*N + j] = A[j*N + k] + A[k*N + i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn A[dest*N + source];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u*N + v]) {\n\t\t\t\tif (dist[v] < 0) {\n\t\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\t\tq.push(v);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n  std::vector<bool> visited(N, false);\n  std::vector<int> predecessors(N, -1);\n  dist[source] = 0;\n  visited[source] = true;\n\n  // Use a queue to store vertices that have already been visited and may need to be revisited.\n  std::queue<int> queue;\n  queue.push(source);\n\n  // Repeat until all vertices have been visited.\n  while (not queue.empty()) {\n    int u = queue.front();\n    queue.pop();\n\n    // For each vertex v adjacent to u\n    for (size_t v = 0; v < N; v++) {\n      // We skip self-loops\n      if (A[u*N+v] and u!= v) {\n        // If v has not already been visited\n        if (not visited[v]) {\n          // Set the distance of v to the distance of u plus 1.\n          dist[v] = dist[u] + 1;\n\n          // Set v's predecessor to be u.\n          predecessors[v] = u;\n\n          // Add v to the queue for further processing\n          queue.push(v);\n          visited[v] = true;\n        }\n        // If v has already been visited and its distance is greater than the distance of u plus 1\n        else if (dist[v] > dist[u] + 1) {\n          // Update the distance of v to be the distance of u plus 1.\n          dist[v] = dist[u] + 1;\n\n          // Update v's predecessor to be u.\n          predecessors[v] = u;\n        }\n      }\n    }\n  }\n\n  // Compute the shortest path by working back from the destination node to the source node.\n  std::vector<int> shortestPath;\n  int u = dest;\n  while (u!= -1) {\n    shortestPath.push_back(u);\n    u = predecessors[u];\n  }\n  return shortestPath.size() - 1;\n}",
            "// TODO: Fill this in.\n  int out = 0;\n  #pragma omp parallel for\n  for(int i=0; i<N; i++){\n      for(int j=0; j<N; j++){\n        if(i == source){\n          if(j == dest){\n            out = 1;\n            break;\n          }\n          if(A[i*N + j] == 1){\n            out = 2;\n            break;\n          }\n        }\n      }\n  }\n  return out;\n}",
            "std::vector<int> distances(N, INT_MAX);\n\tdistances[source] = 0;\n\tstd::vector<int> processed(N, 0);\n\tbool found = false;\n\t#pragma omp parallel for num_threads(4)\n\tfor (int i=0; i<N; i++) {\n\t\tfor (int j=0; j<N; j++) {\n\t\t\tint distance_to_j = distances[j];\n\t\t\tif (A[i*N + j]!= 0 && distance_to_j!= INT_MAX) {\n\t\t\t\tdistances[j] = std::min(distances[j], distance_to_j + 1);\n\t\t\t}\n\t\t}\n\t}\n\treturn distances[dest];\n}",
            "int length = -1;\n\n  #pragma omp parallel for\n  for (size_t v = 0; v < N; ++v) {\n    if (v == source)\n      continue;\n\n    std::vector<int> predecessor(N);\n    std::vector<int> distance(N);\n    for (size_t i = 0; i < N; ++i) {\n      predecessor[i] = -1;\n      distance[i] = INT_MAX;\n    }\n\n    predecessor[source] = -1;\n    distance[source] = 0;\n\n    // initialize the visited list\n    std::vector<bool> visited(N);\n    visited[source] = true;\n\n    // initialize the Q list\n    std::vector<int> Q;\n    Q.push_back(source);\n\n    // BFS traversal\n    while (Q.size() > 0) {\n      int u = Q[0];\n      Q.erase(Q.begin());\n\n      if (u == dest) {\n        length = distance[u];\n        break;\n      }\n\n      for (size_t i = 0; i < N; ++i) {\n        if (!visited[i] && A[u * N + i] > 0) {\n          Q.push_back(i);\n          predecessor[i] = u;\n          distance[i] = distance[u] + 1;\n          visited[i] = true;\n        }\n      }\n    }\n\n    // BFS traversal ends, check if length > 0\n    if (length!= -1) {\n      break;\n    }\n  }\n\n  // backtracking to get the shortest path\n  std::vector<int> path;\n  int u = dest;\n  while (u!= -1) {\n    path.push_back(u);\n    u = predecessor[u];\n  }\n\n  return length;\n}",
            "// allocate arrays for the values and predecessors of each vertex\n  std::vector<int> values(N, std::numeric_limits<int>::max());\n  std::vector<int> pred(N, std::numeric_limits<int>::max());\n\n  // mark the source vertex as having length 0\n  values[source] = 0;\n\n  // the following 2 vars are just for debugging; they help you to see the correctness of your results\n  int num_iters = 0;\n  int num_threads = 1;\n\n  // TODO: write your solution here\n  //...\n\n  // Return the value at the destination vertex\n  return values[dest];\n}",
            "int const inf = 100000;\n\t// std::vector<int> distances(N, inf);\n\tint * distances = new int[N];\n\tint * Q = new int[N];\n\t// int distances[N];\n\t// int Q[N];\n\t#pragma omp parallel for\n\tfor(int i = 0; i < N; i++) {\n\t\tdistances[i] = inf;\n\t\tQ[i] = i;\n\t}\n\tdistances[source] = 0;\n\n\twhile(Q[0]!= dest) {\n\t\tint min = inf;\n\t\tint minIdx = -1;\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tint node = Q[i];\n\t\t\tif(distances[node] < min) {\n\t\t\t\tmin = distances[node];\n\t\t\t\tminIdx = i;\n\t\t\t}\n\t\t}\n\n\t\tint u = Q[minIdx];\n\t\tQ[minIdx] = Q[N - 1];\n\t\tQ[N - 1] = u;\n\t\tN--;\n\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tint v = Q[i];\n\t\t\tif(A[u * N + v]!= 0) {\n\t\t\t\tif(distances[v] > distances[u] + A[u * N + v]) {\n\t\t\t\t\tdistances[v] = distances[u] + A[u * N + v];\n\t\t\t\t\tQ[i] = v;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tint result = distances[dest];\n\tdelete[] distances;\n\tdelete[] Q;\n\treturn result;\n}",
            "#pragma omp parallel for schedule(dynamic,1)\n\tfor (int i=0; i<N; ++i) {\n\t\tint temp_val = A[source*N+i];\n\t\tif (temp_val == 0) {\n\t\t\tA[source*N+i] = INT_MAX;\n\t\t}\n\t\telse {\n\t\t\tA[source*N+i] = i;\n\t\t}\n\t}\n\tint source_pos = source;\n\tbool found = false;\n\twhile (found!= true) {\n\t\t#pragma omp parallel for schedule(dynamic,1)\n\t\tfor (int i=0; i<N; ++i) {\n\t\t\tint temp_val = A[source_pos*N+i];\n\t\t\tif (temp_val > A[source_pos*N+dest]) {\n\t\t\t\tA[source_pos*N+i] = A[source_pos*N+dest] + 1;\n\t\t\t}\n\t\t}\n\t\tint min_val = INT_MAX;\n\t\tfor (int i=0; i<N; ++i) {\n\t\t\tif (A[source_pos*N+i] < min_val && A[source_pos*N+i]!= INT_MAX) {\n\t\t\t\tmin_val = A[source_pos*N+i];\n\t\t\t\tsource_pos = i;\n\t\t\t}\n\t\t}\n\t\tif (source_pos == dest) {\n\t\t\tfound = true;\n\t\t}\n\t}\n\treturn A[source*N+dest];\n}",
            "// Initialize a vector to store the distance from each node to the source\n  std::vector<int> distances(N, -1);\n  distances[source] = 0;\n\n  // Define a queue to store the nodes whose distances are not yet known\n  std::queue<int> q;\n  q.push(source);\n\n  // Loop until the queue is empty\n  while(!q.empty()) {\n\n    // Get the next node whose distance is still unknown\n    int u = q.front();\n    q.pop();\n\n    // Loop over all nodes adjacent to u\n    for(size_t v = 0; v < N; v++) {\n\n      // If the distance is not yet known and the edge exists\n      if(distances[v] == -1 && A[u*N + v] == 1) {\n\n        // Store the distance to v\n        distances[v] = distances[u] + 1;\n\n        // Add v to the queue\n        q.push(v);\n      }\n    }\n  }\n\n  return distances[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tstd::vector<int> prev(N, -1);\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> Q(N, 0);\n\t\n\tint current;\n\tint length = 0;\n\n\tdist[source] = 0;\n\n\tint idx = 0;\n\tQ[idx++] = source;\n\n\twhile (idx) {\n\t\tcurrent = Q[--idx];\n\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[current * N + i] &&!visited[i]) {\n\t\t\t\tdist[i] = dist[current] + 1;\n\t\t\t\tprev[i] = current;\n\n\t\t\t\tQ[idx++] = i;\n\t\t\t}\n\t\t}\n\t\t\n\t\tvisited[current] = true;\n\t}\n\n\tif (prev[dest]!= -1) {\n\t\tlength = dist[dest];\n\t\twhile (dest!= source) {\n\t\t\tdest = prev[dest];\n\t\t\tlength++;\n\t\t}\n\t}\n\n\treturn length;\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\t\n\t//#pragma omp parallel for schedule(dynamic)\n\tfor(int t=0; t<1000; t++){\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tif(A[i*N + j]!= 0){\n\t\t\t\t\t#pragma omp critical\n\t\t\t\t\t{\n\t\t\t\t\t\tif(dist[j] > dist[i] + 1){\n\t\t\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "int length = 1000;\n\t#pragma omp parallel for num_threads(4)\n\tfor (int i = 0; i < N; i++) {\n\t\t// Do some work here\n\t\tint currentLength = 0;\n\t\tcurrentLength = (source == dest)? 0 : 1000;\n\n\t\tif (A[source * N + i] == 1 && currentLength < length) {\n\t\t\tcurrentLength = shortestPathLength(A, N, i, dest);\n\t\t\tif (currentLength < length)\n\t\t\t\tlength = currentLength;\n\t\t}\n\t}\n\treturn length;\n}",
            "// TODO: insert your code here\n    int length;\n    std::vector<int> dist(N, INT_MAX);\n    dist[source]=0;\n\n    // TODO: insert your code here\n\n    return length;\n}",
            "// TODO: Your code here\n}",
            "std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n\n# pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] && dist[j]!= INT_MAX && dist[i] + 1 < dist[j]) {\n        dist[j] = dist[i] + 1;\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n  dist[source] = 0;\n\n  #pragma omp parallel for\n  for (int k = 0; k < N; ++k) {\n    for (int i = 0; i < N; ++i) {\n      if (dist[i] == -1)\n        continue;\n\n      for (int j = 0; j < N; ++j) {\n        if (dist[j] == -1 && A[i * N + j] == 1)\n          dist[j] = dist[i] + 1;\n      }\n    }\n  }\n  return dist[dest];\n}",
            "// TODO\n    return 0;\n}",
            "int len = 0;\n\n\t#pragma omp parallel for schedule(dynamic,1)\n\tfor (int i = 0; i < N; i++) {\n\t\tif (i == source) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tint path = 0;\n\t\tbool visited[N] = {false};\n\t\tstd::vector<int> queue;\n\t\tqueue.push_back(source);\n\t\tvisited[source] = true;\n\n\t\twhile (queue.size() > 0) {\n\t\t\tint s = queue.back();\n\t\t\tqueue.pop_back();\n\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[N*s + j] == 1 &&!visited[j]) {\n\t\t\t\t\tqueue.push_back(j);\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (visited[i]) {\n\t\t\t\tpath = visited[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (visited[i]) {\n\t\t\t#pragma omp critical\n\t\t\t{\n\t\t\t\tif (path > len) {\n\t\t\t\t\tlen = path;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn len;\n}",
            "// Your code here\n}",
            "// TODO: implement\n\tint i = 0;\n\tint j = 0;\n\tint k = 0;\n\tint m = 0;\n\tint n = 0;\n\tint length = 0;\n\tbool* v = new bool[N];\n\n\tfor (k = 0; k < N; k++) {\n\t\tv[k] = false;\n\t}\n\tv[source] = true;\n\tm = source;\n\tint* p = new int[N];\n\tfor (j = 0; j < N; j++) {\n\t\tp[j] = -1;\n\t}\n\tp[source] = -2;\n\ti = 0;\n\tlength = 0;\n\twhile (m!= dest) {\n\t\tif (p[m] == -2) {\n\t\t\ti = 0;\n\t\t\tfor (n = 0; n < N; n++) {\n\t\t\t\tif (A[N * m + n] == 1) {\n\t\t\t\t\tv[n] = true;\n\t\t\t\t\tp[n] = m;\n\t\t\t\t\tif (i == 0) {\n\t\t\t\t\t\tm = n;\n\t\t\t\t\t\ti++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (p[m] >= 0) {\n\t\t\tm = p[m];\n\t\t\tlength++;\n\t\t}\n\t\telse {\n\t\t\tm = -1;\n\t\t}\n\t}\n\tdelete[] v;\n\tdelete[] p;\n\treturn length;\n}",
            "int *shortestPath = new int[N];\n  int *isVisited = new int[N];\n  int *parent = new int[N];\n  for (int i = 0; i < N; i++) {\n    isVisited[i] = 0;\n    parent[i] = -1;\n    shortestPath[i] = INT_MAX;\n  }\n  shortestPath[source] = 0;\n  // std::cout << \"parent \" << parent[source] << std::endl;\n\n  // std::cout << \"isVisited \" << isVisited[source] << std::endl;\n  // std::cout << \"shortestPath \" << shortestPath[source] << std::endl;\n\n  // Start the timer!\n  auto start = omp_get_wtime();\n  bool changed = true;\n  while (changed) {\n    changed = false;\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n      if (!isVisited[i]) {\n        for (int j = 0; j < N; j++) {\n          if (A[i*N + j] &&!isVisited[j] && shortestPath[i]!= INT_MAX && shortestPath[i] + 1 < shortestPath[j]) {\n            shortestPath[j] = shortestPath[i] + 1;\n            parent[j] = i;\n            // std::cout << \"parent \" << parent[j] << std::endl;\n            isVisited[j] = 1;\n            // std::cout << \"isVisited \" << isVisited[j] << std::endl;\n            changed = true;\n          }\n        }\n      }\n    }\n  }\n  int result = -1;\n  if (isVisited[dest]) {\n    result = shortestPath[dest];\n  }\n\n  delete[] shortestPath;\n  delete[] isVisited;\n  delete[] parent;\n\n  // Stop the timer!\n  auto end = omp_get_wtime();\n  auto elapsed = end - start;\n  return result;\n}",
            "int *dist = new int[N];\n    int *parent = new int[N];\n\n    for (int i = 0; i < N; i++) {\n        dist[i] = -1;\n        parent[i] = -1;\n    }\n\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; i++) {\n            if (A[source * N + i] == 1) {\n                #pragma omp critical\n                {\n                    dist[i] = 0;\n                    parent[i] = source;\n                }\n            }\n        }\n\n        #pragma omp for schedule(dynamic)\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (dist[j] >= 0 && A[j * N + i] == 1) {\n                    #pragma omp critical\n                    {\n                        if (dist[i] == -1 || dist[i] > dist[j] + 1) {\n                            dist[i] = dist[j] + 1;\n                            parent[i] = j;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    int shortestPathLength = dist[dest];\n    delete[] dist;\n    delete[] parent;\n    return shortestPathLength;\n}",
            "std::vector<int> dist(N, -1);\n  dist[source] = 0;\n\n  #pragma omp parallel\n  {\n    // TODO\n  }\n\n  return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n  dist[source] = 0;\n\n  std::vector<int> pred(N, -1);\n\n#pragma omp parallel for num_threads(2)\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (i == j) {\n        continue;\n      }\n\n      if (A[i * N + j] == 1 && (dist[i] == -1 || dist[i] > dist[j] + 1)) {\n        dist[i] = dist[j] + 1;\n        pred[i] = j;\n      }\n    }\n  }\n\n  std::vector<int> path;\n  int x = dest;\n  while (x!= -1) {\n    path.push_back(x);\n    x = pred[x];\n  }\n\n  return path.size() - 1;\n}",
            "// TODO: YOUR CODE HERE\n\t\n    int nthreads;\n    int* dist;\n    int* prev;\n    int* temp;\n    int i, j, k, x, y, l, len;\n    int* dist_array;\n    int* prev_array;\n    int* finished;\n    int length;\n    int dist_length;\n    \n    #pragma omp parallel private(nthreads, x, y, l) shared(A, N, source, dest)\n    {\n        #pragma omp single\n        {\n            nthreads = omp_get_num_threads();\n        }\n        \n        dist_array = (int*) malloc(nthreads * sizeof(int));\n        prev_array = (int*) malloc(nthreads * sizeof(int));\n        finished = (int*) calloc(nthreads, sizeof(int));\n        \n        #pragma omp for schedule(static)\n        for (i = 0; i < nthreads; i++) {\n            dist_array[i] = -1;\n            prev_array[i] = -1;\n        }\n        \n        #pragma omp for schedule(static)\n        for (i = 0; i < nthreads; i++) {\n            dist_array[i] = -1;\n            prev_array[i] = -1;\n        }\n        \n        #pragma omp single\n        {\n            dist = (int*) malloc(N * sizeof(int));\n            prev = (int*) malloc(N * sizeof(int));\n            \n            for (i = 0; i < N; i++) {\n                dist[i] = -1;\n                prev[i] = -1;\n            }\n            \n            dist[source] = 0;\n            for (i = 0; i < N; i++) {\n                for (j = 0; j < N; j++) {\n                    for (k = 0; k < nthreads; k++) {\n                        if (finished[k] == 0 && dist_array[k]!= -1) {\n                            x = dist_array[k];\n                            y = prev_array[k];\n                            break;\n                        }\n                    }\n                    \n                    if (A[x * N + j] == 1 && dist[j] == -1) {\n                        dist[j] = dist[x] + 1;\n                        prev[j] = x;\n                    }\n                    \n                    if (x == dest) {\n                        finished[k] = 1;\n                        dist_array[k] = -1;\n                        prev_array[k] = -1;\n                    } else {\n                        dist_array[k] = x;\n                        prev_array[k] = prev[x];\n                    }\n                }\n            }\n            \n            free(dist);\n            free(prev);\n        }\n    }\n    \n    length = 0;\n    for (i = 0; i < N; i++) {\n        if (dist_array[i] == dest) {\n            length = dist_array[i];\n            break;\n        }\n    }\n    \n    return length;\n}",
            "// TODO: Replace me\n  return -1;\n}",
            "int shortestPathLength = 0;\n\tbool hasFoundDest = false;\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> distance(N, -1);\n\tstd::queue<int> queue;\n\n\tdistance[source] = 0;\n\tqueue.push(source);\n\n\twhile (!queue.empty() &&!hasFoundDest) {\n\t\tint curr = queue.front();\n\t\tqueue.pop();\n\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[curr * N + i] &&!visited[i]) {\n\t\t\t\tdistance[i] = distance[curr] + 1;\n\t\t\t\tqueue.push(i);\n\t\t\t\tvisited[i] = true;\n\n\t\t\t\tif (i == dest) {\n\t\t\t\t\tshortestPathLength = distance[dest];\n\t\t\t\t\thasFoundDest = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn shortestPathLength;\n}",
            "// Your code here\n  int dis[N];\n  int visited[N];\n  int path[N];\n\n  for (int i = 0; i < N; i++) {\n    dis[i] = INT_MAX;\n    visited[i] = 0;\n    path[i] = -1;\n  }\n\n  dis[source] = 0;\n\n  // Do a BFS to find the shortest path\n  int next_node = source;\n  while (next_node!= -1) {\n    for (int i = 0; i < N; i++) {\n      if (A[next_node * N + i] == 1 && visited[i] == 0) {\n        dis[i] = dis[next_node] + 1;\n        path[i] = next_node;\n        if (i == dest) {\n          next_node = -1;\n          break;\n        } else {\n          next_node = i;\n        }\n      }\n    }\n    visited[next_node] = 1;\n  }\n\n  // Now, walk the path to find the path length\n  int curr_node = dest;\n  int path_length = 0;\n  while (path[curr_node]!= -1) {\n    path_length++;\n    curr_node = path[curr_node];\n  }\n\n  return path_length;\n}",
            "std::vector<int> V = std::vector<int>(N,0);\n    std::vector<int> S = std::vector<int>(N,0);\n    int dist = 0;\n    int max_dist = 0;\n\n    // for each row\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++)\n    {\n        if (i!= source)\n        {\n            // for each column\n            for (int j = 0; j < N; j++)\n            {\n                if (A[i*N+j] == 1)\n                {\n                    // V[i] = max(V[i], V[j] + 1);\n                    if (V[j] + 1 > V[i])\n                        V[i] = V[j] + 1;\n                }\n            }\n        }\n    }\n\n    // for each row\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++)\n    {\n        if (i!= source)\n        {\n            // for each column\n            for (int j = 0; j < N; j++)\n            {\n                if (A[i*N+j] == 1)\n                {\n                    // S[i] = max(S[i], S[j] + 1);\n                    if (S[j] + 1 > S[i])\n                        S[i] = S[j] + 1;\n                }\n            }\n        }\n    }\n\n    dist = V[dest];\n    max_dist = S[dest];\n\n    return dist;\n}",
            "const int INF = INT_MAX;\n    std::vector<int> d(N, INF);\n    std::vector<int> pi(N);\n    d[source] = 0;\n    bool update = true;\n    while (update) {\n        update = false;\n        #pragma omp parallel for\n        for (size_t i = 0; i < N; ++i) {\n            for (size_t j = 0; j < N; ++j) {\n                if (A[N*i + j] == 0)\n                    continue;\n                int alt = d[i] + A[N*i + j];\n                #pragma omp critical\n                if (alt < d[j]) {\n                    d[j] = alt;\n                    pi[j] = i;\n                    update = true;\n                }\n            }\n        }\n    }\n    return d[dest];\n}",
            "int path_length = 1;\n\tstd::vector<int> distance = A;\n\tstd::vector<int> count = std::vector<int>(N, 0);\n\tstd::vector<int> Q = std::vector<int>(N, -1);\n\n\tQ[0] = source;\n\n\tcount[source] = 1;\n\tdistance[source] = 0;\n\n\t// std::cout << \"Q: \" << Q << std::endl;\n\n\tint j, k, min;\n\n\twhile (true) {\n\n\t\tmin = distance[Q[0]] + 1;\n\n\t\tfor (k = 0; k < N; k++) {\n\t\t\tif (distance[Q[k]] >= min) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (distance[Q[0]] < min) {\n\t\t\tbreak;\n\t\t}\n\n\t\tj = k;\n\n\t\tmin = distance[Q[j]] + 1;\n\n\t\tfor (k = j + 1; k < N; k++) {\n\t\t\tif (distance[Q[k]] < min && count[Q[k]] == 0) {\n\t\t\t\tj = k;\n\t\t\t\tmin = distance[Q[j]];\n\t\t\t}\n\t\t}\n\n\t\tfor (k = 0; k < N; k++) {\n\t\t\tif (A[Q[j] * N + k]!= 0 && count[k] == 0 && distance[k] > distance[Q[j]] + A[Q[j] * N + k]) {\n\t\t\t\tdistance[k] = distance[Q[j]] + A[Q[j] * N + k];\n\t\t\t\tQ[k] = Q[j];\n\t\t\t}\n\t\t}\n\n\t\tcount[Q[j]] = 1;\n\t\tpath_length++;\n\t\tQ[j] = -1;\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> D(N, INT_MAX);\n  std::vector<bool> seen(N, false);\n\n  #pragma omp parallel\n  {\n    #pragma omp for schedule(dynamic, 1) nowait\n    for (size_t i = 0; i < N; i++) {\n      if (i == source) {\n        D[i] = 0;\n        seen[i] = true;\n      }\n    }\n\n    #pragma omp for schedule(dynamic, 1)\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (A[i * N + j] == 1) {\n          if (!seen[j]) {\n            continue;\n          }\n          if (D[j] + 1 < D[i]) {\n            D[i] = D[j] + 1;\n          }\n        }\n      }\n    }\n  }\n  return D[dest];\n}",
            "int length = 0;\n    #pragma omp parallel\n    {\n    \t#pragma omp single\n        {\n        \t// TODO: your code here\n\n        }\n    }\n\n    return length;\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (dist[j] < INT_MAX && A[N*j + i]) {\n                dist[i] = std::min(dist[i], dist[j] + 1);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tint min_dist = dist[i];\n\t\tint argmin_dist = i;\n\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (dist[j] < min_dist && A[i * N + j]!= 0) {\n\t\t\t\tmin_dist = dist[j];\n\t\t\t\targmin_dist = j;\n\t\t\t}\n\t\t}\n\n\t\tif (min_dist == INT_MAX)\n\t\t\tbreak;\n\n\t\t++min_dist;\n\n\t\t#pragma omp parallel for\n\t\tfor (int j = 0; j < N; ++j)\n\t\t\tdist[j] = A[argmin_dist * N + j]!= 0? std::min(dist[j], min_dist) : -1;\n\t}\n\n\treturn dist[dest] == -1? -1 : dist[dest];\n}",
            "int dist[N];\n\tint queue[N];\n\tint tail = 0;\n\tint head = 0;\n\tint* distp = dist;\n\tfor (size_t i = 0; i < N; i++) {\n\t\tdist[i] = INT_MAX;\n\t\tqueue[i] = i;\n\t}\n\tdist[source] = 0;\n\n\twhile (tail!= head) {\n\t\tint u = queue[tail];\n\t\ttail++;\n\t\t#pragma omp parallel for\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[N*u + i]) {\n\t\t\t\tint alt = dist[u] + 1;\n\t\t\t\tif (alt < dist[i]) {\n\t\t\t\t\tdist[i] = alt;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "int ret = INT_MAX;\n\tstd::vector<int> dist(N, INT_MAX);\n\tstd::vector<bool> vis(N, false);\n\tstd::vector<int> next(N);\n\t\n\t// TODO: fill this in\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor (size_t i=0; i<N; i++) {\n\t\t\tif (A[i*N + source]!= 0) {\n\t\t\t\tdist[i] = 1;\n\t\t\t\tnext[i] = source;\n\t\t\t}\n\t\t}\n\t\t\n\t\t#pragma omp for\n\t\tfor (int k=0; k<N-1; k++) {\n\t\t\tfor (size_t i=0; i<N; i++) {\n\t\t\t\tif (A[i*N + k]!= 0) {\n\t\t\t\t\tfor (size_t j=0; j<N; j++) {\n\t\t\t\t\t\tif (A[k*N + j]!= 0) {\n\t\t\t\t\t\t\tif (dist[i] + 1 < dist[j]) {\n\t\t\t\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t\t\t\t\tnext[j] = next[i];\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp for\n\t\tfor (size_t i=0; i<N; i++) {\n\t\t\tif (next[i]!= -1 && dist[i]!= INT_MAX) {\n\t\t\t\tvis[i] = true;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp single\n\t\t{\n\t\t\tint min = INT_MAX;\n\t\t\tint cur_next = dest;\n\t\t\tfor (size_t i=0; i<N; i++) {\n\t\t\t\tif (vis[i]) {\n\t\t\t\t\tif (min > dist[i]) {\n\t\t\t\t\t\tmin = dist[i];\n\t\t\t\t\t\tcur_next = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tret = min;\n\t\t\tdest = cur_next;\n\t\t}\n\t}\n\n\treturn ret;\n}",
            "/* TODO: Implement me! */\n\tint *visited = new int[N];\n\tint *dist = new int[N];\n\tint *path = new int[N];\n\tint *parent = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tdist[i] = -1;\n\t\tpath[i] = -1;\n\t\tparent[i] = -1;\n\t}\n\n\tint shortestPathLength = -1;\n\n\t// BFS\n\tstd::queue<int> q;\n\tq.push(source);\n\tvisited[source] = 1;\n\tdist[source] = 0;\n\tpath[source] = source;\n\tparent[source] = -1;\n\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[v*N+i]!= 0 && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tq.push(i);\n\t\t\t\tdist[i] = dist[v] + 1;\n\t\t\t\tpath[i] = v;\n\t\t\t\tparent[i] = v;\n\t\t\t}\n\t\t}\n\t}\n\n\t// find the shortest path\n\tif (path[dest]!= -1) {\n\t\tshortestPathLength = 0;\n\t\tint current = dest;\n\t\twhile (current!= -1) {\n\t\t\tshortestPathLength++;\n\t\t\tcurrent = parent[current];\n\t\t}\n\t}\n\n\tdelete[] visited;\n\tdelete[] dist;\n\tdelete[] path;\n\tdelete[] parent;\n\treturn shortestPathLength;\n}",
            "std::vector<int> shortest_path_lengths(N, -1);\n  // Use shortest_path_lengths as a queue of vertices to check\n  std::queue<int> que;\n  std::vector<int> que_lengths(N, -1);\n  shortest_path_lengths[source] = 0;\n  que.push(source);\n  que_lengths[source] = 0;\n\n  while (!que.empty()) {\n    int s = que.front();\n    que.pop();\n    que_lengths[s] = -1;\n\n#pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n      if (shortest_path_lengths[i] == -1 && A[N * s + i]) {\n        // Add the new vertex to the queue\n        shortest_path_lengths[i] = shortest_path_lengths[s] + 1;\n        que.push(i);\n        que_lengths[i] = shortest_path_lengths[i];\n      }\n    }\n  }\n\n  return shortest_path_lengths[dest];\n}",
            "/* YOUR CODE HERE */\n}",
            "const int BLOCK_SIZE = 256;\n\tint thread_count = omp_get_max_threads();\n\tint local_lengths[thread_count];\n\n\t#pragma omp parallel shared(local_lengths)\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\tint source_thread = source / BLOCK_SIZE;\n\t\tint start_index = BLOCK_SIZE * tid;\n\t\tint end_index = std::min(BLOCK_SIZE * (tid+1), N);\n\n\t\tstd::vector<int> visited(N, false);\n\t\tstd::vector<int> prev(N);\n\t\tstd::queue<int> q;\n\t\tstd::vector<int> cur(N);\n\n\t\tvisited[start_index] = true;\n\t\tfor (int i = start_index; i < end_index; ++i) {\n\t\t\tif (i == source && i!= dest) {\n\t\t\t\tq.push(source);\n\t\t\t\tcur[source] = -1;\n\t\t\t} else if (i == dest) {\n\t\t\t\tvisited[dest] = true;\n\t\t\t\tcur[dest] = -1;\n\t\t\t\tq.push(dest);\n\t\t\t\tlocal_lengths[tid] = 0;\n\t\t\t\tbreak;\n\t\t\t} else {\n\t\t\t\tint count = 0;\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[i * N + j]) {\n\t\t\t\t\t\tcur[j] = i;\n\t\t\t\t\t\t++count;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (count == 1) {\n\t\t\t\t\tq.push(i);\n\t\t\t\t\tprev[i] = cur[i];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\twhile (!q.empty()) {\n\t\t\tint cur_node = q.front(); q.pop();\n\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (A[cur_node * N + i] &&!visited[i]) {\n\t\t\t\t\tvisited[i] = true;\n\t\t\t\t\tq.push(i);\n\t\t\t\t\tcur[i] = cur_node;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (i == dest) {\n\t\t\t\tlocal_lengths[tid] = 0;\n\t\t\t\twhile (cur_node!= source) {\n\t\t\t\t\t++local_lengths[tid];\n\t\t\t\t\tcur_node = prev[cur_node];\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tint lengths[thread_count];\n\t#pragma omp parallel for schedule(static)\n\tfor (int i = 0; i < thread_count; ++i) {\n\t\tlengths[i] = local_lengths[i];\n\t}\n\tint min_length = INT_MAX;\n\tfor (int i = 0; i < thread_count; ++i) {\n\t\tmin_length = std::min(min_length, lengths[i]);\n\t}\n\treturn min_length;\n}",
            "int minPath = INT_MAX;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        std::vector<int> distances(N);\n        distances[i] = 1;\n\n        bool changed = true;\n        while (changed) {\n            changed = false;\n\n            for (int j = 0; j < N; ++j) {\n                for (int k = 0; k < N; ++k) {\n                    if (distances[j]!= INT_MAX && A[j*N + k]!= 0 && distances[j] + A[j*N + k] < distances[k]) {\n                        distances[k] = distances[j] + A[j*N + k];\n                        changed = true;\n                    }\n                }\n            }\n        }\n\n        if (distances[dest] < minPath) {\n            minPath = distances[dest];\n        }\n    }\n\n    return minPath;\n}",
            "// Your code here!\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      A[i * N + j] = std::min(A[i * N + j], A[i * N + source] + A[source * N + j]);\n    }\n  }\n  return A[dest * N + source];\n}",
            "// BEGIN_YOUR_CODE (Modify the code to implement shortestPathLength)\n\t// The code inside BEGIN_YOUR_CODE... END_YOUR_CODE will be replaced by the grading script\n\t// You can add additional functions if you need\n\n\t\n\tint* dp=new int[N];\n\tint* visited=new int[N];\n\n\tint* min_dp=new int[N];\n\tint* min_visited=new int[N];\n\n\tint** queue=new int*[N];\n\tfor(int i=0;i<N;i++)\n\t\tqueue[i]=new int[N];\n\n\tint* front=new int[N];\n\tint* rear=new int[N];\n\t\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tdp[i]=-1;\n\t\tvisited[i]=0;\n\t}\n\n\tdp[source]=0;\n\tvisited[source]=1;\n\tint num=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tif(A[source*N+i]==1&&visited[i]==0)\n\t\t{\n\t\t\tqueue[num][0]=source;\n\t\t\tqueue[num][1]=i;\n\t\t\tnum++;\n\t\t}\n\t}\n\trear[source]=num-1;\n\tfront[source]=0;\n\tfor(int i=0;i<num;i++)\n\t{\n\t\tint u=queue[source][i];\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A[u*N+j]==1&&visited[j]==0)\n\t\t\t{\n\t\t\t\tqueue[source][rear[source]][1]=j;\n\t\t\t\trear[source]++;\n\t\t\t}\n\t\t}\n\t}\n\n\t\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tmin_dp[i]=-1;\n\t\tmin_visited[i]=0;\n\t}\n\tmin_dp[source]=0;\n\tmin_visited[source]=1;\n\tint num1=0;\n\tfor(int i=0;i<N;i++)\n\t{\n\t\tif(A[source*N+i]==1&&visited[i]==0)\n\t\t{\n\t\t\tqueue[num1][0]=source;\n\t\t\tqueue[num1][1]=i;\n\t\t\tnum1++;\n\t\t}\n\t}\n\trear[source]=num1-1;\n\tfront[source]=0;\n\tfor(int i=0;i<num1;i++)\n\t{\n\t\tint u=queue[source][i];\n\t\tfor(int j=0;j<N;j++)\n\t\t{\n\t\t\tif(A[u*N+j]==1&&visited[j]==0)\n\t\t\t{\n\t\t\t\tqueue[source][rear[source]][1]=j;\n\t\t\t\trear[source]++;\n\t\t\t}\n\t\t}\n\t}\n\t\n\twhile(rear[source]!=-1)\n\t{\n\t\tint num2=0;\n\t\tfor(int i=front[source];i<=rear[source];i++)\n\t\t{\n\t\t\tint v=queue[source][i][1];\n\t\t\tif(dp[v]==-1)\n\t\t\t{\n\t\t\t\tdp[v]=dp[queue[source][i][0]]+1;\n\t\t\t\tqueue[source][num2][0]=queue[source][i][0];\n\t\t\t\tqueue[source][num2][1]=v;\n\t\t\t\tnum2++;\n\t\t\t}\n\t\t}\n\t\trear[source]=num2-1;\n\t\tfront[source]=0;\n\t\tfor(int i=0;i<num2;i++)\n\t\t{\n\t\t\tint u=queue[source][i][1];\n\t\t\tfor(int j=0;j<N;j++)\n\t\t\t{",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\n\t#pragma omp parallel for\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] && dist[i]!= INT_MAX && dist[i] + 1 < dist[j])\n\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] == INT_MAX)\n\t\treturn -1;\n\telse\n\t\treturn dist[dest];\n}",
            "std::vector<int> dist(N, INF);\n    std::vector<bool> seen(N, false);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        if (u == dest) {\n            return dist[u];\n        }\n        for (int v = 0; v < N; v++) {\n            if (!seen[v] && A[u*N + v]) {\n                q.push(v);\n                dist[v] = dist[u] + 1;\n                seen[v] = true;\n            }\n        }\n    }\n    return dist[dest];\n}",
            "// TODO: Replace the code below with your code\n  auto const& A_ = A;\n  size_t const& N_ = N;\n  int const& source_ = source;\n  int const& dest_ = dest;\n  auto visited = std::vector<int>(N_, 0);\n  auto distance = std::vector<int>(N_, INT_MAX);\n  distance[source_] = 0;\n  auto previous = std::vector<int>(N_, -1);\n\n  #pragma omp parallel for schedule(guided)\n  for (size_t v = 0; v < N_; ++v) {\n    for (size_t w = 0; w < N_; ++w) {\n      if (A_[v*N_+w] && visited[v] &&!visited[w]) {\n        visited[w] = 1;\n        distance[w] = distance[v]+1;\n        previous[w] = v;\n      }\n    }\n  }\n\n  for (size_t v = 0; v < N_; ++v) {\n    if (v == dest_) {\n      return distance[v];\n    }\n  }\n\n  int result = INT_MAX;\n  for (size_t v = 0; v < N_; ++v) {\n    if (previous[dest_] == v) {\n      result = distance[dest_] - 1;\n    }\n  }\n\n  return result;\n}",
            "// Fill this in\n    return 0;\n}",
            "// Use BFS to find the length of the shortest path.\n  // Hint: you may find std::queue useful.\n\n  if(source==dest) return 0;\n\n  std::queue<std::tuple<int,int,int>> q;\n  std::vector<std::vector<int>> dist(N,std::vector<int>(N,INT_MAX));\n\n  q.push({source,0,INT_MAX});\n\n  while(!q.empty())\n  {\n    auto [i,d,p] = q.front(); q.pop();\n    if(d==INT_MAX) continue;\n    if(i==dest) return d;\n\n    for(auto j=0;j<N;++j)\n    {\n      if(A[i*N+j] && (p==INT_MAX || d+1<dist[j][i]))\n      {\n        dist[j][i] = d+1;\n        q.push({j,d+1,i});\n      }\n    }\n  }\n\n  return -1;\n}",
            "// TODO: YOUR CODE HERE\n\t// hint: use Dijkstra's algorithm, and don't forget to parallelize!\n    int dist[N];\n    bool visited[N];\n    for(int i = 0; i < N; i++)\n    {\n        dist[i] = INT_MAX;\n        visited[i] = false;\n    }\n    std::vector<int> stack;\n    dist[source] = 0;\n    stack.push_back(source);\n    while(stack.size() > 0)\n    {\n        int x = stack.back();\n        stack.pop_back();\n        if(visited[x])\n        {\n            continue;\n        }\n        visited[x] = true;\n        for(int i = 0; i < N; i++)\n        {\n            if(A[N * x + i] == 1 && dist[i] > dist[x] + 1)\n            {\n                dist[i] = dist[x] + 1;\n                if(i == dest)\n                {\n                    return dist[dest];\n                }\n                stack.push_back(i);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "std::vector<int> Q{source};\n    std::vector<int> V{source};\n    std::vector<int> D{0};\n\n    while (!Q.empty()) {\n        // Dequeue a vertex from Q\n        int u = Q.back();\n        Q.pop_back();\n\n        // Explore neighbors of u\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] == 1 && std::find(V.begin(), V.end(), v) == V.end()) {\n                // Enqueue v and set D(v) to D(u) + 1\n                Q.push_back(v);\n                V.push_back(v);\n                D.push_back(D[u] + 1);\n                // Break if found a path from source to dest\n                if (v == dest)\n                    return D[v];\n            }\n        }\n    }\n\n    // No path exists\n    return -1;\n}",
            "int shortestLength = 0;\n\n  // TODO\n\n  return shortestLength;\n}",
            "// TODO: FILL THIS IN\n\tstd::vector<int> d(N, -1);\n\n\tint *d_ptr = &d[0];\n\n\t// TODO: FILL THIS IN\n\n\treturn -1;\n}",
            "std::vector<int> dist(N, INT_MAX);\n\n  #pragma omp parallel for shared(dist)\n  for (size_t i = 0; i < N; ++i) {\n    dist[i] = i == source? 0 : INT_MAX;\n  }\n\n  std::vector<bool> visited(N, false);\n  std::queue<int> q;\n  q.push(source);\n  visited[source] = true;\n\n  while (not q.empty()) {\n    auto x = q.front();\n    q.pop();\n\n    for (size_t i = 0; i < N; ++i) {\n      if (A[x*N+i] and not visited[i]) {\n        visited[i] = true;\n        dist[i] = dist[x]+1;\n        q.push(i);\n      }\n    }\n  }\n  return dist[dest];\n}",
            "int length = 0;\n    std::vector<bool> visited(N, false);\n\n    #pragma omp parallel num_threads(4)\n    {\n        int length_private = 0;\n        #pragma omp for nowait\n        for (int i = 0; i < N; i++) {\n            int length_temp = 0;\n            std::vector<int> stack;\n            stack.push_back(i);\n            visited[i] = true;\n            while (!stack.empty()) {\n                int index = stack.back();\n                stack.pop_back();\n                length_temp++;\n                if (index == dest) {\n                    break;\n                }\n                for (int j = 0; j < N; j++) {\n                    if (A[index * N + j] &&!visited[j]) {\n                        stack.push_back(j);\n                        visited[j] = true;\n                    }\n                }\n            }\n            if (length_temp > length_private) {\n                length_private = length_temp;\n            }\n        }\n        #pragma omp critical\n        {\n            if (length_private > length) {\n                length = length_private;\n            }\n        }\n    }\n\n    return length;\n}",
            "// TODO: YOUR CODE HERE\n}",
            "/*\n\t\t\t[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]\n\t\t\t1 2 3 4\n\t\t\t0 [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]\n\t\t\t2 [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]\n\t\t\t3 [1, 0, 0, 1], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]\n\t\t\t4 [0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]\n\t\t\t5 [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]\n\t\t\t6 [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]\n\t\t\t7 [0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [1, 1, 1, 0]\n\t\t\t8 [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]\n\n\t*/\n\n\t// your code here\n\n\n\tint *result = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tresult[i] = 0;\n\t}\n\t//for (int i = 0; i < N; i++) {\n\t//\tfor (int j = 0; j < N; j++) {\n\t//\t\tcout << A[i * N + j] << \" \";\n\t//\t}\n\t//\tcout << endl;\n\t//}\n\t//cout << endl;\n\t//cout << \"Source: \" << source << endl;\n\t//cout << \"Dest: \" << dest << endl;\n\tint length = 0;\n\n\n\tint *visited = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\t//visited[0] = 1;\n\t//#pragma omp parallel num_threads(N)\n\t//{\n\t//\tint i = omp_get_thread_num();\n\t//\tvisited[i] = 1;\n\t//}\n\n\t//cout << \"Visited: \" << visited[0] << endl;\n\t//#pragma omp parallel for\n\t//for (int i = 0; i < N; i++) {\n\t//\tvisited[i] = 1;\n\t//}\n\n\tint *queue = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tqueue[i] = 0;\n\t}\n\tint queue_start = 0;\n\tint queue_end = 0;\n\tqueue[queue_end] = source;\n\tqueue_end++;\n\tvisited[source] = 1;\n\tint index = 0;\n\tint temp_index = 0;\n\tint temp_index_2 = 0;\n\tint next_source = 0;\n\tint next_source_2 = 0;\n\tint next_source_3 = 0;\n\twhile (index < N) {\n\t\tlength++;\n\t\t//cout << \"L: \" << length << endl;\n\t\ttemp_index = queue",
            "// TODO: replace this with your solution\n    int dist[N];\n    int prev[N];\n    for(int i = 0; i < N; ++i){\n        dist[i] = A[source * N + i];\n        prev[i] = -1;\n    }\n    dist[source] = 0;\n\n    bool changed = true;\n    while(changed){\n        changed = false;\n        #pragma omp parallel for\n        for(int k = 0; k < N; ++k){\n            #pragma omp parallel for\n            for(int j = 0; j < N; ++j){\n                if(A[k * N + j]!= 0){\n                    for(int i = 0; i < N; ++i){\n                        if(dist[i]!= -1 && dist[k]!= -1 && dist[i] + A[i * N + k] > dist[k] + A[k * N + j]){\n                            changed = true;\n                            dist[i] = dist[k] + A[i * N + k];\n                            prev[i] = k;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    return dist[dest];\n}",
            "if (source == dest)\n    return 0;\n  int *dist = new int[N];\n  for(int i = 0; i < N; i++) {\n    dist[i] = INT_MAX;\n  }\n  dist[source] = 0;\n  #pragma omp parallel\n  {\n    #pragma omp for\n    for(int i = 0; i < N; i++) {\n      for(int j = 0; j < N; j++) {\n        if (A[i*N + j] == 1) {\n          if (dist[i]!= INT_MAX && dist[i]+1 < dist[j]) {\n            dist[j] = dist[i] + 1;\n          }\n        }\n      }\n    }\n  }\n  int answer = dist[dest];\n  if (answer == INT_MAX) {\n    answer = -1;\n  }\n  return answer;\n}",
            "int pathLength = INT_MAX;\n\tint dist[N];\n\tbool visited[N];\n\tint pq[N];\n\tint n = 0;\n\tint p = 0;\n\n#pragma omp parallel\n\t{\n#pragma omp single\n\t\t{\n\t\t\t// Set all vertices as not visited\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tvisited[i] = false;\n\t\t\t\tdist[i] = INT_MAX;\n\t\t\t\tpq[i] = i;\n\t\t\t}\n\t\t\t// Set distance to source to 0\n\t\t\tdist[source] = 0;\n\t\t\t// Insert source into pq\n\t\t\tn++;\n\t\t\tpq[n] = source;\n\t\t\t\n\t\t}\n#pragma omp for nowait\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (pq[i]!= source) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// Iterate over vertices adjacent to vertex at pq[p]\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t// If an edge exists and the vertex is not yet visited\n\t\t\t\tif (A[pq[i] * N + j] &&!visited[j]) {\n\t\t\t\t\t// Set distance to adjacent vertex + 1\n\t\t\t\t\tdist[j] = dist[pq[i]] + 1;\n\t\t\t\t\t// Mark the vertex as visited and insert into the pq\n\t\t\t\t\tvisited[j] = true;\n\t\t\t\t\tpq[++n] = j;\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Remove the vertex at pq[p] since it has been processed\n\t\t\tpq[p] = pq[n];\n\t\t\tn--;\n\t\t\t// Swap p and p+1 in the pq if necessary\n\t\t\tif (p < n && dist[pq[p + 1]] < dist[pq[p]]) {\n\t\t\t\tp++;\n\t\t\t}\n\t\t}\n\t}\n\tif (visited[dest]) {\n\t\tpathLength = dist[dest];\n\t}\n\treturn pathLength;\n}",
            "std::vector<int> prev(N);\n    std::vector<int> dist(N);\n\n    for (int i = 0; i < N; ++i) {\n        dist[i] = A[source * N + i];\n    }\n\n    dist[source] = 0;\n    bool changed = true;\n\n    while (changed) {\n        changed = false;\n\n#pragma omp parallel for ordered\n        for (int i = 0; i < N; ++i) {\n            if (dist[i] == -1) continue;\n\n            int min = -1;\n#pragma omp ordered\n            for (int j = 0; j < N; ++j) {\n                if (dist[j] > -1 && (min == -1 || dist[j] < min)) {\n                    min = dist[j];\n                    prev[i] = j;\n                }\n            }\n            if (min == -1) {\n                dist[i] = -1;\n            } else {\n                dist[i] = min + 1;\n                changed = true;\n            }\n        }\n    }\n\n    int res = -1;\n    if (dist[dest] > 0) {\n        int curr = dest;\n        while (curr!= source) {\n            res = res + 1;\n            curr = prev[curr];\n        }\n    }\n    return res;\n}",
            "if (source >= N) throw std::out_of_range(\"Invalid source vertex\");\n\tif (dest >= N) throw std::out_of_range(\"Invalid destination vertex\");\n\n\tstd::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n\tstd::vector<int> Q(N);\n\tint front = 0, rear = 0;\n\tQ[rear++] = source;\n\n\twhile (front < rear) {\n\t\tint u = Q[front++];\n\n\t\t#pragma omp parallel for\n\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v]!= 0 && dist[v] == -1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tQ[rear++] = v;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] == -1) return -1;\n\telse return dist[dest];\n}",
            "// write your code here\n  int* d = new int[N];\n  for (int i = 0; i < N; ++i){\n    d[i] = 0;\n  }\n  d[source] = 1;\n  for (int i = 0; i < N; ++i){\n    bool flag = true;\n    for (int j = 0; j < N; ++j){\n      if (A[i*N + j] == 1 && d[j] == 0){\n        d[j] = d[i] + 1;\n      }\n      if (d[j] > d[i] && A[i*N + j] == 1 && d[j] == d[i] + 1){\n        flag = false;\n      }\n    }\n    if (flag == true){\n      break;\n    }\n  }\n  int shortest = d[dest];\n  delete[] d;\n  return shortest;\n}",
            "/*\n\t\tDONE: Your code here\n\t\t\tImplement a shortest path algorithm\n\t*/\n\tstd::vector<int> dist(N, std::numeric_limits<int>::max());\n\tstd::vector<int> prev(N, -1);\n\tstd::vector<int> visited(N, 0);\n\n\t#pragma omp parallel for\n\tfor (size_t u = 0; u < N; u++) {\n\t\t#pragma omp atomic read\n\t\tint uw = A[source * N + u];\n\t\tif (uw!= 0) {\n\t\t\t#pragma omp atomic write\n\t\t\tdist[u] = uw;\n\t\t\t#pragma omp atomic write\n\t\t\tprev[u] = source;\n\t\t}\n\t}\n\n\tint found = 0;\n\twhile (found == 0) {\n\t\tint current = -1;\n\t\tint min_d = std::numeric_limits<int>::max();\n\t\tfor (size_t u = 0; u < N; u++) {\n\t\t\tif (visited[u] == 0) {\n\t\t\t\tif (dist[u] < min_d) {\n\t\t\t\t\tmin_d = dist[u];\n\t\t\t\t\tcurrent = u;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (current == -1) {\n\t\t\tbreak;\n\t\t}\n\t\t#pragma omp atomic write\n\t\tvisited[current] = 1;\n\n\t\t#pragma omp parallel for\n\t\tfor (size_t u = 0; u < N; u++) {\n\t\t\t#pragma omp atomic read\n\t\t\tint uw = A[current * N + u];\n\t\t\tif (uw!= 0) {\n\t\t\t\tint alt = dist[current] + uw;\n\t\t\t\tint old_alt = dist[u];\n\n\t\t\t\t#pragma omp atomic write\n\t\t\t\tdist[u] = alt;\n\n\t\t\t\tif (alt < old_alt) {\n\t\t\t\t\t#pragma omp atomic write\n\t\t\t\t\tprev[u] = current;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> path;\n\tint p = dest;\n\twhile (p!= source) {\n\t\tpath.push_back(p);\n\t\tp = prev[p];\n\t}\n\tpath.push_back(source);\n\n\tstd::reverse(path.begin(), path.end());\n\treturn path.size() - 1;\n}",
            "// Initialize the distance vector\n\t// Use the length of A as the number of vertices\n\t// Use the value of A[0][0] as the starting distance\n\t// Use INFINITY (defined in <limits>) as a default value\n\t// Use std::vector<>::assign to set the entire vector to a single value\n\t\n\n\t// TODO: Implement Dijkstra's algorithm using the distance vector\n\t// - Implement the relaxation step:\n\t//   - Iterate through all adjacent vertices\n\t//   - If distance[v] > distance[u] + A[u][v]\n\t//     - distance[v] = distance[u] + A[u][v]\n\n\n\t// Return the distance from the source to the destination\n\treturn distance[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\t#pragma omp parallel\n\t#pragma omp single\n\twhile (true) {\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (dist[v] == -1) continue;\n\t\t\tfor (int w = 0; w < N; w++) {\n\t\t\t\tif (A[v*N + w]!= 0 && dist[w] == -1) {\n\t\t\t\t\tdist[w] = dist[v] + 1;\n\t\t\t\t\t#pragma omp flush(dist)\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp barrier\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (dist[v] == -1) continue;\n\t\t\tfor (int w = 0; w < N; w++) {\n\t\t\t\tif (A[v*N + w]!= 0 && dist[w] > dist[v] + 1) {\n\t\t\t\t\tdist[w] = dist[v] + 1;\n\t\t\t\t\t#pragma omp flush(dist)\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp barrier\n\t\t#pragma omp single\n\t\t{\n\t\t\tint flag = 0;\n\t\t\tfor (int v = 0; v < N; v++) {\n\t\t\t\tif (dist[v] == -1) {\n\t\t\t\t\tflag = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (flag) {\n\t\t\t\t#pragma omp flush(dist)\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\t}\n\treturn dist[dest];\n}",
            "if (source == dest) return 0;\n    if (A[source * N + dest] == 0) return -1;\n\n    // Your code here\n    int dist[N];\n    int visited[N];\n\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n        dist[i] = 0;\n    }\n\n    int curr_dist = 0;\n\n    #pragma omp parallel for num_threads(8)\n    for (int i = 0; i < N; i++) {\n        if (i == source) {\n            dist[i] = 0;\n            visited[i] = 1;\n            curr_dist = 1;\n        }\n        else {\n            dist[i] = INT_MAX;\n        }\n    }\n\n    while (curr_dist < N) {\n        #pragma omp parallel for num_threads(8)\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[i * N + j] &&!visited[j] && dist[i] + 1 < dist[j]) {\n                    dist[j] = dist[i] + 1;\n                }\n            }\n        }\n\n        #pragma omp parallel for num_threads(8)\n        for (int i = 0; i < N; i++) {\n            if (dist[i] == curr_dist) {\n                visited[i] = 1;\n            }\n        }\n        curr_dist++;\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n  std::vector<bool> seen(N, false);\n  std::vector<bool> unseen(N, true);\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n  seen[source] = true;\n\n  while (!q.empty()) {\n    int curr_node = q.front();\n    q.pop();\n    unseen[curr_node] = false;\n\n#pragma omp parallel for schedule(dynamic, 1)\n    for (int i = 0; i < N; i++) {\n      if (!seen[i] && A[curr_node * N + i]) {\n        q.push(i);\n        dist[i] = dist[curr_node] + 1;\n        seen[i] = true;\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "int* dist = new int[N];\n\tint* parent = new int[N];\n\tfor(int i=0;i<N;i++) {\n\t\tdist[i] = INT_MAX;\n\t\tparent[i] = -1;\n\t}\n\tdist[source] = 0;\n\t\n\tbool* visited = new bool[N];\n\tfor(int i=0;i<N;i++) {\n\t\tvisited[i] = false;\n\t}\n\t\n\tint count = 0;\n\t#pragma omp parallel for reduction(+:count)\n\tfor(int i=0;i<N;i++) {\n\t\tif(i!= source) {\n\t\t\tfor(int j=0;j<N;j++) {\n\t\t\t\tif(A[i*N+j] == 1 && dist[i]!= INT_MAX && dist[i] + 1 < dist[j]) {\n\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t\tparent[j] = i;\n\t\t\t\t\tif(j == dest) {\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint pathLength = INT_MAX;\n\tfor(int i=0;i<N;i++) {\n\t\tif(dest == i) {\n\t\t\tpathLength = dist[dest];\n\t\t}\n\t}\n\t\n\treturn pathLength;\n}",
            "if (source < 0 || source >= N || dest < 0 || dest >= N) {\n\t\treturn -1;\n\t}\n\tstd::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\twhile (!queue.empty()) {\n\t\tint u = queue.front();\n\t\tqueue.pop();\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[N*u + i] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (dist[i] == -1) {\n\t\t\t\tdist[i] = dist[u] + 1;\n\t\t\t\tqueue.push(i);\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "//std::vector<std::vector<int>> q(N, std::vector<int>(N, -1));\n\tstd::vector<int> q(N * N, -1);\n\n\tq[source] = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (int k = 0; k < N * N; k++) {\n\t\t\tif (q[k] == -1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[k * N + i] == 0) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint const distance = q[k] + 1;\n\t\t\t\t#pragma omp critical\n\t\t\t\tif (q[i] == -1 || q[i] > distance) {\n\t\t\t\t\tq[i] = distance;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn q[dest];\n}",
            "int length = 0;\n\n#pragma omp parallel\n  {\n    // declare and initialize a local variable 'length'\n    int lengthLocal = 0;\n\n    // do parallel work here...\n    if (omp_get_thread_num() == 0) {\n      // do work with thread 0 here...\n    }\n\n    // critical section, only one thread at a time can run this\n    // section at a time, but all threads can read and write to lengthLocal\n#pragma omp critical\n    {\n      lengthLocal = 0;\n    }\n\n    // update the global length value\n#pragma omp atomic\n    length++;\n  }\n\n  return length;\n}",
            "#pragma omp parallel num_threads(3)\n  {\n      std::vector<int> dist(N, -1);\n      dist[source] = 0;\n\n      #pragma omp for schedule(dynamic, 1)\n      for (int i=0; i<N; ++i) {\n          if (dist[i] == -1)\n              continue;\n          for (int j=0; j<N; ++j) {\n              if (dist[j] == -1 && A[i*N + j]) {\n                  #pragma omp critical\n                  {\n                      dist[j] = dist[i] + 1;\n                  }\n              }\n          }\n      }\n  }\n}",
            "// Add your code here.\n\n\n}",
            "std::vector<int> distances(N, INT_MAX);\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> parent(N, -1);\n\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\tdistances[source] = 0;\n\tvisited[source] = true;\n\n\twhile (not queue.empty()) {\n\t\tint u = queue.front();\n\t\tqueue.pop();\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v]) {\n\t\t\t\tif (visited[v]) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tqueue.push(v);\n\t\t\t\tdistances[v] = distances[u] + 1;\n\t\t\t\tvisited[v] = true;\n\t\t\t\tparent[v] = u;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (distances[dest] == INT_MAX) {\n\t\treturn -1;\n\t}\n\n\treturn distances[dest];\n}",
            "// initialize\n\t\tstd::vector<int> distance(N, std::numeric_limits<int>::max());\n\t\tdistance[source] = 0;\n\n\t\t// loop until no changes to distance array\n\t\twhile (true) {\n\t\t\tbool change = false;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i*N + j] && distance[j]!= std::numeric_limits<int>::max()) {\n\t\t\t\t\t\tif (distance[i] > distance[j] + 1) {\n\t\t\t\t\t\t\tdistance[i] = distance[j] + 1;\n\t\t\t\t\t\t\tchange = true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!change) break;\n\t\t}\n\n\t\treturn distance[dest];\n}",
            "// TODO: implement this\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tstd::vector<int> q;\n\tq.push_back(source);\n\tint index = 0;\n\twhile (index < q.size()) {\n\t\tint u = q[index];\n\t\tindex++;\n\t\tif (u == dest) {\n\t\t\treturn dist[u];\n\t\t}\n\t\tif (!visited[u]) {\n\t\t\tvisited[u] = true;\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[N * u + i] == 1 && dist[i] == -1) {\n\t\t\t\t\tdist[i] = dist[u] + 1;\n\t\t\t\t\tq.push_back(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}",
            "std::vector<bool> visited(N, false);\n\tvisited[source] = true;\n\tstd::vector<int> distance(N, INT_MAX);\n\tdistance[source] = 0;\n\tstd::queue<int> Q;\n\tQ.push(source);\n\n#pragma omp parallel\n\twhile(!Q.empty()) {\n#pragma omp single\n\t\t{\n\t\t\tint size = Q.size();\n#pragma omp for\n\t\t\tfor (int i = 0; i < size; i++) {\n\t\t\t\tint u = Q.front();\n\t\t\t\tQ.pop();\n\t\t\t\tfor (int v = 0; v < N; v++) {\n\t\t\t\t\tif (!visited[v] && A[u * N + v] == 1) {\n\t\t\t\t\t\tQ.push(v);\n\t\t\t\t\t\tdistance[v] = distance[u] + 1;\n\t\t\t\t\t\tvisited[v] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "int dist[N];\n\tint p[N];\n\tbool done[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = INF;\n\t\tp[i] = -1;\n\t\tdone[i] = false;\n\t}\n\tdist[source] = 0;\n\n\tint count = 0;\n\tfor (int i = 0; i < N; i++) {\n#pragma omp parallel for num_threads(10)\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist[j] < INF) {\n\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\tif (A[j * N + k] < INF && dist[j] + A[j * N + k] < dist[k]) {\n\t\t\t\t\t\tdist[k] = dist[j] + A[j * N + k];\n\t\t\t\t\t\tp[k] = j;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (dist[dest] < INF)\n\t\t\tbreak;\n\t}\n\n\tif (dist[dest] == INF)\n\t\treturn -1;\n\n\tint u = dest;\n\tint shortestPathLength = 0;\n\twhile (u!= source) {\n\t\tshortestPathLength++;\n\t\tu = p[u];\n\t}\n\n\treturn shortestPathLength;\n}",
            "/* Your solution goes here */\n}",
            "int pathLen = INT_MAX;\n\n  #pragma omp parallel\n  {\n    std::vector<int> dist(N, INT_MAX);\n    #pragma omp for\n    for (size_t i = 0; i < N; ++i) {\n      if (i == source) {\n        dist[source] = 0;\n      }\n      else if (A[source*N + i] == 0) {\n        dist[i] = INT_MAX;\n      }\n      else {\n        dist[i] = A[source*N + i];\n      }\n    }\n    #pragma omp for\n    for (size_t k = 0; k < N; ++k) {\n      for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n          if (A[i*N + j] == 0 || dist[i] == INT_MAX || dist[k] == INT_MAX) {\n            continue;\n          }\n          if (dist[j] > dist[i] + A[i*N + j]) {\n            dist[j] = dist[i] + A[i*N + j];\n          }\n        }\n      }\n    }\n    #pragma omp critical\n    {\n      if (dist[dest] < pathLen) {\n        pathLen = dist[dest];\n      }\n    }\n  }\n  if (pathLen == INT_MAX) {\n    return -1;\n  }\n  return pathLen;\n}",
            "// TODO: Your code here\n\tint shortestPathLength = INT_MAX;\n\n\tint *distances = new int[N];\n\n\tint *q = new int[N];\n\tint *visited = new int[N];\n\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tvisited[i] = 0;\n\t\tdistances[i] = INT_MAX;\n\t}\n\n\tvisited[source] = 1;\n\tq[0] = source;\n\tint q_end = 1;\n\n\tint u, v;\n\tint n_visited;\n\n\tint k = 0;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n#pragma omp critical\n\t\t{\n\t\t\tif (i == source) {\n\t\t\t\tdistances[i] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n#pragma omp parallel\n#pragma omp master\n\t{\n\t\twhile (q_end!= 0) {\n\t\t\tn_visited = 0;\n\t\t\tfor (int i = 0; i < q_end; i++) {\n\t\t\t\tu = q[i];\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tv = j;\n\t\t\t\t\tif (A[u * N + v] == 1 && visited[v] == 0) {\n\t\t\t\t\t\tvisited[v] = 1;\n\t\t\t\t\t\tq[q_end++] = v;\n\t\t\t\t\t\tn_visited++;\n\t\t\t\t\t\tif (v == dest) {\n\t\t\t\t\t\t\tshortestPathLength = distances[u] + 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tq_end -= n_visited;\n\t\t\tfor (int i = 0; i < q_end; i++) {\n\t\t\t\tdistances[q[i]] = distances[q[0]] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] q;\n\tdelete[] visited;\n\n\tdelete[] distances;\n\n\treturn shortestPathLength;\n}",
            "std::vector<bool> marked(N, false); // boolean array of marked vertices\n    std::vector<int> distance(N, std::numeric_limits<int>::max()); // array of distances\n    distance[source] = 0;\n\n    int min_dist = std::numeric_limits<int>::max();\n\n    while (!marked.empty()) {\n\n        int u = -1;\n        for (int i = 0; i < N; ++i) {\n            if (!marked[i] && distance[i] < min_dist) {\n                u = i;\n                min_dist = distance[i];\n            }\n        }\n\n        if (u == -1) {\n            break;\n        }\n\n        marked[u] = true;\n        min_dist = distance[u];\n\n        for (int i = 0; i < N; ++i) {\n            if (A[u*N + i] &&!marked[i]) {\n                distance[i] = std::min(distance[i], min_dist + 1);\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n  dist[source] = 0;\n\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j]!= 0 && dist[i] + 1 < dist[j])\n        dist[j] = dist[i] + 1;\n    }\n  }\n\n  return dist[dest];\n}",
            "std::vector<int> minDist(N, std::numeric_limits<int>::max());\n\tstd::vector<int> prev(N, -1);\n\n\tstd::vector<bool> visited(N, false);\n\n\tminDist[source] = 0;\n\tprev[source] = source;\n\n\tstd::vector<int> Q;\n\tQ.push_back(source);\n\n\tint qsize = 1;\n\n\twhile (qsize > 0) {\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < qsize; ++i) {\n\t\t\tint u = Q[i];\n\t\t\tif (u == dest) {\n\t\t\t\treturn minDist[dest];\n\t\t\t}\n\t\t\tif (visited[u]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tvisited[u] = true;\n\n\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\tif (A[N*u + v]) {\n\t\t\t\t\tif (minDist[v] > minDist[u] + 1) {\n\t\t\t\t\t\tminDist[v] = minDist[u] + 1;\n\t\t\t\t\t\tprev[v] = u;\n\t\t\t\t\t\tQ.push_back(v);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tqsize = Q.size();\n\t}\n\treturn -1;\n}",
            "std::vector<int> dist(N, INT_MAX);\n  // TODO: Fill in this function\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (A[source * N + i]!= 0) {\n      #pragma omp critical\n      {\n        if (dist[i] > 1)\n          dist[i] = 1;\n      }\n    }\n  }\n\n  int max = dist[dest];\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    if (A[source * N + i]!= 0) {\n      #pragma omp critical\n      {\n        if (dist[i] > 1)\n          dist[i] = 1;\n      }\n    }\n  }\n\n  return max;\n}",
            "std::vector<int> dist(N, -1);\n  std::vector<bool> visited(N, false);\n  std::vector<int> parent(N, -1);\n  int minDist = 100000;\n\n  // TODO: implement this\n  // use the parent vector to construct the shortest path\n  // for example:\n  //  parent = [1, 0, 0, 2]\n  //  path = [3, 0]\n  return minDist;\n}",
            "int dist[N];\n    int prev[N];\n    int path[N];\n    bool visited[N];\n\n    for(int i=0; i < N; i++){\n        dist[i] = INF;\n        prev[i] = -1;\n        path[i] = 0;\n        visited[i] = false;\n    }\n\n    std::priority_queue<std::pair<int, int>, std::vector<std::pair<int, int>>, std::greater<std::pair<int, int>>> pq;\n    pq.push(std::make_pair(0, source));\n    dist[source] = 0;\n\n    while(!pq.empty()){\n        auto curr = pq.top();\n        pq.pop();\n\n        if(curr.second == dest){\n            break;\n        }\n\n        for(int i=0; i < N; i++){\n            if(A[curr.second*N + i] == 1){\n                if(dist[i] > dist[curr.second] + 1){\n                    dist[i] = dist[curr.second] + 1;\n                    pq.push(std::make_pair(dist[i], i));\n                    prev[i] = curr.second;\n                }\n            }\n        }\n    }\n\n    // trace back\n    int length = dist[dest];\n    int i = dest;\n    while(prev[i]!= -1){\n        length++;\n        i = prev[i];\n    }\n\n    return length;\n}",
            "//std::vector<int> distances(N, -1); // distances[i] == -1 means we haven't reached node i yet\n\tstd::vector<int> distances(N, 0); // distances[i] == -1 means we haven't reached node i yet\n\tstd::vector<int> path(N, -1); // -1 means we haven't reached node i yet, 0 means we've reached node i but can't reach the dest yet, >0 means we've reached node i and can reach the dest\n\tstd::queue<int> queue;\n\tint dist;\n\tint node;\n\n\tdistances[source] = 0;\n\tpath[source] = 0;\n\tqueue.push(source);\n\t\n\twhile (queue.size() > 0) {\n\t\tnode = queue.front();\n\t\tqueue.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node*N+i]!= 0 && distances[node] + 1 < distances[i]) {\n\t\t\t\tdistances[i] = distances[node] + 1;\n\t\t\t\tpath[i] = node;\n\t\t\t\tqueue.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\tdist = distances[dest];\n\twhile (dest!= source) {\n\t\tdist += 1;\n\t\tdest = path[dest];\n\t}\n\t\n\treturn dist;\n}",
            "// TODO: Fill this in!\n  int min_path_length = -1;\n\n  #pragma omp parallel\n  {\n    int local_min_path_length = -1;\n\n    #pragma omp single\n    {\n      std::vector<bool> visited(N, false);\n      std::vector<int> dist(N, -1);\n      std::vector<int> prev(N, -1);\n      std::queue<int> q;\n      visited[source] = true;\n      dist[source] = 0;\n\n      q.push(source);\n      while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n\n        // If we found the destination, break\n        if (v == dest) {\n          local_min_path_length = dist[dest];\n          break;\n        }\n\n        for (int i = 0; i < N; i++) {\n          if (A[v * N + i] &&!visited[i]) {\n            visited[i] = true;\n            dist[i] = dist[v] + 1;\n            prev[i] = v;\n            q.push(i);\n          }\n        }\n      }\n\n      // We found a new shortest path length\n      if (local_min_path_length!= -1) {\n        #pragma omp critical\n        {\n          if (min_path_length == -1) {\n            min_path_length = local_min_path_length;\n          } else if (local_min_path_length < min_path_length) {\n            min_path_length = local_min_path_length;\n          }\n        }\n      }\n    }\n  }\n\n  return min_path_length;\n}",
            "// TODO\n}",
            "std::vector<int> d(N, std::numeric_limits<int>::max());\n    std::vector<bool> visited(N, false);\n\n    d[source] = 0;\n\n    #pragma omp parallel\n    {\n        #pragma omp for schedule(dynamic, 1)\n        for (int i = 0; i < N; ++i) {\n            if (!visited[i]) {\n                for (int j = 0; j < N; ++j) {\n                    if (i == j) continue;\n                    if (A[i * N + j]!= 0) {\n                        if (d[i]!= std::numeric_limits<int>::max()) {\n                            d[j] = std::min(d[j], d[i] + 1);\n                        }\n                    }\n                }\n                visited[i] = true;\n            }\n        }\n    }\n\n    return d[dest];\n}",
            "std::vector<int> distances = std::vector<int>(N, INT_MAX);\n  std::vector<int> parents = std::vector<int>(N, -1);\n  std::vector<bool> visited = std::vector<bool>(N, false);\n  int n_threads = 8;\n  int n_iterations = 0;\n  int chunk_size = N / n_threads;\n\n  /* Your solution goes here */\n  #pragma omp parallel num_threads(n_threads)\n  {\n    #pragma omp for schedule(static, chunk_size)\n    for (int i = 0; i < N; i++) {\n      if (A[source * N + i]!= INT_MAX) {\n        distances[i] = A[source * N + i];\n        parents[i] = source;\n      }\n    }\n    #pragma omp single\n    {\n      n_iterations = 0;\n    }\n\n    #pragma omp for schedule(static, chunk_size)\n    for (int i = 0; i < N; i++) {\n      int min_dist = INT_MAX;\n      int min_dist_index = -1;\n      for (int j = 0; j < N; j++) {\n        if (!visited[j] && (min_dist > distances[j])) {\n          min_dist = distances[j];\n          min_dist_index = j;\n        }\n      }\n      visited[min_dist_index] = true;\n      for (int j = 0; j < N; j++) {\n        if (!visited[j] && (distances[min_dist_index] + A[min_dist_index * N + j] < distances[j])) {\n          distances[j] = distances[min_dist_index] + A[min_dist_index * N + j];\n          parents[j] = min_dist_index;\n        }\n      }\n      #pragma omp atomic\n      n_iterations++;\n    }\n  }\n  int i = dest;\n  while (i!= -1) {\n    std::cout << i << std::endl;\n    i = parents[i];\n  }\n  std::cout << \"Number of iterations: \" << n_iterations << std::endl;\n  return distances[dest];\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> distance(N, -1);\n  distance[source] = 0;\n  int min_distance = INT_MAX;\n\n#pragma omp parallel\n  {\n#pragma omp for schedule(dynamic, 1)\n    for (int i = 0; i < N; i++) {\n      int current_distance = distance[i];\n      if (current_distance < 0) {\n        continue;\n      }\n\n      for (int j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 && visited[j] == 0 && current_distance!= INT_MAX) {\n          if (distance[j] > current_distance + 1) {\n#pragma omp atomic write\n            distance[j] = current_distance + 1;\n          }\n        }\n      }\n    }\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (distance[i]!= -1) {\n      if (i == dest) {\n        min_distance = std::min(min_distance, distance[i]);\n      } else {\n        visited[i] = 1;\n      }\n    }\n  }\n\n  return min_distance;\n}",
            "int dist[N];\n  std::vector<int> prev(N, -1);\n  std::fill(dist, dist + N, INT_MAX);\n  dist[source] = 0;\n  std::vector<bool> done(N, false);\n\n  // Iteratively find the closest point to the current node\n  for (int i = 0; i < N - 1; ++i) {\n    done[source] = true;\n    for (int j = 0; j < N; ++j) {\n      if (!done[j] && A[j * N + source]!= 0 && dist[source] + A[j * N + source] < dist[j]) {\n        dist[j] = dist[source] + A[j * N + source];\n        prev[j] = source;\n      }\n    }\n\n    // Find the closest point not yet evaluated\n    int closest = -1;\n    for (int j = 0; j < N; ++j) {\n      if (!done[j] && (closest == -1 || dist[j] < dist[closest])) {\n        closest = j;\n      }\n    }\n    source = closest;\n  }\n\n  std::vector<int> path;\n  int curr = dest;\n  while (curr!= -1) {\n    path.push_back(curr);\n    curr = prev[curr];\n  }\n  return path.size() - 1;\n}",
            "int lengths[N]; // lengths[i] is the shortest path length from source to i\n    std::fill(lengths, lengths + N, N); // initialize all lengths to N\n    lengths[source] = 0; // length of path from source to source is 0\n\n    int i;\n\n    #pragma omp parallel for shared(A, lengths, N) private(i)\n    for (i = 0; i < N; i++) { // for each node i\n        int j;\n\n        for (j = 0; j < N; j++) { // for each node j connected to i\n            if (A[i * N + j]!= 0 && lengths[i] + 1 < lengths[j]) { // if path from i to j exists and path from source to i is shorter than from source to j,\n                lengths[j] = lengths[i] + 1; // update the length of the path from source to j to the current length\n            }\n        }\n    }\n    return lengths[dest];\n}",
            "// TODO: implement\n  return -1;\n}",
            "// TODO: Implement this function to return the length of the shortest path from\n\t// source to dest in the graph defined by the adjacency matrix A.\n\t// You may not use this function in your implementation.\n\tint min_len = 100000000;\n\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (i == source)\n\t\t{\n\t\t\tmin_len = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tmin_len = std::min(min_len, shortestPathLength(A, N, source, i) + shortestPathLength(A, N, i, dest));\n\t}\n\n\treturn min_len;\n}",
            "int distance[N];\n    int visited[N];\n    int temp;\n    int minDistance;\n    int minDistanceIndex;\n\n    std::fill_n(distance, N, INT_MAX);\n    std::fill_n(visited, N, 0);\n    distance[source] = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        minDistance = INT_MAX;\n        minDistanceIndex = 0;\n        for (size_t j = 0; j < N; ++j) {\n            if (distance[j] < minDistance &&!visited[j]) {\n                minDistance = distance[j];\n                minDistanceIndex = j;\n            }\n        }\n        visited[minDistanceIndex] = 1;\n        for (size_t j = 0; j < N; ++j) {\n            if (!A[minDistanceIndex * N + j]) {\n                temp = distance[minDistanceIndex] + 1;\n                if (temp < distance[j]) {\n                    distance[j] = temp;\n                }\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "int length = 0;\n    if (A.at(source*N + dest)!= 0) {\n        length = 1;\n    } else {\n        int lengthFromSource = 0;\n        bool hasBeenVisited[N];\n        for (int i = 0; i < N; i++) {\n            hasBeenVisited[i] = false;\n        }\n        #pragma omp parallel for private(lengthFromSource, hasBeenVisited)\n        for (int i = 0; i < N; i++) {\n            if (A.at(source*N + i) == 1 &&!hasBeenVisited[i]) {\n                lengthFromSource = 1 + shortestPathLength(A, N, i, dest);\n                if (lengthFromSource < length) {\n                    length = lengthFromSource;\n                }\n                hasBeenVisited[i] = true;\n            }\n        }\n    }\n    return length;\n}",
            "// TODO: implement me!\n    #pragma omp parallel for num_threads(4) \n    for(int i = 0; i < N; ++i){\n        A[i] = 0;\n    }\n    return 0;\n}",
            "// TODO\n    // YOUR CODE GOES HERE\n    int *dist = new int[N];\n    bool *sptSet = new bool[N];\n    int min = INT_MAX;\n\n    for (int i = 0; i < N; i++) {\n        dist[i] = INT_MAX;\n        sptSet[i] = false;\n    }\n    dist[source] = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N - 1; i++) {\n        for (int u = 0; u < N; u++) {\n            for (int v = 0; v < N; v++) {\n                if (A[u * N + v] && dist[u]!= INT_MAX && dist[u] + 1 < dist[v]) {\n                    dist[v] = dist[u] + 1;\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (dist[i]!= INT_MAX) {\n            min = (min < dist[i])? min : dist[i];\n        }\n    }\n\n    delete[] dist;\n    delete[] sptSet;\n    return min;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> distance(N, -1);\n  std::vector<int> prev(N, -1);\n\n  distance[source] = 0;\n\n#pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    if (distance[i]!= -1) {\n      for (size_t j = 0; j < N; j++) {\n        if (A[i * N + j] == 1 && distance[j] == -1) {\n          distance[j] = distance[i] + 1;\n          prev[j] = i;\n        }\n      }\n    }\n  }\n\n  if (distance[dest] == -1) {\n    return -1;\n  }\n\n  // backtrack to find the shortest path\n  std::vector<int> path;\n  int k = dest;\n  while (k!= -1) {\n    path.push_back(k);\n    k = prev[k];\n  }\n  return path.size() - 1;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> distance(N, 0);\n  distance[source] = 1;\n\n  int pathLen = 0;\n  #pragma omp parallel for\n  for (size_t i=0; i<N; ++i) {\n    for (size_t j=0; j<N; ++j) {\n      if ((A[i*N+j]!= 0) && (visited[j] == 0)) {\n        distance[j] = distance[i] + 1;\n        visited[j] = 1;\n\n        if (j == dest) {\n          pathLen = distance[j];\n        }\n      }\n    }\n  }\n\n  return pathLen;\n}",
            "int nthreads;\n#pragma omp parallel\n\t{\n\t\tnthreads = omp_get_num_threads();\n\t}\n\n\tstd::vector<bool> visited(N);\n\tstd::vector<int> d(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tvisited[i] = false;\n\t\td[i] = 0;\n\t}\n\n\tstd::queue<int> q;\n\tq.push(source);\n\tvisited[source] = true;\n\tint i;\n\twhile (q.size() > 0) {\n\t\ti = q.front();\n\t\tq.pop();\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] == 1 && visited[j] == false) {\n\t\t\t\tq.push(j);\n\t\t\t\tvisited[j] = true;\n\t\t\t\td[j] = d[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn d[dest];\n}",
            "std::vector<int> D(N, 0);\n  // std::vector<int> P(N, -1);\n  std::vector<bool> visited(N, false);\n  std::queue<int> Q;\n\n  D[source] = 0;\n  Q.push(source);\n  visited[source] = true;\n\n  while(!Q.empty()) {\n    int current = Q.front();\n    Q.pop();\n\n    for(int v = 0; v < N; ++v) {\n      if(!visited[v] && A[current*N + v] == 1) {\n        D[v] = D[current] + 1;\n        Q.push(v);\n        visited[v] = true;\n      }\n    }\n  }\n\n  return D[dest];\n}",
            "return 0;\n}",
            "// Your code here\n\n}",
            "int length[N];\n    int visited[N];\n    int min = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        length[i] = 0;\n        visited[i] = 0;\n    }\n\n    length[source] = 1;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N - 1; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[j * N + i] == 1 && visited[j] == 0) {\n                length[j] = length[i] + 1;\n                visited[j] = 1;\n            }\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        if (length[i] > min) {\n            min = length[i];\n        }\n    }\n\n    return min;\n}",
            "int *distance = new int[N];\n  std::fill(distance, distance + N, std::numeric_limits<int>::max());\n  distance[source] = 0;\n\n  #pragma omp parallel for\n  for(int i = 0; i < N; i++){\n    for(int j = 0; j < N; j++){\n      if(distance[i] < std::numeric_limits<int>::max() && A[j * N + i] == 1)\n\tdistance[j] = std::min(distance[j], distance[i] + 1);\n    }\n  }\n\n  int shortestPathLength = distance[dest];\n  delete[] distance;\n  return shortestPathLength;\n}",
            "int dist[N];\n    int queue[N];\n    int head = 0;\n    int tail = 0;\n    int i;\n    int j;\n\n    for(i=0; i<N; i++) {\n        dist[i] = 1000000;\n    }\n\n    dist[source] = 0;\n    queue[tail] = source;\n    tail = (tail+1) % N;\n\n    while(head!=tail) {\n        i = queue[head];\n        head = (head+1) % N;\n        for(j=0; j<N; j++) {\n            if (A[i*N+j] && dist[j] > dist[i]+1) {\n                dist[j] = dist[i]+1;\n                queue[tail] = j;\n                tail = (tail+1) % N;\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "int pathLength[N];\n  int pathLengthNext[N];\n\n  for (int i=0; i<N; ++i) {\n    pathLength[i] = INT_MAX;\n  }\n  pathLength[source] = 0;\n\n  for (int i=0; i<N; ++i) {\n    for (int j=0; j<N; ++j) {\n      if (pathLength[j] < INT_MAX) {\n        pathLengthNext[j] = pathLength[j] + A[j*N+i];\n        pathLength[j] = std::min(pathLength[j], pathLengthNext[j]);\n      }\n    }\n  }\n  return pathLengthNext[dest];\n}",
            "std::vector<int> dist(N, INF);\n\n    // Initialize the distance between the source and itself to be 0\n    dist[source] = 0;\n\n    #pragma omp parallel for\n    for (int k = 0; k < N; ++k) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (dist[i]!= INF && A[i * N + k]!= INF && A[k * N + j]!= INF) {\n                    dist[j] = std::min(dist[j], dist[i] + A[i * N + k] + A[k * N + j]);\n                }\n            }\n        }\n    }\n\n    // Check for negative weight cycle\n    for (int i = 0; i < N; ++i) {\n        if (A[i * N + i] < 0) {\n            return -1;\n        }\n    }\n\n    // If dist[dest] is INF, then there is no path from source to dest\n    if (dist[dest]!= INF) {\n        return dist[dest];\n    }\n    else {\n        return -1;\n    }\n}",
            "if (source < 0 || source >= N) {\n\t\tthrow std::invalid_argument(\"Source must be in range [0, N).\");\n\t}\n\tif (dest < 0 || dest >= N) {\n\t\tthrow std::invalid_argument(\"Destination must be in range [0, N).\");\n\t}\n\n\tif (source == dest) {\n\t\treturn 0;\n\t}\n\n\tint* distances = new int[N];\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tdistances[i] = INT_MAX;\n\t}\n\n\tdistances[source] = 0;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp for\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i + j * N]!= 0 && distances[i]!= INT_MAX) {\n\t\t\t\t\tdistances[j] = std::min(distances[i] + 1, distances[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint result = distances[dest];\n\n\tdelete[] distances;\n\treturn result;\n}",
            "// Your code here\n  int *dists = new int[N];\n  for(int i = 0; i < N; i++) {\n    dists[i] = -1;\n  }\n\n  dists[source] = 0;\n  for (int i = 0; i < N; i++) {\n    #pragma omp parallel for\n    for(int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1 && dists[j] == -1) {\n        dists[j] = dists[i] + 1;\n      }\n    }\n  }\n\n  int shortest = dists[dest];\n  delete [] dists;\n  return shortest;\n}",
            "/*\n\tint length[N][N];\n\tint *A1[N];\n\tfor (int i = 0; i < N; i++){\n\t\tlength[i][i] = 0;\n\t}\n\tfor (int i = 0; i < N; i++){\n\t\tA1[i] = &A[i * N];\n\t}\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = i+1; j < N; j++){\n\t\t\tlength[i][j] = A1[i][j];\n\t\t\tlength[j][i] = A1[j][i];\n\t\t}\n\t}\n\tfor (int k = 0; k < N; k++){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tif (length[i][k] + length[k][j] < length[i][j]){\n\t\t\t\t\tlength[i][j] = length[i][k] + length[k][j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn length[source][dest];\n\t*/\n\n\tint length[N][N];\n\tfor (int i = 0; i < N; i++){\n\t\tlength[i][i] = 0;\n\t}\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (i!= j){\n\t\t\t\tlength[i][j] = A[i * N + j];\n\t\t\t}\n\t\t}\n\t}\n\tfor (int k = 0; k < N; k++){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\tif (i!= j){\n\t\t\t\t\tif (length[i][k] + length[k][j] < length[i][j]){\n\t\t\t\t\t\tlength[i][j] = length[i][k] + length[k][j];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn length[source][dest];\n}",
            "std::vector<int> distance(N, -1);\n\tdistance[source] = 0;\n\n\t// TODO: Use OpenMP to parallelize the for loop over i below\n#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (distance[j] == -1)\n\t\t\t\tcontinue;\n\t\t\tif (A[j * N + i] == 1 && distance[i] == -1)\n\t\t\t\tdistance[i] = distance[j] + 1;\n\t\t}\n\t}\n\n\tint length = distance[dest];\n\treturn length;\n}",
            "int distance[N];\n\tstd::fill(distance, distance + N, 0);\n\tdistance[source] = 1;\n\tint last_iteration = 0;\n\tint curr_iteration = 1;\n\twhile (last_iteration!= curr_iteration) {\n\t\tlast_iteration = curr_iteration;\n#pragma omp parallel for shared(distance)\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (distance[i] == last_iteration) {\n\t\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t\tint tmp = __sync_fetch_and_add(&distance[j], 1);\n\t\t\t\t\t\tif (tmp > curr_iteration)\n\t\t\t\t\t\t\tcurr_iteration = tmp;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn distance[dest];\n}",
            "std::vector<int> dist(N);\n    std::vector<int> path(N);\n    std::vector<bool> visited(N);\n\n    dist[source] = 0;\n    path[source] = -1;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        if (i!= source) {\n            dist[i] = INF;\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        int u = -1;\n\n        #pragma omp parallel for reduction(min:u)\n        for (int j = 0; j < N; j++) {\n            if (!visited[j] && (u == -1 || dist[j] < dist[u])) {\n                u = j;\n            }\n        }\n\n        if (u == -1) {\n            break;\n        }\n\n        visited[u] = true;\n\n        for (int v = 0; v < N; v++) {\n            if (A[N*u+v] && dist[v] > dist[u] + A[N*u+v]) {\n                #pragma omp critical\n                {\n                    dist[v] = dist[u] + A[N*u+v];\n                    path[v] = u;\n                }\n            }\n        }\n    }\n\n    if (dist[dest] == INF) {\n        return -1;\n    }\n\n    int u = dest;\n    int length = dist[dest];\n\n    while (u!= -1) {\n        length++;\n        u = path[u];\n    }\n\n    return length;\n}",
            "int result = 0;\n\t#pragma omp parallel for\n\tfor(int i=0; i<N; ++i) {\n\t\tint tmp = 0;\n\t\tfor(int j=0; j<N; ++j) {\n\t\t\tif(A[i * N + j] == 1)\n\t\t\t\ttmp++;\n\t\t}\n\t\tresult = std::max(result, tmp);\n\t}\n\treturn result;\n}",
            "// TODO: Your code here\n\treturn 0;\n}",
            "if (source == dest) {\n    return 0;\n  }\n\n  // your code here\n  int dist[N];\n  std::fill(dist, dist+N, std::numeric_limits<int>::max());\n  dist[source] = 0;\n\n  bool visited[N];\n  std::fill(visited, visited+N, false);\n  visited[source] = true;\n\n  std::queue<int> q;\n  q.push(source);\n\n  while (!q.empty()) {\n    int n = q.front();\n    q.pop();\n    for (int i = 0; i < N; i++) {\n      if (A[n*N+i] == 1 &&!visited[i]) {\n        visited[i] = true;\n        q.push(i);\n        dist[i] = dist[n] + 1;\n      }\n    }\n  }\n  return dist[dest];\n}",
            "// TODO: Your code here\n\tint res = -1;\n\n\tif (source == dest) return 0;\n\tif (source < 0 || source > N - 1 || dest < 0 || dest > N - 1) return -1;\n\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> parent(N, -1);\n\tstd::vector<int> d(N, INT_MAX);\n\td[source] = 0;\n\n\tstd::vector<std::vector<int>> children(N, std::vector<int>());\n\n\t#pragma omp parallel for schedule(dynamic, 1)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[N * i + j] == 1) {\n\t\t\t\tchildren[i].push_back(j);\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::queue<int> q;\n\tq.push(source);\n\tvisited[source] = true;\n\t\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\n\t\t#pragma omp parallel for\n\t\tfor (auto c : children[v]) {\n\t\t\tif (!visited[c]) {\n\t\t\t\tvisited[c] = true;\n\t\t\t\td[c] = d[v] + 1;\n\t\t\t\tparent[c] = v;\n\t\t\t\tq.push(c);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (d[dest]!= INT_MAX) {\n\t\tres = d[dest];\n\t\twhile (parent[dest]!= -1) {\n\t\t\tres++;\n\t\t\tdest = parent[dest];\n\t\t}\n\t}\n\n\treturn res;\n}",
            "int *dist = new int[N];\n\tint *visited = new int[N];\n\tint *q = new int[N];\n\n\t// TODO: Your code here\n\n\tdelete[] dist;\n\tdelete[] visited;\n\tdelete[] q;\n\treturn -1;\n}",
            "std::vector<int> dist(N, INT_MAX);\n\n  // TODO: Fill in the code to compute the shortest path distance between the source and each node in parallel\n  int Nthreads = omp_get_max_threads();\n  int* dist_thread = new int[Nthreads];\n  int* dist_thread_tmp = new int[Nthreads];\n  #pragma omp parallel num_threads(Nthreads)\n  {\n    int tid = omp_get_thread_num();\n    for(int i=0; i<Nthreads; i++)\n      dist_thread[i] = INT_MAX;\n    dist_thread_tmp[tid] = 0;\n    #pragma omp for\n    for (int i=0; i<N; i++)\n      for (int j=0; j<N; j++)\n        if (A[i*N+j] == 1 && i == source)\n          dist_thread_tmp[tid] = 1;\n    #pragma omp critical\n    {\n      for(int i=0; i<Nthreads; i++)\n      {\n        if(dist_thread_tmp[i] < dist_thread[i])\n        {\n          dist_thread[i] = dist_thread_tmp[i];\n        }\n      }\n    }\n    #pragma omp barrier\n    for (int i=0; i<N; i++)\n      for (int j=0; j<N; j++)\n        if (A[i*N+j] == 1 && dist_thread[tid] > dist_thread[j])\n          dist_thread[tid] = dist_thread[j]+1;\n    #pragma omp critical\n    {\n      for(int i=0; i<Nthreads; i++)\n      {\n        if(dist_thread[i] < dist[tid])\n        {\n          dist[tid] = dist_thread[i];\n        }\n      }\n    }\n  }\n\n  // Find the shortest path length\n  int minDist = INT_MAX;\n  for (int i = 0; i < N; i++)\n    if (minDist > dist[i])\n      minDist = dist[i];\n  return minDist;\n}",
            "// TODO: write your solution here\n\n\treturn -1;\n}",
            "// TODO: replace this line with your code\n    return 0;\n}",
            "/* YOUR CODE GOES HERE */\n\t//int count = 0;\n\t//int source = 0;\n\t//int dest = 3;\n\t//int i, j, k, l, x, y, z, p;\n\t//int queue[10000];\n\t//bool queue_start[10000];\n\t//int queue_size;\n\t//int queue_tail;\n\t//int queue_head;\n\t//bool done;\n\t//bool visited[10000];\n\t//int distance[10000];\n\t//int distance2[10000];\n\t//int path[10000];\n\t//int min_distance;\n\t//int min_index;\n\t//int num;\n\t//int num2;\n\n\t//for (int i = 0; i < N; i++) {\n\t//\tvisited[i] = false;\n\t//\tdistance[i] = 0;\n\t//}\n\n\t//visited[source] = true;\n\t//distance[source] = 0;\n\t//queue[0] = source;\n\t//queue_size = 1;\n\t//queue_tail = 1;\n\t//queue_head = 0;\n\t//done = false;\n\t//while (!done) {\n\t//\tx = queue[queue_head];\n\t//\tqueue_head++;\n\t//\tfor (int i = 0; i < N; i++) {\n\t//\t\tif (visited[i] == false && A[x * N + i] == 1) {\n\t//\t\t\tvisited[i] = true;\n\t//\t\t\tdistance[i] = distance[x] + 1;\n\t//\t\t\tqueue[queue_tail] = i;\n\t//\t\t\tqueue_size++;\n\t//\t\t\tqueue_tail++;\n\t//\t\t}\n\t//\t}\n\t//\tif (queue_size == 0)\n\t//\t\tdone = true;\n\t//}\n\n\t//for (int i = 0; i < N; i++)\n\t//\tdistance2[i] = distance[i];\n\n\t//for (int i = 0; i < N; i++) {\n\t//\tfor (int j = 0; j < N; j++) {\n\t//\t\tif (distance2[j] + A[j * N + i] < distance2[i])\n\t//\t\t\tdistance2[i] = distance2[j] + A[j * N + i];\n\t//\t}\n\t//}\n\n\t//min_distance = distance2[dest];\n\t//min_index = dest;\n\n\t//for (int i = 0; i < N; i++) {\n\t//\tif (distance2[i] < min_distance) {\n\t//\t\tmin_distance = distance2[i];\n\t//\t\tmin_index = i;\n\t//\t}\n\t//}\n\n\t//path[min_index] = 1;\n\t//for (int i = 0; i < N; i++) {\n\t//\tif (path[i]!= 1) {\n\t//\t\tpath[i] = 2;\n\t//\t}\n\t//}\n\n\t//for (int i = 0; i < N; i++) {\n\t//\tif (path[i] == 2) {\n\t//\t\tfor (int j = 0; j < N; j++) {\n\t//\t\t\tif (distance[j] + A[j * N + i] < distance[i]) {\n\t//\t\t\t\tpath[i] = j;\n\t//\t\t\t\tbreak;\n\t//\t\t\t}\n\t//\t\t}\n\t//\t}\n\t//}\n\n\t//for (int i = 0; i < N; i++) {\n\t//\tif (i == 0) {\n\t//\t\tif (path[i]!= -1)\n\t//\t\t\tcount++;\n\t//\t}\n\t//\telse if (path[i]!= path[i - 1]) {\n\t//\t\tcount++;\n\t//\t}\n\t//}\n\n\t//return count;\n\n\treturn -1;\n}",
            "// TODO: Replace this statement with your code\n  return -1;\n}",
            "// TODO: Implement me\n  int shortestPath = INT_MAX;\n  int nthreads;\n  int i, j, k;\n  bool *visited = new bool[N];\n  int distance[N];\n  std::queue<int> q;\n  std::vector<int> adj[N];\n  std::vector<int>::iterator it;\n  int u, v, weight;\n\n  //create adjacency list for graph\n  for(i = 0; i < N; i++) {\n    for(j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        adj[i].push_back(j);\n      }\n    }\n  }\n\n  #pragma omp parallel\n  {\n    nthreads = omp_get_num_threads();\n    printf(\"I'm thread %d of %d\\n\", omp_get_thread_num(), nthreads);\n  }\n\n  for(k = 0; k < N; k++) {\n    visited[k] = false;\n    distance[k] = INT_MAX;\n  }\n\n  visited[source] = true;\n  distance[source] = 0;\n  q.push(source);\n\n  while(!q.empty()) {\n    u = q.front();\n    q.pop();\n\n    it = adj[u].begin();\n    while(it!= adj[u].end()) {\n      v = *it;\n      if(!visited[v]) {\n        weight = A[u*N + v];\n        distance[v] = distance[u] + weight;\n        q.push(v);\n        visited[v] = true;\n      }\n      it++;\n    }\n  }\n\n  for(i = 0; i < N; i++) {\n    if(distance[i]!= INT_MAX) {\n      if(distance[i] < shortestPath) {\n        shortestPath = distance[i];\n      }\n    }\n  }\n\n  return shortestPath;\n}",
            "int num_threads;\n  int source_length[N];\n  int dest_length[N];\n  int max_dest_length;\n\n  // Set initial source and dest length to 0\n  #pragma omp parallel for num_threads(num_threads)\n  for (int i = 0; i < N; i++){\n    source_length[i] = 0;\n    dest_length[i] = 0;\n  }\n\n  // Set initial source length to 1\n  source_length[source] = 1;\n\n  // Repeat while at least one destination length has not been updated\n  while (max_dest_length <= dest_length[dest]) {\n\n    // Determine max length of destination vertices\n    max_dest_length = 0;\n    for (int i = 0; i < N; i++) {\n      if (dest_length[i] > max_dest_length) {\n        max_dest_length = dest_length[i];\n      }\n    }\n\n    // Update destination vertices to include the new length\n    #pragma omp parallel for num_threads(num_threads)\n    for (int i = 0; i < N; i++) {\n      if (dest_length[i] == max_dest_length) {\n        for (int j = 0; j < N; j++) {\n          if (A[i*N+j] == 1 && source_length[j] > 0) {\n            dest_length[i] = source_length[j] + 1;\n          }\n        }\n      }\n    }\n  }\n\n  return max_dest_length;\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n  std::vector<bool> in_queue(N, false);\n\n  std::vector<int> queue;\n\n  dist[source] = 0;\n  queue.push_back(source);\n  in_queue[source] = true;\n\n  // BFS loop\n  while (!queue.empty()) {\n    int u = queue.back();\n    queue.pop_back();\n    in_queue[u] = false;\n\n    if (u == dest) break;\n\n    for (int v = 0; v < N; ++v) {\n      if (A[v * N + u] == 1 && dist[v] > dist[u] + 1) {\n        dist[v] = dist[u] + 1;\n\n        if (!in_queue[v]) {\n          in_queue[v] = true;\n          queue.push_back(v);\n        }\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "/*\n    Your solution goes here\n    */\n    return 0;\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tstd::vector<bool> visited(N);\n\tstd::vector<int> parent(N);\n\tstd::vector<int> dist_to_visit;\n\n\tdist[source] = 0;\n\tparent[source] = source;\n\n\tbool found = false;\n\tdist_to_visit.push_back(source);\n\n\twhile (!found && dist_to_visit.size() > 0) {\n\t\tint node = dist_to_visit.front();\n\t\tdist_to_visit.erase(dist_to_visit.begin());\n\n\t\tvisited[node] = true;\n\t\tfor (int n = 0; n < N; ++n) {\n\t\t\tif (A[node * N + n] == 0) continue;\n\t\t\tif (visited[n]) continue;\n\t\t\tif (dist[node] + A[node * N + n] < dist[n]) {\n\t\t\t\tdist[n] = dist[node] + A[node * N + n];\n\t\t\t\tparent[n] = node;\n\t\t\t\tdist_to_visit.push_back(n);\n\t\t\t}\n\t\t}\n\n\t\tif (node == dest) {\n\t\t\tfound = true;\n\t\t}\n\t}\n\n\tif (!found) {\n\t\treturn INT_MAX;\n\t}\n\n\tstd::vector<int> shortest_path;\n\tshortest_path.push_back(dest);\n\twhile (parent[dest]!= dest) {\n\t\tshortest_path.push_back(parent[dest]);\n\t\tdest = parent[dest];\n\t}\n\tstd::reverse(shortest_path.begin(), shortest_path.end());\n\n\treturn shortest_path.size() - 1;\n}",
            "// Initialize vectors to store the distance from source to each vertex, and a boolean value indicating whether\n    // the corresponding vertex has been visited.\n    std::vector<int> distance(N, std::numeric_limits<int>::max());\n    std::vector<bool> visited(N, false);\n\n    // Set the distance from source to source to 0.\n    distance[source] = 0;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n\n        // Compute the distances from source to all vertices.\n        // If a shortest path from source to v has already been found, the loop continues immediately.\n        // Otherwise, the shortest path from source to v is computed using BFS.\n        //\n        // This loop uses a critical section to update the distances and visited vectors.\n        // We use the same logic as in the shortestPathLength function in the slides.\n        #pragma omp critical\n        if (!visited[i]) {\n            queue<int> q;\n            q.push(i);\n            visited[i] = true;\n\n            while (!q.empty()) {\n                int u = q.front();\n                q.pop();\n\n                for (int v = 0; v < N; ++v) {\n                    if (A[N * u + v]) {\n                        if (distance[v] > distance[u] + 1) {\n                            distance[v] = distance[u] + 1;\n                        }\n\n                        if (!visited[v]) {\n                            q.push(v);\n                            visited[v] = true;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, -1);\n    dist[source] = 0;\n\n    #pragma omp parallel for shared(dist)\n    for (int k = 0; k < N; ++k) {\n        for (int i = 0; i < N; ++i) {\n            if (dist[i] < 0) {\n                continue;\n            }\n            for (int j = 0; j < N; ++j) {\n                if (A[i * N + j] == 0) {\n                    continue;\n                }\n                if (dist[j] < 0 || dist[i] + 1 < dist[j]) {\n                    dist[j] = dist[i] + 1;\n                }\n            }\n        }\n    }\n\n    if (dist[dest] < 0) {\n        return -1;\n    }\n    return dist[dest];\n}",
            "std::vector<int> distances(N, INT_MAX);\n    std::vector<bool> visited(N, false);\n\n    // initialize queue\n    std::queue<int> q;\n    q.push(source);\n    distances[source] = 0;\n\n    int u, v, w;\n\n    #pragma omp parallel num_threads(2)\n    {\n        #pragma omp single\n        {\n            #pragma omp taskloop shared(q,distances,visited)\n            for (int i = 0; i < N; ++i) {\n                u = q.front();\n                q.pop();\n                visited[u] = true;\n\n                for (int j = 0; j < N; ++j) {\n                    if (A[u*N + j] &&!visited[j]) {\n                        q.push(j);\n                        distances[j] = distances[u] + 1;\n                    }\n                }\n            }\n        }\n\n        #pragma omp taskloop shared(q,distances,visited)\n        for (int i = 0; i < N; ++i) {\n            u = q.front();\n            q.pop();\n            visited[u] = true;\n\n            for (int j = 0; j < N; ++j) {\n                if (A[u*N + j] &&!visited[j]) {\n                    q.push(j);\n                    distances[j] = distances[u] + 1;\n                }\n            }\n        }\n    }\n\n    return distances[dest];\n}",
            "std::vector<int> distance(N, INT_MAX);\n    distance[source] = 0;\n    std::vector<bool> visited(N, false);\n    omp_set_num_threads(4);\n\n    while (true) {\n        int min_dist = INT_MAX;\n        int next = -1;\n\n#pragma omp parallel for\n        for (size_t i = 0; i < N; i++) {\n            if (!visited[i] && distance[i] < min_dist) {\n                min_dist = distance[i];\n                next = i;\n            }\n        }\n\n        if (next == -1)\n            break;\n\n        visited[next] = true;\n\n#pragma omp parallel for\n        for (size_t i = 0; i < N; i++) {\n            if (A[next * N + i] == 1 && distance[i] > distance[next] + 1) {\n                distance[i] = distance[next] + 1;\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[j*N + i] == 1 && dist[j]!= -1) {\n\t\t\t\tdist[i] = 1 + dist[j];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "// BEGIN_YOUR_CODE\n  if (source == dest) {\n    return 0;\n  }\n\n  std::vector<int> distance(N, -1);\n  distance[source] = 0;\n  bool found = false;\n  int step = 0;\n\n  #pragma omp parallel\n  {\n    #pragma omp single\n    {\n      while (not found and step < N) {\n        #pragma omp for schedule(static)\n        for (int i = 0; i < N; i++) {\n          for (int j = 0; j < N; j++) {\n            if (distance[j] == -1 and A[i * N + j]) {\n              distance[j] = step + 1;\n            }\n          }\n        }\n        step++;\n        #pragma omp for schedule(static) reduction(|:found)\n        for (int i = 0; i < N; i++) {\n          found = found or (distance[i] >= 0);\n        }\n      }\n    }\n  }\n\n  return distance[dest];\n  // END_YOUR_CODE\n}",
            "std::vector<int> dists(N, INT_MAX);\n    dists[source] = 0;\n    int num_threads;\n    int* dists_ptr = dists.data();\n    #pragma omp parallel\n    {\n        #pragma omp single\n        {\n            num_threads = omp_get_num_threads();\n            #pragma omp taskloop\n            for(int i = 0; i < N; i++) {\n                for(int j = 0; j < N; j++) {\n                    if(A[i * N + j]) {\n                        #pragma omp task\n                        {\n                            int newDist = dists[i] + 1;\n                            if(newDist < dists[j])\n                                dists[j] = newDist;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return dists[dest];\n}",
            "std::vector<int> lengths(N);\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; i++) {\n    lengths[i] = INT_MAX;\n  }\n  lengths[source] = 0;\n\n  bool changed = true;\n  while (changed) {\n    changed = false;\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n      if (A[N * source + i]!= 0 && lengths[i] > lengths[source] + A[N * source + i]) {\n        lengths[i] = lengths[source] + A[N * source + i];\n        changed = true;\n      }\n    }\n  }\n  return lengths[dest];\n}",
            "// write your code here\n  std::vector<int> d(N, INT_MAX);\n  d[source] = 0;\n  #pragma omp parallel for\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i*N + j] == 1) {\n        if (d[j] > d[i] + 1) d[j] = d[i] + 1;\n      }\n    }\n  }\n  return d[dest];\n}",
            "// TODO: your code here\n  std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n  std::vector<int> vis(N, 0);\n  std::vector<int> prev(N, -1);\n\n  for (int step = 0; step < N - 1; ++step) {\n    #pragma omp parallel for\n    for (int u = 0; u < N; ++u) {\n      for (int v = 0; v < N; ++v) {\n        if (!vis[u]) {\n          if (A[u * N + v] > 0 && dist[u] + A[u * N + v] < dist[v]) {\n            dist[v] = dist[u] + A[u * N + v];\n            prev[v] = u;\n          }\n        }\n      }\n    }\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n      vis[i] = 1;\n    }\n  }\n\n  int u = dest;\n  int count = 0;\n  while (prev[u] >= 0) {\n    ++count;\n    u = prev[u];\n  }\n  return count;\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n\tint nthreads = 1;\n\tint* nthreads_ptr = &nthreads;\n\t#pragma omp parallel\n\t{\n\t\tif (omp_get_thread_num() == 0)\n\t\t\tnthreads = omp_get_num_threads();\n\t}\n\n\tstd::vector<std::vector<int>> work(nthreads);\n\tfor (int t = 0; t < nthreads; t++)\n\t\twork[t].resize(N, -1);\n\n\tint count = 0;\n\tstd::vector<int> count_per_thread(nthreads, 0);\n\tstd::vector<int> next_count_per_thread(nthreads, 0);\n\tbool done = false;\n\n\twhile (!done) {\n\t\t#pragma omp parallel num_threads(nthreads)\n\t\t{\n\t\t\tint tid = omp_get_thread_num();\n\t\t\tint start = count_per_thread[tid];\n\t\t\tint end = count_per_thread[tid] + next_count_per_thread[tid];\n\n\t\t\tfor (int i = start; i < end; i++) {\n\t\t\t\tint u = work[tid][i];\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tint weight = A[u*N + j];\n\t\t\t\t\tif (weight == 0)\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\tif (dist[j] == -1 || dist[j] > dist[u] + weight) {\n\t\t\t\t\t\tdist[j] = dist[u] + weight;\n\t\t\t\t\t\twork[tid].push_back(j);\n\t\t\t\t\t\tnext_count_per_thread[tid]++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tcount += next_count_per_thread[0];\n\t\tfor (int t = 1; t < nthreads; t++)\n\t\t\tcount += next_count_per_thread[t];\n\t\tnext_count_per_thread[0] = 0;\n\t\tfor (int t = 1; t < nthreads; t++)\n\t\t\tnext_count_per_thread[t] = 0;\n\n\t\tdone = true;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tif (dist[i] == -1) {\n\t\t\t\tdone = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "int result = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> queue;\n\n\tqueue.push_back(source);\n\tvisited[source] = true;\n\t\n\t#pragma omp parallel shared(result)\n\t{\n\t\twhile (queue.size() > 0) {\n\t\t\tint vertex = queue.back();\n\t\t\tqueue.pop_back();\n\t\t\tif (vertex == dest) {\n\t\t\t\tresult = 1;\n\t\t\t\t#pragma omp critical\n\t\t\t\t{\n\t\t\t\t\tif (result < 2)\n\t\t\t\t\t\tresult = 2;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[vertex * N + i] == 1 &&!visited[i]) {\n\t\t\t\t\t#pragma omp critical\n\t\t\t\t\t{\n\t\t\t\t\t\tqueue.push_back(i);\n\t\t\t\t\t\tvisited[i] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "#pragma omp parallel\n\t{\n\t\tstd::vector<int> dist(N, -1);\n\t\tdist[source] = 0;\n\n\t\t#pragma omp for schedule(static, 1)\n\t\tfor(size_t i = 0; i < N; i++)\n\t\t{\n\t\t\tfor(size_t j = 0; j < N; j++)\n\t\t\t{\n\t\t\t\tint tmp = dist[j] + A[j * N + i];\n\t\t\t\tif(dist[i] < 0 || tmp < dist[i])\n\t\t\t\t{\n\t\t\t\t\tdist[i] = tmp;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif(dist[dest] >= 0)\n\t\t\t{\n\t\t\t\tprintf(\"Path length %d\\n\", dist[dest]);\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}",
            "std::vector<int> dis(N, std::numeric_limits<int>::max());\n\tdis[source] = 0;\n\tstd::vector<bool> visited(N, false);\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j] == 0)\n\t\t\t\tcontinue;\n\t\t\tif (dis[j] > dis[i] + 1)\n\t\t\t\tdis[j] = dis[i] + 1;\n\t\t}\n\t}\n\n\treturn dis[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n  #pragma omp parallel for\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i * N + j]!= 0) {\n        if (dist[i]!= INT_MAX && dist[i] + 1 < dist[j]) {\n          dist[j] = dist[i] + 1;\n        }\n      }\n    }\n  }\n  return dist[dest];\n}",
            "/*\n   * TODO: Implement this.\n   */\n  int length=0;\n  std::vector<int> visited(N,0);\n  std::vector<int> queue;\n  queue.push_back(source);\n  visited[source]=1;\n  int next_vertex;\n  while(visited[dest]==0)\n  {\n    length++;\n    for(int i=0;i<queue.size();i++)\n    {\n      for(int j=0;j<N;j++)\n      {\n        if(A[queue[i]*N+j]==1)\n        {\n          if(visited[j]==0)\n          {\n            queue.push_back(j);\n            visited[j]=1;\n          }\n        }\n      }\n    }\n    next_vertex=queue[0];\n    for(int i=1;i<queue.size();i++)\n    {\n      if(visited[queue[i]]==1)\n      {\n        next_vertex=queue[i];\n      }\n    }\n    queue.erase(queue.begin());\n  }\n  return length-1;\n}",
            "int i, j;\n\tint *dist, *parent, *q;\n\tint front = 0;\n\tint rear = 0;\n\tint length = 0;\n\n\t// allocate and initialize queue and distance arrays\n\tdist = new int [N+1];\n\tparent = new int [N+1];\n\tq = new int [N+1];\n\tfor(i=0; i<N+1; i++){\n\t\tdist[i] = INFINITE;\n\t\tparent[i] = -1;\n\t}\n\n\t// initialize queue with source\n\tq[rear++] = source;\n\tdist[source] = 0;\n\t\n\t// breadth first search\n\twhile(front < rear){\n\t\t// dequeue node v\n\t\ti = q[front++];\n\t\t// for each neighbor w of v\n\t\tfor(j=0; j<N; j++){\n\t\t\t// if edge from v to w exists and destination not found and shorter path to w exists\n\t\t\tif(A[N*i + j] && dist[j] > dist[i] + 1){\n\t\t\t\t// enqueue w, update parent[w], dist[w]\n\t\t\t\tq[rear++] = j;\n\t\t\t\tparent[j] = i;\n\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\t// trace shortest path\n\tj = dest;\n\twhile(j!= -1){\n\t\tlength++;\n\t\tj = parent[j];\n\t}\n\tdelete[] dist;\n\tdelete[] parent;\n\tdelete[] q;\n\treturn length-1;\n}",
            "// Your code goes here.\n}",
            "int *distances = new int[N];\n    std::fill(distances, distances + N, -1);\n    distances[source] = 0;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n        int min = -1;\n        for (int j = 0; j < N; j++) {\n            if (A[j * N + i] == 1 && distances[j]!= -1) {\n                if (min == -1) {\n                    min = distances[j];\n                } else if (distances[j] < min) {\n                    min = distances[j];\n                }\n            }\n        }\n        if (min!= -1) {\n            distances[i] = min + 1;\n        }\n    }\n\n    int result = distances[dest];\n    delete [] distances;\n    return result;\n}",
            "// TODO: Implement shortest path using Dijkstra\n    std::vector<int> dist(N, -1);\n\tstd::vector<int> pred(N, -1);\n\tstd::vector<bool> visited(N, false);\n\n\t// 0. Initialize dist with \u221e\n\tfor (int i = 0; i < N; ++i)\n\t\tdist[i] = INT_MAX;\n\n\t// 1. Set dist[source] to 0\n\tdist[source] = 0;\n\n\t// 2. Find all vertices v that have a path to the source\n\t//    in the current shortest path tree T\n\tfor (int i = 0; i < N; ++i) {\n\t\tint u = -1;\n\t\tint min_dist = INT_MAX;\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (!visited[v] && dist[v] < min_dist) {\n\t\t\t\tu = v;\n\t\t\t\tmin_dist = dist[v];\n\t\t\t}\n\t\t}\n\t\tif (u == -1)\n\t\t\tbreak;\n\t\tvisited[u] = true;\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (!visited[v] && A[u * N + v]) {\n\t\t\t\tint alt = dist[u] + 1;\n\t\t\t\tif (alt < dist[v]) {\n\t\t\t\t\tdist[v] = alt;\n\t\t\t\t\tpred[v] = u;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// 3. Return dist[dest]\n\treturn dist[dest];\n}",
            "std::vector<int> distances(N, INT_MAX);\n    distances[source] = 0;\n\n    for (int i = 0; i < N - 1; ++i) {\n        #pragma omp parallel for\n        for (int u = 0; u < N; ++u) {\n            for (int v = 0; v < N; ++v) {\n                if (A[u*N + v] && distances[u]!= INT_MAX && distances[u] + 1 < distances[v]) {\n                    distances[v] = distances[u] + 1;\n                }\n            }\n        }\n    }\n\n    return distances[dest];\n}",
            "// TODO: Replace this code with a correct implementation\n    std::vector<int> dist(N, 0);\n    dist[source] = 1;\n\n    std::vector<bool> visited(N, 0);\n\n    // TODO: replace this code with a correct implementation\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            if (visited[j] == 0 && A[i * N + j]!= 0) {\n                dist[j] = dist[i] + 1;\n                visited[j] = 1;\n            }\n        }\n    }\n    return dist[dest];\n}",
            "int length=0;\n    bool *visited = new bool[N];\n    for(int i=0;i<N;i++)\n    {\n        visited[i]=false;\n    }\n    omp_set_num_threads(8);\n    visited[source]=true;\n    #pragma omp parallel for\n    for(int i=0;i<N;i++)\n    {\n        for(int j=0;j<N;j++)\n        {\n            if(A[i*N+j]==1 &&!visited[j])\n            {\n                visited[j]=true;\n            }\n        }\n    }\n    for(int i=0;i<N;i++)\n    {\n        if(visited[dest]==true)\n        {\n            length++;\n        }\n    }\n\n\n    return length;\n\n}",
            "int *d = new int[N];\n\tfor (size_t i = 0; i < N; i++) {\n\t\td[i] = INT_MAX;\n\t}\n\td[source] = 0;\n\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i * N + j] && d[i]!= INT_MAX && d[j] > d[i] + 1) {\n\t\t\t\td[j] = d[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tint result = d[dest];\n\tdelete[] d;\n\treturn result;\n}",
            "// TODO: Fill in the function here\n}",
            "int distance[N];\n\t//int* distance = new int[N];\n\tint path[N];\n\t//int* path = new int[N];\n\n\t// initialize distance to INFINITY\n\tfor (size_t i = 0; i < N; i++)\n\t\tdistance[i] = INFINITY;\n\t\n\t// distance[source] = 0\n\tdistance[source] = 0;\n\n\t// start the search\n\t#pragma omp parallel for\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[N * i + j]!= 0) {\n\t\t\t\tif (distance[i] + 1 < distance[j]) {\n\t\t\t\t\tdistance[j] = distance[i] + 1;\n\t\t\t\t\tpath[j] = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// backtrack from dest\n\tint i = dest;\n\twhile (i!= source) {\n\t\tdest = i;\n\t\ti = path[i];\n\t}\n\t\n\treturn distance[dest];\n}",
            "// TODO: Replace this code with a correct implementation\n    int result = 0;\n\n    // std::vector<std::vector<int>> minDist(N, std::vector<int>(N, INT_MAX));\n    std::vector<int> minDist(N, INT_MAX);\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; ++i) {\n        minDist[i] = A[source * N + i];\n    }\n\n    for (size_t i = 0; i < N; ++i) {\n        int u;\n        int min = INT_MAX;\n        for (size_t j = 0; j < N; ++j) {\n            if (min > minDist[j]) {\n                min = minDist[j];\n                u = j;\n            }\n        }\n\n        if (min == INT_MAX) {\n            break;\n        }\n\n        if (u == dest) {\n            result = min;\n            break;\n        }\n\n        #pragma omp parallel for\n        for (size_t v = 0; v < N; ++v) {\n            if (A[u * N + v]!= INT_MAX) {\n                if (minDist[v] > minDist[u] + A[u * N + v]) {\n                    minDist[v] = minDist[u] + A[u * N + v];\n                }\n            }\n        }\n    }\n\n    return result;\n}",
            "const int size = N;\n  const int NT = 16;\n  const int chunk_size = (size+NT-1)/NT;\n  const int nthreads = (size+chunk_size-1)/chunk_size;\n\n  std::vector<int> distances(size);\n\n  #pragma omp parallel num_threads(nthreads)\n  {\n    int tid = omp_get_thread_num();\n    int start = tid * chunk_size;\n    int end = std::min(start + chunk_size, size);\n    int source_dist = INT_MAX;\n    int dest_dist = INT_MAX;\n    std::vector<int> local_distances(size, INT_MAX);\n\n    #pragma omp single\n    {\n      local_distances[source] = 0;\n      source_dist = local_distances[source];\n      dest_dist = local_distances[dest];\n    }\n\n    #pragma omp barrier\n\n    // BFS to calculate distances of nodes from the source.\n    for (int t = 1; t <= size; ++t) {\n      for (int u = start; u < end; ++u) {\n        if (local_distances[u] < INT_MAX) {\n          for (int v = 0; v < size; ++v) {\n            if (A[u*size + v] && local_distances[v] > local_distances[u] + 1)\n              local_distances[v] = local_distances[u] + 1;\n          }\n        }\n      }\n\n      #pragma omp barrier\n    }\n\n    #pragma omp barrier\n\n    // Accumulate the local distances into the global distance vector.\n    #pragma omp for\n    for (int u = 0; u < size; ++u) {\n      if (local_distances[u] < INT_MAX)\n        #pragma omp atomic update\n        distances[u] += local_distances[u];\n    }\n  }\n\n  // Check for any negative cycles.\n  for (int i = 0; i < size; ++i)\n    if (distances[i] < 0) {\n      std::cout << \"Negative cycle detected!\" << std::endl;\n      return -1;\n    }\n\n  // Distances from source to dest.\n  for (int i = 0; i < size; ++i) {\n    if (distances[i] > 0)\n      return distances[i];\n  }\n  return 0;\n}",
            "/* This vector will store all the shortest paths\n\t   from each vertex to the destination.\n\t*/\n\tstd::vector<int> shortestPath(N, -1);\n\t\n\t// 0th element in shortestPath stores the shortest path from\n\t// source to itself. For the other elements, we will\n\t// use -1 to indicate that we haven't yet found the shortest\n\t// path from that vertex to dest.\n\tshortestPath[source] = 0;\n\n\t// Perform breadth-first search to find shortest paths\n\t// from source to each of the other vertices.\n\tstd::queue<int> q;\n\tq.push(source);\n\n\t// To keep track of which vertices have been visited\n\tstd::vector<bool> visited(N, false);\n\tvisited[source] = true;\n\t\n\tint pathLength = 1; // shortestPath[source] == 0\n\twhile(!q.empty()) {\n\t\tint curr = q.front();\n\t\tq.pop();\n\n\t\t// For each neighbor of curr not visited yet...\n\t\tfor(int neighbor = 0; neighbor < N; ++neighbor) {\n\t\t\t// If curr --> neighbor is a valid edge\n\t\t\tif(A[curr*N + neighbor] == 1 &&!visited[neighbor]) {\n\t\t\t\tq.push(neighbor);\n\t\t\t\tvisited[neighbor] = true;\n\t\t\t\t\n\t\t\t\t// Update shortest path length\n\t\t\t\tif(shortestPath[neighbor] == -1) {\n\t\t\t\t\t// First time seeing this neighbor\n\t\t\t\t\tshortestPath[neighbor] = pathLength;\n\t\t\t\t}\n\t\t\t\telse if(shortestPath[neighbor] > pathLength) {\n\t\t\t\t\tshortestPath[neighbor] = pathLength;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpathLength++;\n\t}\n\t\n\t// Destination has not been reached from the source\n\tif(shortestPath[dest] == -1) {\n\t\treturn -1;\n\t}\n\t\n\t// Return the shortest path length\n\treturn shortestPath[dest];\n}",
            "// Your code here\n    int dist[N][N];\n    int parent[N][N];\n    for(int i=0;i<N;i++){\n        for(int j=0;j<N;j++){\n            dist[i][j]=-1;\n            parent[i][j]=-1;\n        }\n    }\n\n    dist[source][source]=0;\n    for(int k=0;k<N;k++){\n        for(int i=0;i<N;i++){\n            for(int j=0;j<N;j++){\n                if(dist[i][k]!=-1 && dist[k][j]!=-1){\n                    if(dist[i][k]+dist[k][j]<dist[i][j]){\n                        dist[i][j]=dist[i][k]+dist[k][j];\n                        parent[i][j]=k;\n                    }\n                }\n            }\n        }\n    }\n\n    int l=dist[source][dest];\n    return l;\n}",
            "std::vector<int> dist(N, 0);\n  std::vector<int> pred(N, -1);\n  std::vector<int> work(N, 0);\n  dist[source] = 1;\n\n  // while there is something in the work list,\n  // repeat the operation\n  int num_iters = 0;\n  int num_work_items = 0;\n  while (num_work_items > 0) {\n    ++num_iters;\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n      if (work[i] == 0) continue;\n\n      int min_dist = std::numeric_limits<int>::max();\n      int min_idx = -1;\n      for (int j = 0; j < N; ++j) {\n        if (A[i * N + j] == 0) continue;\n        int alt = dist[i] + 1;\n        if (alt < dist[j]) {\n          dist[j] = alt;\n          pred[j] = i;\n        }\n\n        if (alt < min_dist) {\n          min_dist = alt;\n          min_idx = j;\n        }\n      }\n\n      // If we found a better path, then add this\n      // node to the work list\n      if (min_idx!= -1) {\n        work[min_idx] = 1;\n      }\n    }\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n      work[i] = 0;\n    }\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n      if (dist[i]!= 0) work[i] = 1;\n    }\n\n    num_work_items = std::accumulate(work.begin(), work.end(), 0);\n  }\n\n  std::cout << \"num_iters: \" << num_iters << std::endl;\n\n  // find the path from source to dest using the pred array\n  std::vector<int> path;\n  int current = dest;\n  while (current!= -1) {\n    path.push_back(current);\n    current = pred[current];\n  }\n  std::reverse(path.begin(), path.end());\n\n  std::cout << \"path: \";\n  for (int i = 0; i < path.size(); ++i) {\n    std::cout << path[i] << \" \";\n  }\n  std::cout << std::endl;\n\n  return dist[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    bool changed;\n    std::vector<bool> visit(N, false);\n    #pragma omp parallel for\n    for(int i=0; i < N; ++i) {\n        for(int j=0; j < N; ++j) {\n            changed = false;\n            if(A[i*N+j] == 1) {\n                if(dist[j] > dist[i] + 1) {\n                    dist[j] = dist[i] + 1;\n                    changed = true;\n                }\n            }\n            if(changed) {\n                #pragma omp critical(visit)\n                {\n                    visit[j] = true;\n                }\n            }\n        }\n    }\n\n    while (true) {\n        changed = false;\n        #pragma omp parallel for\n        for(int i=0; i < N; ++i) {\n            if(visit[i]) {\n                for(int j=0; j < N; ++j) {\n                    if(A[i*N+j] == 1) {\n                        if(dist[j] > dist[i] + 1) {\n                            dist[j] = dist[i] + 1;\n                            changed = true;\n                        }\n                    }\n                }\n            }\n        }\n        if(changed == false) {\n            break;\n        }\n    }\n    return dist[dest];\n}",
            "// TODO: implement this function\n    int len = -1;\n    std::vector<bool> visited(N, false);\n    visited[source] = true;\n    std::vector<int> queue;\n    queue.push_back(source);\n    while (!queue.empty())\n    {\n        int u = queue.front();\n        queue.erase(queue.begin());\n        if (u == dest)\n            break;\n        for (int v = 0; v < N; v++)\n        {\n            if (A[u * N + v]!= 0)\n            {\n                if (!visited[v])\n                {\n                    visited[v] = true;\n                    queue.push_back(v);\n                }\n            }\n        }\n    }\n    return len;\n}",
            "std::vector<int> distances(N, INT_MAX);\n\n  // Fill this in.\n  return 0;\n}",
            "// your code here\n\tint *d = new int[N];\n\tint *pred = new int[N];\n\t\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\td[i] = INT_MAX;\n\t\tpred[i] = INT_MIN;\n\t}\n\td[source] = 0;\n\t#pragma omp parallel for\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] > 0 && (d[i] + A[i * N + j]) < d[j]) {\n\t\t\t\t\td[j] = d[i] + A[i * N + j];\n\t\t\t\t\tpred[j] = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint i = dest;\n\twhile (pred[i] >= 0) {\n\t\ti = pred[i];\n\t}\n\t\n\tdelete [] d;\n\tdelete [] pred;\n\treturn d[dest];\n}",
            "// TODO: Replace this code with a parallel implementation.\n    return -1;\n}",
            "std::vector<int> distances(N);\n\n  // TODO: Fill in the distances vector\n\n  return distances[dest];\n}",
            "int result = 0;\n  std::vector<bool> reached(N, false);\n\n#pragma omp parallel for schedule(dynamic)\n  for (int i = 0; i < N; ++i) {\n    int current = source;\n    int steps = 0;\n\n    while (current!= dest &&!reached[current]) {\n      // check if we reached the end\n      if (current >= N) {\n        break;\n      }\n\n      // check if we reached the destination\n      if (current == dest) {\n        steps++;\n        break;\n      }\n\n      // check if we can go to next node\n      if (A[current * N + i]) {\n        current = i;\n        steps++;\n      } else {\n        break;\n      }\n    }\n\n    if (current == dest) {\n      #pragma omp critical\n      {\n        if (!reached[dest] || steps < result) {\n          result = steps;\n        }\n      }\n      reached[dest] = true;\n    }\n  }\n\n  return result;\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\tint prev = source;\n\tint min_dist = dist[source];\n\tint u, v;\n\tbool visited[N];\n\tfor (int i = 0; i < N; ++i)\n\t{\n\t\tvisited[i] = false;\n\t}\n\n\t#pragma omp parallel for\n\tfor (u = 0; u < N; ++u)\n\t{\n\t\tif (visited[u] == false)\n\t\t{\n\t\t\tfor (v = 0; v < N; ++v)\n\t\t\t{\n\t\t\t\tif (A[u * N + v]!= 0 && dist[v] > dist[u] + A[u * N + v])\n\t\t\t\t{\n\t\t\t\t\tdist[v] = dist[u] + A[u * N + v];\n\t\t\t\t\tprev = u;\n\t\t\t\t\tif (dist[v] < min_dist)\n\t\t\t\t\t{\n\t\t\t\t\t\tmin_dist = dist[v];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (u = 0; u < N; ++u)\n\t{\n\t\tif (A[u * N + dest]!= 0 && dist[dest] > dist[u] + A[u * N + dest])\n\t\t{\n\t\t\tdist[dest] = dist[u] + A[u * N + dest];\n\t\t\tprev = u;\n\t\t\tif (dist[dest] < min_dist)\n\t\t\t{\n\t\t\t\tmin_dist = dist[dest];\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> sss(N, INT_MAX);\n\tsss[dest] = 0;\n\tint prev2 = dest;\n\tfor (u = 0; u < N; ++u)\n\t{\n\t\tif (A[prev2 * N + u]!= 0 && sss[u] > sss[prev2] + A[prev2 * N + u])\n\t\t{\n\t\t\tsss[u] = sss[prev2] + A[prev2 * N + u];\n\t\t\tprev2 = u;\n\t\t}\n\t}\n\tfor (u = 0; u < N; ++u)\n\t{\n\t\tif (sss[dest] > sss[u] + dist[u])\n\t\t{\n\t\t\tsss[dest] = sss[u] + dist[u];\n\t\t}\n\t}\n\treturn sss[dest];\n}",
            "// TODO: Implement this function to compute shortest path length from source to dest using A.\n  int length = -1;\n  if (source == dest) {\n    length = 0;\n  } else {\n    // This is where you should implement your solution.\n    // Note: you can use an array of size N to store the distance\n    // from the source to each vertex.  For instance:\n    // distance[i] = distance from the source to vertex i.\n    // Use an array of size N * N to store the distance\n    // from each vertex to every other vertex.  For instance:\n    // distance[i][j] = distance from vertex i to vertex j.\n  }\n  return length;\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n    dist[source] = 0;\n    std::vector<bool> vis(N, false);\n    #pragma omp parallel for\n    for (size_t v = 0; v < N; ++v) {\n        if (A[source * N + v]!= 0) {\n            dist[v] = 1;\n        }\n    }\n    while (true) {\n        // bool vis[N];\n        std::vector<bool> vis(N, false);\n        vis[source] = true;\n        #pragma omp parallel for\n        for (size_t v = 0; v < N; ++v) {\n            if (A[source * N + v]!= 0) {\n                int dist_temp = dist[v];\n                int dist_temp_pre = dist[source] + 1;\n                if (dist_temp > dist_temp_pre) {\n                    dist[v] = dist_temp_pre;\n                    vis[v] = true;\n                }\n            }\n        }\n        bool flag = true;\n        for (size_t i = 0; i < N; ++i) {\n            if (vis[i] == false) {\n                flag = false;\n                break;\n            }\n        }\n        if (flag == true) {\n            return dist[dest];\n        }\n        source = dest;\n        int min = std::numeric_limits<int>::max();\n        #pragma omp parallel for\n        for (size_t v = 0; v < N; ++v) {\n            if (dist[v] < min && A[source * N + v]!= 0) {\n                min = dist[v];\n                source = v;\n            }\n        }\n        if (min == std::numeric_limits<int>::max()) {\n            return -1;\n        }\n    }\n}",
            "int nb_threads;\n\n\t#pragma omp parallel\n\t{\n\t\t#pragma omp single\n\t\t{\n\t\t\tnb_threads = omp_get_num_threads();\n\t\t\tprintf(\"Using %d threads\\n\", nb_threads);\n\t\t}\n\t}\n\n\tstd::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\n\tstd::vector<bool> is_visited(N, false);\n\n\t#pragma omp parallel for schedule(dynamic)\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (!is_visited[i] && A[i * N + j] == 1) {\n\t\t\t\tdist[j] = std::min(dist[j], dist[i] + 1);\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\tis_visited[i] = true;\n\t}\n\n\treturn dist[dest];\n}",
            "int length = 0;\n\tbool visited[N];\n\tint prev[N];\n\tstd::fill(visited, visited + N, false);\n\tprev[source] = -1;\n\tvisited[source] = true;\n\n\twhile (source!= dest) {\n\t\tint min = INT_MAX;\n\t\tint candidate;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[source*N + i]!= 0 &&!visited[i]) {\n\t\t\t\tif (min > A[source*N + i]) {\n\t\t\t\t\tmin = A[source*N + i];\n\t\t\t\t\tcandidate = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (candidate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\tprev[candidate] = source;\n\t\tsource = candidate;\n\t\tvisited[source] = true;\n\t\tlength++;\n\t}\n\treturn length;\n}",
            "if (source < 0 || source >= N || dest < 0 || dest >= N) {\n        return -1;\n    }\n\n    std::vector<int> path(N);\n    path[source] = 0;\n\n    // TODO: implement this function using OpenMP\n\n    return path[dest];\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "serial",
        "prompt": "/* Return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// Write your code here\n    auto& adj = A;\n    int distance = 0;\n    std::queue<int> que;\n    std::vector<bool> visited(N, false);\n    que.push(source);\n    visited[source] = true;\n    \n    while (!que.empty()) {\n        int size = que.size();\n        while (size--) {\n            int node = que.front();\n            que.pop();\n            if (node == dest) return distance;\n            for (int i = 0; i < N; ++i) {\n                if (adj[node * N + i] &&!visited[i]) {\n                    visited[i] = true;\n                    que.push(i);\n                }\n            }\n        }\n        distance++;\n    }\n    \n    return -1;\n}",
            "// Write your code here\n    std::vector<int> dist(N, std::numeric_limits<int>::max());\n    dist[source] = 0;\n    std::vector<int> prev(N, -1);\n    std::vector<bool> in_queue(N, false);\n    std::queue<int> q;\n    q.push(source);\n    in_queue[source] = true;\n    while (!q.empty()) {\n        int cur = q.front();\n        q.pop();\n        in_queue[cur] = false;\n        if (cur == dest)\n            break;\n        for (int i = 0; i < N; i++) {\n            if (A[cur * N + i] && dist[cur]!= std::numeric_limits<int>::max() && dist[i] > dist[cur] + A[cur * N + i]) {\n                dist[i] = dist[cur] + A[cur * N + i];\n                prev[i] = cur;\n                if (!in_queue[i]) {\n                    q.push(i);\n                    in_queue[i] = true;\n                }\n            }\n        }\n    }\n    int len = 0;\n    int cur = dest;\n    while (cur!= -1) {\n        len++;\n        cur = prev[cur];\n    }\n    return len;\n}",
            "auto const is_adjacent = [&A, N](int i, int j) {\n        return A[i * N + j]!= 0;\n    };\n\n    constexpr int MAX_INT = std::numeric_limits<int>::max();\n    std::vector<int> dists(N, MAX_INT);\n    dists[source] = 0;\n\n    std::deque<int> next;\n    next.push_back(source);\n    while (!next.empty()) {\n        auto u = next.front();\n        next.pop_front();\n        for (auto v = 0; v < N; ++v) {\n            if (is_adjacent(u, v) && dists[v] == MAX_INT) {\n                dists[v] = dists[u] + 1;\n                next.push_back(v);\n            }\n        }\n    }\n\n    return dists[dest];\n}",
            "std::vector<int> distances(N, -1);\n  std::vector<bool> in_queue(N, false);\n  std::queue<int> queue;\n\n  queue.push(source);\n  in_queue[source] = true;\n  distances[source] = 0;\n\n  while (!queue.empty()) {\n    int u = queue.front();\n    queue.pop();\n    in_queue[u] = false;\n\n    for (size_t v = 0; v < N; ++v) {\n      if (A[u * N + v] > 0) {\n        if (distances[v] < 0) {\n          queue.push(v);\n          in_queue[v] = true;\n          distances[v] = distances[u] + 1;\n        }\n        else if (distances[v] == distances[u] + 1) {\n          // The shortest path from the source to u has length distances[u] + 1,\n          // and the shortest path from the source to v has length distances[v]\n          // (which is distances[u] + 1).\n          // Therefore the shortest path from the source to v has length\n          // distances[u] + 1, and the distance from u to v is 1.\n          // Since the path from u to v has length 1, the path from source to\n          // v has length distances[u] + 2.\n          distances[v] = distances[u] + 2;\n        }\n      }\n    }\n  }\n\n  if (distances[dest] >= 0)\n    return distances[dest];\n  else\n    return -1;\n}",
            "std::vector<int> dist(N, INT_MAX);\n  std::vector<int> parent(N, -1);\n  dist[source] = 0;\n  for (int i = 0; i < N - 1; ++i) {\n    for (int s = 0; s < N; ++s) {\n      for (int d = 0; d < N; ++d) {\n        if (A[s * N + d] && dist[s]!= INT_MAX && dist[s] + 1 < dist[d]) {\n          dist[d] = dist[s] + 1;\n          parent[d] = s;\n        }\n      }\n    }\n  }\n  return dist[dest];\n}",
            "const std::vector<int> INF = std::vector<int>(N, -1);\n\tstd::vector<int> dist = INF;\n\tstd::vector<int> prev = std::vector<int>(N, -1);\n\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\tdist[source] = 0;\n\n\twhile (!queue.empty()) {\n\t\tint node = queue.front();\n\t\tqueue.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (dist[i] == INF[i] && A[node * N + i]!= 0) {\n\t\t\t\tdist[i] = dist[node] + 1;\n\t\t\t\tprev[i] = node;\n\t\t\t\tqueue.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\tint len = dist[dest];\n\tint node = dest;\n\twhile (node!= source) {\n\t\tnode = prev[node];\n\t\tlen--;\n\t}\n\n\treturn len;\n}",
            "// Your code goes here.\n    if (source == dest) return 0;\n    std::vector<int> distances(N, std::numeric_limits<int>::max());\n    distances[source] = 0;\n    std::vector<int> has_visited(N, 0);\n    std::queue<int> queue;\n    queue.push(source);\n    while (!queue.empty()) {\n        int cur = queue.front();\n        queue.pop();\n        for (int i = 0; i < N; ++i) {\n            if (A[cur * N + i] == 1 && has_visited[i] == 0) {\n                has_visited[i] = 1;\n                distances[i] = distances[cur] + 1;\n                queue.push(i);\n            }\n            if (has_visited[i] == 1 && A[cur * N + i] == 0) {\n                // if we have already visited a neighbor of cur, then\n                // cur must be able to visit its neighbor\n                return std::numeric_limits<int>::max();\n            }\n        }\n    }\n    if (distances[dest] == std::numeric_limits<int>::max()) return -1;\n    return distances[dest];\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> dist(N, -1);\n    std::vector<int> prev(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n\n    while(!q.empty()) {\n        int u = q.front();\n        q.pop();\n\n        if(u == dest)\n            break;\n\n        if(visited[u])\n            continue;\n\n        visited[u] = true;\n        for(int i = 0; i < N; ++i) {\n            if(A[u * N + i] && dist[i] == -1) {\n                dist[i] = dist[u] + 1;\n                prev[i] = u;\n                q.push(i);\n            }\n        }\n    }\n\n    if(dist[dest] == -1)\n        return -1;\n\n    int pathLen = dist[dest];\n    int cur = dest;\n    while(prev[cur]!= -1) {\n        cur = prev[cur];\n        pathLen++;\n    }\n\n    return pathLen;\n}",
            "std::vector<int> parent(N, -1);\n    std::vector<int> distance(N, INT_MAX);\n    distance[source] = 0;\n    bool found = false;\n\n    for (int i = 0; i < N; ++i) {\n        int node = -1;\n        for (int j = 0; j < N; ++j) {\n            if (distance[j] < INT_MAX) {\n                node = j;\n                break;\n            }\n        }\n        if (node == -1) {\n            break;\n        }\n\n        if (node == dest) {\n            found = true;\n            break;\n        }\n\n        for (int j = 0; j < N; ++j) {\n            if (A[node * N + j] == 1 && distance[node] + 1 < distance[j]) {\n                distance[j] = distance[node] + 1;\n                parent[j] = node;\n            }\n        }\n    }\n\n    if (found == false) {\n        return -1;\n    }\n\n    int length = distance[dest];\n\n    std::vector<int> path;\n    int p = dest;\n    while (p!= -1) {\n        path.push_back(p);\n        p = parent[p];\n    }\n\n    std::cout << \"Path: \";\n    for (int i = path.size() - 1; i >= 0; --i) {\n        std::cout << path[i] << \" \";\n    }\n    std::cout << std::endl;\n\n    return length;\n}",
            "// TODO: replace this code with a faster algorithm.\n    std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    std::vector<bool> visited(N, false);\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n\n        if (visited[u]) continue;\n        visited[u] = true;\n\n        for (int v = 0; v < N; v++) {\n            if (A[u * N + v] == 1 && dist[v] > dist[u] + 1) {\n                dist[v] = dist[u] + 1;\n                q.push(v);\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "// TODO: insert your code here\n\tif (source < 0 || dest < 0 || source >= N || dest >= N || A.size()!= N * N)\n\t\tthrow std::invalid_argument(\"Invalid arguments\");\n\t\n\tstd::vector<int> visited(N);\n\tvisited[source] = 1;\n\tstd::queue<int> q;\n\tq.push(source);\n\tint cur, next;\n\twhile (!q.empty()) {\n\t\tcur = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[N * cur + i] == 1 && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t\tif (i == dest)\n\t\t\t\treturn visited[i];\n\t\t}\n\t}\n\treturn -1;\n}",
            "std::vector<int> distances(N, INT_MAX);\n  std::vector<bool> seen(N, false);\n  distances[source] = 0;\n  std::queue<std::pair<int, int>> Q;\n  Q.push(std::make_pair(source, 0));\n  while (!Q.empty()) {\n    auto u = Q.front();\n    Q.pop();\n    if (u.second > distances[u.first]) {\n      continue;\n    }\n    seen[u.first] = true;\n    for (int i = 0; i < N; i++) {\n      if (u.second + A[u.first * N + i] < distances[i]) {\n        distances[i] = u.second + A[u.first * N + i];\n        Q.push(std::make_pair(i, distances[i]));\n      }\n    }\n  }\n  return seen[dest]? distances[dest] : -1;\n}",
            "// Write your code here.\n  if (source == dest) return 0;\n  std::vector<int> dist(N, -1);\n  std::vector<int> parent(N, -1);\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n  while (q.size() > 0) {\n    int node = q.front();\n    q.pop();\n    for (size_t i = 0; i < N; ++i) {\n      if (A[node * N + i]!= 0 && dist[i] == -1) {\n        dist[i] = dist[node] + 1;\n        parent[i] = node;\n        q.push(i);\n      }\n    }\n  }\n  if (dist[dest] == -1) {\n    return -1;\n  }\n  return dist[dest];\n}",
            "/*\n    1. Create a boolean visited array, and initialize all to false\n    2. Create a BFS queue to hold visited nodes.\n    3. Enqueue the source node\n    4. Initialize an integer distance array, and initialize all to -1\n    5. Set distance[source] = 0\n    6. While queue is not empty\n        7. Dequeue the front element\n        8. If it is the destination node, return distance[dest]\n        9. Else\n            For each neighbor i of the dequeued element\n                If i is not visited\n                    Set distance[i] = distance[dequeued] + 1\n                    Set visited[i] = true\n                    Enqueue i\n  */\n\n  if (source == dest)\n    return 0;\n\n  std::vector<bool> visited(N, false);\n  std::queue<int> q;\n  q.push(source);\n  std::vector<int> distance(N, -1);\n  distance[source] = 0;\n\n  while (!q.empty()) {\n    int const v = q.front();\n    q.pop();\n\n    if (v == dest)\n      return distance[dest];\n\n    for (int i = 0; i < N; ++i) {\n      if (A[v * N + i] &&!visited[i]) {\n        visited[i] = true;\n        distance[i] = distance[v] + 1;\n        q.push(i);\n      }\n    }\n  }\n\n  return -1;\n}",
            "int len = -1;\n    if (source == dest) {\n        return 0;\n    }\n    std::vector<std::vector<int>> D;\n    for (int i = 0; i < N; ++i) {\n        std::vector<int> v(N, -1);\n        D.push_back(v);\n    }\n    std::queue<int> q;\n    q.push(source);\n    D[source][source] = 0;\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        for (int u = 0; u < N; ++u) {\n            if (A[v * N + u] == 1) {\n                if (D[u][u] == -1) {\n                    q.push(u);\n                    D[u][u] = D[v][v] + 1;\n                }\n                if (D[u][dest] < 0) {\n                    D[u][dest] = D[v][v] + 1;\n                } else {\n                    D[u][dest] = std::min(D[u][dest], D[v][v] + 1);\n                }\n            }\n        }\n    }\n    return D[dest][dest];\n}",
            "// BFS \ubc29\uc2dd\uc73c\ub85c \ud480\uc774\n    std::queue<int> q;\n    std::vector<bool> visited(N, false);\n    std::vector<int> d(N, -1);\n\n    // \ucd9c\ubc1c\uc9c0 \ud45c\uc2dc\n    q.push(source);\n    visited[source] = true;\n\n    // \ucd5c\ub2e8\uac70\ub9ac\ub97c \ubc18\ud658\ud558\ub294 \ubcc0\uc218\n    int min_length = -1;\n\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n\n        for (int i = 0; i < N; ++i) {\n            if (visited[i]) {\n                continue;\n            }\n\n            if (A[node * N + i]) {\n                q.push(i);\n                visited[i] = true;\n                d[i] = d[node] + 1;\n            }\n        }\n\n        // \ucd5c\ub2e8\uac70\ub9ac \ubc18\ud658\n        if (node == dest) {\n            min_length = d[node];\n            break;\n        }\n    }\n\n    return min_length;\n}",
            "std::vector<int> dist(N, -1);\n    dist[source] = 0;\n\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty()) {\n        auto u = q.front();\n        q.pop();\n\n        auto row = A.begin() + u * N;\n        for (size_t i = 0; i < N; ++i) {\n            if (row[i] == 1) {\n                if (dist[i] == -1) {\n                    dist[i] = dist[u] + 1;\n                    q.push(i);\n                }\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::queue<int> toVisit;\n\ttoVisit.push(source);\n\n\twhile (toVisit.size() > 0) {\n\t\tint node = toVisit.front();\n\t\ttoVisit.pop();\n\t\tif (!visited[node]) {\n\t\t\tvisited[node] = true;\n\t\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\t\tif (!visited[i] && (A[N * node + i] > 0)) {\n\t\t\t\t\tint newDist = dist[node] + A[N * node + i];\n\t\t\t\t\tif (newDist < dist[i]) {\n\t\t\t\t\t\tdist[i] = newDist;\n\t\t\t\t\t\ttoVisit.push(i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "if (source < 0 || source > N - 1 || dest < 0 || dest > N - 1) {\n    return -1;\n  }\n  if (source == dest) {\n    return 0;\n  }\n\n  // Initializing the array with -1 to indicate that the node is not yet\n  // explored\n  std::vector<int> distance(N, -1);\n\n  // Mark the source node as 0 distance\n  distance[source] = 0;\n\n  // Initializing the queue to store the vertex to be explored\n  std::queue<int> q;\n\n  // Enqueuing the source vertex\n  q.push(source);\n\n  // While the queue is not empty, pop the front element and\n  // explore its adjacent nodes\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n\n    for (int v = 0; v < N; v++) {\n      if (A[u * N + v] == 1 && distance[v] < 0) {\n        distance[v] = distance[u] + 1;\n        q.push(v);\n      }\n    }\n  }\n\n  // If we were able to reach the destination return the distance\n  // else return -1 to indicate that no path exists\n  if (distance[dest] < 0) {\n    return -1;\n  }\n\n  return distance[dest];\n}",
            "// write your code here\n\t// return the length of the shortest path from source to dest\n\n\tstd::vector<int> costs(N, INT_MAX);\n\tcosts[source] = 0;\n\tstd::vector<int> next_costs;\n\tnext_costs.reserve(N);\n\n\tbool done = false;\n\twhile (!done) {\n\t\tdone = true;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[N * i + j] && costs[i]!= INT_MAX && costs[i] + 1 < costs[j]) {\n\t\t\t\t\tcosts[j] = costs[i] + 1;\n\t\t\t\t\tdone = false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcosts.swap(next_costs);\n\t\tnext_costs.clear();\n\t\tnext_costs.resize(N, INT_MAX);\n\t}\n\n\treturn (costs[dest] == INT_MAX)? -1 : costs[dest];\n}",
            "if (source == dest) return 0;\n\tstd::vector<int> distance(N, -1);\n\tdistance[source] = 0;\n\n\tstd::queue<int> q;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[u * N + i] == 0 || distance[i] >= 0) continue;\n\t\t\tdistance[i] = distance[u] + 1;\n\t\t\tq.push(i);\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "if (source < 0 || source >= static_cast<int>(N) || dest < 0 || dest >= static_cast<int>(N) ||\n\t\tsource == dest)\n\t{\n\t\tthrow std::runtime_error(\"Invalid source or dest node.\");\n\t}\n\n\tstd::vector<int> distance(N, std::numeric_limits<int>::max());\n\tdistance[source] = 0;\n\n\tstd::vector<int> parents(N, -1);\n\tstd::vector<bool> visited(N, false);\n\n\t// Use BFS to find the shortest path between two nodes.\n\tstd::queue<int> q;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint const v = q.front();\n\t\tq.pop();\n\t\tif (visited[v]) {\n\t\t\tcontinue;\n\t\t}\n\t\tvisited[v] = true;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[v * N + i] == 1) {\n\t\t\t\tif (distance[i] == std::numeric_limits<int>::max()) {\n\t\t\t\t\tdistance[i] = distance[v] + 1;\n\t\t\t\t\tparents[i] = v;\n\t\t\t\t\tq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> path;\n\t// Find the shortest path from source to dest by traversing parents.\n\tfor (int i = dest; i!= source; i = parents[i]) {\n\t\tpath.push_back(i);\n\t}\n\tpath.push_back(source);\n\tstd::reverse(path.begin(), path.end());\n\n\treturn static_cast<int>(path.size()) - 1;\n}",
            "std::vector<int> distance(N, -1);\n  distance[source] = 0;\n  std::vector<int> queue = {source};\n  while (!queue.empty()) {\n    int node = queue.front();\n    queue.erase(queue.begin());\n    if (node == dest) {\n      break;\n    }\n    for (size_t i = 0; i < N; ++i) {\n      if (A[node * N + i] && distance[i] == -1) {\n        distance[i] = distance[node] + 1;\n        queue.push_back(i);\n      }\n    }\n  }\n  return distance[dest];\n}",
            "std::queue<int> q;\n  q.push(source);\n\n  std::vector<bool> visited(N);\n  visited[source] = true;\n  std::vector<int> parents(N, -1);\n\n  while (!q.empty()) {\n    auto cur = q.front();\n    q.pop();\n\n    for (int i = 0; i < N; i++) {\n      if (A[cur * N + i] == 1 &&!visited[i]) {\n        visited[i] = true;\n        q.push(i);\n        parents[i] = cur;\n      }\n    }\n\n    if (cur == dest) {\n      break;\n    }\n  }\n\n  if (!visited[dest]) {\n    return -1;\n  }\n\n  int ans = 0;\n  while (dest!= source) {\n    ans++;\n    dest = parents[dest];\n  }\n\n  return ans;\n}",
            "std::vector<int> distances(N, INT_MAX);\n\tdistances[source] = 0;\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v]!= 0 && distances[v] == INT_MAX) {\n\t\t\t\tq.push(v);\n\t\t\t\tdistances[v] = distances[u] + 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn distances[dest];\n}",
            "// Implement this.\n\tstd::vector<int> distances(N, std::numeric_limits<int>::max());\n\tstd::deque<int> queue;\n\tqueue.push_back(source);\n\tdistances[source] = 0;\n\n\twhile (!queue.empty()) {\n\t\tint current = queue.front();\n\t\tqueue.pop_front();\n\t\tif (current == dest)\n\t\t\tbreak;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[N * current + i] == 1 && distances[i] == std::numeric_limits<int>::max()) {\n\t\t\t\tdistances[i] = distances[current] + 1;\n\t\t\t\tqueue.push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest];\n}",
            "// TODO: implement me!\n    return -1;\n}",
            "// Complete this function\n\tstd::vector<int> dist;\n\tstd::vector<int> pred;\n\t\n\t\n\t//init\n\tfor(size_t i = 0; i < N; i++)\n\t{\n\t\tdist.push_back(INT_MAX);\n\t\tpred.push_back(INT_MIN);\n\t}\n\t\n\tstd::queue<int> q;\n\tq.push(source);\n\tdist[source] = 0;\n\t\n\twhile(!q.empty())\n\t{\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tfor(size_t i = 0; i < N; i++)\n\t\t{\n\t\t\tif(A[u*N + i] == 1 && dist[i] == INT_MAX)\n\t\t\t{\n\t\t\t\tq.push(i);\n\t\t\t\tpred[i] = u;\n\t\t\t\tdist[i] = dist[u] + 1;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t\n\tint u = dest;\n\tint len = dist[u];\n\t\n\twhile(pred[u]!= INT_MIN)\n\t{\n\t\tlen++;\n\t\tu = pred[u];\n\t}\n\t\n\treturn len;\n}",
            "int d[N];\n  for (int i = 0; i < N; ++i) {\n    d[i] = A[i];\n  }\n\n  for (int k = 0; k < N; ++k) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        d[i] = min(d[i], d[j] + A[i][j]);\n      }\n    }\n  }\n\n  return d[source];\n}",
            "std::vector<int> dist(N, INT_MAX);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n    while(!q.empty()) {\n        int u = q.front();\n        q.pop();\n        for(int i = 0; i < N; i++) {\n            if(A[u*N + i] && dist[i] == INT_MAX) {\n                dist[i] = dist[u] + 1;\n                q.push(i);\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "int shortest_path = INT_MAX;\n\t// Initialize the DP table\n\t// dp[source][0] = 1;\n\tstd::vector<std::vector<int>> dp(N, std::vector<int>(N, 0));\n\n\tfor(int i = 0; i < N; i++) {\n\t\tdp[source][i] = 1;\n\t}\n\n\t// Traverse the graph\n\tfor(int step = 1; step < N; step++) {\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tif(A[i * N + j] && dp[i][j]) {\n\t\t\t\t\tdp[i][j] = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Compute the shortest path length\n\tfor(int i = 0; i < N; i++) {\n\t\tif(dp[dest][i]) {\n\t\t\tshortest_path = min(shortest_path, step);\n\t\t}\n\t}\n\n\treturn shortest_path;\n}",
            "std::vector<int> distance(N, -1);\n\tstd::queue<int> q;\n\tq.push(source);\n\tdistance[source] = 0;\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[u * N + i] == 1) {\n\t\t\t\tif (distance[i] == -1) {\n\t\t\t\t\tdistance[i] = distance[u] + 1;\n\t\t\t\t\tq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> B(N, -1);\n\tB[source] = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[N * j + i] && B[j] >= 0 && B[i] < 0) {\n\t\t\t\tB[i] = B[j] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn B[dest];\n}",
            "std::vector<int> minDist(N, INF);\n    std::vector<bool> visited(N, false);\n\n    std::queue<int> q;\n    q.push(source);\n    minDist[source] = 0;\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        if (u == dest) {\n            return minDist[u];\n        }\n        if (visited[u]) continue;\n        visited[u] = true;\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v]) {\n                int alt = minDist[u] + 1;\n                if (alt < minDist[v]) {\n                    minDist[v] = alt;\n                    q.push(v);\n                }\n            }\n        }\n    }\n    return INF;\n}",
            "if (source == dest) return 0;\n    std::vector<std::vector<int>> dist(N, std::vector<int>(N, -1));\n    std::vector<int> parents(N, -1);\n    int cur_dist = 0;\n    std::queue<std::pair<int, int>> queue;\n    queue.emplace(source, 0);\n    dist[source][source] = 0;\n    while (!queue.empty()) {\n        auto [u, dist_u] = queue.front();\n        queue.pop();\n        if (u == dest) return cur_dist;\n        for (int v = 0; v < N; ++v) {\n            if (dist[v][u] == -1) {\n                if (A[v][u] == 1) {\n                    dist[v][u] = dist_u + 1;\n                    dist[u][v] = dist_u + 1;\n                    parents[v] = u;\n                    queue.emplace(v, dist_u + 1);\n                    if (v == dest) {\n                        std::vector<int> path;\n                        while (true) {\n                            if (u == source) {\n                                path.emplace_back(u);\n                                break;\n                            }\n                            path.emplace_back(u);\n                            u = parents[u];\n                        }\n                        std::reverse(path.begin(), path.end());\n                        return path.size();\n                    }\n                }\n            }\n        }\n    }\n    return -1;\n}",
            "std::vector<int> dist(N, -1);\n\n\tdist[source] = 0;\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\tif (A[i*N+j]!= 0 && dist[i]!= -1) {\n\t\t\t\tif (dist[j] == -1) {\n\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t} else {\n\t\t\t\t\tdist[j] = std::min(dist[j], dist[i] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn (dist[dest]!= -1)? dist[dest] : -1;\n}",
            "// create a dist vector of size N and initialize all distances to -1\n\tstd::vector<int> dist(N, -1);\n\n\t// put the source vertex into the queue\n\tstd::queue<int> q;\n\tq.push(source);\n\n\t// keep track of the visited vertices\n\tstd::vector<bool> visited(N, false);\n\tvisited[source] = true;\n\n\twhile (!q.empty()) {\n\t\tint vertex = q.front();\n\t\tq.pop();\n\n\t\tfor (int neighbor = 0; neighbor < N; ++neighbor) {\n\t\t\tif (A[vertex * N + neighbor] == 1 &&!visited[neighbor]) {\n\t\t\t\tq.push(neighbor);\n\t\t\t\tvisited[neighbor] = true;\n\t\t\t\tdist[neighbor] = dist[vertex] + 1;\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "// TODO: implement\n    return 0;\n}",
            "std::vector<bool> seen(N, false);\n    std::vector<int> dist(N, -1);\n    dist[source] = 0;\n    std::vector<int> prev(N, -1);\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        seen[u] = true;\n\n        for (int i = 0; i < N; ++i) {\n            if (A[u * N + i] &&!seen[i]) {\n                q.push(i);\n                dist[i] = dist[u] + 1;\n                prev[i] = u;\n            }\n        }\n    }\n\n    std::vector<int> path;\n    if (dist[dest] < 0) return -1;\n\n    int x = dest;\n    while (prev[x] >= 0) {\n        path.push_back(x);\n        x = prev[x];\n    }\n    path.push_back(x);\n\n    return dist[dest];\n}",
            "// Your code here.\n\tint max_weight = 0;\n\tint min_weight = 0;\n\tint cur_weight = 0;\n\tstd::vector<std::vector<int>> path_cost;\n\tstd::vector<int> min_paths;\n\tfor(int i = 0; i < N; ++i)\n\t{\n\t\tstd::vector<int> cur_path;\n\t\tpath_cost.push_back(cur_path);\n\t\tmin_paths.push_back(INT_MAX);\n\t}\n\tfor(int i = 0; i < N; ++i)\n\t{\n\t\tfor(int j = 0; j < N; ++j)\n\t\t{\n\t\t\tpath_cost[i].push_back(A[i * N + j]);\n\t\t}\n\t}\n\tpath_cost[source][source] = 0;\n\tmin_paths[source] = 0;\n\tfor(int i = 0; i < N; ++i)\n\t{\n\t\tfor(int j = 0; j < N; ++j)\n\t\t{\n\t\t\tif(path_cost[j][j] == 0)\n\t\t\t{\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif(min_paths[j] < INT_MAX)\n\t\t\t{\n\t\t\t\tfor(int k = 0; k < N; ++k)\n\t\t\t\t{\n\t\t\t\t\tif(path_cost[j][k] == 0)\n\t\t\t\t\t{\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tcur_weight = min_paths[j] + path_cost[j][k];\n\t\t\t\t\tif(cur_weight < min_paths[k])\n\t\t\t\t\t{\n\t\t\t\t\t\tmin_paths[k] = cur_weight;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor(int i = 0; i < N; ++i)\n\t{\n\t\tif(min_paths[i] < INT_MAX)\n\t\t{\n\t\t\tif(min_paths[i] > max_weight)\n\t\t\t{\n\t\t\t\tmax_weight = min_paths[i];\n\t\t\t}\n\t\t}\n\t}\n\tif(max_weight == 0)\n\t{\n\t\treturn 0;\n\t}\n\treturn max_weight;\n}",
            "// Fill in the body of the function below\n\t// BFS\n\tstd::vector<int> queue;\n\tqueue.push_back(source);\n\tstd::vector<bool> visited;\n\tvisited.resize(N, false);\n\tvisited[source] = true;\n\tint hops = 0;\n\n\twhile (queue.size() > 0) {\n\t\tint head = queue.front();\n\t\tqueue.erase(queue.begin());\n\t\tif (head == dest) {\n\t\t\treturn hops;\n\t\t}\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[N * head + i] &&!visited[i]) {\n\t\t\t\tqueue.push_back(i);\n\t\t\t\tvisited[i] = true;\n\t\t\t}\n\t\t}\n\t\t++hops;\n\t}\n\treturn -1;\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tstd::deque<int> Q{source};\n\twhile(!Q.empty()) {\n\t\tint curr = Q.front();\n\t\tQ.pop_front();\n\t\tfor(size_t next = 0; next < N; ++next) {\n\t\t\tif(A[curr * N + next] && dist[next] == -1) {\n\t\t\t\tdist[next] = dist[curr] + 1;\n\t\t\t\tif(next == dest) {\n\t\t\t\t\treturn dist[next];\n\t\t\t\t}\n\t\t\t\tQ.push_back(next);\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}",
            "// create an N-size vector to hold the distances to the source\n    // from all other nodes in the graph\n    std::vector<int> dist(N, -1);\n\n    // set the distance to the source as 0\n    dist[source] = 0;\n\n    // create a queue to keep track of the nodes in the graph\n    std::queue<int> q;\n\n    // add the source node to the queue\n    q.push(source);\n\n    // while the queue is not empty\n    while (!q.empty()) {\n\n        // get the node in the front of the queue\n        int node = q.front();\n\n        // remove the front node from the queue\n        q.pop();\n\n        // loop over the neighbors of this node\n        for (int i = 0; i < N; ++i) {\n\n            // only consider the neighbors that haven't been visited yet\n            // and whose distance is -1\n            if (A[node * N + i]!= 0 && dist[i] == -1) {\n\n                // update the distance to the neighbor\n                dist[i] = dist[node] + 1;\n\n                // add the neighbor to the back of the queue\n                q.push(i);\n\n                // if the neighbor is the destination node,\n                // we're done\n                if (i == dest) {\n                    return dist[i];\n                }\n            }\n        }\n    }\n\n    return -1; // no path found\n}",
            "std::vector<int> B(N, 0);\n  B[source] = 1;\n\n  std::queue<int> Q;\n  Q.push(source);\n\n  while (!Q.empty()) {\n    int curr = Q.front();\n    Q.pop();\n\n    for (size_t i = 0; i < N; i++) {\n      if (A[curr * N + i] &&!B[i]) {\n        B[i] = B[curr] + 1;\n        Q.push(i);\n      }\n    }\n  }\n\n  return B[dest];\n}",
            "std::vector<int> length(N, INT_MAX);\n    length[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        for (int u = 0; u < N; ++u) {\n            if (A[v * N + u] && length[u] == INT_MAX) {\n                length[u] = length[v] + 1;\n                q.push(u);\n            }\n        }\n    }\n    return length[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n  bool found = false;\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (A[j * N + i]!= 0 && dist[i]!= INT_MAX && dist[i] + 1 < dist[j])\n        dist[j] = dist[i] + 1;\n    }\n    if (dist[dest]!= INT_MAX) {\n      found = true;\n      break;\n    }\n  }\n  return found? dist[dest] : -1;\n}",
            "std::vector<int> bfs(N, -1);\n\tstd::queue<int> q;\n\tbfs[source] = 0;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint current = q.front();\n\t\tq.pop();\n\t\tfor (int next = 0; next < N; ++next) {\n\t\t\tif (A[current*N + next] == 1 && bfs[next] == -1) {\n\t\t\t\tbfs[next] = bfs[current] + 1;\n\t\t\t\tq.push(next);\n\t\t\t}\n\t\t}\n\t}\n\treturn bfs[dest];\n}",
            "std::vector<int> distances(N, INT_MAX);\n    distances[source] = 0;\n\n    std::vector<bool> visited(N);\n\n    for (size_t i = 0; i < N; ++i) {\n        int currentNode = -1;\n        for (size_t j = 0; j < N; ++j) {\n            if (!visited[j] && (currentNode == -1 || distances[j] < distances[currentNode])) {\n                currentNode = j;\n            }\n        }\n\n        if (currentNode == -1) {\n            break;\n        }\n\n        visited[currentNode] = true;\n\n        for (size_t j = 0; j < N; ++j) {\n            if (!visited[j] && A[currentNode * N + j]!= 0 && distances[currentNode] + 1 < distances[j]) {\n                distances[j] = distances[currentNode] + 1;\n            }\n        }\n    }\n\n    return distances[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n  bool changed = true;\n  for (int i = 0; i < N && changed; i++) {\n    changed = false;\n    for (int j = 0; j < N; j++) {\n      if (dist[j]!= INT_MAX) {\n        for (int k = 0; k < N; k++) {\n          if (A[j * N + k] && dist[k] > dist[j] + 1) {\n            dist[k] = dist[j] + 1;\n            changed = true;\n          }\n        }\n      }\n    }\n  }\n  return dist[dest];\n}",
            "// -----\n    // Compute the length of the shortest path from source to dest.\n    // Use an adjacency matrix A and return the length of the shortest path from source to dest.\n    // -----\n\n    // YOUR CODE HERE\n    int dist[N];\n    int prev[N];\n\n    memset(dist, 0x7f, sizeof(dist));\n    memset(prev, -1, sizeof(prev));\n\n    dist[source] = 0;\n    for (int i = 0; i < N; ++i) {\n        int min_dist = INT_MAX;\n        int min_dist_index = -1;\n        for (int j = 0; j < N; ++j) {\n            if (dist[j] < min_dist) {\n                min_dist = dist[j];\n                min_dist_index = j;\n            }\n        }\n\n        if (min_dist_index == -1)\n            break;\n\n        for (int j = 0; j < N; ++j) {\n            if (A[min_dist_index * N + j] && dist[min_dist_index] + 1 < dist[j]) {\n                dist[j] = dist[min_dist_index] + 1;\n                prev[j] = min_dist_index;\n            }\n        }\n    }\n\n    int path_len = 0;\n    if (prev[dest]!= -1) {\n        int curr = dest;\n        while (curr!= -1) {\n            path_len += 1;\n            curr = prev[curr];\n        }\n    }\n\n    return path_len;\n}",
            "int const INF = std::numeric_limits<int>::max();\n    // Create the distance vector.\n    std::vector<int> distance(N, INF);\n    distance[source] = 0;\n    // Create the color vector.\n    std::vector<int> color(N, 0);\n    color[source] = 1;\n\n    // Perform the breadth-first search.\n    while (color[source]!= N) {\n        for (int i = 0; i < N; ++i) {\n            // Skip visited vertices.\n            if (color[i] == 1) {\n                continue;\n            }\n            // Check the distance to this vertex.\n            if (A[source * N + i] > 0 && distance[source] + A[source * N + i] < distance[i]) {\n                // Update distance and color.\n                distance[i] = distance[source] + A[source * N + i];\n                color[i] = 1;\n            }\n        }\n        // Move the source to the next vertex.\n        color[source] = 2;\n        source = minVertex(distance, color);\n    }\n\n    // Return the distance to the destination.\n    return distance[dest];\n}",
            "int const INF = std::numeric_limits<int>::max();\n\n    std::vector<int> dist(N, INF);\n    dist[source] = 0;\n\n    // BFS\n    for (int i = 0; i < N; i++) {\n        int u = -1;\n        for (int v = 0; v < N; v++) {\n            if (dist[v] == i) {\n                u = v;\n                break;\n            }\n        }\n        if (u == -1)\n            break;\n        for (int v = 0; v < N; v++) {\n            if (dist[v] > dist[u] + A[u * N + v]) {\n                dist[v] = dist[u] + A[u * N + v];\n            }\n        }\n    }\n    return dist[dest];\n}",
            "auto distance = std::vector<int>(N, std::numeric_limits<int>::max());\n    distance[source] = 0;\n    std::vector<bool> visited(N, false);\n    std::deque<int> deq;\n    deq.push_back(source);\n    while (not deq.empty()) {\n        int node = deq.front();\n        deq.pop_front();\n        if (visited[node]) {\n            continue;\n        }\n        visited[node] = true;\n        for (size_t i = 0; i < N; ++i) {\n            if (A[node * N + i]) {\n                if (distance[node] + 1 < distance[i]) {\n                    distance[i] = distance[node] + 1;\n                }\n                deq.push_back(i);\n            }\n        }\n    }\n    return distance[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n\n    std::vector<bool> visited(N, false);\n    std::queue<int> Q;\n    Q.push(source);\n\n    while (!Q.empty()) {\n        int node = Q.front();\n        Q.pop();\n        visited[node] = true;\n\n        for (int i = 0; i < N; i++) {\n            if (visited[i]) {\n                continue;\n            }\n            if (A[node * N + i] > 0) {\n                if (dist[i] > dist[node] + 1) {\n                    dist[i] = dist[node] + 1;\n                    Q.push(i);\n                }\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tstd::vector<int> path(N, -1);\n\n\t// BFS\n\tstd::queue<int> Q;\n\tQ.push(source);\n\n\twhile (!Q.empty()) {\n\n\t\tint x = Q.front();\n\t\tQ.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\n\t\t\tif (A[x * N + i] > 0) {\n\t\t\t\tif (dist[i] < 0) {\n\t\t\t\t\tdist[i] = dist[x] + 1;\n\t\t\t\t\tpath[i] = x;\n\t\t\t\t\tQ.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Backtrack from dest to source\n\tint i = dest;\n\tint pathLength = 0;\n\twhile (i!= source) {\n\t\tpathLength++;\n\t\ti = path[i];\n\t}\n\n\treturn pathLength;\n}",
            "if (source == dest) return 0;\n    int min_distance = 1e5;\n\n    // Create a visited matrix.\n    std::vector<bool> visited(N, false);\n\n    // Create a queue for BFS and enqueue source node.\n    std::queue<int> queue;\n    queue.push(source);\n\n    // Enqueue source node in visited and initialize its distance as 0.\n    visited[source] = true;\n\n    while (!queue.empty()) {\n        // Dequeue a vertex from queue and print it.\n        auto current = queue.front();\n        queue.pop();\n\n        // Get all adjacent vertices of the dequeued vertex s. If a adjacent has not been visited, then mark it visited and enqueue it.\n        for (size_t i = 0; i < N; i++) {\n            if (A[current * N + i] == 1 &&!visited[i]) {\n                if (i == dest) {\n                    min_distance = std::min(min_distance, 1);\n                }\n                visited[i] = true;\n                queue.push(i);\n            }\n        }\n    }\n    return min_distance == 1e5? -1 : min_distance;\n}",
            "std::vector<int> dist(N, -1);\n    std::queue<int> q;\n\n    q.push(source);\n    dist[source] = 0;\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        for (int i = 0; i < N; ++i) {\n            if (dist[i] == -1 && A[v * N + i]!= 0) {\n                dist[i] = dist[v] + 1;\n                q.push(i);\n            }\n        }\n    }\n\n    return dist[dest] == -1? -1 : dist[dest];\n}",
            "if (source == dest)\n\t\treturn 0;\n\tstd::vector<std::pair<int, int>> Q(N, {0, 0});\n\tint n = 1;\n\tint front = 0;\n\tint back = 1;\n\tQ[0] = {source, 0};\n\twhile (front < back) {\n\t\tauto& [cur, depth] = Q[front++];\n\t\tif (cur == dest)\n\t\t\treturn depth;\n\t\tfor (int nxt = 0; nxt < N; ++nxt) {\n\t\t\tif (A[cur * N + nxt] == 1) {\n\t\t\t\tif (n == N)\n\t\t\t\t\treturn -1;\n\t\t\t\tQ[back++] = {nxt, depth + 1};\n\t\t\t\t++n;\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}",
            "// Dijkstra's algorithm\n\tstd::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\n\t// Priority queue\n\tstd::priority_queue<int, std::vector<int>, std::greater<int>> pq;\n\tpq.push(source);\n\n\twhile(!pq.empty()) {\n\t\tint u = pq.top();\n\t\tpq.pop();\n\n\t\tfor(int i=0; i<N; ++i) {\n\t\t\tif(A[u*N + i] == 1) {\n\t\t\t\tif(dist[i] > dist[u] + 1) {\n\t\t\t\t\tdist[i] = dist[u] + 1;\n\t\t\t\t\tpq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "if(source == dest)\n        return 0;\n\n    std::queue<int> q;\n    q.push(source);\n\n    std::vector<int> distances(N, -1);\n    distances[source] = 0;\n\n    while(!q.empty()) {\n        auto current = q.front();\n        q.pop();\n        for(auto i = 0; i < N; ++i) {\n            if(A[current*N + i] == 0)\n                continue;\n            if(distances[i]!= -1)\n                continue;\n            distances[i] = distances[current] + 1;\n            q.push(i);\n        }\n    }\n\n    return distances[dest];\n}",
            "int result = 0;\n    std::vector<int> dist(N, -1);\n    dist[source] = 0;\n    std::queue<int> Q;\n    Q.push(source);\n\n    while (!Q.empty()) {\n        auto v = Q.front();\n        Q.pop();\n\n        for (size_t i = 0; i < N; i++) {\n            if (A[v * N + i] == 1 && dist[i] == -1) {\n                dist[i] = dist[v] + 1;\n                Q.push(i);\n                if (i == dest) {\n                    result = dist[i];\n                    break;\n                }\n            }\n        }\n    }\n\n    return result;\n}",
            "std::vector<int> dists(N, -1);\n\tstd::vector<bool> in_queue(N, false);\n\tstd::queue<int> q;\n\tq.push(source);\n\tin_queue[source] = true;\n\tdists[source] = 0;\n\n\tint dist = 0;\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\t\tin_queue[node] = false;\n\n\t\tif (node == dest)\n\t\t\tbreak;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node * N + i] == 1) {\n\t\t\t\tif (dists[i] == -1) {\n\t\t\t\t\tq.push(i);\n\t\t\t\t\tin_queue[i] = true;\n\t\t\t\t\tdists[i] = dists[node] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tdist++;\n\t}\n\n\treturn dist;\n}",
            "if (source == dest) return 0;\n\t\n\t// find all paths\n\tstd::vector<int> shortest_paths(N, -1);\n\tshortest_paths[source] = 0;\n\t\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\t\n\twhile (!queue.empty()) {\n\t\tint current = queue.front();\n\t\tqueue.pop();\n\t\t\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[current * N + i] == 0 || shortest_paths[i]!= -1) continue;\n\t\t\t\n\t\t\tshortest_paths[i] = shortest_paths[current] + 1;\n\t\t\tqueue.push(i);\n\t\t}\n\t}\n\t\n\tif (shortest_paths[dest] == -1) return -1;\n\telse return shortest_paths[dest];\n}",
            "int length = -1;\n\tif (source < 0 || source >= N || dest < 0 || dest >= N)\n\t\treturn length;\n\n\tstd::vector<int> dis(N, -1);\n\tdis[source] = 0;\n\tstd::vector<bool> vis(N, false);\n\tstd::vector<int> cur_node;\n\tcur_node.push_back(source);\n\twhile (cur_node.size()) {\n\t\tint cur = cur_node.back();\n\t\tcur_node.pop_back();\n\t\tif (cur == dest) {\n\t\t\tlength = dis[dest];\n\t\t\tbreak;\n\t\t}\n\t\tif (vis[cur])\n\t\t\tcontinue;\n\t\tvis[cur] = true;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[cur * N + i]) {\n\t\t\t\tif (dis[i] < 0) {\n\t\t\t\t\tcur_node.push_back(i);\n\t\t\t\t\tdis[i] = dis[cur] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn length;\n}",
            "if (N == 0) {\n\t\treturn -1;\n\t}\n\n\tstd::vector<int> distances(N, -1);\n\tdistances[source] = 0;\n\n\tstd::queue<int> toVisit;\n\ttoVisit.push(source);\n\n\twhile (!toVisit.empty()) {\n\t\tint current = toVisit.front();\n\t\ttoVisit.pop();\n\n\t\tif (current == dest) {\n\t\t\tbreak;\n\t\t}\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[current * N + i] == 1 && distances[i] == -1) {\n\t\t\t\tdistances[i] = distances[current] + 1;\n\t\t\t\ttoVisit.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest];\n}",
            "// write your code here\n  std::vector<std::vector<int>> matrix(N, std::vector<int>(N));\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      matrix[i][j] = A[i * N + j];\n    }\n  }\n  std::vector<int> dist(N, -1);\n  std::vector<int> parent(N);\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n  parent[source] = -1;\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n    for (int i = 0; i < N; i++) {\n      if (matrix[u][i] && dist[i] == -1) {\n        dist[i] = dist[u] + 1;\n        parent[i] = u;\n        q.push(i);\n      }\n    }\n  }\n  int path = -1;\n  int u = dest;\n  while (u >= 0) {\n    path = std::max(path, dist[u]);\n    u = parent[u];\n  }\n  return path;\n}",
            "// write your code here\n\tstd::vector<int> dist(N, -1);\n\tstd::vector<int> prev(N, -1);\n\tstd::vector<int> visited(N, 0);\n\n\tdist[source] = 0;\n\tprev[source] = -1;\n\tvisited[source] = 1;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (visited[j] == 0 && dist[j] == -1) {\n\t\t\t\tdist[j] = dist[prev[j]] + 1;\n\t\t\t\tprev[j] = i;\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t\tif (A[i * N + j]!= 0) {\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] == -1) {\n\t\treturn -1;\n\t}\n\n\treturn dist[dest];\n}",
            "using T = std::vector<int>::const_iterator;\n\n    std::vector<int> distances(N, INT_MAX);\n\n    // Bellman-Ford relaxation to find the shortest paths.\n    distances[source] = 0;\n    for (int i = 0; i < N - 1; i++) {\n        for (size_t u = 0; u < N; u++) {\n            for (size_t v = 0; v < N; v++) {\n                if (A[u * N + v]!= 0) {\n                    if (distances[u]!= INT_MAX) {\n                        if (distances[v] > distances[u] + A[u * N + v]) {\n                            distances[v] = distances[u] + A[u * N + v];\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    return distances[dest];\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> depth(N, -1);\n\n  std::queue<int> q;\n  q.push(source);\n\n  while (!q.empty()) {\n    auto u = q.front();\n    q.pop();\n\n    for (auto v = 0; v < N; ++v) {\n      if (A[u * N + v] == 1 &&!visited[v]) {\n        q.push(v);\n        visited[v] = true;\n        depth[v] = depth[u] + 1;\n      }\n    }\n  }\n\n  return depth[dest];\n}",
            "std::queue<int> q;\n    std::vector<int> distances(N, INT_MAX);\n    q.push(source);\n    distances[source] = 0;\n    while (!q.empty()) {\n        int current = q.front();\n        q.pop();\n        if (current == dest) {\n            return distances[current];\n        }\n        for (int next : reachable(A, current, N)) {\n            if (distances[next] > distances[current] + 1) {\n                q.push(next);\n                distances[next] = distances[current] + 1;\n            }\n        }\n    }\n    return -1;\n}",
            "std::vector<int> distances(N, -1);\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\tdistances[source] = 0;\n\n\twhile (!queue.empty()) {\n\t\tint v = queue.front();\n\t\tqueue.pop();\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[v * N + i] == 1 && distances[i] == -1) {\n\t\t\t\tdistances[i] = distances[v] + 1;\n\t\t\t\tqueue.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest];\n}",
            "std::vector<int> distance(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    distance[source] = 0;\n\n    while (!q.empty()) {\n        int vertex = q.front();\n        q.pop();\n        for (int i = 0; i < N; ++i) {\n            if (A[vertex * N + i] == 1 && distance[i] == -1) {\n                q.push(i);\n                distance[i] = distance[vertex] + 1;\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tstd::queue<int> Q;\n\tQ.push(source);\n\n\twhile (!Q.empty()) {\n\t\tint u = Q.front();\n\t\tQ.pop();\n\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v] && dist[v] == -1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tQ.push(v);\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "if (source == dest) {\n      return 0;\n   }\n\n   // Create a set of integers to keep track of which vertices have been visited\n   std::set<int> visited;\n\n   // Create a queue for the BFS\n   std::queue<int> q;\n\n   // Insert the source vertex into the queue\n   q.push(source);\n\n   // Set the initial distance to all vertices to -1\n   std::vector<int> distance(N, -1);\n\n   // Set the source distance to 0\n   distance[source] = 0;\n\n   // While the queue is not empty\n   while (q.size() > 0) {\n\n      // Get the first element in the queue\n      int u = q.front();\n      q.pop();\n\n      // Add the vertex to the visited set\n      visited.insert(u);\n\n      // For each neighbor of u\n      for (int v = 0; v < N; v++) {\n         if (A[u * N + v] == 1) {\n\n            // If v has not been visited, add it to the queue and set its distance to one more than the distance of its parent\n            if (visited.count(v) == 0) {\n               q.push(v);\n               distance[v] = distance[u] + 1;\n            }\n\n            // If v has been visited but has a shorter distance than u's neighbor, set the shorter distance\n            else if (distance[v] > distance[u] + 1) {\n               distance[v] = distance[u] + 1;\n            }\n         }\n      }\n   }\n\n   return distance[dest];\n}",
            "// Implementation here\n\n\tstd::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\t\n\tstd::queue<int> bfs;\n\tbfs.push(source);\n\twhile (!bfs.empty()) {\n\t\tint u = bfs.front();\n\t\tbfs.pop();\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u*N + v] == 1 && dist[v] == -1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tbfs.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "// Write your code here\n\tif (source == dest)\n\t\treturn 0;\n\tstd::vector<int> dist = std::vector<int>(N, 0);\n\tstd::vector<bool> visited = std::vector<bool>(N, false);\n\tstd::vector<int> parent = std::vector<int>(N, 0);\n\tstd::vector<bool> inQueue = std::vector<bool>(N, false);\n\tstd::queue<int> Q;\n\tQ.push(source);\n\tvisited[source] = true;\n\tinQueue[source] = true;\n\twhile (Q.size()) {\n\t\tint u = Q.front();\n\t\tQ.pop();\n\t\tinQueue[u] = false;\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v] &&!visited[v]) {\n\t\t\t\tvisited[v] = true;\n\t\t\t\tparent[v] = u;\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tQ.push(v);\n\t\t\t\tinQueue[v] = true;\n\t\t\t}\n\t\t}\n\t}\n\tif (!visited[dest])\n\t\treturn -1;\n\telse {\n\t\tint u = dest;\n\t\tstd::vector<int> path;\n\t\twhile (u!= -1) {\n\t\t\tpath.push_back(u);\n\t\t\tu = parent[u];\n\t\t}\n\t\treturn dist[dest];\n\t}\n}",
            "// Create a queue of vertex indices to be processed and\n  // an empty set of discovered vertices.\n  std::queue<int> q;\n  std::unordered_set<int> discovered{source};\n\n  // Create a vector of distances from source to the other vertices.\n  std::vector<int> dists(N, std::numeric_limits<int>::max());\n  dists[source] = 0;\n\n  // Add the source vertex to the queue.\n  q.push(source);\n\n  while (!q.empty()) {\n    // Get the next vertex from the queue.\n    int const u = q.front();\n    q.pop();\n\n    // Get the outgoing neighbors of the current vertex.\n    auto const neighbors = getOutNeighbors(A, N, u);\n\n    for (auto const v : neighbors) {\n      // If the destination has already been reached,\n      // return the distance to it.\n      if (v == dest)\n        return dists[v];\n\n      // If the destination has not yet been discovered,\n      // add it to the queue and the set of discovered vertices.\n      if (discovered.count(v) == 0) {\n        discovered.insert(v);\n        q.push(v);\n\n        // Set the distance to the current vertex.\n        dists[v] = dists[u] + 1;\n      }\n    }\n  }\n\n  // Return -1 if the destination has not been reached.\n  return -1;\n}",
            "if (source == dest) return 0;\n\t// 1. Find shortest path from each vertex to dest\n\tstd::vector<int> dist(N, -1);\n\tdist[dest] = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (dist[j] == -1) continue;\n\t\t\tif (A[j * N + i] == 0) continue;\n\t\t\tdist[j] = std::min(dist[j], dist[i] + 1);\n\t\t}\n\t}\n\t// 2. Find shortest path from each vertex to source\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 0) continue;\n\t\t\tif (dist[i] == -1) continue;\n\t\t\tif (dist[j] == -1) continue;\n\t\t\tdist[j] = std::min(dist[j], dist[i] + 1);\n\t\t}\n\t}\n\t// 3. Find shortest path from source to dest\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (dist[i] == -1) continue;\n\t\tif (A[source * N + i] == 0) continue;\n\t\tif (dist[i] + 1 > dist[dest]) continue;\n\t\tdist[dest] = std::min(dist[dest], dist[i] + 1);\n\t}\n\treturn dist[dest];\n}",
            "std::vector<int> dist(N);\n  for (int i = 0; i < N; i++) {\n    dist[i] = 0;\n  }\n  dist[source] = 1;\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[N * j + i] == 1) {\n        dist[j] += dist[i];\n      }\n    }\n  }\n  return dist[dest];\n}",
            "std::queue<int> q;\n\tq.push(source);\n\n\tstd::vector<int> visited(N, 0);\n\n\tvisited[source] = 1;\n\tint distance = 0;\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node * N + i] == 1 && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t\tif (visited[dest] == 1)\n\t\t\t\treturn distance;\n\t\t}\n\t\tdistance++;\n\t}\n\n\treturn -1;\n}",
            "std::vector<std::vector<bool>> reachable(N, std::vector<bool>(N, false));\n\n\tstd::queue<std::tuple<int, int, int>> q;\n\tq.push(std::make_tuple(source, source, 0));\n\treachable[source][source] = true;\n\n\tint minLen = std::numeric_limits<int>::max();\n\twhile (!q.empty()) {\n\t\tstd::tuple<int, int, int> t = q.front();\n\t\tq.pop();\n\n\t\tint x = std::get<0>(t);\n\t\tint y = std::get<1>(t);\n\t\tint len = std::get<2>(t);\n\n\t\tif (x == dest) {\n\t\t\tminLen = std::min(minLen, len);\n\t\t\tcontinue;\n\t\t}\n\n\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\tif (reachable[x][k] == false && A[x][k] == 1) {\n\t\t\t\tq.push(std::make_tuple(k, y, len + 1));\n\t\t\t\treachable[x][k] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn minLen == std::numeric_limits<int>::max()? -1 : minLen;\n}",
            "// write your code here\n  std::vector<int> dist(N, -1);\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n  while(!q.empty()) {\n    int curr = q.front();\n    q.pop();\n    for(size_t i=0; i<N; ++i) {\n      if(A[curr*N+i] == 1 && dist[i] == -1) {\n        dist[i] = dist[curr] + 1;\n        q.push(i);\n      }\n    }\n  }\n  return dist[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n    dist[source] = 0;\n    std::vector<bool> visited(N, false);\n    while (std::any_of(visited.begin(), visited.end(), [](bool b) { return!b; })) {\n        int u = std::distance(visited.begin(), std::find(visited.begin(), visited.end(), false));\n        visited[u] = true;\n        for (size_t v = 0; v < N; ++v) {\n            if (A[u * N + v]) {\n                dist[v] = std::min(dist[v], dist[u] + 1);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "std::vector<std::vector<int>> g(N);\n    for (size_t i = 0; i < N; i++) {\n        g[i].resize(N);\n        for (size_t j = 0; j < N; j++) {\n            g[i][j] = A[N * i + j];\n        }\n    }\n\n    // A queue of vertices to visit.\n    std::vector<int> queue;\n\n    // A vector of distances to each vertex.\n    std::vector<int> dist(N, -1);\n\n    // The distance from source to source is 0.\n    dist[source] = 0;\n\n    // We start by visiting only the source vertex.\n    queue.push_back(source);\n\n    // For every vertex in the queue, visit all of its neighbors.\n    while (!queue.empty()) {\n        int v = queue.back();\n        queue.pop_back();\n        for (int w : g[v]) {\n            // If we haven't yet visited w, or if we've found a shorter path to w, then mark w as visited and enqueue it.\n            if (dist[w] == -1 || dist[w] > dist[v] + 1) {\n                dist[w] = dist[v] + 1;\n                queue.push_back(w);\n            }\n        }\n    }\n\n    // If we've visited all of the vertices without finding a path to the destination, then there is no path.\n    if (dist[dest] == -1) {\n        return -1;\n    }\n\n    // Otherwise, return the distance to the destination.\n    return dist[dest];\n}",
            "// BFS search from source\n    std::vector<int> dist(N, -1);\n    std::vector<bool> visited(N, false);\n    dist[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n    while (!q.empty()) {\n        int u = q.front(); q.pop();\n        visited[u] = true;\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v]) {\n                if (dist[v] == -1) {\n                    dist[v] = dist[u] + 1;\n                    q.push(v);\n                }\n            }\n        }\n    }\n\n    // Find shortest path\n    int dist_min = -1;\n    for (int u = 0; u < N; ++u) {\n        if (A[u * N + dest]) {\n            if (visited[u]) {\n                if (dist[u] < dist_min || dist_min == -1)\n                    dist_min = dist[u];\n            }\n        }\n    }\n\n    // Return result\n    if (dist_min == -1)\n        return -1;\n    else\n        return dist_min;\n}",
            "if (N == 0 || N > 100) throw std::length_error(\"bad length for N\");\n  if (source < 0 || source >= N) throw std::length_error(\"bad value for source\");\n  if (dest < 0 || dest >= N) throw std::length_error(\"bad value for dest\");\n  if (A.size()!= N*N) throw std::length_error(\"bad size for adjacency matrix\");\n\n  // your code here\n  int cur = source, prev = -1, count = 0;\n  std::vector<int> visited(N, 0);\n  while (cur!= dest)\n  {\n    if (cur == prev)\n      return -1;\n    prev = cur;\n    ++count;\n    if (visited[cur] > 0)\n      break;\n    visited[cur] = 1;\n    for (int i = 0; i < N; ++i)\n    {\n      if (A[cur * N + i] == 1 &&!visited[i])\n        cur = i;\n    }\n  }\n  return count;\n}",
            "// Write your code here\n    if (source == dest)\n    {\n        return 0;\n    }\n    if (A[source][dest] == 0)\n    {\n        return -1;\n    }\n    std::vector<int> dis(N, INT_MAX);\n    std::vector<int> pred(N, -1);\n    dis[source] = 0;\n    for (int i = 0; i < N; i++)\n    {\n        int u = -1;\n        for (int j = 0; j < N; j++)\n        {\n            if (dis[j] < INT_MAX && (u == -1 || dis[j] < dis[u]))\n            {\n                u = j;\n            }\n        }\n        if (u == -1)\n        {\n            return -1;\n        }\n        dis[u] = INT_MAX;\n        for (int v = 0; v < N; v++)\n        {\n            if (A[u][v]!= 0 && dis[v] > dis[u] + A[u][v])\n            {\n                dis[v] = dis[u] + A[u][v];\n                pred[v] = u;\n            }\n        }\n    }\n    int v = dest;\n    int pathLength = dis[dest];\n    while (v!= source)\n    {\n        pathLength++;\n        v = pred[v];\n    }\n    return pathLength;\n}",
            "std::vector<int> dist(N);\n\tstd::vector<int> prev(N);\n\tstd::fill(std::begin(dist), std::end(dist), std::numeric_limits<int>::max());\n\tstd::fill(std::begin(prev), std::end(prev), -1);\n\n\tstd::queue<int> q;\n\tq.push(source);\n\tdist[source] = 0;\n\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\t\tif (v == dest) {\n\t\t\tbreak;\n\t\t}\n\t\tif (dist[v] >= 0) {\n\t\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\t\tif (A[v * N + i]!= 0) {\n\t\t\t\t\tif (dist[i] > dist[v] + 1) {\n\t\t\t\t\t\tdist[i] = dist[v] + 1;\n\t\t\t\t\t\tprev[i] = v;\n\t\t\t\t\t}\n\t\t\t\t\tif (dist[i] == dist[v] + 1) {\n\t\t\t\t\t\tif (prev[i] < 0 || prev[i] == v) {\n\t\t\t\t\t\t\tprev[i] = v;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] == std::numeric_limits<int>::max()) {\n\t\treturn -1;\n\t}\n\treturn dist[dest];\n}",
            "if (source == dest)\n        return 0;\n\n    std::vector<int> dist(N, -1);\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty()) {\n        auto u = q.front();\n        q.pop();\n\n        for (size_t v = 0; v < N; ++v) {\n            if (A[u * N + v] == 1 && dist[v] == -1) {\n                dist[v] = dist[u] + 1;\n                q.push(v);\n                if (v == dest)\n                    return dist[v];\n            }\n        }\n    }\n\n    return -1;\n}",
            "std::vector<int> distance(N, std::numeric_limits<int>::max());\n\tdistance[source] = 0;\n\tstd::queue<int> Q;\n\tQ.push(source);\n\twhile (!Q.empty()) {\n\t\tauto u = Q.front();\n\t\tQ.pop();\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v]!= 0 && distance[v] > distance[u] + 1) {\n\t\t\t\tdistance[v] = distance[u] + 1;\n\t\t\t\tQ.push(v);\n\t\t\t}\n\t\t}\n\t}\n\treturn distance[dest];\n}",
            "std::vector<int> distance(N, INT_MAX);\n    std::vector<bool> inQueue(N, false);\n    distance[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n    inQueue[source] = true;\n    while (!q.empty()) {\n        auto curr = q.front();\n        q.pop();\n        inQueue[curr] = false;\n        for (auto next : A[curr]) {\n            if (distance[next] > distance[curr] + 1) {\n                distance[next] = distance[curr] + 1;\n                if (!inQueue[next]) {\n                    q.push(next);\n                    inQueue[next] = true;\n                }\n            }\n        }\n    }\n    return distance[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\tfor (size_t i = 0; i < N - 1; ++i) {\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\tif (A[j * N + k] && dist[k]!= INT_MAX) {\n\t\t\t\t\tdist[j] = std::min(dist[j], dist[k] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "if (source == dest) return 0;\n\n    std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n\n    std::priority_queue<std::pair<int, int>, std::vector<std::pair<int, int>>, std::greater<std::pair<int, int>>> queue;\n    queue.push({dist[source], source});\n\n    while (!queue.empty()) {\n        auto node = queue.top();\n        queue.pop();\n\n        for (int v = 0; v < N; ++v) {\n            if (A[node.second * N + v] == 0) continue;\n            if (dist[v] > dist[node.second] + 1) {\n                dist[v] = dist[node.second] + 1;\n                queue.push({dist[v], v});\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "const int n = N;\n\tconst int INF = 1e6;\n\n\tstd::vector<int> dist(n, INF);\n\tdist[source] = 0;\n\n\tstd::vector<int> prev(n, -1);\n\n\tfor (int i = 0; i < n; i++) {\n\t\tint u = -1;\n\t\tfor (int v = 0; v < n; v++) {\n\t\t\tif (dist[v] < INF && (u == -1 || dist[v] < dist[u])) {\n\t\t\t\tu = v;\n\t\t\t}\n\t\t}\n\t\tif (u == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\tdist[u] = INF;\n\t\tfor (int v = 0; v < n; v++) {\n\t\t\tif (A[u*n + v] && dist[v] > dist[u] + A[u*n + v]) {\n\t\t\t\tdist[v] = dist[u] + A[u*n + v];\n\t\t\t\tprev[v] = u;\n\t\t\t}\n\t\t}\n\t}\n\n\t// reconstruct path\n\tstd::vector<int> path;\n\tint v = dest;\n\twhile (prev[v]!= -1) {\n\t\tpath.push_back(v);\n\t\tv = prev[v];\n\t}\n\tpath.push_back(v);\n\n\tstd::reverse(path.begin(), path.end());\n\n\t// print path\n\tfor (int i = 0; i < path.size(); i++) {\n\t\tstd::cout << path[i] << \" \";\n\t}\n\tstd::cout << std::endl;\n\n\treturn dist[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tauto cur = q.front();\n\t\tq.pop();\n\t\tif (cur == dest)\n\t\t\treturn dist[cur];\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[cur * N + j]) {\n\t\t\t\tif (dist[j] == INT_MAX) {\n\t\t\t\t\tdist[j] = dist[cur] + 1;\n\t\t\t\t\tq.push(j);\n\t\t\t\t} else if (dist[j] > dist[cur] + 1) {\n\t\t\t\t\tdist[j] = dist[cur] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn INT_MAX;\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> distance(N, std::numeric_limits<int>::max());\n    std::vector<int> parent(N, -1);\n    std::vector<std::queue<int>> queues(N);\n\n    queues[source].push(source);\n    distance[source] = 0;\n    visited[source] = true;\n\n    while (!queues.empty()) {\n        int current = queues.back().front();\n        queues.back().pop();\n        if (current == dest) {\n            return distance[dest];\n        }\n        for (int neighbor = 0; neighbor < N; ++neighbor) {\n            if (A[current * N + neighbor] &&!visited[neighbor]) {\n                queues[neighbor].push(neighbor);\n                distance[neighbor] = distance[current] + 1;\n                parent[neighbor] = current;\n                visited[neighbor] = true;\n            }\n        }\n        if (queues.back().empty()) {\n            queues.pop_back();\n        }\n    }\n\n    return -1;\n}",
            "// The BFS algorithm.\n\tint min_distance = -1;\n\tstd::vector<int> dist(N, -1);\n\tstd::queue<int> q;\n\tq.push(source);\n\tdist[source] = 0;\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v] == 1 && dist[v] == -1) {\n\t\t\t\tq.push(v);\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tif (v == dest) {\n\t\t\t\t\tmin_distance = dist[v];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn min_distance;\n}",
            "int d[N];\n    std::fill(d, d + N, -1);\n    d[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n    while (!q.empty()) {\n        auto u = q.front();\n        q.pop();\n        auto u_dist = d[u];\n        for (int i = 0; i < N; i++) {\n            if (A[u * N + i] && d[i] == -1) {\n                d[i] = u_dist + 1;\n                q.push(i);\n            }\n        }\n    }\n    return d[dest];\n}",
            "// Your code here\n    std::vector<int> dp(N, INT_MAX);\n    dp[source] = 0;\n    \n    for(int i=0;i<N;++i){\n        for(int j=0;j<N;++j){\n            if(A[N*i+j]){\n                dp[j]=std::min(dp[i]+1, dp[j]);\n            }\n        }\n    }\n    return dp[dest];\n}",
            "int const INF = 1 << 30;\n    std::vector<int> dists(N, INF);\n    std::deque<int> q;\n    q.push_back(source);\n    dists[source] = 0;\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop_front();\n\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] && dists[v] > dists[u] + 1) {\n                dists[v] = dists[u] + 1;\n                q.push_back(v);\n            }\n        }\n    }\n\n    return dists[dest];\n}",
            "using Edge = std::tuple<int, int, int>;\n\n    auto isValidVertex = [N](int v) { return v >= 0 && v < N; };\n    auto isValidEdge = [N](int a, int b) { return a!= b && isValidVertex(a) && isValidVertex(b); };\n    auto getWeight = [&A, N](int a, int b) { return A[a * N + b]; };\n    auto buildEdge = [&getWeight, &isValidEdge](int a, int b) {\n        if (isValidEdge(a, b))\n            return Edge{a, b, getWeight(a, b)};\n        return std::nullopt;\n    };\n\n    std::vector<int> weights(N, std::numeric_limits<int>::max());\n    weights[source] = 0;\n\n    std::vector<int> predecessors(N, -1);\n    std::vector<std::vector<int>> queue(N, std::vector<int>{});\n    auto push = [&queue](int vertex) { queue[vertex].push_back(vertex); };\n\n    std::deque<Edge> edges{};\n    for (int u = 0; u < N; ++u) {\n        for (int v = 0; v < N; ++v) {\n            auto edge = buildEdge(u, v);\n            if (edge.has_value())\n                edges.push_back(edge.value());\n        }\n    }\n\n    auto pop = [&queue]() {\n        auto i = queue[queue.size() - 1].begin();\n        int u = *i;\n        queue[queue.size() - 1].erase(i);\n        if (queue[queue.size() - 1].size() == 0)\n            queue.pop_back();\n        return u;\n    };\n\n    while (!edges.empty()) {\n        auto edge = edges.front();\n        edges.pop_front();\n\n        auto [a, b, weight] = edge;\n        if (weights[b] == std::numeric_limits<int>::max()) {\n            weights[b] = weight + weights[a];\n            predecessors[b] = a;\n            push(b);\n        }\n\n        if (predecessors[a] == b) {\n            while (a!= b) {\n                a = predecessors[a];\n                if (weights[a] == std::numeric_limits<int>::max()) {\n                    weights[a] = weight + weights[b];\n                    predecessors[a] = b;\n                    push(a);\n                }\n            }\n        }\n    }\n\n    return weights[dest];\n}",
            "if (source == dest) {\n\t\treturn 0;\n\t}\n\tstd::vector<std::vector<int>> dist(N, std::vector<int>(N, INF));\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[source][i] = A[source * N + i];\n\t}\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tdist[i][j] = std::min(dist[i][j], std::min(dist[i][k], dist[k][j]));\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[source][dest];\n}",
            "// --------------------------------------------------------------------\n\t// TODO: Implement me\n\t// --------------------------------------------------------------------\n\tint length = 0;\n\tint min = 0;\n\tstd::vector<int> visit;\n\tstd::vector<int> pre;\n\t\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tvisit.push_back(0);\n\t\tpre.push_back(0);\n\t}\n\t\n\tstd::queue<int> q;\n\tq.push(source);\n\tvisit[source] = 1;\n\tpre[source] = -1;\n\t\n\twhile (!q.empty())\n\t{\n\t\tint cur = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; i++)\n\t\t{\n\t\t\tif (A[cur * N + i] == 1 && visit[i] == 0)\n\t\t\t{\n\t\t\t\tq.push(i);\n\t\t\t\tvisit[i] = 1;\n\t\t\t\tpre[i] = cur;\n\t\t\t}\n\t\t}\n\t\tif (cur == dest)\n\t\t{\n\t\t\tbreak;\n\t\t}\n\t}\n\t\n\tlength = 0;\n\tif (pre[dest] == -1)\n\t{\n\t\tmin = -1;\n\t}\n\telse\n\t{\n\t\twhile (dest!= -1)\n\t\t{\n\t\t\tlength++;\n\t\t\tdest = pre[dest];\n\t\t}\n\t\tmin = length;\n\t}\n\t\n\treturn min;\n}",
            "// write your code here\n\tif(A[source*N+dest]) {\n\t\treturn 1;\n\t}\n\n\tstd::vector<int> dist(N, -1);\n\tstd::queue<int> q;\n\tstd::vector<bool> visited(N, false);\n\t\n\tq.push(source);\n\tdist[source] = 0;\n\twhile(!q.empty()) {\n\t\tint i = q.front();\n\t\tq.pop();\n\t\tvisited[i] = true;\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tif(A[i*N+j] &&!visited[j]) {\n\t\t\t\tif(dist[j] == -1) {\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "// TODO: implement\n    std::vector<int> distance(N, -1);\n    std::queue<int> q;\n\n    distance[source] = 0;\n    q.push(source);\n\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n\n        for (int i = 0; i < N; ++i) {\n            if (distance[i]!= -1)\n                continue;\n\n            if (A[v * N + i] == 1) {\n                distance[i] = distance[v] + 1;\n                q.push(i);\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n  dist[source] = 0;\n  for(int i = 0; i < N; ++i)\n  {\n    int min = std::numeric_limits<int>::max();\n    for(int j = 0; j < N; ++j)\n    {\n      if(dist[j]!= std::numeric_limits<int>::max())\n      {\n        if(A[i*N + j]!= 0 && A[i*N + j] < min)\n        {\n          min = A[i*N + j];\n        }\n      }\n    }\n    for(int j = 0; j < N; ++j)\n    {\n      if(dist[j]!= std::numeric_limits<int>::max())\n      {\n        if(A[i*N + j]!= 0 && A[i*N + j] == min)\n        {\n          dist[j] = min + dist[i];\n        }\n      }\n    }\n  }\n\n  return (dist[dest] == std::numeric_limits<int>::max())? -1 : dist[dest];\n}",
            "if (N == 0 || source < 0 || dest < 0) return 0;\n\n\tstd::queue<int> Q;\n\tstd::vector<int> dist(N, -1);\n\tstd::vector<bool> visited(N, false);\n\tdist[source] = 0;\n\tvisited[source] = true;\n\tQ.push(source);\n\twhile (!Q.empty()) {\n\t\tint s = Q.front();\n\t\tQ.pop();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[s * N + i] > 0) {\n\t\t\t\tif (dist[i] == -1) {\n\t\t\t\t\tdist[i] = dist[s] + 1;\n\t\t\t\t\tQ.push(i);\n\t\t\t\t\tvisited[i] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (visited[dest] == false) return 0;\n\treturn dist[dest];\n}",
            "std::vector<int> dis(N, -1);\n    dis[source] = 0;\n    std::queue<int> queue;\n    queue.push(source);\n\n    while (!queue.empty()) {\n        auto u = queue.front();\n        queue.pop();\n\n        for (size_t i = 0; i < N; i++) {\n            if (A[u * N + i]) {\n                if (dis[i] == -1) {\n                    dis[i] = dis[u] + 1;\n                    queue.push(i);\n                }\n            }\n        }\n    }\n\n    return dis[dest];\n}",
            "std::vector<std::vector<int>> dist(N, std::vector<int>(N, INF));\n\tstd::vector<std::vector<int>> prev(N, std::vector<int>(N, -1));\n\tdist[source][source] = 0;\n\n\tstd::queue<int> q;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v] && dist[source][v] > dist[source][u] + 1) {\n\t\t\t\tdist[source][v] = dist[source][u] + 1;\n\t\t\t\tprev[source][v] = u;\n\t\t\t\tq.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::stack<int> st;\n\tint cur = dest;\n\tst.push(cur);\n\twhile (cur!= source) {\n\t\tcur = prev[source][cur];\n\t\tst.push(cur);\n\t}\n\tstd::vector<int> path;\n\twhile (!st.empty()) {\n\t\tpath.push_back(st.top());\n\t\tst.pop();\n\t}\n\n\treturn dist[source][dest];\n}",
            "std::vector<std::vector<int>> dist(N, std::vector<int>(N, INT_MAX));\n    std::vector<int> next(N, -1);\n    std::queue<int> Q;\n    Q.push(source);\n    dist[source][source] = 0;\n    while (!Q.empty()) {\n        int u = Q.front();\n        Q.pop();\n        for (size_t v = 0; v < N; ++v) {\n            if (A[u * N + v]!= 0) {\n                if (dist[u][v] > dist[u][source] + 1) {\n                    dist[u][v] = dist[u][source] + 1;\n                    next[v] = u;\n                    if (v == dest)\n                        break;\n                    Q.push(v);\n                }\n            }\n        }\n    }\n\n    std::vector<int> path;\n    int p = dest;\n    while (p!= -1) {\n        path.push_back(p);\n        p = next[p];\n    }\n\n    return dist[source][dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n\n    std::vector<int> currLevel(1, source);\n\n    for(int curr = 0; curr < N; ++curr) {\n        if(currLevel.empty()) break;\n        currLevel = bfs(A, N, currLevel, dist);\n    }\n    return dist[dest];\n}",
            "if (source < 0 || dest < 0 || source >= N || dest >= N || source == dest) return 0;\n  std::vector<bool> visited(N);\n  visited[source] = true;\n  std::queue<int> q;\n  q.push(source);\n  std::vector<int> parent(N);\n  parent[source] = source;\n  while (!q.empty()) {\n    auto v = q.front();\n    q.pop();\n    for (size_t u = 0; u < N; ++u) {\n      if (A[v*N + u] == 1 &&!visited[u]) {\n        q.push(u);\n        parent[u] = v;\n        visited[u] = true;\n        if (u == dest) return parent[u];\n      }\n    }\n  }\n  return -1;\n}",
            "if (source >= N || source < 0)\n\t\tthrow std::invalid_argument(\"source is out of range\");\n\tif (dest >= N || dest < 0)\n\t\tthrow std::invalid_argument(\"dest is out of range\");\n\n\tstd::vector<int> dists(N, INT_MAX);\n\tstd::queue<int> queue;\n\n\tdists[source] = 0;\n\tqueue.push(source);\n\n\twhile (!queue.empty()) {\n\t\tint node = queue.front();\n\t\tqueue.pop();\n\n\t\tfor (int neighbor = 0; neighbor < N; ++neighbor) {\n\t\t\tif (A[node * N + neighbor] == 1) {\n\t\t\t\tif (dists[neighbor] == INT_MAX) {\n\t\t\t\t\tdists[neighbor] = dists[node] + 1;\n\t\t\t\t\tqueue.push(neighbor);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dists[dest];\n}",
            "if(A[source * N + dest]!= 0){\n        return 1;\n    }\n    // Your code here.\n    std::vector<bool> visited(N, false);\n\n    std::vector<int> dist(N, -1);\n    dist[source] = 0;\n\n    std::vector<int> parent(N, -1);\n\n    std::queue<int> Q;\n    Q.push(source);\n\n    while (!Q.empty()) {\n        int node = Q.front();\n        Q.pop();\n        visited[node] = true;\n        for (int i = 0; i < N; i++) {\n            if (!visited[i] && A[node * N + i] == 1 && dist[i] == -1) {\n                Q.push(i);\n                dist[i] = dist[node] + 1;\n                parent[i] = node;\n            }\n        }\n    }\n\n    if (dist[dest]!= -1) {\n        return dist[dest];\n    } else {\n        return -1;\n    }\n}",
            "std::vector<int> distances(N, -1);\n    std::queue<int> queue;\n\n    // Add the source to the queue and initialize the distance to source to 0\n    queue.push(source);\n    distances[source] = 0;\n\n    while (queue.size() > 0) {\n        // Pop the first element from the queue\n        int current = queue.front();\n        queue.pop();\n\n        // Loop through all the adjacent nodes to the current node\n        for (int i = 0; i < N; ++i) {\n            // If the current node is adjacent to the destination node, return the distance\n            if (A[current * N + i] == 1 && i == dest) {\n                return distances[current];\n            }\n\n            // If the current node is adjacent to an unvisited node, add the node to the queue\n            // and initialize the distance to the current node's distance + 1\n            if (A[current * N + i] == 1 && distances[i] == -1) {\n                queue.push(i);\n                distances[i] = distances[current] + 1;\n            }\n        }\n    }\n\n    // If we do not find the destination node, return -1\n    return -1;\n}",
            "// TODO: write your solution here\n   // You may find the following resources helpful:\n   // https://www.cs.cmu.edu/~adamchik/15-121/lectures/Graph%20Algorithms/graph.html\n   // http://www.geeksforgeeks.org/dynamic-programming-set-16-floyd-warshall-algorithm/\n\n   std::vector<int> path_length(N, -1); // stores shortest path length from source to i for i in 0..(N-1)\n\n   // initialize path_length as a copy of A\n   for (size_t i = 0; i < N; ++i)\n      for (size_t j = 0; j < N; ++j)\n         if (A[i*N + j] > 0)\n            path_length[j] = A[i*N + j];\n\n   // update path_length using Floyd-Warshall algorithm\n   for (size_t k = 0; k < N; ++k)\n      for (size_t i = 0; i < N; ++i)\n         for (size_t j = 0; j < N; ++j)\n            path_length[j] = std::min(path_length[j], path_length[i] + path_length[k]);\n\n   return path_length[dest];\n}",
            "std::vector<int> distances(N, -1);\n\tstd::queue<int> queue;\n\n\tdistances[source] = 0;\n\tqueue.push(source);\n\n\twhile (!queue.empty()) {\n\n\t\tint node = queue.front();\n\t\tqueue.pop();\n\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[node*N + i] == 1 && distances[i] == -1) {\n\t\t\t\tdistances[i] = distances[node] + 1;\n\t\t\t\tqueue.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest];\n}",
            "// The \"distance\" vector stores the distance to the shortest path to the given vertex.\n    // The \"distance\" vector is initialized with -1 as default values (unvisited).\n    std::vector<int> distance(N, -1);\n    std::queue<int> queue;\n\n    distance[source] = 0;\n    queue.push(source);\n\n    while (!queue.empty()) {\n        const int curr = queue.front();\n        queue.pop();\n\n        for (int i = 0; i < N; i++) {\n            if (A[curr * N + i] == 1) {\n                if (distance[i] == -1) {\n                    distance[i] = distance[curr] + 1;\n                    queue.push(i);\n                }\n            }\n        }\n    }\n\n    if (distance[dest]!= -1) {\n        return distance[dest];\n    }\n    return -1;\n}",
            "std::vector<std::vector<int>> dist(N, std::vector<int>(N, -1));\n  dist[source][source] = 0;\n  std::queue<int> Q;\n  Q.push(source);\n  while (!Q.empty()) {\n    int u = Q.front();\n    Q.pop();\n    if (u == dest) {\n      return dist[source][u];\n    }\n    for (int v = 0; v < N; v++) {\n      if (A[u * N + v]) {\n        if (dist[source][v] < 0) {\n          dist[source][v] = dist[source][u] + 1;\n          Q.push(v);\n        }\n      }\n    }\n  }\n  return -1;\n}",
            "// Write your code here\n    if (source < 0 || source >= N || dest < 0 || dest >= N) return -1;\n    auto dist = std::vector<int>(N, INT_MAX);\n    dist[source] = 0;\n    auto visited = std::vector<bool>(N, false);\n    std::queue<int> q;\n    q.push(source);\n    while (!q.empty()) {\n        auto cur = q.front();\n        q.pop();\n        visited[cur] = true;\n        auto row = A[cur];\n        for (auto i = 0; i < N; ++i) {\n            if (row[i] &&!visited[i]) {\n                dist[i] = std::min(dist[i], dist[cur] + 1);\n                q.push(i);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "int paths[N][N] = { { 0 } };\n\tfor (int i = 0; i < N; i++)\n\t\tpaths[source][i] = i == source;\n\tfor (int k = 0; k < N; k++)\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tfor (int j = 0; j < N; j++)\n\t\t\t\tif (A[i * N + j])\n\t\t\t\t\tpaths[i][j] += paths[i][k] * paths[k][j];\n\treturn paths[source][dest];\n}",
            "std::vector<int> dists(N, INF);\n\tdists[source] = 0;\n\tstd::vector<int> prev(N, INF);\n\tstd::set<int> Q;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[i*N+source] > 0) {\n\t\t\tQ.insert(i);\n\t\t}\n\t}\n\twhile (!Q.empty()) {\n\t\tint u = *Q.begin();\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[v*N+u] > 0 && dists[u]+A[v*N+u] < dists[v]) {\n\t\t\t\tprev[v] = u;\n\t\t\t\tdists[v] = dists[u]+A[v*N+u];\n\t\t\t\tQ.insert(v);\n\t\t\t}\n\t\t}\n\t\tQ.erase(Q.begin());\n\t}\n\tif (dists[dest]!= INF) {\n\t\treturn dists[dest];\n\t}\n\telse {\n\t\treturn INF;\n\t}\n}",
            "std::vector<int> dist(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        for (size_t i = 0; i < N; ++i) {\n            if (dist[i] < 0 && A[N*u+i] == 1) {\n                q.push(i);\n                dist[i] = dist[u] + 1;\n            }\n        }\n    }\n    return dist[dest];\n}",
            "if (source < 0 || source >= N)\n    throw std::invalid_argument(\"source is invalid\");\n  if (dest < 0 || dest >= N)\n    throw std::invalid_argument(\"dest is invalid\");\n  if (A.size()!= N * N)\n    throw std::invalid_argument(\"input adjacency matrix is invalid\");\n  if (source == dest)\n    return 0;\n  std::vector<std::pair<int, int>> Q;\n  std::vector<int> dist(N, std::numeric_limits<int>::max());\n  dist[source] = 0;\n  Q.emplace_back(source, 0);\n  while (!Q.empty()) {\n    auto q = Q.back();\n    Q.pop_back();\n    auto u = q.first, d = q.second;\n    for (auto v = 0; v < N; ++v) {\n      if (A[N * u + v] && dist[v] > d + 1) {\n        dist[v] = d + 1;\n        Q.emplace_back(v, d + 1);\n      }\n    }\n  }\n  return dist[dest];\n}",
            "// TODO\n\n  int *distance = new int[N];\n  bool *visited = new bool[N];\n  int *parents = new int[N];\n\n  for(int i=0; i<N; i++)\n    distance[i] = INT_MAX;\n\n  std::list<int> q;\n  q.push_back(source);\n\n  distance[source] = 0;\n  visited[source] = false;\n\n  while (!q.empty())\n  {\n    int x = q.front();\n    q.pop_front();\n\n    for(int i=0; i<N; i++)\n    {\n      if (A[x*N+i] == 1 &&!visited[i])\n      {\n        distance[i] = distance[x] + 1;\n        parents[i] = x;\n        q.push_back(i);\n      }\n    }\n    visited[x] = true;\n  }\n\n  if (distance[dest] == INT_MAX)\n    return -1;\n  else\n    return distance[dest];\n}",
            "if (source == dest)\n        return 0;\n\n    std::queue<int> q;\n    std::vector<bool> visited(N);\n    std::vector<int> dist(N, 10000);\n\n    q.push(source);\n    visited[source] = true;\n    dist[source] = 0;\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] == 1 &&!visited[v]) {\n                q.push(v);\n                visited[v] = true;\n                dist[v] = dist[u] + 1;\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> d(N, INT_MAX);\n    std::queue<int> q;\n    q.push(source);\n    d[source] = 0;\n    while (q.size()) {\n        int u = q.front();\n        q.pop();\n        for (int v = 0; v < N; ++v) {\n            if (A[u*N + v] == 1 && d[v] == INT_MAX) {\n                q.push(v);\n                d[v] = d[u] + 1;\n            }\n        }\n    }\n    return d[dest];\n}",
            "if (source == dest) { return 0; }\n  std::vector<int> visited(N);\n  std::vector<int> dist(N);\n  std::queue<int> queue;\n  queue.push(source);\n  visited[source] = 1;\n  dist[source] = 0;\n  while (!queue.empty()) {\n    int v = queue.front();\n    queue.pop();\n    for (int i = 0; i < N; ++i) {\n      if (A[v * N + i] &&!visited[i]) {\n        queue.push(i);\n        visited[i] = 1;\n        dist[i] = dist[v] + 1;\n      }\n    }\n  }\n  return dist[dest];\n}",
            "std::vector<std::vector<int>> V(N, std::vector<int>(N, -1));\n\tstd::vector<int> V_prev(N, -1);\n\tstd::vector<bool> V_visited(N, false);\n\tstd::queue<int> Q;\n\n\tV_visited[source] = true;\n\tV[source][source] = 0;\n\tQ.push(source);\n\twhile (!Q.empty()) {\n\t\tauto s = Q.front();\n\t\tQ.pop();\n\t\tfor (int d = 0; d < N; ++d) {\n\t\t\tif (A[s * N + d] == 1 &&!V_visited[d]) {\n\t\t\t\tV[s][d] = V[s][s] + 1;\n\t\t\t\tV_visited[d] = true;\n\t\t\t\tV_prev[d] = s;\n\t\t\t\tQ.push(d);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (V_visited[dest]) {\n\t\tint length = V[dest][dest];\n\t\tfor (int v = dest; v!= source; v = V_prev[v])\n\t\t\t--length;\n\t\treturn length;\n\t} else {\n\t\treturn -1;\n\t}\n}",
            "std::vector<bool> visited(N, false);\n    std::vector<int> distance(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    visited[source] = true;\n    distance[source] = 0;\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] == 0) {\n                continue;\n            }\n            if (visited[v]) {\n                continue;\n            }\n            q.push(v);\n            distance[v] = distance[u] + 1;\n            visited[v] = true;\n            if (v == dest) {\n                return distance[dest];\n            }\n        }\n    }\n    return -1;\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> distances(N, std::numeric_limits<int>::max());\n  std::queue<int> q;\n  q.push(source);\n  visited[source] = true;\n  distances[source] = 0;\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n    for (size_t i = 0; i < N; ++i) {\n      if (A[u * N + i] == 1) {\n        if (visited[i]) {\n          continue;\n        }\n        q.push(i);\n        visited[i] = true;\n        distances[i] = distances[u] + 1;\n      }\n    }\n  }\n  return distances[dest];\n}",
            "// TODO\n\n\treturn 0;\n}",
            "// A is an NxN matrix representing an adjacency matrix.\n    // The elements of A are either 0 or 1 (representing non-edge or an edge, respectively).\n    // Source and dest are the 0-based indices of the starting and ending vertices of the path\n    // that we want to find the shortest length of.\n\n    // Create a distance vector for all the nodes in the graph.\n    // Initialize all the nodes to be infinity except for the source node, which has a distance of 0.\n    std::vector<int> distance(N, -1);\n    distance[source] = 0;\n\n    // Create a vector for storing the nodes whose distance needs to be updated.\n    std::vector<int> nodeList(N, -1);\n\n    // Add the source node to the nodeList.\n    nodeList[0] = source;\n\n    // Loop until we've added all the nodes whose distance needs to be updated.\n    while (nodeList[0]!= -1) {\n        // Remove the first node from the nodeList.\n        int node = nodeList[0];\n        nodeList[0] = -1;\n\n        // Find all the neighboring nodes of the current node.\n        std::vector<int> neighborNodes;\n        for (int i = 0; i < N; ++i) {\n            if (A[node * N + i] == 1) {\n                neighborNodes.push_back(i);\n            }\n        }\n\n        // Update the distance vector for all the neighboring nodes of the current node.\n        for (int i = 0; i < neighborNodes.size(); ++i) {\n            int neighborNode = neighborNodes[i];\n            if (distance[neighborNode] == -1) {\n                distance[neighborNode] = distance[node] + 1;\n                nodeList[neighborNode] = neighborNode;\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\tbool hasPath = false;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tint u = -1;\n\t\tint minDist = std::numeric_limits<int>::max();\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (dist[v] < minDist) {\n\t\t\t\tu = v;\n\t\t\t\tminDist = dist[v];\n\t\t\t}\n\t\t}\n\n\t\tif (u == -1) break;\n\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[N * u + v] && dist[v] > minDist + 1) {\n\t\t\t\tdist[v] = minDist + 1;\n\t\t\t}\n\t\t}\n\n\t\tif (dist[dest]!= std::numeric_limits<int>::max()) {\n\t\t\thasPath = true;\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn hasPath? dist[dest] : -1;\n}",
            "if (source == dest) return 0;\n\n\tstd::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\n\tstd::vector<int> parent(N, -1);\n\tparent[source] = -1;\n\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\n\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\tif (A[N * u + v] && dist[v] < 0) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tparent[v] = u;\n\t\t\t\tq.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] < 0) return -1;\n\n\tstd::vector<int> path;\n\tint p = dest;\n\twhile (p >= 0) {\n\t\tpath.push_back(p);\n\t\tp = parent[p];\n\t}\n\n\treturn path.size() - 1;\n}",
            "std::vector<int> dists(N, INT_MAX);\n    dists[source] = 0;\n\n    for (size_t i = 0; i < N; ++i) {\n        int next = -1;\n        for (size_t j = 0; j < N; ++j) {\n            if (dists[j] == INT_MAX) continue;\n\n            for (size_t k = 0; k < N; ++k) {\n                if (A[j * N + k] && dists[j] + 1 < dists[k]) {\n                    next = k;\n                    dists[k] = dists[j] + 1;\n                    break;\n                }\n            }\n\n            if (next!= -1) break;\n        }\n\n        if (next == -1) break;\n    }\n\n    return dists[dest];\n}",
            "// A is NxN adjacency matrix stored in row-major\n    // shortestPathLength is length of shortest path from source to dest in graph defined by A\n\n    std::vector<int> d(N, -1);\n    std::vector<int> prev(N, -1);\n\n    std::queue<int> Q;\n    Q.push(source);\n    d[source] = 0;\n    while (!Q.empty()) {\n        int u = Q.front();\n        Q.pop();\n        for (int v = 0; v < N; ++v) {\n            if (A[u*N+v] == 1 && d[v] == -1) {\n                d[v] = d[u] + 1;\n                prev[v] = u;\n                Q.push(v);\n            }\n        }\n    }\n\n    if (d[dest]!= -1) {\n        std::vector<int> path;\n        for (int u = dest; u!= source; u = prev[u]) {\n            path.push_back(u);\n        }\n        path.push_back(source);\n        std::reverse(path.begin(), path.end());\n        return path.size() - 1;\n    } else {\n        return -1;\n    }\n}",
            "std::vector<int> dist(N, INF);\n\tdist[source] = 0;\n\tstd::vector<int> visited(N);\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] &&!visited[j]) {\n\t\t\t\tif (dist[i]!= INF) {\n\t\t\t\t\tdist[j] = std::min(dist[j], dist[i] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tvisited[i] = 1;\n\t}\n\treturn dist[dest];\n}",
            "if (source == dest) return 0;\n  // find path by depth first search\n  std::vector<int> const& row = A[source];\n  int path_length = row[dest];\n  if (path_length == 0) return -1;\n  return path_length;\n}",
            "std::vector<int> distance(N, -1);\n\tdistance[source] = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (distance[j]!= -1 && A[N * j + i]!= 0) {\n\t\t\t\tif (distance[i] == -1 || distance[j] + 1 < distance[i]) {\n\t\t\t\t\tdistance[i] = distance[j] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> dist(N);\n\tdist[source] = 0;\n\n\tstd::vector<bool> visited(N);\n\tstd::vector<int> prev(N);\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tif (i == source) {\n\t\t\tvisited[i] = true;\n\t\t} else {\n\t\t\tvisited[i] = false;\n\t\t}\n\t}\n\n\twhile (true) {\n\t\tint minDist = -1;\n\t\tint minNode = -1;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (visited[i] == false && (minDist == -1 || minDist > dist[i])) {\n\t\t\t\tminDist = dist[i];\n\t\t\t\tminNode = i;\n\t\t\t}\n\t\t}\n\n\t\tif (minNode == -1) {\n\t\t\tbreak;\n\t\t}\n\n\t\tvisited[minNode] = true;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[minNode*N + i] == 1 && (dist[i] == -1 || dist[minNode] + 1 < dist[i])) {\n\t\t\t\tdist[i] = dist[minNode] + 1;\n\t\t\t\tprev[i] = minNode;\n\t\t\t}\n\t\t}\n\t}\n\n\tint pathLength = dist[dest];\n\tstd::vector<int> path;\n\tint current = dest;\n\twhile (current!= source) {\n\t\tpath.push_back(current);\n\t\tcurrent = prev[current];\n\t}\n\n\tpath.push_back(source);\n\tstd::reverse(path.begin(), path.end());\n\n\t//for (auto const& x : path) {\n\t//\tstd::cout << x << \", \";\n\t//}\n\n\treturn pathLength;\n}",
            "// TODO: Your code here\n\t\n\treturn 0;\n}",
            "// Write your code here\n    std::vector<bool> visited(N, false);\n    std::vector<int> distances(N, 0);\n    std::queue<int> que;\n    que.push(source);\n    while (que.size() > 0) {\n        int u = que.front();\n        que.pop();\n        if (visited[u]) continue;\n        visited[u] = true;\n        if (u == dest) return distances[u];\n        for (size_t i = 0; i < N; i++) {\n            if (A[u * N + i] == 0) continue;\n            if (visited[i]) continue;\n            distances[i] = distances[u] + 1;\n            que.push(i);\n        }\n    }\n    return -1;\n}",
            "std::vector<int> minDist(N, INF);\n\tminDist[source] = 0;\n\n\tauto q = std::queue<int>();\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tauto v = q.front();\n\t\tq.pop();\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (A[v*N + i] && minDist[i] > minDist[v] + 1) {\n\t\t\t\tminDist[i] = minDist[v] + 1;\n\t\t\t\tq.push(i);\n\t\t\t\tif (i == dest)\n\t\t\t\t\treturn minDist[i];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn INF;\n}",
            "int* dist = new int[N];\n\n    for (size_t i = 0; i < N; ++i) {\n        dist[i] = -1;\n    }\n\n    dist[source] = 0;\n\n    std::vector<int> worklist;\n    worklist.push_back(source);\n\n    while (worklist.size() > 0) {\n        int node = worklist.back();\n        worklist.pop_back();\n\n        for (size_t i = 0; i < N; ++i) {\n            if (A[node * N + i] == 1 && dist[i] == -1) {\n                dist[i] = dist[node] + 1;\n                worklist.push_back(i);\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> distance(N, std::numeric_limits<int>::max());\n\tstd::vector<bool> visited(N, false);\n\n\tdistance[source] = 0;\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint curr = q.front();\n\t\tq.pop();\n\t\tvisited[curr] = true;\n\n\t\tfor (size_t n = 0; n < N; ++n) {\n\t\t\tif (!visited[n] && A[curr * N + n]!= 0) {\n\t\t\t\tint newDistance = distance[curr] + A[curr * N + n];\n\t\t\t\tif (newDistance < distance[n]) {\n\t\t\t\t\tdistance[n] = newDistance;\n\t\t\t\t\tq.push(n);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> distance(N, -1);\n\tstd::queue<int> q;\n\tq.push(source);\n\n\tdistance[source] = 0;\n\n\twhile (!q.empty()) {\n\t\tauto const u = q.front();\n\t\tq.pop();\n\n\t\tfor (auto i = 0u; i < N; ++i) {\n\t\t\tif (distance[i]!= -1) continue;\n\n\t\t\tif (A[N * u + i] == 1) {\n\t\t\t\tdistance[i] = distance[u] + 1;\n\t\t\t\tq.push(i);\n\n\t\t\t\tif (i == dest) return distance[i];\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}",
            "if (source == dest)\n\t\treturn 0;\n\n\tstd::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\n\tstd::vector<int> prev(N, -1);\n\tstd::vector<bool> visited(N, false);\n\tvisited[source] = true;\n\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (!visited[v] && A[u * N + v]) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tprev[v] = u;\n\t\t\t\tvisited[v] = true;\n\t\t\t\tq.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\tstd::vector<int> path;\n\tint u = dest;\n\twhile (prev[u]!= -1) {\n\t\tpath.push_back(u);\n\t\tu = prev[u];\n\t}\n\tpath.push_back(u);\n\n\tstd::reverse(path.begin(), path.end());\n\n\treturn static_cast<int>(path.size());\n}",
            "assert(N == A.size());\n    std::vector<int> D; // Distance from source\n    std::vector<int> P; // Predecessor in shortest path\n    for (size_t i = 0; i < N; ++i) {\n        D.push_back(INT_MAX);\n        P.push_back(-1);\n    }\n    std::queue<int> Q;\n    Q.push(source);\n    D[source] = 0;\n    while (!Q.empty()) {\n        int u = Q.front();\n        Q.pop();\n        int d = D[u];\n        for (size_t i = 0; i < N; ++i) {\n            if (A[u * N + i] && D[i] > d + 1) {\n                Q.push(i);\n                D[i] = d + 1;\n                P[i] = u;\n            }\n        }\n    }\n    return D[dest];\n}",
            "if (A.size()!= N * N) {\n    throw std::invalid_argument(\"A should be an NxN matrix\");\n  }\n  if (source < 0 || source >= N) {\n    throw std::invalid_argument(\"source is out of bounds\");\n  }\n  if (dest < 0 || dest >= N) {\n    throw std::invalid_argument(\"dest is out of bounds\");\n  }\n  std::vector<bool> visited(N, false);\n  std::vector<int> distance(N, -1);\n  std::queue<int> Q;\n  Q.push(source);\n  visited[source] = true;\n  distance[source] = 0;\n  while (!Q.empty()) {\n    int v = Q.front();\n    Q.pop();\n    for (int i = 0; i < N; ++i) {\n      if (A[v * N + i] == 1 &&!visited[i]) {\n        Q.push(i);\n        visited[i] = true;\n        distance[i] = distance[v] + 1;\n      }\n    }\n  }\n  if (distance[dest] < 0) {\n    throw std::invalid_argument(\"there is no path from source to dest\");\n  }\n  return distance[dest];\n}",
            "// This is your job. :)\n\n\tstd::vector<int> dist(N, -1);\n\tstd::queue<int> q;\n\tq.push(source);\n\tdist[source] = 0;\n\twhile (q.size()) {\n\t\tint cur = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[cur * N + i] && dist[i] == -1) {\n\t\t\t\tdist[i] = dist[cur] + 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "const int INF = std::numeric_limits<int>::max();\n\n\t// construct an array of all reachable cells from the source cell\n\tstd::vector<std::vector<int>> dist(N, std::vector<int>(N, INF));\n\tdist[source][source] = 0;\n\n\t// construct a queue of the cells to be explored\n\tstd::queue<int> q;\n\tq.push(source);\n\n\t// keep exploring reachable cells as long as the queue is non-empty\n\twhile (!q.empty()) {\n\t\tint curr = q.front();\n\t\tq.pop();\n\n\t\t// explore all of the cells that can be reached from the current cell\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\t// skip if we've already explored this cell\n\t\t\tif (dist[curr][i] < INF) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// skip if this cell can't be reached\n\t\t\tif (A[curr][i] == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t// this cell can be reached\n\t\t\tdist[curr][i] = dist[curr][curr] + 1;\n\t\t\tq.push(i);\n\t\t}\n\t}\n\n\t// return the length of the shortest path from the source to the destination\n\treturn dist[source][dest];\n}",
            "std::vector<int> distances(N, INT_MAX);\n  distances[source] = 0;\n\n  std::vector<bool> visited(N);\n  std::queue<int> queue;\n\n  queue.push(source);\n\n  while (!queue.empty()) {\n    int vertex = queue.front();\n    queue.pop();\n\n    visited[vertex] = true;\n\n    for (int i = 0; i < N; i++) {\n      if (A[vertex*N + i] == 1 && visited[i] == false && distances[i] > distances[vertex] + 1) {\n        distances[i] = distances[vertex] + 1;\n        queue.push(i);\n      }\n    }\n  }\n\n  return distances[dest];\n}",
            "// TODO: YOUR CODE HERE\n\treturn -1;\n}",
            "std::vector<int> distances(N, -1);\n  distances[source] = 0;\n  std::queue<int> queue;\n  queue.push(source);\n  while (!queue.empty()) {\n    int u = queue.front();\n    queue.pop();\n    for (size_t i = 0; i < N; ++i) {\n      if (A[u * N + i] == 1 && distances[i] == -1) {\n        distances[i] = distances[u] + 1;\n        queue.push(i);\n      }\n    }\n  }\n  return distances[dest];\n}",
            "std::vector<bool> visited(N, false);\n\tstd::vector<int> distance(N, INT_MAX);\n\tdistance[source] = 0;\n\n\twhile (true) {\n\t\tint min = INT_MAX;\n\t\tint min_i = -1;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (!visited[i] && distance[i] < min) {\n\t\t\t\tmin = distance[i];\n\t\t\t\tmin_i = i;\n\t\t\t}\n\t\t}\n\t\tif (min_i == -1)\n\t\t\tbreak;\n\t\tvisited[min_i] = true;\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (A[min_i * N + j]!= 0 &&!visited[j] && distance[min_i] + A[min_i * N + j] < distance[j])\n\t\t\t\tdistance[j] = distance[min_i] + A[min_i * N + j];\n\t\t}\n\t}\n\treturn distance[dest];\n}",
            "const int INF = 1 << 20;\n\tstd::vector<int> dists(N, INF);\n\tdists[source] = 0;\n\n\t// use a min heap to keep track of the nodes to visit next\n\tstd::priority_queue<std::tuple<int, int>, std::vector<std::tuple<int, int>>, std::greater<std::tuple<int, int>>> pq;\n\tpq.emplace(0, source);\n\n\t// BFS with min heap\n\twhile (!pq.empty()) {\n\t\tauto [d, u] = pq.top();\n\t\tpq.pop();\n\t\tif (d > dists[u]) continue;\n\t\tfor (size_t v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v] && dists[v] > dists[u] + 1) {\n\t\t\t\tdists[v] = dists[u] + 1;\n\t\t\t\tpq.emplace(dists[v], v);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dists[dest] == INF? -1 : dists[dest];\n}",
            "int dist[N];\n    std::fill(dist, dist+N, INT_MAX);\n\n    // Initialize distance from source to source as 0\n    dist[source] = 0;\n\n    // Traverse all vertices\n    for (int i = 0; i < N; i++) {\n        // Traverse all edges of the current vertex\n        for (int j = 0; j < N; j++) {\n            // If there is an edge from current vertex i to j and\n            // there is a shorter path to j through current vertex i\n            if (A[i*N+j] == 1 && dist[j] > dist[i] + 1) {\n                // Then update distance of j\n                dist[j] = dist[i] + 1;\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "int count = 0;\n\tint current_source = source;\n\n\twhile (current_source!= dest) {\n\t\t++count;\n\t\tcurrent_source = get_next_source(A, N, current_source, dest);\n\t}\n\treturn count;\n}",
            "if (source == dest)\n    return 0;\n  if (N == 0)\n    return -1;\n\n  std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n  std::vector<bool> visited(N);\n  std::vector<std::pair<int, int>> adj;\n  std::queue<int> Q;\n  Q.push(source);\n\n  while (!Q.empty()) {\n    int current = Q.front();\n    Q.pop();\n    if (visited[current])\n      continue;\n    visited[current] = true;\n\n    for (int j = 0; j < N; ++j) {\n      if (A[current * N + j] == 1 &&!visited[j]) {\n        adj.emplace_back(current, j);\n        dist[j] = std::min(dist[j], dist[current] + 1);\n        Q.push(j);\n      }\n    }\n  }\n\n  for (auto& a : adj) {\n    if (a.first == source && a.second == dest)\n      return dist[dest];\n  }\n\n  return -1;\n}",
            "std::vector<std::vector<int>> dist;\n\tdist.resize(N, std::vector<int>(N, INT_MAX));\n\n\tstd::queue<std::pair<int,int>> Q;\n\tQ.push({source,0});\n\n\twhile (!Q.empty()) {\n\t\tauto curr = Q.front();\n\t\tQ.pop();\n\n\t\tauto const& curr_v = curr.first;\n\t\tauto const& curr_dist = curr.second;\n\n\t\tif (curr_dist > dist[curr_v][curr_v]) continue;\n\t\tif (curr_v == dest) return curr_dist;\n\n\t\tfor (size_t i=0; i<N; ++i) {\n\t\t\tif (A[curr_v*N + i] == 1) {\n\t\t\t\tif (dist[curr_v][i] > curr_dist+1) {\n\t\t\t\t\tdist[curr_v][i] = curr_dist+1;\n\t\t\t\t\tQ.push({i, curr_dist+1});\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn INT_MAX;\n}",
            "std::vector<int> dist(N, -1);\n  std::vector<int> prev(N, -1);\n  dist[source] = 0;\n\n  for (int i = 0; i < N; i++) {\n    int current = -1;\n    for (int j = 0; j < N; j++) {\n      if (dist[j] == -1) continue;\n      if (current == -1 || dist[j] < dist[current]) current = j;\n    }\n    if (current == -1) break;\n\n    int d = dist[current];\n    for (int j = 0; j < N; j++) {\n      if (A[current * N + j] == 1 && dist[j] == -1) {\n        dist[j] = d + 1;\n        prev[j] = current;\n      }\n    }\n  }\n\n  if (dist[dest] == -1) return -1;\n\n  std::vector<int> path;\n  for (int j = dest; j!= source; j = prev[j]) path.push_back(j);\n  path.push_back(source);\n  std::reverse(path.begin(), path.end());\n\n  for (int i = 0; i < path.size(); i++) {\n    std::cout << \" \" << path[i];\n  }\n  std::cout << \"\\n\";\n\n  return dist[dest];\n}",
            "std::vector<std::vector<int>> matrix;\n\tfor (auto row : A) {\n\t\tstd::vector<int> temp;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\ttemp.push_back(row & (1 << i));\n\t\t}\n\t\tmatrix.push_back(temp);\n\t}\n\tint visited[N] = { 0 };\n\tstd::queue<std::pair<int, int>> q;\n\tq.push(std::make_pair(source, 0));\n\tvisited[source] = 1;\n\twhile (!q.empty()) {\n\t\tauto [current, level] = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (matrix[current][i]!= 0 && visited[i] == 0) {\n\t\t\t\tvisited[i] = 1;\n\t\t\t\tq.push(std::make_pair(i, level + 1));\n\t\t\t\tif (i == dest) {\n\t\t\t\t\treturn level + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 0;\n}",
            "// TODO: implement me\n\treturn 0;\n}",
            "assert(N > 0);\n\tassert(source < static_cast<int>(N));\n\tassert(dest < static_cast<int>(N));\n\n\tstd::vector<int> pathLength(N);\n\tstd::queue<int> q;\n\tq.push(source);\n\tpathLength[source] = 0;\n\n\twhile (!q.empty()) {\n\t\tint curr = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < static_cast<int>(N); ++i) {\n\t\t\tif (pathLength[i] > pathLength[curr] && A[curr * N + i] == 1) {\n\t\t\t\tq.push(i);\n\t\t\t\tpathLength[i] = pathLength[curr] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn pathLength[dest];\n}",
            "// For every node, we need to know whether it has been processed, and the distance\n\t// to that node from the source.\n\tstd::vector<int> processed(N);\n\tstd::vector<int> distance(N, -1);\n\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\tprocessed[source] = 0;\n\tdistance[source] = 0;\n\tint min = distance[source];\n\n\t// Breadth-first search\n\twhile(!queue.empty()) {\n\t\tint node = queue.front();\n\t\tqueue.pop();\n\n\t\t// Iterate over all neighbours of current node and add them to the queue if they\n\t\t// have not been processed yet.\n\t\tfor(int i=0; i<N; ++i) {\n\t\t\tif(A[node*N + i] == 1) {\n\t\t\t\tif(processed[i] == 0) {\n\t\t\t\t\tqueue.push(i);\n\t\t\t\t\tprocessed[i] = 1;\n\t\t\t\t\tdistance[i] = distance[node] + 1;\n\t\t\t\t}\n\n\t\t\t\t// If we have already processed the neighbour, but the current distance is shorter,\n\t\t\t\t// update the distance.\n\t\t\t\tif(processed[i] == 1 && distance[i] > distance[node] + 1) {\n\t\t\t\t\tdistance[i] = distance[node] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// If the destination has been processed, we can return the distance from the source to\n\t// the destination, otherwise -1.\n\tif(processed[dest] == 1) {\n\t\treturn distance[dest];\n\t} else {\n\t\treturn -1;\n\t}\n}",
            "// Your code goes here\n    std::vector<int> d(N, INT_MAX);\n    std::vector<int> prev(N, -1);\n    d[source] = 0;\n    int u = source;\n    while(u!= dest){\n        for(int v = 0; v < N; ++v){\n            if(A[u*N + v] && d[u]!= INT_MAX && d[u] + 1 < d[v]){\n                d[v] = d[u] + 1;\n                prev[v] = u;\n            }\n        }\n        int min = INT_MAX;\n        for(int v = 0; v < N; ++v){\n            if(d[v] < min && d[v]!= INT_MAX)\n                min = d[v];\n        }\n        u = -1;\n        for(int v = 0; v < N; ++v){\n            if(d[v] == min && d[v]!= INT_MAX)\n                u = v;\n        }\n    }\n    std::vector<int> path;\n    int cur = dest;\n    while(prev[cur]!= -1){\n        path.push_back(cur);\n        cur = prev[cur];\n    }\n    path.push_back(cur);\n    std::reverse(path.begin(), path.end());\n    std::cout << \"Path: \";\n    for(auto i : path)\n        std::cout << i << \" \";\n    std::cout << std::endl;\n    return d[dest];\n}",
            "// TODO: implement me\n  std::vector<int> distance(N, INT_MAX);\n  distance[source] = 0;\n\n  std::vector<bool> seen(N, false);\n\n  std::queue<int> q;\n  q.push(source);\n\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n    seen[u] = true;\n    for (int i = 0; i < N; i++) {\n      if (A[u * N + i] == 1 &&!seen[i]) {\n        distance[i] = distance[u] + 1;\n        q.push(i);\n      }\n    }\n  }\n\n  return distance[dest];\n}",
            "// The number of vertices in the graph\n  // The length of the shortest path from the source to the destination\n  std::vector<int> distance(N);\n\n  for (int i = 0; i < N; ++i) {\n    distance[i] = INT_MAX;\n  }\n\n  distance[source] = 0;\n\n  // The set of visited vertices\n  std::vector<bool> visited(N);\n\n  // Initialize all vertices as not visited\n  for (int i = 0; i < N; ++i) {\n    visited[i] = false;\n  }\n\n  // A queue to store the next vertices to be processed\n  std::queue<int> q;\n  q.push(source);\n\n  while (!q.empty()) {\n    int v = q.front();\n    q.pop();\n\n    if (v == dest) {\n      break;\n    }\n\n    visited[v] = true;\n\n    for (int i = 0; i < N; ++i) {\n      if (A[v * N + i] == 1 &&!visited[i]) {\n        q.push(i);\n        distance[i] = distance[v] + 1;\n      }\n    }\n  }\n\n  return distance[dest];\n}",
            "if (source == dest)\n        return 0;\n\n    std::vector<int> dist = std::vector<int>(N, std::numeric_limits<int>::max());\n    dist[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty()) {\n        int node = q.front();\n        q.pop();\n\n        for (size_t i = 0; i < N; i++) {\n            if (A[node * N + i] && dist[i] > dist[node] + 1) {\n                dist[i] = dist[node] + 1;\n                q.push(i);\n            }\n        }\n    }\n\n    if (dist[dest] == std::numeric_limits<int>::max())\n        return -1;\n\n    return dist[dest];\n}",
            "// create a graph\n    std::vector<std::vector<int>> g(N, std::vector<int>(N));\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            g[i][j] = A[i * N + j];\n        }\n    }\n\n    // create a BFS queue\n    std::queue<std::pair<int, int>> bfs;\n\n    // push the source node into the queue\n    bfs.push(std::pair<int, int>(source, 0));\n\n    // store the nodes visited in a vector\n    std::vector<bool> visited(N, false);\n    visited[source] = true;\n\n    // traverse the graph using BFS\n    while (!bfs.empty()) {\n        int u = bfs.front().first;\n        int u_distance = bfs.front().second;\n        bfs.pop();\n\n        // check if we have reached the destination node\n        if (u == dest) return u_distance;\n\n        // traverse the adjacent vertices of the current vertex and enqueue them if they have not been visited\n        for (int v = 0; v < N; v++) {\n            if (g[u][v] == 1 &&!visited[v]) {\n                bfs.push(std::pair<int, int>(v, u_distance + 1));\n                visited[v] = true;\n            }\n        }\n    }\n\n    // if we have not reached the destination node by the time we finish traversing the graph, return -1\n    return -1;\n}",
            "int ret = 0;\n    int max_reachable = -1;\n\n    if (source == dest) {\n        return 0;\n    }\n\n    std::vector<int> reachable(N, -1);\n    std::vector<int> pending;\n    pending.push_back(source);\n\n    while (pending.size() > 0) {\n        auto curr = pending.front();\n        pending.pop_front();\n\n        if (curr == dest) {\n            return ret;\n        }\n\n        if (reachable[curr] == -1) {\n            reachable[curr] = ret;\n        }\n\n        for (int i = 0; i < N; ++i) {\n            if (A[curr * N + i]) {\n                if (reachable[i] == -1) {\n                    pending.push_back(i);\n                } else if (reachable[i] > ret) {\n                    reachable[i] = ret;\n                    if (i == dest) {\n                        return ret + 1;\n                    }\n                }\n            }\n        }\n\n        ++ret;\n    }\n\n    return -1;\n}",
            "if (source == dest) return 0;\n\n\tstd::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\n\tstd::vector<int> prev(N, -1);\n\tstd::queue<int> Q;\n\n\tQ.push(source);\n\n\twhile (!Q.empty()) {\n\t\tint u = Q.front();\n\t\tQ.pop();\n\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u*N + v] == 1 and dist[v] > dist[u] + 1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tprev[v] = u;\n\n\t\t\t\tif (v == dest) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tQ.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (prev[dest] == -1) {\n\t\treturn -1;\n\t}\n\n\tint curr = dest;\n\tint distSum = 0;\n\twhile (curr!= source) {\n\t\tcurr = prev[curr];\n\t\tdistSum += 1;\n\t}\n\n\treturn distSum;\n}",
            "// write your code here\n  std::vector<bool> visited(N);\n  std::vector<int> dist(N, std::numeric_limits<int>::max());\n\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n\n  while (!q.empty()) {\n    int v = q.front();\n    q.pop();\n\n    if (visited[v]) {\n      continue;\n    }\n\n    visited[v] = true;\n\n    for (int i = 0; i < N; ++i) {\n      if (A[N * v + i] == 0 || visited[i]) {\n        continue;\n      }\n\n      if (dist[i] > dist[v] + 1) {\n        dist[i] = dist[v] + 1;\n        q.push(i);\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "std::vector<int> dists(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    dists[source] = 0;\n    while (!q.empty()) {\n        int i = q.front();\n        q.pop();\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j] == 0 || dists[j] >= 0)\n                continue;\n            dists[j] = dists[i] + 1;\n            q.push(j);\n            if (j == dest)\n                return dists[j];\n        }\n    }\n    return -1;\n}",
            "std::vector<int> d(N, std::numeric_limits<int>::max());\n  d[source] = 0;\n  std::queue<int> Q;\n  Q.push(source);\n  while (!Q.empty()) {\n    int u = Q.front();\n    Q.pop();\n    for (size_t v = 0; v < N; ++v) {\n      if (A[u * N + v] == 0) continue;\n      if (d[v] > d[u] + 1) {\n        d[v] = d[u] + 1;\n        Q.push(v);\n      }\n    }\n  }\n  return d[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    std::deque<int> Q;\n    Q.push_back(source);\n    std::set<int> visited;\n    while (!Q.empty()) {\n        int v = Q.front();\n        visited.insert(v);\n        Q.pop_front();\n        for (size_t i = 0; i < N; i++) {\n            if (!A[v * N + i])\n                continue;\n            if (dist[i] > dist[v] + 1) {\n                dist[i] = dist[v] + 1;\n                if (i == dest)\n                    return dist[i];\n                if (visited.find(i) == visited.end())\n                    Q.push_back(i);\n            }\n        }\n    }\n    return -1;\n}",
            "std::vector<int> dist;\n    std::vector<int> prev;\n    std::vector<bool> visited;\n    for(size_t i=0;i<N;i++) {\n        visited.push_back(false);\n        dist.push_back(INT_MAX);\n        prev.push_back(-1);\n    }\n    dist[source] = 0;\n    // Visit the vertex that is currently at the front of the queue.\n    for(int i=0;i<N;i++) {\n        // Choose the next node to expand.\n        int current = -1;\n        for(int i=0;i<N;i++) {\n            if(!visited[i] && ((current==-1) || (dist[i]<dist[current]))) {\n                current = i;\n            }\n        }\n        // Check if we're done\n        if(current == -1) {\n            break;\n        }\n        // Check each neighbor of the current node.\n        visited[current] = true;\n        for(int i=0;i<N;i++) {\n            // The distance from the source to a neighbor is at most\n            // the distance from the source to the current node + the\n            // weight of the edge from the current node to the neighbor.\n            // We can therefore check for a shorter path by first checking\n            // if the neighbor has been visited at all, then checking if\n            // the distance through the current node is shorter than the\n            // previously recorded distance. If so, we save the new distance\n            // and the index of the node we passed through to get to the\n            // neighbor.\n            if(A[current*N + i] == 1 && (!visited[i] || (dist[i]>dist[current]+1))) {\n                dist[i] = dist[current]+1;\n                prev[i] = current;\n            }\n        }\n    }\n    // Walk back to the source node and print the shortest path.\n    int pathLength = 0;\n    int current = dest;\n    while(prev[current]!= -1) {\n        current = prev[current];\n        pathLength++;\n    }\n    return pathLength;\n}",
            "if (source == dest)\n\t\treturn 0;\n\n\tstd::vector<int> minDistance(N, INT_MAX);\n\tminDistance[source] = 0;\n\tstd::priority_queue<Edge, std::vector<Edge>, EdgeComp> pq;\n\tpq.push(Edge(source, 0));\n\n\twhile (!pq.empty()) {\n\t\tint v = pq.top().v;\n\t\tpq.pop();\n\n\t\tif (v == dest)\n\t\t\treturn minDistance[v];\n\n\t\tfor (int u = 0; u < N; u++) {\n\t\t\tif (A[v * N + u] && minDistance[v]!= INT_MAX && minDistance[u] > minDistance[v] + A[v * N + u]) {\n\t\t\t\tminDistance[u] = minDistance[v] + A[v * N + u];\n\t\t\t\tpq.push(Edge(u, minDistance[u]));\n\t\t\t}\n\t\t}\n\t}\n\n\treturn minDistance[dest];\n}",
            "if (source == dest) {\n    return 0;\n  }\n  std::vector<int> dist(N, -1);\n  dist[source] = 0;\n  std::queue<int> q;\n  q.push(source);\n  while (!q.empty()) {\n    int x = q.front();\n    q.pop();\n    for (int i = 0; i < N; ++i) {\n      if (A[x * N + i] == 1 && dist[i] == -1) {\n        dist[i] = dist[x] + 1;\n        q.push(i);\n      }\n    }\n  }\n  return dist[dest];\n}",
            "std::vector<std::vector<int>> dist(N, std::vector<int>(N));\n\n    for (size_t i = 0; i < N; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            dist[i][j] = std::numeric_limits<int>::max();\n        }\n    }\n\n    std::vector<int> queue = {source};\n    dist[source][source] = 0;\n\n    while (!queue.empty()) {\n        size_t const size = queue.size();\n        for (size_t i = 0; i < size; ++i) {\n            int const curr = queue[i];\n            for (size_t j = 0; j < N; ++j) {\n                if (A[curr * N + j] == 0 || dist[source][j]!= std::numeric_limits<int>::max()) {\n                    continue;\n                }\n                dist[source][j] = dist[source][curr] + 1;\n                queue.push_back(j);\n            }\n        }\n        queue.erase(queue.begin(), queue.begin() + size);\n    }\n\n    return dist[source][dest];\n}",
            "if (source == dest)\n        return 0;\n\n    std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    std::vector<bool> visited(N, false);\n    std::vector<int> prev(N, -1);\n    std::vector<int> Q;\n    Q.push_back(source);\n    while (!Q.empty()) {\n        int u = Q.back();\n        Q.pop_back();\n        if (u == dest)\n            break;\n\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] &&!visited[v]) {\n                visited[v] = true;\n                dist[v] = dist[u] + 1;\n                prev[v] = u;\n                Q.push_back(v);\n            }\n        }\n    }\n\n    if (dist[dest] == INT_MAX)\n        return -1;\n    else\n        return dist[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tint n_steps = 0;\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> predecessors(N, -1);\n\tvisited[source] = true;\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tauto node = q.front();\n\t\tq.pop();\n\t\tif (node == dest) break;\n\t\tfor (auto i = 0u; i < N; ++i) {\n\t\t\tif (!visited[i] && A[node * N + i]) {\n\t\t\t\tvisited[i] = true;\n\t\t\t\tdist[i] = dist[node] + 1;\n\t\t\t\tq.push(i);\n\t\t\t\tpredecessors[i] = node;\n\t\t\t}\n\t\t}\n\t\t++n_steps;\n\t}\n\tif (dist[dest] == -1) return -1;\n\tint v = dest;\n\twhile (v!= -1) {\n\t\tif (predecessors[v]!= -1) {\n\t\t\tn_steps += dist[v] - dist[predecessors[v]] - 1;\n\t\t\tv = predecessors[v];\n\t\t} else {\n\t\t\tv = -1;\n\t\t}\n\t}\n\treturn n_steps;\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tint n = std::numeric_limits<int>::max();\n\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\tif (dist[j]!= std::numeric_limits<int>::max()) {\n\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\tn = std::min(n, dist[j] + A[j * N + k]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tdist[source] = n;\n\t}\n\treturn dist[dest];\n}",
            "std::vector<int> distances(N, std::numeric_limits<int>::max());\n    std::vector<int> visited(N, 0);\n    distances[source] = 0;\n    std::vector<int> Q;\n    Q.push_back(source);\n\n    while (Q.size() > 0) {\n        int u = Q.back();\n        Q.pop_back();\n        for (int v = 0; v < N; ++v) {\n            if (A[N * u + v] &&!visited[v]) {\n                distances[v] = distances[u] + 1;\n                Q.push_back(v);\n            }\n        }\n        visited[u] = 1;\n    }\n\n    return distances[dest];\n}",
            "int result = -1;\n\n\t// Your code here\n\t\n\t// Initialization\n\tstd::vector<int> distances(N, INFINITY);\n\tstd::vector<bool> visisted(N, false);\n\t\n\t// BFS\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\tdistances[source] = 0;\n\t\n\twhile(!queue.empty())\n\t{\n\t\tint current = queue.front();\n\t\tqueue.pop();\n\t\tif (current == dest)\n\t\t\treturn distances[current];\n\t\t\n\t\tfor (int i = 0; i < N; ++i)\n\t\t{\n\t\t\tif (!visisted[i] && A[current * N + i] > 0)\n\t\t\t{\n\t\t\t\tqueue.push(i);\n\t\t\t\tdistances[i] = distances[current] + 1;\n\t\t\t}\n\t\t}\n\t\tvisisted[current] = true;\n\t}\n\t\n\treturn result;\n}",
            "std::vector<int> distance(N, INT_MAX);\n  distance[source] = 0;\n\n  std::queue<int> Q;\n  Q.push(source);\n\n  while (!Q.empty()) {\n    int node = Q.front();\n    Q.pop();\n\n    for (size_t i = 0; i < N; ++i) {\n      if (A[node * N + i]) {\n        if (distance[i] == INT_MAX) {\n          distance[i] = distance[node] + 1;\n          Q.push(i);\n        }\n      }\n    }\n  }\n\n  return distance[dest];\n}",
            "std::vector<bool> visited(N);\n    std::vector<int> length(N, INT_MAX);\n    std::queue<int> q;\n\n    length[source] = 0;\n    q.push(source);\n\n    while (!q.empty()) {\n        auto v = q.front();\n        q.pop();\n        if (v == dest) {\n            break;\n        }\n        visited[v] = true;\n        for (size_t i = 0; i < N; i++) {\n            if (A[v * N + i] == 1 && visited[i] == false) {\n                q.push(i);\n                length[i] = length[v] + 1;\n            }\n        }\n    }\n\n    return length[dest];\n}",
            "// TODO: write your code here\n    int res = 0;\n    std::vector<int> dist(N, INT_MAX);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n    while(!q.empty())\n    {\n        auto node = q.front();\n        q.pop();\n        \n        for(int i=0; i<N; i++)\n        {\n            if(A[node*N+i] && dist[i]>dist[node]+1)\n            {\n                dist[i] = dist[node]+1;\n                q.push(i);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "// Your code here\n    if (source == dest)\n        return 0;\n\n    auto adj = A;\n    std::vector<int> dist(N, INT_MAX);\n    std::vector<int> prev(N, -1);\n    std::queue<int> q;\n    dist[source] = 0;\n    q.push(source);\n\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n\n        for (size_t i = 0; i < N; ++i) {\n            if (adj[u * N + i] == 1 && dist[i] == INT_MAX) {\n                dist[i] = dist[u] + 1;\n                prev[i] = u;\n                q.push(i);\n            }\n        }\n    }\n\n    if (dist[dest] == INT_MAX)\n        return -1;\n\n    std::vector<int> path;\n    for (int v = dest; v!= -1; v = prev[v]) {\n        path.push_back(v);\n    }\n\n    return path.size();\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\t\n\tstd::queue<int> q;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[node * N + i]!= 0) {\n\t\t\t\tif (dist[i] > dist[node] + 1) {\n\t\t\t\t\tdist[i] = dist[node] + 1;\n\t\t\t\t\tq.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "std::vector<int> dist(N, INF);\n  std::queue<int> q;\n  q.push(source);\n  dist[source] = 0;\n  while (!q.empty()) {\n    int v = q.front();\n    q.pop();\n    for (int u = 0; u < N; u++) {\n      if (A[v * N + u] == 1 && dist[u] == INF) {\n        dist[u] = dist[v] + 1;\n        q.push(u);\n      }\n    }\n  }\n  return dist[dest];\n}",
            "// TODO: Implement\n\treturn 0;\n}",
            "std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (dist[j]!= INT_MAX && A[N*j + i]!= 0)\n                dist[j] = std::min(dist[j], dist[i] + 1);\n        }\n    }\n    return dist[dest];\n}",
            "if(source < 0 || source >= N || dest < 0 || dest >= N) {\n\t\tthrow std::invalid_argument(\"Source or destination is not valid for the graph.\");\n\t}\n\n\t// Create a disjoint set for union find.\n\tDisjointSet ds(N);\n\n\t// The bfs queue holds the state: (parent vertex, path length from source to parent vertex).\n\tstd::queue<std::pair<int, int> > q;\n\tq.push(std::make_pair(source, 0));\n\n\t// Process the bfs queue until it is empty.\n\twhile(!q.empty()) {\n\t\t// Get the current state (parent vertex, path length from source to parent vertex).\n\t\tint parent = q.front().first;\n\t\tint pathLength = q.front().second;\n\t\tq.pop();\n\n\t\t// If we found the shortest path to the destination vertex, return the path length.\n\t\tif(parent == dest) {\n\t\t\treturn pathLength;\n\t\t}\n\n\t\t// Add the children of the current vertex to the bfs queue.\n\t\tfor(int i = 0; i < N; ++i) {\n\t\t\t// If the current vertex is connected to the child vertex, and the child vertex is not part of the same set as the parent vertex,\n\t\t\t// add the child vertex to the bfs queue.\n\t\t\tif(A[parent*N + i] == 1 && ds.find(i)!= parent) {\n\t\t\t\tq.push(std::make_pair(i, pathLength + 1));\n\t\t\t\tds.unionSets(parent, i);\n\t\t\t}\n\t\t}\n\t}\n\n\t// If we didn't find the shortest path to the destination vertex, return -1.\n\treturn -1;\n}",
            "assert(source < N);\n\tassert(dest < N);\n\tassert(A.size() == N*N);\n\n\t// Use Breadth First Search to find the shortest path\n\t// The first value is the distance and the second value is the predecessor index\n\t// A value of -1 means the index has not been visited yet\n\tstd::vector<std::pair<int, int>> distances(N, {-1, -1});\n\tdistances[source] = {0, source};\n\t\n\tstd::queue<int> queue;\n\tqueue.push(source);\n\n\twhile(!queue.empty()) {\n\t\tint curr = queue.front();\n\t\tqueue.pop();\n\t\tif(curr == dest) {\n\t\t\treturn distances[curr].first;\n\t\t}\n\t\tfor(size_t j = 0; j < N; j++) {\n\t\t\tif(A[N * curr + j] && distances[j].first == -1) {\n\t\t\t\tqueue.push(j);\n\t\t\t\tdistances[j] = {distances[curr].first + 1, curr};\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}",
            "const int INF = N + 1;\n\tstd::vector<int> dist(N, INF);\n\tdist[source] = 0;\n\n\t// relax vertices iteratively until no more changes are made\n\t// to distance (dijkstra)\n\tbool relaxed = true;\n\twhile (relaxed) {\n\t\trelaxed = false;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\t// relax edges only if a shorter path exists\n\t\t\t\tif (dist[i]!= INF && A[i * N + j]!= 0 && dist[i] + A[i * N + j] < dist[j]) {\n\t\t\t\t\tdist[j] = dist[i] + A[i * N + j];\n\t\t\t\t\trelaxed = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "std::queue<int> q;\n\tint distance[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tdistance[i] = 0;\n\t}\n\n\tq.push(source);\n\tdistance[source] = 1;\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node * N + i] == 1 && distance[i] == 0) {\n\t\t\t\tdistance[i] = distance[node] + 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> distances(N);\n\tstd::vector<bool> visited(N);\n\tstd::queue<int> q;\n\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tdistances[i] = std::numeric_limits<int>::max();\n\t\tvisited[i] = false;\n\t}\n\n\tdistances[source] = 0;\n\tvisited[source] = true;\n\tq.push(source);\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\t\tvisited[node] = true;\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (!visited[i] && A[node * N + i] == 1 && distances[i] > distances[node] + 1) {\n\t\t\t\tdistances[i] = distances[node] + 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest];\n}",
            "std::vector<int> dist(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    dist[source] = 0;\n\n    while (!q.empty()) {\n        int curr = q.front();\n        q.pop();\n        for (int i = 0; i < N; ++i) {\n            if (A[curr * N + i] == 0)\n                continue;\n            if (dist[i] == -1) {\n                dist[i] = dist[curr] + 1;\n                q.push(i);\n            }\n        }\n    }\n\n    return dist[dest];\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "hip",
        "prompt": "/* Compute the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Store the result in pathLength.\n   Use AMD HIP to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\n__global__ void shortestPathLength(const int *A, size_t N, int source, int dest, int *pathLength) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int row = blockDim.y * blockIdx.y + threadIdx.y;\n    int col = blockDim.x * blockIdx.x + threadIdx.x;\n\n    __shared__ int visited[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ int dist[BLOCK_SIZE][BLOCK_SIZE];\n\n    int myDist = MAX_DISTANCE;\n    if (row == col) {\n        myDist = 0;\n    }\n    dist[threadIdx.x][threadIdx.y] = myDist;\n    visited[threadIdx.x][threadIdx.y] = 0;\n\n    __syncthreads();\n\n    if (row < N && col < N && A[row * N + col] == 1) {\n        int minDist = min(dist[threadIdx.x][threadIdx.y], dist[threadIdx.y][threadIdx.x]);\n        if (minDist < myDist) {\n            visited[threadIdx.x][threadIdx.y] = 1;\n            dist[threadIdx.x][threadIdx.y] = minDist + 1;\n        }\n    }\n    __syncthreads();\n\n    if (row == col && row == source) {\n        // Set the distance to the source to 0.\n        dist[threadIdx.x][threadIdx.y] = 0;\n        visited[threadIdx.x][threadIdx.y] = 0;\n    }\n    __syncthreads();\n\n    for (int i = 0; i < 32; ++i) {\n        if (row < N && col < N) {\n            int minDist = min(dist[threadIdx.x][threadIdx.y], dist[threadIdx.y][threadIdx.x]);\n            if (minDist < myDist) {\n                visited[threadIdx.x][threadIdx.y] = 1;\n                dist[threadIdx.x][threadIdx.y] = minDist + 1;\n            }\n        }\n        __syncthreads();\n    }\n\n    __syncthreads();\n\n    if (row == col && visited[threadIdx.x][threadIdx.y] == 1) {\n        if (col == dest) {\n            *pathLength = dist[threadIdx.x][threadIdx.y];\n        }\n    }\n}",
            "// Get our global thread ID\n    int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    __shared__ bool pathFound;\n    __shared__ int *distance;\n    __shared__ int *previous;\n\n    if (threadIdx.x == 0) {\n        pathFound = false;\n        distance = new int[N];\n        previous = new int[N];\n    }\n\n    // Wait for all threads to finish\n    __syncthreads();\n\n    if (id < N) {\n        distance[id] = INT_MAX;\n        previous[id] = -1;\n    }\n\n    __syncthreads();\n\n    distance[source] = 0;\n    __syncthreads();\n\n    bool converged = false;\n    while (!converged) {\n        __syncthreads();\n        if (id < N) {\n            int rowStart = id * N;\n\n            for (int j = 0; j < N; j++) {\n                int distanceFromSource = distance[id];\n                int distanceViaCurrent = distanceFromSource + A[rowStart + j];\n\n                if (distanceViaCurrent < distance[j]) {\n                    distance[j] = distanceViaCurrent;\n                    previous[j] = id;\n                }\n            }\n        }\n        __syncthreads();\n        converged = true;\n\n        if (id < N) {\n            int rowStart = id * N;\n\n            for (int j = 0; j < N; j++) {\n                if (A[rowStart + j] == 0) {\n                    distance[j] = INT_MAX;\n                    previous[j] = -1;\n                }\n\n                if (distance[j] < distance[id]) {\n                    converged = false;\n                }\n            }\n        }\n        __syncthreads();\n    }\n\n    if (id == dest && distance[dest]!= INT_MAX) {\n        pathFound = true;\n    }\n\n    __syncthreads();\n\n    if (pathFound) {\n        int distanceFromSource = distance[dest];\n        int distanceFromPrevious = INT_MAX;\n        int current = dest;\n\n        while (previous[current]!= -1) {\n            distanceFromPrevious = distanceFromSource;\n            distanceFromSource = distance[previous[current]];\n            current = previous[current];\n        }\n\n        *pathLength = distanceFromSource + distanceFromPrevious;\n    } else {\n        *pathLength = INT_MAX;\n    }\n\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        delete[] distance;\n        delete[] previous;\n    }\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n\n\t__shared__ int cache[1024];\n\n\tint depth = 0;\n\n\twhile (id < N) {\n\t\tint s = __ldg(&A[id*N+source]);\n\t\tint d = __ldg(&A[id*N+dest]);\n\n\t\tif (s == 1 || d == 1) {\n\t\t\tif (s == 1) {\n\t\t\t\t//source to id\n\t\t\t\tcache[threadIdx.x] = depth;\n\t\t\t} else {\n\t\t\t\t//id to dest\n\t\t\t\tcache[threadIdx.x] = depth + 1;\n\t\t\t}\n\n\t\t\t__syncthreads();\n\n\t\t\tfor (int i = 1; i < blockDim.x; i <<= 1) {\n\t\t\t\tif (threadIdx.x >= i) {\n\t\t\t\t\tcache[threadIdx.x] = min(cache[threadIdx.x], cache[threadIdx.x - i]);\n\t\t\t\t}\n\t\t\t\t__syncthreads();\n\t\t\t}\n\n\t\t\tint len = cache[threadIdx.x];\n\t\t\tif (threadIdx.x == 0) {\n\t\t\t\tint minlen = len;\n\t\t\t\tfor (int i = 0; i < blockDim.x; i++) {\n\t\t\t\t\tminlen = min(minlen, cache[i]);\n\t\t\t\t}\n\t\t\t\tif (minlen < pathLength[0]) {\n\t\t\t\t\tpathLength[0] = minlen;\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\n\t\t\tdepth++;\n\t\t}\n\n\t\tid += blockDim.x*gridDim.x;\n\t}\n}",
            "int x = blockIdx.x;\n  int y = blockIdx.y;\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n\n  int offset = y * (N - 1) + x;\n\n  int u = (tx + offset) / (N - 1);\n  int v = (tx + offset) % (N - 1);\n\n  if (A[u * N + v]!= 0) {\n    // We want the distance to be +inf if we haven't reached this vertex yet.\n    // The distance is only updated if it's larger than the current distance plus the edge weight.\n    if (u == source) {\n      pathLength[v] = A[u * N + v];\n    } else if (u == dest) {\n      if (pathLength[v] > pathLength[u] + A[u * N + v]) {\n        pathLength[v] = pathLength[u] + A[u * N + v];\n      }\n    } else if (pathLength[u]!= INF) {\n      if (pathLength[v] > pathLength[u] + A[u * N + v]) {\n        pathLength[v] = pathLength[u] + A[u * N + v];\n      }\n    }\n  }\n\n  __syncthreads();\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n   int pathLength_tid = pathLength[tid];\n   //if the source node is not the same as the destination node\n   //and the source node is not the same as the current thread\n   //and the destination node is not the same as the current thread\n   if((source!= dest) && (source!= tid) && (dest!= tid)){\n\t\tint pathLength_source = pathLength[source];\n\t\tint pathLength_dest = pathLength[dest];\n\t\tif((pathLength_source == 0) && (pathLength_dest == 0)){\n\t\t\t//if the path length to the source node is 0, and the path length to the destination node is 0\n\t\t\t//then the path length is 1\n\t\t\tpathLength[tid] = 1;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = 1;\n\t\t}\n\t\telse if((pathLength_source == 0) && (pathLength_tid == 1)){\n\t\t\t//if the path length to the source node is 0, and the path length to the current thread is 1\n\t\t\t//then the path length is 2\n\t\t\tpathLength[tid] = 2;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = 2;\n\t\t}\n\t\telse if((pathLength_dest == 0) && (pathLength_tid == 1)){\n\t\t\t//if the path length to the destination node is 0, and the path length to the current thread is 1\n\t\t\t//then the path length is 2\n\t\t\tpathLength[tid] = 2;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = 2;\n\t\t}\n\t\telse if((pathLength_source == 0) && (pathLength_dest == 0)){\n\t\t\t//if the path length to the source node is 0, and the path length to the destination node is 0\n\t\t\t//then the path length is 1\n\t\t\tpathLength[tid] = 1;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = 1;\n\t\t}\n\t}\n   __syncthreads();\n   //if the current thread's path length is still 0 (neither the source or destination node)\n   //then compute the path length\n   if(pathLength_tid == 0){\n\t\t//if the current node is connected to the source node\n\t\tif(A[source * N + tid]!= 0){\n\t\t\t//update the path length to the current node\n\t\t\tpathLength[tid] = pathLength[source] + 1;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = pathLength[source] + 1;\n\t\t}\n\t\t//if the current node is connected to the destination node\n\t\tif(A[tid * N + dest]!= 0){\n\t\t\t//update the path length to the current node\n\t\t\tpathLength[tid] = pathLength[dest] + 1;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = pathLength[dest] + 1;\n\t\t}\n\t}\n   __syncthreads();\n   //if the current thread's path length is still 0 (neither the source or destination node)\n   //then compute the path length\n   if(pathLength_tid == 0){\n\t\t//if the current node is connected to the source node\n\t\tif(A[source * N + tid]!= 0){\n\t\t\t//update the path length to the current node\n\t\t\tpathLength[tid] = pathLength[source] + 1;\n\t\t\t//update the current thread's path length\n\t\t\tpathLength_tid = pathLength[source] + 1;\n\t\t}\n\t\t//if the current node is connected to the destination node\n\t\tif(A[tid * N + dest]!= 0){\n\t\t\t//update the path length to the current node\n\t\t\tpathLength[tid] = pathLength[dest] + 1;",
            "/* Your code goes here */\n\t__shared__ int dist[BLOCK_SIZE*BLOCK_SIZE];\n\tint bx = blockIdx.x;\n\tint tx = threadIdx.x;\n\n\tint bsize = BLOCK_SIZE;\n\tint bid = bx * bsize + tx;\n\n\tdist[bid] = -1;\n\t__syncthreads();\n\n\t//bid is the thread id in the block\n\tif (bid == source) {\n\t\tdist[bid] = 0;\n\t}\n\n\t__syncthreads();\n\n\tfor(int i = 0; i < N; i++) {\n\t\tint s = (bid * N + bid) * bsize;\n\t\tif (tx < bsize && bid < N) {\n\t\t\tdist[bid] = min(dist[bid], dist[bid] + A[s]);\n\t\t}\n\t\t__syncthreads();\n\t\ts = (bid * N + tx) * bsize;\n\t\tif (tx < bsize && bid < N) {\n\t\t\tdist[bid] = min(dist[bid], dist[tx] + A[s]);\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t*pathLength = dist[bid];\n}",
            "int row = blockIdx.x;\n  int col = threadIdx.x;\n  if (col == 0) {\n    if (A[row * N + col]!= 0 && row!= source) {\n      pathLength[row] = INT_MAX;\n    } else if (row == source) {\n      pathLength[row] = 0;\n    } else {\n      pathLength[row] = -1;\n    }\n  }\n\n  __syncthreads();\n\n  for (int i = 0; i < N; ++i) {\n    __syncthreads();\n\n    int next = pathLength[col];\n    if (next!= -1) {\n      if (row == source) {\n        next = 0;\n      }\n      int dist = A[row * N + col];\n      if (dist!= 0) {\n        dist += next;\n      } else {\n        dist = INT_MAX;\n      }\n      if (dist < pathLength[row]) {\n        pathLength[row] = dist;\n      }\n    }\n  }\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int j = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif (i < N && j < N) {\n\t\tint isShortestPath = A[i*N + j] && (i == source || i == dest);\n\t\t*pathLength = isShortestPath? min(*pathLength, j-i) : *pathLength;\n\t}\n}",
            "// TODO: implement\n    int row = blockIdx.y;\n    int col = blockIdx.x;\n    int tid = threadIdx.x;\n    int trow = blockDim.y;\n    int tcol = blockDim.x;\n    int bid = blockIdx.y*gridDim.x + blockIdx.x;\n    int tid_num = trow*tcol;\n    int bid_num = gridDim.y*gridDim.x;\n    int warp_num = bid_num/WARP_SIZE;\n\n    __shared__ int sdata[WARP_SIZE];\n    int id = bid*tid_num + tid;\n    int row_start = row*N;\n    int row_end = (row+1)*N;\n    int col_start = col*N;\n    int col_end = (col+1)*N;\n    int i;\n    int min_length = 0x3fffffff;\n    if(row == col){\n        sdata[tid] = 0;\n    }else if(row < col){\n        sdata[tid] = 0x3fffffff;\n    }else{\n        for(i = row_start+col; i < row_end; i += N){\n            if(A[i] == 1 && A[i] < min_length){\n                min_length = A[i];\n            }\n        }\n        sdata[tid] = min_length;\n    }\n    __syncthreads();\n\n    for(int i = WARP_SIZE/2; i >= 1; i /= 2){\n        if(tid < i){\n            sdata[tid] = min(sdata[tid], sdata[tid+i]);\n        }\n    }\n\n    if(tid == 0){\n        atomicMin(&pathLength[bid], sdata[0]);\n    }\n}",
            "const int tid = blockIdx.x * blockDim.x + threadIdx.x; // global thread index\n   __shared__ int myPathLength[256]; // shared array to store thread data\n   myPathLength[tid] = -1;\n   if (tid == source) myPathLength[tid] = 0;\n   __syncthreads();\n   for (int i = 0; i < N; i++) {\n      int newLength = -1;\n      if (tid < N) {\n         int u = tid;\n         int v = A[u * N + i];\n         newLength = myPathLength[u] + 1;\n         if (v >= 0) {\n            newLength = myPathLength[v] + 1;\n         }\n      }\n      __syncthreads();\n      myPathLength[tid] = newLength;\n      __syncthreads();\n   }\n   if (tid == dest) *pathLength = myPathLength[tid];\n}",
            "// TODO: Replace me!\n    const size_t i = blockIdx.x;\n    const size_t j = blockIdx.y;\n    const size_t k = threadIdx.x;\n\n    __shared__ int visited[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ int dist[BLOCK_SIZE][BLOCK_SIZE];\n    __shared__ int queue[BLOCK_SIZE];\n    int cur = 0;\n\n    int *visited_p = &visited[k][0];\n    int *dist_p = &dist[k][0];\n    int *queue_p = &queue[k];\n\n    if (i == j) {\n        if (k == 0) {\n            // Initialize the visited and distance arrays to 0.\n            for (int l = 0; l < N; ++l) {\n                visited_p[l] = 0;\n                dist_p[l] = 0;\n            }\n            // Set the source node to 1.\n            dist_p[source] = 1;\n            // Set the destination node to 2.\n            dist_p[dest] = 2;\n            // Add the source node to the queue.\n            queue_p[0] = source;\n        }\n        cur = k;\n    }\n\n    // TODO: Replace me!\n    __syncthreads();\n\n    // Perform BFS to search for the shortest path.\n    while (queue_p[cur]!= -1) {\n        // Get the current node from the queue.\n        int node = queue_p[cur];\n        // Mark the current node as visited.\n        visited_p[node] = 1;\n        cur = (cur + 1) % BLOCK_SIZE;\n\n        // Check all the neighbors of the current node.\n        for (int neighbor = 0; neighbor < N; ++neighbor) {\n            if (visited_p[neighbor] == 0 && A[node * N + neighbor] == 1) {\n                // Update the distance for the neighboring node.\n                dist_p[neighbor] = dist_p[node] + 1;\n                // Add the neighboring node to the queue.\n                queue_p[(cur + 1) % BLOCK_SIZE] = neighbor;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    // Store the result in pathLength.\n    pathLength[i] = dist_p[dest];\n}",
            "// Obtain the 1D thread index.\n    const int threadIndex = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // Create a shared array to store the shortest path lengths from source to each vertex v.\n    extern __shared__ int pathLengths[];\n\n    // Obtain the current vertex, i.e. the row index.\n    const int vertex = threadIndex / blockDim.x;\n\n    // Initially, the length of the shortest path from the source to vertex v is 0.\n    if (vertex == source) {\n        pathLengths[vertex] = 0;\n    } else {\n        pathLengths[vertex] = MAX_DISTANCE;\n    }\n\n    __syncthreads();\n\n    // Obtain the current edge, i.e. the column index.\n    const int edge = threadIndex % blockDim.x;\n\n    // Update the length of the shortest path from source to vertex v if there is an edge from v to another vertex u.\n    if (A[vertex * N + edge] == 1 && vertex!= edge) {\n        if (pathLengths[vertex] < MAX_DISTANCE) {\n            pathLengths[edge] = pathLengths[vertex] + 1;\n        }\n    }\n\n    __syncthreads();\n\n    // Update the length of the shortest path from source to vertex v if there is an edge from v to another vertex u.\n    if (A[vertex * N + edge] == 1 && vertex!= edge) {\n        if (pathLengths[vertex] < MAX_DISTANCE) {\n            pathLengths[edge] = pathLengths[vertex] + 1;\n        }\n    }\n\n    __syncthreads();\n\n    // Obtain the current edge, i.e. the column index.\n    const int edge2 = threadIndex % blockDim.x;\n\n    // Update the length of the shortest path from source to vertex v if there is an edge from v to another vertex u.\n    if (A[vertex * N + edge2] == 1 && vertex!= edge2) {\n        if (pathLengths[vertex] < MAX_DISTANCE) {\n            pathLengths[edge2] = pathLengths[vertex] + 1;\n        }\n    }\n\n    __syncthreads();\n\n    // Compute the length of the shortest path from source to vertex v.\n    if (vertex == dest) {\n        *pathLength = pathLengths[dest];\n    }\n}",
            "// TODO: implement\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bx = blockIdx.x;\n  int by = blockIdx.y;\n  int bw = blockDim.x;\n  int bh = blockDim.y;\n\n  __shared__ int path[1024];\n  __shared__ int pathLength_s[1024];\n  __shared__ int prev[1024];\n  __shared__ int distance[1024];\n  __shared__ int distance_s[1024];\n  __shared__ bool done[1024];\n\n  if(ty == 0)\n  {\n    path[tx] = 0;\n    pathLength_s[tx] = 0;\n    done[tx] = false;\n    prev[tx] = -1;\n    distance[tx] = 0;\n    distance_s[tx] = 0;\n  }\n  __syncthreads();\n\n  if(tx == source)\n  {\n    if(ty == 0)\n    {\n      path[tx] = 1;\n      pathLength_s[tx] = 0;\n      distance_s[tx] = 0;\n    }\n    __syncthreads();\n  }\n\n  for(int k = 0; k < N; ++k)\n  {\n    __syncthreads();\n    if(ty == k)\n    {\n      distance_s[tx] = distance[tx];\n      __syncthreads();\n      if(tx == source)\n      {\n        if(k == 0)\n        {\n          distance_s[tx] = 0;\n        }\n        if(path[tx] == 1)\n        {\n          path[tx] = path[ty];\n          pathLength_s[tx] = pathLength_s[ty] + 1;\n          distance[tx] = distance_s[ty] + 1;\n        }\n        else if(A[tx * N + ty] == 1)\n        {\n          path[tx] = path[ty];\n          pathLength_s[tx] = pathLength_s[ty] + 1;\n          distance[tx] = distance_s[ty] + 1;\n        }\n      }\n    }\n    __syncthreads();\n  }\n  __syncthreads();\n  if(ty == 0)\n  {\n    if(path[tx] == dest)\n    {\n      done[tx] = true;\n    }\n  }\n  __syncthreads();\n  int min_pathLength = 10000;\n  if(done[tx] && (pathLength_s[tx] < min_pathLength))\n  {\n    if(ty == 0)\n    {\n      min_pathLength = pathLength_s[tx];\n    }\n  }\n  __syncthreads();\n  if(ty == 0)\n  {\n    if(done[tx])\n    {\n      pathLength[tx] = min_pathLength;\n    }\n  }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n    if (tid < N) {\n        pathLength[tid] = -1;\n    }\n\n    __shared__ bool complete;\n    __shared__ int *current;\n    __shared__ int *previous;\n    __shared__ int *dist;\n\n    if (tid < N) {\n        previous = pathLength;\n        current = (tid + N)%2 + pathLength;\n        dist = current + N;\n    }\n\n    // first iteration\n    if (tid == source) {\n        dist[source] = 0;\n    }\n    complete = false;\n\n    while (!complete) {\n        __syncthreads();\n\n        // Relax all edges\n        if (tid < N) {\n            for (int i = 0; i < N; i++) {\n                int w = A[i * N + tid];\n                if (w && (dist[i] + w < dist[tid])) {\n                    current[tid] = i;\n                    dist[tid] = dist[i] + w;\n                }\n            }\n        }\n        __syncthreads();\n\n        if (tid == dest) {\n            complete = (dist[dest]!= INT_MAX);\n        }\n        // swap pointers\n        int *temp = previous;\n        previous = current;\n        current = temp;\n    }\n\n    if (tid == dest) {\n        *pathLength = dist[dest];\n    }\n}",
            "// TODO\n\n\tint sourceIndex = threadIdx.x;\n\tint destIndex = threadIdx.y;\n\tint resultIndex = sourceIndex * N + destIndex;\n\n\tif (A[sourceIndex * N + destIndex] == 1) {\n\t\tif (sourceIndex == destIndex) {\n\t\t\t// Path length from i to i is 0\n\t\t\tpathLength[resultIndex] = 0;\n\t\t}\n\t\telse {\n\t\t\t// Path length from i to j is the shortest path from i to k + the shortest path from k to j\n\t\t\tint min = pathLength[sourceIndex * N + sourceIndex] + pathLength[sourceIndex * N + destIndex];\n\t\t\tpathLength[resultIndex] = min;\n\t\t}\n\t}\n\telse {\n\t\t// There is no path from i to j\n\t\tpathLength[resultIndex] = -1;\n\t}\n}",
            "int threadIdx_x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint threadIdx_y = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (threadIdx_x == threadIdx_y) {\n\t\t// The diagonal of the adjacency matrix is all 0, so we can't possibly get to dest from source.\n\t\tpathLength[threadIdx_x] = 0;\n\t} else if (threadIdx_x < N && threadIdx_y < N) {\n\t\t// The source and destination nodes are in different connected components.\n\t\t// We will never get to dest from source.\n\t\tif (A[N * threadIdx_x + threadIdx_y] == 0 && A[N * threadIdx_y + threadIdx_x] == 0) {\n\t\t\tpathLength[threadIdx_x] = 0;\n\t\t} else {\n\t\t\t// Use Dijkstra's algorithm to find the shortest path length between source and dest.\n\t\t\tbool visited[N];\n\t\t\tfor (int i = 0; i < N; i++) visited[i] = false;\n\t\t\tvisited[source] = true;\n\t\t\tint prev[N];\n\t\t\tfor (int i = 0; i < N; i++) prev[i] = -1;\n\t\t\tint pathLength[N];\n\t\t\tfor (int i = 0; i < N; i++) pathLength[i] = -1;\n\t\t\tpathLength[source] = 0;\n\t\t\twhile (true) {\n\t\t\t\t// Find the node that has the shortest path so far and has not been visited.\n\t\t\t\tint shortest = -1;\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (pathLength[i] >= 0 &&!visited[i]) {\n\t\t\t\t\t\tif (shortest < 0 || pathLength[i] < pathLength[shortest]) shortest = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (shortest < 0) break;\n\t\t\t\tvisited[shortest] = true;\n\t\t\t\t// Find all nodes adjacent to the shortest path.\n\t\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\t\tif (!visited[i] && A[N * shortest + i] == 1) {\n\t\t\t\t\t\tpathLength[i] = pathLength[shortest] + 1;\n\t\t\t\t\t\tprev[i] = shortest;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t// Follow the shortest path from dest to source.\n\t\t\tint cur = dest;\n\t\t\twhile (prev[cur] >= 0) cur = prev[cur];\n\t\t\tpathLength[threadIdx_x] = pathLength[cur] + 1;\n\t\t}\n\t}\n}",
            "// A[source][dest] should be a path of length 1\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i == source) {\n\t\tpathLength[0] = 1;\n\t} else if (i == dest) {\n\t\tpathLength[0] = 2;\n\t} else {\n\t\tpathLength[0] = 0;\n\t}\n\t__syncthreads();\n\n\t// A[i][j] should be a path of length pathLength[j] + 1\n\tfor (int k = 0; k < N; ++k) {\n\t\tint pathLength_k = pathLength[k];\n\t\tif (pathLength_k > 0 && A[i*N+k] > 0) {\n\t\t\tpathLength[i] = pathLength_k + 1;\n\t\t\tbreak;\n\t\t}\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n  if (tid == source) {\n    for (int i = 0; i < N; ++i) {\n      __threadfence();\n      if (i!= source && i!= dest)\n        A[tid * N + i] = INT_MAX;\n      __syncthreads();\n    }\n  }\n  __syncthreads();\n\n  for (int t = 0; t < N; ++t) {\n    __syncthreads();\n\n    if (tid == source && A[tid * N + dest] == INT_MAX) {\n      int *B = new int[N];\n      for (int i = 0; i < N; ++i)\n        B[i] = A[tid * N + i];\n\n      int count = 0;\n      while (count < N) {\n        for (int i = 0; i < N; ++i) {\n          int u = -1, min = INT_MAX;\n          for (int j = 0; j < N; ++j) {\n            if (B[j]!= INT_MAX && B[j] < min) {\n              u = j;\n              min = B[j];\n            }\n          }\n\n          for (int j = 0; j < N; ++j)\n            B[j] = min(B[j], B[u] + A[u * N + j]);\n\n          if (B[dest]!= INT_MAX)\n            count++;\n        }\n      }\n\n      *pathLength = B[dest];\n      delete[] B;\n      break;\n    }\n  }\n}",
            "int tx = hipThreadIdx_x;\n\tint ty = hipThreadIdx_y;\n\tint bx = hipBlockIdx_x;\n\tint by = hipBlockIdx_y;\n\n\tint i = tx + bx * hipBlockDim_x;\n\tint j = ty + by * hipBlockDim_y;\n\n\textern __shared__ int sA[];\n\tsA[tx + ty * hipBlockDim_x] = A[i + j * N];\n\n\t__syncthreads();\n\n\tif (tx < ty) {\n\t\tint tmp = sA[tx + ty * hipBlockDim_x];\n\t\tsA[tx + ty * hipBlockDim_x] = sA[ty + tx * hipBlockDim_x];\n\t\tsA[ty + tx * hipBlockDim_x] = tmp;\n\t}\n\n\t__syncthreads();\n\n\tfor (int k = hipBlockDim_x / 2; k > 0; k >>= 1) {\n\t\tif (tx < k) {\n\t\t\tint tmp = sA[tx + k + ty * hipBlockDim_x];\n\t\t\tsA[tx + k + ty * hipBlockDim_x] = sA[tx + ty * hipBlockDim_x] + sA[k + ty * hipBlockDim_x];\n\t\t\tsA[tx + ty * hipBlockDim_x] = min(tmp, sA[tx + ty * hipBlockDim_x]);\n\t\t}\n\n\t\t__syncthreads();\n\t}\n\n\tif (tx == 0 && i == dest) {\n\t\tpathLength[by * hipBlockDim_y + ty] = sA[ty * hipBlockDim_x];\n\t}\n}",
            "int idx = blockIdx.x*blockDim.x + threadIdx.x;\n    int idy = blockIdx.y*blockDim.y + threadIdx.y;\n    if (idx >= N || idy >= N) return;\n    __shared__ int dist[1024];\n    dist[threadIdx.x] = A[idy*N + idx];\n    __syncthreads();\n    for (int i = 1; i <= N; i++) {\n        if (dist[threadIdx.x] > i) {\n            dist[threadIdx.x] = dist[threadIdx.x] - i;\n            if (idx == dest && idy == source) {\n                pathLength[0] = i;\n            }\n        }\n        __syncthreads();\n    }\n}",
            "__shared__ int dist[MAX_SIZE];\n  int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  dist[tid] = A[tid*N + source];\n  __syncthreads();\n  for (int k = 0; k < N - 1; k++) {\n    if (tid == k)\n      dist[tid] = min(dist[tid], A[k*N + dest]);\n    __syncthreads();\n    if (tid < k)\n      dist[tid] = min(dist[tid], min(dist[tid + 1], A[tid*N + dest]));\n    __syncthreads();\n  }\n  if (tid == 0)\n    *pathLength = dist[0];\n}",
            "unsigned int i, j;\n\ti = blockIdx.x * blockDim.x + threadIdx.x;\n\tj = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i >= N || j >= N || i == j) {\n\t\treturn;\n\t}\n\tif (A[i*N+j] == 1) {\n\t\tpathLength[i] = pathLength[i] + 1;\n\t}\n\treturn;\n}",
            "// TODO: Fill in the implementation.\n    int index = blockDim.x * blockIdx.x + threadIdx.x;\n    if (index >= N) return;\n    if (A[source*N + index]!= 0 && A[index*N + dest]!= 0) {\n        int pathLength_tmp = pathLength[index];\n        int value = A[source*N + index] + A[index*N + dest] + 1;\n        if (pathLength_tmp < 0 || pathLength_tmp > value) {\n            pathLength[index] = value;\n        }\n    }\n}",
            "// TODO: implement\n  // - A is adjacency matrix, N is matrix size\n  // - source and dest are indices of source and dest vertices\n  // - pathLength is output\n  int idx = threadIdx.y * blockDim.x + threadIdx.x;\n  __shared__ int visited[16];\n  __shared__ int dist[16];\n  __shared__ int prev[16];\n  if (idx < N) {\n    visited[idx] = 0;\n    dist[idx] = INT_MAX;\n    prev[idx] = -1;\n  }\n\n  if (idx == source) {\n    dist[source] = 0;\n  }\n  __syncthreads();\n  bool found = false;\n  for (int k = 0; k < N &&!found; k++) {\n    __syncthreads();\n    if (idx == source) {\n      for (int i = 0; i < N &&!found; i++) {\n        if (!visited[i]) {\n          int alt = dist[i] + A[i * N + idx];\n          if (alt < dist[idx]) {\n            dist[idx] = alt;\n            prev[idx] = i;\n          }\n        }\n      }\n    }\n    visited[idx] = 1;\n    __syncthreads();\n  }\n  if (idx == dest) {\n    *pathLength = dist[idx];\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x; // Get current global thread id\n\n    if (tid >= N * N) { // Don't compute if we're out of bounds of the matrix\n        return;\n    }\n\n    int currentVertex = tid / N; // Get current vertex number\n    int currentState = tid % N;  // Get current state number\n\n    int nextVertex = A[tid] - 1; // Get the next vertex number\n\n    if (nextVertex == source && currentVertex == source && currentState == 0) { // Start the path by initializing the shortest path length\n        pathLength[tid] = 0;\n    }\n\n    if (nextVertex == source && currentVertex!= source) { // Don't compute if we're trying to get the shortest path from a source to itself\n        return;\n    }\n\n    if (nextVertex == dest && currentVertex == source) { // Compute the shortest path length from source to dest\n        pathLength[tid] = 1;\n    }\n\n    if (nextVertex!= dest && currentVertex == source && currentState == 1) { // Don't compute if we're trying to get the shortest path from a source to itself\n        return;\n    }\n\n    if (nextVertex!= dest && currentVertex!= source && currentState == 0) { // Don't compute if we're trying to get the shortest path from a source to itself\n        return;\n    }\n\n    if (nextVertex!= dest && currentVertex!= source && currentState == 1) { // Compute the shortest path length from source to dest\n        pathLength[tid] = pathLength[tid - N] + 1;\n    }\n}",
            "__shared__ int cache[DIM][DIM];\n\n\tconst int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x * blockDim.x + threadIdx.x;\n\tint distance = INT_MAX;\n\n\t// check if the source node is reachable from dest\n\tif (col == dest && A[row * N + col] > 0) {\n\t\tdistance = 1;\n\t}\n\n\tif (row == source) {\n\t\tcache[threadIdx.y][threadIdx.x] = 1;\n\t}\n\n\t__syncthreads();\n\n\t// initialize all elements of the 2D array cache with zero\n\tif (threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tfor (int i = 0; i < DIM; i++) {\n\t\t\tfor (int j = 0; j < DIM; j++) {\n\t\t\t\tcache[i][j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t// do multiple passes of relaxation\n\tfor (int i = 0; i < N; i++) {\n\t\t// relax outgoing edges for all nodes\n\t\tif (row < N && col < N) {\n\t\t\tint weight = A[row * N + col];\n\t\t\tif (weight > 0) {\n\t\t\t\tint distance_new = cache[row][col] + weight;\n\t\t\t\t// check if the distance is lower than the distance of the current node\n\t\t\t\tif (distance_new < distance) {\n\t\t\t\t\tdistance = distance_new;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// update cache for the new iteration\n\t\tif (row < N && col < N) {\n\t\t\tcache[row][col] = distance;\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (row == source && col == dest) {\n\t\tpathLength[0] = distance;\n\t}\n}",
            "// TODO: add GPU code here\n  __shared__ int dist[N];\n  int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if(threadIdx.x == 0) {\n    dist[idx] = A[source * N + idx];\n  }\n  __syncthreads();\n  for(int iter = 0; iter < N; iter++) {\n    for(int offset = blockDim.x / 2; offset > 0; offset /= 2) {\n      int id = threadIdx.x;\n      if(id < offset) {\n        int i = id + offset;\n        int j = id;\n        int index_i = blockIdx.x * blockDim.x + i;\n        int index_j = blockIdx.x * blockDim.x + j;\n        if(index_i < N && index_j < N) {\n          if(dist[i] > dist[j] + A[index_i * N + index_j]) {\n            dist[i] = dist[j] + A[index_i * N + index_j];\n          }\n        }\n      }\n      __syncthreads();\n    }\n  }\n\n  if(threadIdx.x == 0) {\n    pathLength[0] = dist[dest];\n  }\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n  if (idx >= N)\n    return;\n  __shared__ int dist[BLOCK_DIM * BLOCK_DIM];\n  __shared__ bool visited[BLOCK_DIM * BLOCK_DIM];\n  // Initialize the distance and visited arrays\n  dist[threadIdx.x] = INT_MAX;\n  visited[threadIdx.x] = false;\n  __syncthreads();\n\n  // source vertex has distance 0\n  if (idx == source) {\n    dist[threadIdx.x] = 0;\n  }\n\n  // Initialize the distances of all other vertices as INFINITE\n  if (idx!= source) {\n    dist[threadIdx.x] = INT_MAX;\n  }\n\n  // Mark the current vertex as visited\n  visited[threadIdx.x] = true;\n  __syncthreads();\n\n  // Relax all edges for all vertices\n  for (int i = 0; i < N; i++) {\n    int v = (A[idx * N + i] == 0)? INT_MAX : 1;\n    if (v < dist[threadIdx.x]) {\n      dist[threadIdx.x] = v;\n    }\n    __syncthreads();\n  }\n\n  // The shortest path from source to dest has the final distance stored in dist[dest]\n  if (idx == dest) {\n    *pathLength = dist[threadIdx.x];\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(tid == dest) {\n\t\tpathLength[tid] = 0;\n\t} else if(tid == source) {\n\t\tpathLength[tid] = 1;\n\t}\n\t__syncthreads();\n\n\tfor(int i = 0; i < N - 1; i++) {\n\t\tif(tid == dest) {\n\t\t\tpathLength[tid] = 1e9;\n\t\t}\n\t\t__syncthreads();\n\n\t\tif(tid < N) {\n\t\t\tint oldPathLength = pathLength[tid];\n\t\t\tpathLength[tid] = min(oldPathLength, A[tid * N + source]);\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "// TODO: implement\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid == source) {\n    // if we are on the source node, we know the path length to be 0\n    *pathLength = 0;\n  } else {\n    // otherwise we need to compute the path length\n    int minPathLength = INT_MAX;\n    for (int i = 0; i < N; i++) {\n      if (A[i*N + tid]!= 0) {\n        int pathLengthToNeighbor = 1 + pathLength[i];\n        minPathLength = min(minPathLength, pathLengthToNeighbor);\n      }\n    }\n    pathLength[tid] = minPathLength;\n  }\n}",
            "extern __shared__ int dist[];\n  int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // Initialize distance to INFINITE if id is source, otherwise it's 0\n  dist[id] = id == source? INFINITE : 0;\n\n  __syncthreads();\n\n  int iter = 0;\n  while (true) {\n    bool updated = false;\n\n    for (int j = 0; j < N; j++) {\n      int jDistance = dist[j];\n      int iDistance = dist[id];\n\n      // If iDistance < INFINITE, then i can reach j through id\n      if (iDistance!= INFINITE && jDistance > iDistance + A[id * N + j]) {\n        // j can be reached from id through i, so update its distance\n        dist[j] = iDistance + A[id * N + j];\n        updated = true;\n      }\n    }\n\n    __syncthreads();\n\n    // Terminate the loop when nothing gets updated\n    if (!updated) {\n      break;\n    }\n\n    __syncthreads();\n  }\n\n  // Check if the destination was reached\n  if (dist[dest]!= INFINITE) {\n    pathLength[0] = dist[dest];\n  }\n}",
            "int i, j, k;\n\tint minLength = INT_MAX;\n\n\tfor (k = 0; k < N; k++) {\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tfor (j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] < minLength && (i == source || A[i * N + k] + A[k * N + j] < minLength)) {\n\t\t\t\t\tminLength = A[i * N + j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t*pathLength = minLength;\n}",
            "int tid = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int visited[32];\n\t__shared__ int distances[32];\n\t__shared__ int pathLengths[32];\n\t__shared__ bool stop[32];\n\n\tif (tid == 0) {\n\t\tfor (int i = 0; i < 32; ++i) {\n\t\t\tvisited[i] = 0;\n\t\t\tdistances[i] = -1;\n\t\t\tstop[i] = false;\n\t\t}\n\t\tdistances[0] = 0;\n\t}\n\n\t__syncthreads();\n\n\tfor (int u = 0; u < N; ++u) {\n\t\t__syncthreads();\n\t\tint neighbor;\n\t\tint u_dist = distances[u];\n\n\t\tif (u_dist == -1)\n\t\t\tcontinue;\n\n\t\tif (A[u * N + tid] == 1 && visited[tid] == 0) {\n\t\t\t// printf(\"(%d) -> (%d)\\n\", tid, u);\n\t\t\tint n_dist = u_dist + 1;\n\t\t\tdistances[tid] = n_dist;\n\t\t\tvisited[tid] = 1;\n\t\t\tneighbor = tid;\n\t\t}\n\t\t__syncthreads();\n\n\t\tif (neighbor!= 0) {\n\t\t\tif (distances[neighbor] == n_dist) {\n\t\t\t\t// printf(\"(%d) <- (%d), dist: %d\\n\", neighbor, tid, n_dist);\n\t\t\t\tdistances[neighbor] = -1;\n\t\t\t\tvisited[neighbor] = 1;\n\t\t\t\tpathLengths[neighbor] = n_dist;\n\t\t\t\tstop[neighbor] = true;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\t\tif (stop[tid] == true) {\n\t\t\tif (tid == 0)\n\t\t\t\t*pathLength = pathLengths[tid];\n\t\t\tbreak;\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n    // For each thread in the block...\n    if (tid < N) {\n        // Mark the node with the smallest distance to source as visited.\n        int visited = (A[source * N + tid] == 1)? 1 : 0;\n\n        // Initialize to the max possible value.\n        int minDistance = INT_MAX;\n\n        // For each node...\n        for (int i = 0; i < N; ++i) {\n            if (A[i * N + tid] == 1) {\n                // If the node is reachable, compute its distance.\n                int distance = min(minDistance, (visited + 1));\n\n                // Set the minimum distance.\n                minDistance = distance;\n            }\n        }\n        pathLength[tid] = minDistance;\n    }\n}",
            "// Get the current thread's ID, with 0 <= ID < N.\n  int ID = blockIdx.x * blockDim.x + threadIdx.x;\n\n  // If the current thread's ID equals the destination, then return.\n  if (ID == dest) {\n    *pathLength = 1;\n    return;\n  }\n\n  // Mark the current thread as visited.\n  __shared__ bool isVisited[N];\n  isVisited[ID] = true;\n\n  __syncthreads();\n\n  // Find the shortest path from source to current thread, recursively.\n  int distance = findShortestPathLength(A, source, ID, isVisited);\n\n  // If the distance is INF, then the destination is unreachable from the source.\n  if (distance == INF) {\n    *pathLength = INF;\n    return;\n  }\n\n  // The current thread is unreachable from the source.\n  if (distance == 0) {\n    *pathLength = INF;\n    return;\n  }\n\n  *pathLength = distance + 1;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x; // current vertex\n    int j = blockIdx.y * blockDim.y + threadIdx.y; // adjacent vertex\n\n    if (i >= N || j >= N) return; // check that the current thread is in bounds\n\n    int length = INT_MAX; // length of the shortest path to vertex j\n    if (A[i * N + j] == 1) {\n        if (i == dest) length = 1; // we've reached the destination\n        else if (i == source) length = 1 + pathLength[j]; // we've reached the source\n        else length = 1 + min(pathLength[i], pathLength[j]); // the path is at least 1 longer than either of the adjacent paths\n    }\n\n    atomicMin(&pathLength[i], length); // update the minimum length for vertex i\n}",
            "int i,j,k;\n\tint count = 0;\n\tint visited[N];\n\tfor(i=0;i<N;i++)\n\t\tvisited[i]=0;\n\tvisited[source] = 1;\n\tfor(k=0;k<N;k++) {\n\t\tfor(i=0;i<N;i++) {\n\t\t\tif(visited[i]==0) {\n\t\t\t\tcount = 0;\n\t\t\t\tfor(j=0;j<N;j++) {\n\t\t\t\t\tif((i==j) && (A[i*N+j]==0))\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tif((i!=j) && (A[i*N+j]==1))\n\t\t\t\t\t\tcount++;\n\t\t\t\t}\n\t\t\t\tif(count==N-1) {\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\tif(i==dest) {\n\t\t\t\t\t\t*pathLength = k+1;\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int tid = hipThreadIdx_x + hipBlockIdx_x * hipBlockDim_x;\n\tif (tid < N) {\n\t\tint minPath = INT_MAX;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[tid * N + i] == 1) {\n\t\t\t\tint pathLengthTmp = 1;\n\t\t\t\tif (i == dest) {\n\t\t\t\t\tpathLengthTmp = 0;\n\t\t\t\t} else {\n\t\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\t\t\tint pathLengthTmpTmp = 1;\n\t\t\t\t\t\t\tif (j == dest) {\n\t\t\t\t\t\t\t\tpathLengthTmpTmp = 0;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\t\t\t\tif (A[j * N + k] == 1) {\n\t\t\t\t\t\t\t\t\t\tint pathLengthTmpTmpTmp = 1;\n\t\t\t\t\t\t\t\t\t\tif (k == dest) {\n\t\t\t\t\t\t\t\t\t\t\tpathLengthTmpTmpTmp = 0;\n\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\tfor (int l = 0; l < N; l++) {\n\t\t\t\t\t\t\t\t\t\t\t\tif (A[k * N + l] == 1) {\n\t\t\t\t\t\t\t\t\t\t\t\t\tint pathLengthTmpTmpTmpTmp = 1;\n\t\t\t\t\t\t\t\t\t\t\t\t\tif (l == dest) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tpathLengthTmpTmpTmpTmp = 0;\n\t\t\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tfor (int m = 0; m < N; m++) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif (A[l * N + m] == 1) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif (m == dest) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpathLengthTmpTmpTmpTmpTmp = 0;\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\tpathLengthTmpTmpTmpTmp = pathLengthTmpTmpTmpTmpTmp + pathLengthTmpTmpTmpTmp;\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\tpathLengthTmpTmpTmp = pathLengthTmpTmpTmpTmp + pathLengthTmpTmpTmpTmp;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpathLengthTmpTmp = pathLengthTmpTmpTmp + pathLengthTmpTmpTmp;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tpathLengthTmp = pathLengthTmpTmp + pathLengthTmpTmp;\n\t\t\t\tif (pathLengthTmp < minPath) {\n\t\t\t\t\tminPath = pathLengthTmp;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (tid == source) {\n\t\t\t*pathLength = minPath;\n\t\t}\n\t}\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n    int minLength = 0;\n\n    if (id == 0) {\n        pathLength[source] = 0;\n    }\n\n    __syncthreads();\n\n    for (int k = 0; k < N; ++k) {\n        if (id == k) {\n            for (int i = 0; i < N; ++i) {\n                for (int j = 0; j < N; ++j) {\n                    if (i!= j && A[i * N + j] > 0 && pathLength[i]!= -1 && (pathLength[j] == -1 || pathLength[i] + A[i * N + j] < pathLength[j])) {\n                        pathLength[j] = pathLength[i] + A[i * N + j];\n                    }\n                }\n            }\n        }\n        __syncthreads();\n    }\n\n    if (id == dest) {\n        minLength = pathLength[dest];\n    }\n\n    __syncthreads();\n\n    if (id == 0) {\n        *pathLength = minLength;\n    }\n}",
            "/* YOUR CODE HERE */\n\n}",
            "int tx = threadIdx.x;\n   int ty = threadIdx.y;\n\n   __shared__ int sdata[BLOCKDIM][BLOCKDIM];\n   sdata[ty][tx] = 0;\n\n   int j = ty + tx*BLOCKDIM;\n   if (j < N)\n      sdata[ty][tx] = A[source*N + j];\n   __syncthreads();\n\n   for (int s = BLOCKDIM/2; s > 0; s >>= 1) {\n      if (ty == 0 && j < s)\n         sdata[ty][tx] = min(sdata[ty][tx], sdata[ty][tx+s]);\n      __syncthreads();\n   }\n\n   if (ty == 0 && tx == 0)\n      sdata[0][0] = A[dest*N + source];\n\n   __syncthreads();\n   for (int s = BLOCKDIM/2; s > 0; s >>= 1) {\n      if (ty == 0 && j < s)\n         sdata[ty][tx] = min(sdata[ty][tx], sdata[ty][tx+s]);\n      __syncthreads();\n   }\n\n   if (tx == 0 && j < N)\n      atomicMin(&pathLength[0], sdata[ty][0]);\n}",
            "const int row = blockIdx.y;\n\tconst int col = blockIdx.x;\n\t__shared__ int sdata[1024]; // Shared memory for this block\n\tconst int tid = threadIdx.x;\n\tsdata[tid] = 0;\n\tif (row == col) {\n\t\tif (tid == 0) sdata[0] = 0;\n\t\tif (row == source) {\n\t\t\tsdata[tid] = 1;\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (tid < N) {\n\t\tsdata[tid] += A[row*N + tid];\n\t\t__syncthreads();\n\t}\n\tif (tid < N) {\n\t\tfor (int offset = N/2; offset > 0; offset /= 2) {\n\t\t\tif (tid < offset) {\n\t\t\t\tsdata[tid] += sdata[tid + offset];\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\tif (row == dest && tid == 0) {\n\t\t*pathLength = sdata[0];\n\t}\n}",
            "size_t i = blockDim.x*blockIdx.y + threadIdx.x;\n  size_t j = blockDim.y*blockIdx.x + threadIdx.y;\n  if (i == j && A[i*N + j] == 1 && i!= dest) {\n    *pathLength = -1;\n    return;\n  }\n  if (i == source && A[i*N + j] == 1) {\n    *pathLength = 1;\n    return;\n  }\n  if (i!= source && i!= dest && A[i*N + j] == 1 && A[j*N + source] == 1) {\n    atomicMin(pathLength, 1 + shortestPathLength(A, N, j, dest, pathLength));\n  }\n}",
            "// Get the x and y coordinates of the thread in the grid\n  int x = blockIdx.x;\n  int y = blockIdx.y;\n\n  // Store the sum in a register\n  int sum = 0;\n\n  // Do the computation\n  if (x == y) {\n    // If x == y, then we are on the diagonal.\n    // The value in the matrix is the number of steps to reach x from x (i.e., 0)\n    sum = 0;\n  } else if (x < y) {\n    // If x < y, then we are above the diagonal.\n    // The value in the matrix is the number of steps to reach x from y plus the number of steps to reach y from x\n    sum = A[x * N + y] + A[y * N + x];\n  } else {\n    // If x > y, then we are below the diagonal.\n    // The value in the matrix is the number of steps to reach y from x plus the number of steps to reach x from y\n    sum = A[y * N + x] + A[x * N + y];\n  }\n\n  // Update the result only if this is the minimum\n  atomicMin(pathLength, sum);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;  // Global thread index\n  int j = blockIdx.y * blockDim.y + threadIdx.y;  // Global thread index\n  if (i >= N || j >= N) return;\n\n  // Check if this is the shortest path length\n  if (A[i * N + j] == 1 && j!= source && (j < dest || i < dest)) {\n    pathLength[i] = 1 + pathLength[j];\n  }\n}",
            "int id = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// Each thread is assigned to a node and stores its distance from the source\n\tint distance = INT_MAX;\n\n\t// The value for nodes that have not been visited yet is INT_MAX.\n\t// When a node is first visited, its distance is set to 0.\n\tif (id == source)\n\t\tdistance = 0;\n\n\t// Use a global atomic_min operation to determine the minimum distance\n\t// among the threads in a block. This is done to reduce the number of\n\t// global memory writes.\n\tatomicMin(&distance, distance);\n\n\t// Each thread is responsible for updating the distance of all its\n\t// neighbors, if they are unvisited.\n\tif (id < N && distance!= INT_MAX) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[id * N + j] && distance!= INT_MAX && distance!= INT_MAX) {\n\t\t\t\tatomicMin(&distance, __shfl_sync(0xFFFFFFFF, distance, j) + 1);\n\t\t\t}\n\t\t}\n\t}\n\n\t// Use a global atomic_min operation to compute the minimum distance\n\t// among all the blocks.\n\tatomicMin(pathLength, distance);\n}",
            "__shared__ int shared[SHARED_SIZE];\n\n  // Determine our location in the grid.\n  int x = blockIdx.x;\n  int y = blockIdx.y;\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n\n  // We're going to work on two elements of the matrix: A[x, y] and A[x, y+1].\n  // Each threadblock owns two rows of the matrix.\n  // The first two rows of a threadblock are handled by threads [0,31].\n  // The second two rows are handled by threads [32,63].\n  // Note that if N is not a multiple of 32, then not all of these threads will be working on useful data.\n  int myFirstRow = 2*blockIdx.y + threadIdx.y;\n  int mySecondRow = myFirstRow + 1;\n  int myFirstCol = blockIdx.x;\n  int mySecondCol = blockIdx.x + 1;\n\n  // Initialize the shared memory buffer.\n  int *myShared = &shared[ty*SHARED_DIM+tx];\n  myShared[0] = 0;\n  myShared[1] = 0;\n  myShared[2] = 0;\n  myShared[3] = 0;\n  __syncthreads();\n\n  // Each thread computes a subset of the matrix, based on the location of the thread\n  // in the grid, and the size of that subset (which depends on the size of the matrix).\n  if (myFirstRow < N && myFirstCol < N) {\n    myShared[0] = A[myFirstRow*N+myFirstCol];\n  }\n  if (myFirstRow < N && mySecondCol < N) {\n    myShared[1] = A[myFirstRow*N+mySecondCol];\n  }\n  if (mySecondRow < N && myFirstCol < N) {\n    myShared[2] = A[mySecondRow*N+myFirstCol];\n  }\n  if (mySecondRow < N && mySecondCol < N) {\n    myShared[3] = A[mySecondRow*N+mySecondCol];\n  }\n  __syncthreads();\n\n  // Each thread computes the length of the shortest path from source to dest in its\n  // two elements of the matrix.\n  int x1 = (myShared[0] == 1? 1 : 0);\n  int y1 = (myShared[1] == 1? 1 : 0);\n  int x2 = (myShared[2] == 1? 1 : 0);\n  int y2 = (myShared[3] == 1? 1 : 0);\n  myShared[0] = min(x1+y1,x2+y2);\n  myShared[1] = min(x1+y2,x2+y1);\n  myShared[2] = min(x2+y1,x1+y2);\n  myShared[3] = min(x2+y2,x1+y1);\n  __syncthreads();\n\n  // Finally, each thread writes the results to global memory.\n  if (myFirstRow < N && myFirstCol < N) {\n    A[myFirstRow*N+myFirstCol] = myShared[0];\n  }\n  if (myFirstRow < N && mySecondCol < N) {\n    A[myFirstRow*N+mySecondCol] = myShared[1];\n  }\n  if (mySecondRow < N && myFirstCol < N) {\n    A[mySecondRow*N+myFirstCol] = myShared[2];\n  }\n  if (mySecondRow < N && mySecondCol < N) {\n    A[mySecondRow*N+mySecondCol] = myShared[3];\n  }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid == 0) {\n\t\tpathLength[tid] = A[source * N + tid];\n\t} else {\n\t\tpathLength[tid] = -1;\n\t}\n\t__syncthreads();\n\n\tfor (int i = 1; i < N; i++) {\n\t\tif (tid == i) {\n\t\t\tfor (int j = 0; j < i; j++) {\n\t\t\t\tif (pathLength[j]!= -1) {\n\t\t\t\t\tpathLength[i] = A[j * N + i] + pathLength[j];\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// Find the shortest path length\n\tif (tid == 0) {\n\t\t*pathLength = pathLength[dest];\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x; // global index\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\t// TODO\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\n\t//if (tid >= N) return;\n\n\tif (tid == source) {\n\t\tpathLength[tid] = 0;\n\t\treturn;\n\t}\n\n\tif (tid == dest) {\n\t\tpathLength[tid] = INT_MAX;\n\t\treturn;\n\t}\n\n\tpathLength[tid] = INT_MAX;\n\n\tint i;\n\tfor (i = 0; i < N; i++) {\n\t\tint w = A[i*N + tid];\n\t\tif (pathLength[i] + w < pathLength[tid])\n\t\t\tpathLength[tid] = pathLength[i] + w;\n\t}\n\n\treturn;\n}",
            "const int i = threadIdx.x;\n\tconst int j = threadIdx.y;\n\t__shared__ int S[BLOCK_DIM][BLOCK_DIM + 1];\n\tS[i][j] = 0;\n\t__syncthreads();\n\tint k = 0;\n\twhile (k < N) {\n\t\tif (A[source * N + i] && A[i * N + j]) {\n\t\t\tS[i][j]++;\n\t\t}\n\t\t__syncthreads();\n\t\tif (S[i][j] == 0) {\n\t\t\tbreak;\n\t\t}\n\t\tif (i == j) {\n\t\t\tS[i][j] /= 2;\n\t\t}\n\t\t__syncthreads();\n\t\tif (i > j) {\n\t\t\tint tmp = S[i][j];\n\t\t\tS[i][j] = S[j][i];\n\t\t\tS[j][i] = tmp;\n\t\t}\n\t\t__syncthreads();\n\t\tif (S[i][j] == 0) {\n\t\t\tbreak;\n\t\t}\n\t\tif (i < j) {\n\t\t\tS[j][i] += S[i][j];\n\t\t}\n\t\t__syncthreads();\n\t\tk++;\n\t}\n\tif (i == dest && j == source) {\n\t\t*pathLength = S[i][j];\n\t}\n}",
            "size_t tid = threadIdx.x + blockIdx.x * blockDim.x;\n  if (tid == source) {\n    *pathLength = 0;\n  }\n  __syncthreads();\n  for (int i = 0; i < N; i++) {\n    int src = tid;\n    int dst = i;\n    __syncthreads();\n    if (A[src + N * dst] > 0) {\n      atomicMin(pathLength, 1 + atomicMin(pathLength, *pathLength));\n    }\n    __syncthreads();\n  }\n}",
            "const int BLOCK_DIM = 256;\n\tconst int GRID_DIM = 1024;\n\tconst int BLOCKS_PER_GRID = GRID_DIM/BLOCK_DIM;\n\n\tint id = threadIdx.x + blockIdx.x*blockDim.x;\n\n\t__shared__ int queue[BLOCK_DIM];\n\t__shared__ int nItems;\n\n\tif(id < N)\n\t\tqueue[threadIdx.x] = id;\n\tnItems = 1;\n\n\twhile(nItems > 0)\n\t{\n\t\t__syncthreads();\n\t\tint nextLevelNItems = 0;\n\t\tfor(int i = 0; i < nItems; ++i)\n\t\t{\n\t\t\tint id = queue[threadIdx.x];\n\t\t\tint start = id*N;\n\t\t\tint end = start + N;\n\t\t\tfor(int j = start; j < end; ++j)\n\t\t\t{\n\t\t\t\tif(A[j] == 1)\n\t\t\t\t{\n\t\t\t\t\tint nextLevelID = j/N;\n\t\t\t\t\tif(id == source && nextLevelID == dest)\n\t\t\t\t\t{\n\t\t\t\t\t\t*pathLength = blockIdx.x*BLOCK_DIM + threadIdx.x;\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tif(nextLevelID!= id &&!(threadIdx.x > 0 && nextLevelID == queue[threadIdx.x - 1]))\n\t\t\t\t\t{\n\t\t\t\t\t\tqueue[threadIdx.x + nextLevelNItems] = nextLevelID;\n\t\t\t\t\t\tnextLevelNItems++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif(i + 1 < nItems)\n\t\t\t\tqueue[threadIdx.x] = queue[threadIdx.x + 1];\n\t\t}\n\t\tnItems = nextLevelNItems;\n\t}\n}",
            "const int i = blockIdx.x;\n    const int j = threadIdx.x;\n    extern __shared__ int s[];\n    const int threadId = threadIdx.x;\n    const int warpId = threadIdx.x / WARP_SIZE;\n\n    if (i!= j) {\n        s[threadId] = A[i * N + j];\n    }\n    __syncthreads();\n    int u = 0;\n    int v = 0;\n    if (threadId == 0) {\n        u = s[warpId];\n        v = s[warpId + 1];\n    }\n\n    int u_dist = INF;\n    int v_dist = INF;\n\n    if (i == source) {\n        u_dist = 0;\n    }\n    if (j == source) {\n        v_dist = 0;\n    }\n\n    int min_dist = min(u_dist, v_dist);\n\n    for (int k = 0; k < N; ++k) {\n        int w = 0;\n        if (threadId == 0) {\n            w = s[warpId + 2 * k];\n        }\n\n        int w_dist = INF;\n\n        if (i == k) {\n            w_dist = u_dist + w;\n        }\n        if (j == k) {\n            w_dist = v_dist + w;\n        }\n        min_dist = min(min_dist, min(w_dist, min(u_dist + w + v, v_dist + w + u)));\n    }\n    __syncthreads();\n    if (i == j) {\n        s[threadId] = min_dist;\n    }\n\n    __syncthreads();\n    if (threadId == 0) {\n        pathLength[i] = s[0];\n    }\n}",
            "//__shared__ int sdata[THREADS_PER_BLOCK];\n\tint row, col;\n\n\t//printf(\"%d\\n\", source);\n\t//printf(\"%d\\n\", dest);\n\t//for (int i = 0; i < N; i++) {\n\t\t//for (int j = 0; j < N; j++) {\n\t\t\t//printf(\"%d \", A[i*N+j]);\n\t\t//}\n\t\t//printf(\"\\n\");\n\t//}\n\t//printf(\"\\n\");\n\n\t//int* A_dev = A;\n\t//int* A_dev = (int*)malloc(N*N*sizeof(int));\n\t//cudaMalloc((void **) &A_dev, N*N*sizeof(int));\n\t//cudaMemcpy(A_dev, A, N*N*sizeof(int), cudaMemcpyHostToDevice);\n\n\trow = blockIdx.x; // current row (y-coordinate in Cartesian)\n\tcol = blockIdx.y; // current column (x-coordinate in Cartesian)\n\n\tif (row == col) {\n\t\tif (row == source) {\n\t\t\t//printf(\"row = source\\n\");\n\t\t\tpathLength[row] = 0;\n\t\t} else if (row == dest) {\n\t\t\t//printf(\"row = dest\\n\");\n\t\t\tpathLength[row] = A[row*N + source];\n\t\t} else {\n\t\t\tpathLength[row] = A[row*N + source] + A[row*N + dest];\n\t\t}\n\t} else {\n\t\tint min = INT_MAX;\n\t\tint x, y;\n\t\tfor (x = 0; x < N; x++) {\n\t\t\t//printf(\"(%d, %d)\\n\", row, x);\n\t\t\tfor (y = 0; y < N; y++) {\n\t\t\t\t//printf(\"(%d, %d)\\n\", y, col);\n\t\t\t\tif ((x!= row) && (y!= col)) {\n\t\t\t\t\tmin = (min < A[row*N + x] + A[y*N + col])? min : A[row*N + x] + A[y*N + col];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tpathLength[row] = min;\n\t}\n}",
            "int start = blockIdx.y * blockDim.y + threadIdx.y;\n    int end = N;\n    extern __shared__ int distances[];\n    int *distance = distances + threadIdx.y;\n    if (start == source) {\n        *distance = 0;\n    } else {\n        *distance = INT_MAX;\n    }\n    __syncthreads();\n    for (int k = start; k < end; k += blockDim.y) {\n        if (A[start * N + k] < *distance) {\n            *distance = A[start * N + k];\n        }\n    }\n    __syncthreads();\n    for (int i = 1; i < blockDim.y; i *= 2) {\n        int s = 2 * i;\n        if (threadIdx.y >= i && threadIdx.y < s) {\n            int d = distance[i];\n            int dd = distance[s];\n            if (dd < d) {\n                distance[i] = dd;\n            }\n        }\n        __syncthreads();\n    }\n    if (threadIdx.y == 0) {\n        atomicMin(pathLength, distance[0]);\n    }\n}",
            "int tx = threadIdx.x + blockIdx.x*blockDim.x;\n  int ty = threadIdx.y + blockIdx.y*blockDim.y;\n\n  // if (tx == 0 && ty == 0)\n  //   printf(\"grid: (%d,%d) block: (%d,%d) thread: (%d,%d)\\n\", gridDim.x, gridDim.y, blockDim.x, blockDim.y, tx, ty);\n\n  __shared__ int dist[512][512];\n  __shared__ bool in_queue[512];\n  __shared__ int queue[512];\n\n  if (tx == 0 && ty == 0) {\n    dist[0][0] = 0;\n    in_queue[0] = true;\n    queue[0] = source;\n  }\n\n  __syncthreads();\n\n  if (tx < N && ty < N) {\n    dist[ty+1][tx+1] = A[ty*N+tx];\n  }\n\n  __syncthreads();\n\n  // BFS\n  for (int i = 0; i < N; ++i) {\n    if (tx < N && ty < N && tx == queue[0]) {\n      dist[ty+1][tx+1] = dist[queue[0]+1][tx+1] + dist[queue[0]+1][ty+1];\n    }\n\n    __syncthreads();\n\n    if (tx < N && ty < N && tx == queue[0] && dist[ty+1][tx+1]!= -1 && in_queue[ty+1] == false) {\n      in_queue[ty+1] = true;\n      queue[i+1] = ty;\n    }\n\n    __syncthreads();\n\n    if (tx == 0 && ty == 0 && queue[i+1]!= -1) {\n      in_queue[queue[i+1]+1] = false;\n    }\n\n    __syncthreads();\n  }\n\n  if (tx == 0 && ty == 0 && pathLength) {\n    *pathLength = dist[dest+1][dest+1];\n  }\n}",
            "// Get the row and column indices of the thread.\n\t// In this kernel, we launch a 1D grid of threads, so the row index is set to the global thread index.\n\tconst int row = blockIdx.x;\n\tconst int col = threadIdx.x;\n\n\t// If the thread is outside the matrix or if the source is equal to the dest, then no path exists.\n\tif (row >= N || col >= N || A[row*N+col] == 0 || row == dest) {\n\t\treturn;\n\t}\n\n\t// Compute the shortest path length as the minimum of the two adjacent shortest paths.\n\t// For simplicity, if the current thread is at a boundary, we use a sentinel value of 10000.\n\tconst int left  = (col == 0)? 10000 : pathLength[(row)*N+(col-1)];\n\tconst int right = (col == N-1)? 10000 : pathLength[(row)*N+(col+1)];\n\n\tpathLength[(row)*N+(col)] = 1 + min(left, right);\n}",
            "int myId = blockIdx.x * blockDim.x + threadIdx.x;\n\n   extern __shared__ int sdata[];\n   sdata[threadIdx.x] = 1000000;\n\n   //__syncthreads();\n\n   if (myId == source)\n      sdata[threadIdx.x] = 0;\n\n   //__syncthreads();\n\n   for (int i = 0; i < N; i++) {\n      int myPathLength = sdata[myId];\n      if (myPathLength == 1000000)\n         return;\n\n      int neighbour = A[myId * N + i];\n      if (neighbour == 1)\n         sdata[myId] = myPathLength + 1;\n\n      __syncthreads();\n   }\n\n   pathLength[0] = sdata[dest];\n}",
            "int tx = threadIdx.x + blockIdx.x * blockDim.x;\n   if (tx == source)\n      pathLength[source] = 0;\n   else\n      pathLength[tx] = INT_MAX;\n\n   __syncthreads();\n\n   // Process neighbors in the first warp. \n   if (tx < N) {\n      if (A[source*N + tx] && tx < pathLength[source])\n         pathLength[source] = tx;\n      if (A[tx*N + dest] && tx < pathLength[dest])\n         pathLength[dest] = tx;\n   }\n\n   // Roll the vector twice. \n   for (int d = 0; d < N; d += 32) {\n      int index = d + threadIdx.x;\n      if (index < N && index!= source && index!= dest && A[dest*N + index]) {\n         int temp = pathLength[index];\n         if (temp < pathLength[dest])\n            pathLength[dest] = temp;\n      }\n      __syncthreads();\n   }\n\n   // Process neighbors in the second warp. \n   for (int d = 0; d < N; d += 32) {\n      int index = d + threadIdx.x;\n      if (index < N && index!= source && index!= dest && A[source*N + index]) {\n         int temp = pathLength[index];\n         if (temp < pathLength[source])\n            pathLength[source] = temp;\n      }\n      __syncthreads();\n   }\n}",
            "int myRow = blockIdx.x;\n    int myCol = blockIdx.y;\n    int myIdx = myCol * N + myRow;\n\n    int *myDist = (int *)malloc(sizeof(int)*N);\n    for(int i=0;i<N;i++)\n        myDist[i] = -1;\n\n    __shared__ int dist[BLOCKSIZE][BLOCKSIZE];\n    dist[threadIdx.x][threadIdx.y] = -1;\n    __syncthreads();\n\n    myDist[myIdx] = 0;\n    int frontier = 1;\n    int newFrontier = 0;\n    int frontierIdx = -1;\n\n    while (frontier!= 0) {\n        frontier = 0;\n        newFrontier = 0;\n        for(int i=0;i<N;i++) {\n            int myRowIdx = myRow*N + i;\n            if (myDist[myRowIdx] >= 0 && A[myRowIdx] < 0xFFFFFFFE) {\n                for(int j=0;j<N;j++) {\n                    int myColIdx = j*N + myCol;\n                    if (myDist[myColIdx] == -1 && A[myRowIdx] < 0xFFFFFFFE) {\n                        int w = A[myRowIdx];\n                        if (w < 0xFFFFFFFE) {\n                            dist[threadIdx.x][threadIdx.y] = myDist[myRowIdx] + w;\n                            if (myIdx == myColIdx) {\n                                frontierIdx = dist[threadIdx.x][threadIdx.y];\n                            }\n                            __syncthreads();\n                            myDist[myColIdx] = dist[threadIdx.x][threadIdx.y];\n                            __syncthreads();\n                            newFrontier++;\n                            frontier++;\n                        }\n                    }\n                }\n            }\n        }\n        frontier = newFrontier;\n        newFrontier = 0;\n    }\n\n    *pathLength = frontierIdx;\n    __syncthreads();\n\n    free(myDist);\n\n}",
            "int row = threadIdx.y + blockDim.y * blockIdx.y;\n  int col = threadIdx.x + blockDim.x * blockIdx.x;\n  int threadID = row * blockDim.x * gridDim.x + col;\n  int nThreads = blockDim.x * blockDim.y * gridDim.x * gridDim.y;\n\n  extern __shared__ int cache[];\n  int *cacheR = cache;\n  int *cacheC = cache + N;\n  int *cacheP = cache + 2 * N;\n\n  if (row < N && col < N) {\n    cacheR[threadID] = (row == source)? 0 : INT_MAX;\n    cacheC[threadID] = (col == dest)? 0 : INT_MAX;\n  }\n\n  __syncthreads();\n\n  int *myR = &cacheR[threadID];\n  int *myC = &cacheC[threadID];\n  int *myP = &cacheP[threadID];\n\n  // Initialize\n  if (row < N && col < N) {\n    *myP = ((*myR > 0) && (*myC > 0))? 0 : INT_MAX;\n  }\n\n  __syncthreads();\n\n  // Sweep over all rows\n  for (int k = 0; k < N; k++) {\n\n    // Swap cache pointers\n    if (k % 2 == 0) {\n      int *tmp = cacheR;\n      cacheR = cacheC;\n      cacheC = tmp;\n    }\n\n    __syncthreads();\n\n    if (row == k) {\n      *myR = *myC + A[row * N + col];\n    }\n\n    __syncthreads();\n\n    if (col == k) {\n      *myC = *myR + A[row * N + col];\n    }\n\n    __syncthreads();\n\n    if (row == k && col == k) {\n      *myP = min(*myR, *myC);\n    }\n\n    __syncthreads();\n\n  }\n\n  // Swap cache pointers\n  if (N % 2 == 0) {\n    int *tmp = cacheR;\n    cacheR = cacheC;\n    cacheC = tmp;\n  }\n\n  __syncthreads();\n\n  if (row < N && col < N) {\n    if (pathLength) {\n      *pathLength = *myP;\n    }\n  }\n}",
            "/* Insert your code here */\n}",
            "// Thread index\n\tint i = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// If we are not on the diagonal and we have a direct path to dest, \n\t// set pathLength to be the length of that direct path.\n\t// Note that if A[i][dest]!= 0, then A[dest][i]!= 0\n\tif ((i!= dest) && A[i * N + dest]) {\n\t\t*pathLength = 1;\n\t}\n}",
            "__shared__ int pathLengths[N][N]; // shared memory to store the current best paths from source to all nodes\n  __shared__ bool done[N]; // shared memory to indicate if the best path to a node has been found\n\n  int myId = threadIdx.x;\n  int node = blockIdx.x;\n\n  // Set the initial values for the best paths\n  if (myId == 0) {\n    if (node == source) {\n      pathLengths[source][source] = 0;\n      done[source] = true;\n    } else {\n      pathLengths[source][node] = INT_MAX;\n    }\n  }\n  __syncthreads();\n\n  // Use relaxation to find the shortest path from source to all nodes\n  for (int i = 0; i < N; i++) {\n    __syncthreads();\n\n    int w = A[node * N + i];\n    int myPathLength = pathLengths[source][node];\n\n    if (myPathLength!= INT_MAX &&!done[i]) {\n      if (w == 0) {\n        pathLengths[source][i] = INT_MAX;\n      } else {\n        pathLengths[source][i] = myPathLength + w;\n      }\n    }\n    __syncthreads();\n\n    done[i] = (done[i] || (pathLengths[source][i]!= INT_MAX && pathLengths[source][i] < pathLengths[source][dest]));\n    __syncthreads();\n  }\n\n  // Copy the result to the pathLength memory\n  if (myId == 0) {\n    pathLength[node] = pathLengths[source][dest];\n  }\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n  int bid = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;\n  extern __shared__ int sData[];\n\n  // Initialize the shared memory for use by the CTA\n  if (tid < N) {\n    sData[tid] = A[bid*N + tid];\n  }\n  __syncthreads();\n\n  // Iterate until no threads change their values\n  int changed = 1;\n  while (changed) {\n    changed = 0;\n\n    // Check if the current thread can update any of its neighbors\n    if (tid < N) {\n      for (int i = 0; i < N; ++i) {\n        int new_dist = sData[tid] + sData[i];\n        if (new_dist < sData[N*bid + i]) {\n          sData[N*bid + i] = new_dist;\n          changed = 1;\n        }\n      }\n    }\n    __syncthreads();\n  }\n\n  // Copy result from shared memory to global memory\n  if (tid == 0) {\n    *pathLength = sData[N*bid + dest];\n  }\n}",
            "// \n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    if (i == j && A[i * N + j] == 0) {\n        *pathLength = -1;\n    } else if (i == source) {\n        *pathLength = A[i * N + j];\n    } else if (i == dest && j == source) {\n        *pathLength = A[i * N + j];\n    } else if (i == dest && j!= source) {\n        atomicMin(pathLength, A[i * N + j]);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint k;\n\n\t__shared__ int sdist[N][N];\n\t__shared__ int sprev[N][N];\n\n\t// The first thread of the block initializes the values of sdist and sprev.\n\tif(threadIdx.x == 0 && threadIdx.y == 0) {\n\t\tfor(k=0; k<N; k++) {\n\t\t\tsdist[k][k] = 0;\n\t\t\tsprev[k][k] = -1;\n\t\t}\n\t\tsdist[source][source] = 0;\n\t\tsprev[source][source] = source;\n\t}\n\t__syncthreads();\n\n\t// The remaining threads of the block perform the Bellman-Ford algorithm.\n\tfor(k=0; k<N; k++) {\n\t\t// Update sdist and sprev for the rows indexed by i.\n\t\tif(i<N) {\n\t\t\tif(A[i*N+j] > 0 && sdist[i][j] > sdist[i][k]+A[i*N+k]) {\n\t\t\t\tsdist[i][j] = sdist[i][k]+A[i*N+k];\n\t\t\t\tsprev[i][j] = k;\n\t\t\t}\n\t\t}\n\t\t// Update sdist and sprev for the columns indexed by j.\n\t\tif(j<N) {\n\t\t\tif(A[i*N+j] > 0 && sdist[i][j] > sdist[k][j]+A[k*N+j]) {\n\t\t\t\tsdist[i][j] = sdist[k][j]+A[k*N+j];\n\t\t\t\tsprev[i][j] = k;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t// The thread (0, 0) of the block stores the shortest path length and the predecessor array for the destination node.\n\tif(threadIdx.x == 0 && threadIdx.y == 0 && i==dest && j==dest) {\n\t\t*pathLength = sdist[i][j];\n\t\tfor(k=0; k<N; k++) {\n\t\t\tprev[dest*N+k] = sprev[i][j];\n\t\t}\n\t}\n}",
            "// Get the thread indices\n\tint tid = threadIdx.x + blockIdx.x*blockDim.x;\n\tint bid = blockIdx.x;\n\n\t// Initialize the path length for the source node to 0\n\tif (tid == source) {\n\t\tpathLength[source] = 0;\n\t}\n\n\t// Make sure all the threads have written their results to global memory\n\t__syncthreads();\n\n\t// Compute the shortest path distance from source to all other nodes\n\tif (tid < N) {\n\t\tint j, k, minDistance = 0;\n\t\tfor (j = 0; j < N; j++) {\n\t\t\tfor (k = 0; k < N; k++) {\n\t\t\t\tif (A[N*j + k]!= 0 && pathLength[k] < minDistance) {\n\t\t\t\t\tminDistance = pathLength[k];\n\t\t\t\t}\n\t\t\t}\n\t\t\tpathLength[j] = minDistance + A[N*tid + j];\n\t\t}\n\t}\n\n\t// Make sure all the threads have written their results to global memory\n\t__syncthreads();\n\n\t// Return the shortest path length\n\tif (tid == dest) {\n\t\t*pathLength = pathLength[tid];\n\t}\n}",
            "int tx = hipThreadIdx_x; // Thread ID in X dimension\n    int bx = hipBlockIdx_x;  // Block ID in X dimension\n\n    int i, j;\n\n    __shared__ int cache[BLOCKSIZE];\n    __shared__ int min;\n\n    if (tx < N) {\n        cache[tx] = A[tx * N + bx];\n    }\n\n    __syncthreads();\n\n    min = (tx < N)? cache[tx] : 1000000;\n\n    for (i = 0; i < BLOCKSIZE; i++) {\n        if (min > cache[i]) {\n            min = cache[i];\n        }\n    }\n\n    __syncthreads();\n\n    if (tx < N) {\n        A[tx * N + bx] = min;\n    }\n\n    __syncthreads();\n\n    if (tx == 0 && bx == 0) {\n        pathLength[dest] = min;\n    }\n}",
            "int j = blockIdx.x*blockDim.x + threadIdx.x;\n    if (j<N) {\n        if (A[source*N+j] && j!=source) {\n            int k = blockIdx.y*blockDim.y + threadIdx.y;\n            int length = 0;\n            while (k<N) {\n                if (A[j*N+k] && k!=dest) {\n                    // The path is shorter if there is a path from j to k and a path from k to dest\n                    atomicMin(pathLength, length+1);\n                }\n                k += blockDim.y*gridDim.y;\n                length++;\n            }\n        }\n    }\n}",
            "const int tid = threadIdx.y * blockDim.x + threadIdx.x;\n\tconst int bid = blockIdx.y * gridDim.x + blockIdx.x;\n\tconst int u = bid / N;\n\tconst int v = bid % N;\n\tconst int w = tid / N;\n\tconst int x = tid % N;\n\n\t// Compute shortest path length from source to dest using the Bellman-Ford algorithm.\n\t// See: https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm\n\tif (u == v && x == w) {\n\t\tif (tid == 0)\n\t\t\tpathLength[tid] = 0;\n\t\telse\n\t\t\tpathLength[tid] = INT_MAX;\n\t} else if (u == source && v == dest) {\n\t\tpathLength[tid] = A[tid];\n\t} else if (u == source && v!= dest) {\n\t\tif (w == v) {\n\t\t\tpathLength[tid] = A[tid];\n\t\t} else if (w == dest) {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t} else {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t}\n\t} else if (u!= source && v == dest) {\n\t\tif (w == u) {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t} else if (w == v) {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t} else {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t}\n\t} else if (u!= source && v!= dest) {\n\t\tif (w == u || w == v) {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t} else {\n\t\t\tpathLength[tid] = INT_MAX;\n\t\t}\n\t} else {\n\t\tpathLength[tid] = INT_MAX;\n\t}\n}",
            "//TODO: FILL THIS IN\n\n}",
            "// This is the 1D thread ID\n\tconst int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// This is the 2D thread ID\n\tint tj = threadIdx.y;\n\tint ti = threadIdx.x;\n\n\t// These are the 2D dimensions\n\tint blockDimX = blockDim.x;\n\tint blockDimY = blockDim.y;\n\n\t// The 2D block ID\n\tint bid = blockIdx.y * gridDim.x + blockIdx.x;\n\tint bidy = blockIdx.y;\n\tint bidx = blockIdx.x;\n\n\t// The 2D grid dimensions\n\tint gridDimX = gridDim.x;\n\tint gridDimY = gridDim.y;\n\n\tint tidx = 0;\n\tint tidy = 0;\n\n\tint cur = source;\n\tint last = -1;\n\tint next = cur;\n\tint next_last = -1;\n\tint next_next = -1;\n\tint next_next_last = -1;\n\tint next_next_next = -1;\n\tint next_next_next_last = -1;\n\n\tint cur_pathLength = 0;\n\tint last_pathLength = -1;\n\tint next_pathLength = -1;\n\tint next_last_pathLength = -1;\n\tint next_next_pathLength = -1;\n\tint next_next_last_pathLength = -1;\n\tint next_next_next_pathLength = -1;\n\tint next_next_next_last_pathLength = -1;\n\n\tbool next_next_next_stop = false;\n\n\tif(tid == source){\n\t\tpathLength[cur] = 0;\n\t}\n\n\t__syncthreads();\n\n\tint sharedArray[512];\n\tfor(int i = 0; i < 512; i++){\n\t\tsharedArray[i] = 0;\n\t}\n\n\twhile(cur_pathLength!= -1){\n\n\t\tnext_next_next_stop = false;\n\n\t\tif(tid == source){\n\t\t\tpathLength[next] = cur_pathLength + 1;\n\t\t}\n\n\t\tcur_pathLength = sharedArray[tid];\n\t\tif(cur_pathLength == -1){\n\t\t\tsharedArray[tid] = last_pathLength;\n\t\t}else{\n\t\t\tnext = tid;\n\t\t\tif(tj == 0){\n\t\t\t\twhile(next_next_next_stop == false){\n\t\t\t\t\tnext_next = A[next*N+next];\n\t\t\t\t\tif(next_next == -1){\n\t\t\t\t\t\tnext_next_next_stop = true;\n\t\t\t\t\t}else{\n\t\t\t\t\t\tnext_next_next = A[next_next*N+next_next];\n\t\t\t\t\t\tif(next_next_next == -1){\n\t\t\t\t\t\t\tnext_next_next_stop = true;\n\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\tnext_next_next_last = A[next_next_next*N+next_next_next];\n\t\t\t\t\t\t\tnext = next_next_next;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif(next == dest){\n\t\t\t\tif(tj == 0){\n\t\t\t\t\tsharedArray[tid] = last_pathLength + 3;\n\t\t\t\t}\n\t\t\t}else if(tid == dest){\n\t\t\t\tsharedArray[tid] = last_pathLength + 1;\n\t\t\t}\n\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tif(tid == dest){\n\t\t\tnext_pathLength = sharedArray[tid];\n\t\t}\n\n\t\tif(tj == 0){\n\t\t\tlast_pathLength = cur_pathLength;\n\t\t\tif(next_pathLength!= -1){\n\t\t\t\tnext_last_pathLength =",
            "// Allocate shared memory\n  __shared__ int sdata[BLOCKSIZE];\n\n  // Allocate variables\n  int myPathLength = INT_MAX;\n  int mySource = INT_MAX;\n  int myDest = INT_MAX;\n  bool hasSource = false;\n  bool hasDest = false;\n\n  // Read A into shared memory\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int idx = ty * BLOCKSIZE + tx;\n  if (idx < N*N) {\n    sdata[idx] = A[idx];\n  }\n\n  // Wait for shared memory to be populated\n  __syncthreads();\n\n  // If I have the source or destination\n  if (source == ty) {\n    mySource = tx;\n    hasSource = true;\n  }\n  if (dest == ty) {\n    myDest = tx;\n    hasDest = true;\n  }\n\n  // Wait for mySource and myDest to be populated\n  __syncthreads();\n\n  // If I have the source and destination\n  if (hasSource && hasDest) {\n    // Compute the path length between the source and destination\n    int i = 0;\n    int x = mySource;\n    int y = myDest;\n    while ((x!= y) && (i < N)) {\n      int xy = x + N * y;\n      x = sdata[xy];\n      i++;\n    }\n    // Update the path length\n    myPathLength = i;\n  }\n\n  // Store the path length in shared memory\n  sdata[idx] = myPathLength;\n\n  // Wait for sdata to be populated\n  __syncthreads();\n\n  // Reduce the path length using a parallel reduction\n  if (ty == 0) {\n    for (int i = 1; i < BLOCKSIZE; i++) {\n      myPathLength = min(myPathLength, sdata[i]);\n    }\n    // Update the path length\n    if (hasSource && hasDest) {\n      pathLength[0] = myPathLength;\n    }\n  }\n}",
            "int s = blockIdx.x;\n\tint t = blockIdx.y;\n\tint tid = threadIdx.x;\n\tint len = 0;\n\n\tif (s >= N || t >= N) return;\n\n\tint cur = tid;\n\tint p = s;\n\tint q = t;\n\t\n\twhile (p!= dest) {\n\t\tlen++;\n\t\tp = A[p*N + q];\n\t\tq = A[q*N + p];\n\t}\n\n\tatomicMin(pathLength, len);\n}",
            "int row = blockDim.y * blockIdx.y + threadIdx.y;\n\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n\n\tif (row < N && col < N) {\n\t\tif (A[row * N + col] == 1 && (row == source || col == dest)) {\n\t\t\tpathLength[0] = 1;\n\t\t}\n\t\telse if (row == source && col == dest) {\n\t\t\tpathLength[0] = 0;\n\t\t}\n\t\telse if (row == source && col!= dest) {\n\t\t\tpathLength[0] = -1;\n\t\t}\n\t\telse if (col == dest && row!= source) {\n\t\t\tpathLength[0] = -1;\n\t\t}\n\t\telse if (row!= source && row!= dest && col!= dest && col!= source) {\n\t\t\tpathLength[0] = -1;\n\t\t}\n\t\telse if (row == dest && col == source) {\n\t\t\tpathLength[0] = 0;\n\t\t}\n\t\telse {\n\t\t\tpathLength[0] = -1;\n\t\t}\n\t}\n}",
            "__shared__ int *dist;\n  dist = (int *)malloc(N * sizeof(int));\n  for (int k = 0; k < N; k++) {\n    dist[k] = INT_MAX;\n  }\n  dist[source] = 0;\n\n  __syncthreads();\n\n  int k = blockDim.x * blockIdx.x + threadIdx.x;\n  int i = blockDim.x * blockIdx.y + threadIdx.y;\n  int cur_dist;\n  int next_dist;\n\n  for (int j = 0; j < N; j++) {\n    cur_dist = dist[i];\n    next_dist = dist[j];\n\n    if (A[i * N + j] == 1 && cur_dist!= INT_MAX && cur_dist + 1 < next_dist) {\n      next_dist = cur_dist + 1;\n    }\n\n    __syncthreads();\n\n    dist[j] = next_dist;\n    __syncthreads();\n  }\n\n  *pathLength = dist[dest];\n\n  free(dist);\n}",
            "// thread index\n  unsigned int tidx = blockDim.x * blockIdx.y * gridDim.x\t// rows preceeding current row in grid\n\t\t      + blockDim.x * blockIdx.x\t\t\t// blocks preceeding current block\n\t\t      + threadIdx.x;\n\n  if(tidx == source) {\n    pathLength[dest] = 1;\n  }\n\n  // copy data from global to shared memory\n  __shared__ int sdata[BLOCK_SIZE][BLOCK_SIZE];\n  sdata[threadIdx.y][threadIdx.x] = A[tidx];\n  __syncthreads();\n\n  // process data\n  int sum = 0;\n  for(int i = 0; i < BLOCK_SIZE; i++) {\n    sum += sdata[threadIdx.y][i];\n  }\n\n  // copy data from shared to global memory\n  A[tidx] = sum;\n}",
            "__shared__ int sData[BLOCK_SIZE][BLOCK_SIZE];\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\n\tint row = BLOCK_SIZE * by + ty;\n\tint col = BLOCK_SIZE * bx + tx;\n\n\tif ((row < N) && (col < N))\n\t{\n\t\tsData[ty][tx] = A[row * N + col];\n\t\t__syncthreads();\n\n\t\t// Do the reduction in shared memory\n\t\tfor (int k = 0; k < BLOCK_SIZE; k++) {\n\t\t\tsData[ty][tx] = min(sData[ty][tx], sData[ty][k]);\n\t\t}\n\n\t\t// Write the result to global memory\n\t\t__syncthreads();\n\t\tif ((row == source) && (col == dest))\n\t\t\t*pathLength = sData[ty][tx];\n\t}\n}",
            "int i = blockDim.y*blockIdx.y + threadIdx.y;\n\tint j = blockDim.x*blockIdx.x + threadIdx.x;\n\tif (i < N && j < N && i!= j && A[i*N + j] > 0)\n\t\tpathLength[i] = min(pathLength[i], pathLength[j] + 1);\n}",
            "int row = blockIdx.x;\n  int col = blockIdx.y;\n  int threadsPerBlock = blockDim.x * blockDim.y;\n  int threadId = threadIdx.x + threadIdx.y * blockDim.x;\n\n  // Each thread computes a single cell in the matrix\n  if (row < N && col < N && threadId < threadsPerBlock) {\n    int idx = row * N + col;\n    if (row == source && col == dest) {\n      pathLength[idx] = 0;\n    }\n    if (row == source && col!= dest) {\n      pathLength[idx] = A[idx];\n    }\n    if (row!= source && col == dest) {\n      pathLength[idx] = A[idx];\n    }\n    if (row!= source && col!= dest) {\n      int min = A[idx];\n      int minLeft = 0;\n      int minUp = 0;\n      if (idx - N >= 0) {\n        minLeft = pathLength[idx - N];\n      }\n      if (idx - 1 >= 0) {\n        minUp = pathLength[idx - 1];\n      }\n      if (minLeft > 0 && minUp > 0 && minLeft < min && minUp < min) {\n        pathLength[idx] = minLeft + minUp + A[idx];\n      } else {\n        if (minLeft < min) {\n          pathLength[idx] = minLeft + A[idx];\n        }\n        if (minUp < min) {\n          pathLength[idx] = minUp + A[idx];\n        }\n      }\n    }\n  }\n}",
            "const int tid = blockDim.x * blockIdx.x + threadIdx.x;\n\n    if (tid < N && A[tid * N + source]!= 0) {\n        int distance = A[tid * N + source];\n        int nextId = tid;\n        while (nextId!= dest) {\n            nextId = A[nextId * N + source];\n            distance++;\n        }\n        pathLength[source] = distance;\n    }\n}",
            "// Allocate shared memory for the current distance array\n  extern __shared__ int dist[];\n  int numThreads = blockDim.x;\n  int threadId = threadIdx.x;\n\n  // Each thread is assigned a vertex\n  int vertex = threadId + blockIdx.x * numThreads;\n\n  // Copy vertex distance to shared memory\n  dist[threadId] = (vertex == source)? 0 : A[source * N + vertex];\n\n  // Synchronize all threads\n  __syncthreads();\n\n  // Start with vertex 0\n  for (int i = 0; i < N; i++) {\n    // Relax edges\n    int relaxed = __shfl(dist, vertex);\n    if (relaxed!= INF && (A[vertex * N + dest] > relaxed + A[vertex * N + dest])) {\n      // Copy relaxed distance to shared memory\n      dist[threadId] = relaxed + A[vertex * N + dest];\n    }\n\n    // Synchronize all threads\n    __syncthreads();\n  }\n\n  // Copy final result to global memory\n  pathLength[threadId] = dist[threadId];\n}",
            "// Store the source in a register\n   int source_ = source;\n   // Store the destination in a register\n   int dest_ = dest;\n   // Get the x index into the grid\n   int x = blockIdx.x;\n   // Get the y index into the grid\n   int y = blockIdx.y;\n   // Use a register to store the length of the current path\n   int pathLength_ = 0;\n   // Do not process nodes if the path length exceeds the shortest path so far\n   if (pathLength_ >= *pathLength) return;\n\n   // Calculate the length of the path between the current node and the destination\n   // This is done by adding the length of the current path to the length of the shortest\n   // path between the current node and the source.\n   if (x == y) pathLength_ += A[x*N+y];\n   else if (A[x*N+y] > 0) pathLength_ += A[source_*N+x] + A[x*N+y] + A[y*N+dest_];\n\n   // If the path length is less than the shortest path so far\n   if (pathLength_ < *pathLength) {\n      // Update the shortest path\n      *pathLength = pathLength_;\n   }\n}",
            "int row = blockIdx.y;\n\tint col = blockIdx.x;\n\tint tid = threadIdx.x;\n\textern __shared__ int s[];\n\tint *s_A = s;\n\tint *s_pathLength = s_A + (N+1)*(N+1);\n\tint *s_pathStart = s_pathLength + (N+1)*(N+1);\n\n\tint start = 0;\n\tint stop = 0;\n\n\tif (tid == 0) {\n\t\tfor (int i = 0; i < N*N; ++i)\n\t\t\ts_A[i] = A[i];\n\n\t\ts_pathLength[row*N + col] = INT_MAX;\n\t\ts_pathLength[dest*N + dest] = 0;\n\t\ts_pathStart[row*N + col] = -1;\n\n\t\t// If the current thread belongs to the source, update start to 1.\n\t\t// Note that the source thread has ID 0,0.\n\t\tif (row == source && col == source) {\n\t\t\tstart = 1;\n\t\t}\n\t}\n\t__syncthreads();\n\n\t// Initialize stop to 0.\n\tstop = 0;\n\t__syncthreads();\n\n\twhile (1) {\n\t\t// Check if the destination has been reached.\n\t\t// If so, set stop to 1 and exit the loop.\n\t\tif (row == dest && col == dest) {\n\t\t\tstop = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\t// Compute the new path length to the destination.\n\t\tint new_dist = INT_MAX;\n\t\tif (s_A[row*N + col] > 0) {\n\t\t\t// If the current thread is not the destination, compute the new path length.\n\t\t\tnew_dist = s_pathLength[row*N + col] + s_A[row*N + col];\n\t\t}\n\n\t\t// Update the new path length and path start.\n\t\t// Note that this update only happens if the new distance is smaller than the current distance.\n\t\tif (new_dist < s_pathLength[dest*N + dest]) {\n\t\t\ts_pathLength[dest*N + dest] = new_dist;\n\t\t\ts_pathStart[dest*N + dest] = row*N + col;\n\t\t}\n\t\t__syncthreads();\n\n\t\t// If the destination has been reached, exit the loop.\n\t\tif (stop)\n\t\t\tbreak;\n\n\t\t// Perform the relaxation step.\n\t\t// The new path start is s_pathStart[row*N + col].\n\t\t// The new path length is s_pathLength[row*N + col].\n\t\tint new_row = row;\n\t\tint new_col = col;\n\n\t\tif (s_pathStart[row*N + col]!= -1) {\n\t\t\tnew_row = s_pathStart[row*N + col] / N;\n\t\t\tnew_col = s_pathStart[row*N + col] % N;\n\t\t}\n\t\t__syncthreads();\n\n\t\trow = new_row;\n\t\tcol = new_col;\n\t\t__syncthreads();\n\t}\n\n\tif (tid == 0) {\n\t\t*pathLength = s_pathLength[dest*N + dest];\n\t}\n}",
            "// The grid is NxN. The block size is 1x1, and the block index is\n    // source and dest.\n    int i = blockIdx.x;\n    int j = blockIdx.y;\n\n    // If this thread is computing the path from source to dest,\n    // start a DFS to find the length of the shortest path.\n    if (i == source && j == dest) {\n        int pathLengthFromSource = 0;\n        __shared__ int explored[1024];\n        __shared__ bool found;\n        __shared__ int pathLengthFromSource_shared;\n\n        // Clear the explored array to false, except for the source\n        // where the value is true.\n        if (threadIdx.x < N) {\n            explored[threadIdx.x] = (threadIdx.x == source);\n        }\n        __syncthreads();\n\n        // Perform the DFS.\n        found = false;\n        pathLengthFromSource = 0;\n        while (!found) {\n            for (int k = 0; k < N; ++k) {\n                if (A[i * N + k] &&!explored[k]) {\n                    if (k == dest) {\n                        pathLengthFromSource++;\n                        found = true;\n                        break;\n                    }\n                    explored[k] = true;\n                    pathLengthFromSource++;\n                    i = k;\n                    break;\n                }\n            }\n            __syncthreads();\n        }\n\n        // Store the path length in the output array.\n        if (threadIdx.x == 0) {\n            pathLength[0] = pathLengthFromSource;\n        }\n    }\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n    if (tid < N && A[source * N + tid] > 0) {\n        // Each thread finds the shortest path from the source to the thread's node.\n        // If the source node can reach the thread's node, then the thread's node can also\n        // reach the source node.\n        int length = 1 + shortestPathLength(A, N, tid, dest);\n        if (length < pathLength[tid]) {\n            pathLength[tid] = length;\n        }\n    }\n}",
            "int tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint x = bx * blockDim.x + tx;\n\tint y = by * blockDim.y + ty;\n\n\t__shared__ int path[32][32];\n\t__shared__ int dist[32][32];\n\n\tif (x < N && y < N) {\n\t\tif (x == y) {\n\t\t\tpath[x][y] = source;\n\t\t\tdist[x][y] = 0;\n\t\t} else {\n\t\t\tpath[x][y] = 0;\n\t\t\tdist[x][y] = 1;\n\t\t}\n\t\tif (A[N*x+y] == 1) {\n\t\t\tpath[y][x] = x;\n\t\t\tdist[y][x] = 1;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (A[N*j+k] == 1 && A[N*k+i] == 1) {\n\t\t\t\t\tif (dist[j][k] + 1 < dist[j][i]) {\n\t\t\t\t\t\tdist[j][i] = dist[j][k] + 1;\n\t\t\t\t\t\tpath[j][i] = path[k][i];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (x == dest && y == source) {\n\t\tpathLength[0] = dist[y][x];\n\t}\n}",
            "// TODO: Implement me\n\n\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid == source) {\n\t\t*pathLength = 0;\n\t}\n\telse if (tid == dest) {\n\t\t*pathLength = INT_MAX;\n\t}\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (A[source*N + tid]!= 0) {\n\t\t\tint dist = atomicMin(pathLength + tid, *(pathLength + source) + A[source*N + tid]);\n\t\t\tif (tid == dest && dist == *(pathLength + source) + A[source*N + tid]) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "int tx = threadIdx.x;\n    int bx = blockIdx.x;\n    __shared__ int distance[256];\n    __shared__ bool visited[256];\n\n    if (tx == 0) {\n        distance[bx] = INT_MAX;\n        visited[bx] = false;\n    }\n    __syncthreads();\n    if (tx == source) {\n        distance[bx] = 0;\n        visited[bx] = true;\n    }\n    __syncthreads();\n\n    for (int iter = 0; iter < N; iter++) {\n        int x = tx + iter * blockDim.x;\n        int y = bx + iter * gridDim.x;\n\n        if (x >= N || y >= N) {\n            continue;\n        }\n\n        if (distance[bx] < INT_MAX && A[x * N + y] &&!visited[bx]) {\n            distance[bx] = min(distance[bx], distance[y] + 1);\n            visited[bx] = true;\n        }\n        __syncthreads();\n    }\n    if (tx == dest && distance[bx] < INT_MAX) {\n        atomicMin(pathLength, distance[bx]);\n    }\n}",
            "// Your code here\n}",
            "int i = blockIdx.x*blockDim.x+threadIdx.x;\n\n   if (i < N)\n      if (A[i * N + dest] == 1)\n         if (i!= source)\n            if (i!= dest)\n               pathLength[i] = INT_MAX;\n   __syncthreads();\n   for (int j = 0; j < N; j++) {\n      if (i == source && A[i * N + j] == 1)\n         pathLength[i] = 1;\n      else if (A[i * N + j] == 1) {\n         if (pathLength[j]!= INT_MAX)\n            pathLength[i] = min(pathLength[i], pathLength[j] + 1);\n      }\n      __syncthreads();\n   }\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n  int col = blockIdx.x * blockDim.x + threadIdx.x;\n\n  if (row >= N || col >= N || A[row * N + col] == 0 || row == col) {\n    return;\n  }\n\n  __shared__ int cache[256];\n  if (threadIdx.y == 0) {\n    cache[threadIdx.x] = -1;\n  }\n  __syncthreads();\n\n  // We want a thread to access the shortestPathLength array exactly once, but\n  // we need to keep track of the previous node and the length so far to\n  // calculate the next shortest path.\n  // We use two threads to keep track of this, with the same node in one thread\n  // and the length in the other.\n  // The two threads in a warp will share the same value in the cache array.\n  // The first thread to reach the destination node will update the\n  // shortestPathLength array with the minimum value between the length it\n  // calculated and the length in the array.\n  int nextNode = -1;\n  int nextLength = -1;\n  for (int k = 0; k < N; k++) {\n    if (nextNode!= -1) {\n      // We found the next node, so move on to calculating the length of the\n      // path from there to the destination.\n      if (nextNode == dest) {\n        nextLength = k + 1;\n        break;\n      }\n\n      nextNode = cache[nextNode];\n    } else {\n      if (row == source) {\n        // The first thread in a warp will find the next node.\n        if (cache[col] == -1) {\n          cache[col] = A[row * N + col];\n        }\n        nextNode = cache[col];\n      }\n    }\n    __syncthreads();\n  }\n\n  if (nextNode == dest) {\n    // Update the minimum length.\n    atomicMin(pathLength, nextLength);\n  }\n}",
            "int tid = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\tif (tid >= N * N) return;\n\tint x = tid / N;\n\tint y = tid % N;\n\tif (x == dest && y == source) {\n\t\tpathLength[tid] = 1;\n\t} else if (A[tid] > 0) {\n\t\tpathLength[tid] = 1 + min(pathLength[y * N + x], pathLength[y * N + A[y * N + x]]);\n\t} else {\n\t\tpathLength[tid] = INT_MAX;\n\t}\n}",
            "int row = blockIdx.x*blockDim.x + threadIdx.x;\n  int col = blockIdx.y*blockDim.y + threadIdx.y;\n  if (row == col && row == dest && A[row*N+col] == 1)\n    *pathLength = 0;\n  if (row < N && col < N && row!= col && A[row*N+col] == 1)\n    atomicMin(pathLength, 1+A[dest*N+col]);\n}",
            "int tid = blockIdx.y * gridDim.x + blockIdx.x;\n\tint pathLength_tid = 0;\n\tint nextVertex_tid;\n\tint curVertex_tid = source;\n\tif (tid == source) {\n\t\tif (A[tid*N+dest] > 0) {\n\t\t\tpathLength[tid] = 1;\n\t\t}\n\t\telse {\n\t\t\tpathLength[tid] = 0;\n\t\t}\n\t\treturn;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tpathLength_tid = pathLength_tid + pathLength[curVertex_tid];\n\t\tnextVertex_tid = curVertex_tid + N;\n\t\tif (A[nextVertex_tid] > 0) {\n\t\t\tpathLength_tid = pathLength_tid + 1;\n\t\t}\n\t\tif (pathLength_tid < pathLength[tid]) {\n\t\t\tpathLength[tid] = pathLength_tid;\n\t\t}\n\t\tcurVertex_tid = nextVertex_tid;\n\t}\n}",
            "int i = blockIdx.x;\n\tint j = threadIdx.x;\n\t\n\textern __shared__ int pathLengths[];\n\t\n\tint *pathLength_row = pathLengths + blockDim.x * i;\n\tint *pathLength_col = pathLengths + blockDim.x * j;\n\t\n\t__syncthreads();\n\t\n\t// If we are on the diagonal, set the value to 0\n\tif(i == j) {\n\t\tpathLength_row[j] = 0;\n\t}\n\t// If we are above the diagonal, set the value to infinity (INT_MAX)\n\telse if(i > j) {\n\t\tpathLength_row[j] = INT_MAX;\n\t}\n\t// If we are below the diagonal, set the value to 0\n\telse {\n\t\tpathLength_row[j] = 0;\n\t}\n\t__syncthreads();\n\t\n\tint distance = 0;\n\tint count = 0;\n\t\n\twhile(count < N) {\n\t\t__syncthreads();\n\t\t\n\t\tint minPathLength = INT_MAX;\n\t\t\n\t\t// Find the shortest path to a neighboring node\n\t\tfor(int k = 0; k < blockDim.x; k++) {\n\t\t\tif(A[i * N + k] == 1) {\n\t\t\t\tint pathLength_k = pathLengths[k * blockDim.x + j];\n\t\t\t\tif(pathLength_k < minPathLength) {\n\t\t\t\t\tminPathLength = pathLength_k;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t\t\n\t\t// Update the path length of the current node\n\t\tpathLength_row[j] = minPathLength + 1;\n\t\t__syncthreads();\n\t\t\n\t\t// If this iteration reached the destination, store the result\n\t\tif(i == dest && j == source) {\n\t\t\tdistance = pathLength_row[j];\n\t\t}\n\t\t\n\t\t__syncthreads();\n\t\t\n\t\tcount++;\n\t}\n\t\n\tpathLength[i * blockDim.x + j] = distance;\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n\tif (tid < N*N) {\n\t\tint i = tid / N;\n\t\tint j = tid % N;\n\t\tif (i == j && A[tid] == 0) {\n\t\t\tpathLength[i] = -1;\n\t\t}\n\t\telse if (A[tid] == 1) {\n\t\t\tpathLength[i] += 1;\n\t\t}\n\t}\n}",
            "int n = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (n < N) {\n\t\tint cost = 0;\n\t\tint i;\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (A[n * N + i] == 1) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (i == N && source == n) {\n\t\t\t*pathLength = 0;\n\t\t}\n\t\tif (i!= N) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (j == N) {\n\t\t\t\t*pathLength = cost + 1;\n\t\t\t}\n\t\t}\n\t}\n}",
            "int src = blockIdx.x * blockDim.x + threadIdx.x;\n    int dest_val = 0;\n\n    if (src == source)\n    {\n        pathLength[src] = 0;\n        dest_val = 1;\n    }\n    __syncthreads();\n\n    int min_dist = 0;\n    for (int i = 0; i < N; ++i)\n    {\n        for (int j = 0; j < N; ++j)\n        {\n            min_dist = pathLength[i] + A[i*N + j];\n            if (dest_val == 1 && i == dest)\n            {\n                pathLength[dest] = min_dist;\n            }\n            else if (i == src)\n            {\n                if (dest_val == 0 && j == dest)\n                {\n                    pathLength[dest] = min_dist;\n                    dest_val = 1;\n                }\n                else if (dest_val == 0 && j!= dest)\n                {\n                    pathLength[j] = min_dist;\n                }\n            }\n            __syncthreads();\n        }\n    }\n}",
            "// Get our global thread ID\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// We're done if we're past the end of the array\n\tif (tid >= N)\n\t\treturn;\n\n\t// Initialize the shortest path distance for this vertex as infinite\n\tint d = INF;\n\n\t// Check if this vertex is the source vertex, and if so, set the\n\t// distance to zero\n\tif (tid == source)\n\t\td = 0;\n\n\t// Otherwise, if there is a path from the source to this vertex,\n\t// consider all possible paths from the source to this vertex via\n\t// some other vertex, k, and save the smallest such distance found\n\tif (A[source * N + tid] > 0) {\n\t\tfor (int k = 0; k < N; ++k) {\n\t\t\tif (k!= source && k!= tid && A[source * N + k] > 0 && A[k * N + tid] > 0) {\n\t\t\t\tint alt = d + A[k * N + tid];\n\t\t\t\tif (alt < d)\n\t\t\t\t\td = alt;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set the shortest path distance for this vertex in the result array\n\tpathLength[tid] = d;\n}",
            "int tid = threadIdx.x + blockIdx.x*blockDim.x;\n\tif (tid == source)\n\t{\n\t\tpathLength[tid] = 0;\n\t}\n\telse\n\t{\n\t\tpathLength[tid] = INT_MAX;\n\t}\n\t__syncthreads();\n\tfor (int i = 0; i < N; i++) {\n\t\t__syncthreads();\n\t\tif (A[tid*N + i]!= 0)\n\t\t{\n\t\t\tatomicMin(&pathLength[i], pathLength[tid] + 1);\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "int tX = threadIdx.x;\n    int tY = threadIdx.y;\n    int tZ = threadIdx.z;\n    int bX = blockIdx.x;\n    int bY = blockIdx.y;\n    int bZ = blockIdx.z;\n    int i = tX + bX * blockDim.x;\n    int j = tY + bY * blockDim.y;\n    int k = tZ + bZ * blockDim.z;\n    __shared__ int shPathLength[TILE_DIM][TILE_DIM][TILE_DIM];\n    __shared__ int shPathLengthMin[TILE_DIM][TILE_DIM][TILE_DIM];\n    if (i >= N || j >= N || k >= N) {\n        return;\n    }\n    int pathLength_t = 999999999;\n    if (i == j) {\n        pathLength_t = 0;\n    }\n    shPathLength[tX][tY][tZ] = pathLength_t;\n    __syncthreads();\n    // TODO: Compute the length of the shortest path from source to dest using dynamic programming\n    // TODO: Use AMD HIP to compute in parallel. The kernel is launched on an NxNxN grid of threads.\n    // TODO: The kernel should iterate over all values of k <= N and store the result in shPathLengthMin[tX][tY][tZ].\n    // TODO: The kernel should use shPathLength as a scratchpad to hold the current value of pathLength during the iteration.\n    // TODO: The kernel should use shPathLengthMin as a scratchpad to hold the current value of pathLength during the iteration.\n\n    __syncthreads();\n    pathLength_t = shPathLengthMin[tX][tY][tZ];\n    if (i == source && j == dest) {\n        pathLength[0] = pathLength_t;\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid == source) {\n        *pathLength = 0;\n        return;\n    }\n    if (tid == dest) {\n        *pathLength = 0;\n        return;\n    }\n    int shortestPathLength = INT_MAX;\n    for (int i = 0; i < N; i++) {\n        int edgeWeight = A[tid * N + i];\n        if (edgeWeight > 0) {\n            int distanceToI = atomicAdd(pathLength, 0);\n            int pathLengthFromSourceViaI = distanceToI + edgeWeight;\n            int distanceToIAlreadyUpdated = atomicMax(pathLength, pathLengthFromSourceViaI);\n            if (distanceToIAlreadyUpdated < pathLengthFromSourceViaI) {\n                // Some other thread beat us to it and updated the distance\n                // to i with a better path length, so we need to check whether\n                // we have a better path length to i via the current thread's\n                // path length to i.\n                shortestPathLength = min(shortestPathLength, pathLengthFromSourceViaI);\n            }\n        }\n    }\n    atomicMax(pathLength, shortestPathLength);\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint k;\n\t// if (i >= N || j >= N) return;\n\n\t// if (A[N*i + j] == 0 || i == j) return;\n\n\t__shared__ int cache[BLOCK_SIZE][BLOCK_SIZE];\n\tint min = 9999;\n\n\tif (i >= N || j >= N) return;\n\n\tif (A[N*i + j] == 0 || i == j) {\n\t\tcache[threadIdx.y][threadIdx.x] = 9999;\n\t\treturn;\n\t}\n\n\tif (i == source && j == dest) {\n\t\tcache[threadIdx.y][threadIdx.x] = 1;\n\t\treturn;\n\t}\n\n\tif (i == source && j!= dest) {\n\t\tcache[threadIdx.y][threadIdx.x] = 1;\n\t\treturn;\n\t}\n\n\tif (i!= source && j == dest) {\n\t\tcache[threadIdx.y][threadIdx.x] = 9999;\n\t\treturn;\n\t}\n\n\tif (i!= source && j!= dest) {\n\t\t// cache[threadIdx.y][threadIdx.x] = 1;\n\t\t// return;\n\t}\n\n\n\tcache[threadIdx.y][threadIdx.x] = 9999;\n\n\tfor (k = 0; k < N; k++) {\n\t\tif (A[N*i + k]!= 0 && A[N*k + j]!= 0) {\n\t\t\tif (min > cache[threadIdx.y][threadIdx.x])\n\t\t\t\tmin = cache[threadIdx.y][threadIdx.x];\n\t\t}\n\t}\n\tcache[threadIdx.y][threadIdx.x] = min + A[N*i + j];\n}",
            "// TODO\n\t// You may need to use the atomicMin function to compute the minimum distance\n\t// See https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions\n\n}",
            "int threadIdx_x = blockDim.x * blockIdx.x + threadIdx.x;\n\tint threadIdx_y = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tint dist[N];\n\tfor (int i = 0; i < N; i++)\n\t\tdist[i] = INT_MAX;\n\n\tdist[source] = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (dist[j]!= INT_MAX && A[N * j + i]!= 0)\n\t\t\t\tdist[i] = min(dist[i], dist[j] + 1);\n\t\t}\n\t}\n\n\tif (dist[dest] == INT_MAX)\n\t\tpathLength[0] = 0;\n\telse\n\t\tpathLength[0] = dist[dest];\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    if (i == j && A[i * N + j] == 0)\n        *pathLength = -1;\n    else\n        *pathLength = 1 + A[i * N + j];\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n\n    extern __shared__ int sdata[];\n\n    if (id < N)\n        sdata[threadIdx.x] = A[id * N + source];\n    __syncthreads();\n\n    for (int i = 0; i < blockDim.x; i++)\n        sdata[threadIdx.x] += sdata[i];\n    __syncthreads();\n\n    int sum = sdata[threadIdx.x];\n    __syncthreads();\n\n    if (sum!= 0 && id == dest)\n        *pathLength = sum;\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x;\n    int y = blockDim.y * blockIdx.y + threadIdx.y;\n\n    __shared__ int sdata[BLOCK_SIZE * BLOCK_SIZE];\n\n    int index = y * N + x;\n\n    if (x >= N || y >= N || A[index] == 0) {\n        sdata[index] = INT_MAX;\n    } else {\n        sdata[index] = 1;\n    }\n\n    __syncthreads();\n\n    for (int i = 0; i < LOG_BLOCK_SIZE; i++) {\n        int mask = (1 << i) - 1;\n        if (((threadIdx.x | threadIdx.y) & mask) == 0) {\n            if (sdata[index] > sdata[index + (1 << i)]) {\n                sdata[index] = sdata[index + (1 << i)];\n            }\n        }\n        __syncthreads();\n    }\n\n    if (sdata[index]!= INT_MAX && x == 0 && y == 0) {\n        *pathLength = sdata[index];\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int i, j, k;\n  int *V, *E;\n  __shared__ int *S;\n  int *P;\n  __shared__ int *Q;\n  __shared__ int *dist;\n  __shared__ int *par;\n\n  if (tid == 0) {\n    V = (int *)malloc(sizeof(int) * N);\n    E = (int *)malloc(sizeof(int) * N);\n    P = (int *)malloc(sizeof(int) * N);\n    Q = (int *)malloc(sizeof(int) * N);\n    dist = (int *)malloc(sizeof(int) * N);\n    par = (int *)malloc(sizeof(int) * N);\n  }\n  __syncthreads();\n\n  // init\n  if (tid < N) {\n    V[tid] = -1;\n    E[tid] = 0;\n    P[tid] = -1;\n    Q[tid] = -1;\n    dist[tid] = -1;\n    par[tid] = -1;\n  }\n  __syncthreads();\n\n  // enqueue initial nodes\n  if (tid < N) {\n    if (A[tid * N + source] == 1) {\n      E[tid] = 1;\n      Q[tid] = 0;\n    }\n  }\n\n  int min_v;\n  int min_d;\n  int min_i;\n  int flag = 0;\n\n  while (flag == 0) {\n    __syncthreads();\n\n    // find the node with min dist\n    if (tid < N) {\n      min_d = INT_MAX;\n      min_i = -1;\n      for (i = 0; i < N; i++) {\n        if (dist[i] < min_d && dist[i] >= 0) {\n          min_d = dist[i];\n          min_i = i;\n        }\n      }\n    }\n    __syncthreads();\n\n    // check if queue is empty\n    if (min_i == -1) {\n      __syncthreads();\n      if (tid == 0)\n        *pathLength = -1;\n      __syncthreads();\n      flag = 1;\n      break;\n    }\n\n    // dequeue and enqueue adjacent vertices\n    if (tid < N) {\n      if (min_i == dest) {\n        if (tid == 0)\n          *pathLength = min_d;\n        flag = 1;\n      }\n      V[min_i] = 1;\n      S = &A[min_i * N];\n      for (i = 0; i < N; i++) {\n        if (E[i] == 1 && S[i] == 1 && V[i] == -1) {\n          dist[i] = min_d + 1;\n          E[i] = 0;\n          P[i] = min_i;\n          Q[i] = dist[i];\n        }\n      }\n    }\n    __syncthreads();\n\n    if (tid < N) {\n      E[tid] = Q[tid];\n      Q[tid] = -1;\n      dist[tid] = -1;\n    }\n    __syncthreads();\n  }\n\n  // find the path from source to dest\n  i = dest;\n  while (i!= -1) {\n    __syncthreads();\n    if (tid == 0) {\n      par[i] = P[i];\n    }\n    __syncthreads();\n    i = P[i];\n    __syncthreads();\n  }\n  __syncthreads();\n\n  if (tid == 0) {\n    pathLength[dest] = *pathLength;\n  }\n  __syncthreads();\n  if (tid == 0) {\n    for (i = 0; i < N; i++) {\n      P[i] = par[i];\n    }\n    free(V);\n    free(E);\n    free(P);",
            "__shared__ int dist[MAX_SIZE];\n    __shared__ bool flag[MAX_SIZE];\n\n    int myID = blockIdx.x * blockDim.x + threadIdx.x;\n    if (myID == source) {\n        dist[source] = 0;\n        flag[source] = true;\n    }\n    __syncthreads();\n    if (myID < N) {\n        for (int j = 0; j < N; j++) {\n            int pred = preds[myID];\n            int currDist = dist[pred];\n            int currFlag = flag[pred];\n            if (A[myID * N + pred] > 0 && currFlag) {\n                dist[myID] = currDist + 1;\n                flag[myID] = true;\n                preds[myID] = pred;\n            }\n            __syncthreads();\n        }\n        __syncthreads();\n    }\n    if (myID == dest) {\n        pathLength[0] = dist[dest];\n    }\n}",
            "// TODO\n}",
            "int i = blockIdx.x;\n    int j = blockIdx.y;\n    int k = threadIdx.x;\n    int l = threadIdx.y;\n\n    __shared__ int s_pathLength[THREADS_PER_BLOCK][THREADS_PER_BLOCK];\n    __shared__ int s_A[THREADS_PER_BLOCK][THREADS_PER_BLOCK];\n\n    if (i == j && k == l) {\n        s_pathLength[k][l] = INT_MAX;\n        s_A[k][l] = A[i * N + j];\n    }\n\n    __syncthreads();\n\n    if (k == l) {\n        int d = s_pathLength[k][l];\n        for (int n = 0; n < N; n++) {\n            if (n!= source && n!= dest && s_A[k][l] == 1 && d < s_pathLength[n][l]) {\n                s_pathLength[k][l] = s_pathLength[n][l] + 1;\n            }\n        }\n    }\n\n    __syncthreads();\n\n    if (i == j && k == l && s_A[k][l] == 1) {\n        if (source == i) {\n            s_pathLength[k][l] = 0;\n        }\n        if (dest == i) {\n            *pathLength = s_pathLength[k][l];\n        }\n    }\n}",
            "int row = threadIdx.y * blockDim.y + threadIdx.x;\n  int col = blockIdx.y * blockDim.y + blockIdx.x;\n  if (row == col) {\n    __shared__ int distance[BLOCK_SIZE][BLOCK_SIZE];\n    distance[threadIdx.x][threadIdx.y] = A[row * N + col];\n    __syncthreads();\n    for (int i = 0; i < BLOCK_SIZE; ++i) {\n      distance[threadIdx.y][threadIdx.x] = min(distance[threadIdx.x][threadIdx.y], distance[threadIdx.y][i] + distance[i][threadIdx.x]);\n    }\n    __syncthreads();\n    if (threadIdx.x == 0 && threadIdx.y == 0) {\n      pathLength[blockIdx.y * blockDim.y + blockIdx.x] = distance[0][0];\n    }\n  }\n}",
            "int thread = blockIdx.x*blockDim.x + threadIdx.x; // global thread index\n    int *dist = new int[N]; // store the distance from source\n    dist[source] = 0;\n\n    // perform BFS to compute the distance from source to every other vertex\n    for (int i = 0; i < N; i++) {\n        // use all threads to find the shortest path from source to dest\n        for (int j = 0; j < N; j++) {\n            if (A[thread*N + j] && dist[j] > dist[thread] + 1) {\n                dist[j] = dist[thread] + 1;\n            }\n        }\n    }\n\n    // store the result in pathLength\n    if (thread == dest) {\n        *pathLength = dist[dest];\n    }\n}",
            "// use thread index to compute the position in the adjacency matrix\n\tint row = blockIdx.x;\n\tint col = threadIdx.x;\n\n\t// if thread is inside the adjacency matrix and not on the main diagonal\n\tif (row < N && col < N && row!= col) {\n\t\t// compute the distance from the current source to the current destination\n\t\t// if distance is infinity, no path exists\n\t\tint distance = A[row + N*col]!= 0? 1 + A[source + N*col] : INF;\n\n\t\t// use atomicMin to update the path length from source to dest\n\t\tatomicMin(&pathLength[dest], distance);\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid >= N) return;\n\n\t__shared__ int distances[1024];\n\n\tdistances[threadIdx.x] = 0;\n\tif (tid == source) {\n\t\tdistances[threadIdx.x] = 1;\n\t}\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < N - 1; ++i) {\n\t\tint j = i * blockDim.x + threadIdx.x;\n\t\tif (j < N && distances[threadIdx.x] > 0) {\n\t\t\tint s0 = distances[threadIdx.x];\n\t\t\tint s1 = (j < N)? distances[j] : 0;\n\t\t\tdistances[threadIdx.x] = s0 + s1;\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\t*pathLength = distances[dest];\n}",
            "// get the location of this thread in the grid\n    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N*N) {\n        int i = tid / N;\n        int j = tid % N;\n        if (i == source) {\n            // if i == source, then set pathLength[j] = 1. This is an initialization\n            // so the thread is responsible for the entire row of pathLength.\n            pathLength[j] = 1;\n        } else {\n            // otherwise, this thread is responsible for checking if pathLength[j] is less than pathLength[i] + A[i][j]\n            if ((pathLength[i] + A[i * N + j]) < pathLength[j]) {\n                pathLength[j] = pathLength[i] + A[i * N + j];\n            }\n        }\n    }\n}",
            "int tx = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n  int ty = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;\n  if (tx < N && ty < N) {\n    if (tx == source)\n      pathLength[ty] = ty == dest? 0 : INT_MAX;\n    else if (ty == source)\n      pathLength[tx] = tx == dest? 0 : INT_MAX;\n    else\n      pathLength[ty] = pathLength[tx] + A[tx * N + ty];\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i < N && j < N) {\n\n\t\tif (A[i * N + j] == 0) {\n\t\t\tpathLength[i * N + j] = -1;\n\t\t} else {\n\t\t\tpathLength[i * N + j] = INT_MAX;\n\t\t}\n\t}\n\n\tif (i == source && j == dest) {\n\t\tpathLength[i * N + j] = 0;\n\t}\n\n\tif (i == dest && j == source) {\n\t\tpathLength[i * N + j] = 0;\n\t}\n}",
            "// TODO: Your code here\n}",
            "int sourceN = blockIdx.x * blockDim.x + threadIdx.x; // Node index of the source vertex\n\tint destN = blockIdx.y * blockDim.y + threadIdx.y; // Node index of the destination vertex\n\n\tif (sourceN == source && destN == dest)\n\t\t*pathLength = 0;\n\telse if (sourceN == destN)\n\t\t*pathLength = 1;\n\telse if (sourceN >= N || destN >= N)\n\t\t*pathLength = -1;\n\telse\n\t\t*pathLength = A[sourceN * N + destN];\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid == dest) {\n    pathLength[tid] = 1;\n  } else if (tid == source) {\n    pathLength[tid] = 0;\n  } else {\n    pathLength[tid] = -1;\n  }\n}",
            "int myId = threadIdx.x + blockIdx.x * blockDim.x;\n\n\tif (myId < N) {\n\t\tif (A[source * N + myId] == 1) {\n\t\t\t*pathLength = 1 + shortestPathLength(A, N, myId, dest, pathLength);\n\t\t\treturn;\n\t\t}\n\t}\n}",
            "int src = blockIdx.x;\n\tint dest = blockIdx.y;\n\tint minDistance = INT_MAX;\n\tint distance;\n\n\tif (src == dest) {\n\t\tdistance = 0;\n\t} else if (A[src * N + dest] > 0) {\n\t\tdistance = 1 + A[dest * N + src];\n\t} else {\n\t\tdistance = INT_MAX;\n\t}\n\n\tminDistance = min(distance, minDistance);\n\n\tif (minDistance < INT_MAX) {\n\t\t*pathLength = minDistance;\n\t}\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x; // Global thread index\n  extern __shared__ int s_A[]; // Allocate shared memory for the array\n  if (tid < N) {\n    s_A[tid] = A[tid];\n  }\n  __syncthreads();\n\n  int current_path_length = 0;\n  if (tid == source) {\n    current_path_length = 1;\n  }\n  __syncthreads();\n\n  for (int i = 0; i < N - 1; i++) {\n    int old_current_path_length = current_path_length;\n    __syncthreads();\n    if (tid < N) {\n      if (s_A[tid] == 1) {\n        current_path_length = min(old_current_path_length + 1, current_path_length);\n      }\n    }\n    __syncthreads();\n  }\n\n  if (tid == dest) {\n    pathLength[0] = current_path_length;\n  }\n}",
            "// Fill this in.\n}",
            "__shared__ int cache[1024];\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  int len = 0;\n  if (i == source && j == source) {\n    cache[threadIdx.y * blockDim.x + threadIdx.x] = 0;\n  } else {\n    cache[threadIdx.y * blockDim.x + threadIdx.x] = 999999999;\n  }\n  __syncthreads();\n  if (i == source && j == source) {\n    cache[threadIdx.y * blockDim.x + threadIdx.x] = 0;\n  } else if (A[j * N + i] == 1) {\n    cache[threadIdx.y * blockDim.x + threadIdx.x] = 1;\n  }\n  __syncthreads();\n  for (int k = 0; k < N; k++) {\n    if (k!= source && cache[threadIdx.y * blockDim.x + threadIdx.x] >\n                           cache[threadIdx.y * blockDim.x + k] + cache[k * blockDim.x + threadIdx.x]) {\n      cache[threadIdx.y * blockDim.x + threadIdx.x] = cache[threadIdx.y * blockDim.x + k] + cache[k * blockDim.x + threadIdx.x];\n    }\n    __syncthreads();\n  }\n  if (i == dest && j == dest) {\n    *pathLength = cache[threadIdx.y * blockDim.x + threadIdx.x];\n  }\n}",
            "int u = blockIdx.x;\n\tint v = blockIdx.y;\n\tint w = threadIdx.x;\n\t// int n = blockDim.x;\n\t// int m = gridDim.x;\n\tint min = -1;\n\n\tif(u == v)\n\t{\n\t\tif(w == source)\n\t\t\tmin = 0;\n\t\tif(w == dest)\n\t\t\tmin = 1;\n\t}\n\n\tif(u > v)\n\t{\n\t\tif(A[u*N + v]!= 0)\n\t\t\tmin = 1;\n\t\telse\n\t\t\tmin = 0;\n\t}\n\n\tif(u < v)\n\t{\n\t\tif(A[v*N + u]!= 0)\n\t\t\tmin = 1;\n\t\telse\n\t\t\tmin = 0;\n\t}\n\n\tif(u == v && w > v)\n\t\tmin = 0;\n\n\t__shared__ int s[32];\n\tint t = min;\n\n\tif(w < 32)\n\t\ts[w] = min;\n\t__syncthreads();\n\n\tint laneID = threadIdx.x % warpSize;\n\tint wid = threadIdx.x / warpSize;\n\n\tif(laneID == 0)\n\t{\n\t\tint i;\n\t\tfor(i = 1; i < warpSize; i++)\n\t\t\tt = min(t, s[i + laneID]);\n\n\t\ts[wid] = t;\n\t}\n\n\t__syncthreads();\n\tif(laneID == 0 && wid!= 0)\n\t\tt = min(t, s[wid - 1]);\n\t__syncthreads();\n\n\tif(t!= -1 && wid == 0 && laneID == 0)\n\t\t*pathLength = t + 1;\n}",
            "// TODO\n}",
            "size_t threadID = blockIdx.x * blockDim.x + threadIdx.x;\n  if (threadID < N*N) {\n    int i = threadID / N;\n    int j = threadID % N;\n    if (A[i*N + j] == 1 && i == source) {\n      atomicMin(pathLength, j);\n    }\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < N) {\n    if (A[tid * N + source] && tid!= source)\n      pathLength[tid] = 1 + pathLength[source];\n    else\n      pathLength[tid] = 0;\n  }\n}",
            "int start = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = start; i < N * N; i += stride) {\n        if (A[i]!= 0) {\n            *pathLength = 2;\n            return;\n        }\n    }\n}",
            "extern __shared__ int sdata[];\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bx = blockIdx.x;\n  int by = blockIdx.y;\n\n  // each thread loads one element from global to shared mem\n  sdata[tx + ty * (blockDim.x)] = A[bx * (blockDim.x * blockDim.y) + ty * (blockDim.x) + tx];\n  __syncthreads();\n\n  // the thread (tx, ty) computes the shortest path length from source to dest\n  if (bx == source && ty == dest) {\n    // the first thread does the reduction of the shortest path length in its block\n    for (int i = 1; i < blockDim.x; i++)\n      sdata[0] += sdata[i + ty * (blockDim.x)];\n    __syncthreads();\n\n    // the first thread of each block does the reduction of the shortest path length in the grid\n    if (tx == 0) {\n      for (int i = 1; i < blockDim.y; i++)\n        sdata[0] += sdata[i * (blockDim.x)];\n      // the first thread of the grid stores the shortest path length in the result array\n      if (ty == 0)\n        pathLength[by] = sdata[0];\n    }\n  }\n}",
            "//\n\t// TODO: write your code here\n\t//\n\n\n\n\tint i = threadIdx.x;\n\tint j = blockIdx.x;\n\n\tif (i == j) {\n\t\tif (i == source) {\n\t\t\t*pathLength = 0;\n\t\t}\n\t\telse {\n\t\t\t*pathLength = -1;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (A[i*N + j] == 1) {\n\t\tatomicMin(pathLength, *pathLength + 1);\n\t}\n}",
            "// TODO: Fill this in\n}",
            "int tid = threadIdx.x + blockDim.x * blockIdx.x;\n\t// Check if current thread is valid\n\tif (tid >= N) return;\n\n\t// Create a queue and initialize its variables\n\tint *queue = new int[N];\n\tint front = -1, rear = -1;\n\n\t// Initialize the visited array\n\tint *visited = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t}\n\n\t// Enqueue source node\n\tfront++;\n\trear++;\n\tqueue[rear] = source;\n\n\t// Visit the first node\n\tvisited[source] = 1;\n\t\n\t// As long as the queue is not empty\n\twhile (front <= rear) {\n\t\t// Dequeue node\n\t\tint u = queue[front];\n\t\tfront++;\n\n\t\t// For each neighbor of node u, if not visited\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (visited[v] == 0 && A[u * N + v] > 0) {\n\t\t\t\tif (v == dest) {\n\t\t\t\t\t*pathLength = visited[u] + 1;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\t// Enqueue node\n\t\t\t\trear++;\n\t\t\t\tqueue[rear] = v;\n\t\t\t\t// Visit the node\n\t\t\t\tvisited[v] = visited[u] + 1;\n\t\t\t}\n\t\t}\n\t}\n\t*pathLength = -1;\n}",
            "int threadId = threadIdx.y * blockDim.x + threadIdx.x;\n\tint blockId = blockIdx.y * gridDim.x + blockIdx.x;\n\n\t__shared__ int sData[BLOCK_SIZE * BLOCK_SIZE];\n\n\t// Initialize the path length array\n\tif (threadId == 0) {\n\t\tpathLength[blockId] = INF;\n\t}\n\t__syncthreads();\n\n\t// If the destination has been reached, we can exit early.\n\tif (source == dest) {\n\t\tif (threadId == 0) {\n\t\t\tpathLength[blockId] = 0;\n\t\t}\n\t\treturn;\n\t}\n\n\t// Copy the adjacency matrix into shared memory.\n\tif (threadId < N * N) {\n\t\tsData[threadId] = A[threadId];\n\t}\n\t__syncthreads();\n\n\t// Each thread computes the length of the path from source to its own row in the adjacency matrix.\n\t// The shortest path length to any row is the minimum over all thread-computed paths.\n\tint myPathLength = INF;\n\tfor (int j = 0; j < N; j++) {\n\t\tmyPathLength = min(myPathLength, sData[source * N + j]);\n\t}\n\n\t// Update the path length.\n\tif (myPathLength < INF) {\n\t\tmyPathLength++;\n\t}\n\tatomicMin(pathLength + blockId, myPathLength);\n}",
            "// Define and set thread ID variables.\n\tint tid = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + threadIdx.x;\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t// If the thread ID is valid...\n\tif (tid < N) {\n\t\t// Initialize all nodes to \"unvisited\" (-1) except for the source node, which is set to 0.\n\t\tif (tid == source) {\n\t\t\tpathLength[tid] = 0;\n\t\t}\n\t\telse {\n\t\t\tpathLength[tid] = -1;\n\t\t}\n\t}\n\n\t// Wait for all threads to complete their initialization.\n\t__syncthreads();\n\n\t// Loop until all nodes are visited.\n\twhile (true) {\n\t\t// If the thread ID is valid...\n\t\tif (tid < N) {\n\t\t\t// If this node has not been visited...\n\t\t\tif (pathLength[tid] == -1) {\n\t\t\t\t// If this node has a path to the source node...\n\t\t\t\tif (A[id * N + source]!= 0) {\n\t\t\t\t\t// Mark this node as visited, then wait for all threads to complete.\n\t\t\t\t\tpathLength[tid] = 1;\n\t\t\t\t\t__syncthreads();\n\n\t\t\t\t\t// Loop through all neighbors of this node.\n\t\t\t\t\tfor (int nid = 0; nid < N; ++nid) {\n\t\t\t\t\t\t// If the neighbor has not been visited...\n\t\t\t\t\t\tif (pathLength[nid] == -1) {\n\t\t\t\t\t\t\t// If the neighbor has a path to the source node...\n\t\t\t\t\t\t\tif (A[id * N + nid]!= 0) {\n\t\t\t\t\t\t\t\t// Mark the neighbor as visited and wait for all threads to complete.\n\t\t\t\t\t\t\t\tpathLength[nid] = pathLength[tid] + 1;\n\t\t\t\t\t\t\t\t__syncthreads();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Wait for all threads to complete their iterations.\n\t\t__syncthreads();\n\n\t\t// Determine if all nodes have been visited.\n\t\tint allVisited = 1;\n\t\tfor (int nid = 0; nid < N; ++nid) {\n\t\t\tif (pathLength[nid] == -1) {\n\t\t\t\tallVisited = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t// If all nodes have been visited, then terminate the loop.\n\t\tif (allVisited) {\n\t\t\tbreak;\n\t\t}\n\n\t\t// Wait for all threads to complete their iterations.\n\t\t__syncthreads();\n\t}\n\n\t// Store the length of the shortest path from the source to the dest node.\n\tif (tid == dest) {\n\t\tpathLength[dest] = pathLength[dest] - 1;\n\t}\n}",
            "int blockId = blockIdx.y * gridDim.x + blockIdx.x;\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bid = blockId * (blockDim.x * blockDim.y);\n  int index = bid + (ty * blockDim.x) + tx;\n\n  __shared__ int sData[BLOCK_SIZE][BLOCK_SIZE + 1];\n  sData[ty][tx] = index < N * N? A[index] : 0;\n\n  __syncthreads();\n\n  if (index < N * N) {\n    if (tx == 0) {\n      if (sData[ty][1]!= 0) {\n        sData[ty][0] = 1;\n      }\n      for (int offset = 1; offset < BLOCK_SIZE; offset <<= 1) {\n        __syncthreads();\n        if (ty >= offset) {\n          sData[ty][tx] += sData[ty - offset][tx];\n        }\n        __syncthreads();\n      }\n    }\n  }\n  __syncthreads();\n\n  if (index < N * N) {\n    if (tx == 0 && sData[ty][BLOCK_SIZE - 1]!= 0) {\n      atomicAdd(pathLength, sData[ty][BLOCK_SIZE - 1]);\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i < N) {\n    if (i == source) {\n      *pathLength = 0;\n    } else {\n      *pathLength = INT_MAX;\n    }\n  }\n  __syncthreads();\n\n  for (int s = 0; s < N; s++) {\n    int minPathLength = INT_MAX;\n    for (int d = 0; d < N; d++) {\n      if (A[d * N + s] == 1) {\n        int alternatePathLength = 0;\n        if (s == source) {\n          alternatePathLength = 1;\n        } else {\n          alternatePathLength = *(pathLength + s * N + d);\n        }\n        if (alternatePathLength < minPathLength) {\n          minPathLength = alternatePathLength;\n        }\n      }\n    }\n    *(pathLength + i * N + s) = minPathLength + 1;\n  }\n\n  __syncthreads();\n\n  int shortestPathLength = INT_MAX;\n  if (i < N) {\n    shortestPathLength = *(pathLength + i * N + dest);\n  }\n  if (threadIdx.x == 0) {\n    atomicMin(pathLength, shortestPathLength);\n  }\n}",
            "// TODO\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (tid < N) {\n\t\tint length = 0;\n\t\tint current = source;\n\t\tbool found = false;\n\n\t\twhile (!found) {\n\t\t\t// Find the next vertex to visit\n\t\t\tint next = A[current * N + tid];\n\n\t\t\t// Stop when we reach dest\n\t\t\tif (next == dest) {\n\t\t\t\tfound = true;\n\t\t\t\tlength++;\n\t\t\t}\n\n\t\t\t// Stop when we reach a dead end\n\t\t\tif (next == 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tcurrent = next;\n\t\t\tlength++;\n\t\t}\n\n\t\tpathLength[tid] = length;\n\t}\n}",
            "__shared__ int cache[32];\n    int startNode = blockIdx.x;\n    int threadIdx_x = threadIdx.x;\n    if(startNode!= source)\n        return;\n\n    // Initialize the path length to be INFINITE if the destination node is reached.\n    if (startNode == dest) {\n        cache[threadIdx_x] = INFINITE;\n    } else {\n        cache[threadIdx_x] = 0;\n    }\n\n    // If the source node is reached, then store 1 in the cache.\n    if (startNode == source) {\n        cache[threadIdx_x] = 1;\n    }\n\n    __syncthreads();\n\n    // Traverse through the remaining nodes to find the shortest path length.\n    for (int i=0; i<N; i++) {\n        if (cache[threadIdx_x] < INFINITE) {\n            // Update the path length of each node with the minimum of the path length of the current node and the path length of the adjacent nodes.\n            cache[threadIdx_x] = min(cache[threadIdx_x], cache[threadIdx_x] + A[startNode*N + i]);\n        }\n\n        __syncthreads();\n    }\n\n    // Store the path length in the global memory.\n    if (threadIdx_x == 0)\n        *pathLength = cache[0];\n}",
            "int idX = threadIdx.x + blockIdx.x * blockDim.x;\n\tint idY = threadIdx.y + blockIdx.y * blockDim.y;\n\n\tif ((idX < N) && (idY < N)) {\n\t\tint pathLengthX = A[idX + N * idY];\n\t\tint pathLengthY = A[idY + N * idX];\n\t\tint temp = pathLengthX + pathLengthY;\n\n\t\tif (temp > *pathLength) {\n\t\t\t*pathLength = temp;\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i >= N || j >= N)\n\t\treturn;\n\tif (A[i * N + j] == 1) {\n\t\tatomicMin(&pathLength[i], pathLength[j] + 1);\n\t}\n}",
            "int mySource = source;\n\tint myDest = dest;\n\tint myPathLength = -1;\n\tint myPrev = -1;\n\tint *myPath = NULL;\n\tint myPathLengthNew = -1;\n\tint myPrevNew = -1;\n\tint myPathNew[MAX_NUM_VERTICES];\n\n\t__shared__ int sLength[MAX_NUM_VERTICES];\n\t__shared__ int sPrev[MAX_NUM_VERTICES];\n\n\tfor(int i=blockIdx.x; i<N; i+=gridDim.x) {\n\t\tif(i==blockIdx.x) {\n\t\t\tmyPathLength = 0;\n\t\t\tmyPath = myPathNew;\n\t\t}\n\t\tif(i==mySource) {\n\t\t\tmyPathLength = 0;\n\t\t\tmyPath[0] = mySource;\n\t\t\tmyPrev = -1;\n\t\t\tmyPathLengthNew = 0;\n\t\t\tmyPathNew[0] = mySource;\n\t\t\tmyPrevNew = -1;\n\t\t}\n\n\t\tint minLength = INT_MAX;\n\t\tint minLengthIndex = 0;\n\t\tif(threadIdx.x==0) {\n\t\t\tsLength[threadIdx.x] = 0;\n\t\t\tsPrev[threadIdx.x] = -1;\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor(int j=threadIdx.x; j<N; j+=blockDim.x) {\n\t\t\tif(j!=i && A[i*N+j]>0 && A[i*N+j]<INT_MAX) {\n\t\t\t\tif(j==myDest && myPathLength<A[i*N+j]) {\n\t\t\t\t\tmyPathLength = A[i*N+j];\n\t\t\t\t\tmyPrev = i;\n\t\t\t\t}\n\n\t\t\t\tif(sLength[threadIdx.x]<A[i*N+j]) {\n\t\t\t\t\tsLength[threadIdx.x] = A[i*N+j];\n\t\t\t\t\tsPrev[threadIdx.x] = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tfor(int j=blockDim.x/2; j>0; j/=2) {\n\t\t\tif(threadIdx.x<j) {\n\t\t\t\tif(sLength[threadIdx.x]>sLength[threadIdx.x+j]) {\n\t\t\t\t\tsLength[threadIdx.x] = sLength[threadIdx.x+j];\n\t\t\t\t\tsPrev[threadIdx.x] = sPrev[threadIdx.x+j];\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\n\t\tif(threadIdx.x==0) {\n\t\t\tminLength = sLength[0];\n\t\t\tminLengthIndex = sPrev[0];\n\t\t\tfor(int j=1; j<blockDim.x; j++) {\n\t\t\t\tif(sLength[j]<minLength) {\n\t\t\t\t\tminLength = sLength[j];\n\t\t\t\t\tminLengthIndex = sPrev[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tif(minLength!=INT_MAX) {\n\t\t\tA[i*N+minLengthIndex] = minLength+1;\n\t\t\tif(minLengthIndex!=i && minLengthIndex==myDest && myPathLength+1>myPathLengthNew) {\n\t\t\t\tmyPathLengthNew = myPathLength+1;\n\t\t\t\tmyPrevNew = i;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tif(minLengthIndex==myDest && myPathLength+1>myPathLengthNew) {\n\t\t\tmyPathLengthNew = myPathLength+1;\n\t\t\tmyPrev",
            "// Compute the grid and block dimensions\n\tconst int BLOCK_DIM_X = 16;\n\tconst int BLOCK_DIM_Y = 16;\n\tconst int gridDimX = (int)ceil((float)N / BLOCK_DIM_X);\n\tconst int gridDimY = (int)ceil((float)N / BLOCK_DIM_Y);\n\tconst int gridDim = gridDimX * gridDimY;\n\t// Compute this thread's unique ID\n\tconst int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int blockId = blockIdx.x;\n\t__shared__ int sdata[2 * BLOCK_DIM_X * BLOCK_DIM_Y];\n\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint bdx = blockDim.x;\n\tint bdy = blockDim.y;\n\n\t// Initialize the distance\n\tif (threadId < N) {\n\t\tsdata[threadId] = (threadId == source)? 0 : INT_MAX;\n\t}\n\n\t__syncthreads();\n\n\t// Perform BFS\n\tfor (int d = 0; d < N; d++) {\n\t\tint x, y;\n\t\tif (tx < N && ty < N) {\n\t\t\tx = tx + bx * bdx;\n\t\t\ty = ty + by * bdy;\n\t\t\tif (y >= x) {\n\t\t\t\tint idx = x * N + y;\n\t\t\t\tint nx = y;\n\t\t\t\tint ny = x;\n\t\t\t\tsdata[threadId] = min(sdata[threadId], sdata[nx * bdy + ty] + A[idx]);\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (threadId < N) {\n\t\tpathLength[threadId] = sdata[threadId];\n\t}\n}",
            "int id = blockDim.x * blockIdx.y + blockDim.x * gridDim.y * blockIdx.z + threadIdx.x;\n\n    __shared__ int s_A[BLOCKSIZE*BLOCKSIZE];\n    __shared__ int s_dist[BLOCKSIZE];\n\n    if (id < N)\n    {\n        s_A[threadIdx.x] = A[id*N + threadIdx.x];\n        s_dist[threadIdx.x] = INT_MAX;\n\n        if (threadIdx.x == 0)\n        {\n            s_dist[0] = 0;\n        }\n    }\n\n    __syncthreads();\n\n    if (id < N && s_A[threadIdx.x]!= 0)\n    {\n        int min_dist = INT_MAX;\n        int min_dist_index = -1;\n\n        for (int i = 0; i < BLOCKSIZE; i++)\n        {\n            if (min_dist > s_dist[i])\n            {\n                min_dist = s_dist[i];\n                min_dist_index = i;\n            }\n        }\n\n        if (s_A[threadIdx.x]!= INT_MAX)\n        {\n            s_dist[min_dist_index] = min_dist + s_A[threadIdx.x];\n        }\n    }\n\n    __syncthreads();\n\n    if (id < N)\n    {\n        int min_dist = INT_MAX;\n        int min_dist_index = -1;\n\n        for (int i = 0; i < BLOCKSIZE; i++)\n        {\n            if (min_dist > s_dist[i])\n            {\n                min_dist = s_dist[i];\n                min_dist_index = i;\n            }\n        }\n\n        if (min_dist!= INT_MAX)\n        {\n            *pathLength = min_dist;\n        }\n    }\n}",
            "int id = blockIdx.x*blockDim.x + threadIdx.x;\n    int tid = threadIdx.x;\n    // __shared__ int pathLength[MAX_THREADS];\n    extern __shared__ int pathLength[];\n\n    if(id < N) {\n        pathLength[tid] = A[id*N + source];\n    }\n\n    for(int j = 0; j < N; ++j) {\n        int k = pow(2, j);\n        __syncthreads();\n        if(tid % (2*k) == 0) {\n            int i = tid + k;\n            if(i < N) {\n                int w = min(pathLength[tid], pathLength[i]);\n                pathLength[tid] = w + A[id*N + i];\n            }\n        }\n    }\n\n    __syncthreads();\n    if(id == dest) {\n        *pathLength = pathLength[0];\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n   int gridSize = blockDim.x * gridDim.x;\n\n   for (int j = tid; j < N; j += gridSize) {\n      if (A[source * N + j] == 1 && A[j * N + dest] == 1) {\n         *pathLength = 2;\n      }\n   }\n}",
            "// TODO: Implement the kernel function\n\tconst int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tconst int j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif (A[i * N + j] > 0 && i!= j) {\n\t\tint length = 1;\n\t\tif (i == source) {\n\t\t\tlength += 1;\n\t\t}\n\t\tif (j == dest) {\n\t\t\tlength += 1;\n\t\t}\n\t\tif (length < pathLength[i]) {\n\t\t\tpathLength[i] = length;\n\t\t}\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\t__shared__ int dist[100];\n\t__shared__ int visited[100];\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = A[tid * N + i];\n\t\tvisited[i] = 0;\n\t}\n\tdist[source] = 0;\n\tint flag = 1;\n\twhile (flag) {\n\t\tflag = 0;\n\t\t__syncthreads();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (visited[i] == 0 && dist[tid]!= 0 && dist[tid] + dist[i] < dist[i]) {\n\t\t\t\tdist[i] = dist[tid] + dist[i];\n\t\t\t\tflag = 1;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t\tvisited[tid] = 1;\n\t\t__syncthreads();\n\t}\n\t*pathLength = dist[dest];\n}",
            "const size_t N_thread = blockDim.x * gridDim.x;\n    const size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n\n    extern __shared__ int sdata[];\n    int *localPathLength = sdata;\n\n    int localMinPathLength = INT_MAX;\n\n    if (i >= N) {\n        return;\n    }\n\n    localPathLength[threadIdx.x] = INT_MAX;\n\n    __syncthreads();\n\n    if (i == source) {\n        localPathLength[threadIdx.x] = 0;\n    }\n\n    __syncthreads();\n\n    for (int j = 0; j < N; j++) {\n        if (localPathLength[threadIdx.x]!= INT_MAX && localPathLength[threadIdx.x]!= INT_MIN) {\n            localMinPathLength = min(localMinPathLength, localPathLength[threadIdx.x]);\n        }\n\n        __syncthreads();\n\n        int newLocalMinPathLength = INT_MAX;\n\n        if (i < N) {\n            if (i == source || i == dest) {\n                newLocalMinPathLength = localMinPathLength;\n            }\n\n            if (A[i*N + j] == 1) {\n                newLocalMinPathLength = 1 + localMinPathLength;\n            }\n        }\n\n        localPathLength[threadIdx.x] = newLocalMinPathLength;\n\n        __syncthreads();\n    }\n\n    if (localPathLength[threadIdx.x] == INT_MIN) {\n        localPathLength[threadIdx.x] = INT_MAX;\n    }\n\n    __syncthreads();\n\n    if (i == dest) {\n        pathLength[0] = localMinPathLength;\n    }\n}",
            "__shared__ int row[BLOCK_SIZE]; // row[x] is the shortest distance from source to x\n\t__shared__ bool finished[BLOCK_SIZE]; // set true when destination x has been reached\n\t__shared__ int row2[BLOCK_SIZE]; // row2[x] is the shortest distance from source to x via another vertex\n\n\tint tid = threadIdx.x;\n\tint bid = blockIdx.x;\n\tint x = bid;\n\tint y = tid;\n\n\tif (x == source) row[tid] = 0;\n\telse row[tid] = INT_MAX;\n\trow2[tid] = INT_MAX;\n\tif (x == dest) finished[tid] = true;\n\telse finished[tid] = false;\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (finished[y]) continue;\n\t\tint tx = min(row[y], row2[y]);\n\t\tint a = A[x + N * y];\n\t\tif (a > 0 && tx + a < row[x]) {\n\t\t\trow[x] = tx + a;\n\t\t\trow2[x] = tx + a;\n\t\t}\n\t\tif (a > 0 && tx + a < row2[x]) {\n\t\t\trow2[x] = tx + a;\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (x == dest &&!finished[y]) {\n\t\tif (row2[y] < INT_MAX) {\n\t\t\tatomicMin(pathLength, row2[y]);\n\t\t}\n\t}\n}",
            "// For simplicity, assume 1D thread indices correspond to row major order in the 2D grid.\n    int x = blockIdx.x*blockDim.x + threadIdx.x;\n    int y = blockIdx.y*blockDim.y + threadIdx.y;\n\n    // Each thread works on one entry in the adjacency matrix A.\n    if(x >= N || y >= N || x == y) return;\n\n    // Use atomicCAS to ensure that only one thread updates the value of the shared array sPathLength[x]\n    // at a time. This guarantees that the shortest path from the source to any other vertex v in the\n    // graph is computed correctly.\n    int pathLengthSoFar = atomicCAS(&sPathLength[x], -1, A[source*N+x]);\n    while(pathLengthSoFar < A[source*N+y]) {\n        if (pathLengthSoFar == -1)\n            pathLengthSoFar = atomicCAS(&sPathLength[x], -1, A[source*N+x]);\n        else\n            pathLengthSoFar = atomicCAS(&sPathLength[x], pathLengthSoFar, A[source*N+x] + pathLengthSoFar);\n    }\n\n    // Update the shortest path length from the source to destination vertex if necessary.\n    if (x == dest) {\n        atomicMin(&pathLength[0], pathLengthSoFar);\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        // TODO: Fill this in\n    }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int nthreads = gridDim.x * blockDim.x;\n    int src = source;\n    int dst = dest;\n    __shared__ int distance[256];\n    distance[tid] = 0;\n    __syncthreads();\n    // printf(\"Block %d, thread %d\\n\", blockIdx.x, threadIdx.x);\n    for (int i = src; i <= dst; i++) {\n        if (tid < N && distance[tid] < INT_MAX) {\n            distance[tid] = min(distance[tid], A[tid * N + i]);\n        }\n        __syncthreads();\n    }\n    if (tid == 0) {\n        printf(\"Thread %d, distance %d\\n\", tid, distance[tid]);\n        *pathLength = distance[tid];\n    }\n}",
            "// 1D thread ID\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint my_source = source;\n\n\t// Each thread computes the length of the shortest path from its source vertex to the dest vertex\n\tif (tid < N && A[source * N + tid]!= 0 && tid!= my_source) {\n\t\tif (A[tid * N + dest]!= 0) {\n\t\t\t// If dest can be reached from tid\n\t\t\tpathLength[tid] = 1;\n\t\t} else {\n\t\t\t// If dest cannot be reached from tid\n\t\t\tpathLength[tid] = -1;\n\t\t}\n\t}\n\t// __syncthreads();\n}",
            "int i = blockIdx.y;\n    int j = blockIdx.x;\n    __shared__ int cache[BLOCK_SIZE][BLOCK_SIZE];\n    if (j == source) {\n        cache[threadIdx.y][threadIdx.x] = 1;\n    }\n    else {\n        cache[threadIdx.y][threadIdx.x] = 0;\n    }\n    __syncthreads();\n    for (int k = 0; k < BLOCK_SIZE; k++) {\n        int id = k * BLOCK_SIZE + threadIdx.x;\n        if (id < N) {\n            int neighbor = __ldg(&A[i*N + id]);\n            if (neighbor > 0 && cache[threadIdx.y][neighbor - 1] > 0) {\n                cache[threadIdx.y][threadIdx.x] = 1;\n                break;\n            }\n        }\n        __syncthreads();\n    }\n    __syncthreads();\n    if (i == dest && cache[threadIdx.y][threadIdx.x] > 0) {\n        pathLength[blockIdx.y * blockDim.y + threadIdx.y] = 1;\n    }\n}",
            "int x = blockIdx.x;\n   int y = blockIdx.y;\n\n   __shared__ int cache[BLOCK_DIM][BLOCK_DIM];\n   cache[threadIdx.x][threadIdx.y] = A[y * N + x];\n   __syncthreads();\n\n   if (x == y) {\n      if (x == dest && cache[0][0] == 1)\n         pathLength[0] = 0;\n      else if (x == source && cache[0][0] == 1)\n         pathLength[0] = 1;\n      else\n         pathLength[0] = -1;\n   } else if (cache[threadIdx.x][threadIdx.y] == 1) {\n      int left  = (threadIdx.x > 0)? cache[threadIdx.x - 1][threadIdx.y] : -1;\n      int right = (threadIdx.x < BLOCK_DIM - 1)? cache[threadIdx.x + 1][threadIdx.y] : -1;\n      int up    = (threadIdx.y > 0)? cache[threadIdx.x][threadIdx.y - 1] : -1;\n      int down  = (threadIdx.y < BLOCK_DIM - 1)? cache[threadIdx.x][threadIdx.y + 1] : -1;\n\n      if (left!= -1 || right!= -1 || up!= -1 || down!= -1) {\n         int min = left;\n         if (right!= -1 && (right < min || min == -1))\n            min = right;\n         if (up!= -1 && (up < min || min == -1))\n            min = up;\n         if (down!= -1 && (down < min || min == -1))\n            min = down;\n         cache[threadIdx.x][threadIdx.y] = 1 + min;\n      }\n   }\n   __syncthreads();\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    if (tid < N) {\n        //if (tid == source) printf(\"TID %d\\n\", tid);\n        pathLength[tid] = A[source * N + tid];\n    }\n}",
            "// use this to index into the input adjacency matrix\n  size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n  if (index < N*N) {\n    // convert 1D index into a 2D index\n    int x = index / N;\n    int y = index % N;\n    //printf(\"A[%d][%d] = %d\\n\", x, y, A[index]);\n    if (A[index] == 1) {\n      atomicAdd(&pathLength[y], 1);\n    }\n  }\n}",
            "int tx = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n\tint ty = hipBlockIdx_y * hipBlockDim_x + hipThreadIdx_y;\n\n\t__shared__ int sdata[256];\n\n\t// Initialize our per-thread accumulator\n\tint accum = INT_MAX;\n\n\t// Iterate over the entire input\n\tfor(int i = ty; i < N; i += hipBlockDim_y * hipGridDim_y) {\n\t\tint j;\n\t\tif(A[ty * N + i] == 1) {\n\t\t\tif(tx == 0)\n\t\t\t\taccum = 1;\n\t\t}\n\t\telse if(tx == 0) {\n\t\t\taccum = INT_MAX;\n\t\t}\n\n\t\t// Accumulate the sum using a parallel reduction\n\t\tsdata[hipThreadIdx_x] = accum;\n\t\tfor(int stride = (hipBlockDim_x >> 1); stride > 0; stride >>= 1) {\n\t\t\t__syncthreads();\n\t\t\tif(hipThreadIdx_x < stride) {\n\t\t\t\tif(sdata[hipThreadIdx_x + stride] < sdata[hipThreadIdx_x])\n\t\t\t\t\tsdata[hipThreadIdx_x] = sdata[hipThreadIdx_x + stride];\n\t\t\t}\n\t\t}\n\n\t\t// Atomically update the path length\n\t\t__syncthreads();\n\t\tif(tx == 0) {\n\t\t\tint old = atomicMin(pathLength, sdata[0]);\n\t\t\tif(old > sdata[0])\n\t\t\t\t*pathLength = sdata[0];\n\t\t}\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  int shortestPath = INT_MAX;\n  if (i >= N || j >= N) {\n    return;\n  }\n  if (i == j && A[i*N + j] == 0) {\n    return;\n  }\n  int distance = A[i*N + j];\n  int path = INT_MAX;\n  if (distance!= 0) {\n    path = min(path, distance);\n    path = min(path, shortestPath);\n  }\n  atomicMin(pathLength, path);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i >= N || j >= N) return;\n\n    int cost = 0;\n    if (A[i * N + j]!= 0) {\n        if (i == source) {\n            cost = 1;\n        } else if (i == dest) {\n            cost = 0;\n        } else if (j == dest) {\n            cost = 0;\n        } else {\n            cost = INT_MAX;\n        }\n    }\n\n    __shared__ int cost_sh[BLOCK_SIZE][BLOCK_SIZE];\n    cost_sh[threadIdx.y][threadIdx.x] = cost;\n    __syncthreads();\n\n    int minCost = INT_MAX;\n    for (int i = 0; i < BLOCK_SIZE; i++) {\n        int c = cost_sh[threadIdx.y][i];\n        if (c < minCost) {\n            minCost = c;\n        }\n    }\n\n    __syncthreads();\n\n    if (threadIdx.x == 0) {\n        if (minCost < cost) {\n            pathLength[i * N + j] = minCost;\n        }\n    }\n}",
            "int myID = blockIdx.x * blockDim.x + threadIdx.x;\n\tint myShortest = 0;\n\tif (myID < N) {\n\t\tif (myID == source) {\n\t\t\tmyShortest = 1;\n\t\t} else if (A[myID * N + source]) {\n\t\t\tmyShortest = 2;\n\t\t}\n\t}\n\t__syncthreads();\n\tfor (int i = 0; i < 32; i++) {\n\t\tint temp = __shfl_sync(0xffffffff, myShortest, i);\n\t\tif (temp > 0) {\n\t\t\tint myPathLength = __shfl_sync(0xffffffff, pathLength[myID], i);\n\t\t\tif (myPathLength < temp) {\n\t\t\t\tmyShortest = myPathLength + 1;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (myID < N) {\n\t\tif (myID == dest) {\n\t\t\tpathLength[myID] = myShortest;\n\t\t}\n\t}\n}",
            "size_t id = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (id >= N)\n\t\treturn;\n\n\tif (id == source) {\n\t\tpathLength[id] = 0;\n\t\treturn;\n\t}\n\n\tpathLength[id] = INT_MAX;\n}",
            "__shared__ int sData[BLOCK_SIZE][BLOCK_SIZE + 1];\n\n  // Each thread block computes a sub-matrix of A, with one row per thread block\n  int x = blockIdx.x * blockDim.x + threadIdx.x;\n  int y = blockIdx.y * blockDim.y + threadIdx.y;\n  int offset = x * N + y;\n  if (x < N && y < N) {\n    sData[threadIdx.y][threadIdx.x] = A[offset];\n  }\n  __syncthreads();\n\n  // Iterate over the sub-matrix\n  for (int k = 0; k < BLOCK_SIZE; k++) {\n    // Each thread updates one entry in the sub-matrix, using atomicCAS\n    // to handle potential conflicts if two threads attempt to update the same entry\n    if (threadIdx.x == 0) {\n      if (y == source && sData[k][0] > 0) {\n        atomicMin(pathLength, sData[k][k]);\n      }\n    }\n\n    __syncthreads();\n\n    if (sData[k][k] == 0) {\n      break;\n    }\n    __syncthreads();\n\n    for (int i = 0; i < BLOCK_SIZE; i++) {\n      // Perform a reduction step\n      if (sData[k][i] > 0 && i > k) {\n        atomicMin(&sData[k][i], sData[k][k] + sData[i][k]);\n      }\n    }\n    __syncthreads();\n  }\n\n  if (x == 0 && y == dest) {\n    // The destination is on the first row and column of the sub-matrix,\n    // so we can read the final value of pathLength\n    *pathLength = sData[0][dest];\n  }\n}",
            "int col = threadIdx.x;\n\tint row = blockIdx.x;\n\n\t// Get the value in the (row, col) position of the matrix\n\tint value = A[row * N + col];\n\n\t// Update the path length\n\tif (value!= 0 && row == source) {\n\t\tatomicAdd(pathLength, 1);\n\t} else if (value!= 0 && row == dest) {\n\t\tatomicAdd(pathLength, 1);\n\t} else if (value!= 0) {\n\t\tatomicAdd(pathLength, INT_MAX);\n\t}\n}",
            "int tid = threadIdx.x + blockDim.x*blockIdx.x; // global thread index\n   int index = tid; // index into the global array of the adjacency matrix\n   int myDistance = INF; // distance from the source\n   __shared__ int myDistance_shm[BLOCKSIZE];\n   __shared__ int pathLength_shm[BLOCKSIZE];\n\n   // if this thread's vertex is the source vertex, set the distance to 0 and the path to 1\n   if (tid == source) {\n      myDistance = 0;\n      pathLength[index] = 1;\n   }\n   else {\n      // initialize the distance to infinity for all other vertices\n      myDistance = INF;\n      // initialize the path to 0 for all other vertices\n      pathLength[index] = 0;\n   }\n\n   myDistance_shm[threadIdx.x] = myDistance;\n   pathLength_shm[threadIdx.x] = pathLength[index];\n   __syncthreads();\n\n   for (int i = 0; i < BLOCKSIZE; i++) {\n      int myDistance = myDistance_shm[threadIdx.x];\n      if (myDistance!= INF) {\n         // if the distance from the source is not infinity for this vertex\n         // check if there is a connection to another vertex\n         if (A[index]!= 0) {\n            // if this vertex is connected to another vertex\n            // find the distance from the source to this vertex\n            int distanceToNeighbor = myDistance + A[index];\n            // if the distance from the source to this vertex\n            // is less than the current distance\n            // update the distance\n            if (distanceToNeighbor < myDistance_shm[i]) {\n               myDistance_shm[i] = distanceToNeighbor;\n               pathLength_shm[i] = pathLength_shm[threadIdx.x] + 1;\n            }\n         }\n      }\n      __syncthreads();\n   }\n   myDistance = myDistance_shm[threadIdx.x];\n   pathLength[index] = pathLength_shm[threadIdx.x];\n\n   // if this thread's vertex is the destination vertex,\n   // set the distance to the shortest distance to the destination\n   // and the path to the shortest path\n   if (tid == dest) {\n      myDistance = myDistance_shm[0];\n      pathLength[tid] = pathLength_shm[0];\n   }\n   __syncthreads();\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i >= N || j >= N) return;\n\n\t// The value of the matrix at i, j.\n\t// The value of the matrix at i, j.\n\tint value = A[i * N + j];\n\n\t// If the path from source to dest passes through i, j then\n\t// set the value in the output array at i, j to the path length\n\tif (value > 0) {\n\t\tint dist = pathLength[i] + 1;\n\t\t// Update the path length if dist is shorter.\n\t\t// Note that atomicMin() is not used since atomicMin() is only supported in compute capability 3.0 or higher\n\t\tif (dist < pathLength[j]) {\n\t\t\tpathLength[j] = dist;\n\t\t}\n\t}\n}",
            "// Write your code here.\n\tint tid = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = gridDim.x * blockDim.x;\n\tif(tid >= N * N) return;\n\tint i = tid / N;\n\tint j = tid % N;\n\tint k = 0;\n\twhile (A[i * N + j] == 1 && i!= source && j!= dest) {\n\t\tk++;\n\t\tif (j == dest) {\n\t\t\ti = source;\n\t\t\tj = dest;\n\t\t} else {\n\t\t\ti = j;\n\t\t\tj = dest;\n\t\t}\n\t}\n\tif(i == source && j == dest)\n\t\tpathLength[tid] = k;\n}",
            "// TODO: Replace with your code\n\tint id = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint next = id;\n\tint distance = 0;\n\n\twhile (next!= -1) {\n\t\tdistance++;\n\t\tnext = A[id * N + next];\n\t\tid = next;\n\t}\n\n\tif (distance > 0 && id == dest) {\n\t\t*pathLength = distance;\n\t}\n}",
            "const int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\t__shared__ int myPathLength[256];\n\n\tif (tid == 0) {\n\t\tmyPathLength[0] = 1;\n\t} else {\n\t\tmyPathLength[tid] = 0;\n\t}\n\n\t__syncthreads();\n\n\tif (tid!= source) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (tid == i) {\n\t\t\t\tmyPathLength[tid] = myPathLength[i] + A[N * i + tid];\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t}\n\t}\n\n\t__syncthreads();\n\t// use atomicMin to make sure only 1 thread updates the shared memory location\n\tatomicMin(myPathLength + source, myPathLength[tid]);\n\t__syncthreads();\n\t__threadfence();\n\n\tif (tid == dest) {\n\t\t*pathLength = myPathLength[source];\n\t}\n}",
            "int currentVertex, currentVertexIdx, neighborIdx, neighborVertexIdx, nextVertexIdx, nextVertex;\n\tint pathLengthSoFar;\n\n\tcurrentVertexIdx = blockIdx.x*blockDim.x + threadIdx.x;\n\tnextVertexIdx = currentVertexIdx + 1;\n\n\tif(currentVertexIdx >= N) return;\n\n\tif(currentVertexIdx == source) {\n\t\tpathLengthSoFar = 0;\n\t} else {\n\t\tpathLengthSoFar = INT_MAX;\n\t}\n\n\tcurrentVertex = A[currentVertexIdx*N + source];\n\n\tfor(int i = 0; i < N; i++) {\n\n\t\tif(currentVertex == INT_MAX) break;\n\n\t\tfor(int j = 0; j < N; j++) {\n\n\t\t\tneighborIdx = currentVertex*N + j;\n\n\t\t\tif(A[neighborIdx] == nextVertexIdx) {\n\t\t\t\tnextVertex = nextVertexIdx;\n\t\t\t\tneighborVertexIdx = neighborIdx + 1;\n\t\t\t} else {\n\t\t\t\tneighborVertexIdx = neighborIdx;\n\t\t\t\tnextVertex = A[neighborIdx];\n\t\t\t}\n\n\t\t\tif(nextVertex == dest) {\n\t\t\t\tpathLengthSoFar = min(pathLengthSoFar, 1 + A[neighborVertexIdx]);\n\t\t\t\tbreak;\n\t\t\t} else if(A[neighborVertexIdx] < INT_MAX) {\n\t\t\t\tpathLengthSoFar = min(pathLengthSoFar, 1 + A[neighborVertexIdx]);\n\t\t\t}\n\t\t}\n\t\tcurrentVertexIdx = nextVertexIdx;\n\t\tcurrentVertex = nextVertex;\n\t\tnextVertexIdx = nextVertexIdx + 1;\n\t}\n\n\tpathLength[source] = pathLengthSoFar;\n}",
            "// TODO: replace this with your code\n  int *d;\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n  extern __shared__ int shared[];\n  d = shared;\n  if (i == 0 && j == 0)\n    d[i*N+j] = A[source * N + j];\n  else\n    d[i*N+j] = A[i * N + j];\n\n  __syncthreads();\n  if (i < N && j < N) {\n    if (d[i*N+j] > d[(i+1)*N+j])\n      d[i*N+j] = d[(i+1)*N+j];\n    if (d[i*N+j] > d[i*N+(j+1)])\n      d[i*N+j] = d[i*N+(j+1)];\n  }\n  __syncthreads();\n  if (i < N && j < N) {\n    if (d[i*N+j] > d[(i-1)*N+j])\n      d[i*N+j] = d[(i-1)*N+j];\n    if (d[i*N+j] > d[i*N+(j-1)])\n      d[i*N+j] = d[i*N+(j-1)];\n  }\n  __syncthreads();\n  if (i == N-1 && j == N-1)\n    *pathLength = d[i*N+j];\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  int length = 0;\n  int i = source;\n  if (tid == dest) {\n    pathLength[tid] = 0;\n    return;\n  }\n  while (i!= dest) {\n    if (i < 0 || i >= N) {\n      break;\n    }\n    if (A[i * N + tid] == 1) {\n      length += 1;\n      i = tid;\n    } else {\n      i = -1;\n    }\n  }\n  pathLength[tid] = length;\n}",
            "// TODO: Implement this kernel\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint nthreads = gridDim.x * blockDim.x;\n\tfor (int i = tid; i < N * N; i += nthreads) {\n\t\tint n = i / N;\n\t\tint m = i % N;\n\t\tif (A[n * N + m] &&!pathLength[n] && m!= source)\n\t\t\tpathLength[n] = 1 + pathLength[m];\n\t}\n}",
            "// TODO: your code here\n}",
            "int tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tif (tid == source) {\n\t\tpathLength[dest] = 0;\n\t}\n\t__syncthreads();\n\twhile (tid < N) {\n\t\tif (A[tid * N + dest]!= 0) {\n\t\t\tpathLength[dest] = pathLength[source] + 1;\n\t\t}\n\t\t__syncthreads();\n\t\ttid += blockDim.x * gridDim.x;\n\t}\n}",
            "// TODO\n\n\n}",
            "int tid = blockDim.x * blockIdx.y * gridDim.x\t\t//rows preceeding current row in grid\n\t\t\t+ blockDim.x * blockIdx.x\t\t\t\t\t//blocks preceeding current block\n\t\t\t+ threadIdx.x;\n\n\tif (tid >= N) return;\n\n\t__shared__ bool path[BLOCKSIZE];\n\t__shared__ bool distance[BLOCKSIZE];\n\n\tpath[threadIdx.x] = (A[tid * N + source] == 1);\n\tdistance[threadIdx.x] = 0;\n\n\t__syncthreads();\n\n\tif (threadIdx.x == 0) {\n\t\tint distanceOld;\n\t\tint distanceNew;\n\t\tdo {\n\t\t\tdistanceOld = distance[threadIdx.x];\n\t\t\t__syncthreads();\n\t\t\tfor (int i = 0; i < BLOCKSIZE; i++) {\n\t\t\t\tif (path[i] == 1) {\n\t\t\t\t\tdistance[i] = min(distance[i], distance[i] + distanceOld);\n\t\t\t\t}\n\t\t\t}\n\t\t\t__syncthreads();\n\t\t\tdistanceNew = distance[threadIdx.x];\n\t\t} while (distanceOld!= distanceNew);\n\t\tpathLength[0] = distance[dest];\n\t}\n}",
            "// Get the global thread index.\n    // Each thread represents one element of the adjacency matrix.\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // Compute the shortest path distance from i to dest.\n    int dist[N];\n    dist[i] = (i == source)? 0 : INT_MAX;\n\n    // Compute the shortest path distance from j to dest.\n    int dist2[N];\n    dist2[j] = (j == source)? 0 : INT_MAX;\n\n    int iter = 0;\n    for (iter = 0; iter < N; ++iter) {\n        __syncthreads();\n\n        int dist_new[N];\n        // Parallelize over the row of the adjacency matrix.\n        if (i < N) {\n            // For each node k, compute the min of dist[k] + A[i][k] and dist[i].\n            // Update dist[i].\n            dist_new[i] = dist[i];\n            if (A[i * N + j] > 0 && dist[j] < INT_MAX)\n                dist_new[i] = min(dist_new[i], dist[j] + A[i * N + j]);\n        }\n\n        // Parallelize over the column of the adjacency matrix.\n        if (j < N) {\n            // For each node k, compute the min of dist2[k] + A[k][j] and dist2[j].\n            // Update dist2[j].\n            dist2[j] = dist2[j];\n            if (A[j * N + i] > 0 && dist2[i] < INT_MAX)\n                dist2[j] = min(dist2[j], dist2[i] + A[j * N + i]);\n        }\n\n        // Swap the distance arrays.\n        __syncthreads();\n        int *tmp = dist;\n        dist = dist2;\n        dist2 = tmp;\n    }\n\n    // Return the min distance from source to dest.\n    if (i == dest) {\n        *pathLength = dist[i];\n    }\n}",
            "int tid = blockDim.x*blockIdx.y*gridDim.x + blockDim.x*blockIdx.x + threadIdx.x;\n\tif (tid < N) {\n\t\tpathLength[tid] = 0x7FFFFFFF;\n\t}\n\t__syncthreads();\n\tif (tid == source) {\n\t\tpathLength[source] = 0;\n\t}\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t__syncthreads();\n\t\t\tif (tid < N && A[tid*N + j] && pathLength[j] < 0x7FFFFFFF) {\n\t\t\t\tatomicMin(&pathLength[tid], pathLength[j] + 1);\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tid == dest) {\n\t\tatomicMin(pathLength, pathLength[dest]);\n\t}\n}",
            "int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tint col = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row == dest) {\n\t\tpathLength[row] = A[col * N + dest]!= 0? 1 : 0;\n\t} else if (row == source) {\n\t\tpathLength[row] = A[col * N + source]!= 0? 1 : 0;\n\t} else {\n\t\tpathLength[row] = 0;\n\t}\n\n\t// Do the BFS\n\tfor (int k = 0; k < N; k++) {\n\t\tif (k == dest) {\n\t\t\tpathLength[row] = pathLength[row] + A[col * N + dest]!= 0? 1 : 0;\n\t\t} else if (k == source) {\n\t\t\tpathLength[row] = pathLength[row] + A[col * N + source]!= 0? 1 : 0;\n\t\t} else {\n\t\t\tpathLength[row] = pathLength[row] + A[col * N + k] * pathLength[k];\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "// Add code here\n}",
            "int tx = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;\n  int ty = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;\n  int tid = tx + ty*hipBlockDim_x*hipGridDim_x;\n  if(tx < N && ty < N && A[tid*N+dest] && A[tid*N+source])\n    *pathLength = 1;\n  __syncthreads();\n\n  for(int d = N/2; d > 0; d >>= 1) {\n    if(tx < d && ty < d) {\n      if(A[((tx + ty*d)*N + dest)*N + source]) {\n        //int t = *pathLength; // atomic read, atomic write\n        int t = atomicAdd(pathLength, 0);\n        if(t == 1)\n          atomicAdd(pathLength, 1);\n      }\n    }\n    __syncthreads();\n  }\n}",
            "// TODO: Fill in the kernel function\n  int start_x = blockIdx.x*blockDim.x+threadIdx.x;\n  int start_y = blockIdx.y*blockDim.y+threadIdx.y;\n\n  int num_threads = blockDim.x*blockDim.y;\n\n  for(int i = 0; i < num_threads; i++){\n    int id = i;\n    int x = id / blockDim.y;\n    int y = id % blockDim.y;\n    int index = x*N+y;\n    int curr = index;\n    if(A[index] == 1 && index == source){\n      int count = 0;\n      int pre = -1;\n      while(A[curr] == 1){\n        if(curr == dest){\n          break;\n        }\n        pre = curr;\n        curr = pre + N;\n        count++;\n      }\n      if(curr == dest){\n        pathLength[index] = count;\n      }\n      else{\n        pathLength[index] = -1;\n      }\n    }\n    else{\n      pathLength[index] = -1;\n    }\n  }\n}",
            "int tid = threadIdx.x + blockIdx.x*blockDim.x;\n  if (tid == source) {\n    for (int i = 0; i < N; i++) {\n      if (i == tid) continue;\n      if (A[tid*N + i] == 1) {\n        *pathLength = 1 + *pathLength;\n      }\n    }\n  } else if (tid == dest) {\n    for (int i = 0; i < N; i++) {\n      if (i == tid) continue;\n      if (A[tid*N + i] == 1) {\n        *pathLength = 1 + *pathLength;\n      }\n    }\n  }\n}",
            "// TODO: replace this code with your implementation\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\t// if (tid < N) {\n\t// \tprintf(\"Thread %d, source=%d\\n\", tid, source);\n\t// \tpathLength[tid] = -1;\n\t// \tif (A[source*N+tid] == 1) {\n\t// \t\tpathLength[tid] = 1;\n\t// \t\t// printf(\"Thread %d, source=%d, tid=%d\\n\", threadIdx.x, source, tid);\n\t// \t}\n\t// }\n\tif (tid < N) {\n\t\tpathLength[tid] = -1;\n\t\tif (tid == source) {\n\t\t\tpathLength[tid] = 0;\n\t\t} else {\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (A[tid*N+i] == 1) {\n\t\t\t\t\tpathLength[tid] = max(pathLength[tid], pathLength[i] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO: use a grid of NxN threads to compute the shortest path length.\n\n  int x = blockDim.x * blockIdx.x + threadIdx.x; // Get this thread's x-index into the NxN grid.\n  int y = blockDim.y * blockIdx.y + threadIdx.y; // Get this thread's y-index into the NxN grid.\n\n  // Make sure the thread is inside the bounds of the matrix.\n  if (x >= N || y >= N || x == y)\n    return;\n\n  // We can use A[x][y] to access the adjacency matrix A at row x, column y.\n  int minLength = 1000000;\n  if (A[x * N + y] > 0) {\n    if (x == source) {\n      minLength = 1;\n    }\n    if (y == source) {\n      minLength = 1;\n    }\n    if (x == dest) {\n      minLength = 1;\n    }\n    if (y == dest) {\n      minLength = 1;\n    }\n    // TODO: compute the minimum path length between source and dest using A[x][y].\n  }\n\n  // Write the results into the output array.\n  // TODO: use atomicMin to update the path length of all threads at this location.\n\n  if (x == y) {\n    atomicMin(pathLength, minLength);\n  }\n}",
            "size_t id = blockIdx.x * blockDim.x + threadIdx.x;\n    if(id < N) {\n        if(A[id*N+dest]) {\n            pathLength[id] = 1 + pathLength[dest];\n        } else {\n            pathLength[id] = 0;\n        }\n    }\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tint di = (j + 1) * (j + 2) / 2;\n\tif (i == dest && j == source) {\n\t\tpathLength[0] = 1;\n\t} else if (i >= j) {\n\t\tpathLength[di] = A[i * N + j];\n\t}\n\t__syncthreads();\n\tint k;\n\tfor (k = N / 2; k > 0; k /= 2) {\n\t\tif (i >= j + k) {\n\t\t\tint s = i - (i - j + k) / 2;\n\t\t\tif (pathLength[di] > pathLength[s * (s - 1) / 2 + (i - s)]) {\n\t\t\t\tpathLength[di] = pathLength[s * (s - 1) / 2 + (i - s)];\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "mpi",
        "prompt": "#include <mpi.h>\n\n/* Return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The shortest path length is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "// TODO: your code here\n\tint size, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\t\n\t\n\tif (A[source*N + dest]!= 0) {\n\t\treturn 1;\n\t} else {\n\t\tint localMin = 0;\n\t\t\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[i*N + source]!= 0) {\n\t\t\t\tint len = shortestPathLength(A, N, i, dest);\n\t\t\t\t\n\t\t\t\tif (rank == 0 && localMin == 0) {\n\t\t\t\t\tlocalMin = len + 1;\n\t\t\t\t} else if (rank == 0 && len + 1 < localMin) {\n\t\t\t\t\tlocalMin = len + 1;\n\t\t\t\t} else if (rank > 0 && len + 1 < localMin) {\n\t\t\t\t\tlocalMin = len + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (rank == 0) {\n\t\t\treturn localMin;\n\t\t} else {\n\t\t\treturn -1;\n\t\t}\n\t}\n}",
            "// your code here\n  return -1;\n}",
            "// TODO: Your code goes here.\n\n}",
            "// TODO: your code here\n}",
            "// YOUR CODE HERE\n}",
            "// TODO\n}",
            "if (source >= N || source < 0)\n    throw std::out_of_range(\"Source outside of matrix\");\n  if (dest >= N || dest < 0)\n    throw std::out_of_range(\"Destination outside of matrix\");\n  //...\n}",
            "// TODO\n  return 0;\n}",
            "// Your code goes here\n}",
            "/* Your code here */\n}",
            "// TODO: compute shortest path length between source and dest\n\tint shortestLength = INT_MAX;\n\n\treturn shortestLength;\n}",
            "return 0;\n}",
            "// TODO\n}",
            "// TODO: implement this\n    return 0;\n}",
            "/*... */\n}",
            "// TODO\n}",
            "int *data, *recvData;\n  data = new int[N];\n  recvData = new int[N];\n  int s = source;\n  int d = dest;\n  MPI_Status status;\n  int procNum, procRank;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &procNum);\n  MPI_Comm_rank(MPI_COMM_WORLD, &procRank);\n\n  for (int i = 0; i < N; i++)\n    data[i] = A[i*N + s];\n\n  int len = (N+procNum-1)/procNum;\n  int start = procRank*len;\n\n  if (procRank == 0)\n    for (int i = 0; i < N; i++)\n      recvData[i] = 0;\n\n  for (int i = 0; i < len; i++) {\n    int j = 0;\n    for (; j < N; j++) {\n      if (data[j] == 1)\n        break;\n    }\n    if (j == N)\n      break;\n\n    for (int k = 0; k < N; k++) {\n      if (data[k] == 1 && k!= s) {\n        data[j] = A[j*N + k];\n        break;\n      }\n    }\n    if (k == N)\n      data[j] = 0;\n  }\n\n  MPI_Gather(data, len, MPI_INT, recvData, len, MPI_INT, 0, MPI_COMM_WORLD);\n\n  int ret = 0;\n  if (procRank == 0) {\n    for (int i = 0; i < N; i++) {\n      if (recvData[i] == 1)\n        ret++;\n      if (i == d)\n        break;\n    }\n  }\n\n  delete[] data;\n  delete[] recvData;\n  return ret;\n}",
            "int* send = new int[N];\n\tint* recv = new int[N];\n\n\tfor (size_t i = 0; i < N; i++) {\n\t\tsend[i] = A[source*N + i];\n\t}\n\n\tMPI_Bcast(send, N, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Reduce(send, recv, N, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n\tif (MPI_COMM_WORLD.rank == 0) {\n\t\tint len = 0;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tlen = std::max(len, recv[dest] + recv[i] - A[dest*N + i]);\n\t\t}\n\t\treturn len;\n\t}\n\telse {\n\t\treturn 0;\n\t}\n}",
            "MPI_Comm rowComm, colComm;\n\n  // TODO: Implement me\n  return 0;\n}",
            "// TODO: Your code here\n    int mysize,myrank;\n    int *dist;\n    int *pred;\n    int *recvcounts;\n    int *displs;\n\n    dist = new int[N];\n    pred = new int[N];\n    recvcounts = new int[N];\n    displs = new int[N];\n\n    dist[0] = 0;\n    MPI_Comm_size(MPI_COMM_WORLD,&mysize);\n    MPI_Comm_rank(MPI_COMM_WORLD,&myrank);\n    for(int i=0;i<N;i++)\n    {\n        dist[i] = INT_MAX;\n        pred[i] = INT_MAX;\n    }\n    for(int i=0;i<N;i++)\n    {\n        for(int j=0;j<N;j++)\n        {\n            if(A[i*N+j]!=INT_MAX)\n            {\n                if(myrank == i)\n                {\n                    if(myrank == dest)\n                    {\n                        printf(\"myrank %d pred %d \\n\",myrank,j);\n                        dist[i] = 0;\n                        pred[i] = j;\n                    }\n                    else if(A[i*N+j] < dist[j])\n                    {\n                        dist[j] = A[i*N+j];\n                        pred[j] = i;\n                    }\n                }\n            }\n        }\n    }\n    for(int i=0;i<mysize;i++)\n    {\n        recvcounts[i] = 0;\n    }\n    for(int i=0;i<N;i++)\n    {\n        recvcounts[pred[i]]++;\n    }\n    MPI_Allgather(MPI_IN_PLACE,0,MPI_INT,recvcounts,1,MPI_INT,MPI_COMM_WORLD);\n    displs[0] = 0;\n    for(int i=1;i<mysize;i++)\n    {\n        displs[i] = displs[i-1] + recvcounts[i-1];\n    }\n    MPI_Allgatherv(dist,N,MPI_INT,dist,recvcounts,displs,MPI_INT,MPI_COMM_WORLD);\n    return dist[dest];\n}",
            "// TODO\n  return 0;\n}",
            "// Add your code here\n\treturn -1;\n}",
            "// TODO: Implement\n    return -1;\n}",
            "// Your code here\n\tint min_path_length;\n\tint local_path_length;\n\tint global_path_length;\n\tint local_source;\n\tint local_dest;\n\tint local_path_length_buffer[A.size()];\n\tint source_buffer, dest_buffer;\n\tint rank, size;\n\tMPI_Status status;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tlocal_source = source/size;\n\tlocal_dest = dest/size;\n\t//std::cout << \"local source is: \" << local_source << std::endl;\n\t//std::cout << \"local dest is: \" << local_dest << std::endl;\n\tfor (int i = 0; i < local_path_length_buffer; i++){\n\t\tlocal_path_length_buffer[i] = 0;\n\t}\n\n\tint* dp_array = new int[N];\n\tfor (int i = 0; i < N; i++){\n\t\tdp_array[i] = 0;\n\t}\n\n\tlocal_path_length = 0;\n\n\tif (local_source == rank){\n\t\tlocal_path_length = 1;\n\t}\n\tlocal_path_length_buffer[rank] = local_path_length;\n\n\n\tif (local_source == 1){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (A[i] == 1){\n\t\t\t\tdp_array[i] = 1;\n\t\t\t}\n\t\t}\n\t}\n\tif (local_source == 2){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (A[i] == 2){\n\t\t\t\tdp_array[i] = 2;\n\t\t\t}\n\t\t}\n\t}\n\tif (local_source == 3){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (A[i] == 3){\n\t\t\t\tdp_array[i] = 3;\n\t\t\t}\n\t\t}\n\t}\n\tif (local_source == 4){\n\t\tfor (int i = 0; i < N; i++){\n\t\t\tif (A[i] == 4){\n\t\t\t\tdp_array[i] = 4;\n\t\t\t}\n\t\t}\n\t}\n\n\n\tfor (int i = 0; i < N; i++){\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (A[i][j] == 1 && dp_array[i]!= 0 && dp_array[j] == 0){\n\t\t\t\tdp_array[j] = dp_array[i] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tlocal_path_length = dp_array[local_dest];\n\n\tMPI_Gather(&local_path_length, 1, MPI_INT, local_path_length_buffer, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0){\n\t\tglobal_path_length = 0;\n\t\tfor (int i = 0; i < size; i++){\n\t\t\tif (local_path_length_buffer[i] > global_path_length){\n\t\t\t\tglobal_path_length = local_path_length_buffer[i];\n\t\t\t}\n\t\t}\n\t\treturn global_path_length;\n\t}\n\n}",
            "if (source == dest) return 0;\n    if (N == 0) return -1;\n    if (source >= N || source < 0) return -1;\n    if (dest >= N || dest < 0) return -1;\n\n    std::vector<int> visited(N, 0);\n    std::vector<int> q;\n    q.push_back(source);\n    visited[source] = 1;\n\n    int steps = 0;\n    while (!q.empty()) {\n        int cur = q.front();\n        q.erase(q.begin());\n        for (int i = 0; i < N; ++i) {\n            if (A[cur*N + i] &&!visited[i]) {\n                q.push_back(i);\n                visited[i] = 1;\n                if (i == dest) return steps + 1;\n            }\n        }\n        ++steps;\n    }\n    return -1;\n}",
            "// TODO: implement\n  return 0;\n}",
            "//...\n}",
            "int length = 0;\n  std::vector<int> distance(N, -1);\n  distance[source] = 0;\n\n  /* TODO */\n\n  return length;\n}",
            "std::vector<int> A2(N*N);\n\tMPI_Datatype shortest_path_type;\n\tMPI_Datatype row_type;\n\tMPI_Datatype int_type;\n\n\t// TODO\n\n\tMPI_Type_commit(&shortest_path_type);\n\tMPI_Type_commit(&row_type);\n\tMPI_Type_commit(&int_type);\n\n\tMPI_Type_free(&shortest_path_type);\n\tMPI_Type_free(&row_type);\n\tMPI_Type_free(&int_type);\n\n\treturn 0;\n}",
            "}",
            "int lsp; // local shortest path\n    int gsp; // global shortest path\n    std::vector<int> visited(N, 0);\n    std::queue<int> q;\n    q.push(source);\n\n    visited[source] = 1;\n    lsp = 0;\n    while (!q.empty()) {\n        int v = q.front();\n        q.pop();\n        if (v == dest) {\n            break;\n        }\n        for (int i = 0; i < N; i++) {\n            if (A[v*N+i] &&!visited[i]) {\n                q.push(i);\n                visited[i] = 1;\n            }\n        }\n        lsp++;\n    }\n\n    // send local shortest path length to rank 0\n    MPI_Gather(&lsp, 1, MPI_INT, &gsp, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    if (0 == rank) {\n        int i;\n        for (i = 0; i < size; i++) {\n            if (gsp > gsp[i]) {\n                gsp = gsp[i];\n            }\n        }\n    }\n    return gsp;\n}",
            "}",
            "if (N == 0) return 0;\n  auto num_nodes = N * N;\n  auto my_rank = 0;\n  auto world_size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n  if (world_size <= 1) return shortestPathLength(A, N, source, dest);\n  if (num_nodes < world_size) return 0;\n  auto nodes_per_rank = num_nodes / world_size;\n  std::vector<int> local_A(nodes_per_rank);\n  MPI_Scatter(&A[0], nodes_per_rank, MPI_INT, &local_A[0], nodes_per_rank, MPI_INT, 0, MPI_COMM_WORLD);\n  auto result = shortestPathLength(local_A, sqrt(nodes_per_rank), source % sqrt(nodes_per_rank), dest % sqrt(nodes_per_rank));\n  auto local_result = 0;\n  MPI_Gather(&result, 1, MPI_INT, &local_result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return local_result;\n}",
            "// TODO: implement\n  return 0;\n}",
            "// TODO: implement shortest path algorithm here\n\tstd::vector<int> distances(N, -1);\n\tdistances[source] = 0;\n\tstd::vector<int> predecessors(N, -1);\n\tint count = 0;\n\tint rank = 0;\n\tint comm_sz = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &comm_sz);\n\tint send_count = (N + comm_sz - 1) / comm_sz;\n\tint my_send_start = rank*send_count;\n\tint my_send_end = std::min(N, (rank+1)*send_count);\n\tint my_recv_start = std::max(my_send_start, 1);\n\tint my_recv_end = std::min(N, my_send_end);\n\tint my_recv_count = my_recv_end - my_recv_start;\n\tint tag = 0;\n\n\twhile (count < N) {\n\t\t// send distances to neighbors\n\t\tfor (int i = my_send_start; i < my_send_end; i++) {\n\t\t\tint nbr = -1;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] && (distances[j]!= -1) && (distances[j] < distances[i])) {\n\t\t\t\t\tnbr = j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (nbr!= -1) {\n\t\t\t\tMPI_Send(&distances[nbr], 1, MPI_INT, nbr, tag, MPI_COMM_WORLD);\n\t\t\t\tMPI_Send(&nbr, 1, MPI_INT, nbr, tag, MPI_COMM_WORLD);\n\t\t\t}\n\t\t}\n\n\t\t// receive distances from neighbors\n\t\tfor (int i = my_recv_start; i < my_recv_end; i++) {\n\t\t\tint nbr;\n\t\t\tMPI_Recv(&nbr, 1, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tMPI_Recv(&distances[nbr], 1, MPI_INT, MPI_ANY_SOURCE, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tpredecessors[nbr] = nbr;\n\t\t}\n\n\t\t// find the minimum\n\t\tfor (int i = my_recv_start; i < my_recv_end; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] && (distances[j]!= -1) && (distances[j] < distances[i])) {\n\t\t\t\t\tpredecessors[i] = j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcount++;\n\t\t}\n\t}\n\n\tint min_distance = 0;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (distances[i]!= -1) {\n\t\t\tmin_distance = std::min(min_distance, distances[i]);\n\t\t}\n\t}\n\n\tint my_min_distance = min_distance;\n\tMPI_Reduce(&my_min_distance, &min_distance, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\tif (rank == 0) {\n\t\treturn min_distance;\n\t}\n\telse {\n\t\treturn -1;\n\t}\n}",
            "// TODO: implement\n    return -1;\n}",
            "std::vector<bool> visited(N, false);\n\n  std::vector<int> dist(N, INT_MAX);\n  dist[source] = 0;\n\n  std::vector<int> prev(N, -1);\n\n  std::queue<int> Q;\n  Q.push(source);\n\n  while (!Q.empty()) {\n    auto node = Q.front();\n    Q.pop();\n\n    visited[node] = true;\n\n    for (size_t i = 0; i < N; ++i) {\n      if (!visited[i] && A[node * N + i]!= 0) {\n        if (dist[i] > dist[node] + 1) {\n          dist[i] = dist[node] + 1;\n          prev[i] = node;\n          Q.push(i);\n        }\n      }\n    }\n  }\n\n  std::vector<int> path;\n\n  auto current = dest;\n\n  while (current!= -1) {\n    path.push_back(current);\n    current = prev[current];\n  }\n\n  return path.size();\n}",
            "if (source == dest) return 0;\n\n\tint length = INT_MAX;\n\t// Your code goes here\n\n\treturn length;\n}",
            "// YOUR CODE HERE\n    return -1;\n}",
            "if (source >= N || source < 0) throw std::out_of_range(\"source is out of range\");\n\tif (dest >= N || dest < 0) throw std::out_of_range(\"dest is out of range\");\n\n\tstd::vector<std::vector<int>> distances(N, std::vector<int>(N, INT_MAX));\n\tstd::vector<std::vector<int>> predecessors(N, std::vector<int>(N, -1));\n\tstd::vector<bool> visited(N, false);\n\tstd::vector<int> queue;\n\n\tdistances[source][source] = 0;\n\n\tqueue.push_back(source);\n\twhile (queue.size() > 0) {\n\t\tint u = queue.back();\n\t\tqueue.pop_back();\n\t\tvisited[u] = true;\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (!visited[v] && A[u][v]!= 0 && distances[u][v] > distances[u][source] + A[u][v]) {\n\t\t\t\tdistances[v][v] = distances[u][v] = distances[u][source] + A[u][v];\n\t\t\t\tpredecessors[v][v] = predecessors[u][v] = u;\n\t\t\t\tqueue.push_back(v);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distances[dest][dest];\n}",
            "// TODO\n  return -1;\n}",
            "int length = 0;\n\n    // TODO: Fill in this function\n\n    return length;\n}",
            "// Your code here\n  return 0;\n}",
            "if (source == dest)\n\t\treturn 0;\n\tif (source >= N || dest >= N || source < 0 || dest < 0)\n\t\tthrow std::out_of_range(\"Invalid source or dest\");\n\tstd::vector<int> pathLength(N, 0);\n\tstd::vector<bool> seen(N, false);\n\tstd::vector<int> Q = { source };\n\tint nextSource = -1;\n\twhile (Q.size() > 0) {\n\t\tnextSource = Q.back();\n\t\tQ.pop_back();\n\t\tseen[nextSource] = true;\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (!seen[i] && A[N * nextSource + i] > 0) {\n\t\t\t\tpathLength[i] = pathLength[nextSource] + 1;\n\t\t\t\tQ.push_back(i);\n\t\t\t}\n\t\t}\n\t}\n\treturn pathLength[dest];\n}",
            "int n = N;\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int m = n / size;\n    int s = m * rank;\n    int e = s + m;\n    if (rank == size - 1) {\n        e = n;\n    }\n    std::vector<int> B(e - s);\n    for (int i = s; i < e; ++i) {\n        B[i - s] = A[i];\n    }\n    return shortestPathLength(B, e - s, source, dest);\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\t\n\t// TODO\n\treturn -1;\n}",
            "std::vector<std::vector<int>> adjacency(N, std::vector<int>(N, 0));\n\tstd::vector<int> pathLength(N, -1);\n\n\t// Your code goes here\n\n\treturn pathLength[dest];\n}",
            "// TODO: Replace with your code.\n\n\tint path = 0;\n\t// \u5728\u8fd9\u91cc\u5b9e\u73b0\u4e00\u4e0b\u6c42\u6700\u77ed\u8def\u5f84\n\n\t// \u4f7f\u7528bfs\u6216\u8005dfs\n\t// \u5728\u8fd9\u91cc\u5199\u7b97\u6cd5\uff0c\u6ce8\u610f\u5bf9\u5e94\u95ee\u9898\u8981\u8003\u8651\u5230\u8fb9\u6743\u95ee\u9898\n\t// \u4f8b\u5982\u6709n\u4e2a\u9876\u70b9\uff0c\u6709m\u6761\u8fb9\n\t// \u5bf9\u4e8ebfs\u7684\u601d\u8def\u5c31\u662f\u5148\u627e\u5230\u8d77\u70b9\uff0c\u628a\u5b83\u52a0\u5165\u5230\u961f\u5217\u4e2d\uff0c\u7136\u540e\u5f00\u59cb\u5faa\u73af\uff0c\u961f\u5217\u4e2d\u51fa\u6765\u7684\u70b9\u4e0d\u662f\u76ee\u6807\u70b9\u5c31\u628a\u5b83\u90bb\u63a5\u70b9\u52a0\u5165\u5230\u961f\u5217\u4e2d\uff0c\u5982\u679c\u961f\u5217\u4e3a\u7a7a\u5c31\u7ec8\u6b62\u9012\u5f52\n\t// \u8fd9\u4e2a\u601d\u8def\u5176\u5b9e\u5c31\u662f\u5e7f\u5ea6\u4f18\u5148\uff0c\u5bf9\u4e8edfs\u5c31\u662f\u6df1\u5ea6\u4f18\u5148\n\t// \u6ce8\u610f\uff1a\u961f\u5217\u8981\u4f7f\u7528vector\u6765\u6a21\u62df\uff0c\u5982\u679c\u7528list\u7684\u8bdd\uff0c\u5c31\u5f97\u8981\u4f7f\u7528\u5230\u5176\u4e2d\u7684\u8fed\u4ee3\u5668\u4e86\uff0c\u4e0d\u8fc7\u611f\u89c9\u7528list\u4e5f\u6ca1\u5fc5\u8981\uff0cvector\u7684\u8bdd\u8981\u6ce8\u610f\u8fb9\u754c\u95ee\u9898\n\n\t// \u8fd9\u91cc\u600e\u4e48\u627e\u5230\u8d77\u70b9\uff1f\n\t// \u627e\u5230\u6240\u67090\u884c\u7684\u5217\uff0c\u627e\u5230\u6700\u5c0f\u7684\u884c\uff0c\u90a3\u4e48\u5c31\u662f\u8d77\u70b9\uff0c\u8d77\u70b9\u5c31\u662f\u7b2c\u4e00\u4e2a\n\n\t// \u5728\u8fd9\u91cc\u627e\u5230\u4e86\u8d77\u70b9\uff0c\u5148\u628a\u8d77\u70b9\u52a0\u5165\u5230\u961f\u5217\u4e2d\uff0c\u7136\u540e\u5f00\u59cb\u5faa\u73af\uff0c\u5982\u679c\u961f\u5217\u4e3a\u7a7a\uff0c\u5c31\u7ec8\u6b62\u9012\u5f52\uff0c\u5982\u679c\u6709\uff0c\u5c31\u5faa\u73af\n\n\t// \u5982\u679c\u961f\u5217\u7684\u7b2c\u4e00\u4e2a\u4e0d\u662f\u76ee\u6807\u70b9\uff0c\u90a3\u4e48\u628a\u961f\u5217\u4e2d\u7684\u70b9\u52a0\u5165\u5230\u961f\u5217\u4e2d\n\n\t// \u5982\u679c\u961f\u5217\u4e0d\u4e3a\u7a7a\uff0c\u90a3\u4e48\u627e\u5230\u961f\u5217\u7b2c\u4e00\u4e2a\u70b9\u5728\u7b2c\u51e0\u884c\uff0c\u5728\u7b2c\u51e0\u5217\uff0c\u7136\u540e\u627e\u5230\u5bf9\u5e94\u7684\u884c\uff0c\u5224\u65ad\u662f\u5426\u6709\u4e00\u4e2a\u4e3a1\uff0c\u5982\u679c\u6709\u5c31\u52a0\u5165\u5230\u961f\u5217\u4e2d\uff0c\u6ca1\u6709\u7684\u8bdd\u5c31\u7ee7\u7eed\u9012\u5f52\n\t// \u4e0d\u8981\u5fd8\u8bb0\u628a\u8fd9\u4e2a\u70b9\u5220\u9664\u6389\uff0c\u6216\u8005\u662f\u53d8\u62100\n\n\treturn path;\n}",
            "// TODO\n    return 0;\n}",
            "int shortest_path_length = std::numeric_limits<int>::max();\n\n  // TODO: Your code goes here\n  // Hint: you will need a queue for BFS\n\n  return shortest_path_length;\n}",
            "if (N == 0)\n\t\treturn -1;\n\tif (source >= N || dest >= N || source < 0 || dest < 0)\n\t\treturn -1;\n\tauto dist = std::vector<int>(N, INT_MAX);\n\tdist[source] = 0;\n\tint n_proc;\n\tMPI_Comm_size(MPI_COMM_WORLD, &n_proc);\n\tauto work_per_proc = N / n_proc;\n\tauto start = source;\n\tauto end = source + work_per_proc;\n\tint proc = 0;\n\tfor (int proc = 0; proc < n_proc - 1; ++proc) {\n\t\tMPI_Send(&A[start], work_per_proc, MPI_INT, proc + 1, 0, MPI_COMM_WORLD);\n\t\tMPI_Send(&start, 1, MPI_INT, proc + 1, 0, MPI_COMM_WORLD);\n\t\tstart += work_per_proc;\n\t\tend += work_per_proc;\n\t}\n\tint start_p = 0;\n\tMPI_Send(&A[start], work_per_proc + N % n_proc, MPI_INT, proc + 1, 0, MPI_COMM_WORLD);\n\tMPI_Send(&start, 1, MPI_INT, proc + 1, 0, MPI_COMM_WORLD);\n\tMPI_Recv(&start_p, 1, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\tMPI_Recv(&dist[start_p], work_per_proc + N % n_proc, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\treturn dist[dest];\n}",
            "int pathLength = -1; // -1 if there is no path from source to dest\n\n\t// YOUR CODE HERE\n\n\treturn pathLength;\n}",
            "// TODO: implement this function\n    return 0;\n}",
            "int mpi_rank, mpi_size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &mpi_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &mpi_size);\n\n    // TODO: Your code here!\n    return 0;\n}",
            "int length = 0;\n    bool found = false;\n    std::queue<int> Q;\n    Q.push(source);\n    std::vector<bool> visited(N, false);\n    visited[source] = true;\n\n    while (!Q.empty() &&!found) {\n        int cur = Q.front();\n        Q.pop();\n        length++;\n\n        for (size_t i = 0; i < N; i++) {\n            if (A[cur * N + i] == 1 &&!visited[i]) {\n                Q.push(i);\n                visited[i] = true;\n                if (i == dest) {\n                    found = true;\n                    break;\n                }\n            }\n        }\n    }\n    return found? length : -1;\n}",
            "// YOUR CODE HERE\n\t\n\treturn 0;\n}",
            "// TODO: Replace this with your code\n  return -1;\n}",
            "// TODO\n  return 0;\n}",
            "int send_buffer[N][N];\n    int recv_buffer[N][N];\n\n    int num_row = N;\n    int num_col = N;\n\n    int my_rank;\n    int num_procs;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n\n    int source_row = source / N;\n    int source_col = source % N;\n    int dest_row = dest / N;\n    int dest_col = dest % N;\n\n    int source_proc = source_row * num_col + source_col;\n    int dest_proc = dest_row * num_col + dest_col;\n\n    std::vector<int> send_indices(num_procs);\n    std::vector<int> recv_indices(num_procs);\n\n    int num_source = source_proc / num_procs;\n    int num_dest = dest_proc / num_procs;\n\n    int num_source_proc = 0;\n    int num_dest_proc = 0;\n\n    for (int i = 0; i < num_procs; i++) {\n        int row = i / num_col;\n        int col = i % num_col;\n        int curr_proc = row * num_col + col;\n\n        if (curr_proc == source_proc) {\n            send_indices[i] = 1;\n            num_source_proc++;\n        } else {\n            send_indices[i] = 0;\n        }\n\n        if (curr_proc == dest_proc) {\n            recv_indices[i] = 1;\n            num_dest_proc++;\n        } else {\n            recv_indices[i] = 0;\n        }\n    }\n\n    if (my_rank == 0) {\n        for (int i = 0; i < num_row; i++) {\n            for (int j = 0; j < num_col; j++) {\n                send_buffer[i][j] = A[i * N + j];\n            }\n        }\n    }\n\n    MPI_Scatter(send_buffer, N * N, MPI_INT, recv_buffer, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    int recv_buffer_source[N];\n    int recv_buffer_dest[N];\n\n    if (my_rank == source_proc) {\n        for (int i = 0; i < N; i++) {\n            recv_buffer_source[i] = recv_buffer[i][source_col];\n        }\n    }\n\n    if (my_rank == dest_proc) {\n        for (int i = 0; i < N; i++) {\n            recv_buffer_dest[i] = recv_buffer[dest_row][i];\n        }\n    }\n\n    int recv_source;\n    int recv_dest;\n\n    if (my_rank == source_proc) {\n        MPI_Scatter(recv_buffer_source, N, MPI_INT, &recv_source, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    } else {\n        MPI_Scatter(NULL, N, MPI_INT, &recv_source, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    }\n\n    if (my_rank == dest_proc) {\n        MPI_Scatter(recv_buffer_dest, N, MPI_INT, &recv_dest, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    } else {\n        MPI_Scatter(NULL, N, MPI_INT, &recv_dest, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    }\n\n    std::vector<int> distances(N, 100000000);\n\n    std::vector<int> shortest_paths(N, 1000000",
            "// Your code here\n}",
            "return 0;\n}",
            "int mysize, myrank, mylength;\n  std::vector<int> length(N, -1);\n  std::vector<int> distance(N, 0);\n  std::vector<int> path(N, -1);\n  std::vector<int> sendbuf(N*N);\n  std::vector<int> recvbuf(N*N);\n\n  MPI_Comm_size(MPI_COMM_WORLD, &mysize);\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n\n  // Fill distance with shortest path length from source to each other node\n  distance[source] = 0;\n  for (int i = 0; i < N; ++i) {\n    for (int j = 0; j < N; ++j) {\n      sendbuf[i*N + j] = A[i*N + j];\n    }\n  }\n\n  // If only one processor, calculate shortest path lengths\n  if (mysize == 1) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (distance[i] >= 0 && distance[j] < 0) {\n          if (A[i*N + j] == 1) {\n            distance[j] = distance[i] + 1;\n          }\n        }\n      }\n    }\n\n    mylength = distance[dest];\n\n  // If more than one processor, use master-worker model\n  } else {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (distance[i] >= 0 && distance[j] < 0) {\n          if (A[i*N + j] == 1) {\n            distance[j] = distance[i] + 1;\n          }\n        }\n      }\n    }\n\n    // Master send shortest path lengths to workers\n    if (myrank == 0) {\n      for (int i = 1; i < mysize; ++i) {\n        MPI_Send(distance.data(), N, MPI_INT, i, 0, MPI_COMM_WORLD);\n      }\n    }\n\n    // Workers receive shortest path lengths and calculate new shortest path lengths\n    if (myrank!= 0) {\n      MPI_Recv(recvbuf.data(), N*N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n      for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n          if (recvbuf[i*N + j] >= 0 && distance[j] < 0) {\n            if (A[i*N + j] == 1) {\n              distance[j] = recvbuf[i*N + j] + 1;\n            }\n          }\n        }\n      }\n    }\n\n    // Master receive shortest path lengths from all workers and calculate final shortest path lengths\n    if (myrank == 0) {\n      for (int i = 1; i < mysize; ++i) {\n        MPI_Recv(recvbuf.data(), N*N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n        for (int j = 0; j < N; ++j) {\n          if (recvbuf[j] >= 0 && distance[j] < 0) {\n            distance[j] = recvbuf[j];\n          }\n        }\n      }\n    }\n\n    // Master broadcast final shortest path lengths to workers\n    if (myrank == 0) {\n      for (int i = 1; i < mysize; ++i) {\n        MPI_Send(distance.data(), N, MPI_INT, i, 0, MPI_COMM_WORLD);\n      }\n    }\n\n    // Workers receive final shortest path lengths from master and calculate shortest path length to destination node\n    if",
            "// TODO: replace this with code that solves the problem.\n    // You may assume the matrix is square with N rows and N columns.\n    // Each row and column corresponds to a vertex in the graph.\n    // The element at row i, column j is the weight of the edge from vertex i to vertex j.\n    // An edge with weight 0 means there is no edge.\n    // The function should return the length of the shortest path between\n    // the source vertex and the dest vertex.\n    int length;\n    int myrank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n    int size;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int sourceRank = source / (N / size);\n    int destRank = dest / (N / size);\n\n    int localSource = source % (N / size);\n    int localDest = dest % (N / size);\n\n    if (myrank == 0) {\n        MPI_Send(&A[localSource * N], N, MPI_INT, sourceRank, 1, MPI_COMM_WORLD);\n    }\n    if (myrank == sourceRank) {\n        std::vector<int> localA(N);\n        MPI_Recv(&localA[0], N, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n        std::vector<int> dist(N, INT_MAX);\n        std::vector<bool> visited(N, false);\n        dist[localSource] = 0;\n\n        while (!visited[localDest]) {\n            for (int i = 0; i < N; i++) {\n                if (dist[i]!= INT_MAX) {\n                    for (int j = 0; j < N; j++) {\n                        if (localA[i * N + j] &&!visited[j]) {\n                            if (dist[i] + 1 < dist[j]) {\n                                dist[j] = dist[i] + 1;\n                            }\n                        }\n                    }\n                }\n            }\n            for (int i = 0; i < N; i++) {\n                visited[i] = dist[i] == INT_MAX;\n            }\n        }\n        length = dist[localDest];\n        MPI_Send(&length, 1, MPI_INT, destRank, 2, MPI_COMM_WORLD);\n    }\n    if (myrank == destRank) {\n        int length;\n        MPI_Recv(&length, 1, MPI_INT, sourceRank, 2, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        return length;\n    }\n    return -1;\n}",
            "// TODO: Implement me\n  // Your solution must be parallel\n  // You can assume source!= dest\n\n  // You may assume the following is valid code (for convenience)\n  // int numRanks = mpi::world.size();\n  // int rankId = mpi::world.rank();\n  // int rootRankId = 0;\n\n  return -1;\n}",
            "// Initialize the distance vector to the maximum value, except for the source node which is 0\n    // Initialize the visited vector to 0.\n    std::vector<int> distance(N, std::numeric_limits<int>::max());\n    distance[source] = 0;\n    std::vector<int> visited(N, 0);\n\n    // Initialize the number of iterations to 0\n    int iteration = 0;\n\n    // Loop until all distances have been computed\n    while (1) {\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Compute the shortest distance from source to all the other nodes\n        for (size_t u = 0; u < N; u++) {\n            for (size_t v = 0; v < N; v++) {\n                if (!visited[u] && A[u*N+v] && distance[u]!= std::numeric_limits<int>::max() && distance[u] + 1 < distance[v]) {\n                    distance[v] = distance[u] + 1;\n                }\n            }\n        }\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Broadcast the distance vector to every rank\n        MPI_Bcast(distance.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Check if we have reached the destination\n        if (distance[dest]!= std::numeric_limits<int>::max()) {\n            break;\n        }\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Update the visited vector\n        for (size_t i = 0; i < N; i++) {\n            if (distance[i]!= std::numeric_limits<int>::max()) {\n                visited[i] = 1;\n            }\n        }\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Update the visited vector\n        for (size_t i = 0; i < N; i++) {\n            if (visited[i] == 1) {\n                distance[i] = std::numeric_limits<int>::max();\n            }\n        }\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Update the visited vector\n        for (size_t i = 0; i < N; i++) {\n            if (distance[i] == std::numeric_limits<int>::max()) {\n                visited[i] = 0;\n            }\n        }\n\n        // Wait for all the ranks to reach this point\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Increment the number of iterations\n        iteration++;\n\n        // If we have iterated through the graph more than the number of nodes, then we will never be able to\n        // compute the shortest path length\n        if (iteration > N) {\n            break;\n        }\n    }\n\n    // If the shortest path length is infinity, then there is no path to dest from source\n    if (distance[dest] == std::numeric_limits<int>::max()) {\n        distance[dest] = -1;\n    }\n\n    // Wait for all the ranks to reach this point\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    // Return the shortest path length on rank 0\n    int pathLength;\n    if (MPI::COMM_WORLD.Get_rank() == 0) {\n        pathLength = distance[dest];\n    }\n\n    // Wait for all the ranks to reach this point\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    // Broadcast the path length to every rank\n    MPI_Bcast(&pathLength, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    // Wait for all the ranks to reach this point\n    MPI_Barrier",
            "int shortestPathLength = INT_MAX;\n  // your code goes here\n  return shortestPathLength;\n}",
            "if (A[source*N+dest] == 0) {\n\t\treturn -1;\n\t}\n\n\t// Fill in your code here\n\t//...\n\n\treturn 0;\n}",
            "// TODO: insert code here\n\treturn 0;\n}",
            "// TODO: implement me!\n\treturn 0;\n}",
            "// BEGIN_YOUR_CODE (Modify the following lines of code)\n\n\tint myRank;\n\tint p;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &p);\n\n\tint length = 100000000;\n\tint maxLen = 0;\n\n\tif(myRank == 0) {\n\t\tfor (int i = 1; i < N; i++) {\n\t\t\tif (A[i*N + source] == 1) {\n\t\t\t\tlength = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tint step = 0;\n\tint next_step = 0;\n\twhile (length!= 0) {\n\t\tstep = length;\n\t\tlength = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j] == 1 && i!= dest && i!= source) {\n\t\t\t\t\tif (step + 1 < next_step) {\n\t\t\t\t\t\tlength = step + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMPI_Allreduce(&length, &next_step, 1, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\t\tif (next_step > maxLen) {\n\t\t\tmaxLen = next_step;\n\t\t}\n\t}\n\tif (myRank == 0) {\n\t\treturn maxLen;\n\t}\n\n\t// END_YOUR_CODE\n}",
            "// TODO\n}",
            "int l = 0;\n\t// TODO: Fill in the function\n\treturn l;\n}",
            "// Implement this function!\n\tint m_rank, m_size;\n\tint count=0;\n\tMPI_Status status;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &m_rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &m_size);\n\tMPI_Bcast(&A[0], N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&dest, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tstd::vector<int> path(N, -1);\n\tstd::queue<int> q;\n\tq.push(source);\n\tpath[source] = 0;\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[v*N + i] && path[i] == -1) {\n\t\t\t\tpath[i] = path[v] + 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\tif (m_rank == 0) {\n\t\tcount = path[dest];\n\t}\n\tMPI_Bcast(&count, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\treturn count;\n}",
            "// TODO: implement\n  return 0;\n}",
            "return 0;\n}",
            "return 0;\n}",
            "return 0;\n}",
            "/*\n     * TODO:\n     * This implementation doesn't work, but it should get you started.\n     *\n     * Note: In a distributed graph problem, we don't necessarily know how many nodes\n     * are on each processor (rank). As a result, we can't assume the processor on rank\n     * 0 has a complete copy of the graph.\n     *\n     * Since we can't assume the graph is contiguous on a processor, we can't use a\n     * standard matrix data structure. Instead, we have to use a 1D vector to store\n     * the adjacency matrix and then compute the index manually.\n     */\n    MPI_Comm comm = MPI_COMM_WORLD;\n    int nproc, rank, i, j, k;\n    int localN = N / (int)sqrt(numproc);\n    int globalN = N;\n    int localNum = 0;\n\n    MPI_Comm_size(comm, &nproc);\n    MPI_Comm_rank(comm, &rank);\n\n    int* localA = new int[localN*localN];\n    int* localD = new int[localN];\n    int* localP = new int[localN];\n\n    std::vector<int> D(N, std::numeric_limits<int>::max());\n    std::vector<int> P(N, -1);\n\n    // Compute the local sub-matrix and D and P\n    for(i = 0; i < localN; ++i) {\n        for(j = 0; j < localN; ++j) {\n            if(A[i + localN*rank] == 1) {\n                localA[i*localN + j] = 1;\n            }\n        }\n        localD[i] = D[i + localN*rank];\n        localP[i] = P[i + localN*rank];\n    }\n\n    // Create the send and receive buffers\n    int* sendBuffer = new int[localN*localN];\n    int* recvBuffer = new int[localN*localN];\n\n    // Send data to rank+1\n    if(rank!= nproc - 1) {\n        MPI_Send(&localA[0], localN*localN, MPI_INT, rank+1, 0, comm);\n        MPI_Send(&localD[0], localN, MPI_INT, rank+1, 1, comm);\n        MPI_Send(&localP[0], localN, MPI_INT, rank+1, 2, comm);\n    }\n\n    // Receive data from rank-1\n    if(rank!= 0) {\n        MPI_Recv(&recvBuffer[0], localN*localN, MPI_INT, rank-1, 0, comm, MPI_STATUS_IGNORE);\n        MPI_Recv(&recvBuffer[localN*localN], localN, MPI_INT, rank-1, 1, comm, MPI_STATUS_IGNORE);\n        MPI_Recv(&recvBuffer[localN*localN+localN], localN, MPI_INT, rank-1, 2, comm, MPI_STATUS_IGNORE);\n    }\n\n    for(i = 0; i < localN; ++i) {\n        // Update D and P\n        for(j = 0; j < localN; ++j) {\n            if(localA[i*localN + j] == 1) {\n                if(localD[i]!= std::numeric_limits<int>::max() && localD[j] > localD[i] + 1) {\n                    localD[j] = localD[i] + 1;\n                    localP[j] = i;\n                }\n            }\n        }\n\n        // Update localD and localP\n        for(j = 0; j < localN; ++j) {\n            if(recvBuffer[j*localN + i] == 1) {\n                if(localD[i]!= std::numeric_limits<int>::max() && recvBuffer[localN*localN + j] > localD[i] + 1) {\n                    localD[j] = localD[i] + 1;\n                    local",
            "int nbProcs, rank, value;\n\tMPI_Status stat;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &nbProcs);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tif(rank == 0) {\n\t\tstd::vector<int> sendBuff(N * N);\n\t\tstd::copy(A.begin(), A.end(), sendBuff.begin());\n\n\t\tfor(int i = 1; i < nbProcs; ++i)\n\t\t\tMPI_Send(&sendBuff[0], N * N, MPI_INT, i, 1, MPI_COMM_WORLD);\n\n\t\tfor(int i = 1; i < nbProcs; ++i) {\n\t\t\tMPI_Recv(&value, 1, MPI_INT, i, 2, MPI_COMM_WORLD, &stat);\n\n\t\t\tif(value == -1)\n\t\t\t\treturn -1;\n\t\t}\n\t}\n\telse {\n\t\tstd::vector<int> recvBuff(N * N);\n\t\tMPI_Recv(&recvBuff[0], N * N, MPI_INT, 0, 1, MPI_COMM_WORLD, &stat);\n\n\t\tvalue = shortestPathLength(recvBuff, N, source, dest);\n\n\t\tMPI_Send(&value, 1, MPI_INT, 0, 2, MPI_COMM_WORLD);\n\t}\n\n\treturn value;\n}",
            "int length = std::numeric_limits<int>::max();\n    std::vector<int> paths(N, std::numeric_limits<int>::max());\n    paths[source] = 0;\n    std::vector<int> visited(N, 0);\n    //std::vector<int> visited2(N, 0);\n    bool isFirst = true;\n\n    std::list<int> neighbors;\n\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    while (isFirst ||!neighbors.empty()) {\n        isFirst = false;\n        MPI_Barrier(MPI_COMM_WORLD);\n\n        // Calculate path length for neighboring vertices\n        std::vector<int> new_paths(N, std::numeric_limits<int>::max());\n        std::vector<int> new_visited(N, 0);\n        for (auto& neighbor : neighbors) {\n            for (size_t i = 0; i < N; i++) {\n                if (A[i * N + neighbor] == 1) {\n                    int temp = paths[neighbor] + 1;\n                    new_paths[i] = std::min(new_paths[i], temp);\n                    new_visited[i] = 1;\n                }\n            }\n        }\n\n        neighbors.clear();\n\n        // Check if any of the new_paths are shorter than the current paths\n        for (size_t i = 0; i < N; i++) {\n            if (new_paths[i] < paths[i]) {\n                paths[i] = new_paths[i];\n                visited[i] = 1;\n                if (i == dest) {\n                    length = new_paths[i];\n                }\n            }\n        }\n\n        for (size_t i = 0; i < N; i++) {\n            if (visited[i] == 0 && new_visited[i]!= 0) {\n                neighbors.push_back(i);\n            }\n        }\n    }\n\n    return length;\n}",
            "std::vector<int> dist(N);\n  std::vector<int> visited(N);\n  std::vector<int> parent(N);\n\n  // TODO\n  return -1;\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int nProc;\n  MPI_Comm_size(MPI_COMM_WORLD, &nProc);\n\n  // find the partitioning of the graph\n  int m = N / nProc;\n  int remainder = N % nProc;\n  int start;\n  if (rank < remainder) {\n    start = rank * (m + 1);\n  } else {\n    start = rank * m + remainder;\n  }\n\n  // get the part of the graph we have\n  std::vector<int> A_local(m * m);\n  std::copy(A.begin() + start * N, A.begin() + (start + m) * N, A_local.begin());\n\n  // TODO: Compute the shortest path length\n\n  return 0;\n}",
            "// TODO: implement\n  int result;\n  MPI_Reduce(&result, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "if (A.size()!= N * N) {\n\t\tthrow std::invalid_argument(\"A is not an NxN matrix\");\n\t}\n\n\tif (source < 0 || source >= N || dest < 0 || dest >= N) {\n\t\tthrow std::invalid_argument(\"source and dest must be 0 <= n < N\");\n\t}\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (size == 1) {\n\t\tthrow std::logic_error(\"Must use multiple processes\");\n\t}\n\n\tif (N % size!= 0) {\n\t\tthrow std::logic_error(\"N must be divisible by the number of processes\");\n\t}\n\n\tint chunkSize = N / size;\n\tint rankStart = rank * chunkSize;\n\tint rankEnd = (rank + 1) * chunkSize;\n\n\t// TODO: Your code here\n\tint localLen = -1;\n\tint localMin = -1;\n\n\tint count = 0;\n\tint dest_index = -1;\n\tint source_index = -1;\n\tint result;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tif (source == i)\n\t\t\tsource_index = i;\n\t\telse if (dest == i)\n\t\t\tdest_index = i;\n\t}\n\n\tint sum = 0;\n\tfor (int i = 0; i < N; i++)\n\t{\n\t\tfor (int j = 0; j < N; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t\tsum++;\n\t\t}\n\t}\n\t\n\tif (source_index == -1 || dest_index == -1)\n\t\treturn -1;\n\tfor (int i = source_index; i < rankEnd; i++)\n\t{\n\t\tif (A[i * N + dest_index] == 1)\n\t\t{\n\t\t\tlocalLen = 1;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (localLen == 1)\n\t\treturn 1;\n\telse\n\t\tlocalLen = -1;\n\n\tfor (int i = source_index; i < rankEnd; i++)\n\t{\n\t\tfor (int j = 0; j < rankEnd; j++)\n\t\t{\n\t\t\tif (A[i * N + j] == 1)\n\t\t\t{\n\t\t\t\tcount++;\n\t\t\t\tfor (int k = 0; k < rankEnd; k++)\n\t\t\t\t{\n\t\t\t\t\tif (A[j * N + k] == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tlocalMin = count;\n\n\tMPI_Reduce(&localLen, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\tif (result == -1)\n\t\treturn -1;\n\telse\n\t{\n\t\tMPI_Reduce(&localMin, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\t\tif (result == -1)\n\t\t\treturn -1;\n\t\telse\n\t\t\treturn result + 1;\n\t}\n\t\n}",
            "// TODO: Fill this in.\n}",
            "// TODO: Your code here\n\n\t// int world_rank;\n\t// MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\t// int world_size;\n\t// MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n\t// int i, j;\n\t// for(i = 0; i < world_size; i++){\n\t// \tfor(j = 0; j < world_size; j++){\n\t// \t\tif(i == j){\n\t// \t\t\tA[i][j] = 0;\n\t// \t\t}\n\t// \t}\n\t// }\n\n\tint world_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n\tint world_size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n\tint root = 0;\n\n\tstd::vector<int> path = {};\n\n\tif(world_rank == root){\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tpath.push_back(i);\n\t\t}\n\n\t\tstd::vector<std::vector<int>> dis_table(world_size, path);\n\n\t\tstd::vector<int> send_buffer = {};\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tsend_buffer.push_back(A[i][j]);\n\t\t\t}\n\t\t}\n\n\t\tint total_size = send_buffer.size() * sizeof(int);\n\t\tint block_size = total_size / world_size;\n\t\tint extra_size = total_size % world_size;\n\t\tstd::vector<int> send_size = {};\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\tsend_size.push_back(block_size);\n\t\t}\n\t\tfor(int i = 0; i < extra_size; i++){\n\t\t\tsend_size[i] += 1;\n\t\t}\n\n\t\tstd::vector<int> send_disp = {};\n\t\tint total_disp = 0;\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\tsend_disp.push_back(total_disp);\n\t\t\ttotal_disp += send_size[i];\n\t\t}\n\n\t\tint** recv_buffer = new int* [world_size];\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\trecv_buffer[i] = new int [N];\n\t\t}\n\n\t\tMPI_Scatterv(&send_buffer[0], &send_size[0], &send_disp[0], MPI_INT, &recv_buffer[0], N, MPI_INT, root, MPI_COMM_WORLD);\n\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tif(recv_buffer[i][j] == 0){\n\t\t\t\t\tdis_table[i][j] = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor(int i = 0; i < world_size; i++){\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tfor(int k = 0; k < N; k++){\n\t\t\t\t\tif(recv_buffer[i][j] == recv_buffer[i][k] && dis_table[i][j]!= -1 && dis_table[i][k]!= -1 && dis_table[i][j] > dis_table[i][k] + 1){\n\t\t\t\t\t\tdis_table[i][j] = dis_table[i][k] + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor(int i",
            "}",
            "int myrank;\n\tint nbproc;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nbproc);\n\n\tstd::vector<int> d(N);\n\tstd::vector<int> f(N);\n\tstd::vector<int> parent(N);\n\tfor (size_t i = 0; i < N; i++) {\n\t\td[i] = -1;\n\t\tf[i] = -1;\n\t\tparent[i] = -1;\n\t}\n\n\td[source] = 0;\n\n\twhile (true) {\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (A[i * N + source] == 1 && d[i] == -1) {\n\t\t\t\td[i] = 1;\n\t\t\t\tparent[i] = source;\n\t\t\t}\n\t\t}\n\n\t\tbool changed = false;\n\n\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\tif (d[i]!= -1) {\n\t\t\t\tfor (size_t j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i * N + j] == 1 && d[j] == -1) {\n\t\t\t\t\t\td[j] = d[i] + 1;\n\t\t\t\t\t\tparent[j] = i;\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (!changed)\n\t\t\tbreak;\n\t}\n\n\tstd::vector<int> d_total(N);\n\tstd::vector<int> parent_total(N);\n\n\tMPI_Allreduce(&d[0], &d_total[0], N, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\tMPI_Allreduce(&parent[0], &parent_total[0], N, MPI_INT, MPI_MAX, MPI_COMM_WORLD);\n\n\tif (myrank == 0) {\n\t\tint path = 0;\n\t\tif (d_total[dest]!= -1) {\n\t\t\tint i = dest;\n\t\t\tpath = d_total[dest];\n\t\t\twhile (i!= -1) {\n\t\t\t\tpath++;\n\t\t\t\ti = parent_total[i];\n\t\t\t}\n\t\t}\n\t\treturn path;\n\t} else {\n\t\treturn 0;\n\t}\n}",
            "// YOUR CODE HERE\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  std::vector<int> dist(N);\n  std::fill(dist.begin(), dist.end(), INT_MAX);\n  dist[source] = 0;\n  bool change = true;\n\n  while (change) {\n    change = false;\n    MPI_Allreduce(MPI_IN_PLACE, dist.data(), N, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (A[i * N + j] && dist[i]!= INT_MAX && dist[i] + 1 < dist[j]) {\n          dist[j] = dist[i] + 1;\n          change = true;\n        }\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "// TODO: Implement\n\treturn 0;\n}",
            "std::vector<int> dists(N, INT_MAX);\n    std::vector<int> prev(N, -1);\n    std::queue<int> q;\n    q.push(source);\n    dists[source] = 0;\n    while (!q.empty()) {\n        int cur = q.front();\n        q.pop();\n        for (int j = 0; j < N; ++j) {\n            if (A[cur * N + j] == 1 && dists[j] == INT_MAX) {\n                dists[j] = dists[cur] + 1;\n                prev[j] = cur;\n                q.push(j);\n            }\n        }\n    }\n    if (dists[dest] == INT_MAX)\n        return -1;\n    std::vector<int> path;\n    for (int cur = dest; cur!= source; cur = prev[cur]) {\n        path.push_back(cur);\n    }\n    path.push_back(source);\n    return path.size();\n}",
            "/* Your code here */\n}",
            "}",
            "return -1;\n}",
            "int size, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  int length = -1;\n  if (rank == 0) {\n    std::vector<std::vector<int>> all_paths(size);\n    std::vector<int> root_paths;\n    std::vector<int> root_nodes;\n    std::queue<int> q;\n\n    for (int i = 0; i < N; ++i) {\n      q.push(i);\n      root_nodes.push_back(i);\n      root_paths.push_back(0);\n    }\n\n    while (!q.empty()) {\n      int node = q.front();\n      q.pop();\n\n      for (int i = 0; i < N; ++i) {\n        if (A[node * N + i] == 1 &&!q.empty()) {\n          q.push(i);\n          root_nodes.push_back(i);\n          root_paths.push_back(root_paths[node] + 1);\n        }\n      }\n    }\n\n    for (int i = 0; i < size; ++i) {\n      MPI_Send(root_nodes.data(), root_nodes.size(), MPI_INT, i, 0, MPI_COMM_WORLD);\n      MPI_Send(root_paths.data(), root_paths.size(), MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n\n    for (int i = 1; i < size; ++i) {\n      int* nodes;\n      int* paths;\n      int length_paths;\n      MPI_Recv(&length_paths, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      nodes = new int[length_paths];\n      paths = new int[length_paths];\n\n      MPI_Recv(nodes, length_paths, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n      MPI_Recv(paths, length_paths, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n      for (int j = 0; j < length_paths; ++j) {\n        all_paths[i].push_back(paths[j]);\n      }\n    }\n\n    for (int i = 0; i < size; ++i) {\n      for (int j = 0; j < all_paths[i].size(); ++j) {\n        if (all_paths[i][j] == dest) {\n          length = all_paths[i][j];\n          break;\n        }\n      }\n    }\n  } else {\n    int length_paths;\n    int* nodes;\n    int* paths;\n\n    MPI_Recv(&length_paths, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    nodes = new int[length_paths];\n    paths = new int[length_paths];\n\n    MPI_Recv(nodes, length_paths, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n    MPI_Recv(paths, length_paths, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n    for (int i = 0; i < length_paths; ++i) {\n      if (paths[i] == dest) {\n        length = paths[i];\n        break;\n      }\n    }\n  }\n  int result;\n  MPI_Reduce(&length, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "int result = 0;\n\tMPI_Reduce(result, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\treturn result;\n}",
            "if (source == dest) return 0;\n  std::vector<int> next(N);\n  next[source] = 1;\n  for (size_t i = 0; i < N; ++i) {\n    for (size_t j = 0; j < N; ++j) {\n      if (A[i*N + j] == 1 && next[i]!= 0) {\n        next[j] = std::max(next[i], next[j]);\n      }\n    }\n  }\n  return next[dest];\n}",
            "// TODO: Your code here\n    MPI_Status status;\n    int size;\n    int rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    std::vector<int> a(N * N);\n    std::vector<int> a_result(N * N);\n    MPI_Request reqs[2];\n\n    if (size > N) {\n        MPI_Abort(MPI_COMM_WORLD, -1);\n    }\n\n    int chunk = N / size;\n    int remainder = N % size;\n    int start, end;\n    if (rank < remainder) {\n        start = chunk * rank + rank;\n        end = chunk * (rank + 1) + rank + 1;\n    } else {\n        start = chunk * rank + remainder;\n        end = chunk * (rank + 1) + remainder;\n    }\n\n    for (int i = 0; i < N * N; i++) {\n        if (i >= start && i < end) {\n            a[i] = A[i];\n        }\n    }\n\n    if (rank == 0) {\n        for (int i = 1; i < size; i++) {\n            MPI_Irecv(&a[i * N], N, MPI_INT, i, 0, MPI_COMM_WORLD, &reqs[0]);\n            MPI_Isend(&a[0], N, MPI_INT, i, 0, MPI_COMM_WORLD, &reqs[1]);\n        }\n    } else {\n        MPI_Send(&a[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n        MPI_Recv(&a[0], N, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    }\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (i == 0) {\n                a_result[i * N + j] = a[j];\n            } else if (j == 0) {\n                a_result[i * N + j] = a[i];\n            } else {\n                a_result[i * N + j] = a[i] + a[j];\n            }\n        }\n    }\n\n    if (rank == 0) {\n        int ans = std::numeric_limits<int>::max();\n        for (int i = 0; i < N; i++) {\n            if (a_result[dest * N + i] == 0) {\n                ans = 0;\n                break;\n            } else if (a_result[source * N + i] + a_result[i * N + dest] == 0) {\n                ans = 2;\n                break;\n            } else if (a_result[source * N + i] + a_result[i * N + dest] < ans) {\n                ans = a_result[source * N + i] + a_result[i * N + dest];\n            }\n        }\n        return ans;\n    } else {\n        MPI_Send(&a_result[0], N * N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n        MPI_Recv(&a_result[0], N * N, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n    }\n\n    int ans = std::numeric_limits<int>::max();\n    for (int i = 0; i < N; i++) {\n        if (a_result[dest * N + i] == 0) {\n            ans = 0;\n            break;\n        } else if (a_result[source * N + i] + a_result[i * N + dest] == 0) {\n            ans = 2;\n            break;\n        } else if (a_result[source * N + i] + a_result[i * N + dest] < ans) {\n            ans = a_result[source * N",
            "int length;\n\n  // rank 0 computes the shortest path length\n  if (source == dest) {\n    length = 0;\n  }\n  else {\n    length = A.at(source*N + dest);\n  }\n\n  // Send the shortest path length to rank 0\n  if (length!= 0) {\n    MPI_Send(&length, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n  }\n\n  // Receive the shortest path length from rank 0\n  if (source == dest) {\n    MPI_Recv(&length, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n\n  return length;\n}",
            "// TODO: complete this function\n\tstd::vector<int> d(N, INT_MAX);\n\tstd::vector<int> p(N, -1);\n\td[source] = 0;\n\tstd::queue<int> q;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v] == 0 || d[v]!= INT_MAX) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\td[v] = d[u] + 1;\n\t\t\tq.push(v);\n\t\t\tp[v] = u;\n\t\t}\n\t}\n\treturn d[dest];\n}",
            "// TODO: implement\n}",
            "int length = 0;\n\n  /* TODO: Implement */\n\n  return length;\n}",
            "// TODO: Your code here\n  return -1;\n}",
            "// Your code goes here.\n  int l=0;\n  int k=0;\n  int * d=new int[N];\n  int * s=new int[N];\n  int * d_new=new int[N];\n  for(int i=0;i<N;i++)\n  {\n    d[i]=INT_MAX;\n    s[i]=0;\n    d_new[i]=INT_MAX;\n  }\n  d[source]=0;\n  k=1;\n  while(k>0)\n  {\n    k=0;\n    for(int i=0;i<N;i++)\n    {\n      for(int j=0;j<N;j++)\n      {\n        if(A[i*N+j]==1)\n        {\n          if(d[i]+1<d[j])\n          {\n            d[j]=d[i]+1;\n            k=1;\n          }\n        }\n      }\n    }\n  }\n  for(int i=0;i<N;i++)\n  {\n    if(d[i]<d_new[i])\n      d_new[i]=d[i];\n  }\n  l=d_new[dest];\n  delete[] d;\n  delete[] s;\n  delete[] d_new;\n  return l;\n}",
            "int distance[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tdistance[i] = -1;\n\t}\n\n\tfor (int i = 0; i < N; i++) {\n\t\tdistance[source] = 0;\n\t\t\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (distance[j]!= -1 && A[source * N + j] == 1) {\n\t\t\t\tdistance[j] += 1;\n\t\t\t}\n\t\t}\n\t}\n\t\n\treturn distance[dest];\n}",
            "return -1;\n}",
            "// Your code here\n\treturn 0;\n}",
            "/*\n     * YOUR CODE HERE\n     */\n}",
            "// your code here\n}",
            "// TODO: Your code here\n    int path_length = INT_MAX;\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    for (int i = 0; i < N; i++) {\n        if (rank == i) {\n            std::vector<int> path_lengths(N, INT_MAX);\n            std::queue<int> to_visit;\n            std::set<int> visited;\n            to_visit.push(source);\n            visited.insert(source);\n            path_lengths[source] = 0;\n            while (!to_visit.empty()) {\n                int curr = to_visit.front();\n                to_visit.pop();\n                for (int j = 0; j < N; j++) {\n                    if (A[curr * N + j] == 1 && visited.find(j) == visited.end()) {\n                        visited.insert(j);\n                        to_visit.push(j);\n                        path_lengths[j] = std::min(path_lengths[j], path_lengths[curr] + 1);\n                    }\n                }\n            }\n            path_length = std::min(path_length, path_lengths[dest]);\n        }\n    }\n    int result;\n    MPI_Reduce(&path_length, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    return result;\n}",
            "int l = 0; // shortest length\n  std::vector<int> s; // visited\n  s.resize(N);\n  for(size_t i = 0; i < N; i++)\n    s[i] = 0;\n  s[source] = 1;\n  int f = 1;\n  int i = 0;\n  while(f) {\n    int fp = 0;\n    for(size_t j = 0; j < N; j++) {\n      if(s[j] && A[i*N+j]==1) {\n        s[j] = 2;\n        fp++;\n      }\n    }\n    if(fp)\n      l++;\n    else\n      f = 0;\n    i++;\n  }\n  if(s[dest])\n    return l;\n  else\n    return -1;\n}",
            "// TODO\n}",
            "/* Your code here */\n\n\n\treturn 0;\n}",
            "// You need to complete this function\n}",
            "// TODO: Your code here\n    std::vector<int> dist(N,INT_MAX);\n    dist[source]=0;\n    int count=0,active=0;\n    while(active){\n        active=0;\n        for (int i=0;i<N;i++){\n            for (int j=0;j<N;j++){\n                if (A[i*N+j] && dist[i]!= INT_MAX && dist[i]+1 < dist[j]){\n                    dist[j]=dist[i]+1;\n                    active=1;\n                }\n            }\n        }\n        count++;\n    }\n    return dist[dest];\n}",
            "int length = 0;\n    int count = 0;\n    std::vector<int> visited(N, 0);\n\n    std::queue<int> q;\n    q.push(source);\n\n    while (!q.empty() &&!visited[dest]) {\n        int current = q.front();\n        q.pop();\n        count++;\n        if (current == dest) {\n            return length;\n        }\n        for (size_t i = 0; i < N; ++i) {\n            if (A[current * N + i] &&!visited[i]) {\n                q.push(i);\n                visited[i] = 1;\n            }\n        }\n        length++;\n    }\n    if (visited[dest]) {\n        return length - 1;\n    }\n    return -1;\n}",
            "// TODO\n}",
            "// Your code goes here.\n}",
            "int rank, size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tstd::vector<int> distances;\n\n\tint sourceRank = source / N * size + rank;\n\tint destRank = dest / N * size + rank;\n\tif (rank == 0) {\n\t\tdistances = A;\n\t\tdistances[source] = 0;\n\t\tstd::queue<int> queue;\n\t\tqueue.push(source);\n\n\t\twhile (!queue.empty()) {\n\t\t\tint vertex = queue.front();\n\t\t\tqueue.pop();\n\n\t\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\t\tif (A[vertex * N + i]) {\n\t\t\t\t\tint newDistance = distances[vertex] + 1;\n\t\t\t\t\tif (newDistance < distances[i * N + vertex]) {\n\t\t\t\t\t\tdistances[i * N + vertex] = newDistance;\n\t\t\t\t\t\tqueue.push(i);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tstd::vector<int> receivedDistances(N * N);\n\t\tMPI_Bcast(receivedDistances.data(), N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\t\tdistances = receivedDistances;\n\t}\n\n\tMPI_Reduce(&distances[destRank], NULL, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\tint distance = INT_MAX;\n\tif (rank == 0)\n\t\tdistance = distances[destRank];\n\n\treturn distance;\n}",
            "int length = 0;\n    // your code goes here\n    return length;\n}",
            "// Your code here\n\treturn -1;\n}",
            "return 0;\n}",
            "if (N == 0 || N == 1) return 0;\n  // TODO\n}",
            "// your code here\n\treturn -1;\n}",
            "}",
            "// TODO: Your code here\n  return 0;\n}",
            "// Add your code here!\n\tint ret = -1;\n\treturn ret;\n}",
            "if (source == dest)\n        return 0;\n\n    std::vector<int> predecessors(N, -1);\n    std::vector<int> dist(N, INT_MAX);\n    std::vector<int> processed(N, 0);\n    std::vector<int> min_dist(1, INT_MAX);\n\n    int my_rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    int world_size;\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\n    dist[source] = 0;\n\n    for (int i = 0; i < N; i++) {\n        if (my_rank == 0) {\n            for (int j = 0; j < N; j++)\n                if (A[i * N + j]!= 0)\n                    dist[j] = std::min(dist[j], dist[i] + 1);\n        }\n        MPI_Bcast(&dist[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n        int min_idx;\n        if (my_rank == 0) {\n            int local_min = INT_MAX;\n            for (int j = 0; j < N; j++)\n                if (dist[j] < local_min) {\n                    local_min = dist[j];\n                    min_idx = j;\n                }\n            min_dist[0] = local_min;\n        }\n\n        MPI_Bcast(&min_dist[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n        if (my_rank == 0) {\n            for (int j = 0; j < N; j++)\n                if (dist[j] == min_dist[0]) {\n                    processed[j] = 1;\n                    for (int k = 0; k < N; k++)\n                        if (A[j * N + k]!= 0)\n                            dist[k] = std::min(dist[k], dist[j] + 1);\n                }\n        }\n    }\n\n    return dist[dest];\n}",
            "int distance = -1;\n    std::vector<int> distance_array(N, 1000);\n    distance_array[source] = 0;\n\n    for (int i = 0; i < N; i++) {\n        int min_distance = 1000;\n        int min_vertex = -1;\n        for (int j = 0; j < N; j++) {\n            if (distance_array[j] < min_distance && A[i*N+j] > 0) {\n                min_distance = distance_array[j];\n                min_vertex = j;\n            }\n        }\n\n        distance_array[min_vertex] = 1000;\n        for (int j = 0; j < N; j++) {\n            if (A[min_vertex*N+j] > 0) {\n                if (distance_array[j] > min_distance+1) {\n                    distance_array[j] = min_distance+1;\n                }\n            }\n        }\n\n        if (min_vertex == dest) {\n            distance = distance_array[min_vertex];\n            break;\n        }\n    }\n\n    return distance;\n}",
            "int* distances = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (i == source) {\n\t\t\tdistances[i] = 0;\n\t\t}\n\t\telse {\n\t\t\tdistances[i] = INT_MAX;\n\t\t}\n\t}\n\n\tstd::queue<int> q;\n\tq.push(source);\n\tdistances[source] = 0;\n\n\twhile (!q.empty()) {\n\t\tint currentVertex = q.front();\n\t\tq.pop();\n\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[currentVertex*N + j] == 1) {\n\t\t\t\tif (distances[j] > distances[currentVertex] + 1) {\n\t\t\t\t\tdistances[j] = distances[currentVertex] + 1;\n\t\t\t\t\tq.push(j);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint shortestPathLength = distances[dest];\n\tdelete[] distances;\n\n\treturn shortestPathLength;\n}",
            "assert(source >= 0 && source < N);\n  assert(dest >= 0 && dest < N);\n\n  // TODO: implement this function\n\n  return -1;\n}",
            "// Your code here\n    return 0;\n}",
            "//\n  // Write your solution here\n  //\n}",
            "int path = -1;\n\n  // TODO: Your code here\n\n  return path;\n}",
            "int count = 0;\n    int num_proc;\n    int rank;\n    int root = 0;\n    int sum;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    std::vector<int> dist(N);\n    std::vector<bool> visited(N);\n    std::vector<int> parent(N);\n    dist.assign(N, INT_MAX);\n    dist[source] = 0;\n    visited[source] = true;\n    parent[source] = -1;\n\n    for (int count = 0; count < N; ++count) {\n        for (int i = 0; i < N; ++i) {\n            for (int j = 0; j < N; ++j) {\n                if (A[i*N + j]!= 0 && dist[i]!= INT_MAX && dist[i] + 1 < dist[j]) {\n                    dist[j] = dist[i] + 1;\n                    parent[j] = i;\n                }\n            }\n        }\n    }\n\n    if (rank == 0) {\n        for (int i = 0; i < N; ++i) {\n            if (i == source) continue;\n            if (dist[i]!= INT_MAX) {\n                printf(\"i = %d, parent = %d, dist = %d\\n\", i, parent[i], dist[i]);\n            }\n        }\n        int sum = 0;\n        for (int i = 0; i < N; ++i) {\n            if (i == source) continue;\n            if (dist[i]!= INT_MAX) {\n                sum = sum + dist[i];\n            }\n        }\n        return sum;\n    }\n    return 0;\n}",
            "/* your code goes here */\n}",
            "// TODO\n\treturn 0;\n}",
            "int rank;\n  int procs;\n\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &procs);\n\n  int shortestPath = INT_MAX;\n  int localShortestPath = INT_MAX;\n\n  std::vector<int> frontier, nextFrontier;\n  frontier.push_back(source);\n\n  int localPathLength = 0;\n  while (!frontier.empty() && localPathLength < shortestPath) {\n    for (int v : frontier) {\n      if (v == dest) {\n        localShortestPath = std::min(localShortestPath, localPathLength);\n        continue;\n      }\n      for (int u = 0; u < N; u++) {\n        if (A[v*N + u] == 1 && std::find(nextFrontier.begin(), nextFrontier.end(), u) == nextFrontier.end()) {\n          nextFrontier.push_back(u);\n        }\n      }\n    }\n    frontier = nextFrontier;\n    nextFrontier.clear();\n    localPathLength++;\n  }\n\n  MPI_Reduce(&localShortestPath, &shortestPath, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n  return shortestPath;\n}",
            "// TO DO\n}",
            "/* TODO */\n    return 0;\n}",
            "int ret = -1;\n  MPI_Reduce(&ret, &ret, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n  return ret;\n}",
            "int rank = 0, size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    //...\n}",
            "std::vector<int> dist(N, INT_MAX);\n    std::vector<bool> visited(N, false);\n    std::vector<int> prev(N, -1);\n\n    dist[source] = 0;\n    visited[source] = true;\n\n    for (int i = 0; i < N; ++i) {\n        int u = -1;\n        int min_dist = INT_MAX;\n        for (int v = 0; v < N; ++v) {\n            if (!visited[v] && dist[v] < min_dist) {\n                u = v;\n                min_dist = dist[v];\n            }\n        }\n\n        if (u == -1) {\n            break;\n        }\n\n        visited[u] = true;\n\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] && dist[u]!= INT_MAX && dist[u] + 1 < dist[v]) {\n                dist[v] = dist[u] + 1;\n                prev[v] = u;\n            }\n        }\n    }\n\n    std::vector<int> path;\n    int v = dest;\n    while (prev[v]!= -1) {\n        path.push_back(v);\n        v = prev[v];\n    }\n    path.push_back(source);\n    std::reverse(path.begin(), path.end());\n    return path.size() - 1;\n}",
            "// write your code here\n}",
            "// your code here\n}",
            "// Your code here\n\n    int* dist = new int[N];\n    for (int i = 0; i < N; i++) {\n        dist[i] = A[source*N+i];\n    }\n\n    for (int k = 0; k < N; k++) {\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                int cur_dist = dist[i] + A[i*N+k] + A[k*N+j];\n                if (cur_dist < dist[j]) {\n                    dist[j] = cur_dist;\n                }\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "int local_source = source;\n  int local_dest = dest;\n\n  int *distance = new int[N];\n  int *predecessor = new int[N];\n\n  for (int i = 0; i < N; i++) {\n    distance[i] = INT_MAX;\n    predecessor[i] = -1;\n  }\n\n  distance[source] = 0;\n\n  // use the Bellman-Ford algorithm to find the shortest distance from source to any node\n  for (int i = 0; i < N - 1; i++) {\n    for (int j = 0; j < N; j++) {\n      for (int k = 0; k < N; k++) {\n        if (distance[j]!= INT_MAX && A[j*N+k]!= 0 && distance[j]+A[j*N+k] < distance[k]) {\n          distance[k] = distance[j] + A[j*N+k];\n          predecessor[k] = j;\n        }\n      }\n    }\n  }\n\n  int shortest_distance = distance[local_dest];\n  int predecessor_value = predecessor[local_dest];\n\n  // use the predecessor array to find the shortest path from source to dest\n  while (predecessor_value!= -1) {\n    predecessor_value = predecessor[predecessor_value];\n    shortest_distance++;\n  }\n\n  return shortest_distance;\n}",
            "std::vector<bool> visited(N, false);\n    std::queue<int> q;\n    std::vector<int> d(N, -1);\n    q.push(source);\n    d[source] = 0;\n    visited[source] = true;\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        for (int v = 0; v < N; ++v) {\n            if (A[u * N + v] &&!visited[v]) {\n                q.push(v);\n                d[v] = d[u] + 1;\n                visited[v] = true;\n            }\n        }\n    }\n    return d[dest];\n}",
            "// TODO\n    return 0;\n}",
            "int num_procs, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  std::vector<int> lengths(N, std::numeric_limits<int>::max());\n  std::vector<int> sources(N, -1);\n  std::vector<bool> visited(N, false);\n  std::vector<bool> in_queue(N, false);\n  std::vector<int> parent(N, -1);\n  std::queue<int> q;\n  q.push(source);\n  lengths[source] = 0;\n  in_queue[source] = true;\n  while (!q.empty()) {\n    int u = q.front();\n    q.pop();\n    visited[u] = true;\n    in_queue[u] = false;\n    for (int v = 0; v < N; ++v) {\n      if (A[u * N + v] &&!visited[v]) {\n        lengths[v] = lengths[u] + 1;\n        parent[v] = u;\n        q.push(v);\n        in_queue[v] = true;\n      }\n    }\n  }\n  for (int u = 0; u < N; ++u) {\n    if (lengths[u]!= std::numeric_limits<int>::max()) {\n      for (int v = 0; v < N; ++v) {\n        if (lengths[v] > lengths[u] + 1) {\n          lengths[v] = lengths[u] + 1;\n          parent[v] = u;\n        }\n      }\n    }\n  }\n  std::vector<int> result(num_procs);\n  MPI_Gather(&lengths[dest], 1, MPI_INT, &result[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n  if (rank == 0) {\n    int ans = result[0];\n    for (int i = 1; i < num_procs; ++i) {\n      ans = std::min(ans, result[i]);\n    }\n    return ans;\n  }\n  return 0;\n}",
            "std::vector<int> minPath(N, -1);\n  minPath[source] = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (minPath[j] == -1) {\n        continue;\n      }\n      if (A[j * N + i] == 0) {\n        continue;\n      }\n\n      if (minPath[i] == -1 || minPath[i] > minPath[j] + 1) {\n        minPath[i] = minPath[j] + 1;\n      }\n    }\n  }\n\n  return minPath[dest];\n}",
            "int length=INT_MAX;\n\tint distance[N];\n\n\tint max_rank=0;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &max_rank);\n\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint *receive=new int[size];\n\tint *receive2=new int[size];\n\n\tif (rank==0) {\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tdistance[i]=INT_MAX;\n\t\t}\n\t\tdistance[source]=0;\n\t}\n\n\tMPI_Bcast(&distance[0], N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tfor (int i=0; i<N; i++) {\n\t\tfor (int j=0; j<N; j++) {\n\t\t\tif (A[i*N+j]==1) {\n\t\t\t\tif (distance[i]!=INT_MAX) {\n\t\t\t\t\tdistance[j]=std::min(distance[j],distance[i]+1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tMPI_Gather(&distance[0], N, MPI_INT, receive, N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank==0) {\n\t\tfor (int i=0; i<size; i++) {\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\treceive2[j]=std::min(receive2[j],receive[i][j]);\n\t\t\t}\n\t\t}\n\t\tlength=receive2[dest];\n\t}\n\n\tdelete [] receive;\n\tdelete [] receive2;\n\treturn length;\n}",
            "// TODO: replace this code with a correct implementation\n\n\t// TODO: return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n\n\treturn 0;\n}",
            "int pathLength = 0;\n\n\t// TODO: fill this in\n\n\treturn pathLength;\n}",
            "}",
            "const int inf = 100000;\n\tint length[N];\n\tfor (int i = 0; i < N; i++)\n\t\tlength[i] = inf;\n\tlength[source] = 0;\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (length[i] < inf && A[i * N + j] > 0) {\n\t\t\t\t\tif (length[j] > length[i] + A[i * N + j])\n\t\t\t\t\t\tlength[j] = length[i] + A[i * N + j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn length[dest];\n}",
            "/*... */\n}",
            "// TODO: Your code here\n  std::vector<std::vector<int>> table(N, std::vector<int>(N, INT_MAX));\n  for (int i = 0; i < N; ++i)\n    table[i][i] = 0;\n\n  int count = 0;\n  for (int i = 0; i < N; ++i) {\n    if (A[source * N + i] == 1) {\n      table[source][i] = 1;\n    }\n  }\n\n  for (int step = 1; step < N; ++step) {\n    for (int i = 0; i < N; ++i) {\n      for (int j = 0; j < N; ++j) {\n        if (table[i][j] == INT_MAX && table[i][step] < INT_MAX && table[step][j] < INT_MAX) {\n          table[i][j] = table[i][step] + table[step][j];\n        }\n      }\n    }\n  }\n\n  return table[source][dest];\n}",
            "int num_nodes = N;\n\n  int* visited = new int[num_nodes];\n  int* path = new int[num_nodes];\n\n  for (int i = 0; i < num_nodes; i++) {\n    visited[i] = 0;\n    path[i] = -1;\n  }\n\n  for (int i = 0; i < num_nodes; i++) {\n    if (i == source) {\n      path[i] = 0;\n    }\n  }\n\n  for (int i = 0; i < num_nodes; i++) {\n    int v = -1;\n    for (int j = 0; j < num_nodes; j++) {\n      if ((!visited[j]) && (path[j] >= 0)) {\n        if (v == -1 || path[j] < path[v]) {\n          v = j;\n        }\n      }\n    }\n\n    if (v == -1)\n      break;\n\n    visited[v] = 1;\n    int val = 0;\n    if (A[v * num_nodes + v] == 1) {\n      val = path[v] + 1;\n    } else {\n      val = path[v];\n    }\n    for (int j = 0; j < num_nodes; j++) {\n      if (A[v * num_nodes + j] == 1) {\n        if (path[j] < 0 || path[j] > val) {\n          path[j] = val;\n        }\n      }\n    }\n  }\n  return path[dest];\n}",
            "std::vector<int> dist(N, -1);\n\tstd::vector<int> p(N, -1);\n\tstd::vector<int> queue(N);\n\tint front = 0, rear = 0, size = 0;\n\tdist[source] = 0;\n\tqueue[rear++] = source;\n\tsize++;\n\twhile (front!= rear) {\n\t\tint u = queue[front++];\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v]!= 0 && dist[v] < 0) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tp[v] = u;\n\t\t\t\tqueue[rear++] = v;\n\t\t\t\tsize++;\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> path(N, -1);\n\tint curr = dest;\n\tint path_size = 0;\n\twhile (curr!= source) {\n\t\tpath[path_size++] = curr;\n\t\tcurr = p[curr];\n\t}\n\tpath[path_size++] = source;\n\treturn path_size - 1;\n}",
            "MPI_Status status;\n\tint num_ranks, rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n\tint *A_buf = new int[N * N];\n\tint *send_buf = new int[N * N];\n\tint *recv_buf = new int[N * N];\n\tstd::copy(A.begin(), A.end(), A_buf);\n\n\tif (num_ranks == 1) {\n\t\treturn 0;\n\t}\n\n\tint *dis = new int[N];\n\tint *pred = new int[N];\n\tstd::fill(dis, dis + N, INT_MAX);\n\tstd::fill(pred, pred + N, -1);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tdis[i] = A_buf[i * N + source];\n\t}\n\tint min_dis = INT_MAX;\n\tint min_index = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (dis[i] < min_dis) {\n\t\t\tmin_dis = dis[i];\n\t\t\tmin_index = i;\n\t\t}\n\t}\n\tpred[source] = -2;\n\twhile (min_index!= -1) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A_buf[min_index * N + i] == 1) {\n\t\t\t\tif (dis[i] > dis[min_index] + 1) {\n\t\t\t\t\tdis[i] = dis[min_index] + 1;\n\t\t\t\t\tpred[i] = min_index;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tmin_dis = INT_MAX;\n\t\tmin_index = -1;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (dis[i] < min_dis) {\n\t\t\t\tmin_dis = dis[i];\n\t\t\t\tmin_index = i;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (rank == 0) {\n\t\treturn dis[dest];\n\t}\n\telse {\n\t\tstd::copy(A_buf, A_buf + N * N, send_buf);\n\t\tMPI_Send(send_buf, N * N, MPI_INT, 0, 1, MPI_COMM_WORLD);\n\t}\n\n\tif (rank == 0) {\n\t\tfor (int i = 1; i < num_ranks; i++) {\n\t\t\tMPI_Recv(recv_buf, N * N, MPI_INT, i, 1, MPI_COMM_WORLD, &status);\n\t\t\tfor (int j = 0; j < N * N; j++) {\n\t\t\t\tif (send_buf[j] > recv_buf[j]) {\n\t\t\t\t\tsend_buf[j] = recv_buf[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint min_dis = INT_MAX;\n\t\tint min_index = -1;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (send_buf[i * N + dest] < min_dis) {\n\t\t\t\tmin_dis = send_buf[i * N + dest];\n\t\t\t\tmin_index = i;\n\t\t\t}\n\t\t}\n\t\tint dis = 0;\n\t\twhile (min_index!= -2) {\n\t\t\tdis++;\n\t\t\tmin_index = pred[min_index];\n\t\t}\n\t\treturn dis;\n\t}\n\n\treturn 0;\n}",
            "int myPathLength = 0;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tmyPathLength = std::min(myPathLength, A[source * N + i] + A[i * N + dest]);\n\t}\n\n\tint minPathLength;\n\tMPI_Reduce(&myPathLength, &minPathLength, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n\treturn minPathLength;\n}",
            "// TODO\n\treturn 0;\n}",
            "// TODO: replace with your code\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    std::vector<int> local_A(A.begin() + (size * rank) / N, A.begin() + (size * (rank + 1)) / N);\n\n    std::vector<int> length(local_A.size());\n    for (size_t i = 0; i < local_A.size(); i++) {\n        length[i] = -1;\n    }\n\n    length[source] = 0;\n    bool done = false;\n    while (!done) {\n        MPI_Request request[local_A.size()];\n        MPI_Status status[local_A.size()];\n        done = true;\n        for (size_t i = 0; i < local_A.size(); i++) {\n            for (size_t j = 0; j < local_A.size(); j++) {\n                if (local_A[i][j] == 1 && length[i]!= -1 && length[j] == -1) {\n                    length[j] = length[i] + 1;\n                    done = false;\n                    MPI_Send(length.data(), local_A.size(), MPI_INT, j, 0, MPI_COMM_WORLD);\n                }\n            }\n        }\n        MPI_Waitall(local_A.size(), request, status);\n    }\n\n    if (rank == 0) {\n        return length[dest];\n    }\n\n    return -1;\n}",
            "// your code here\n\t// The number of processes \n    int n = A.size();\n    // The rank of the process \n    int rank;\n    // The total number of processes \n    int p;\n\n    // Finding total number of processes \n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n\n    // Finding the rank of the process \n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    std::vector<int> local_A;\n    std::vector<int> local_A_out;\n    int local_size = n / p;\n    int start = rank * local_size;\n    int end = (rank + 1) * local_size;\n    for (int i = start; i < end; i++) {\n        for (int j = 0; j < n; j++) {\n            local_A.push_back(A[i * n + j]);\n        }\n    }\n\n    int local_dest = dest / local_size;\n    if (rank == 0) {\n        for (int i = 0; i < local_size; i++) {\n            local_A_out.push_back(0);\n        }\n    }\n\n    // if (rank == 0) {\n    //     for (int i = 0; i < local_size; i++) {\n    //         std::cout << local_A_out[i] << \" \";\n    //     }\n    //     std::cout << std::endl;\n    // }\n\n    int local_source = source / local_size;\n\n    if (rank == 0) {\n        for (int i = 0; i < local_size; i++) {\n            local_A_out[i] = local_A[i * n + local_dest];\n        }\n    }\n    // if (rank == 0) {\n    //     for (int i = 0; i < local_size; i++) {\n    //         std::cout << local_A_out[i] << \" \";\n    //     }\n    //     std::cout << std::endl;\n    // }\n\n    int local_result = 10000;\n    int final_result = 10000;\n    if (rank == 0) {\n        local_result = local_A_out[local_source];\n        for (int i = 1; i < p; i++) {\n            MPI_Status status;\n            MPI_Recv(&local_result, 1, MPI_INT, i, 1, MPI_COMM_WORLD, &status);\n            if (local_result < final_result) {\n                final_result = local_result;\n            }\n        }\n    } else {\n        MPI_Send(&local_result, 1, MPI_INT, 0, 1, MPI_COMM_WORLD);\n    }\n\n    MPI_Barrier(MPI_COMM_WORLD);\n\n    return final_result;\n}",
            "return 0;\n}",
            "int rank, size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tint local_source = source;\n\tint local_dest = dest;\n\n\tif (A.size() == 1) {\n\t\treturn A[0];\n\t}\n\n\tint local_length = 0;\n\t\n\tfor (int i = 0; i < N; i++) {\n\t\tlocal_length += A[source * N + i];\n\t}\n\n\tMPI_Bcast(&local_length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\twhile (local_source!= local_dest) {\n\t\tlocal_length++;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[local_source * N + i] == 1) {\n\t\t\t\tlocal_source = i;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tMPI_Bcast(&local_source, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\t}\n\treturn local_length;\n}",
            "// TODO: Your code here\n    return 0;\n}",
            "// Implement this function.\n\tint* dist = (int*)malloc(N*sizeof(int));\n\tint* temp = (int*)malloc(N*sizeof(int));\n\tint* visited = (int*)malloc(N*sizeof(int));\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint i;\n\tint min = 10000;\n\tif (source == dest) {\n\t\treturn 0;\n\t}\n\tif (A[source*N + dest] == 1) {\n\t\treturn 1;\n\t}\n\n\tfor (i = 0; i < N; i++) {\n\t\tdist[i] = A[source*N + i];\n\t\tvisited[i] = 0;\n\t}\n\tvisited[source] = 1;\n\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tif (visited[i] == 0) {\n\t\t\t\ttemp[i] = 10000;\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (visited[j] == 1 && A[j*N + i] == 1) {\n\t\t\t\t\t\ttemp[i] = min(dist[j] + 1, temp[i]);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (i = 0; i < N; i++) {\n\t\t\tdist[i] = temp[i];\n\t\t\tvisited[i] = 1;\n\t\t}\n\t}\n\n\tfor (i = 0; i < N; i++) {\n\t\tif (dist[i]!= 10000) {\n\t\t\tmin = min(min, dist[i]);\n\t\t}\n\t}\n\n\treturn min;\n}",
            "std::vector<int> visited(N);\n  std::vector<int> distances(N, INT_MAX);\n  std::vector<int> parents(N, -1);\n\n  // initialize the starting point\n  visited[source] = 1;\n  distances[source] = 0;\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      if (A[i * N + j] == 1 && visited[j] == 0) {\n        visited[j] = 1;\n        distances[j] = distances[i] + 1;\n        parents[j] = i;\n      }\n    }\n  }\n  return distances[dest];\n}",
            "// Implement me!\n}",
            "// TODO: add code here\n\t//\n\t// Assume MPI has been initialized.\n\t// A is an NxN adjacency matrix stored in row-major.\n\t//\n\t// Rank 0 has a complete copy of A.\n\t// Rank 0 returns the length of the shortest path from source to dest in A.\n\t// Use MPI to compute in parallel.\n\t//\n\t// Every rank has a complete copy of A.\n\t//\n\t// Example:\n\t//\n\t//  input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n\t//  output: 2\n\t//\n\n    return 0;\n}",
            "int rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Request req[2];\n\tMPI_Status status[2];\n\tint left_dest, right_dest;\n\tleft_dest = left_neighbor(rank, size);\n\tright_dest = right_neighbor(rank, size);\n\n\tif (rank == 0) {\n\t\tMPI_Send(&A[0], N*N, MPI_INT, right_dest, 0, MPI_COMM_WORLD);\n\t} else if (rank == size - 1) {\n\t\tMPI_Send(&A[0], N*N, MPI_INT, left_dest, 0, MPI_COMM_WORLD);\n\t} else {\n\t\tMPI_Sendrecv(&A[0], N*N, MPI_INT, right_dest, 0, &A[0], N*N, MPI_INT, left_dest, 0, MPI_COMM_WORLD, &status[0]);\n\t\tMPI_Sendrecv(&A[0], N*N, MPI_INT, left_dest, 0, &A[0], N*N, MPI_INT, right_dest, 0, MPI_COMM_WORLD, &status[1]);\n\t}\n\n\t// Compute the shortest path length for each node using Floyd-Warshall.\n\t// (You can write this recursively or iteratively.)\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N+j] > A[i*N+k] + A[k*N+j])\n\t\t\t\t\tA[i*N+j] = A[i*N+k] + A[k*N+j];\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Use this to return the answer on rank 0.\n\tint shortest_path_length = A[source*N + dest];\n\tMPI_Reduce(&shortest_path_length, NULL, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n\treturn 0;\n}",
            "int length = -1;\n\t// TODO: implement me\n\treturn length;\n}",
            "int rank, size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\t// TODO\n\treturn 0;\n}",
            "// Your code here.\n}",
            "return 0;\n}",
            "int local_source = source;\n  int local_dest = dest;\n\n  std::vector<int> distance(N, -1);\n  distance[source] = 0;\n\n  for (size_t i = 0; i < N; i++) {\n    for (size_t j = 0; j < N; j++) {\n      if (distance[j]!= -1) {\n        for (size_t k = 0; k < N; k++) {\n          if (A[j*N + k]!= 0 && distance[k] == -1) {\n            distance[k] = distance[j] + 1;\n          }\n        }\n      }\n    }\n  }\n\n  return distance[dest];\n}",
            "int* distances = new int[N];\n    std::fill(distances, distances + N, INT_MAX);\n    distances[source] = 0;\n\n    std::vector<int> updated(N);\n    MPI_Request requests[N];\n    MPI_Status statuses[N];\n\n    int nProcs, rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &nProcs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int updated_count = 0;\n    int rank_from, rank_to;\n    while (true) {\n        // Distribute updates among ranks\n        if (rank == 0) {\n            for (int i = 0; i < N; ++i) {\n                updated[i] = updated_count == 0? 0 : (distances[i]!= INT_MAX);\n            }\n            for (int r = 1; r < nProcs; ++r) {\n                MPI_Isend(updated.data(), N, MPI_INT, r, 0, MPI_COMM_WORLD, &requests[r]);\n            }\n        }\n        // Receive updates\n        if (rank > 0) {\n            MPI_Recv(updated.data(), N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        }\n        // Compute path lengths\n        int proc_count = 0;\n        for (int r = 0; r < nProcs; ++r) {\n            if (rank == r) {\n                rank_from = rank_to = r;\n                if (r > 0) {\n                    MPI_Wait(&requests[r], MPI_STATUS_IGNORE);\n                }\n            }\n            else if (updated[r]) {\n                ++proc_count;\n                rank_from = r;\n            }\n            else if (updated[rank]) {\n                ++proc_count;\n                rank_to = r;\n            }\n            if (proc_count == 2) {\n                for (int i = 0; i < N; ++i) {\n                    if (distances[i]!= INT_MAX && A[rank_from * N + i]!= 0) {\n                        distances[i] = std::min(distances[i], distances[rank_from] + A[rank_from * N + i]);\n                    }\n                }\n                updated_count += 1;\n                proc_count = 0;\n            }\n        }\n        // Check if we are done\n        if (updated_count == nProcs) {\n            break;\n        }\n    }\n    // Return the result\n    int result = INT_MAX;\n    if (rank == 0) {\n        for (int i = 0; i < N; ++i) {\n            result = std::min(result, distances[i]);\n        }\n    }\n    MPI_Bcast(&result, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    return result;\n}",
            "int ret;\n    MPI_Status status;\n    int* A_recv = new int[N];\n    int* A_send = new int[N];\n    for (size_t i = 0; i < N; i++) {\n        A_send[i] = A[i];\n    }\n    MPI_Bcast(A_send, N, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Reduce(&source, &ret, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    return ret;\n}",
            "// TODO\n\treturn -1;\n}",
            "int source_rank = source/N;\n  int dest_rank = dest/N;\n  int source_index = source % N;\n  int dest_index = dest % N;\n  int* data = &A[0];\n  if(source_rank==0 && dest_rank==0){\n    int* newdata = new int[N*N];\n    memcpy(newdata, data, N*N*sizeof(int));\n    data = newdata;\n  }\n  if(source_rank==0){\n    for(int i=0; i<N; i++){\n      for(int j=0; j<N; j++){\n\tMPI_Send(data+source_index*N+j, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n      }\n    }\n  }\n  if(dest_rank==0){\n    for(int i=0; i<N; i++){\n      for(int j=0; j<N; j++){\n\tMPI_Send(data+i*N+dest_index, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n      }\n    }\n  }\n  if(source_rank==dest_rank && source_rank==0){\n    return 0;\n  }\n  if(source_rank==dest_rank && source_rank==1){\n    for(int i=0; i<N; i++){\n      for(int j=0; j<N; j++){\n\tif(data[i*N+j]==1){\n\t  data[i*N+j]=data[dest_index*N+i]+1;\n\t}\n      }\n    }\n    return data[source_index*N+dest_index];\n  }\n  else{\n    int r = source_rank-dest_rank;\n    int l = dest_rank-source_rank;\n    if(source_rank > dest_rank){\n      r = source_rank-dest_rank;\n      l = dest_rank-source_rank;\n    }\n    if(r>0){\n      for(int i=0; i<N; i++){\n\tfor(int j=0; j<N; j++){\n\t  if(data[i*N+j]==1){\n\t    data[i*N+j]=data[dest_index*N+i]+1;\n\t  }\n\t}\n      }\n      for(int k=0; k<r; k++){\n\tint rdata[N*N];\n\tMPI_Recv(&rdata, N*N, MPI_INT, source_rank-k-1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\tfor(int i=0; i<N; i++){\n\t  for(int j=0; j<N; j++){\n\t    if(rdata[i*N+j]==1){\n\t      data[i*N+j]=data[j*N+i]+1;\n\t    }\n\t  }\n\t}\n      }\n      return data[source_index*N+dest_index];\n    }\n    else if(l>0){\n      for(int i=0; i<N; i++){\n\tfor(int j=0; j<N; j++){\n\t  if(data[i*N+j]==1){\n\t    data[i*N+j]=data[dest_index*N+i]+1;\n\t  }\n\t}\n      }\n      for(int k=0; k<l; k++){\n\tint ldata[N*N];\n\tMPI_Recv(&ldata, N*N, MPI_INT, source_rank+k+1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\tfor(int i=0; i<N; i++){\n\t  for(int j=0; j<N; j++){\n\t    if(ldata[i*N+j]==1){\n\t      data[i*N+j]=data[j*N+i]+1;\n\t    }\n\t  }\n\t}\n      }\n      return data[source_index*N+dest_index];",
            "// Implement this function\n    return 0;\n}",
            "// Fill in this function\n}",
            "int result;\n  MPI_Reduce(&result, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n  return result;\n}",
            "// Your code here.\n    int shortestPath = INT_MAX;\n\n    MPI_Datatype path_t;\n    MPI_Type_vector(N, 1, N, MPI_INT, &path_t);\n    MPI_Type_commit(&path_t);\n\n    MPI_Status status;\n    int *path = new int[N];\n\n    for (int i = 0; i < N; ++i)\n        path[i] = INT_MAX;\n    path[source] = 0;\n\n    MPI_Bcast(path, N, path_t, 0, MPI_COMM_WORLD);\n\n    for (int i = 0; i < N; ++i) {\n        int newPath = path[i] + 1;\n        int myDest = i;\n        MPI_Bcast(&myDest, 1, MPI_INT, i, MPI_COMM_WORLD);\n        if (myDest == dest) {\n            shortestPath = newPath;\n        }\n\n        MPI_Bcast(&path, N, path_t, i, MPI_COMM_WORLD);\n        MPI_Bcast(&newPath, 1, MPI_INT, i, MPI_COMM_WORLD);\n\n        for (int j = 0; j < N; ++j) {\n            if (A[i*N+j] && newPath < path[j]) {\n                path[j] = newPath;\n            }\n        }\n    }\n\n    delete[] path;\n\n    return shortestPath;\n}",
            "// TODO\n\n  return 0;\n}",
            "// TODO: Replace this code with a correct implementation\n    if (source == dest)\n    {\n        return 0;\n    }\n\n    std::vector<int> dist(N, -1);\n    dist[source] = 0;\n\n    for (int i = 0; i < N; ++i)\n    {\n        int u = -1;\n        for (int j = 0; j < N; ++j)\n        {\n            if (dist[j] >= 0 && (u < 0 || dist[j] < dist[u]))\n            {\n                u = j;\n            }\n        }\n\n        if (u < 0)\n        {\n            break;\n        }\n\n        for (int v = 0; v < N; ++v)\n        {\n            if (A[u * N + v] && dist[v] < 0)\n            {\n                dist[v] = dist[u] + 1;\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "// TODO\n\n  return -1;\n}",
            "std::queue<int> q;\n\tstd::vector<bool> visited(N, false);\n\n\tq.push(source);\n\tvisited[source] = true;\n\n\twhile (!q.empty()) {\n\t\tint v = q.front();\n\t\tq.pop();\n\n\t\tif (v == dest) {\n\t\t\treturn q.size();\n\t\t}\n\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (visited[i]) continue;\n\n\t\t\tif (A[N * v + i]) {\n\t\t\t\tq.push(i);\n\t\t\t\tvisited[i] = true;\n\t\t\t}\n\t\t}\n\t}\n\treturn -1;\n}",
            "// TODO\n}",
            "// 2-D array to hold the path lengths from source to all other nodes\n  std::vector<std::vector<int>> paths(N, std::vector<int>(N, std::numeric_limits<int>::max()));\n  // initialize the distance of the source from itself to zero\n  paths[source][source] = 0;\n\n  // use BFS to find the distance to each node from the source node\n  std::queue<std::pair<int, int>> q; // (node, distance)\n  q.push({source, 0});\n\n  while (!q.empty()) {\n    int node, distance;\n    std::tie(node, distance) = q.front();\n    q.pop();\n\n    for (int n = 0; n < N; n++) {\n      if (n == node) continue; // skip self-edges\n      if (A[node*N + n] == 0) continue; // skip non-edges\n\n      int dist = distance + 1;\n      if (paths[node][n] > dist) {\n        // if this is a shorter path than any we've seen before, update the distance\n        paths[node][n] = dist;\n        q.push({n, dist});\n      }\n    }\n  }\n  return paths[source][dest];\n}",
            "// TODO: Implement\n  return -1;\n}",
            "return 0;\n}",
            "return -1;\n}",
            "// TODO: your code here\n  return 0;\n}",
            "// Your code here\n}",
            "// TODO\n\n\treturn 0;\n}",
            "int nb_nodes = static_cast<int>(N);\n  int *distance = new int[nb_nodes];\n  int *parent = new int[nb_nodes];\n  int nb_nodes_local = static_cast<int>(N);\n  int nb_nodes_total = nb_nodes;\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  //int nb_nodes_per_proc = nb_nodes / size;\n\n  int my_first_node = rank * nb_nodes_local;\n  int my_last_node = (rank + 1) * nb_nodes_local - 1;\n\n  if (rank == 0) {\n    for (int i = 0; i < nb_nodes; i++)\n      distance[i] = INT_MAX;\n  } else {\n    for (int i = 0; i < nb_nodes_local; i++)\n      distance[i] = INT_MAX;\n  }\n\n  distance[source] = 0;\n\n  int iter = 1;\n  while (iter) {\n    for (int i = 0; i < nb_nodes_local; i++) {\n      for (int j = 0; j < nb_nodes_local; j++) {\n        int node = i * nb_nodes + j;\n        if (node < my_first_node || node > my_last_node)\n          continue;\n        for (int neighbor = 0; neighbor < nb_nodes; neighbor++) {\n          if (A[node * nb_nodes + neighbor]!= 0 && distance[node]!= INT_MAX && distance[neighbor] > distance[node] + 1) {\n            distance[neighbor] = distance[node] + 1;\n            parent[neighbor] = node;\n          }\n        }\n      }\n    }\n    iter = 0;\n    for (int i = 0; i < nb_nodes_local; i++) {\n      if (distance[i] == INT_MAX) {\n        iter = 1;\n        break;\n      }\n    }\n  }\n\n  int dist_dest = distance[dest];\n\n  delete[] distance;\n  delete[] parent;\n\n  int dist_dest_final = INT_MAX;\n  MPI_Reduce(&dist_dest, &dist_dest_final, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n  return dist_dest_final;\n}",
            "int l = 0;\n\n  // Your code here.\n  return l;\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "cuda",
        "prompt": "/* Compute the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Store the result in pathLength.\n   Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\n__global__ void shortestPathLength(const int *A, size_t N, int source, int dest, int *pathLength) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "int myID = threadIdx.x + blockIdx.x * blockDim.x;\n    __shared__ int myPathLength[THREADS_PER_BLOCK];\n    __shared__ int pathFound[THREADS_PER_BLOCK];\n    __shared__ int mySource[THREADS_PER_BLOCK];\n    __shared__ int myDest[THREADS_PER_BLOCK];\n\n    mySource[threadIdx.x] = source;\n    myDest[threadIdx.x] = dest;\n    if (myID == source) {\n        myPathLength[threadIdx.x] = 0;\n        pathFound[threadIdx.x] = 0;\n    } else {\n        myPathLength[threadIdx.x] = INT_MAX;\n        pathFound[threadIdx.x] = 0;\n    }\n    __syncthreads();\n\n    for (int i = 0; i < N; i++) {\n        __syncthreads();\n        // Check for path between source and dest\n        if (mySource[threadIdx.x] == myDest[threadIdx.x] && mySource[threadIdx.x] == myID) {\n            pathFound[threadIdx.x] = 1;\n        }\n        // Check for path between source and me\n        if (mySource[threadIdx.x] == myID) {\n            // Check if current ID is connected to a node that has already been visited\n            for (int j = 0; j < THREADS_PER_BLOCK; j++) {\n                if (A[myID * N + myPathLength[j]] == 1) {\n                    myPathLength[threadIdx.x] = myPathLength[j] + 1;\n                }\n            }\n        }\n        __syncthreads();\n    }\n    __syncthreads();\n    // Store the final path length in output array\n    if (pathFound[threadIdx.x] == 1) {\n        pathLength[blockIdx.x] = myPathLength[threadIdx.x];\n    }\n}",
            "int i = blockIdx.x;\n  int j = blockIdx.y;\n  __shared__ int B[BLOCK_SIZE][BLOCK_SIZE];\n  B[threadIdx.y][threadIdx.x] = A[i*N + j];\n  __syncthreads();\n  if(i==source && j==dest) {\n    pathLength[0] = 0;\n  } else if(i==dest && j==source) {\n    pathLength[0] = 0;\n  } else if(i==source && j==source) {\n    pathLength[0] = 0;\n  } else if(i==dest && j==dest) {\n    pathLength[0] = 0;\n  } else if(i==source && j!=dest && j!=source) {\n    pathLength[0] = INT_MAX;\n  } else if(i==dest && j!=source && j!=dest) {\n    pathLength[0] = INT_MAX;\n  } else if(i!=source && i!=dest && j==dest) {\n    pathLength[0] = INT_MAX;\n  } else if(i!=source && i!=dest && j==source) {\n    pathLength[0] = INT_MAX;\n  } else if(i!=source && i!=dest && j!=source && j!=dest) {\n    if(B[i][source]!= INT_MAX && B[j][dest]!= INT_MAX) {\n      pathLength[0] = min(B[i][source] + B[j][dest], pathLength[0]);\n    }\n  }\n  __syncthreads();\n}",
            "size_t row = blockDim.y * blockIdx.y + threadIdx.y;\n    size_t col = blockDim.x * blockIdx.x + threadIdx.x;\n    if (row == dest && col == source) {\n        // Found the path. Store it in *pathLength.\n    }\n}",
            "const int i = blockDim.x*blockIdx.x+threadIdx.x;\n\tconst int j = blockDim.y*blockIdx.y+threadIdx.y;\n\tif (i < N && j < N && A[i*N+j]!= 0) {\n\t\tif (i == dest && j == source) {\n\t\t\tatomicMin(pathLength, 1);\n\t\t} else if (i == source && j == dest) {\n\t\t\tatomicMin(pathLength, 1);\n\t\t} else {\n\t\t\tshortestPathLength(A, N, i, j, pathLength);\n\t\t}\n\t}\n}",
            "__shared__ int sData[BLOCK_SIZE][BLOCK_SIZE];\n\tint my_ID = threadIdx.x + blockDim.x * blockIdx.x;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint block_size = BLOCK_SIZE;\n\n\tint col = block_size*block_size;\n\n\tif (my_ID < N*N) {\n\t\tsData[tx][ty] = A[my_ID];\n\t\t__syncthreads();\n\t\tint min_path = A[my_ID];\n\t\tfor (int i = 0; i < block_size; i++) {\n\t\t\tif (sData[tx][i] < min_path) {\n\t\t\t\tmin_path = sData[tx][i];\n\t\t\t}\n\t\t}\n\t\tpathLength[my_ID] = min_path;\n\t}\n\n}",
            "/* TODO: Your code here */\n\n}",
            "}",
            "// Your code here\n\n}",
            "int i = blockIdx.x*blockDim.x + threadIdx.x;\n    int j = blockIdx.y*blockDim.y + threadIdx.y;\n    if (i < N && j < N) {\n        if (A[i*N+j] == 1 && source == i && dest == j) {\n            *pathLength = 0;\n        } else if (A[i*N+j] == 1) {\n            if (i < j && A[i*N+i] == 1 && A[j*N+j] == 1) {\n                atomicMin(pathLength, 2);\n            }\n            if (i < j && A[i*N+i] == 0 && A[j*N+j] == 0) {\n                atomicMin(pathLength, 2);\n            }\n        }\n    }\n}",
            "int tid = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid == source) {\n    pathLength[source] = 0;\n  } else {\n    pathLength[tid] = INF;\n  }\n  // TODO: Your code here.\n  // You can use atomicCAS for better performance.\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i < N && j < N) {\n\t\tint cost = A[i * N + j];\n\t\tif (i == source && j == dest) {\n\t\t\t*pathLength = cost;\n\t\t} else if (i == source && cost < *pathLength) {\n\t\t\t*pathLength = cost;\n\t\t}\n\t}\n}",
            "int i = blockIdx.y;\n  int j = blockIdx.x;\n  int tid = threadIdx.y * blockDim.x + threadIdx.x;\n  extern __shared__ int s[];\n\n  s[tid] = 0;\n\n  __syncthreads();\n\n  if (A[i*N + j]) {\n    s[tid] = 1;\n  }\n\n  __syncthreads();\n\n  if (source == i && j == dest) {\n    s[tid] = 1;\n  }\n\n  for (int k = 1; k < N; k <<= 1) {\n    __syncthreads();\n\n    int index = 2*tid-1;\n\n    if (index < k) {\n      s[index + k] += s[index];\n      s[index] = 0;\n    }\n\n    __syncthreads();\n  }\n\n  if (tid == 0) {\n    pathLength[i*N + j] = s[N - 1];\n  }\n}",
            "// Store the thread index as a variable\n\tconst int thread = blockDim.x * blockIdx.y * gridDim.x\n\t\t\t\t\t+ blockDim.x * blockIdx.x\n\t\t\t\t\t+ threadIdx.x;\n\n\t// Compute the length of the shortest path from source to dest in the graph\n\t// defined by the adjacency matrix A\n\n\t// A is an NxN adjacency matrix stored in row-major\n\t// Store the result in pathLength\n\n\tif (thread == 0) {\n\t\tpathLength[0] = 0;\n\t\tint distance = 0;\n\t\tbool seen[N];\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tseen[i] = false;\n\t\t}\n\n\t\tseen[source] = true;\n\t\tstd::queue<int> queue;\n\t\tqueue.push(source);\n\n\t\twhile (!queue.empty()) {\n\t\t\tint front = queue.front();\n\t\t\tqueue.pop();\n\n\t\t\tif (front == dest) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (seen[i] == false && A[front * N + i] == 1) {\n\t\t\t\t\tseen[i] = true;\n\t\t\t\t\tqueue.push(i);\n\t\t\t\t}\n\t\t\t}\n\t\t\tdistance++;\n\t\t}\n\t\tpathLength[0] = distance;\n\t}\n}",
            "// Your code goes here\n\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i == dest) {\n\t\tpathLength[i] = 0;\n\t\treturn;\n\t}\n\n\tsize_t min = INT_MAX;\n\n\t// Traverse all rows of the current column\n\tfor (size_t j = 0; j < N; j++) {\n\t\tint weight = A[j * N + i];\n\t\tif (weight > 0) {\n\t\t\tint path = pathLength[j];\n\t\t\tif (path < min) {\n\t\t\t\tmin = path;\n\t\t\t}\n\t\t}\n\t}\n\n\tpathLength[i] = min + 1;\n}",
            "// TODO: Implement this function\n    // Use a queue to store the nodes to process\n    // Create a queue to store the nodes to process\n    int *queue = new int[N];\n    // Store the index of the first element and the last element\n    int first = -1;\n    int last = -1;\n    // Define a variable to store the current node\n    int current;\n\n    // Insert the source node into the queue\n    queue[++last] = source;\n    // Define a variable to store the distance to the destination\n    int distance = 0;\n\n    while (first <= last) {\n        // Remove the first element from the queue\n        current = queue[++first];\n        // Stop when the destination is found\n        if (current == dest) {\n            *pathLength = distance;\n            return;\n        }\n        // Compute the distance to the current node from the source\n        distance++;\n\n        for (int i = 0; i < N; i++) {\n            // Insert the next node into the queue if it is adjacent to the current node\n            if (A[current * N + i] && i!= source) {\n                queue[++last] = i;\n            }\n        }\n    }\n\n    *pathLength = 0;\n}",
            "// Store the length of the shortest path here.\n  int myLength;\n\n  // Store the length of the shortest path from the source to current vertex here.\n  int length[N];\n\n  // Store the vertices already visited.\n  int visited[N];\n\n  // Initialize the length to infinite.\n  myLength = INT_MAX;\n\n  // Set the current vertex to source.\n  int current = source;\n\n  // Initialize the length of the shortest path from the source to the source to 0.\n  length[source] = 0;\n\n  // Initialize all vertices as unvisited.\n  for(int i = 0; i < N; i++) {\n    visited[i] = 0;\n  }\n\n  // Initialize the visited variable to true.\n  visited[source] = 1;\n\n  // Find the shortest path from the source to all other vertices using BFS.\n  while(current!= dest) {\n    // Go through all the adjacent vertices and find the shortest path.\n    for(int i = 0; i < N; i++) {\n      // Check if the adjacent vertex is valid.\n      if(A[current * N + i] == 1 && visited[i] == 0) {\n        // Check if the length of the shortest path from the source to the adjacent vertex is smaller.\n        if(length[current] + 1 < length[i]) {\n          // Update the length.\n          length[i] = length[current] + 1;\n        }\n\n        // Set the current vertex to the adjacent vertex.\n        current = i;\n\n        // Set the visited variable to true.\n        visited[i] = 1;\n      }\n    }\n  }\n\n  // Set the length of the shortest path to the destination.\n  myLength = length[dest];\n\n  // Store the length in the global memory.\n  *pathLength = myLength;\n}",
            "// your code goes here\n\n\tint *s;\n\tint *d;\n\tint *t;\n\n\tint tidx = threadIdx.x;\n\tint tidy = threadIdx.y;\n\n\tint blockx = blockIdx.x;\n\tint blocky = blockIdx.y;\n\n\tint blockx_sz = blockDim.x;\n\tint blocky_sz = blockDim.y;\n\n\t__shared__ int s_path_length[32][32];\n\n\tint index = (blockx * blockDim.x + tidx) * N + (blocky * blockDim.y + tidy);\n\n\tif (index == 0) {\n\t\ts_path_length[tidx][tidy] = 0;\n\t\tif (tidx == tidy) {\n\t\t\ts_path_length[tidx][tidy] = 1;\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (tidx == tidy) {\n\t\ts = &s_path_length[tidx][tidy];\n\t\td = &s_path_length[tidx][tidy + 1];\n\t\tt = &s_path_length[tidx][tidy - 1];\n\t\tif (index + 1 < N * N) {\n\t\t\t*d = *s + *(&A[index + 1]);\n\t\t}\n\t\tif (index - 1 >= 0) {\n\t\t\t*t = *s + *(&A[index - 1]);\n\t\t}\n\t} else {\n\t\tif (index + blockDim.y < N * N) {\n\t\t\ts = &s_path_length[tidx][tidy];\n\t\t\td = &s_path_length[tidx][tidy + 1];\n\t\t\tt = &s_path_length[tidx][tidy - 1];\n\t\t\t*d = *s + *(&A[index + blockDim.y]);\n\t\t\t*t = *s + *(&A[index - blockDim.y]);\n\t\t}\n\t}\n\t__syncthreads();\n\n\tif (index == 0) {\n\t\tpathLength[blockIdx.x * blockDim.y + blockIdx.y] = s_path_length[tidx][tidy];\n\t}\n}",
            "// TODO\n}",
            "// 1. You need to first figure out the index for the destination node, destIdx, and check whether destIdx is valid.\n\n  // 2. You need to compute the shortest path from source to dest.\n  // Use the array visited to keep track of the nodes that have been visited.\n  // You should first initialize the array to 0 for all elements.\n\n  // 3. If the path is valid, you should store the length of the path in pathLength.\n  // If the path is invalid, pathLength should be set to -1.\n}",
            "// The row and column index of the current thread in the NxN grid.\n    int row = blockIdx.x;\n    int col = blockIdx.y;\n\n    // If the current thread is in the pathLength matrix, then it stores the value.\n    if (row == col && col < N)\n        *pathLength = A[source + col*N];\n}",
            "// TODO: Compute the shortest path length between source and dest in A.\n    // Store the result in pathLength.\n    // You can use the following global variables in your code:\n    //   size_t N: the number of vertices in the graph\n    //   int source: the source vertex\n    //   int dest: the destination vertex\n    //   int *pathLength: pointer to the path length.\n    //   int *d_pathLength: a device pointer to pathLength\n    //   int *d_A: a device pointer to A\n}",
            "int idx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (idx == source)\n\t\tpathLength[0] = 0;\n\tif (idx == dest)\n\t\tpathLength[0] = 0;\n\tif (idx >= N)\n\t\treturn;\n\t__shared__ int distances[N];\n\t__shared__ bool valid[N];\n\t__shared__ bool invalid[N];\n\t__shared__ int parent[N];\n\t__shared__ bool visited[N];\n\t__shared__ bool in_queue[N];\n\tif (idx == 0) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tdistances[i] = -1;\n\t\t\tparent[i] = -1;\n\t\t\tvisited[i] = false;\n\t\t\tin_queue[i] = false;\n\t\t\tvalid[i] = true;\n\t\t\tinvalid[i] = false;\n\t\t}\n\t\tdistances[source] = 0;\n\t\tvisited[source] = true;\n\t\tin_queue[source] = true;\n\t}\n\t__syncthreads();\n\t// BFS\n\twhile (true) {\n\t\t__syncthreads();\n\t\tif (!in_queue[idx]) {\n\t\t\t__syncthreads();\n\t\t\tbreak;\n\t\t}\n\t\tif (invalid[idx]) {\n\t\t\t__syncthreads();\n\t\t\tcontinue;\n\t\t}\n\t\tif (!valid[idx]) {\n\t\t\t__syncthreads();\n\t\t\tcontinue;\n\t\t}\n\t\t__syncthreads();\n\t\tint cur_distance = distances[idx];\n\t\t__syncthreads();\n\t\tif (cur_distance == -1)\n\t\t\tcontinue;\n\t\tif (idx == dest) {\n\t\t\tpathLength[0] = cur_distance;\n\t\t\t__syncthreads();\n\t\t\tbreak;\n\t\t}\n\t\t__syncthreads();\n\t\tbool has_child = false;\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[idx * N + i] == 0)\n\t\t\t\tcontinue;\n\t\t\tif (valid[i]) {\n\t\t\t\thas_child = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t\tif (!has_child)\n\t\t\tvalid[idx] = false;\n\t\t__syncthreads();\n\t\tif (!valid[idx]) {\n\t\t\tinvalid[idx] = true;\n\t\t\t__syncthreads();\n\t\t\tcontinue;\n\t\t}\n\t\t__syncthreads();\n\t\tint child_distance = cur_distance + 1;\n\t\t__syncthreads();\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[idx * N + i] == 0)\n\t\t\t\tcontinue;\n\t\t\tif (visited[i])\n\t\t\t\tcontinue;\n\t\t\tint old = atomicMin(&distances[i], child_distance);\n\t\t\tif (old > child_distance) {\n\t\t\t\tparent[i] = idx;\n\t\t\t\tvisited[i] = true;\n\t\t\t\tin_queue[i] = true;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t\tin_queue[idx] = false;\n\t\t__syncthreads();\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid == 0) {\n\t\tpathLength[0] = -1;\n\t\treturn;\n\t}\n\tint sourceRow = tid - 1;\n\tint destRow = dest - 1;\n\tint curPathLength = 0;\n\tbool valid = false;\n\twhile (sourceRow!= destRow && curPathLength < N) {\n\t\tif (A[sourceRow*N + destRow]!= 0) {\n\t\t\tsourceRow = destRow;\n\t\t\tdestRow = (destRow == 0)? N - 1 : destRow - 1;\n\t\t\tcurPathLength++;\n\t\t\tvalid = true;\n\t\t} else {\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (valid) {\n\t\tpathLength[0] = curPathLength;\n\t}\n}",
            "// Your code here\n\n}",
            "// The current vertex.\n\tint v = blockDim.x * blockIdx.x + threadIdx.x;\n\n\t// We process the vertices in parallel. The index of each vertex processed by this thread is given by the thread's index.\n\tif (v >= N) {\n\t\treturn;\n\t}\n\n\t// The path length of v to the destination.\n\tint pathLen = INT_MAX;\n\n\t// Initialize the path length of each vertex to the maximum value.\n\t// We will overwrite the path length of vertices that can reach the destination.\n\tfor (int i = 0; i < N; i++) {\n\t\tpathLength[i] = INT_MAX;\n\t}\n\n\t// Start with the source vertex. The distance from the source to itself is 0.\n\tpathLength[source] = 0;\n\n\t// Compute the shortest path from the source to each vertex.\n\t// To do so, we start at the source and explore all of the reachable vertices in the graph.\n\t// The number of vertices that can be reached from the source is bounded by the diameter of the graph.\n\t// The diameter of the graph is bounded by N, since the graph is a complete graph.\n\tfor (int i = 0; i < N; i++) {\n\t\tint u = pathLength[v];\n\n\t\t// We can reach the destination by starting at the source and exploring all of the vertices reachable from the source.\n\t\tif (u == INT_MAX) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// We can reach the destination by starting at the source and exploring all of the vertices reachable from the source.\n\t\tif (u!= INT_MAX) {\n\t\t\tpathLen = u + 1;\n\t\t}\n\t}\n\n\t// Store the path length to the destination in the output.\n\tpathLength[v] = pathLen;\n}",
            "int i = blockIdx.x;\n  int j = blockIdx.y;\n\n  if (i == j && A[i*N+j] == 1) {\n    atomicMin(pathLength, 0);\n  }\n}",
            "int src = source;\n  int dst = dest;\n\n  int x = blockIdx.x;\n  int y = blockIdx.y;\n  int tid = threadIdx.x;\n  int i = x * blockDim.x + tid;\n\n  // Create a 2-D shared memory array for the nodes to be visited\n  // The first dimension is the number of threads in a block\n  // The second dimension is the maximum length of the path from source to dest\n  extern __shared__ int dist[];\n\n  if(i >= N)\n  {\n    return;\n  }\n\n  // Initialize shared memory array\n  if(tid == 0)\n  {\n    dist[0] = 0;\n  }\n\n  __syncthreads();\n\n  // Perform Breadth First Search from source to dest\n  // Increment shared memory array each time a node is visited\n  // Shared memory array is used to store the distance from the source to each node\n  // For example, if the source is 0, the shared memory array might look like the following:\n  //\n  //           thread\n  //            0   1   2   3\n  //    distance\n  // 0     0\n  // 1     0\n  // 2     0\n  // 3     0\n  // 4     0\n  //...\n  //\n  // When the source is incremented to 1, the shared memory array might look like the following:\n  //\n  //           thread\n  //            0   1   2   3\n  //    distance\n  // 0     0\n  // 1     1\n  // 2     0\n  // 3     0\n  // 4     0\n  //...\n  //\n  // The process is repeated until the destination is reached.\n  while(src!= dst && i < N)\n  {\n    if(A[src*N + i]!= 0)\n    {\n      dist[tid]++;\n      src = i;\n    }\n\n    __syncthreads();\n  }\n\n  // Set pathLength to the distance from source to dest\n  if(i == dest)\n  {\n    pathLength[0] = dist[tid];\n  }\n}",
            "size_t i = blockDim.x * blockIdx.x + threadIdx.x;\n\tsize_t j = blockDim.y * blockIdx.y + threadIdx.y;\n\t\n\tif (i < N && j < N && A[i*N + j] == 1 && (i!= j)) {\n\t\tatomicMin(pathLength, A[source*N + i] + A[i*N + j] + A[j*N + dest]);\n\t}\n}",
            "// Get the x and y indices of the thread\n\tint x = blockIdx.x;\n\tint y = blockIdx.y;\n\n\t// Check if the thread should compute the shortest path length\n\tif ((x < N) && (y < N) && (x!= y) && (A[x*N+y]!= 0)) {\n\t\tint *dp = new int[N]; // Initialize dynamic programming array\n\n\t\t// Base case for 0 steps\n\t\tdp[0] = 1;\n\n\t\t// Compute dp\n\t\tfor (int i = 1; i < N; i++) {\n\t\t\tdp[i] = 0;\n\n\t\t\t// Add up all the dp[i-1] values which are at most 1 step away\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[i*N + j]!= 0) {\n\t\t\t\t\tdp[i] += dp[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Set pathLength\n\t\t*pathLength = dp[dest];\n\n\t\t// Clean up\n\t\tdelete[] dp;\n\t}\n}",
            "int x = blockIdx.x * blockDim.x + threadIdx.x;\n   int y = blockIdx.y * blockDim.y + threadIdx.y;\n\n   __shared__ int shared[32][32];\n\n   int minDistance = 1000000;\n\n   if (x < N && y < N) {\n      shared[threadIdx.x][threadIdx.y] = A[x * N + y];\n\n      __syncthreads();\n\n      for (int offset = 16; offset > 0; offset /= 2) {\n         if (threadIdx.x < offset) {\n            shared[threadIdx.x][threadIdx.y] += shared[threadIdx.x + offset][threadIdx.y];\n         }\n         __syncthreads();\n      }\n\n      if (threadIdx.x == 0) {\n         if (shared[0][threadIdx.y] == 0 && x == dest) {\n            minDistance = y + 1;\n         }\n      }\n\n      __syncthreads();\n   }\n\n   if (threadIdx.x == 0 && threadIdx.y == 0 && x == source && y == source) {\n      *pathLength = minDistance;\n   }\n}",
            "const int startVertex = blockIdx.x * blockDim.x + threadIdx.x;\n  const int stride = blockDim.x * gridDim.x;\n\n  int distance = INT_MAX;\n  for (int vertex = startVertex; vertex < N; vertex += stride) {\n    if (A[vertex*N + source] == 1) {\n      if (vertex == dest) {\n        distance = 0;\n      } else if (A[vertex*N + dest] == 1) {\n        if (distance == INT_MAX) {\n          distance = 1;\n        } else {\n          distance++;\n        }\n      }\n    }\n  }\n\n  if (distance!= INT_MAX) {\n    atomicMin(pathLength, distance);\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    __shared__ int sdata[BLOCK_SIZE * BLOCK_SIZE];\n    if (i < N && j < N && A[i * N + j] == 1) {\n        // printf(\"i = %d, j = %d\\n\", i, j);\n        sdata[threadIdx.x * BLOCK_SIZE + threadIdx.y] = 1;\n        __syncthreads();\n        if (i == source && j == dest) {\n            pathLength[0] = 1;\n        }\n        for (int k = 0; k < BLOCK_SIZE * BLOCK_SIZE; k++) {\n            if (i == source && j == dest) {\n                break;\n            }\n            if (sdata[k] == 1 && i!= j) {\n                if (i == source) {\n                    sdata[threadIdx.x * BLOCK_SIZE + threadIdx.y] = 1;\n                    __syncthreads();\n                    pathLength[0]++;\n                    __syncthreads();\n                } else if (j == source) {\n                    sdata[threadIdx.x * BLOCK_SIZE + threadIdx.y] = 1;\n                    __syncthreads();\n                    pathLength[0]++;\n                    __syncthreads();\n                } else if (i == dest) {\n                    sdata[threadIdx.x * BLOCK_SIZE + threadIdx.y] = 1;\n                    __syncthreads();\n                    pathLength[0]++;\n                    __syncthreads();\n                } else if (j == dest) {\n                    sdata[threadIdx.x * BLOCK_SIZE + threadIdx.y] = 1;\n                    __syncthreads();\n                    pathLength[0]++;\n                    __syncthreads();\n                }\n            }\n        }\n        // printf(\"pathLength[0] = %d\\n\", pathLength[0]);\n    }\n}",
            "// TODO: Your code here\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i < N && j < N) {\n\t\tint isEdge = A[i * N + j];\n\t\tif (i == source && isEdge) {\n\t\t\tpathLength[j] = 1;\n\t\t}\n\t\telse if (i == dest && isEdge) {\n\t\t\tpathLength[j] = 1;\n\t\t}\n\t\telse {\n\t\t\tint tmp = INT_MAX;\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tint isEdge = A[i * N + k];\n\t\t\t\tif (isEdge && pathLength[k]!= INT_MAX) {\n\t\t\t\t\ttmp = min(tmp, pathLength[k] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t\tpathLength[i] = tmp;\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "int tid = blockDim.x * blockIdx.y * gridDim.x\t//rows preceeding current row in grid\n\t+ blockDim.x * blockIdx.x\t\t\t//blocks preceeding current block\n\t+ threadIdx.x;\n\n  if (tid < N * N) {\n    if (A[tid]!= 0) {\n      int row = tid / N;\n      int col = tid % N;\n      int distance = 1;\n\n      while (row!= dest) {\n        if (col < N) {\n          distance += 1;\n        }\n        row = col;\n        col = A[row * N + col];\n        if (col < 0) {\n          col = 0;\n        }\n      }\n\n      if (row == dest) {\n        pathLength[0] = distance;\n      }\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < N) {\n        pathLength[i] = A[i * N + dest] + A[i * N + source];\n    }\n}",
            "// TODO: fill this in.\n  // use a grid-stride loop to compute the shortest path length from source to dest\n  // the grid-stride loop looks like this:\n  //\n  // __shared__ int *cache;\n  // int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  //\n  // if (tid < N) {\n  //   // do something\n  // }\n  //\n  // if (tid + blockDim.x < N) {\n  //   // do something\n  // }\n  //\n  // if (tid + blockDim.x * 2 < N) {\n  //   // do something\n  // }\n  //\n  // etc...\n  //\n  // you should only need 1 shared memory cache line, so make sure to dynamically allocate\n  // the amount of shared memory you need\n  //\n  // to get started, try implementing this using a single-threaded for-loop\n  //\n\n}",
            "int i = threadIdx.x + blockIdx.x*blockDim.x;\n    int j = threadIdx.y + blockIdx.y*blockDim.y;\n    __shared__ int local_A[TILE_DIM][TILE_DIM];\n    __shared__ int local_pathLength[TILE_DIM][TILE_DIM];\n\n    int global_i = threadIdx.x + blockIdx.x*blockDim.x;\n    int global_j = threadIdx.y + blockIdx.y*blockDim.y;\n\n    // printf(\"I'm in thread (%d, %d)\\n\", global_i, global_j);\n\n    if (i < N && j < N) {\n        local_A[threadIdx.x][threadIdx.y] = A[i*N + j];\n    }\n    if (global_i == dest && global_j == source) {\n        local_pathLength[threadIdx.x][threadIdx.y] = 1;\n    } else {\n        local_pathLength[threadIdx.x][threadIdx.y] = INT_MAX;\n    }\n\n    __syncthreads();\n\n    // printf(\"local A: \\n\");\n    // for (int i = 0; i < TILE_DIM; i++) {\n    //     for (int j = 0; j < TILE_DIM; j++) {\n    //         printf(\"%d \", local_A[i][j]);\n    //     }\n    //     printf(\"\\n\");\n    // }\n    // printf(\"local pathLength: \\n\");\n    // for (int i = 0; i < TILE_DIM; i++) {\n    //     for (int j = 0; j < TILE_DIM; j++) {\n    //         printf(\"%d \", local_pathLength[i][j]);\n    //     }\n    //     printf(\"\\n\");\n    // }\n\n    for (int k = 0; k < TILE_DIM; k++) {\n        // printf(\"k is %d, i is %d, j is %d\\n\", k, i, j);\n        if (local_A[i][k]!= 0 && local_A[k][j]!= 0) {\n            local_pathLength[i][j] = min(local_pathLength[i][j], local_pathLength[i][k] + local_pathLength[k][j]);\n        }\n        __syncthreads();\n    }\n\n    // printf(\"local pathLength: \\n\");\n    // for (int i = 0; i < TILE_DIM; i++) {\n    //     for (int j = 0; j < TILE_DIM; j++) {\n    //         printf(\"%d \", local_pathLength[i][j]);\n    //     }\n    //     printf(\"\\n\");\n    // }\n    // printf(\"minimum: %d\\n\", min);\n    // printf(\"global_i is %d, global_j is %d\\n\", global_i, global_j);\n\n    if (global_i < N && global_j < N) {\n        if (local_pathLength[threadIdx.x][threadIdx.y]!= INT_MAX) {\n            atomicMin(&pathLength[global_i*N + global_j], local_pathLength[i][j]);\n        }\n    }\n}",
            "}",
            "int n = blockDim.x * blockIdx.x + threadIdx.x; // Row index\n\n    // TODO: Fill in the body of this function\n\n    __syncthreads();\n\n    int pathLen;\n    if (n == source) {\n        pathLen = 0;\n        atomicMin(pathLength, pathLen);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tif(i < N) {\n\t\tint minPathLength = INF;\n\t\tfor(int j = 0; j < N; ++j) {\n\t\t\tif(A[i * N + j] == 1) {\n\t\t\t\tint tmp = minPathLength;\n\t\t\t\tminPathLength = min(minPathLength, pathLength[j]);\n\t\t\t\tpathLength[j] = min(tmp, pathLength[j]);\n\t\t\t}\n\t\t}\n\t}\n}",
            "int x = threadIdx.x;\n  int y = threadIdx.y;\n  int idx = x * N + y;\n\n  __shared__ bool s_marked[16][16];\n  __shared__ int s_distance[16][16];\n\n  if (x == y) {\n    s_distance[x][y] = 0;\n    s_marked[x][y] = false;\n  }\n  __syncthreads();\n\n  for (int k = 0; k < N; k++) {\n    // Wait for all threads in block to reach this point.\n    __syncthreads();\n\n    if (s_marked[x][y]) continue;\n\n    if (s_distance[x][y] == -1) {\n      s_distance[x][y] = 0;\n    } else if (x == y) {\n      s_distance[x][y] = 0;\n    } else {\n      s_distance[x][y] = INT_MAX;\n    }\n\n    __syncthreads();\n\n    if (s_distance[x][y]!= INT_MAX) {\n      for (int i = 0; i < N; i++) {\n        if (i == x) continue;\n        if (A[x * N + i] && s_distance[i][y]!= INT_MAX) {\n          s_distance[x][y] = min(s_distance[x][y], s_distance[i][y] + 1);\n          break;\n        }\n      }\n    }\n\n    __syncthreads();\n\n    if (idx == x * N + y) {\n      if (x == source) {\n        if (s_distance[x][y] == INT_MAX) {\n          s_marked[x][y] = true;\n        } else {\n          s_distance[x][y] = 0;\n        }\n      } else if (s_distance[x][y]!= INT_MAX && s_distance[x][y] == s_distance[y][x] + 1) {\n        s_marked[x][y] = true;\n        s_marked[y][x] = true;\n      }\n    }\n\n    __syncthreads();\n  }\n\n  if (idx == source * N + dest) {\n    pathLength[0] = s_distance[dest][source];\n  }\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x;\n    int y = blockDim.y * blockIdx.y + threadIdx.y;\n    __shared__ int cache[128];\n    int c = x*128+y;\n\n    if (x == dest && y == source) {\n        pathLength[c] = 1;\n    } else {\n        pathLength[c] = 0;\n    }\n\n    __syncthreads();\n\n    for (int k = 0; k < N; k++) {\n        if (k == source) {\n            for (int i = 0; i < N; i++) {\n                for (int j = 0; j < N; j++) {\n                    if (i == x && j == y) {\n                        continue;\n                    }\n                    if (A[i*N+k] > 0 && A[k*N+j] > 0) {\n                        cache[k] = 1;\n                    }\n                }\n            }\n            __syncthreads();\n\n            int sum = 0;\n            for (int i = 0; i < N; i++) {\n                if (i == k) {\n                    continue;\n                }\n                sum += cache[i];\n            }\n            pathLength[c] += sum;\n            __syncthreads();\n        }\n        __syncthreads();\n    }\n}",
            "__shared__ int frontier[256];\n\t__shared__ int frontierLength;\n\tfrontierLength = 0;\n\tint threadIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\tint blockIdx = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (threadIdx == 0) {\n\t\tfrontier[blockIdx] = source;\n\t\tfrontierLength = 1;\n\t}\n\t__syncthreads();\n\twhile (blockIdx < frontierLength) {\n\t\tint v = frontier[blockIdx];\n\t\tfor (int i = A[v * N + 0]; i < A[v * N + v + 1]; i++) {\n\t\t\tint u = A[i];\n\t\t\tif (u == dest) {\n\t\t\t\tif (threadIdx == 0) {\n\t\t\t\t\tpathLength[0] = 1;\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (blockIdx == 0 && threadIdx == 0) {\n\t\t\t\tfrontier[frontierLength] = u;\n\t\t\t\tfrontierLength += 1;\n\t\t\t}\n\t\t}\n\t\tblockIdx = blockIdx + 1;\n\t\t__syncthreads();\n\t}\n\tif (threadIdx == 0) {\n\t\tpathLength[0] = 0;\n\t}\n}",
            "int i = blockIdx.y * gridDim.x + blockIdx.x;\n    int j = threadIdx.x;\n    __shared__ int sdata[BLOCK_SIZE];\n    sdata[threadIdx.x] = A[i*N+j];\n    __syncthreads();\n    if (threadIdx.x == 0)\n    {\n        int shortest = 0;\n        if (i == source)\n            shortest = 1;\n        for (int k = 0; k < N; k++)\n        {\n            if (sdata[k]!= 0)\n                shortest += sdata[k];\n        }\n        if (i == dest)\n            *pathLength = shortest;\n    }\n}",
            "int start = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = start; i < N; i += stride) {\n        int len = 1 + A[N*i + source];\n        for (int j = 0; j < N; j++) {\n            if (j!= i && j!= source) {\n                int temp = A[N*i + j];\n                if (len > temp) len = temp;\n            }\n        }\n        if (i == dest) pathLength[source] = len;\n    }\n}",
            "__shared__ int dist[MAX_SIZE]; // shared memory\n\t__shared__ bool visited[MAX_SIZE]; // shared memory\n\t__shared__ int prev[MAX_SIZE]; // shared memory\n\n\t// Get this thread's global row and column index\n\tint row = blockIdx.x;\n\tint col = threadIdx.x;\n\n\tif (row == source) {\n\t\tdist[col] = col == source? 0 : INT_MAX;\n\t\tvisited[col] = col == source? true : false;\n\t\tprev[col] = col == source? col : -1;\n\t}\n\n\t__syncthreads();\n\n\twhile (true) {\n\t\t// Update distance if current distance is greater than distance to next vertex plus weight\n\t\tif (row == col &&!visited[col]) {\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (A[row * N + i]!= INT_MAX && (!visited[i] || dist[row] + A[row * N + i] < dist[i])) {\n\t\t\t\t\tdist[i] = dist[row] + A[row * N + i];\n\t\t\t\t\tprev[i] = row;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\n\t\tint smallest = INT_MAX;\n\t\tint next;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (!visited[i] && dist[i] < smallest) {\n\t\t\t\tsmallest = dist[i];\n\t\t\t\tnext = i;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tif (smallest == INT_MAX) {\n\t\t\tbreak;\n\t\t}\n\n\t\tvisited[next] = true;\n\n\t\t__syncthreads();\n\t}\n\n\t__syncthreads();\n\n\tif (row == dest) {\n\t\t*pathLength = dist[dest];\n\t}\n}",
            "// TODO\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    __shared__ int dist[100][100];\n    __shared__ bool visited[100];\n    if (j >= N || i >= N)\n        return;\n    if (j == source) {\n        dist[j][i] = 0;\n    } else {\n        dist[j][i] = -1;\n    }\n    if (threadIdx.x == 0)\n        visited[j] = false;\n    __syncthreads();\n    int min = -1;\n    for (int k = 0; k < N; k++) {\n        if (visited[k]) {\n            if (A[j * N + k] == 1 && dist[j][k]!= -1 && dist[j][k] + 1 < min)\n                min = dist[j][k] + 1;\n            else if (A[k * N + j] == 1 && dist[k][j]!= -1 && dist[k][j] + 1 < min)\n                min = dist[k][j] + 1;\n        }\n    }\n    if (min!= -1) {\n        dist[j][i] = min;\n        if (i == dest)\n            *pathLength = min;\n    }\n    __syncthreads();\n    if (i == dest) {\n        visited[j] = true;\n        __syncthreads();\n    }\n    __syncthreads();\n}",
            "// Your code here\n\tint x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint id = x * N + y;\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint tid = tx * N + ty;\n\n\tint n = N * N;\n\tint *dist = new int[n];\n\tint *prev = new int[n];\n\tint *visited = new int[n];\n\n\tfor(int i=0; i<n; i++)\n\t{\n\t\tdist[i] = INT_MAX;\n\t\tprev[i] = -1;\n\t\tvisited[i] = 0;\n\t}\n\n\tdist[source] = 0;\n\tint *s = new int[1];\n\ts[0] = source;\n\tint s_cnt = 1;\n\tint s_cnt_new = 0;\n\tint s_ptr = 0;\n\tint u;\n\tint v;\n\tint w;\n\tbool found = false;\n\n\twhile(s_cnt > 0)\n\t{\n\t\tu = s[s_ptr];\n\t\ts_ptr++;\n\t\ts_cnt--;\n\t\tvisited[u] = 1;\n\t\tfor(int i=0; i<N; i++)\n\t\t{\n\t\t\tv = u * N + i;\n\t\t\tif(A[v] == 0) continue;\n\t\t\tw = v * N + i;\n\t\t\tif(dist[v] > dist[u] + A[w])\n\t\t\t{\n\t\t\t\tdist[v] = dist[u] + A[w];\n\t\t\t\tprev[v] = u;\n\t\t\t\tif(visited[v] == 0)\n\t\t\t\t{\n\t\t\t\t\ts[s_cnt_new] = v;\n\t\t\t\t\ts_cnt_new++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif(dist[dest] == INT_MAX)\n\t{\n\t\tpathLength[0] = -1;\n\t\treturn;\n\t}\n\telse\n\t{\n\t\tint v = dest;\n\t\tpathLength[0] = 0;\n\t\twhile(v!= -1)\n\t\t{\n\t\t\tpathLength[0]++;\n\t\t\tv = prev[v];\n\t\t}\n\t}\n\n}",
            "// Replace the code below to compute the shortest path length from source to dest in A.\n\tint i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint k = threadIdx.x;\n\tint l = threadIdx.y;\n\n\tif(i == j && k == l && i == source) {\n\t\t*pathLength = 0;\n\t}\n\n\tif(i == j && k == l && i == dest) {\n\t\t*pathLength = 1;\n\t}\n\n\tif(i == j && k == l) {\n\t\tif(A[k + j*N] == 1 && *pathLength!= 0) {\n\t\t\t*pathLength = 1;\n\t\t}\n\t\tif(A[k + j*N] == 1 && *pathLength!= 1) {\n\t\t\t*pathLength = -1;\n\t\t}\n\t}\n}",
            "// TODO: Write your kernel code here\n    int *dist;\n    int *parent;\n    int *s;\n\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n\n    extern __shared__ int shd[];\n\n    dist = shd;\n    parent = dist + N;\n    s = parent + N;\n\n    if (tid < N) {\n        dist[tid] = INT_MAX;\n        parent[tid] = -1;\n        s[tid] = 0;\n    }\n    __syncthreads();\n\n    dist[tid] = A[tid * N + bid];\n    if (bid == tid) {\n        parent[bid] = -1;\n    }\n    __syncthreads();\n\n    for (int i = 0; i < N; i++) {\n        if (i == N - 1) {\n            break;\n        }\n        s[bid] = 0;\n        __syncthreads();\n        for (int j = 0; j < N; j++) {\n            s[j] = 0;\n            int u = j;\n            int v = parent[u];\n            while (v >= 0) {\n                s[u] += dist[v];\n                u = v;\n                v = parent[u];\n            }\n            __syncthreads();\n        }\n        __syncthreads();\n        for (int j = 0; j < N; j++) {\n            int u = j;\n            int alt = dist[u] + s[j];\n            if (alt < dist[j]) {\n                parent[j] = u;\n                dist[j] = alt;\n            }\n            __syncthreads();\n        }\n    }\n    if (tid == 0) {\n        *pathLength = dist[dest];\n    }\n    __syncthreads();\n}",
            "int u = blockIdx.x * blockDim.x + threadIdx.x;\n  int v = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (u >= N || v >= N) {\n    return;\n  }\n\n  // TODO\n  int u_v = A[u * N + v];\n\n  if (u == source && v == dest) {\n    pathLength[0] = u_v;\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i == j) {\n\t\tif (i == source) {\n\t\t\t*pathLength = 0;\n\t\t} else {\n\t\t\t*pathLength = -1;\n\t\t}\n\t}\n\n\tif (i < N && j < N && A[N * i + j]!= 0) {\n\t\tint tmp = *pathLength;\n\t\t*pathLength = min(*pathLength, 1 + tmp);\n\t}\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ int distance[1024];\n  if (i == j) {\n    distance[threadIdx.y * 32 + threadIdx.x] = 0;\n  } else {\n    distance[threadIdx.y * 32 + threadIdx.x] = 99999;\n  }\n  __syncthreads();\n\n  // Compute path length from source to i\n  for (int k = 0; k < N; k++) {\n    if (k!= source && k!= dest && i!= j && distance[threadIdx.y * 32 + threadIdx.x]!= 99999) {\n      distance[threadIdx.y * 32 + threadIdx.x] = min(distance[threadIdx.y * 32 + threadIdx.x],\n                                                     A[source * N + k] + A[k * N + i]);\n    }\n    __syncthreads();\n  }\n\n  // Compute path length from i to dest\n  for (int k = 0; k < N; k++) {\n    if (k!= source && k!= dest && i!= j && distance[threadIdx.y * 32 + threadIdx.x]!= 99999) {\n      distance[threadIdx.y * 32 + threadIdx.x] = min(distance[threadIdx.y * 32 + threadIdx.x],\n                                                     A[i * N + k] + A[k * N + dest]);\n    }\n    __syncthreads();\n  }\n\n  if (i == j) {\n    distance[threadIdx.y * 32 + threadIdx.x] = min(distance[threadIdx.y * 32 + threadIdx.x],\n                                                   A[i * N + source] + A[source * N + i]);\n  }\n  __syncthreads();\n\n  // Compute the minimum path length over the whole grid\n  for (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n    if (threadIdx.x < stride) {\n      distance[threadIdx.y * 32 + threadIdx.x] =\n        min(distance[threadIdx.y * 32 + threadIdx.x], distance[threadIdx.y * 32 + threadIdx.x + stride]);\n    }\n    __syncthreads();\n  }\n\n  if (threadIdx.x == 0) {\n    atomicMin(pathLength, distance[threadIdx.y * 32]);\n  }\n}",
            "int row = blockIdx.y*blockDim.y + threadIdx.y;\n    int col = blockIdx.x*blockDim.x + threadIdx.x;\n    extern __shared__ int sdata[];\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n    int tid = ty * blockDim.x + tx;\n    int myPath = 0;\n    int myMinPath = 0;\n    int myIndex = row * N + col;\n    int myTarget = dest * N + col;\n    // first iteration\n    if(row == source) {\n        if(col == dest) {\n            myPath = 0;\n            myMinPath = 0;\n        } else if(col == source) {\n            myPath = 1;\n            myMinPath = 1;\n        } else if(A[row * N + col] == 1) {\n            myPath = 1;\n            myMinPath = 1;\n        } else {\n            myPath = 0;\n            myMinPath = 0;\n        }\n    } else if(row == dest) {\n        if(col == dest) {\n            myPath = 1;\n            myMinPath = 1;\n        } else if(col == source) {\n            myPath = 0;\n            myMinPath = 0;\n        } else if(A[row * N + col] == 1) {\n            myPath = 0;\n            myMinPath = 0;\n        } else {\n            myPath = 1;\n            myMinPath = 1;\n        }\n    } else if(row == col) {\n        if(A[row * N + col] == 1) {\n            myPath = 1;\n            myMinPath = 1;\n        } else {\n            myPath = 0;\n            myMinPath = 0;\n        }\n    } else {\n        if(A[row * N + col] == 1) {\n            myPath = 1;\n            myMinPath = 1;\n        } else {\n            myPath = 0;\n            myMinPath = 0;\n        }\n    }\n    sdata[tid] = myPath;\n    __syncthreads();\n    if(tid < 32) {\n        sdata[tid] = warpReduceMin(sdata[tid]);\n    }\n    if(tid == 0) {\n        atomicMin(pathLength, sdata[0]);\n    }\n\n    if(row == source) {\n        // now compute the shortest path from the source to the target\n        if(col!= source && A[row * N + col] == 1) {\n            // the cost is 2 + the min path cost from the source to the current destination\n            myPath = 2 + *pathLength;\n        } else {\n            myPath = 0;\n        }\n    } else if(row == dest) {\n        // now compute the shortest path from the source to the target\n        if(col!= dest && A[row * N + col] == 1) {\n            // the cost is 2 + the min path cost from the source to the current destination\n            myPath = 2 + *pathLength;\n        } else {\n            myPath = 0;\n        }\n    } else {\n        if(A[row * N + col] == 1) {\n            // the cost is 2 + the min path cost from the source to the current destination\n            myPath = 2 + *pathLength;\n        } else {\n            myPath = 0;\n        }\n    }\n\n    // compute the shortest path from the current destination to the target\n    sdata[tid] = myPath;\n    __syncthreads();\n    if(tid < 32) {\n        sdata[tid] = warpReduceMin(sdata[tid]);\n    }\n    if(tid == 0) {\n        atomicMin(pathLength, sdata[0]);\n    }\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = gridDim.x * blockDim.x;\n    int currentLength = 0;\n    int isFound = 0;\n\n    for (int i = index; i < N; i += stride) {\n        if (i == source) {\n            isFound = 1;\n            pathLength[i] = 0;\n        } else {\n            pathLength[i] = INT_MAX;\n        }\n    }\n\n    __syncthreads();\n\n    for (int k = 0; k < N; ++k) {\n        for (int i = index; i < N; i += stride) {\n            for (int j = 0; j < N; ++j) {\n                if (i == dest && j == dest && A[i * N + j] == 1) {\n                    currentLength = pathLength[j];\n                }\n                if (A[i * N + j] == 1) {\n                    int tmp = pathLength[j] + 1;\n                    if (pathLength[i] > tmp) {\n                        pathLength[i] = tmp;\n                    }\n                }\n            }\n        }\n        __syncthreads();\n    }\n\n    if (isFound) {\n        if (pathLength[dest] == INT_MAX) {\n            pathLength[dest] = -1;\n        }\n    } else {\n        pathLength[source] = -1;\n    }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n    int col = blockIdx.y * blockDim.y + threadIdx.y;\n    int start = source;\n    int distance = INT_MAX;\n\n    // Check if the source and the destination nodes are the same\n    if(row == col && start == dest) {\n        pathLength[0] = 0;\n    }\n\n    // Check if the source and the destination nodes are not the same\n    if(row == col && start!= dest) {\n        pathLength[0] = INT_MAX;\n    }\n\n    if(row == col && start!= dest) {\n        return;\n    }\n\n    if(A[row * N + col] == 1 && row!= col && start!= dest) {\n        distance = 1 + min(pathLength[col], pathLength[row]);\n    }\n\n    pathLength[col] = min(pathLength[col], distance);\n}",
            "// Find the (x,y) location of the thread in the CUDA grid\n  size_t x = blockIdx.x;\n  size_t y = blockIdx.y;\n  size_t n = threadIdx.x;\n\n  // Check if the thread location is valid\n  if (x >= N || y >= N || n >= N) return;\n\n  // Check if the (x,y) location is the source\n  if (x == source && y == source && n == 0) {\n    pathLength[x*N+y] = 0;\n    return;\n  }\n\n  // Check if the (x,y) location is the destination\n  if (x == dest && y == dest && n == 0) {\n    pathLength[x*N+y] = 1;\n    return;\n  }\n\n  // The thread location is not the source or destination\n  if (x == source && y == source) {\n    pathLength[x*N+y] = A[x*N+y];\n  }\n\n  // The thread location is not the source or destination\n  if (x == dest && y == dest) {\n    pathLength[x*N+y] = A[x*N+y];\n  }\n\n  // Compute the shortest path length\n  if (x!= source && x!= dest && y!= source && y!= dest) {\n    if (n == 0) {\n      pathLength[x*N+y] = pathLength[x*N+y-1] + A[x*N+y-1];\n    }\n    else if (n == 1) {\n      pathLength[x*N+y] = pathLength[x*N+y-N] + A[x*N+y-N];\n    }\n    else if (n == 2) {\n      pathLength[x*N+y] = pathLength[x*N+y-N+1] + A[x*N+y-N+1];\n    }\n    else if (n == 3) {\n      pathLength[x*N+y] = pathLength[x*N+y-N-1] + A[x*N+y-N-1];\n    }\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tif (i == j) {\n\t\tif (i == source) {\n\t\t\tpathLength[i] = 0;\n\t\t} else {\n\t\t\tpathLength[i] = INT_MAX;\n\t\t}\n\t} else if (A[i * N + j] == 1) {\n\t\tpathLength[j] = pathLength[i] + 1;\n\t}\n\t\n\t// __syncthreads();\n}",
            "int id = blockIdx.x * blockDim.x + threadIdx.x;\n  int tid = threadIdx.x;\n\n  __shared__ int s_A[BLOCKSIZE];\n  __shared__ int s_min_dis[BLOCKSIZE];\n  __shared__ int s_min_path[BLOCKSIZE];\n  __shared__ int s_index;\n\n  if(tid == 0) {\n    s_min_path[0] = source;\n  }\n  __syncthreads();\n  int min_dis = A[source * N + id];\n  s_A[tid] = A[source * N + id];\n  if(min_dis < 0) {\n    min_dis = INT_MAX;\n  }\n  s_min_dis[tid] = min_dis;\n  __syncthreads();\n  if(id == dest) {\n    min_dis = s_min_dis[tid];\n    for(int i = tid; i >= 0; i >>= 1) {\n      int s_min_dis_i = s_min_dis[i];\n      if(s_min_dis_i < min_dis) {\n        min_dis = s_min_dis_i;\n        s_min_path[tid] = s_min_path[i];\n      }\n    }\n  }\n  __syncthreads();\n  if(tid == 0) {\n    *pathLength = min_dis;\n  }\n  __syncthreads();\n  if(id == dest) {\n    *pathLength = s_min_path[tid];\n  }\n}",
            "__shared__ int sdata[256];\n\tint tid = threadIdx.x + blockIdx.x * blockDim.x;\n\tint thread_source_dest = A[source * N + dest];\n\tint thread_source_dest_reverse = A[dest * N + source];\n\tint thread_source_source = A[source * N + source];\n\tint thread_dest_dest = A[dest * N + dest];\n\t// The start node\n\tif (tid == source) {\n\t\tsdata[tid] = 0;\n\t} else if (tid == dest) {\n\t\tsdata[tid] = thread_source_dest_reverse + thread_source_source + thread_dest_dest;\n\t} else {\n\t\tsdata[tid] = INF;\n\t}\n\tint idx = blockDim.x * blockIdx.x;\n\twhile (idx < N) {\n\t\t__syncthreads();\n\t\tint tid_threadIdx_idx = tid + idx;\n\t\tif (tid_threadIdx_idx == source) {\n\t\t\tsdata[tid] = 0;\n\t\t} else if (tid_threadIdx_idx == dest) {\n\t\t\tsdata[tid] = thread_source_dest_reverse + thread_source_source + thread_dest_dest;\n\t\t} else {\n\t\t\tint thread_tid_threadIdx_idx = A[tid * N + tid_threadIdx_idx];\n\t\t\tint thread_tid_threadIdx_idx_reverse = A[tid_threadIdx_idx * N + tid];\n\t\t\tif (thread_tid_threadIdx_idx == INF && thread_tid_threadIdx_idx_reverse == INF) {\n\t\t\t\tsdata[tid] = INF;\n\t\t\t} else if (thread_tid_threadIdx_idx == INF && thread_tid_threadIdx_idx_reverse!= INF) {\n\t\t\t\tsdata[tid] = sdata[tid_threadIdx_idx] + thread_tid_threadIdx_idx_reverse;\n\t\t\t} else if (thread_tid_threadIdx_idx!= INF && thread_tid_threadIdx_idx_reverse == INF) {\n\t\t\t\tsdata[tid] = sdata[tid_threadIdx_idx] + thread_tid_threadIdx_idx;\n\t\t\t} else {\n\t\t\t\tsdata[tid] = min(sdata[tid_threadIdx_idx] + thread_tid_threadIdx_idx, sdata[tid_threadIdx_idx] + thread_tid_threadIdx_idx_reverse);\n\t\t\t}\n\t\t}\n\t\tidx += blockDim.x * gridDim.x;\n\t}\n\t__syncthreads();\n\tint N_threads = N;\n\t__shared__ bool done;\n\tif (tid == 0) done = false;\n\twhile (!done) {\n\t\t__syncthreads();\n\t\tint next = (tid + 1) * 2 - 1;\n\t\tif (next < N_threads) {\n\t\t\tsdata[tid] = min(sdata[tid], sdata[next]);\n\t\t}\n\t\tnext = (tid + 1) * 2;\n\t\tif (next < N_threads) {\n\t\t\tsdata[tid] = min(sdata[tid], sdata[next]);\n\t\t}\n\t\t__syncthreads();\n\t\tif (tid == 0) {\n\t\t\tdone = true;\n\t\t\tfor (int i = 0; i < blockDim.x; i++) {\n\t\t\t\tif (sdata[i]!= sdata[0]) done = false;\n\t\t\t}\n\t\t}\n\t\tN_threads = (N_threads + 1) / 2;\n\t}\n\t__syncthreads();\n\tif (tid == 0) {\n\t\tpathLength[0] = sdata[0];\n\t}\n}",
            "int tid = threadIdx.x;\n  int bid = blockIdx.x;\n\n  // Create shared memory and initialize it to -1\n  __shared__ int sh_A[N][N];\n  if(tid == 0) {\n    for(int i = 0; i < N; ++i) {\n      for(int j = 0; j < N; ++j) {\n        sh_A[i][j] = -1;\n      }\n    }\n  }\n  __syncthreads();\n\n  // Copy data from global memory to shared memory\n  if(tid < N) {\n    for(int j = 0; j < N; ++j) {\n      sh_A[tid][j] = A[bid*N + j];\n    }\n  }\n  __syncthreads();\n\n  // Perform a breadth-first search to find the shortest path from the source node to the destination node\n  if(tid == 0) {\n    // Create a queue to perform the breadth-first search\n    queue<int> queue;\n\n    // Create an array to hold the shortest path lengths\n    int shortestPath[N];\n    for(int i = 0; i < N; ++i) {\n      shortestPath[i] = -1;\n    }\n\n    // Set the starting point for the breadth-first search\n    queue.push(source);\n    shortestPath[source] = 0;\n\n    while(!queue.empty()) {\n      // Remove a node from the queue\n      int current = queue.front();\n      queue.pop();\n\n      // If the node is the destination node, the path length has been found.\n      if(current == dest) {\n        *pathLength = shortestPath[dest];\n        return;\n      }\n\n      // Examine the neighbors of the current node\n      for(int neighbor = 0; neighbor < N; ++neighbor) {\n        // If a neighbor is unvisited and there is an edge between the current node and the neighbor\n        if(shortestPath[neighbor] == -1 && sh_A[current][neighbor]!= 0) {\n          // Add the neighbor to the queue and set its shortest path length\n          queue.push(neighbor);\n          shortestPath[neighbor] = shortestPath[current] + 1;\n        }\n      }\n    }\n  }\n}",
            "int *dist = new int[N];\n\tdist[source] = 0;\n\tint *pred = new int[N];\n\tpred[source] = -1;\n\n\tfor (int i = 0; i < N; i++) {\n\t\t// printf(\"i: %d\\n\", i);\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tint minDist = INT_MAX;\n\t\t\tint minV = INT_MAX;\n\n\t\t\tfor (int w = 0; w < N; w++) {\n\t\t\t\tif (dist[w] + A[w * N + v] < minDist) {\n\t\t\t\t\tminDist = dist[w] + A[w * N + v];\n\t\t\t\t\tminV = w;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdist[v] = minDist;\n\t\t\tpred[v] = minV;\n\t\t}\n\t}\n\n\tprintf(\"source: %d, dest: %d\\n\", source, dest);\n\tint distToSource = dist[source];\n\tint distToDest = dist[dest];\n\tprintf(\"dist[source]: %d, dist[dest]: %d\\n\", distToSource, distToDest);\n\n\t// printf(\"dist: \");\n\t// for (int i = 0; i < N; i++) {\n\t// \tprintf(\"%d \", dist[i]);\n\t// }\n\t// printf(\"\\n\");\n\n\tint pathLengthCUDA = dist[dest];\n\n\tprintf(\"pred: \");\n\tfor (int i = 0; i < N; i++) {\n\t\tprintf(\"%d \", pred[i]);\n\t}\n\tprintf(\"\\n\");\n\n\tfor (int i = dest; i >= 0; i = pred[i]) {\n\t\tprintf(\"%d \", i);\n\t}\n\tprintf(\"\\n\");\n\n\t// printf(\"pathLength: %d\\n\", pathLengthCUDA);\n\t*pathLength = dist[dest];\n}",
            "// Use blockIdx and threadIdx to figure out which node we're working on.\n\tint node = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// Get a pointer to the first element of our column of the adjacency matrix.\n\tconst int *column = A + node;\n\t// Set pathLength[node] to the length of the shortest path to node from the source.\n\t// Initialize it to -1 if the node is not reachable from the source.\n\tif (node == source) {\n\t\tpathLength[node] = 0;\n\t} else if (column[source] > 0) {\n\t\tpathLength[node] = 1;\n\t} else {\n\t\tpathLength[node] = -1;\n\t}\n\n\t// Use __syncthreads() to wait for the updates to pathLength to be visible to all threads in the block.\n\t__syncthreads();\n\n\t// Now that the first thread in the block has the length of the shortest path to the source,\n\t// it can use that to compute the length of the shortest path to all the other nodes.\n\tfor (int i = 0; i < N; i++) {\n\t\tif (pathLength[node] < 0) {\n\t\t\t// Stop if we know we can't reach the node.\n\t\t\tbreak;\n\t\t}\n\t\t// If node has a direct edge to i, add 1 to pathLength[i] to get the length of the path to i.\n\t\t// Use atomicMin() to keep pathLength[i] up-to-date as we traverse the graph.\n\t\tif (column[i] > 0) {\n\t\t\tatomicMin(&pathLength[i], pathLength[node] + 1);\n\t\t}\n\n\t\t// Use __syncthreads() to wait for all threads in the block to finish their work.\n\t\t__syncthreads();\n\t}\n}",
            "int src = blockIdx.x * blockDim.x + threadIdx.x;\n   int dest = blockIdx.y * blockDim.y + threadIdx.y;\n\n   // Check if the thread's coordinates are within bounds\n   if(src >= N || dest >= N || src == dest) {\n     return;\n   }\n\n   // If the path from the source to the destination is shorter than the current length in the output, update the output\n   if (A[src*N + dest]!= 0 && src + 1 + A[src*N + dest] < *pathLength) {\n     *pathLength = src + 1 + A[src*N + dest];\n   }\n}",
            "// Your code here\n\n  int tx = threadIdx.x;\n  int ty = threadIdx.y;\n  int bx = blockIdx.x;\n  int by = blockIdx.y;\n\n  extern __shared__ int sdata[];\n  int x = bx * blockDim.x + tx;\n  int y = by * blockDim.y + ty;\n\n  if (x < N && y < N)\n    sdata[ty * blockDim.x + tx] = A[x * N + y];\n\n  __syncthreads();\n\n  if (x == source && y == dest)\n    sdata[ty * blockDim.x + tx] = 0;\n\n  if (x == source && y < N)\n    sdata[ty * blockDim.x + tx] = 1;\n\n  if (x < N && y == dest)\n    sdata[ty * blockDim.x + tx] = 1;\n\n  for (int k = 0; k < N; k += blockDim.x) {\n    __syncthreads();\n    int index = ty * blockDim.x + tx;\n    if (index < N)\n      sdata[index] = A[index * N + k] + sdata[index];\n\n    __syncthreads();\n    index = ty * blockDim.x + tx;\n    if (x < N && index < N && y < N && sdata[index]!= -1 && sdata[index] < sdata[y * blockDim.x + tx])\n      sdata[y * blockDim.x + tx] = sdata[index];\n\n  }\n\n  __syncthreads();\n  if (x == source && y == dest)\n    pathLength[0] = sdata[y * blockDim.x + tx];\n\n  __syncthreads();\n}",
            "// TODO\n}",
            "int x = blockDim.x * blockIdx.x + threadIdx.x; // horizontal thread index in grid\n  int y = blockDim.y * blockIdx.y + threadIdx.y; // vertical thread index in grid\n  if (x >= N || y >= N)\n    return;\n  int dist = A[y * N + x];\n  // TODO: update pathLength to be the shortest path length from source to dest\n}",
            "int tid = blockIdx.x*blockDim.x+threadIdx.x;\n\n    if(A[tid] == dest) {\n        *pathLength = 0;\n        return;\n    }\n\n    if(tid < N) {\n        for(int i=1; i<N; ++i) {\n            if(A[tid] == source) {\n                *pathLength = 1;\n                break;\n            } else {\n                int A_tid_A[N];\n                for(int j=0; j<N; ++j) {\n                    A_tid_A[j] = A[tid*N+j];\n                }\n                shortestPathLength(A_tid_A, N, A[tid*N+i], dest, pathLength);\n                *pathLength += 1;\n            }\n        }\n    }\n}",
            "// TODO\n\n}",
            "int tid = blockDim.x*blockIdx.x + threadIdx.x;\n\tint bid = blockIdx.x;\n\t\n\tif(tid == source) {\n\t\tint shortestPath = 0;\n\t\tpathLength[tid] = shortestPath;\n\t}\n\t\n\tif(tid < N) {\n\t\tint parent = tid;\n\t\tint shortestPath = 0;\n\t\twhile(parent!= source) {\n\t\t\tshortestPath++;\n\t\t\tparent = A[parent * N + bid];\n\t\t}\n\t\tpathLength[tid] = shortestPath;\n\t}\n}",
            "}",
            "int id = blockIdx.x*blockDim.x+threadIdx.x;\n\tint len = N * N;\n\tint *d = (int *)malloc(len * sizeof(int));\n\tint *p = (int *)malloc(len * sizeof(int));\n\tint *q = (int *)malloc(len * sizeof(int));\n\tint *s = (int *)malloc(len * sizeof(int));\n\n\tfor(int i = 0; i < len; i++) {\n\t\td[i] = INT_MAX;\n\t\tp[i] = -1;\n\t\tq[i] = -1;\n\t\ts[i] = -1;\n\t}\n\td[source] = 0;\n\tp[source] = source;\n\n\tfor(int i = 0; i < N; i++) {\n\t\tfor(int j = 0; j < N; j++) {\n\t\t\tint u = i * N + j;\n\t\t\tif(u!= source && A[u * N + source] < INT_MAX) {\n\t\t\t\td[u] = A[u * N + source];\n\t\t\t\tp[u] = source;\n\t\t\t}\n\t\t}\n\t}\n\n\twhile(!(q[dest] >= 0)) {\n\t\tint min = INT_MAX;\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tint u = i * N + j;\n\t\t\t\tif(d[u] < min &&!(s[u] >= 0)) {\n\t\t\t\t\tmin = d[u];\n\t\t\t\t\tq[u] = u;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor(int i = 0; i < N; i++) {\n\t\t\tfor(int j = 0; j < N; j++) {\n\t\t\t\tint u = i * N + j;\n\t\t\t\tif(q[u] >= 0) {\n\t\t\t\t\ts[u] = q[u];\n\t\t\t\t\tfor(int k = 0; k < N; k++) {\n\t\t\t\t\t\tint v = i * N + k;\n\t\t\t\t\t\tif(A[u * N + v] < INT_MAX && d[v] > d[u] + A[u * N + v]) {\n\t\t\t\t\t\t\td[v] = d[u] + A[u * N + v];\n\t\t\t\t\t\t\tp[v] = u;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tq[u] = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint t = dest;\n\tint dist = 0;\n\twhile(t >= 0) {\n\t\tdist += A[t * N + p[t]];\n\t\tt = p[t];\n\t}\n\t*pathLength = dist;\n}",
            "const int tIdx = blockIdx.y*gridDim.x*blockDim.x + blockIdx.x*blockDim.x + threadIdx.x;\n\tconst int tIdy = blockIdx.x*gridDim.y*blockDim.y + blockIdx.y*blockDim.y + threadIdx.y;\n\n\tint *minPathLength = new int[N];\n\tbool *visited = new bool[N];\n\tfor(int i=0; i<N; i++){\n\t\tminPathLength[i] = INT_MAX;\n\t\tvisited[i] = false;\n\t}\n\t\n\tminPathLength[source] = 0;\n\tvisited[source] = true;\n\t\n\tfor(int i=0; i<N; i++){\n\t\tfor(int j=0; j<N; j++){\n\t\t\tif(visited[j] == false && A[tIdx*N + j]!= 0 && minPathLength[j] > minPathLength[tIdy] + A[tIdx*N + j]){\n\t\t\t\tminPathLength[j] = minPathLength[tIdy] + A[tIdx*N + j];\n\t\t\t}\n\t\t}\n\t}\n\t\n\t*pathLength = minPathLength[dest];\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // Each thread will compute a single element in the result matrix\n    int index = i*N+j;\n    if (i >= N || j >= N) {\n        return;\n    }\n    // TODO\n}",
            "const int tidx = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int tidy = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (tidx >= N || tidy >= N)\n\t\treturn;\n\n\tif (A[tidx * N + tidy] == 0) {\n\t\t*pathLength = INT_MAX;\n\t\treturn;\n\t}\n\n\tint distance = 0;\n\n\tif (tidx == source && tidy == dest) {\n\t\t*pathLength = 0;\n\t\treturn;\n\t} else if (tidx == source) {\n\t\tdistance = 1;\n\t} else if (tidy == dest) {\n\t\tdistance = 1;\n\t} else {\n\t\treturn;\n\t}\n\n\tint shortestDistance = 0;\n\tint shortestSource = 0;\n\n\tshortestDistance = shortestDistance < distance? distance : shortestDistance;\n\tshortestSource = shortestSource < distance? distance : shortestSource;\n\n\t__syncthreads();\n\n\tfor (int i = 0; i < N; i++) {\n\t\tif (i == tidx) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (A[i * N + tidy]!= 0) {\n\t\t\tdistance = shortestPathLength(A, i, tidy, N);\n\t\t\tshortestDistance = shortestDistance < distance? distance : shortestDistance;\n\t\t\tshortestSource = shortestSource < distance? distance : shortestSource;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t*pathLength = shortestDistance + shortestSource;\n}",
            "int threadIdx_x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint threadIdx_y = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (threadIdx_x == 0 && threadIdx_y == 0) {\n\t\tint dist[N];\n\t\tbool visited[N];\n\t\tmemset(visited, 0, N * sizeof(bool));\n\t\tvisited[source] = true;\n\t\tfor (int i = 0; i < N; i++)\n\t\t\tdist[i] = 0;\n\t\tdist[source] = 0;\n\n\t\tfor (int k = 0; k < N; k++) {\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (i!= k && visited[i] &&!visited[j] && dist[j] > dist[i] + A[i * N + j]) {\n\t\t\t\t\t\tdist[j] = dist[i] + A[i * N + j];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tvisited[k] = true;\n\t\t}\n\t\t*pathLength = dist[dest];\n\t}\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x; //global index\n\tint j = threadIdx.y + blockIdx.y * blockDim.y; //global index\n\n\tif (i == j) //A(i,j) is on the diagonal\n\t{\n\t\tif (i == source) //source is i, update i's neighbours\n\t\t{\n\t\t\tfor (int col = 0; col < N; col++)\n\t\t\t{\n\t\t\t\tif (A[j*N + col] == 1 && j!= dest)\n\t\t\t\t{\n\t\t\t\t\tA[j*N + col] = i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (i == dest) //dest is i, update i's neighbours\n\t\t{\n\t\t\tfor (int col = 0; col < N; col++)\n\t\t\t{\n\t\t\t\tif (A[j*N + col] == 1 && j!= source)\n\t\t\t\t{\n\t\t\t\t\tA[j*N + col] = i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tfor (int col = 0; col < N; col++)\n\t\t\t{\n\t\t\t\tif (A[j*N + col] == 1 && j!= dest && j!= source)\n\t\t\t\t{\n\t\t\t\t\tA[j*N + col] = i + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\telse if (A[i*N + j] == 1 && i!= dest && i!= source && j!= dest && j!= source) //A(i,j) is non-zero and not on the diagonal\n\t{\n\t\tA[i*N + j] = 0; //set to zero\n\t\tfor (int col = 0; col < N; col++)\n\t\t{\n\t\t\tif (A[j*N + col] == 1 && j!= dest && j!= source)\n\t\t\t{\n\t\t\t\tA[j*N + col] = i + 1;\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads(); //sync threads in block\n\n\tif (i == source && i == dest) //source == dest\n\t{\n\t\tpathLength[0] = 0;\n\t}\n\telse if (i == source && A[j*N + i]!= 1) //source == i, pathLength[i] = 0\n\t{\n\t\tA[j*N + i] = 0;\n\t\tpathLength[i] = 0;\n\t}\n\telse if (A[i*N + j] == 1 && j == dest) //dest == j, pathLength[j] = 1\n\t{\n\t\tA[i*N + j] = 1;\n\t\tpathLength[j] = 1;\n\t}\n\t__syncthreads(); //sync threads in block\n\n\tif (i == dest && i!= source && A[j*N + i]!= 1) //dest == i, pathLength[i] = 1\n\t{\n\t\tA[j*N + i] = 0;\n\t\tpathLength[i] = 1;\n\t}\n\t__syncthreads(); //sync threads in block\n\n\tfor (int k = 0; k < N; k++)\n\t{\n\t\tif (i == source && j!= source && A[j*N + k] == i + 1 && A[i*N + k]!= 1) //source == i, pathLength[i] = pathLength[j] + 1\n\t\t{\n\t\t\tA[i*N + k] = A[j*N + k];\n\t\t\tpathLength[k] = pathLength[j] + 1;\n\t\t}\n\t\telse if (A[i*N + j] == i + 1 && A[i*N + k]!= 1 && A[j*N + k] == i + 1) //A(i,j) == i+1, A(i,k)",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n    int j = blockIdx.x * blockDim.x + threadIdx.x;\n    int k = threadIdx.y * blockDim.x + threadIdx.x;\n    __shared__ int localA[BLOCK_SIZE * BLOCK_SIZE];\n\n    if ((i < N) && (j < N)) {\n        localA[k] = A[i * N + j];\n    }\n    __syncthreads();\n\n    if ((i < N) && (j < N) && (localA[k] == 1)) {\n        atomicMin(&pathLength[dest], 1 + pathLength[j]);\n    }\n}",
            "size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint dist[N];\n\tbool visited[N];\n\tfor(int i=0;i<N;i++){\n\t\tdist[i]=-1;\n\t\tvisited[i]=false;\n\t}\n\tdist[source]=0;\n\tvisited[source]=true;\n\tfor(int i=0;i<N;i++){\n\t\tint current=source;\n\t\tfor(int j=0;j<N;j++){\n\t\t\tif(A[current*N+j]>0){\n\t\t\t\tif(visited[j]==false){\n\t\t\t\t\tvisited[j]=true;\n\t\t\t\t\tdist[j]=dist[current]+1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcurrent=get_min(dist,visited,N);\n\t}\n\t*pathLength=dist[dest];\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid == source) {\n\t\t*pathLength = 0;\n\t}\n\tif (tid == dest) {\n\t\t*pathLength = A[tid * N + source];\n\t}\n}",
            "int tid = blockIdx.y * gridDim.x + blockIdx.x;\n\tif (tid >= N * N) return;\n\n\tint i = tid / N;\n\tint j = tid % N;\n\n\tif (i == source && j == dest) {\n\t\tpathLength[i] = 0;\n\t}\n\telse if (i == dest && j == source) {\n\t\tpathLength[i] = 0;\n\t}\n\telse if (i == source && j!= dest) {\n\t\tpathLength[j] = -1;\n\t}\n\telse if (i == dest && j!= source) {\n\t\tpathLength[i] = -1;\n\t}\n\telse if (A[tid] == 1) {\n\t\tpathLength[i] = pathLength[j] + 1;\n\t}\n}",
            "int *dist = new int[N];\n    bool *visited = new bool[N];\n    for (int i = 0; i < N; i++) {\n        dist[i] = INF;\n        visited[i] = false;\n    }\n\n    dist[source] = 0;\n    visited[source] = true;\n\n    bool found = false;\n    while (!found) {\n        int min = INF;\n        for (int i = 0; i < N; i++) {\n            if (!visited[i] && dist[i] < min) {\n                min = dist[i];\n            }\n        }\n\n        found = true;\n        for (int i = 0; i < N; i++) {\n            if (!visited[i] && min == dist[i] && A[i * N + source]!= 0) {\n                dist[i] += A[i * N + source];\n                found = false;\n            }\n        }\n\n        for (int i = 0; i < N; i++) {\n            if (!visited[i] && dist[i] < INF) {\n                visited[i] = true;\n            }\n        }\n    }\n\n    *pathLength = dist[dest];\n\n    delete[] dist;\n    delete[] visited;\n}",
            "// Fill in the body of the kernel.\n}",
            "const int j = blockDim.x * blockIdx.x + threadIdx.x; // Column index\n    const int i = blockDim.y * blockIdx.y + threadIdx.y; // Row index\n\n    __shared__ int row[BLOCK_SIZE];\n    __shared__ bool rowVisited[BLOCK_SIZE];\n\n    // Read row into shared memory\n    if (i < N && threadIdx.y == 0) {\n        row[threadIdx.x] = A[i * N + j];\n        rowVisited[threadIdx.x] = false;\n    }\n\n    __syncthreads();\n\n    // Use BFS to compute the length of the shortest path from source to dest\n    if (i < N && j < N && i!= j) {\n        if (i == source && row[j] == 1) {\n            rowVisited[j] = true;\n        } else if (i!= source && row[j] == 1 && rowVisited[j] == true) {\n            rowVisited[i] = true;\n        }\n    }\n\n    __syncthreads();\n\n    // Check if the destination is in the visited list\n    if (i < N && j < N && rowVisited[dest] == true) {\n        *pathLength = min(j, *pathLength);\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  if (i == dest && j == source) {\n    pathLength[0] = 1;\n  } else if (i == source && j == source) {\n    pathLength[0] = 0;\n  } else {\n    pathLength[0] = -1;\n  }\n}",
            "int i = blockIdx.x;\n    int j = blockIdx.y;\n    if (i < N && j < N) {\n        if (A[i * N + j] && i == source && j == dest) {\n            pathLength[0] = 1;\n        }\n    }\n}",
            "// TODO: Compute the length of the shortest path from source to dest\n    // Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n    int j = threadIdx.x;\n    int i = blockIdx.x;\n\n    if (i == source && j == dest) {\n        atomicAdd(pathLength, 1);\n    }\n\n    if (i == dest && j == source) {\n        atomicAdd(pathLength, 1);\n    }\n\n    if (j == source && i == dest) {\n        atomicAdd(pathLength, 1);\n    }\n\n    if (j == dest && i == source) {\n        atomicAdd(pathLength, 1);\n    }\n}",
            "int tid = threadIdx.y * gridDim.x + blockIdx.x;\n\tint i = tid / N;\n\tint j = tid % N;\n\n\tif (tid == 0)\n\t\t*pathLength = 0;\n\n\t// check if the current cell is unvisited\n\tif (i!= source && i!= dest && j!= source && j!= dest) {\n\t\tif (A[i * N + j] == 1)\n\t\t\t*pathLength = A[i * N + j];\n\t}\n\n\t// do not consider cycles\n\tif (i == j)\n\t\treturn;\n\n\t// check if the current cell is a neighbor of the source or destination\n\t// and update the path length\n\tif (A[source * N + i] == 1 && i == j)\n\t\t*pathLength = 1;\n\telse if (A[dest * N + j] == 1 && i == source)\n\t\t*pathLength = 1;\n\n\t__syncthreads();\n\n\tint newPath = 0;\n\tif (A[i * N + j] == 1)\n\t\tnewPath = *pathLength + A[i * N + j];\n\n\t// update the path length if a shorter path exists\n\tif (newPath < *pathLength)\n\t\t*pathLength = newPath;\n}",
            "// Insert your code here\n\n  // __syncthreads();\n  int i = blockIdx.x;\n  int j = blockIdx.y;\n  int k = blockIdx.z;\n\n  int blockSize = blockDim.x;\n  int blockIdx_x = blockIdx.x;\n  int blockIdx_y = blockIdx.y;\n  int blockIdx_z = blockIdx.z;\n  int threadIdx_x = threadIdx.x;\n  int threadIdx_y = threadIdx.y;\n  int threadIdx_z = threadIdx.z;\n\n  int cur_x = i * blockSize + threadIdx_x;\n  int cur_y = j * blockSize + threadIdx_y;\n  int cur_z = k * blockSize + threadIdx_z;\n\n  __shared__ int s_A[256];\n  __shared__ int s_pathLen[256];\n  int myPathLen = 0;\n  if(i == 0 && j == 0 && k == 0 && threadIdx_x == 0 && threadIdx_y == 0 && threadIdx_z == 0) {\n    for(int ii = 0; ii < N; ii++){\n      for(int jj = 0; jj < N; jj++){\n        for(int kk = 0; kk < N; kk++){\n          s_A[ii*N*N+jj*N+kk] = A[ii*N*N+jj*N+kk];\n        }\n      }\n    }\n    s_pathLen[0] = 0;\n  }\n  __syncthreads();\n\n  // if(threadIdx_x == 0 && threadIdx_y == 0 && threadIdx_z == 0) {\n  //   printf(\"blockIdx_x: %d, blockIdx_y: %d, blockIdx_z: %d, threadIdx_x: %d, threadIdx_y: %d, threadIdx_z: %d, cur_x: %d, cur_y: %d, cur_z: %d, blockSize: %d, N: %d\\n\", blockIdx_x, blockIdx_y, blockIdx_z, threadIdx_x, threadIdx_y, threadIdx_z, cur_x, cur_y, cur_z, blockSize, N);\n  // }\n\n  int cnt = 0;\n  while(cur_x < N && cur_y < N && cur_z < N){\n    if(cur_x == dest && cur_y == dest && cur_z == dest){\n      s_pathLen[i*blockSize+j*blockSize*blockSize+k*blockSize*blockSize*blockSize] = myPathLen;\n    }\n    if(s_A[cur_x*N*N+cur_y*N+cur_z] == 1){\n      cur_z++;\n      myPathLen++;\n      if(cur_z == N){\n        cur_z = 0;\n        cur_y++;\n        myPathLen++;\n      }\n      if(cur_y == N){\n        cur_y = 0;\n        cur_x++;\n        myPathLen++;\n      }\n    }\n    else{\n      cur_z++;\n      if(cur_z == N){\n        cur_z = 0;\n        cur_y++;\n      }\n      if(cur_y == N){\n        cur_y = 0;\n        cur_x++;\n      }\n    }\n    cnt++;\n    __syncthreads();\n  }\n  __syncthreads();\n  if(threadIdx_x == 0 && threadIdx_y == 0 && threadIdx_z == 0){\n    for(int ii = 0; ii < blockDim.x; ii++){\n      for(int jj = 0; jj < blockDim.y; jj++){\n        for(int kk = 0; kk < blockDim.z; kk++){\n          if(s_pathLen[ii*blockDim.y*blockDim.z+jj*blockDim",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n  int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n  // Compute shortest path length for each (row, col)\n  if (row == source && col == dest) {\n    *pathLength = 0;\n  } else if (row < N && col < N && A[row * N + col] == 1) {\n    // Shortest path is already computed, don't recompute\n    *pathLength = INT_MAX;\n  } else if (row == dest && col == source) {\n    *pathLength = 1;\n  } else if (row < N && col < N) {\n    // Compute shortest path length\n    *pathLength = 1;\n\n    // Find shortest path between row and col for all values in the adjacency matrix\n    for (int i = 0; i < N; i++) {\n      // Check if path from row to i is shorter\n      if (A[row * N + i] == 1) {\n        int tmp = INT_MAX;\n        shortestPathLength(A, N, row, i, &tmp);\n        *pathLength = min(*pathLength, tmp + 1);\n      }\n    }\n  } else {\n    // The rest of the matrix is not used, ignore\n    return;\n  }\n\n}",
            "int index = threadIdx.x + blockIdx.x * blockDim.x;\n\tint stride = blockDim.x * gridDim.x;\n\tint next_source = 0;\n\t__shared__ int visited[BLOCK_SIZE];\n\n\tint distance = 0;\n\n\tfor (int i = 0; i < N; i += BLOCK_SIZE) {\n\t\tif (index < N) {\n\t\t\tnext_source = A[source * N + index];\n\t\t\tvisited[threadIdx.x] = next_source;\n\t\t\t__syncthreads();\n\n\t\t\tfor (int j = 0; j < BLOCK_SIZE; j++) {\n\t\t\t\tif (visited[j]!= 0) {\n\t\t\t\t\tdistance = distance + 1;\n\t\t\t\t\tsource = visited[j];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (index == dest) {\n\t\t*pathLength = distance;\n\t}\n}",
            "int x = blockIdx.x;\n\tint y = blockIdx.y;\n\tint *data = (int *)((char *)A + y * N * sizeof(int));\n\n\t__shared__ int sdata[BLOCK_SIZE][BLOCK_SIZE];\n\n\tint index = threadIdx.y * BLOCK_SIZE + threadIdx.x;\n\tsdata[threadIdx.y][threadIdx.x] = data[index];\n\n\t__syncthreads();\n\n\tif (x == y && sdata[0][0]!= 0 && source!= dest) {\n\t\tpathLength[0] = 1;\n\t} else if (x == y && sdata[0][0] == 0 && source == dest) {\n\t\tpathLength[0] = 0;\n\t} else if (x == y && sdata[0][0] == 0) {\n\t\tpathLength[0] = -1;\n\t} else if (sdata[threadIdx.x][threadIdx.y]!= 0) {\n\t\tpathLength[0] = 1 + sdata[threadIdx.y][threadIdx.x];\n\t} else {\n\t\tpathLength[0] = -1;\n\t}\n}",
            "int tidx = blockIdx.x * blockDim.x + threadIdx.x;\n    int tidy = blockIdx.y * blockDim.y + threadIdx.y;\n    if(tidx == tidy && tidx < N) {\n        int temp = A[tidx*N+tidx];\n        int length = 0;\n        int dist = 0;\n        while(temp!= dest){\n            length++;\n            dist = A[tidx*N+temp];\n            temp = dist;\n        }\n        if(length!= 0)\n            pathLength[tidx] = length;\n    }\n}",
            "// TODO: Implement me!\n\n}",
            "int index = blockIdx.x * blockDim.x + threadIdx.x;\n\n\t__shared__ int sdata[BLOCK_SIZE];\n\t__shared__ bool finished[BLOCK_SIZE];\n\t__shared__ bool all_finished;\n\n\tint tid = threadIdx.x;\n\tint bid = blockIdx.x;\n\tint nblocks = gridDim.x;\n\n\t// initialization\n\tsdata[tid] = -1;\n\tfinished[tid] = false;\n\tif (tid == 0) {\n\t\tall_finished = false;\n\t}\n\t__syncthreads();\n\n\twhile (!all_finished) {\n\t\t__syncthreads();\n\t\tint count = 0;\n\t\t// source is 0\n\t\tif (index == source) {\n\t\t\tsdata[tid] = 0;\n\t\t}\n\n\t\t__syncthreads();\n\n\t\t// compute shortest distance\n\t\tif (sdata[tid]!= -1) {\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tint w = A[source * N + i];\n\t\t\t\tif (w!= 0) {\n\t\t\t\t\tif (sdata[i] == -1) {\n\t\t\t\t\t\tsdata[i] = sdata[tid] + w;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsdata[i] = min(sdata[i], sdata[tid] + w);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\n\t\t// mark finished\n\t\tif (sdata[tid]!= -1 && index == dest) {\n\t\t\tfinished[tid] = true;\n\t\t}\n\n\t\t__syncthreads();\n\n\t\t// check if all threads are finished\n\t\tif (tid == 0) {\n\t\t\tcount = 0;\n\t\t\tfor (int i = 0; i < nblocks; i++) {\n\t\t\t\tcount += finished[i];\n\t\t\t}\n\n\t\t\tif (count == nblocks) {\n\t\t\t\tall_finished = true;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\t}\n\n\tif (index == dest) {\n\t\t*pathLength = sdata[tid];\n\t}\n}",
            "// TODO: Implement this function.\n}",
            "const int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (i >= N || j >= N) return;\n\tint dist = (i == source)? 1 : A[i * N + j];\n\tint done = 0;\n\twhile (dist!= 0 &&!done) {\n\t\tint oldDist = dist;\n\t\tdist = min(dist, A[i * N + j]);\n\t\tdone = (oldDist == dist);\n\t}\n\tif (i == dest) *pathLength = dist;\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n  int j = blockIdx.x * blockDim.x + threadIdx.x;\n  int n = blockDim.y * gridDim.y;\n  int m = blockDim.x * gridDim.x;\n  if (i >= N || j >= N)\n    return;\n\n  // TODO: fill this in\n}",
            "int i = blockIdx.x;\n    int j = blockIdx.y;\n    int rowLength = N - 1;\n    int colLength = N - 1;\n    __shared__ int cache[1024];\n\n    if (i == 0 && j == 0) {\n        // the first thread initializes the values in the cache to -1\n        for (int k = threadIdx.x; k < 1024; k += blockDim.x) {\n            cache[k] = -1;\n        }\n        __syncthreads();\n\n        // the first thread runs the loop\n        if (threadIdx.x == 0) {\n            cache[source] = 0;\n            cache[source + N] = 0;\n            int start = clock();\n            bool done = false;\n            while (true) {\n                // do the forward pass\n                for (int k = 0; k <= rowLength; k++) {\n                    int next = cache[k];\n                    if (next!= -1) {\n                        for (int l = 0; l <= colLength; l++) {\n                            int neighbor = l + N * k;\n                            if (A[neighbor] == 1 && cache[neighbor] == -1) {\n                                cache[neighbor] = next + 1;\n                            }\n                        }\n                    }\n                }\n\n                // do the backward pass\n                for (int k = colLength; k >= 0; k--) {\n                    int next = cache[k];\n                    if (next!= -1) {\n                        for (int l = colLength; l >= 0; l--) {\n                            int neighbor = l + N * k;\n                            if (A[neighbor] == 1 && cache[neighbor] == -1) {\n                                cache[neighbor] = next + 1;\n                            }\n                        }\n                    }\n                }\n\n                // if all paths are explored, the answer is found in the cache\n                if (done) {\n                    break;\n                }\n\n                // if the destination is found in the cache, the answer is found\n                if (cache[dest]!= -1) {\n                    done = true;\n                    break;\n                }\n\n                // check if it is time to stop exploring\n                int end = clock();\n                double elapsed = ((double) (end - start)) / CLOCKS_PER_SEC;\n                if (elapsed > 5) {\n                    done = true;\n                }\n            }\n        }\n        __syncthreads();\n        pathLength[0] = cache[dest];\n    }\n}",
            "// get the x, y position in the matrix\n\tint x = blockIdx.x * blockDim.x + threadIdx.x;\n\tint y = blockIdx.y * blockDim.y + threadIdx.y;\n\t\n\tif (x < N && y < N) {\n\t\tif (x == source) {\n\t\t\t// we have found the source, so set the starting point and do a BFS\n\t\t\t// to find the destination\n\t\t\tBFS(A, N, source, dest, pathLength);\n\t\t}\n\t}\n}",
            "int threadRow = threadIdx.y + blockIdx.y * blockDim.y;\n\tint threadCol = threadIdx.x + blockIdx.x * blockDim.x;\n\n\t// Compute the shortest path from source to dest.\n\tif (threadRow < N && threadCol < N) {\n\t\t// Perform the computation for this thread only if it is valid.\n\t\tint dist = A[source * N + threadRow];\n\t\tint prev = source;\n\t\twhile (threadRow!= dest) {\n\t\t\tprev = threadRow;\n\t\t\tthreadRow = A[threadRow * N + dest];\n\t\t\tdist += A[prev * N + threadRow];\n\t\t}\n\t\tpathLength[source] = dist;\n\t}\n}",
            "int n = threadIdx.x;\n\tint m = blockIdx.x;\n\n\tif (n < N && m < N && A[m * N + n]!= 0) {\n\t\tif (n == m) {\n\t\t\t*pathLength = 1;\n\t\t}\n\t\telse {\n\t\t\tatomicMin(pathLength, 1 + *pathLength);\n\t\t}\n\t}\n}",
            "// You may use the following code as a reference\n\n\tint tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (tid == dest) {\n\t\t*pathLength = 0;\n\t\treturn;\n\t}\n\n\tint count = 0;\n\tint visited[N];\n\tfor (int i = 0; i < N; i++)\n\t\tvisited[i] = 0;\n\n\tint currNode = source;\n\twhile (currNode!= dest) {\n\t\tcount++;\n\t\tvisited[currNode] = 1;\n\t\tcurrNode = -1;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (!visited[i]) {\n\t\t\t\tif (A[currNode * N + i] == 1) {\n\t\t\t\t\tcurrNode = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t*pathLength = count;\n}",
            "int tid = blockDim.x * blockIdx.x + threadIdx.x;\n  if (tid == source) {\n    *pathLength = 0;\n    __threadfence();\n  }\n  __syncthreads();\n\n  for (int i = 0; i < N; i++) {\n    if (tid == source) {\n      for (int j = 0; j < N; j++) {\n        if (A[N * tid + j] && i!= j && atomicMin(pathLength, i + A[N * j + dest]) == i) {\n          break;\n        }\n      }\n    }\n    __syncthreads();\n  }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\n\t__shared__ int sdata[BLOCK_DIM*BLOCK_DIM];\n\tint idx = threadIdx.y * blockDim.x + threadIdx.x;\n\tsdata[idx] = INT_MAX;\n\t__syncthreads();\n\n\tif (i >= N || j >= N)\n\t\treturn;\n\n\tif (i == source && A[i * N + j] == 1) {\n\t\tsdata[idx] = 0;\n\t} else if (i == j) {\n\t\tsdata[idx] = INT_MAX;\n\t} else {\n\t\tsdata[idx] = A[i * N + j];\n\t}\n\n\t__syncthreads();\n\tif (idx == 0) {\n\t\tfor (int k = 0; k < BLOCK_DIM * BLOCK_DIM; k++) {\n\t\t\tif (sdata[k] < sdata[0]) {\n\t\t\t\tsdata[0] = sdata[k];\n\t\t\t}\n\t\t}\n\t}\n\t__syncthreads();\n\tif (i == dest && j == source && sdata[0] < INT_MAX) {\n\t\t*pathLength = sdata[0];\n\t}\n}",
            "// TODO: fill this in\n   int i = blockIdx.x;\n   int j = blockIdx.y;\n   int k = threadIdx.x;\n   if (i == dest && j == source) {\n      atomicAdd(&pathLength[0], A[k * N + j]);\n   }\n}",
            "int i = blockDim.x * blockIdx.x + threadIdx.x;\n\tint j = blockDim.y * blockIdx.y + threadIdx.y;\n\n\tif(i == source && j == dest) {\n\t\tpathLength[0] = 0;\n\t}\n\n\t__syncthreads();\n\n\tint *dist;\n\tdist = new int[N];\n\n\tdist[source] = 0;\n\n\tfor(int k = 0; k < N; k++) {\n\t\tif(i == source) {\n\t\t\tdist[j] = A[source * N + j];\n\t\t}\n\t\t__syncthreads();\n\t\tif(dist[j] > dist[i] + A[i * N + j] && i!= j) {\n\t\t\tdist[j] = dist[i] + A[i * N + j];\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif(i == source && j == dest) {\n\t\tpathLength[0] = dist[j];\n\t}\n\n\tdelete dist;\n}",
            "// TODO: implement this function\n\tint *dist = (int *)malloc(N * sizeof(int));\n\tint *prev = (int *)malloc(N * sizeof(int));\n\tint *visited = (int *)malloc(N * sizeof(int));\n\tint *changed = (int *)malloc(N * sizeof(int));\n\tint *flag = (int *)malloc(N * sizeof(int));\n\n\tint *changed_d;\n\tint *visited_d;\n\tint *prev_d;\n\tint *dist_d;\n\tint *flag_d;\n\n\t// Allocate memory on the device\n\tcudaMalloc((void **)&changed_d, N * sizeof(int));\n\tcudaMalloc((void **)&visited_d, N * sizeof(int));\n\tcudaMalloc((void **)&prev_d, N * sizeof(int));\n\tcudaMalloc((void **)&dist_d, N * sizeof(int));\n\tcudaMalloc((void **)&flag_d, N * sizeof(int));\n\n\t// Initialize memory on the device\n\tcudaMemcpy(changed_d, changed, N * sizeof(int), cudaMemcpyHostToDevice);\n\tcudaMemcpy(visited_d, visited, N * sizeof(int), cudaMemcpyHostToDevice);\n\tcudaMemcpy(prev_d, prev, N * sizeof(int), cudaMemcpyHostToDevice);\n\tcudaMemcpy(dist_d, dist, N * sizeof(int), cudaMemcpyHostToDevice);\n\tcudaMemcpy(flag_d, flag, N * sizeof(int), cudaMemcpyHostToDevice);\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tdist[i] = INF;\n\t\tprev[i] = INF;\n\t\tchanged[i] = 1;\n\t}\n\n\t// Initialize\n\tdist[source] = 0;\n\tprev[source] = source;\n\tvisited[source] = 1;\n\tflag[source] = 1;\n\n\tint count = 1;\n\twhile (count < N) {\n\t\tcudaMemcpy(changed_d, changed, N * sizeof(int), cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(visited_d, visited, N * sizeof(int), cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(prev_d, prev, N * sizeof(int), cudaMemcpyHostToDevice);\n\t\tcudaMemcpy(dist_d, dist, N * sizeof(int), cudaMemcpyHostToDevice);\n\n\t\t// Visit unvisited adjacent vertices of the current vertex\n\t\t// with minimum distance\n\t\tupdateVertex<<<N, N>>>(A, N, visited_d, dist_d, prev_d, changed_d, flag_d);\n\n\t\tcudaMemcpy(changed, changed_d, N * sizeof(int), cudaMemcpyDeviceToHost);\n\t\tcudaMemcpy(visited, visited_d, N * sizeof(int), cudaMemcpyDeviceToHost);\n\t\tcudaMemcpy(prev, prev_d, N * sizeof(int), cudaMemcpyDeviceToHost);\n\t\tcudaMemcpy(dist, dist_d, N * sizeof(int), cudaMemcpyDeviceToHost);\n\t\tcudaMemcpy(flag, flag_d, N * sizeof(int), cudaMemcpyDeviceToHost);\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (changed[i] == 1) {\n\t\t\t\tchanged[i] = 0;\n\t\t\t\tcount++;\n\t\t\t}\n\t\t}\n\t}\n\t*pathLength = dist[dest];\n\n\t// Free memory on the device\n\tcudaFree(changed_d);\n\tcudaFree(visited_d);\n\tcudaFree(prev_d);\n\tcudaFree(dist_d);\n\tcudaFree(flag_d);\n\n\t// Free memory on the host\n\tfree(dist);\n\tfree(prev);\n\tfree(visited);\n\tfree(changed);\n\tfree(flag);\n}",
            "int u = blockIdx.x;\n\tint v = blockIdx.y;\n\tint k = blockIdx.z;\n\tint i = threadIdx.x;\n\n\textern __shared__ int sdata[];\n\n\tint pos = 0;\n\tint min = 10000;\n\tint minpos = -1;\n\n\twhile (pos < N) {\n\t\tint x = i + pos;\n\t\tint y = u;\n\t\tif (u!= v && u!= k && v!= k && A[u*N + v]!= 0 && A[v*N + k]!= 0) {\n\t\t\tint dist = A[u*N + v] + A[v*N + k];\n\t\t\tif (dist < min) {\n\t\t\t\tmin = dist;\n\t\t\t\tminpos = x;\n\t\t\t}\n\t\t}\n\n\t\tpos += blockDim.x;\n\t}\n\n\tsdata[i] = min;\n\n\t__syncthreads();\n\n\tint thid = threadIdx.x;\n\n\tfor (int stride = blockDim.x / 2; stride > 0; stride /= 2) {\n\t\tif (thid < stride) {\n\t\t\tint y = sdata[thid + stride];\n\t\t\tif (sdata[thid] > y)\n\t\t\t\tsdata[thid] = y;\n\t\t}\n\n\t\t__syncthreads();\n\t}\n\n\tif (thid == 0) {\n\t\tpathLength[minpos] = sdata[0];\n\t}\n}",
            "int tid = blockDim.x*blockIdx.y*gridDim.x + blockDim.x*blockIdx.x + threadIdx.x;\n  if (tid >= N) return;\n\n  // TODO\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // If we are not in the matrix, do nothing\n    if (i >= N || j >= N) {\n        return;\n    }\n\n    // If we are in the source, initialize\n    if (i == source) {\n        if (j == source) {\n            pathLength[i * N + j] = 0;\n        } else {\n            pathLength[i * N + j] = INFINITY;\n        }\n        return;\n    }\n\n    // If we are not in the source, do nothing\n    if (i!= source) {\n        return;\n    }\n\n    // If the cell is not reachable, do nothing\n    if (A[i * N + j] == 0) {\n        return;\n    }\n\n    // Else we are in the matrix and we are in the source, compute the path length\n    int tmp = pathLength[source * N + j];\n    if (tmp!= INFINITY) {\n        pathLength[i * N + j] = tmp + 1;\n    }\n}",
            "int row = blockIdx.x * blockDim.x + threadIdx.x;\n   int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n   // Use dynamic shared memory to store the shortest path from the source to each node.\n   __shared__ int pathLengths[BLOCK_SIZE][BLOCK_SIZE];\n\n   // Store the length of the shortest path from the source to the current node.\n   pathLengths[threadIdx.y][threadIdx.x] = row == source? 0 : MAX_DIST;\n\n   __syncthreads();\n\n   // Iterate through the rows of the matrix to find the shortest path from the source to each node.\n   for (int i = 0; i < N; ++i) {\n      __syncthreads();\n\n      // Find the shortest path to the next node using the shortest path to the current node.\n      if (row < N && col < N && A[row*N + col] > 0) {\n         int newPathLength = pathLengths[threadIdx.y][threadIdx.x] + A[row*N + col];\n\n         // Compare the shortest path to the next node with the current shortest path length.\n         // The shared memory version of pathLengths is updated with the shorter path.\n         atomicMin(&pathLengths[threadIdx.y + 1][threadIdx.x + 1], newPathLength);\n      }\n   }\n\n   // Store the length of the shortest path from the source to the current node.\n   if (row == dest) {\n      pathLength[0] = pathLengths[threadIdx.y][threadIdx.x];\n   }\n}",
            "// TODO: Replace the following code with your own implementation\n\tint i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint tid = threadIdx.x;\n\tint nthreads = blockDim.x;\n\t// shared memory of size nthreads for storing distance values\n\textern __shared__ int sdata[];\n\tsdata[tid] = 0;\n\t__syncthreads();\n\tint ibegin = N * tid;\n\tint iend = N * (tid + 1);\n\tif(i==j){\n\t\tif(i == source){\n\t\t\tsdata[tid] = 1;\n\t\t}\n\t\telse{\n\t\t\tsdata[tid] = -1;\n\t\t}\n\t}\n\telse if(i<j){\n\t\tsdata[tid] = A[i*N + j];\n\t}\n\telse{\n\t\tsdata[tid] = A[j*N + i];\n\t}\n\t__syncthreads();\n\tint dist = sdata[tid];\n\t// TODO: Implement the algorithm to compute the shortest path length\n\t//       You can use the atomic operations: atomicMin(), atomicMax(), atomicAdd()\n\t//       You can use the barrier instruction: __syncthreads()\n\n\t__syncthreads();\n\tsdata[tid] = dist;\n\t__syncthreads();\n\tfor(unsigned int s = 1; s < nthreads; s *= 2){\n\t\tint index = 2 * s * tid;\n\t\tif(index < nthreads){\n\t\t\tif(sdata[index] > 0 && sdata[index + s] > 0){\n\t\t\t\tsdata[index] = 1 + min(sdata[index], sdata[index + s]);\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\t//sdata[tid] = dist;\n\t//__syncthreads();\n\t//for(unsigned int s = 1; s < nthreads; s *= 2){\n\t//\tint index = 2 * s * tid;\n\t//\tif(index < nthreads){\n\t//\t\tif(sdata[index] > 0 && sdata[index + s] > 0){\n\t//\t\t\tsdata[index] = min(sdata[index], sdata[index + s]);\n\t//\t\t}\n\t//\t}\n\t//\t__syncthreads();\n\t//}\n\tpathLength[i*N + j] = sdata[tid];\n\t//__syncthreads();\n\t//if(ibegin <= i && i < iend){\n\t//\tfor(int k = 0; k < N; ++k){\n\t//\t\tif(A[i*N + k] > 0 && A[k*N + j] > 0){\n\t//\t\t\tdist = 1 + min(dist, pathLength[i*N + k] + pathLength[k*N + j]);\n\t//\t\t}\n\t//\t}\n\t//\tpathLength[i*N + j] = dist;\n\t//}\n}",
            "// TODO: Fill this in\n}",
            "// Your code here.\n}",
            "// Insert code to compute the shortest path length\n}",
            "// YOUR CODE HERE\n\t__shared__ int path[BLOCK_SIZE][BLOCK_SIZE];\n\t__shared__ bool is_visited[BLOCK_SIZE][BLOCK_SIZE];\n\t__shared__ int dist[BLOCK_SIZE][BLOCK_SIZE];\n\t__shared__ int dist_out[BLOCK_SIZE][BLOCK_SIZE];\n\t__shared__ int visited_cnt[BLOCK_SIZE];\n\tint tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\tint bx = blockIdx.x;\n\tint by = blockIdx.y;\n\tint i, j;\n\n\tint i_n = by * BLOCK_SIZE + ty;\n\tint j_n = bx * BLOCK_SIZE + tx;\n\n\tif (i_n < N && j_n < N && i_n >= 0 && j_n >= 0) {\n\t\tpath[ty][tx] = A[i_n * N + j_n];\n\t\tdist[ty][tx] = path[ty][tx];\n\t\tdist_out[ty][tx] = path[ty][tx];\n\t\tis_visited[ty][tx] = false;\n\t}\n\n\tif (ty == 0)\n\t\tvisited_cnt[tx] = 0;\n\n\t__syncthreads();\n\n\tif (i_n >= N || j_n >= N || i_n < 0 || j_n < 0)\n\t\treturn;\n\n\tif (i_n == source) {\n\t\tdist[ty][tx] = 0;\n\t\tis_visited[ty][tx] = true;\n\t}\n\n\t__syncthreads();\n\n\tfor (int k = 0; k < N; k++) {\n\t\t__syncthreads();\n\t\tif (j_n == source && i_n!= j_n && i_n!= k) {\n\t\t\tif (!is_visited[k][tx]) {\n\t\t\t\tdist[ty][tx] = dist[ty][tx] + dist[k][tx];\n\t\t\t}\n\t\t}\n\n\t\tif (j_n == k && i_n!= j_n) {\n\t\t\tif (!is_visited[ty][k]) {\n\t\t\t\tdist[ty][tx] = dist[ty][tx] + dist[ty][k];\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\n\tif (ty == 0)\n\t\tatomicAdd(&visited_cnt[tx], 1);\n\n\t__syncthreads();\n\n\tif (visited_cnt[tx] >= N - 1) {\n\t\tdist_out[ty][tx] = dist[ty][tx];\n\t}\n\n\t__syncthreads();\n\n\tif (j_n == dest) {\n\t\tpathLength[0] = dist_out[ty][tx];\n\t\treturn;\n\t}\n}",
            "int i = blockIdx.x;\n  int j = blockIdx.y;\n  if (i == j) {\n    int dij = 0;\n    int prev = source;\n    int curr = j;\n    while (curr!= dest) {\n      dij++;\n      curr = A[prev * N + curr];\n    }\n    pathLength[i] = dij;\n  }\n}",
            "// Get the position of the thread in the grid\n    int i = threadIdx.y;\n    int j = threadIdx.x;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n\n    // Allocate shared memory to store the adjacency matrix and the distance from the source\n    __shared__ int A_shared[TILE_DIM][TILE_DIM+1];\n    __shared__ int dist[TILE_DIM][TILE_DIM+1];\n    __shared__ bool has_path;\n\n    // Initialize distance\n    if (i == 0) {\n        dist[j][0] = -1;\n    }\n    else {\n        dist[j][0] = -INFINITY;\n    }\n\n    // Initialize adjacency matrix\n    A_shared[i][j] = A[by*TILE_DIM+i + bx*N*TILE_DIM+j];\n\n    // Synchronize\n    __syncthreads();\n\n    // Compute the length of the shortest path from source to dest\n    for (int k = 0; k < N/TILE_DIM; k++) {\n        // Update the distance matrix\n        dist[j][i+1] = dist[j][i] + A_shared[i][j];\n\n        // Check if the path exists\n        if (dist[j][i+1] >= 0 && A_shared[i][j] == 0 && i==0 && j==0 && k==0) {\n            has_path = true;\n        }\n\n        // Synchronize\n        __syncthreads();\n    }\n\n    // Store the path length\n    if (has_path && i==0 && j==0) {\n        *pathLength = dist[j][N/TILE_DIM];\n    }\n}",
            "// Write your code here\n\n\tint col = blockDim.x * blockIdx.x + threadIdx.x;\n\tif (col >= N) {\n\t\treturn;\n\t}\n\n\tint dist = INT_MAX;\n\tif (col == source) {\n\t\tdist = 0;\n\t}\n\n\t__shared__ int blockPaths[1024];\n\t__shared__ int blockUpdated[1024];\n\n\tfor (int iter = 0; iter < N - 1; iter++) {\n\n\t\tblockPaths[threadIdx.x] = dist;\n\t\tblockUpdated[threadIdx.x] = 0;\n\n\t\t__syncthreads();\n\n\t\tif (iter > 0) {\n\t\t\tint tmpDist = INT_MAX;\n\t\t\tfor (int i = 0; i < blockDim.x; i++) {\n\t\t\t\tint currDist = blockPaths[i];\n\t\t\t\tif (currDist < tmpDist) {\n\t\t\t\t\ttmpDist = currDist;\n\t\t\t\t}\n\t\t\t}\n\t\t\tdist = tmpDist + 1;\n\t\t\tblockPaths[threadIdx.x] = dist;\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tint j = A[col + col * N];\n\t\tif (j < INT_MAX) {\n\t\t\tint tmpDist = blockPaths[j];\n\t\t\tif (dist + 1 < tmpDist) {\n\t\t\t\tblockPaths[j] = dist + 1;\n\t\t\t\tblockUpdated[j] = 1;\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\n\t\tint tmpDist = INT_MAX;\n\t\tfor (int i = 0; i < blockDim.x; i++) {\n\t\t\tint currDist = blockPaths[i];\n\t\t\tif (currDist < tmpDist) {\n\t\t\t\ttmpDist = currDist;\n\t\t\t}\n\t\t}\n\t\tdist = tmpDist + 1;\n\t}\n\n\tif (col == dest) {\n\t\tpathLength[0] = blockPaths[col];\n\t}\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint threadIdxX = threadIdx.x;\n\tint threadIdxY = threadIdx.y;\n\n\t__shared__ int pathLengthShared[16][16];\n\n\t// if (i < N && j < N && i!= j)\n\t// \tpathLengthShared[threadIdxX][threadIdxY] = INT_MAX;\n\tif (i < N && j < N && i!= j) {\n\t\tint threadId = threadIdx.x + threadIdx.y * blockDim.x;\n\t\tint threadsInBlock = blockDim.x * blockDim.y;\n\t\tint halfThreadsInBlock = threadsInBlock / 2;\n\n\t\twhile (threadId < threadsInBlock) {\n\t\t\tpathLengthShared[threadIdxX][threadIdxY] = INT_MAX;\n\t\t\tthreadId += halfThreadsInBlock;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\tif (i == source && i!= j) {\n\t\tpathLengthShared[threadIdxX][threadIdxY] = 0;\n\t}\n\n\t__syncthreads();\n\n\tint offset = 0;\n\n\twhile (offset < N - 1) {\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (i!= j && A[i * N + j] == 1 && pathLengthShared[threadIdxX][threadIdxY]!= INT_MAX) {\n\t\t\t\t\tpathLengthShared[threadIdxX][threadIdxY] = min(pathLengthShared[threadIdxX][threadIdxY], pathLengthShared[i][threadIdxY] + 1);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\n\t\toffset++;\n\t}\n\n\tif (i!= j) {\n\t\tif (pathLengthShared[threadIdxX][threadIdxY]!= INT_MAX) {\n\t\t\tif (pathLengthShared[threadIdxX][threadIdxY] == 0 && i == dest) {\n\t\t\t\tatomicMin(pathLength, 1);\n\t\t\t}\n\t\t\telse if (i == dest && pathLengthShared[threadIdxX][threadIdxY] == 1) {\n\t\t\t\tatomicMin(pathLength, 2);\n\t\t\t}\n\t\t\telse if (pathLengthShared[threadIdxX][threadIdxY] == 2 && i == dest) {\n\t\t\t\tatomicMin(pathLength, 3);\n\t\t\t}\n\t\t}\n\t}\n\n\t__syncthreads();\n}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (i == j && A[i * N + j] == 0) {\n\t\t*pathLength = -1;\n\t}\n\tif (i!= j && A[i * N + j] == 0 && A[j * N + i] == 0) {\n\t\t*pathLength = -1;\n\t}\n\n\tif (i == j && A[i * N + j] == 1) {\n\t\t*pathLength = 0;\n\t}\n\n\tif (i!= j && A[i * N + j] == 1 && A[j * N + i] == 1) {\n\t\t*pathLength = 1;\n\t}\n}",
            "// TODO: replace this code with your code\n\n\n\n}",
            "// TODO: your code here\n\n}",
            "}",
            "}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n\tint stride = blockDim.x * gridDim.x;\n\n\tfor (int i = tid; i < N*N; i += stride) {\n\t\tint i0 = i / N;\n\t\tint i1 = i % N;\n\t\tint t = A[i];\n\t\tif (t)\n\t\t\tprintf(\"(%d, %d) = %d\\n\", i0, i1, t);\n\t}\n}",
            "int i = blockDim.x * blockIdx.y + threadIdx.x;\n\tint j = blockDim.y * blockIdx.x + threadIdx.y;\n\n\tif (i >= N || j >= N) {\n\t\treturn;\n\t}\n\n\tif (A[i * N + j] == 1) {\n\t\tatomicMin(pathLength, 1 + min(pathLength[i], pathLength[j]));\n\t}\n}",
            "int i = blockIdx.x;\n    int j = blockIdx.y;\n    int k = threadIdx.x;\n    int l = threadIdx.y;\n    //__shared__ int buffer[32];\n    __shared__ int buffer[2][32];\n\n    // if ((i < N) && (j < N) && (k == l) && (A[i * N + j] == 1)) {\n    if ((i < N) && (j < N) && (k == l)) {\n        // if (A[i * N + j] == 1) {\n        buffer[0][k] = A[i * N + j];\n        // } else {\n        //     buffer[0][k] = 0;\n        // }\n    }\n\n    __syncthreads();\n\n    if (i < N) {\n        if (j < N) {\n            if (buffer[0][k] == 1) {\n                buffer[1][k] = A[i * N + j];\n            } else {\n                buffer[1][k] = 0;\n            }\n        } else {\n            buffer[1][k] = 0;\n        }\n    } else {\n        buffer[1][k] = 0;\n    }\n\n    __syncthreads();\n\n    if ((i < N) && (j < N) && (A[i * N + j] == 1)) {\n        A[i * N + j] = (buffer[0][k] + buffer[1][l]) % 2;\n    }\n\n    __syncthreads();\n\n    if ((i == source) && (j == dest) && (A[i * N + j] == 1)) {\n        *pathLength = 1;\n    }\n\n    __syncthreads();\n\n}\n\nint main() {\n    // Allocate the memory on the host\n    int *A, *A_h;\n    size_t N = 2048;\n\n    A_h = (int *)malloc(N * N * sizeof(int));\n    cudaMalloc((void **)&A, N * N * sizeof(int));\n\n    // Initialize the matrix and the device memory\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            A_h[i * N + j] = 0;\n        }\n    }\n\n    int source = 0;\n    int dest = 1920;\n\n    for (size_t i = 0; i < N; i++) {\n        A_h[i * N + i] = 1;\n    }\n\n    // Copy the matrix from the host to the device\n    cudaMemcpy(A, A_h, N * N * sizeof(int), cudaMemcpyHostToDevice);\n\n    // Launch the kernel\n    shortestPathLength<<<dim3(N, N), dim3(32, 32)>>>(A, N, source, dest, A_h);\n\n    // Copy the result back to the host\n    cudaMemcpy(A_h, A, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n\n    printf(\"%d\\n\", A_h[source * N + dest]);\n\n    // Free the memory\n    cudaFree(A);\n    free(A_h);\n\n    return EXIT_SUCCESS;\n}\n\n/*\nint main() {\n    // Allocate the memory on the host\n    int *A, *A_h;\n    size_t N = 10;\n\n    A_h = (int *)malloc(N * N * sizeof(int));\n    cudaMalloc((void **)&A, N * N * sizeof(int));\n\n    // Initialize the matrix and the device memory\n    for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n            A_h[i * N + j] = 0;\n        }\n    }\n\n    for (size_t i = 0; i < N; i++) {\n        A_h[i * N +",
            "__shared__ int dist[BLOCK_SIZE * BLOCK_SIZE];\n    int i, j;\n    int bx = blockIdx.x;\n    int by = blockIdx.y;\n    int tx = threadIdx.x;\n    int ty = threadIdx.y;\n\n    // Set the thread's \"dist\" to a very high number.\n    dist[BLOCK_SIZE * ty + tx] = INT_MAX;\n    __syncthreads();\n\n    // Initialise the \"dist\" array for the first column of the block\n    if (tx == 0) {\n        dist[ty * BLOCK_SIZE + tx] = ty == source? 0 : A[ty * N + source];\n    }\n    __syncthreads();\n\n    // Use a single thread to compute the \"dist\" for the rest of the columns of the block\n    if (tx == 0) {\n        for (i = 1; i < N; ++i) {\n            for (j = 0; j < BLOCK_SIZE; ++j) {\n                int dist_old = dist[j * BLOCK_SIZE + i - 1];\n                int weight = A[ty * N + i];\n                dist[j * BLOCK_SIZE + i] = dist_old < INT_MAX? dist_old + weight : INT_MAX;\n            }\n        }\n    }\n    __syncthreads();\n\n    // Update the block's \"dist\" array with the minimum distance to the source amongst its neighbours\n    if (ty == 0) {\n        for (i = 1; i < BLOCK_SIZE; ++i) {\n            dist[i * BLOCK_SIZE + tx] = min(dist[i * BLOCK_SIZE + tx], dist[(i - 1) * BLOCK_SIZE + tx]);\n        }\n    }\n    __syncthreads();\n\n    // Store the minimum distance to the source amongst the neighbouring blocks in the first column of the block\n    if (tx == 0) {\n        dist[ty * BLOCK_SIZE] = min(dist[ty * BLOCK_SIZE], dist[(by + 1) * BLOCK_SIZE + ty]);\n    }\n    __syncthreads();\n\n    // Update the \"dist\" array with the minimum distance to the source amongst its neighbours\n    if (ty == 0) {\n        for (i = 1; i < BLOCK_SIZE; ++i) {\n            dist[i * BLOCK_SIZE] = min(dist[i * BLOCK_SIZE], dist[(i - 1) * BLOCK_SIZE]);\n        }\n    }\n    __syncthreads();\n\n    // Store the minimum distance to the source amongst the neighbouring blocks in the first row of the block\n    if (tx == 0) {\n        dist[ty] = min(dist[ty], dist[by * BLOCK_SIZE + ty]);\n    }\n    __syncthreads();\n\n    // Update the block's \"dist\" array with the minimum distance to the source amongst its neighbours\n    if (ty == 0) {\n        for (i = 1; i < BLOCK_SIZE; ++i) {\n            dist[i] = min(dist[i], dist[i - 1]);\n        }\n    }\n    __syncthreads();\n\n    // Store the result in the global memory\n    if (bx == 0 && by == 0 && ty == 0 && tx == 0) {\n        *pathLength = dist[0];\n    }\n}",
            "int t = blockIdx.x*blockDim.x + threadIdx.x;\n\n  if (t < N) {\n    // initialize distances with infinity\n    if (t == source)\n      *pathLength = 0;\n    else\n      *pathLength = 1000000;\n  }\n\n  __syncthreads();\n\n  // start the main loop\n  int dist = 0;\n  for (int i = 0; i < N; i++) {\n    if (*pathLength < 1000000 && t == source && A[t*N + i] == 1) {\n      dist = 1;\n      while (*pathLength < 1000000 && i!= dest) {\n        if (A[i*N + dest] == 1) {\n          dist += 1;\n          i = dest;\n        } else if (A[i*N + t] == 0) {\n          i = t;\n        } else {\n          i = -1;\n        }\n        if (i!= -1 && A[i*N + t] == 1) {\n          *pathLength = dist;\n        }\n      }\n    }\n    __syncthreads();\n  }\n}",
            "// TODO\n\n}",
            "int *dist = (int *) malloc(N * sizeof(int));\n\n\tint *prev = (int *) malloc(N * sizeof(int));\n\n\tint *visited = (int *) malloc(N * sizeof(int));\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = false;\n\t\tprev[i] = -1;\n\t}\n\n\tdist[source] = 0;\n\tvisited[source] = true;\n\n\tbool found = false;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int u = 0; u < N; u++) {\n\t\t\tif (!visited[u]) continue;\n\t\t\tfor (int v = 0; v < N; v++) {\n\t\t\t\tif (A[u * N + v] == 0) continue;\n\t\t\t\tif (dist[u] + 1 < dist[v]) {\n\t\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\t\tprev[v] = u;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (int u = 0; u < N; u++) {\n\t\t\tif (u == dest) {\n\t\t\t\tfound = true;\n\t\t\t}\n\t\t\tvisited[u] = false;\n\t\t}\n\t\tif (found) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (found) {\n\t\tint u = dest;\n\t\twhile (u!= -1) {\n\t\t\tif (u == source) {\n\t\t\t\t*pathLength = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t*pathLength += 1;\n\t\t\tu = prev[u];\n\t\t}\n\t} else {\n\t\t*pathLength = -1;\n\t}\n}",
            "int tx = threadIdx.x;\n\tint ty = threadIdx.y;\n\n\t__shared__ int d_matrix[16][16];\n\tint i;\n\tfor (i = 0; i < N; i += 16) {\n\t\td_matrix[ty][tx] = A[i*N + tx + i*N + ty];\n\t\t__syncthreads();\n\t\tif (d_matrix[ty][tx] < 0)\n\t\t\tbreak;\n\t}\n\tif (i < N)\n\t\treturn;\n\n\t// Initialize values for the first iteration of the loop.\n\tint minPathLength = A[source*N + ty];\n\tif (tx == 0)\n\t\tpathLength[ty] = minPathLength;\n\t__syncthreads();\n\n\t// Loop over all the intermediate nodes.\n\tfor (i = 1; i < N; i++) {\n\t\tminPathLength = min(minPathLength, pathLength[ty]);\n\t\t__syncthreads();\n\t\tif (tx == 0) {\n\t\t\tpathLength[ty] = minPathLength + d_matrix[ty][tx];\n\t\t\tif (ty == dest) {\n\t\t\t\tminPathLength = min(minPathLength, pathLength[ty]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (tx == 0 && ty == dest)\n\t\tpathLength[ty] = minPathLength;\n}",
            "// YOUR CODE GOES HERE\n\t//\n\t//\n\t//\n}",
            "int *distance = new int[N];\n  for (int i = 0; i < N; i++) {\n    distance[i] = A[N * source + i];\n  }\n\n  for (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n      distance[j] = min(distance[j], distance[i] + A[N * i + j]);\n    }\n  }\n\n  *pathLength = distance[dest];\n}",
            "// TODO\n}",
            "// Set up thread block and shared memory\n\t__shared__ bool done[MAX_N];\n\t__shared__ int sdata[MAX_N];\n\n\t// Calculate the index for this thread into the source array\n\tint index = blockIdx.x * blockDim.x + threadIdx.x;\n\tint tid = threadIdx.x;\n\n\t// Initialize shared memory\n\tif (tid == 0) {\n\t\tfor (int i = 0; i < MAX_N; i++) {\n\t\t\tdone[i] = false;\n\t\t\tsdata[i] = 0;\n\t\t}\n\t}\n\n\t__syncthreads();\n\n\t// Mark the start node as done\n\tif (index == source) {\n\t\tdone[source] = true;\n\t\tsdata[source] = 0;\n\t}\n\n\t__syncthreads();\n\n\t// Loop until all nodes have been marked done\n\twhile (true) {\n\t\t// If this thread's node has already been done, return\n\t\tif (done[index]) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Calculate the distance to this node's neighbors\n\t\tfor (int neighbor = 0; neighbor < N; neighbor++) {\n\t\t\t// Make sure to only read/write to existing nodes\n\t\t\tif (A[index * N + neighbor]!= 0 &&!done[neighbor]) {\n\t\t\t\t// Check if this path is the shortest path to the neighbor\n\t\t\t\tint newPathLength = sdata[index] + 1;\n\t\t\t\tint oldPathLength = sdata[neighbor];\n\n\t\t\t\t// Do a compare and swap to find the shortest path to the neighbor\n\t\t\t\tint old = atomicMin(&sdata[neighbor], max(oldPathLength, newPathLength));\n\n\t\t\t\t// If this thread won the compare-and-swap, mark the neighbor as done\n\t\t\t\tif (old == oldPathLength) {\n\t\t\t\t\tdone[neighbor] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t__syncthreads();\n\t}\n}",
            "const int row = blockIdx.x * blockDim.x + threadIdx.x;\n\tconst int col = blockIdx.y * blockDim.y + threadIdx.y;\n\n\tif (row < N && col < N && A[row * N + col]!= -1 && row!= col)\n\t{\n\t\tconst int sourceDist = __ldg(&A[row * N + source]);\n\t\tconst int destDist = __ldg(&A[col * N + dest]);\n\t\tpathLength[row * N + col] = sourceDist + destDist;\n\t}\n}",
            "int tid = blockIdx.x*blockDim.x+threadIdx.x;\n\t__shared__ int distances[THREADS_PER_BLOCK];\n\t__shared__ bool visited[THREADS_PER_BLOCK];\n\tdistances[tid]=INT_MAX;\n\tvisited[tid]=false;\n\t__syncthreads();\n\tif (tid==source) {\n\t\tdistances[tid]=0;\n\t\tvisited[tid]=true;\n\t}\n\t__syncthreads();\n\tfor (int j=0;j<N-1;++j) {\n\t\t__syncthreads();\n\t\tif (tid<N) {\n\t\t\tint v=tid;\n\t\t\tint distance=distances[tid];\n\t\t\tint count=0;\n\t\t\twhile (v<N && count<N) {\n\t\t\t\tif (!visited[v]) {\n\t\t\t\t\tif (A[v*N+tid]==1) {\n\t\t\t\t\t\tdistances[v]=min(distance+1,distances[v]);\n\t\t\t\t\t\tvisited[v]=true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t++count;\n\t\t\t\tv+=blockDim.x*gridDim.x;\n\t\t\t}\n\t\t}\n\t\t__syncthreads();\n\t}\n\tif (tid==dest)\n\t\t*pathLength=distances[tid];\n}",
            "// TODO\n}",
            "int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n    int index = threadID;\n    bool isVisited = false;\n    int *visited = (int *) calloc(N, sizeof(int));\n    int *predecessor = (int *) calloc(N, sizeof(int));\n    int distance = 0;\n    int current = source;\n    int next;\n\n    if (index < N) {\n        predecessor[source] = source;\n    }\n\n    while (!isVisited && (current!= dest)) {\n        for (int i = 0; i < N; i++) {\n            if (A[index * N + i]!= 0) {\n                next = i;\n                distance++;\n                break;\n            }\n        }\n\n        if (index == source) {\n            isVisited = true;\n        } else if (index!= source && index!= dest) {\n            if (visited[current]!= 1) {\n                visited[current] = 1;\n                predecessor[index] = current;\n                current = next;\n            } else {\n                isVisited = true;\n            }\n        } else {\n            isVisited = true;\n        }\n    }\n\n    if (index == dest) {\n        *pathLength = distance;\n    }\n\n    free(visited);\n    free(predecessor);\n}",
            "const int s = blockDim.x * blockIdx.x + threadIdx.x;\n\tconst int t = blockDim.y * blockIdx.y + threadIdx.y;\n\tint *dist = (int *) malloc(sizeof(int) * N);\n\tdist[source] = 0;\n\tdist[dest] = 1;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tdist[j] = min(dist[j], dist[i] + A[i * N + j]);\n\t\t}\n\t}\n\t*pathLength = dist[dest];\n\tfree(dist);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  // if A[i][j] is not a valid entry in the matrix or if either i or j is the\n  // destination node, do not update the path length.\n  if (i >= N || j >= N || A[i * N + j] == 0 || i == dest || j == dest) {\n    return;\n  }\n\n  // The kernel function must be able to work for arbitrary values of i and j\n  // without causing index out of bounds exceptions. \n  // It must be able to work for i = source, j!= source.\n  // That is, if the node at index i is connected to the node at index j, \n  // and i is the source node, then the length of the shortest path from\n  // the source to the destination must be at most 1 + the length of the shortest\n  // path from the source to j. \n  // We can compute the shortest path from the source to j as follows:\n  // 1. Start with the shortest path length from the source to the previous node, pathLength[j]\n  // 2. Add the weight of the edge (i, j) to the previous length, 1 + pathLength[j]\n  // 3. Store the result in pathLength[i]\n  //\n  // The shortest path length from the source to the destination must then be at most\n  // 1 + the length of the shortest path from the source to j.\n  // That is, pathLength[dest] <= 1 + pathLength[j]\n  if (A[i * N + j]!= 0 && i!= j) {\n    atomicMin(pathLength + j, 1 + pathLength[j]);\n  }\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n  if (tid < N * N) {\n    int i = tid / N;\n    int j = tid % N;\n    if (i == source) {\n      if (j == dest) {\n        pathLength[i] = 0;\n      } else if (A[tid] > 0) {\n        pathLength[i] = 1 + pathLength[j];\n      }\n    }\n  }\n}",
            "int *B = new int[N];\n\n  int i = blockIdx.x * blockDim.x + threadIdx.x;\n  if (i == source) {\n    B[i] = 0;\n  } else {\n    B[i] = INF;\n  }\n\n  // Synchronize the threads in the block before moving on\n  __syncthreads();\n\n  for (int k = 0; k < N - 1; k++) {\n\n    if (i == dest) {\n      break;\n    }\n\n    // Synchronize the threads in the block before moving on\n    __syncthreads();\n\n    for (int j = 0; j < N; j++) {\n\n      int b = A[j * N + i];\n      if (b == INF) {\n        continue;\n      }\n\n      if (B[j] + b < B[i]) {\n        B[i] = B[j] + b;\n      }\n    }\n  }\n\n  if (i == dest) {\n    pathLength[0] = B[i];\n  }\n}",
            "}",
            "// TODO: Replace pass with your code\n    printf(\"Shortest path length from %d to %d is %d\\n\", source, dest, INT_MAX);\n}",
            "const int row = blockIdx.y * blockDim.y + threadIdx.y;\n\tconst int col = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (row < N && col < N && A[row * N + col]) {\n\t\t*pathLength = 1;\n\t\treturn;\n\t}\n\t*pathLength = INT_MAX;\n\t__syncthreads();\n}",
            "__shared__ int sdata[BLOCK_SIZE];\n    int tid = threadIdx.x;\n    int bid = blockIdx.x;\n    int i = bid * BLOCK_SIZE + tid;\n    int j = bid * BLOCK_SIZE + tid + 1;\n\n    int result = INF;\n\n    if (i < N && j < N && A[i*N+j] == 1) {\n        int length = 0;\n        if (i == source) length = 1;\n        if (i == dest) length = 2;\n\n        if (length == 1 || length == 2) {\n            sdata[tid] = length;\n            __syncthreads();\n\n            for (unsigned int s = BLOCK_SIZE >> 1; s > 0; s >>= 1) {\n                if (tid < s) {\n                    sdata[tid] = min(sdata[tid], sdata[tid+s]);\n                }\n                __syncthreads();\n            }\n\n            if (tid == 0) {\n                atomicMin(&result, sdata[0]);\n            }\n        }\n    }\n\n    if (result == INF && tid == 0) {\n        pathLength[bid] = INF;\n    } else if (tid == 0) {\n        pathLength[bid] = result;\n    }\n}",
            "/* YOUR CODE HERE */\n\n}",
            "int x = blockIdx.x;\n  int y = blockIdx.y;\n  int width = gridDim.x;\n  int height = gridDim.y;\n  __shared__ int cache[TILE_DIM][TILE_DIM];\n\n  // Use the shared memory to cache the A matrix\n  int bx = threadIdx.x;\n  int by = threadIdx.y;\n  int tx = bx + blockIdx.x * blockDim.x;\n  int ty = by + blockIdx.y * blockDim.y;\n\n  int distance = -1;\n  if (x == y) {\n    distance = 0;\n  } else if (tx == source && ty == dest) {\n    distance = 1;\n  }\n  cache[by][bx] = distance;\n  __syncthreads();\n\n  // Compute the path length\n  // TODO\n}",
            "size_t i = blockIdx.x * blockDim.x + threadIdx.x;\n    size_t j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    // Base case: return infinity if the source is not the destination.\n    if (i == source) {\n        pathLength[j] = INFINITY;\n        return;\n    }\n\n    // Base case: no path from any vertex to itself.\n    if (j == i) {\n        pathLength[j] = INFINITY;\n        return;\n    }\n\n    // If we reached here, we are looking at a pair of vertices (i, j).\n\n    // If the edge from i to j exists, then the shortest path from the source to j is\n    // one longer than the shortest path from the source to i.\n    if (A[i*N + j] == 1) {\n        pathLength[j] = pathLength[i] + 1;\n        return;\n    }\n\n    // If the edge from i to j does not exist, then the shortest path from the source to j is\n    // INFINITY (i.e. there is no path from the source to j).\n    pathLength[j] = INFINITY;\n}",
            "/* TODO: Fill this in. */\n  int row_num = blockIdx.y*gridDim.x + blockIdx.x;\n  int col_num = threadIdx.x;\n\n  int *distance = new int[N];\n  int *parent = new int[N];\n  int *visited = new int[N];\n  int *count = new int[N];\n\n  for (int i = 0; i < N; i++)\n  {\n    distance[i] = INT_MAX;\n    parent[i] = -1;\n    visited[i] = 0;\n    count[i] = 0;\n  }\n\n  distance[source] = 0;\n  parent[source] = -1;\n  visited[source] = 1;\n  count[source] = 1;\n\n  int min;\n  for (int i = 0; i < N; i++)\n  {\n    min = INT_MAX;\n    for (int j = 0; j < N; j++)\n    {\n      if (visited[j] == 1 && distance[j] < min)\n        min = distance[j];\n    }\n\n    for (int j = 0; j < N; j++)\n    {\n      if (A[row_num * N + col_num] == 1 && distance[j] == min)\n      {\n        distance[j] = min + 1;\n        parent[j] = row_num;\n        count[j] += 1;\n      }\n    }\n\n    visited[min] = 0;\n  }\n\n  *pathLength = distance[dest];\n\n  delete[] distance;\n  delete[] parent;\n  delete[] visited;\n  delete[] count;\n}",
            "}",
            "int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n  __shared__ bool marked[100];\n  __shared__ int distance[100];\n\n  if (threadId < N) {\n    marked[threadId] = false;\n    distance[threadId] = INT_MAX;\n  }\n\n  __syncthreads();\n\n  if (threadId == source) {\n    distance[source] = 0;\n  }\n\n  __syncthreads();\n\n  for (int i = 0; i < N; i++) {\n    if (!marked[source] && distance[source] < INT_MAX) {\n      marked[source] = true;\n      for (int j = 0; j < N; j++) {\n        if (!marked[j] && A[source * N + j]!= 0) {\n          if (distance[j] > distance[source] + A[source * N + j]) {\n            distance[j] = distance[source] + A[source * N + j];\n          }\n        }\n      }\n    }\n    __syncthreads();\n  }\n\n  if (threadId == dest) {\n    *pathLength = distance[dest];\n  }\n}",
            "// TODO: Implement this function\n}",
            "/* Your code here */\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x; // global thread index\n\n\tint u = tid; // source vertex\n\n\t// Initialize the path length to -1 for all vertices\n\tif (tid == source) {\n\t\tpathLength[u] = 0;\n\t} else {\n\t\tpathLength[u] = -1;\n\t}\n\n\t__syncthreads();\n\n\t// TODO: Implement the kernel to compute the shortest path length from source to dest\n\n}",
            "// TODO: Replace this line with your code.\n  int id = blockIdx.x * blockDim.x + threadIdx.x;\n  int dist[N];\n  int q[N];\n  int qp = 0;\n  for(int i = 0; i < N; i++) dist[i] = A[id * N + i];\n  q[qp++] = id;\n  int found = 0;\n  while(!found && qp > 0){\n    int v = q[--qp];\n    if(v == dest) {\n      found = 1;\n      *pathLength = dist[v];\n      break;\n    }\n    for(int i = 0; i < N; i++) {\n      if(dist[v] + A[v * N + i] < dist[i]) {\n        dist[i] = dist[v] + A[v * N + i];\n        q[qp++] = i;\n      }\n    }\n  }\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\n\tif (i == j) {\n\t\tA[i * N + j] = 0;\n\t}\n\tif (i > j) {\n\t\tA[i * N + j] = A[j * N + i];\n\t}\n}",
            "int tid = blockDim.x*blockIdx.y*gridDim.x + blockDim.x*blockIdx.x + threadIdx.x;\n  int id = tid;\n  if (id < N*N) {\n    // TODO\n  }\n}",
            "// TODO\n    int i = threadIdx.x + blockIdx.x * blockDim.x;\n    int j = threadIdx.y + blockIdx.y * blockDim.y;\n\n    if (i == dest && j == source)\n        atomicMin(pathLength, 1);\n\n    if (A[i * N + j]!= 0)\n        atomicMin(pathLength, __hmin(A[i * N + j], *pathLength));\n\n}",
            "int i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint k = threadIdx.x;\n\tint idx = blockDim.x * blockDim.y;\n\tint idy = blockDim.x;\n\t// printf(\"%d\\n\", idx);\n\tif (i == source && j == source) {\n\t\tpathLength[k] = 1;\n\t\tif (k == source) {\n\t\t\t// printf(\"1\\n\");\n\t\t}\n\t}\n\t// for (int i = 0; i < N; i++) {\n\t// \tfor (int j = 0; j < N; j++) {\n\t// \t\tif (i == source && j == source) {\n\t// \t\t\tpathLength[i*N + j] = 1;\n\t// \t\t}\n\t// \t}\n\t// }\n\t// for (int k = 0; k < N; k++) {\n\t// \tprintf(\"%d \", pathLength[k]);\n\t// }\n\t// printf(\"\\n\");\n\t// __syncthreads();\n\tfor (int iter = 0; iter < N - 1; iter++) {\n\t\tif (i == source && j == dest) {\n\t\t\tpathLength[k] = 1;\n\t\t}\n\t\t// printf(\"%d %d %d %d\\n\", i, j, k, pathLength[k]);\n\t\t// __syncthreads();\n\t\tif (i == j && i == k) {\n\t\t\tif (k < N && i!= j && pathLength[k] > 0) {\n\t\t\t\tpathLength[k] = A[i*N + k] + pathLength[k];\n\t\t\t\t// printf(\"%d %d %d %d\\n\", i, j, k, pathLength[k]);\n\t\t\t}\n\t\t}\n\t\t// __syncthreads();\n\t\tif (i == j && i!= k) {\n\t\t\tif (i < N && pathLength[i] > 0 && A[i*N + k] > 0) {\n\t\t\t\tpathLength[k] = A[i*N + k] + pathLength[i];\n\t\t\t\t// printf(\"%d %d %d %d\\n\", i, j, k, pathLength[k]);\n\t\t\t}\n\t\t}\n\t\t// __syncthreads();\n\t\tif (j == k && i!= j) {\n\t\t\tif (i < N && pathLength[i] > 0 && A[i*N + j] > 0) {\n\t\t\t\tpathLength[k] = A[i*N + j] + pathLength[j];\n\t\t\t\t// printf(\"%d %d %d %d\\n\", i, j, k, pathLength[k]);\n\t\t\t}\n\t\t}\n\t\t// __syncthreads();\n\t\tif (i!= j && i!= k && j!= k) {\n\t\t\tif (i < N && j < N && pathLength[i] > 0 && pathLength[j] > 0 && A[i*N + k] > 0) {\n\t\t\t\tint tmp = pathLength[i] + pathLength[j];\n\t\t\t\tif (tmp < pathLength[k]) {\n\t\t\t\t\tpathLength[k] = A[i*N + k] + tmp;\n\t\t\t\t\t// printf(\"%d %d %d %d\\n\", i, j, k, pathLength[k]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// __syncthreads();\n\t}\n\t// for (int k = 0; k < N; k++) {\n\t// \tprintf(\"%d \", pathLength[k]);\n\t// }\n\t// printf(\"\\n\");\n}",
            "// TODO\n}",
            "// Fill this in\n\n}",
            "}",
            "int i = blockIdx.y * blockDim.y + threadIdx.y;\n\tint j = blockIdx.x * blockDim.x + threadIdx.x;\n\tif (i < N && j < N) {\n\t\tif (A[i*N+j] == 1) {\n\t\t\tif (i == source) {\n\t\t\t\tpathLength[i] = 0;\n\t\t\t} else {\n\t\t\t\tpathLength[i] = pathLength[j] + 1;\n\t\t\t}\n\t\t} else {\n\t\t\tpathLength[i] = -1;\n\t\t}\n\t}\n}",
            "// TODO\n}",
            "// Your code here\n  int threadId = blockIdx.x * blockDim.x + threadIdx.x;\n  if (threadId < N && A[threadId*N + source]!= 0) {\n    // printf(\"Thread %d is checking %d\\n\", threadId, threadId);\n    int i = 0;\n    int current = source;\n    while (current!= dest) {\n      i++;\n      current = findAdjacent(A, N, current, source);\n      if (current == -1) {\n        break;\n      }\n    }\n    if (i < *pathLength) {\n      *pathLength = i;\n    }\n  }\n}",
            "int myID = threadIdx.x + blockIdx.x * blockDim.x;\n  int startNode = source;\n  int currentNode = startNode;\n  int shortestPathLength = 0;\n  int endNode = dest;\n  while (currentNode!= endNode) {\n    int nextNode = -1;\n    for (int i = 0; i < N; i++) {\n      if (A[currentNode * N + i]) {\n        nextNode = i;\n        break;\n      }\n    }\n    if (nextNode == -1) {\n      break;\n    }\n    currentNode = nextNode;\n    shortestPathLength++;\n  }\n  if (myID == 0) {\n    pathLength[0] = shortestPathLength;\n  }\n}",
            "int i = blockIdx.y*gridDim.x + blockIdx.x;\n   if (i >= N) return;\n   __shared__ int sdata[256];\n   int myPathLength = A[source*N + i];\n   for (int k = 0; k < N; ++k) {\n      int j = (k + 2*threadIdx.x) % N;\n      if (A[i*N + j] + myPathLength < myPathLength) {\n         myPathLength = A[i*N + j] + myPathLength;\n      }\n   }\n   sdata[threadIdx.x] = myPathLength;\n   __syncthreads();\n   if (threadIdx.x == 0) {\n      for (int offset = 1; offset < blockDim.x; offset *= 2) {\n         int j = (threadIdx.x + offset) % blockDim.x;\n         if (sdata[j] + sdata[threadIdx.x] < sdata[threadIdx.x]) {\n            sdata[threadIdx.x] = sdata[j] + sdata[threadIdx.x];\n         }\n         __syncthreads();\n      }\n   }\n   if (threadIdx.x == 0) {\n      pathLength[blockIdx.y] = sdata[0];\n   }\n}",
            "int tid = blockIdx.x*blockDim.x + threadIdx.x;\n    if (tid == source) {\n        *pathLength = 0;\n        return;\n    }\n    if (tid == dest) {\n        *pathLength = 100;\n        return;\n    }\n    if (A[source*N+tid] == 0 || A[tid*N+source] == 0)\n        return;\n    if (A[source*N+dest] == 0 || A[dest*N+source] == 0)\n        return;\n    if (A[tid*N+dest] == 0)\n        return;\n    int local_path_length = 100;\n    for (int i = 0; i < N; i++)\n        local_path_length = min(local_path_length, pathLength[i]);\n    pathLength[tid] = 1 + local_path_length;\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x;\n\tif(i == source){\n\t\tpathLength[i] = 0;\n\t}\n\tif (i == dest){\n\t\tpathLength[i] = 1;\n\t}\n\t__syncthreads();\n\n\tfor (int j = 0; j < N; j++){\n\t\tif (A[i * N + j] == 1){\n\t\t\tint temp = pathLength[j] + 1;\n\t\t\tatomicMin(&pathLength[i], temp);\n\t\t}\n\t\t__syncthreads();\n\t}\n}",
            "// Your code here\n    if (threadIdx.x == threadIdx.y)\n    {\n        if (blockIdx.x == 0 && blockIdx.y == 0)\n        {\n            *pathLength = 0;\n            return;\n        }\n        // printf(\"blockIdx.x: %d, blockIdx.y: %d, blockDim.x: %d, blockDim.y: %d\\n\", blockIdx.x, blockIdx.y, blockDim.x, blockDim.y);\n        if (A[blockIdx.x * N + blockIdx.y] == 1 && A[blockIdx.y * N + blockIdx.x] == 1)\n        {\n            atomicMin(pathLength, __sad(threadIdx.x, threadIdx.y, 0));\n        }\n    }\n}",
            "// TODO\n\tint tid=blockIdx.x*blockDim.x+threadIdx.x;\n\tif(tid>=N)return;\n\tfor(int i=0;i<N;i++){\n\t\tfor(int j=0;j<N;j++){\n\t\t\tif(A[i*N+j]==1){\n\t\t\t\tif(i==source&&j==dest){\n\t\t\t\t\tpathLength[tid]=0;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif(A[tid*N+j]==1){\n\t\t\t\t\tif(j==dest){\n\t\t\t\t\t\tpathLength[tid]=pathLength[j]+1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "// TODO: Compute the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n\t// A is an NxN adjacency matrix stored in row-major.\n\t// Store the result in pathLength.\n\t// Use CUDA to compute in parallel. The kernel is launched on an NxN grid of threads.\n\n\tint i = blockIdx.x;\n\tint j = blockIdx.y;\n\tint index = threadIdx.x;\n\n\t__shared__ int currentLength[BLOCKSIZE];\n\n\tif(i == j)\n\t\tcurrentLength[index] = 0;\n\telse\n\t\tcurrentLength[index] = MAX;\n\n\t__syncthreads();\n\n\tif(i == source)\n\t\tcurrentLength[index] = 1;\n\n\t__syncthreads();\n\n\tfor(int k = 0; k < N; k++) {\n\n\t\t__syncthreads();\n\n\t\tint temp = currentLength[index];\n\n\t\tif(A[i*N+k] == 1 && A[k*N+j] == 1 && temp < MAX)\n\t\t\tcurrentLength[index] = min(currentLength[index], currentLength[index]+1);\n\n\t\t__syncthreads();\n\n\t}\n\n\t__syncthreads();\n\n\tif(currentLength[index] < *pathLength)\n\t\t*pathLength = currentLength[index];\n\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    if (i < N && j < N) {\n        int value = A[i * N + j];\n        if (i == source && value == 1) {\n            *pathLength = 1;\n        } else if (i == dest && value == 1) {\n            *pathLength = 1;\n        } else if (value == 1) {\n            int pathLength_from_source = *pathLength;\n            int pathLength_from_dest = *pathLength;\n            *pathLength = pathLength_from_dest + pathLength_from_source;\n        }\n    }\n}",
            "int tx = threadIdx.x, ty = threadIdx.y;\n\tint row = blockIdx.x, col = blockIdx.y;\n\n\t// Initialize the distance to source to the sentinel value.\n\tif (row == col && tx == ty)\n\t\t*(pathLength + row * N + col) = INT_MAX;\n\t// Initialize the distance to dest to the sentinel value.\n\tif (row == dest && col == dest && tx == ty)\n\t\t*(pathLength + row * N + col) = INT_MAX;\n\n\t// Update the distance to source.\n\tif (row == source && col == source && tx == ty)\n\t\t*(pathLength + row * N + col) = 0;\n\n\t__syncthreads();\n\n\t// Loop until the distance to source is no longer updated.\n\twhile (true) {\n\t\t// Update the distance to source.\n\t\tif (row == source && col!= source && tx == ty) {\n\t\t\tint distance = (*(pathLength + row * N + col));\n\t\t\tif (distance!= INT_MAX)\n\t\t\t\t*(pathLength + col * N + col) = distance + (*(A + row * N + col));\n\t\t}\n\n\t\t// Update the distance to dest.\n\t\tif (row == dest && col!= dest && tx == ty) {\n\t\t\tint distance = (*(pathLength + row * N + col));\n\t\t\tif (distance!= INT_MAX)\n\t\t\t\t*(pathLength + col * N + col) = distance + (*(A + row * N + col));\n\t\t}\n\n\t\t// Update the distance to source and dest.\n\t\tif (row!= source && col!= source && tx == ty) {\n\t\t\tint distanceSource = (*(pathLength + row * N + col));\n\t\t\tint distanceDest = (*(pathLength + row * N + col));\n\t\t\tif (distanceSource!= INT_MAX && distanceDest!= INT_MAX)\n\t\t\t\t*(pathLength + col * N + col) = min(distanceSource + (*(A + row * N + col)), distanceDest + (*(A + row * N + col)));\n\t\t}\n\n\t\t__syncthreads();\n\n\t\t// Check if the distance to source is still updated.\n\t\tif (row == source && col == source && tx == ty) {\n\t\t\tint distance = (*(pathLength + row * N + col));\n\t\t\tif (distance == INT_MAX)\n\t\t\t\tbreak;\n\t\t}\n\n\t\t__syncthreads();\n\t}\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n  int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n  // Handle the case where (i,j) is not in the graph (i.e. there is no edge).\n  if (i >= N || j >= N || A[N*i + j] == 0) {\n    return;\n  }\n\n  // If the edge exists, then set pathLength[i] to 1 + pathLength[j]\n  if (i == source && j == dest) {\n    *pathLength = 1 + pathLength[j];\n  }\n}",
            "// Each thread computes the length of a single shortest path.\n  //  - The source node is at thread (0,0).\n  //  - The destination node is at thread (N-1,N-1).\n  //  - All other nodes are at thread (row, col).\n\n  int row = blockIdx.x;\n  int col = blockIdx.y;\n\n  // Use atomicMin() to avoid conflicts when multiple threads compute the shortest path to the same node.\n  //  - atomicMin(ptr, val) is the atomic version of:\n  //      if (*ptr > val) *ptr = val;\n\n  if (row == col && A[row*N + col]!= 0)\n    atomicMin(pathLength, 1);\n  else if (row > col && A[row*N + col]!= 0)\n    atomicMin(pathLength, __shfl_sync(0xffffffff, *pathLength, col));\n}",
            "int i = blockIdx.x;\n    int j = blockIdx.y;\n    if (i == j)\n        pathLength[i] = 0;\n    else if (A[N*i + j] == 1)\n        pathLength[i] = INT_MAX;\n    else\n        pathLength[i] = INT_MIN;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n    int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n    __shared__ int cache[32];\n    cache[threadIdx.x] = INT_MAX;\n    cache[threadIdx.x] = A[i*N + j];\n    __syncthreads();\n    if (i == j) {\n        cache[threadIdx.x] = 0;\n    }\n    for (int k = 0; k < N; ++k) {\n        if (i == k) {\n            cache[threadIdx.x] = 0;\n        }\n        __syncthreads();\n        int min = cache[threadIdx.x];\n        for (int l = 0; l < N; ++l) {\n            if (cache[l] < min) {\n                min = cache[l];\n            }\n        }\n        cache[threadIdx.x] = min;\n        __syncthreads();\n    }\n    if (i == dest) {\n        *pathLength = cache[threadIdx.x];\n    }\n}",
            "int tid = threadIdx.x + blockIdx.x*blockDim.x;\n  __shared__ int sdata[1024]; // sdata[tid] is updated by tid in this block\n  sdata[tid] = INT_MAX;\n\n  __syncthreads();\n\n  // TODO\n\n  __syncthreads();\n\n  if(tid == 0)\n  {\n    pathLength[0] = sdata[dest];\n  }\n}",
            "const size_t i = blockIdx.x; // i = row\n    const size_t j = blockIdx.y; // j = column\n\n    __shared__ int cache[1024];\n\n    if (i == j) {\n        cache[threadIdx.x] = 0;\n    } else if (i < N && j < N) {\n        cache[threadIdx.x] = A[i * N + j];\n    } else {\n        cache[threadIdx.x] = INT_MAX;\n    }\n\n    __syncthreads();\n\n    // TODO\n\n    // Write the final result to the output array.\n    if (threadIdx.x == 0) {\n        pathLength[0] = cache[threadIdx.x];\n    }\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n   int j = blockIdx.y * blockDim.y + threadIdx.y;\n\n   if (i >= N || j >= N) {\n      return;\n   }\n\n   if (A[j * N + i] == 1) {\n      pathLength[i] = pathLength[j] + 1;\n   }\n\n   __syncthreads();\n\n   // if i == dest, then output the length of the shortest path\n   if (i == dest) {\n      *pathLength = pathLength[i];\n   }\n}",
            "// TODO\n\n}",
            "int row = blockIdx.x;\n\tint col = threadIdx.x;\n\n\tif (row == col) {\n\t\tpathLength[row] = 0;\n\t} else if (row < col) {\n\t\tpathLength[col] = INT_MAX;\n\t}\n\n\t__syncthreads();\n\n\tif (row < N && col < N) {\n\t\t// Find the shortest path between source and col\n\t\tint i = 0;\n\t\tint current = source;\n\t\tint previous;\n\t\twhile (current!= dest && i < N) {\n\t\t\tif (current == col) {\n\t\t\t\tpathLength[col] = i;\n\t\t\t}\n\n\t\t\tprevious = current;\n\t\t\tcurrent = pathLength[previous];\n\n\t\t\t// Check for negative-weight cycles\n\t\t\tif (current == previous) {\n\t\t\t\tpathLength[col] = INT_MAX;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ti++;\n\t\t}\n\t}\n\n\t// Find the shortest path between source and dest\n\tint min = INT_MAX;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (pathLength[i]!= INT_MAX && pathLength[i] + pathLength[source] < min) {\n\t\t\tmin = pathLength[i] + pathLength[source];\n\t\t}\n\t}\n\n\tpathLength[dest] = min;\n}",
            "// Your code here\n}",
            "__shared__ int dist[32][32];\n  int tid = threadIdx.x + threadIdx.y * blockDim.x;\n  int i = tid + blockIdx.x * blockDim.x * blockDim.y;\n  int j = tid + blockIdx.y * blockDim.x * blockDim.y;\n  if (tid == 0)\n    dist[blockIdx.x][blockIdx.y] = INT_MAX;\n  __syncthreads();\n\n  if (i < N && j < N) {\n    if (i == source)\n      dist[blockIdx.x][blockIdx.y] = 0;\n    if (j == source)\n      dist[blockIdx.x][blockIdx.y] = 0;\n  }\n\n  if (i < N && j < N) {\n    if (A[i * N + j] && dist[blockIdx.x][blockIdx.y] + 1 < dist[j][i])\n      dist[j][i] = dist[blockIdx.x][blockIdx.y] + 1;\n  }\n  __syncthreads();\n  if (i == j && dist[blockIdx.x][blockIdx.y]!= INT_MAX)\n    dist[blockIdx.x][blockIdx.y] = 0;\n  __syncthreads();\n  if (i == dest)\n    atomicMin(pathLength, dist[blockIdx.x][blockIdx.y]);\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n   int j = blockIdx.y * blockDim.y + threadIdx.y;\n   // TODO: compute the length of the shortest path from source to dest in the graph defined by the adjacency matrix A\n\n\n\n}",
            "// Set up a 2D grid with NxN threads, so that each thread will \n\t// compute the shortest path length between two vertices.\n\t// We use threadIdx.x and threadIdx.y to identify the thread in the \n\t// grid and the blockIdx.x and blockIdx.y to identify the block.\n\t//\n\t// Remember that in CUDA, each block has its own copy of the global\n\t// memory, so that different blocks can update global memory\n\t// independently. Therefore, we need to share the results computed in \n\t// each block with the other blocks. We use atomicAdd to ensure\n\t// thread safety.\n\t\n\tint x = threadIdx.x + blockIdx.x * blockDim.x;\n\tint y = threadIdx.y + blockIdx.y * blockDim.y;\n\t\n\tif (x >= N || y >= N)\n\t\treturn;\n\t\n\tif (x == y) {\n\t\tatomicAdd(pathLength, 0);\n\t} else if (A[x * N + y] == 1) {\n\t\tatomicAdd(pathLength, 1);\n\t} else if (A[x * N + y] == 0) {\n\t\tatomicAdd(pathLength, INF);\n\t}\n}",
            "int myID = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + threadIdx.x;\n\n\tif (myID == source) {\n\t\tpathLength[source] = 0;\n\t} else {\n\t\tpathLength[myID] = INT_MAX;\n\t}\n\n\t__syncthreads();\n\n\tfor (int k = 0; k < N; k++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tint threadID_j = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + j;\n\t\t\tint threadID_k = blockIdx.y * gridDim.x * blockDim.x + blockIdx.x * blockDim.x + k;\n\n\t\t\t// Check if the edge exists\n\t\t\tif (A[threadID_j * N + threadID_k] == 1) {\n\t\t\t\tif (pathLength[threadID_j] + 1 < pathLength[threadID_k]) {\n\t\t\t\t\tpathLength[threadID_k] = pathLength[threadID_j] + 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}",
            "int i = threadIdx.x + blockIdx.x * blockDim.x; // row\n\tint j = threadIdx.y + blockIdx.y * blockDim.y; // column\n\tif (i == j) {\n\t\tA[i * N + j] = 0;\n\t}\n\tif (i < N && j < N && A[i * N + j] > 0) {\n\t\tA[i * N + j] = min(A[i * N + j], A[i * N + dest] + A[dest * N + j]);\n\t}\n\t//printf(\"(%d, %d): %d\\n\", i, j, A[i * N + j]);\n\t__syncthreads();\n}",
            "int i = blockIdx.y*blockDim.y + threadIdx.y;\n\tint j = blockIdx.x*blockDim.x + threadIdx.x;\n\tif(i >= N || j >= N) return;\n\tif(i == j) {\n\t\tA[i*N + j] = 0;\n\t\treturn;\n\t}\n\tif(A[i*N + j] == 0) return;\n\t\n\tif(i == source) {\n\t\tA[i*N + j] = 1;\n\t} else if(j == source) {\n\t\tA[i*N + j] = 0;\n\t} else {\n\t\tA[i*N + j] = min(A[i*N + j], A[i*N + source] + A[source*N + j]);\n\t}\n\t\n\tif(i == dest) {\n\t\t*pathLength = A[i*N + j];\n\t}\n}",
            "int tid = blockIdx.x * blockDim.x + threadIdx.x;\n    int nthreads = blockDim.x * gridDim.x;\n    int i;\n    for (i = tid; i < N; i += nthreads) {\n        if (i == source && A[dest * N + i] == 1) {\n            pathLength[0] = 1;\n            return;\n        }\n        if (i == dest) {\n            pathLength[0] = 0;\n            return;\n        }\n    }\n    pathLength[0] = -1;\n}",
            "int i = blockIdx.x * blockDim.x + threadIdx.x;\n\tint j = blockIdx.y * blockDim.y + threadIdx.y;\n\tint tmp_source=source;\n\tint tmp_dest=dest;\n\tif (i < N && j < N) {\n\t\tif (A[j * N + i] == 1) {\n\t\t\tif (i < j) {\n\t\t\t\ttmp_source = j;\n\t\t\t\ttmp_dest = i;\n\t\t\t}\n\t\t\tif (tmp_source == dest) {\n\t\t\t\tpathLength[0] = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (tmp_source == source && tmp_dest!= dest) {\n\t\t\t\tpathLength[0] = -1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n}"
        ]
    },
    {
        "problem_type": "graph",
        "language": "cpp",
        "name": "15_graph_shortest_path",
        "parallelism_model": "mpi+omp",
        "prompt": "#include <mpi.h>\n#include <omp.h>\n\n/* Return the length of the shortest path from source to dest in the graph defined by the adjacency matrix A.\n   A is an NxN adjacency matrix stored in row-major.\n   Use MPI and OpenMP to compute in parallel. Assume MPI has already been initialized.\n   Every rank has a complete copy of A. The shortest path length is returned on rank 0.\n   Example:\n\n\t input: [[0, 1, 1, 0], [1, 0, 0, 1], [1, 0, 0, 1], [0, 1, 1, 0]], source=0, dest=3\n   output: 2\n*/\nint shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {",
        "temperature": 0.8,
        "top_p": 0.95,
        "do_sample": true,
        "max_new_tokens": 1024,
        "prompted": false,
        "outputs": [
            "return 0;\n}",
            "// TODO: Your code here\n}",
            "int answer;\n\t// TODO\n\treturn answer;\n}",
            "// TODO\n  return 0;\n}",
            "std::vector<int> queue(N);\n    int const inf = std::numeric_limits<int>::max();\n\n    #pragma omp parallel\n    {\n        std::vector<int> dist(N, inf);\n        dist[source] = 0;\n\n        int front = 0;\n        int rear = 0;\n\n        queue[rear++] = source;\n\n        // BFS\n        while (front!= rear) {\n            int u = queue[front++];\n            for (size_t v = 0; v < N; ++v) {\n                if (A[u * N + v] == 0 || dist[v]!= inf) continue;\n\n                #pragma omp critical\n                {\n                    if (dist[v] == inf) {\n                        queue[rear++] = v;\n                    }\n                    dist[v] = dist[u] + 1;\n                }\n            }\n        }\n\n        #pragma omp critical\n        {\n            if (dist[dest]!= inf)\n                for (size_t i = 0; i < N; ++i)\n                    if (dist[i] == inf)\n                        dist[i] = -1;\n        }\n    }\n\n    return dist[dest];\n}",
            "std::vector<int> lengths(N);\n    for (auto& len : lengths) {\n        len = std::numeric_limits<int>::max();\n    }\n    lengths[source] = 0;\n\n    // 1. Initialize the frontier queue.\n    std::deque<int> frontier;\n    frontier.push_back(source);\n    bool frontierIsEmpty = false;\n\n    // 2. While there are elements on the frontier:\n    while (!frontierIsEmpty) {\n        // 2.1. Fetch an element from the frontier.\n        int vertex = frontier.front();\n        frontier.pop_front();\n\n        // 2.2. For every neighbor of the vertex (i.e. every row i of A):\n        #pragma omp parallel for\n        for (int i = 0; i < N; i++) {\n            // 2.2.1. If the length from the source to i is the shortest so far and i is not the destination:\n            if (lengths[i] > lengths[vertex] + A[vertex * N + i]) {\n                // 2.2.2. Set the length of the path from the source to i.\n                lengths[i] = lengths[vertex] + A[vertex * N + i];\n\n                // 2.2.3. Add i to the frontier if it is not already there.\n                if (i!= dest) {\n                    #pragma omp critical\n                    {\n                        frontier.push_back(i);\n                    }\n                }\n            }\n        }\n    }\n\n    // 3. Return the length of the shortest path from the source to the destination.\n    return lengths[dest];\n}",
            "std::vector<int> distance(N, INT_MAX);\n\tdistance[source] = 0;\n\n\tfor (int i = 0; i < N; ++i) {\n\t\tfor (int j = 0; j < N; ++j) {\n\t\t\tif (A[i * N + j] == 0) continue;\n\n\t\t\tif (distance[j]!= INT_MAX && distance[j] + 1 < distance[i])\n\t\t\t\tdistance[i] = distance[j] + 1;\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "// TODO\n    return 0;\n}",
            "// TODO\n\treturn -1;\n}",
            "/*\n\t\t1. Every thread calculate the shortest path length for each row\n\t\t2. Rank 0 compare and select the shortest\n\t*/\n\n\tint *d_A = new int[N * N];\n\tfor (int i = 0; i < N * N; i++) {\n\t\td_A[i] = A[i];\n\t}\n\n\tint* d_dist = new int[N];\n\n\t#pragma omp parallel\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\tint nthreads = omp_get_num_threads();\n\n\t\tint start = tid * N / nthreads;\n\t\tint end = start + N / nthreads;\n\n\t\tfor (int i = start; i < end; i++) {\n\t\t\td_dist[i] = -1;\n\t\t}\n\n\t\t#pragma omp single\n\t\t{\n\t\t\tfor (int i = 0; i < nthreads; i++) {\n\t\t\t\tif (i == 0) {\n\t\t\t\t\td_dist[source] = 0;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\td_dist[i * N / nthreads] = -1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 0; i < nthreads; i++) {\n\t\t\tfor (int j = 0; j < nthreads; j++) {\n\t\t\t\tif (i!= j) {\n\t\t\t\t\t#pragma omp barrier\n\t\t\t\t\t#pragma omp single\n\t\t\t\t\t{\n\t\t\t\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\t\t\t\tif (d_dist[k] == i * N / nthreads) {\n\t\t\t\t\t\t\t\tfor (int m = 0; m < N; m++) {\n\t\t\t\t\t\t\t\t\tif (d_A[k * N + m] == 1) {\n\t\t\t\t\t\t\t\t\t\td_dist[m] = j * N / nthreads;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint* d_dist_copy = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\td_dist_copy[i] = d_dist[i];\n\t}\n\n\tint* d_dist_final = new int[N];\n\n\tint d_rank = 0;\n\n\t#pragma omp parallel\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\tint nthreads = omp_get_num_threads();\n\n\t\tint start = tid * N / nthreads;\n\t\tint end = start + N / nthreads;\n\n\t\tfor (int i = start; i < end; i++) {\n\t\t\tif (d_dist_copy[i] == dest) {\n\t\t\t\td_dist_final[i] = 1;\n\t\t\t}\n\t\t\telse if (d_dist_copy[i] == -1) {\n\t\t\t\td_dist_final[i] = -1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\td_dist_final[i] = 0;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\t#pragma omp single\n\t\t{\n\t\t\tfor (int i = 0; i < N; i++) {\n\t\t\t\tif (d_dist_final[i] == 1) {\n\t\t\t\t\td_rank = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (d_rank!= -1) {\n\t\treturn d_dist[d_rank];\n\t}\n\telse {\n\t\treturn -1;\n\t}\n}",
            "int path_length;\n\tMPI_Status status;\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tstd::vector<int> path_lengths(size);\n\tstd::vector<int> visited(N, 0);\n\n\tstd::vector<int> temp(N);\n\n\tif (source == dest) {\n\t\tpath_length = 0;\n\t} else if (source == rank) {\n\t\tvisited[source] = 1;\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\ttemp[i] = (A[source * N + i] &&!visited[i])? shortestPathLength(A, N, i, dest) + 1 : -1;\n\t\t}\n\t\tpath_length = std::numeric_limits<int>::max();\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (temp[i]!= -1 && path_length > temp[i])\n\t\t\t\tpath_length = temp[i];\n\t\t}\n\t} else {\n\t\tpath_length = -1;\n\t}\n\n\tif (rank == 0)\n\t\tMPI_Gather(&path_length, 1, MPI_INT, &path_lengths[0], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\telse\n\t\tMPI_Gather(&path_length, 1, MPI_INT, NULL, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\t\tpath_length = std::numeric_limits<int>::max();\n\t\tfor (int i = 0; i < size; i++) {\n\t\t\tif (path_lengths[i]!= -1 && path_length > path_lengths[i])\n\t\t\t\tpath_length = path_lengths[i];\n\t\t}\n\t}\n\n\treturn path_length;\n}",
            "// YOUR CODE GOES HERE\n}",
            "std::vector<int> Q;\n  std::vector<int> distances;\n  std::vector<int> prev;\n  std::queue<int> q;\n  int rank = 0, size = 0;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  Q.assign(N, 0);\n  distances.assign(N, INT_MAX);\n  prev.assign(N, 0);\n  int flag = 0;\n  if(rank == 0){\n    Q[source] = 1;\n    distances[source] = 0;\n    q.push(source);\n  }\n  while(!q.empty()){\n    int u = q.front();\n    q.pop();\n    for(int i = 0; i < N; i++){\n      if(A[u*N + i] == 1 && Q[i] == 0){\n        Q[i] = 1;\n        distances[i] = distances[u] + 1;\n        prev[i] = u;\n        q.push(i);\n      }\n    }\n    if(Q[dest] == 1){\n      flag = 1;\n      break;\n    }\n  }\n  int max_dist = 0;\n  MPI_Reduce(&flag, &max_dist, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  if(max_dist == 1){\n    int max_dist = INT_MAX;\n    MPI_Reduce(&distances[dest], &max_dist, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    return max_dist;\n  }else{\n    return -1;\n  }\n}",
            "// TODO: implement me!\n\n  int nthreads=omp_get_max_threads();\n  //cout<<\"Number of threads: \"<<nthreads<<endl;\n  int nnodes = N * nthreads;\n  int myrank;\n  int rcounts[nthreads];\n  int rdispls[nthreads];\n  //int* sendbuf;\n  //int* recvbuf;\n  int displs[nnodes];\n  int* new_displs;\n  int *sendbuf, *recvbuf;\n  int local_source=source/nthreads;\n  int local_dest=dest/nthreads;\n\n  int* new_sendbuf;\n  int* new_recvbuf;\n\n\n  int* temp;\n  int** temp2;\n  int temp_val;\n  int temp_val2;\n\n  MPI_Comm_rank(MPI_COMM_WORLD,&myrank);\n  MPI_Comm_size(MPI_COMM_WORLD,&nthreads);\n\n  //cout<<\"Inside parallel region\"<<endl;\n\n  //cout<<\"local_source \"<<local_source<<endl;\n  //cout<<\"local_dest \"<<local_dest<<endl;\n  //cout<<\"source \"<<source<<endl;\n  //cout<<\"dest \"<<dest<<endl;\n\n  //Calculate displs array\n  int i = 0;\n  int j = 0;\n  for(i=0; i<nnodes; i++){\n    displs[i] = 0;\n  }\n\n  for(i=0; i<nnodes; i++){\n    if(i<(local_source)){\n      displs[i] = 0;\n    }\n    else if(i==local_source){\n      for(j=0; j<(local_source); j++){\n        displs[i] = displs[i] + A[i*N + j];\n      }\n    }\n    else{\n      displs[i] = displs[i-1] + A[(i-1)*N + (i-1)];\n    }\n  }\n\n  //cout<<\"Displs array\"<<endl;\n  for(i=0; i<nnodes; i++){\n    cout<<displs[i]<<\",\";\n  }\n  cout<<endl;\n\n  //Calculate rcounts and rdispls array\n\n  for(i=0; i<nthreads; i++){\n    if(i==0){\n      rcounts[i] = displs[local_dest] - displs[local_source];\n      rdispls[i] = 0;\n    }\n    else if(i==(nthreads-1)){\n      rcounts[i] = displs[(local_dest+1)*(nthreads)] - displs[local_dest*(nthreads)];\n      rdispls[i] = rdispls[i-1] + rcounts[i-1];\n    }\n    else{\n      rcounts[i] = displs[(local_dest+1)*(nthreads)] - displs[local_dest*(nthreads)];\n      rdispls[i] = rdispls[i-1] + rcounts[i-1];\n    }\n  }\n  //cout<<\"Rcounts array\"<<endl;\n  for(i=0; i<nthreads; i++){\n    cout<<rcounts[i]<<\",\";\n  }\n  cout<<endl;\n  //cout<<\"Rdispls array\"<<endl;\n  for(i=0; i<nthreads; i++){\n    cout<<rdispls[i]<<\",\";\n  }\n  cout<<endl;\n\n  //Calculate new_displs array\n  for(i=0; i<nnodes; i++){\n    new_displs[i] = 0;\n  }\n\n  for(i=0; i<nnodes; i++){\n    if(i<(local_source)){\n      new_displs[i] = 0;\n    }\n    else if(i==local_source){\n      for(j=0; j<(local_source); j",
            "// Your code goes here!\n\t\n\tstd::vector<int> distance(N, INFINITY);\n\n\t// Initialize distance of source\n\tdistance[source] = 0;\n\n\t// Iterate for |V| - 1 times\n\tfor (int i = 0; i < N - 1; i++) {\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tfor (int w = 0; w < N; w++) {\n\t\t\t\t// Relax (u, v)\n\t\t\t\tif (distance[v] > distance[w] + A[w*N + v]) {\n\t\t\t\t\tdistance[v] = distance[w] + A[w*N + v];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn distance[dest];\n}",
            "std::vector<int> dist(N, 0);\n    std::vector<bool> vis(N, false);\n\n    for (int i = 0; i < N; i++) {\n        dist[i] = INT_MAX;\n    }\n    dist[source] = 0;\n    std::queue<int> q;\n    q.push(source);\n    while (!q.empty()) {\n        int u = q.front();\n        q.pop();\n        vis[u] = true;\n        for (int v = 0; v < N; v++) {\n            if (A[u*N + v] == 1 &&!vis[v]) {\n                dist[v] = dist[u] + 1;\n                q.push(v);\n            }\n        }\n    }\n    return dist[dest];\n}",
            "// YOUR CODE HERE\n  return 0;\n}",
            "if (source == dest)\n        return 0;\n    int res = std::numeric_limits<int>::max();\n    // TODO: Fill in the shortestPathLength() function\n    return res;\n}",
            "// TODO\n}",
            "std::vector<int> dist(N, -1);\n\tdist[source] = 0;\n\tbool updated = true;\n\twhile (updated) {\n\t\tupdated = false;\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (dist[i]!= -1) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (A[i * N + j] && dist[j] == -1) {\n\t\t\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\t\t\tupdated = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "// YOUR CODE HERE\n    int shortest=1000000;\n    int x;\n    int y;\n    int temp;\n    int temp2;\n    int temp3;\n    std::vector<int> distance(N,0);\n    std::vector<int> pred(N,0);\n    std::vector<int> path(N,0);\n    distance[source]=0;\n    pred[source]=source;\n    int myrank;\n    int size;\n    int root=0;\n\n    MPI_Comm_rank(MPI_COMM_WORLD,&myrank);\n    MPI_Comm_size(MPI_COMM_WORLD,&size);\n\n    for(int i=0; i<N; i++){\n        int i_rank = i/((N/size)+1);\n        int i_begin = i_rank*(N/size)+(i_rank>0);\n        int i_end = i_begin+(N/size)+(i_rank<size-1);\n        for(int j=i_begin; j<i_end; j++){\n            temp3 = distance[j]+A[j*N+i];\n            if(temp3<distance[i] || distance[i]==0){\n                distance[i]=temp3;\n                pred[i]=j;\n            }\n        }\n    }\n\n    MPI_Gather(&distance,N,MPI_INT,path.data(),N,MPI_INT,root,MPI_COMM_WORLD);\n    MPI_Gather(&pred,N,MPI_INT,path.data(),N,MPI_INT,root,MPI_COMM_WORLD);\n\n    MPI_Gather(&distance,1,MPI_INT,&temp,1,MPI_INT,root,MPI_COMM_WORLD);\n    MPI_Gather(&pred,1,MPI_INT,&temp,1,MPI_INT,root,MPI_COMM_WORLD);\n\n    if(myrank==0){\n        for(int i=0; i<size; i++){\n            for(int j=0; j<N; j++){\n                if(path[j]<shortest){\n                    shortest=path[j];\n                }\n            }\n        }\n        MPI_Bcast(&shortest,1,MPI_INT,0,MPI_COMM_WORLD);\n    }\n    else{\n        MPI_Bcast(&shortest,1,MPI_INT,0,MPI_COMM_WORLD);\n    }\n\n    return shortest;\n\n}",
            "std::vector<bool> visited(N, false);\n  std::vector<int> distances(N, INT_MAX);\n\n  visited[source] = true;\n  distances[source] = 0;\n\n  for (size_t t = 0; t < N - 1; ++t) {\n    for (size_t i = 0; i < N; ++i) {\n      for (size_t j = 0; j < N; ++j) {\n        if (!visited[j]) {\n          int new_dist = std::min(distances[i] + A[i * N + j], distances[j]);\n          if (new_dist < distances[j]) {\n            distances[j] = new_dist;\n          }\n        }\n      }\n    }\n  }\n\n  return distances[dest];\n}",
            "/* YOUR CODE HERE */\n}",
            "int dist[N];\n  int pred[N];\n\n  bool found = false;\n  omp_set_num_threads(4);\n  #pragma omp parallel\n  {\n    int tid = omp_get_thread_num();\n    #pragma omp for\n    for (int i = 0; i < N; ++i) {\n      dist[i] = A[tid * N + i];\n      pred[i] = -1;\n    }\n    dist[source] = 0;\n    pred[source] = -2;\n\n    bool changed;\n    do {\n      changed = false;\n      #pragma omp for\n      for (int i = 0; i < N; ++i) {\n        int newDist = dist[i];\n        for (int j = 0; j < N; ++j) {\n          if (A[tid * N + j] < dist[j]) {\n            newDist = A[tid * N + j];\n          }\n        }\n        if (newDist!= dist[i]) {\n          changed = true;\n        }\n        dist[i] = newDist;\n        pred[i] = j;\n      }\n    } while (changed);\n  }\n\n  int dist_final[N];\n  #pragma omp parallel for\n  for (int i = 0; i < N; ++i) {\n    dist_final[i] = dist[i];\n  }\n\n  int min_dist = dist_final[dest];\n  for (int i = 0; i < N; ++i) {\n    if (dist_final[i] < min_dist) {\n      min_dist = dist_final[i];\n    }\n  }\n\n  return min_dist;\n}",
            "// TODO\n  return -1;\n}",
            "// Replace this comment with your code\n    return 0;\n}",
            "if (N == 0) return 0;\n  int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  if (rank == 0) {\n    std::vector<std::vector<int>> B(N, std::vector<int>(N, 0));\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        B[i][j] = A[i*N + j];\n      }\n    }\n\n    std::vector<int> dist(N, INT_MAX);\n    dist[source] = 0;\n    bool changed = true;\n\n    // TODO\n    while (changed) {\n      changed = false;\n      for (size_t i = 0; i < N; i++) {\n        for (size_t j = 0; j < N; j++) {\n          if (B[i][j]!= 0 && dist[i]!= INT_MAX && dist[j] > dist[i] + B[i][j]) {\n            changed = true;\n            dist[j] = dist[i] + B[i][j];\n          }\n        }\n      }\n    }\n\n    return dist[dest];\n  } else {\n    // TODO\n    return -1;\n  }\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n  dist[source] = 0;\n\n  // MPI stuff.\n  int world_size, world_rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n  MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n  int num_rows = N / world_size;\n  int remainder = N % world_size;\n  int start = world_rank * num_rows;\n  int end = start + num_rows;\n  if (world_rank == world_size - 1) {\n    end += remainder;\n  }\n\n  int num_rows_local = end - start;\n  std::vector<int> local_dist(num_rows_local, std::numeric_limits<int>::max());\n  for (int i = 0; i < num_rows_local; i++) {\n    local_dist[i] = dist[i + start];\n  }\n\n  // Breadth-first search to find the shortest path from source to dest.\n  std::vector<int> queue;\n  queue.push_back(source);\n  std::vector<int> parent(N, -1);\n  parent[source] = source;\n  while (!queue.empty()) {\n    int curr = queue.front();\n    queue.erase(queue.begin());\n    for (int i = 0; i < N; i++) {\n      if (A[curr * N + i] == 1 && local_dist[i] == std::numeric_limits<int>::max()) {\n        local_dist[i] = local_dist[curr] + 1;\n        parent[i] = curr;\n        queue.push_back(i);\n      }\n    }\n  }\n\n  // Find the shortest path length between the source and dest.\n  int local_len = std::numeric_limits<int>::max();\n  if (dest < num_rows_local) {\n    local_len = local_dist[dest];\n  }\n  // Merge the results from all the ranks.\n  int len = std::numeric_limits<int>::max();\n  MPI_Reduce(&local_len, &len, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n  // Compute the shortest path length.\n  if (world_rank == 0) {\n    for (int i = 0; i < N; i++) {\n      if (dist[i]!= std::numeric_limits<int>::max() && parent[i]!= -1) {\n        while (i!= source) {\n          i = parent[i];\n        }\n        return dist[i];\n      }\n    }\n  }\n  return len;\n}",
            "if(source == dest) {\n    return 0;\n  }\n  std::vector<int> V(N);\n  for(int i = 0; i < N; ++i) {\n    V[i] = 1 << 30;\n  }\n  V[source] = 0;\n  bool change = true;\n  while(change) {\n    change = false;\n#pragma omp parallel for reduction(&&:change) schedule(guided)\n    for(int u = 0; u < N; ++u) {\n      for(int v = 0; v < N; ++v) {\n        if(u == v) {\n          continue;\n        }\n        if(A[u * N + v] == 1 && V[u]!= 1 << 30 && V[u] + 1 < V[v]) {\n          V[v] = V[u] + 1;\n          change = true;\n        }\n      }\n    }\n  }\n  return V[dest];\n}",
            "// Your code here.\n}",
            "if (source == dest) return 0;\n\n    int *shortestPath = new int[N];\n    for (int i = 0; i < N; i++) shortestPath[i] = INT_MAX;\n    shortestPath[source] = 0;\n\n    #pragma omp parallel for schedule(dynamic)\n    for (int k = 0; k < N; k++) {\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (shortestPath[i]!= INT_MAX && shortestPath[j] > shortestPath[i] + A[i*N + j]) {\n                    shortestPath[j] = shortestPath[i] + A[i*N + j];\n                }\n            }\n        }\n    }\n\n    int length = shortestPath[dest];\n    delete[] shortestPath;\n    return length;\n}",
            "return 0;\n}",
            "int myrank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n    if (myrank == 0) {\n        // Use MPI to distribute the work of finding the shortest path length from source to dest across the ranks\n\n        // Use OpenMP to parallelize the work that each rank has to do\n\n    } else {\n        // Do work assigned to this rank\n    }\n}",
            "// TODO: YOUR CODE HERE\n\treturn -1;\n}",
            "// TODO: YOUR CODE HERE\n  return 0;\n}",
            "int* bfs_queue = new int[N];\n  int* bfs_dist = new int[N];\n\n  bfs_queue[0] = source;\n  bfs_dist[source] = 0;\n\n  int queue_begin = 0;\n  int queue_end = 1;\n\n  for (int cur_bfs_round = 0; cur_bfs_round < N; ++cur_bfs_round) {\n\n    #pragma omp parallel for\n    for (int i = queue_begin; i < queue_end; ++i) {\n\n      int cur = bfs_queue[i];\n\n      #pragma omp parallel for\n      for (int j = 0; j < N; ++j) {\n\n        if (A[cur*N + j] && bfs_dist[j] == -1) {\n          #pragma omp critical\n          {\n            bfs_queue[queue_end] = j;\n            bfs_dist[j] = bfs_dist[cur] + 1;\n            ++queue_end;\n          }\n        }\n\n      }\n\n    }\n\n    queue_begin = queue_end;\n\n  }\n\n\n  int ret = -1;\n  if (bfs_dist[dest]!= -1) {\n    ret = bfs_dist[dest];\n  }\n\n  delete[] bfs_queue;\n  delete[] bfs_dist;\n\n  return ret;\n\n}",
            "}",
            "if (source == dest)\n    {\n        return 0;\n    }\n\n    int num_proc;\n    int rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &num_proc);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    int sendcounts[num_proc];\n    int displs[num_proc];\n    int* recvcounts = new int[num_proc];\n    int* sendbuf = new int[N];\n    int* recvbuf = new int[N];\n\n    for (int i = 0; i < num_proc; i++)\n    {\n        if (rank == i)\n        {\n            sendcounts[i] = N;\n            displs[i] = 0;\n            for (int j = 0; j < N; j++)\n            {\n                sendbuf[j] = A[j*N+i];\n            }\n        }\n        else\n        {\n            sendcounts[i] = 0;\n            displs[i] = 0;\n        }\n    }\n\n    MPI_Gatherv(sendbuf, N, MPI_INT, recvbuf, recvcounts, displs, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (rank == 0)\n    {\n        delete[] sendbuf;\n        delete[] recvcounts;\n    }\n\n    int global_shortest_length = INT_MAX;\n    if (rank == 0)\n    {\n        global_shortest_length = INT_MAX;\n        for (int i = 0; i < N; i++)\n        {\n            if (recvbuf[i] == 1)\n            {\n                global_shortest_length = std::min(global_shortest_length, shortestPathLength(recvbuf, N, i, dest));\n            }\n        }\n    }\n\n    MPI_Bcast(&global_shortest_length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n    return global_shortest_length;\n}",
            "// TODO: implement me\n\n    int *distance = new int[N];\n    bool *visited = new bool[N];\n    int *parent = new int[N];\n    int i, j;\n\n    for (i = 0; i < N; i++) {\n        distance[i] = INT_MAX;\n        visited[i] = false;\n        parent[i] = -1;\n    }\n\n    distance[source] = 0;\n\n    for (i = 0; i < N; i++) {\n        int u = -1, min = INT_MAX;\n        for (j = 0; j < N; j++) {\n            if (visited[j] == false && distance[j] <= min) {\n                u = j;\n                min = distance[j];\n            }\n        }\n\n        if (u == -1)\n            break;\n\n        visited[u] = true;\n\n        for (j = 0; j < N; j++) {\n            if (!visited[j] && A[u * N + j] && distance[u]!= INT_MAX && distance[u] + A[u * N + j] < distance[j]) {\n                distance[j] = distance[u] + A[u * N + j];\n                parent[j] = u;\n            }\n        }\n    }\n\n    if (distance[dest]!= INT_MAX) {\n        printf(\"shortestPath(%d, %d): %d\\n\", source, dest, distance[dest]);\n    } else {\n        printf(\"There is no path from %d to %d\\n\", source, dest);\n    }\n\n    return distance[dest];\n}",
            "int const n = A.size();\n    std::vector<int> dist(n, std::numeric_limits<int>::max());\n    std::vector<bool> visited(n, false);\n    std::vector<int> predecessors(n, -1);\n    std::vector<std::vector<int>> Q(n);\n\n    dist[source] = 0;\n    visited[source] = true;\n    Q[0].push_back(source);\n\n    while (!Q[0].empty()) {\n        std::vector<int> next;\n        for (auto const& node : Q[0]) {\n            for (int i = 0; i < n; ++i) {\n                if (A[node*n + i]) {\n                    if (dist[i] > dist[node] + 1) {\n                        dist[i] = dist[node] + 1;\n                        predecessors[i] = node;\n                        visited[i] = true;\n                        next.push_back(i);\n                    }\n                }\n            }\n        }\n        Q.push_back(std::move(next));\n        Q.erase(Q.begin());\n    }\n\n    return dist[dest];\n}",
            "// TODO: Your code here\n  if (source == dest) {\n    return 0;\n  }\n\n  std::vector<int> distances(N, INT_MAX);\n  std::vector<int> queue(N, 0);\n  int head = 0, tail = 0;\n  std::vector<bool> visited(N, false);\n  distances[source] = 0;\n  queue[tail++] = source;\n  visited[source] = true;\n  while (head < tail) {\n    auto u = queue[head++];\n    for (int v = 0; v < N; ++v) {\n      if (!visited[v] && A[u * N + v]) {\n        visited[v] = true;\n        distances[v] = distances[u] + 1;\n        queue[tail++] = v;\n      }\n    }\n  }\n\n  return distances[dest];\n}",
            "// Replace this code with a correct implementation\n    if(dest == source){\n        return 0;\n    }\n    int world_size, world_rank;\n    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n    int nb_threads = omp_get_max_threads();\n    int chunksize = N / nb_threads;\n    int chunksize_remain = N % nb_threads;\n    std::vector<int> dists_mpi(N, INT_MAX);\n    if(source == dest){\n        dists_mpi[source] = 0;\n    }\n    std::vector<int> dists_omp(N, INT_MAX);\n\n    if(world_rank == 0){\n        for(int j = 0; j < chunksize + chunksize_remain; j++){\n            for(int i = 0; i < N; i++){\n                for(int k = 0; k < N; k++){\n                    if(A[i*N+k] == 1 && dists_mpi[i]!= INT_MAX && dists_mpi[i] + 1 < dists_mpi[k]){\n                        dists_mpi[k] = dists_mpi[i] + 1;\n                    }\n                }\n            }\n        }\n    }\n    else{\n        for(int j = 0; j < chunksize; j++){\n            for(int i = 0; i < N; i++){\n                for(int k = 0; k < N; k++){\n                    if(A[i*N+k] == 1 && dists_omp[i]!= INT_MAX && dists_omp[i] + 1 < dists_omp[k]){\n                        dists_omp[k] = dists_omp[i] + 1;\n                    }\n                }\n            }\n        }\n    }\n\n    MPI_Reduce(dists_omp.data(), dists_mpi.data(), N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    int dist = dists_mpi[dest];\n    if(dist == INT_MAX){\n        dist = -1;\n    }\n    return dist;\n}",
            "int length = -1;\n  int *distance = (int *) malloc(N * sizeof(int));\n  int *visited = (int *) malloc(N * sizeof(int));\n  int *parents = (int *) malloc(N * sizeof(int));\n  memset(distance, -1, N * sizeof(int));\n  memset(visited, 0, N * sizeof(int));\n  distance[source] = 0;\n  parents[source] = -1;\n  for (int i = 0; i < N; i++) {\n    int min = -1;\n    int min_i = -1;\n    for (int j = 0; j < N; j++) {\n      if (distance[j] >= 0 && (min == -1 || distance[j] < min)) {\n        min = distance[j];\n        min_i = j;\n      }\n    }\n    if (min_i == -1) {\n      break;\n    }\n    visited[min_i] = 1;\n    for (int j = 0; j < N; j++) {\n      if (A[min_i * N + j]!= 0 && visited[j] == 0) {\n        distance[j] = distance[min_i] + 1;\n        parents[j] = min_i;\n      }\n    }\n  }\n  for (int i = 0; i < N; i++) {\n    if (distance[i] == dest) {\n      length = i;\n      break;\n    }\n  }\n  free(distance);\n  free(visited);\n  free(parents);\n  return length;\n}",
            "int length = N;\n  // TODO\n  return length;\n}",
            "int *adjacency = new int[N * N];\n  for (size_t i = 0; i < N * N; i++) {\n      adjacency[i] = A[i];\n  }\n  int* distance = new int[N];\n  int* path = new int[N];\n  int* path_local = new int[N];\n  int* distance_local = new int[N];\n  int* distance_temp = new int[N];\n  int* distance_local_temp = new int[N];\n  for (size_t i = 0; i < N; i++) {\n      distance[i] = 0;\n      path[i] = 0;\n      distance_local[i] = 0;\n      distance_local_temp[i] = 0;\n      path_local[i] = 0;\n  }\n\n  distance[source] = 1;\n  distance_local[source] = 1;\n  path_local[source] = source;\n\n  int nb_vertices = 0;\n  int nb_vertices_local = 0;\n  int nb_vertices_local_temp = 0;\n  std::vector<int> rank_list;\n  int rank = 0;\n  int rank_local = 0;\n  int rank_local_temp = 0;\n  int tag = 0;\n  int tag_local = 0;\n  int nb_vertices_global = 0;\n  int nb_vertices_global_temp = 0;\n  int nb_vertices_global_temp_copy = 0;\n  int source_local = 0;\n  int source_temp = 0;\n  int dest_local = 0;\n  int dest_temp = 0;\n  int dest_local_temp = 0;\n  int dest_local_temp_copy = 0;\n  int source_local_temp = 0;\n  int source_local_temp_copy = 0;\n  int dest_local_temp_copy = 0;\n  int rank_local_temp_copy = 0;\n  int dest_temp_copy = 0;\n  int nb_vertices_global_copy = 0;\n  int rank_local_copy = 0;\n  int rank_local_copy_copy = 0;\n  int rank_local_temp_copy_copy = 0;\n  int source_local_copy = 0;\n  int source_local_temp_copy_copy = 0;\n  int nb_vertices_global_temp_copy_copy = 0;\n  int source_local_temp_copy_copy_copy = 0;\n  int source_temp_copy = 0;\n  int source_local_temp_copy_copy_copy_copy = 0;\n  int source_local_temp_copy_copy_copy_copy_copy = 0;\n  int dest_local_temp_copy_copy = 0;\n  int source_temp_copy_copy = 0;\n  int source_local_temp_copy_copy_copy_copy_copy_copy = 0;\n  int source_local_temp_copy_copy_copy_copy_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy_copy = 0;\n  int dest_temp_copy_copy = 0;\n  int dest_local_temp_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy_copy_copy = 0;\n  int dest_temp_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy_copy_copy_copy = 0;\n  int dest_temp_copy_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy_copy_copy_copy_copy = 0;\n  int dest_temp_copy_copy_copy_copy_copy = 0;\n  int source_temp_copy_copy_copy_copy_copy_copy_copy_copy = 0;\n  int nb_vertices_global_temp_copy_copy_copy = 0;\n  int source_local",
            "int result;\n    MPI_Allreduce(&result, &result, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n    return result;\n}",
            "// TODO: your code here\n    return 0;\n}",
            "int rank;\n\tint size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint source_rank;\n\tint dest_rank;\n\tint source_col;\n\tint dest_col;\n\tint col_size;\n\tint num_col_proc;\n\tint start_col;\n\n\tif (rank == 0) {\n\t\tsource_rank = source / size;\n\t\tdest_rank = dest / size;\n\t\tsource_col = source % size;\n\t\tdest_col = dest % size;\n\t\tcol_size = N / size;\n\t\tnum_col_proc = N / col_size;\n\t\tstart_col = rank * col_size;\n\t\t//printf(\"N = %d, source = %d, dest = %d, source_rank = %d, dest_rank = %d, source_col = %d, dest_col = %d, col_size = %d, num_col_proc = %d, start_col = %d\\n\", N, source, dest, source_rank, dest_rank, source_col, dest_col, col_size, num_col_proc, start_col);\n\t}\n\n\tMPI_Bcast(&source_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&dest_rank, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&source_col, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&dest_col, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&col_size, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&num_col_proc, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\tMPI_Bcast(&start_col, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tstd::vector<int> local_A(col_size * col_size);\n\n\tfor (int i = 0; i < col_size; i++) {\n\t\tfor (int j = 0; j < col_size; j++) {\n\t\t\tlocal_A[i * col_size + j] = A[(start_col + i) * N + (start_col + j)];\n\t\t}\n\t}\n\n\tint num_row_proc = (N / col_size) / size;\n\tint row_size = N / num_row_proc;\n\tint num_row_proc_next = (N / col_size) % size;\n\tint row_size_next = N / num_row_proc_next;\n\tint num_row_proc_this = rank < num_row_proc_next? (row_size + 1) : row_size;\n\tint num_row_this = N / num_row_proc_this;\n\tint num_row_next = N / num_row_proc_next;\n\n\tint num_row = (rank < num_row_proc_next)? num_row_this + 1 : num_row_this;\n\n\tstd::vector<int> dist(num_row, INT_MAX);\n\tstd::vector<int> prev(num_row, -1);\n\n\tint source_row = source / N;\n\tint dest_row = dest / N;\n\n\tdist[source_row] = 0;\n\n\tfor (int i = 0; i < num_row; i++) {\n\t\tint min_dist = INT_MAX;\n\t\tint min_dist_idx = -1;\n\t\tfor (int j = 0; j < num_row; j++) {\n\t\t\tif (dist[j] < min_dist) {\n\t\t\t\tmin_dist = dist[j];\n\t\t\t\tmin_dist_idx = j;\n\t\t\t}\n\t\t}\n\t\tif (min_dist_idx == -1",
            "// your code here\n\treturn 0;\n}",
            "int p = 0;\n\tstd::vector<int> dists(N, -1);\n\tdists[source] = 0;\n\tstd::vector<int> Q(N, 1);\n\tQ[source] = 0;\n\t\n\twhile (p < Q.size()) {\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (Q[i] == 0 && dists[i] < 0) {\n\t\t\t\tQ[i] = 1;\n\t\t\t\tdists[i] = dists[source] + 1;\n\t\t\t\tif (i == dest)\n\t\t\t\t\treturn dists[i];\n\t\t\t\t\n\t\t\t\tfor (size_t j = 0; j < N; ++j)\n\t\t\t\t\tif (A[i*N + j]!= 0)\n\t\t\t\t\t\tQ[j] = 0;\n\t\t\t\t\t\n\t\t\t}\n\t\t}\n\t\t++p;\n\t\t\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (Q[i] == 1)\n\t\t\t\tQ[i] = 0;\n\t\t}\n\t}\n\t\n\treturn -1;\n}",
            "// TODO:\n    // 1. Initialize the BFS queue\n    // 2. Run BFS from the source vertex\n    // 3. Return the length of the shortest path\n}",
            "int result;\n#pragma omp parallel\n{\n    // TODO\n}\n    MPI_Reduce(&result, &result, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n    return result;\n}",
            "/* \n   * Your code here\n   *\n   * Your solution must use OpenMP for parallelization and MPI for distributed computation.\n   * You can use any MPI calls besides MPI_Send/MPI_Recv, but we suggest using MPI_Bcast and\n   * MPI_Scatter/MPI_Gather. Note that all code for sending/receiving must be performed by\n   * a single thread on each rank!\n   *\n   * The code must be portable to any number of nodes and processors on each node.\n   * You can assume that N is a multiple of the number of processors on a node, and the size\n   * of the matrix is NxN. \n   */\n\n  // You can use this for testing:\n  //int shortestPathLength(std::vector<int> const& A, size_t N, int source, int dest) {\n  //  if (source == dest) return 0;\n  //  if (source == 0) {\n  //    int min = 1e8;\n  //    for (int i = 0; i < N; i++) {\n  //      if (i == source) continue;\n  //      if (A[source * N + i] == 0) continue;\n  //      int len = shortestPathLength(A, N, i, dest);\n  //      if (len < min) min = len;\n  //    }\n  //    return min + 1;\n  //  }\n  //  int min = 1e8;\n  //  for (int i = 0; i < N; i++) {\n  //    if (i == source) continue;\n  //    if (A[source * N + i] == 0) continue;\n  //    int len = shortestPathLength(A, N, i, dest);\n  //    if (len < min) min = len;\n  //  }\n  //  return min + 1;\n  //}\n\n  return -1;\n}",
            "// TODO\n}",
            "int dist[N];\n\tint pred[N];\n\n\tfor (int i=0; i<N; i++)\n\t\tdist[i] = INT_MAX;\n\tdist[source] = 0;\n\n\tbool changed = true;\n\twhile (changed) {\n\t\tchanged = false;\n\n\t\t#pragma omp parallel for private(i)\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\tif (A[i*N+j] == 1 && (dist[i]+1) < dist[j]) {\n\t\t\t\t\tdist[j] = dist[i]+1;\n\t\t\t\t\tpred[j] = i;\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "const int nRanks = omp_get_num_threads();\n\tstd::vector<int> dists(N, 1e9);\n\tdists[source] = 0;\n\tstd::vector<int> next(N, -1);\n\tbool changed = true;\n\n\twhile (changed) {\n\t\tchanged = false;\n\n\t\t#pragma omp parallel for num_threads(nRanks)\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tint currDist = dists[i] + 1;\n\t\t\t\t\tif (dists[j] > currDist) {\n\t\t\t\t\t\tdists[j] = currDist;\n\t\t\t\t\t\tnext[j] = i;\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dists[dest];\n}",
            "int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    if (size < 2) {\n        return shortestPathLengthSeq(A, N, source, dest);\n    }\n    if (rank == 0) {\n        return shortestPathLengthSeq(A, N, source, dest);\n    }\n    int rankSize = N / size;\n    int low = rank * rankSize;\n    int high = (rank + 1) * rankSize;\n    if (rank == size - 1) {\n        high = N;\n    }\n    std::vector<int> B(low, 0);\n    for (size_t i = low; i < high; ++i) {\n        for (size_t j = 0; j < N; ++j) {\n            if (A[i * N + j]) {\n                B[i] = 1;\n            }\n        }\n    }\n    int * C = new int[rankSize];\n    MPI_Bcast(B.data(), rankSize, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Bcast(C, rankSize, MPI_INT, 0, MPI_COMM_WORLD);\n    int result = 0;\n    for (size_t i = 0; i < rankSize; ++i) {\n        if (C[i] > 0) {\n            if (B[i]) {\n                result = 1;\n            }\n            break;\n        }\n    }\n    return result + shortestPathLength(B, rankSize, 0, dest);\n}",
            "int* frontier_counts = (int*) calloc(N, sizeof(int));\n    int* frontier_displs = (int*) calloc(N, sizeof(int));\n    int* frontier_sizes = (int*) calloc(N, sizeof(int));\n    int* next_frontier_sizes = (int*) calloc(N, sizeof(int));\n    int* next_frontier_displs = (int*) calloc(N, sizeof(int));\n    int* next_frontier_counts = (int*) calloc(N, sizeof(int));\n    int* next_frontier_nexts = (int*) calloc(N, sizeof(int));\n    int* curr_frontier_nexts = (int*) calloc(N, sizeof(int));\n    int* next_frontier_currs = (int*) calloc(N, sizeof(int));\n\n    for (size_t i = 0; i < N; i++) {\n        frontier_sizes[i] = A[source*N + i];\n        frontier_displs[i] = i == 0? 0 : frontier_displs[i-1] + frontier_sizes[i-1];\n        next_frontier_sizes[i] = 0;\n        next_frontier_displs[i] = i == 0? 0 : next_frontier_displs[i-1] + next_frontier_sizes[i-1];\n    }\n\n    frontier_counts[0] = 1;\n    next_frontier_sizes[0] = frontier_sizes[0];\n    next_frontier_counts[0] = 1;\n    next_frontier_currs[0] = source;\n\n    int rank = -1, rank_count = -1;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &rank_count);\n\n    int* frontier_currs = (int*) calloc(frontier_sizes[0], sizeof(int));\n    int* next_frontier_nexts = (int*) calloc(next_frontier_sizes[0], sizeof(int));\n\n    int n = 0;\n    int shortest_path = -1;\n\n    while (true) {\n        MPI_Allgather(frontier_counts, 1, MPI_INT, frontier_displs, 1, MPI_INT, MPI_COMM_WORLD);\n        MPI_Allgather(next_frontier_counts, 1, MPI_INT, next_frontier_displs, 1, MPI_INT, MPI_COMM_WORLD);\n\n        MPI_Gatherv(next_frontier_nexts, next_frontier_sizes[rank], MPI_INT,\n                    frontier_nexts, frontier_sizes, frontier_displs, MPI_INT, 0, MPI_COMM_WORLD);\n\n        if (rank == 0) {\n            #pragma omp parallel for schedule(static)\n            for (int i = 0; i < frontier_sizes[rank]; i++) {\n                int curr = frontier_nexts[i];\n                if (curr == dest) {\n                    shortest_path = n;\n                    break;\n                }\n                for (int j = 0; j < N; j++) {\n                    if (A[curr*N + j]!= 0) {\n                        next_frontier_nexts[next_frontier_displs[j] + next_frontier_counts[j]] = j;\n                        next_frontier_counts[j] += 1;\n                    }\n                }\n            }\n            if (shortest_path!= -1) {\n                break;\n            }\n        }\n        n += 1;\n        std::swap(frontier_sizes, next_frontier_sizes);\n        std::swap(frontier_displs, next_frontier_displs);\n        std::swap(frontier_nexts, next_frontier_nexts);",
            "const int rank = omp_get_thread_num();\n  const int nRanks = omp_get_num_threads();\n  const int root = 0;\n  const int tag = 0;\n\n  const int rankAhead = (rank + 1) % nRanks;\n  const int rankBehind = (rank - 1 + nRanks) % nRanks;\n  const int nWorkers = nRanks - 1;\n  int nVertices = N;\n  int verticesPerWorker = N / nWorkers;\n  int startVertex = rank * verticesPerWorker;\n  int endVertex = (rank + 1) * verticesPerWorker;\n  int *d = (int *) malloc(N * sizeof(int));\n  int *pred = (int *) malloc(N * sizeof(int));\n  int *s = (int *) malloc(nWorkers * verticesPerWorker * sizeof(int));\n  int *t = (int *) malloc(nWorkers * verticesPerWorker * sizeof(int));\n  int *recvCounts = (int *) malloc(nRanks * sizeof(int));\n  int *displs = (int *) malloc(nRanks * sizeof(int));\n  int *msg = (int *) malloc(nWorkers * verticesPerWorker * sizeof(int));\n  std::vector<int> recvmsg(nWorkers * verticesPerWorker);\n  std::vector<int> sendmsg(nWorkers * verticesPerWorker);\n\n  for (int i = 0; i < N; ++i) {\n    d[i] = INT_MAX;\n    pred[i] = -1;\n  }\n\n  d[source] = 0;\n\n  int iter = 0;\n  bool done = false;\n  while (!done) {\n    MPI_Gather(&d[startVertex], verticesPerWorker, MPI_INT, s, verticesPerWorker, MPI_INT, root, MPI_COMM_WORLD);\n    // O(nW)\n    if (rank == root) {\n      for (int worker = 0; worker < nWorkers; ++worker) {\n        for (int i = 0; i < verticesPerWorker; ++i) {\n          int vertex = startVertex + i;\n          for (int j = 0; j < N; ++j) {\n            if (A[vertex * N + j]!= 0 && s[worker * verticesPerWorker + i] + 1 < d[j]) {\n              d[j] = s[worker * verticesPerWorker + i] + 1;\n              pred[j] = vertex;\n            }\n          }\n        }\n      }\n    }\n\n    // O(nW)\n    for (int i = 0; i < verticesPerWorker; ++i) {\n      int vertex = startVertex + i;\n      int d_vertex = d[vertex];\n      for (int j = 0; j < N; ++j) {\n        if (A[vertex * N + j]!= 0 && d_vertex + 1 < d[j]) {\n          d[j] = d_vertex + 1;\n          pred[j] = vertex;\n        }\n      }\n    }\n\n    MPI_Gather(&d[startVertex], verticesPerWorker, MPI_INT, s, verticesPerWorker, MPI_INT, root, MPI_COMM_WORLD);\n    if (rank == root) {\n      for (int worker = 0; worker < nWorkers; ++worker) {\n        for (int i = 0; i < verticesPerWorker; ++i) {\n          int vertex = startVertex + i;\n          for (int j = 0; j < N; ++j) {\n            if (A[vertex * N + j]!= 0 && s[worker * verticesPerWorker + i] + 1 < d[j]) {\n              d[j] = s[worker * verticesPerWorker + i] + 1;\n              pred[j] = vertex;\n            }\n          }\n        }\n      }\n    }\n\n    // O(nW)\n    for (int i = 0; i < verticesPerWorker; ++i) {\n      int vertex = startVertex + i;\n      int d_vertex = d[vertex];\n      for (int",
            "if (A.size()!= N*N) {\n\t\tthrow std::invalid_argument(\"input matrix is not square\");\n\t}\n\tif (source < 0 || source >= N) {\n\t\tthrow std::invalid_argument(\"source is out of bounds\");\n\t}\n\tif (dest < 0 || dest >= N) {\n\t\tthrow std::invalid_argument(\"destination is out of bounds\");\n\t}\n\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tif (rank == 0) {\n\t\t// Master process\n\t\tstd::vector<int> dist(N, -1);\n\t\tdist[source] = 0;\n\n\t\t// BFS\n\t\twhile (true) {\n\t\t\t// Mark all nodes as unvisited\n\t\t\tstd::vector<bool> visited(N, false);\n\n\t\t\t// Visit all reachable nodes\n\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\tif (visited[i]) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tint curr = i;\n\t\t\t\tint depth = 0;\n\n\t\t\t\tvisited[curr] = true;\n\t\t\t\twhile (dist[curr] < 0 || depth < dist[curr]) {\n\t\t\t\t\tdepth++;\n\t\t\t\t\tif (A[curr*N+curr] == 0) {\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tint next = A[curr*N+curr] - 1;\n\t\t\t\t\tif (dist[next] < 0 || dist[next] > depth) {\n\t\t\t\t\t\tdist[next] = depth;\n\t\t\t\t\t}\n\t\t\t\t\tcurr = next;\n\t\t\t\t\tvisited[curr] = true;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Did we finish?\n\t\t\tbool done = true;\n\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\tif (dist[i] < 0) {\n\t\t\t\t\tdone = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (done) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\treturn dist[dest];\n\t} else {\n\t\t// Slave process\n\t\tint result;\n\t\tMPI_Recv(&result, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\treturn result;\n\t}\n}",
            "// TODO: your code here\n}",
            "/* Your solution goes here.\n     For example, you may use BFS, dijkstra, or A*.\n     Please be mindful of parallelism when using MPI or OpenMP.\n  */\n  int length;\n  std::vector<int> visited(N, 0);\n  std::vector<int> queue;\n\n  queue.push_back(source);\n  visited[source] = 1;\n  length = 0;\n\n  while(queue.size()!= 0) {\n    int node = queue.back();\n    queue.pop_back();\n\n    if(node == dest) {\n      return length;\n    }\n\n    for(int i = 0; i < N; i++) {\n      if(visited[i] == 0 && A[node * N + i] == 1) {\n        queue.push_back(i);\n        visited[i] = 1;\n      }\n    }\n\n    length++;\n  }\n\n  return -1;\n}",
            "int myLength = -1;\n    #pragma omp parallel\n    {\n        std::vector<int> q;\n        q.push_back(source);\n        std::vector<bool> visited(N, false);\n        visited[source] = true;\n\n        while (!q.empty()) {\n            #pragma omp critical\n            {\n                int next = q.back();\n                q.pop_back();\n                if (next == dest) {\n                    myLength = q.size() - 1;\n                    break;\n                }\n            }\n\n            for (int i = 0; i < N; i++) {\n                if (A[next * N + i] == 1 &&!visited[i]) {\n                    #pragma omp critical\n                    {\n                        q.push_back(i);\n                        visited[i] = true;\n                    }\n                }\n            }\n        }\n    }\n\n    int result;\n    MPI_Reduce(&myLength, &result, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    return result;\n}",
            "int *mypath = new int[N];\n  int *visited = new int[N];\n  int *mypath_temp = new int[N];\n\n  for (int i = 0; i < N; i++) {\n    mypath[i] = 0;\n    visited[i] = 0;\n    mypath_temp[i] = 0;\n  }\n\n  visited[source] = 1;\n  mypath[source] = 1;\n\n  int temp_mypath;\n  int temp_visited;\n\n  while (true) {\n    temp_visited = 0;\n    temp_mypath = 0;\n    for (int i = 0; i < N; i++) {\n      if (visited[i]) {\n        for (int j = 0; j < N; j++) {\n          if (A[i * N + j] &&!visited[j]) {\n            visited[j] = 1;\n            mypath[j] = mypath[i] + 1;\n            temp_visited++;\n          }\n        }\n      }\n    }\n    if (temp_visited == 0)\n      break;\n    else {\n      for (int i = 0; i < N; i++) {\n        if (visited[i]) {\n          if (mypath[i] < temp_mypath)\n            temp_mypath = mypath[i];\n        }\n      }\n      for (int i = 0; i < N; i++) {\n        if (visited[i]) {\n          if (mypath[i] == temp_mypath) {\n            mypath_temp[i] = 1;\n          }\n        }\n      }\n      for (int i = 0; i < N; i++) {\n        mypath[i] = mypath_temp[i];\n        mypath_temp[i] = 0;\n      }\n    }\n  }\n\n  for (int i = 0; i < N; i++) {\n    if (mypath[i] == 0)\n      mypath[i] = -1;\n  }\n  int global_path = 0;\n\n  int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int size;\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  int *path_array = new int[size];\n  for (int i = 0; i < size; i++) {\n    path_array[i] = -1;\n  }\n\n  for (int i = 0; i < size; i++) {\n    if (i == rank) {\n      path_array[i] = mypath[dest];\n    }\n  }\n\n  MPI_Allgather(MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, path_array, 1, MPI_INT, MPI_COMM_WORLD);\n\n  for (int i = 0; i < size; i++) {\n    if (path_array[i] >= 0 && path_array[i] < global_path) {\n      global_path = path_array[i];\n    }\n  }\n\n  return global_path;\n}",
            "std::vector<int> visited(N, 0);\n  std::vector<int> distances(N, -1);\n  std::vector<int> predecessors(N, -1);\n  std::vector<bool> changed(N, false);\n  std::queue<int> q;\n\n  distances[source] = 0;\n  q.push(source);\n\n  while (!q.empty()) {\n    int node = q.front();\n    q.pop();\n\n    if (node == dest) {\n      break;\n    }\n\n    for (size_t i = 0; i < N; ++i) {\n      int dist = distances[node] + 1;\n\n      if (A[node * N + i]!= 0 && dist < distances[i]) {\n        distances[i] = dist;\n        predecessors[i] = node;\n        changed[i] = true;\n      }\n    }\n\n    visited[node] = 1;\n\n    for (size_t i = 0; i < N; ++i) {\n      if (changed[i]) {\n        changed[i] = false;\n        if (visited[i] == 0) {\n          q.push(i);\n        }\n      }\n    }\n  }\n\n  return distances[dest];\n}",
            "// TODO\n\tint *d_A = new int[N * N];\n\tfor(int i = 0; i < N; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\td_A[i * N + j] = A[i * N + j];\n\t\t}\n\t}\n\t// int *d_A = (int*)malloc(N * N * sizeof(int));\n\t// for(int i = 0; i < N * N; i++){\n\t// \td_A[i] = A[i];\n\t// }\n\tint *d_dist = new int[N];\n\tfor(int i = 0; i < N; i++)\n\t\td_dist[i] = INT_MAX;\n\td_dist[source] = 0;\n\t// int d_dist[N];\n\t// for(int i = 0; i < N; i++)\n\t// \td_dist[i] = INT_MAX;\n\t// d_dist[source] = 0;\n\tbool *d_visited = new bool[N];\n\tfor(int i = 0; i < N; i++)\n\t\td_visited[i] = false;\n\t// bool d_visited[N];\n\t// for(int i = 0; i < N; i++)\n\t// \td_visited[i] = false;\n\tint step = 1;\n\tint step_all = 0;\n\tint step_now = 0;\n\tint proc_num, proc_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &proc_num);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &proc_rank);\n\t// int proc_num, proc_rank;\n\t// MPI_Comm_size(MPI_COMM_WORLD, &proc_num);\n\t// MPI_Comm_rank(MPI_COMM_WORLD, &proc_rank);\n\tint *d_dist_sum = new int[N];\n\tint *d_visited_sum = new bool[N];\n\tfor(int i = 0; i < N; i++){\n\t\td_visited_sum[i] = false;\n\t}\n\t// int *d_dist_sum = (int*)malloc(N * sizeof(int));\n\t// for(int i = 0; i < N; i++){\n\t// \td_dist_sum[i] = INT_MAX;\n\t// }\n\t// bool *d_visited_sum = (bool*)malloc(N * sizeof(bool));\n\t// for(int i = 0; i < N; i++){\n\t// \td_visited_sum[i] = false;\n\t// }\n\tint *d_dist_min = new int[N];\n\tfor(int i = 0; i < N; i++)\n\t\td_dist_min[i] = INT_MAX;\n\t// int *d_dist_min = (int*)malloc(N * sizeof(int));\n\t// for(int i = 0; i < N; i++){\n\t// \td_dist_min[i] = INT_MAX;\n\t// }\n\twhile(step_all < N){\n\t\tstep = 0;\n\t\tstep_now = 0;\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tif(d_visited[i] == false && d_dist[i]!= INT_MAX){\n\t\t\t\tstep++;\n\t\t\t\tif(d_dist[i] == 0){\n\t\t\t\t\tstep_now = step;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// #pragma omp parallel for shared(d_A, d_dist, d_visited) schedule(dynamic)\n\t\tfor(int i = 0; i < N; i++){\n\t\t\t// #pragma omp parallel for shared(d_dist, d_visited) schedule(dynamic)\n\t\t\tif(d_visited[i] == false && d_dist[i]!= INT_MAX){\n\t\t\t\tfor(int j = 0; j < N; j++){",
            "// TODO\n\treturn 0;\n}",
            "// TODO\n  return 0;\n}",
            "// TODO: Your code here\n\n}",
            "// Replace this code with a correct implementation\n\treturn -1;\n}",
            "/* You will probably want to use a stack data structure, implemented with an STL vector */\n  std::vector<int> stack;\n  std::vector<bool> visited(N, false);\n  int nb_threads;\n  int rank;\n\n  MPI_Comm_size(MPI_COMM_WORLD, &nb_threads);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  stack.push_back(source);\n  visited[source] = true;\n\n  /* Use OpenMP to parallelize the for loop */\n#pragma omp parallel\n  while (stack.size()!= 0) {\n    /* Iterate over the current list of elements in the stack, each rank will do a part of the iteration */\n#pragma omp for\n    for (size_t i = 0; i < stack.size(); i++) {\n      /* If we are in a leaf, we have found the shortest path */\n      if (stack[i] == dest) {\n        return stack.size() - 1;\n      }\n      int current = stack[i];\n      for (size_t j = 0; j < N; j++) {\n        if (visited[j] == false && A[current * N + j] == 1) {\n          stack.push_back(j);\n          visited[j] = true;\n        }\n      }\n    }\n  }\n\n  return -1;\n}",
            "std::vector<int> V;\n    for (size_t i = 0; i < N; ++i) {\n        if (i!= source) {\n            V.push_back(i);\n        }\n    }\n    std::vector<int> path;\n    std::vector<int> dist(N, 1e6);\n    int rank = 0;\n    int numProcs;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n    int thread_count;\n    thread_count = omp_get_max_threads();\n    int size = numProcs / thread_count;\n    int remain = numProcs % thread_count;\n    int my_size = size;\n    if (rank < remain * (size + 1)) {\n        my_size++;\n    }\n    int my_rank = rank % thread_count;\n    int my_start = rank / thread_count * size + my_rank;\n    int my_end = my_start + my_size;\n\n    std::vector<std::vector<int>> d(my_size);\n    for (size_t i = 0; i < my_size; ++i) {\n        d[i].resize(N, 1e6);\n    }\n    std::vector<int> dist_my(N, 1e6);\n\n#pragma omp parallel for num_threads(thread_count)\n    for (int i = my_start; i < my_end; ++i) {\n        dist_my[i] = 0;\n    }\n\n    for (int i = 0; i < thread_count; ++i) {\n        if (i == my_rank) {\n            d[my_rank - my_start] = dist_my;\n        }\n#pragma omp barrier\n    }\n\n    int count = 0;\n    while (!V.empty()) {\n        int u = source;\n        for (int i = 0; i < my_size; ++i) {\n            if (d[i][source] == count) {\n                u = i + my_start;\n                break;\n            }\n        }\n        for (int i = 0; i < my_size; ++i) {\n            if (u == my_start + i) {\n                continue;\n            }\n            for (int v : V) {\n                if (A[u * N + v] && (d[i][v] > d[i][u] + 1)) {\n                    d[i][v] = d[i][u] + 1;\n                }\n            }\n        }\n\n        std::vector<int> V_new;\n        for (int v : V) {\n            int min_v = 1e6;\n            for (int i = 0; i < my_size; ++i) {\n                if (d[i][v] < min_v) {\n                    min_v = d[i][v];\n                }\n            }\n            if (min_v == count + 1) {\n                V_new.push_back(v);\n            }\n        }\n        V = V_new;\n        count++;\n    }\n\n    std::vector<int> dist_global(N, 1e6);\n    for (int i = 0; i < my_size; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (d[i][j] < dist_global[j]) {\n                dist_global[j] = d[i][j];\n            }\n        }\n    }\n    MPI_Reduce(dist_global.data(), dist.data(), N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n    return dist[dest];\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\t\n\tstd::vector<bool> visited(N, false);\n\t\n\tstd::vector<int> path(N, -1);\n\tpath[source] = -2;\n\t\n\tstd::vector<int> queue(N);\n\t\n\tint qstart = 0;\n\tint qend = 0;\n\t\n\tqueue[qend++] = source;\n\t\n\twhile (qstart < qend) {\n\t\tint u = queue[qstart++];\n\t\t\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[u * N + v]!= 0 &&!visited[v]) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tvisited[v] = true;\n\t\t\t\tpath[v] = u;\n\t\t\t\tqueue[qend++] = v;\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// backtrack to find the shortest path\n\t\n\tint shortestPathLength = 0;\n\tint currentVertex = dest;\n\t\n\twhile (currentVertex!= -2) {\n\t\tshortestPathLength++;\n\t\tcurrentVertex = path[currentVertex];\n\t}\n\t\n\treturn shortestPathLength;\n}",
            "int len;\n\tMPI_Status status;\n\tint recvLen = 0;\n\n\tstd::vector<int> sendLen(A.size());\n\tstd::vector<int> recvLenGlobal(A.size());\n\tstd::vector<int> sendLenGlobal(A.size());\n\n\tstd::vector<int> visited(N);\n\tstd::queue<int> q;\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tvisited[i] = 0;\n\t}\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tif (A[source*N+i] == 1) {\n\t\t\tvisited[i] = 1;\n\t\t\tq.push(i);\n\t\t}\n\t}\n\n\twhile (!q.empty()) {\n\t\tint cur = q.front();\n\t\tq.pop();\n\n\t\tif (cur == dest) {\n\t\t\treturn 1;\n\t\t}\n\n\t\tif (visited[cur] == 1) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tvisited[cur] = 1;\n\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tif (A[cur*N+i] == 1) {\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}",
            "int myID, numProcs;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myID);\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n  int* Q = new int[N];\n  int* Q_next = new int[N];\n  int* visited = new int[N];\n  int* D = new int[N];\n  int* sendBuffer = new int[N];\n  for (int i = 0; i < N; i++) {\n    Q[i] = -1;\n    Q_next[i] = -1;\n    visited[i] = 0;\n    D[i] = -1;\n  }\n  Q[source] = source;\n  visited[source] = 1;\n  D[source] = 0;\n\n  int numRounds = 0;\n  while (true) {\n    int numNodes = 0;\n#pragma omp parallel for\n    for (int i = 0; i < N; i++) {\n      if (Q[i] == -1) continue;\n      for (int j = 0; j < N; j++) {\n        if (visited[j] == 1 || A[N * Q[i] + j] == 0) continue;\n        if (Q_next[j]!= -1) continue;\n        Q_next[j] = Q[i];\n        numNodes++;\n      }\n    }\n    if (numNodes == 0) {\n      break;\n    }\n    for (int i = 0; i < N; i++) {\n      if (Q_next[i] == -1) continue;\n      Q[i] = Q_next[i];\n      visited[i] = 1;\n      D[i] = D[Q_next[i]] + 1;\n    }\n    for (int i = 0; i < N; i++) {\n      Q_next[i] = -1;\n    }\n    numRounds++;\n  }\n  for (int i = 0; i < N; i++) {\n    sendBuffer[i] = D[i];\n  }\n  int* recvBuffer = new int[N];\n  MPI_Reduce(sendBuffer, recvBuffer, N, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n  if (myID == 0) {\n    return recvBuffer[dest];\n  }\n  delete[] recvBuffer;\n  delete[] sendBuffer;\n  delete[] D;\n  delete[] visited;\n  delete[] Q_next;\n  delete[] Q;\n  return -1;\n}",
            "int rank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  int numProc;\n  MPI_Comm_size(MPI_COMM_WORLD, &numProc);\n  int destRank = dest / numProc;\n  int destProc = dest % numProc;\n  int destRank2 = dest / (numProc / 2);\n  int destProc2 = dest % (numProc / 2);\n  int destRank3 = dest / (numProc / 3);\n  int destProc3 = dest % (numProc / 3);\n  int destRank4 = dest / (numProc / 4);\n  int destProc4 = dest % (numProc / 4);\n  int myLength = 0;\n  std::vector<int> Q(N);\n  std::vector<int> myQ(N);\n  std::vector<int> myQ2(N);\n  std::vector<int> myQ3(N);\n  std::vector<int> myQ4(N);\n  bool visited[N];\n  for (size_t i = 0; i < N; i++) {\n    visited[i] = false;\n  }\n  visited[source] = true;\n  Q[0] = source;\n  int Qsize = 1;\n  int Qsize2 = 0;\n  int Qsize3 = 0;\n  int Qsize4 = 0;\n\n  if (destProc == 0 && rank == 0) {\n    while (Qsize > 0) {\n      int n = Q[0];\n      for (size_t i = 0; i < N; i++) {\n        if (A[N*n + i] == 1 &&!visited[i]) {\n          Q[Qsize] = i;\n          visited[i] = true;\n          myQ[Qsize] = i;\n          Qsize++;\n        }\n      }\n      Qsize--;\n      for (int i = 0; i < Qsize; i++) {\n        Q[i] = Q[i+1];\n      }\n    }\n  }\n  else if (destProc == 1 && rank == 1) {\n    while (Qsize > 0) {\n      int n = Q[0];\n      for (size_t i = 0; i < N; i++) {\n        if (A[N*n + i] == 1 &&!visited[i]) {\n          Q[Qsize] = i;\n          visited[i] = true;\n          myQ2[Qsize2] = i;\n          Qsize2++;\n        }\n      }\n      Qsize--;\n      for (int i = 0; i < Qsize; i++) {\n        Q[i] = Q[i+1];\n      }\n    }\n  }\n  else if (destProc == 2 && rank == 2) {\n    while (Qsize > 0) {\n      int n = Q[0];\n      for (size_t i = 0; i < N; i++) {\n        if (A[N*n + i] == 1 &&!visited[i]) {\n          Q[Qsize] = i;\n          visited[i] = true;\n          myQ3[Qsize3] = i;\n          Qsize3++;\n        }\n      }\n      Qsize--;\n      for (int i = 0; i < Qsize; i++) {\n        Q[i] = Q[i+1];\n      }\n    }\n  }\n  else if (destProc == 3 && rank == 3) {\n    while (Qsize > 0) {\n      int n = Q[0];\n      for (size_t i = 0; i < N; i++) {\n        if (A[N*n + i] == 1 &&!visited[i]) {\n          Q[Qsize] = i;\n          visited[i] = true;\n          myQ4[Qsize4] = i;\n          Qsize4++;\n        }\n      }\n      Qsize--;\n      for (int i = 0; i < Qsize; i++) {\n        Q[i] = Q[i+1];\n      }\n    }\n  }\n  else {",
            "// TODO: Your code here\n    int *distances = new int[N];\n    for(int i = 0; i < N; i++){\n        if(A[i * N + source]!= 0)\n            distances[i] = 1;\n        else\n            distances[i] = INT_MAX;\n    }\n    distances[source] = 0;\n\n    for(int i = 0; i < N; i++){\n        #pragma omp parallel for num_threads(8)\n        for(int j = 0; j < N; j++){\n            int tmp = distances[j];\n            if(distances[j] > distances[i] + A[i * N + j])\n                distances[j] = distances[i] + A[i * N + j];\n        }\n    }\n\n    MPI_Reduce(MPI_IN_PLACE, distances, N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n    if(rank == 0)\n        return distances[dest];\n\n    return -1;\n}",
            "//TODO\n    int *visited = new int[N];\n    for (int i = 0; i < N; i++) {\n        visited[i] = 0;\n    }\n    int *path_length = new int[N];\n    int *path = new int[N];\n    for (int i = 0; i < N; i++) {\n        path[i] = -1;\n    }\n    path[source] = source;\n    path_length[source] = 0;\n    std::vector<int> queue;\n    queue.push_back(source);\n\n    while(queue.size()!= 0) {\n        int current = queue[0];\n        queue.erase(queue.begin());\n\n        for (int i = 0; i < N; i++) {\n            if (A[current*N + i]!= 0 && visited[i] == 0) {\n                queue.push_back(i);\n                path[i] = current;\n                path_length[i] = path_length[current] + 1;\n                visited[i] = 1;\n            }\n        }\n\n    }\n\n    delete [] visited;\n    delete [] path;\n    delete [] path_length;\n\n    return path_length[dest];\n}",
            "// Initialize a vector of length N to store whether a vertex has been visited\n  std::vector<bool> visited(N, false);\n  // Initialize a vector of length N to store the length of the shortest path from source\n  std::vector<int> shortestPathLength(N, -1);\n\n  /*\n     TODO: Fill this in\n  */\n  return shortestPathLength[dest];\n}",
            "// TODO: Implement me\n\treturn 0;\n}",
            "// TODO: your code here\n\n    int local_source = source;\n    int local_dest = dest;\n    int rank;\n    int size;\n    MPI_Comm_size(MPI_COMM_WORLD,&size);\n    MPI_Comm_rank(MPI_COMM_WORLD,&rank);\n    int nth = size;\n    int *send_source = NULL;\n    int *send_dest = NULL;\n    int *recv_source = NULL;\n    int *recv_dest = NULL;\n    int *dist = new int[N];\n    int *s_dist = new int[N];\n    int *l_dist = new int[N];\n    bool *visited = new bool[N];\n    bool *s_visited = new bool[N];\n    bool *l_visited = new bool[N];\n    int *prev = new int[N];\n    int *s_prev = new int[N];\n    int *l_prev = new int[N];\n\n    //source = 1;\n    //dest = 3;\n\n    int s_size = N/nth;\n    int l_size = N%nth;\n\n    if(rank == 0){\n\n        send_source = new int[s_size];\n        send_dest = new int[s_size];\n        for(int i = 0; i<s_size; i++){\n            send_source[i] = A[source][i];\n            send_dest[i] = A[i][dest];\n        }\n\n        for(int i = 0; i<N; i++){\n            dist[i] = 100;\n            visited[i] = false;\n            prev[i] = -1;\n        }\n\n        dist[source] = 0;\n        visited[source] = true;\n        prev[source] = -1;\n\n    }\n\n    if(rank < nth-1){\n\n        send_source = new int[s_size];\n        send_dest = new int[s_size];\n        for(int i = 0; i<s_size; i++){\n            send_source[i] = A[source][i];\n            send_dest[i] = A[i][dest];\n        }\n\n        s_dist = new int[s_size];\n        s_visited = new bool[s_size];\n        s_prev = new int[s_size];\n        for(int i = 0; i<s_size; i++){\n            s_dist[i] = 100;\n            s_visited[i] = false;\n            s_prev[i] = -1;\n        }\n\n        s_dist[source] = 0;\n        s_visited[source] = true;\n        s_prev[source] = -1;\n\n    }\n\n    if(rank == nth-1){\n\n        l_dist = new int[l_size];\n        l_visited = new bool[l_size];\n        l_prev = new int[l_size];\n        for(int i = 0; i<l_size; i++){\n            l_dist[i] = 100;\n            l_visited[i] = false;\n            l_prev[i] = -1;\n        }\n\n        l_dist[source] = 0;\n        l_visited[source] = true;\n        l_prev[source] = -1;\n\n    }\n\n    int *recv_buffer = NULL;\n    int *l_recv_buffer = NULL;\n    if(rank == 0){\n        recv_buffer = new int[s_size];\n        MPI_Recv(recv_buffer, s_size, MPI_INT, 1, 10, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        //printf(\"rank = %d, recv_buffer[0] = %d\\n\",rank, recv_buffer[0]);\n        for(int i = 0; i<s_size; i++){\n            if(recv_source[i] == 0){\n                s_dist[i] = 0;\n                s_visited[i] = true",
            "int result;\n\n#pragma omp parallel\n    {\n        std::vector<int> current(N, -1);\n        std::vector<int> previous(N, -1);\n        std::vector<int> dist(N, -1);\n        current[source] = 1;\n        dist[source] = 0;\n\n        // Do a BFS traversal\n#pragma omp for schedule(static)\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[j*N + i] && (current[j]!= -1)) {\n                    current[i] = 1;\n                    dist[i] = dist[j] + 1;\n                    previous[i] = j;\n                }\n            }\n        }\n        // If we found a path to dest, return the shortest path length\n        if (current[dest]) {\n#pragma omp critical\n            result = dist[dest];\n        }\n    }\n\n    return result;\n}",
            "// TODO\n}",
            "if (source == dest)\n        return 0;\n\n    int * A_buf = A.data();\n    int * A_sub = new int[N];\n\n    std::vector<int> dist(N, INF);\n    dist[source] = 0;\n\n    for (int k = 0; k < N; k++) {\n        #pragma omp parallel for\n        for (int i = 0; i < N; i++) {\n            if (dist[i]!= INF && A_buf[i * N + k]!= INF) {\n                if (dist[k] == INF || dist[k] > dist[i] + A_buf[i * N + k]) {\n                    dist[k] = dist[i] + A_buf[i * N + k];\n                }\n            }\n        }\n    }\n\n    delete[] A_sub;\n    return dist[dest];\n}",
            "// TODO: Fill this in\n    return 0;\n}",
            "int *dist = new int[N];\n\tint *pre = new int[N];\n\tint *visited = new int[N];\n\tint *Q = new int[N];\n\n\tfor (int i = 0; i < N; i++) {\n\t\tvisited[i] = 0;\n\t\tdist[i] = -1;\n\t}\n\n\tdist[source] = 0;\n\tpre[source] = -1;\n\tint qfront = 0;\n\tint qback = 0;\n\tQ[qback++] = source;\n\tint u;\n\n\twhile (qfront < qback) {\n\t\tu = Q[qfront++];\n\t\tvisited[u] = 1;\n\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v] == 1 && visited[v] == 0) {\n\t\t\t\tQ[qback++] = v;\n\t\t\t\tpre[v] = u;\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (dist[dest] == -1)\n\t\treturn -1;\n\n\tint pathLength = 0;\n\tint cur = dest;\n\twhile (cur!= -1) {\n\t\tpathLength += 1;\n\t\tcur = pre[cur];\n\t}\n\treturn pathLength;\n}",
            "int length;\n  int *A_local = new int[N*N];\n\n  // TODO: Replace this line with your solution\n  length = -1;\n\n  delete[] A_local;\n  return length;\n}",
            "// Your code goes here\n    return 0;\n}",
            "if (N == 0) return 0;\n\tif (source == dest) return 0;\n\n\tint *next = new int[N]; // next[i] is the next vertex to visit\n\tstd::fill(next, next + N, -1);\n\tint *dist = new int[N]; // dist[i] is the distance to vertex i\n\tstd::fill(dist, dist + N, -1);\n\tstd::vector<bool> active(N, false); // active[i] indicates whether vertex i is on the queue\n\n\tstd::queue<int> q;\n\tq.push(source);\n\tactive[source] = true;\n\tdist[source] = 0;\n\n\tint *buffer = new int[N];\n\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tactive[u] = false;\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[u * N + v] && dist[v] == -1) {\n\t\t\t\tq.push(v);\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tnext[v] = u;\n\t\t\t\tactive[v] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\tdelete[] next;\n\tdelete[] buffer;\n\n\treturn dist[dest];\n}",
            "std::vector<int> dist(N, INT_MAX);\n\tdist[source] = 0;\n\n\tstd::vector<bool> sptSet(N, false);\n\tsptSet[source] = true;\n\n\tfor (int count = 0; count < N - 1; ++count) {\n\t\tint u = -1;\n\t\tfor (size_t i = 0; i < N; ++i) {\n\t\t\tif (!sptSet[i] && (u == -1 || dist[i] < dist[u])) {\n\t\t\t\tu = i;\n\t\t\t}\n\t\t}\n\n\t\tsptSet[u] = true;\n\n\t\tfor (size_t v = 0; v < N; ++v) {\n\t\t\tif (!sptSet[v] && A[u * N + v] && dist[u]!= INT_MAX && dist[u] + A[u * N + v] < dist[v]) {\n\t\t\t\tdist[v] = dist[u] + A[u * N + v];\n\t\t\t}\n\t\t}\n\t}\n\treturn dist[dest];\n}",
            "int lvl = 0;\n    int nProc, myID;\n    MPI_Comm_size(MPI_COMM_WORLD, &nProc);\n    MPI_Comm_rank(MPI_COMM_WORLD, &myID);\n\n    if (myID == 0) {\n        int* sendbuf = new int[N];\n        int* recvbuf = new int[N];\n        memset(sendbuf, -1, N * sizeof(int));\n        memset(recvbuf, -1, N * sizeof(int));\n        int* dist = new int[N];\n        memset(dist, -1, N * sizeof(int));\n        std::vector<int> queue = {source};\n        sendbuf[source] = 0;\n        dist[source] = 0;\n\n        while (!queue.empty()) {\n            // parallelize the queue traversal\n            std::vector<int> new_queue;\n            #pragma omp parallel for\n            for (int i = 0; i < queue.size(); i++) {\n                int s = queue[i];\n                for (int j = 0; j < N; j++) {\n                    if (A[s * N + j] == 1 && dist[j] == -1) {\n                        dist[j] = dist[s] + 1;\n                        new_queue.push_back(j);\n                        sendbuf[j] = s;\n                    }\n                }\n            }\n            queue = new_queue;\n            MPI_Reduce(sendbuf, recvbuf, N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n            if (myID == 0) {\n                queue = {};\n                for (int i = 0; i < N; i++) {\n                    if (recvbuf[i]!= -1 && dist[i] == -1) {\n                        dist[i] = dist[recvbuf[i]] + 1;\n                        queue.push_back(i);\n                    }\n                }\n            }\n        }\n        if (dist[dest]!= -1) {\n            lvl = dist[dest];\n        }\n        delete[] dist;\n        delete[] recvbuf;\n        delete[] sendbuf;\n    }\n    MPI_Bcast(&lvl, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    return lvl;\n}",
            "std::vector<int> dist(N, 1e8);\n\tstd::vector<int> next(N);\n\tstd::queue<int> q;\n\tdist[source] = 0;\n\tq.push(source);\n\twhile (!q.empty()) {\n\t\tint u = q.front();\n\t\tq.pop();\n\t\tif (u == dest) {\n\t\t\tbreak;\n\t\t}\n\t\tfor (int v = 0; v < N; ++v) {\n\t\t\tif (A[v * N + u] && dist[v] > dist[u] + 1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tnext[v] = u;\n\t\t\t\tq.push(v);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "int num_processes, my_rank;\n\tMPI_Status status;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n\t// Initialize shortest path array\n\tstd::vector<int> shortestPath(N, -1);\n\t// Initialize predecessor array\n\tstd::vector<int> predecessor(N, -1);\n\n\tif (my_rank == 0) {\n\t\t// Initialize shortest path and predecessor array\n\t\tshortestPath[source] = 0;\n\t\tpredecessor[source] = source;\n\n\t\t// Broadcast initial shortest path and predecessor arrays\n\t\tMPI_Bcast(shortestPath.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\t\tMPI_Bcast(predecessor.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\t}\n\n\t// Synchronize at this point so all ranks have the initial shortest path array\n\tMPI_Barrier(MPI_COMM_WORLD);\n\n\t// Loop through all vertices\n\tfor (size_t v = 0; v < N; v++) {\n\t\t// Loop through all neighbors of v\n\t\tfor (size_t w = 0; w < N; w++) {\n\n\t\t\t// If there is an edge between v and w...\n\t\t\tif (A[v*N + w] == 1) {\n\t\t\t\t// Get shortest path to w\n\t\t\t\tint pathToW = -1;\n\t\t\t\tMPI_Recv(&pathToW, 1, MPI_INT, w, 0, MPI_COMM_WORLD, &status);\n\n\t\t\t\t// Check if we have a shorter path\n\t\t\t\tif (pathToW >= 0 && (shortestPath[v] == -1 || pathToW + 1 < shortestPath[v])) {\n\t\t\t\t\tshortestPath[v] = pathToW + 1;\n\t\t\t\t\tpredecessor[v] = w;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Broadcast shortest path and predecessor arrays to other ranks\n\t\tMPI_Bcast(shortestPath.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\t\tMPI_Bcast(predecessor.data(), N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t\t// Synchronize at this point so all ranks have the most up-to-date shortest path array\n\t\tMPI_Barrier(MPI_COMM_WORLD);\n\t}\n\n\tint pathToDest = -1;\n\tMPI_Recv(&pathToDest, 1, MPI_INT, dest, 0, MPI_COMM_WORLD, &status);\n\n\treturn pathToDest;\n}",
            "// TODO: Your code goes here\n    return 0;\n}",
            "assert(A.size() == N*N);\n\tassert(source < N);\n\tassert(dest < N);\n\n\t// Your code goes here\n\n\treturn -1;\n}",
            "// YOUR CODE HERE\n\n}",
            "int path_length = -1;\n  int current_path_length = 0;\n  int num_processes, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  // TODO:\n  // Initialize path_length.\n\n  // Compute the shortest path length using OpenMP.\n  #pragma omp parallel\n  {\n    if (rank == 0) {\n      // TODO:\n      // Initialize current_path_length and find the shortest path length.\n    }\n  }\n\n  // Use MPI to get the path_length value from rank 0 onto all the other ranks.\n  MPI_Bcast(&path_length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return path_length;\n}",
            "const int Nranks = 1;\n  const int rank = 0;\n  const int source_rank = 0;\n\n  int n_source = -1;\n  int n_dest = -1;\n  int global_source;\n  int global_dest;\n  int source_row = -1;\n  int dest_row = -1;\n\n  // initialize the n_source, n_dest, source_row, dest_row\n  //\n\n  // create an all-to-all communication\n  //\n  MPI_Status status;\n  int a[N];\n  for (int i=0; i<N; i++) {\n    a[i] = i;\n  }\n  MPI_Request req;\n  MPI_Ialltoall(a, 1, MPI_INT, a, 1, MPI_INT, MPI_COMM_WORLD, &req);\n  MPI_Wait(&req, &status);\n  for (int i=0; i<N; i++) {\n    std::cout << \"rank \" << rank << \" \" << a[i] << std::endl;\n  }\n\n  return 0;\n}",
            "int *dist = (int *) calloc(N, sizeof(int));\n\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = INT_MAX;\n\t}\n\tdist[source] = 0;\n\tint active;\n\tdo {\n\t\tactive = 0;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (dist[i] == INT_MAX) continue;\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[N*i + j] == 1) {\n\t\t\t\t\tif (dist[j] > dist[i]+1) {\n\t\t\t\t\t\tdist[j] = dist[i]+1;\n\t\t\t\t\t\tactive = 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} while (active);\n\n\tint ret = dist[dest];\n\n\tfree(dist);\n\n\treturn ret;\n}",
            "//TODO\n  \n  return 0;\n}",
            "int *dist;\n    dist = (int *) calloc(N, sizeof(int));\n\n    int *processed;\n    processed = (int *) calloc(N, sizeof(int));\n\n    int *parent;\n    parent = (int *) calloc(N, sizeof(int));\n\n    int rank, size;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int *localA;\n    localA = (int *) calloc(N * N, sizeof(int));\n    MPI_Scatter(A.data(), N * N, MPI_INT, localA, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    std::vector<int> paths(N);\n\n    if (rank == 0) {\n        dist[source] = 0;\n        processed[source] = 1;\n        parent[source] = -1;\n    }\n\n    int *queue;\n    int *queue_length;\n    queue_length = (int *) calloc(size, sizeof(int));\n    int *queue_front;\n    queue_front = (int *) calloc(size, sizeof(int));\n    queue_length[rank] = 1;\n    queue_front[rank] = 0;\n    queue = (int *) calloc(size, sizeof(int));\n    queue[0] = source;\n\n    int *send;\n    int *recv;\n    int *send_length;\n    int *recv_length;\n    send_length = (int *) calloc(size, sizeof(int));\n    recv_length = (int *) calloc(size, sizeof(int));\n    send = (int *) calloc(N, sizeof(int));\n    recv = (int *) calloc(N, sizeof(int));\n\n    int *local_send;\n    local_send = (int *) calloc(size, sizeof(int));\n\n    int *queue_start;\n    queue_start = (int *) calloc(size, sizeof(int));\n    int *queue_end;\n    queue_end = (int *) calloc(size, sizeof(int));\n\n    while (queue_length[rank]!= 0) {\n\n        // calculate which nodes to send to which processors\n        for (int i = 0; i < size; i++) {\n            queue_start[i] = 0;\n            queue_end[i] = queue_length[i];\n            for (int j = 0; j < queue_length[i]; j++) {\n                int index = queue[queue_start[i] + j];\n                for (int k = 0; k < N; k++) {\n                    if (localA[index * N + k] == 1 && processed[k]!= 1) {\n                        local_send[i]++;\n                        processed[k] = 1;\n                        parent[k] = index;\n                    }\n                }\n            }\n            queue_start[i] = queue_end[i];\n            queue_end[i] += local_send[i];\n            local_send[i] = 0;\n        }\n\n        // send node indices to their destination processors\n        send_length[rank] = queue_length[rank];\n        MPI_Gather(send_length, 1, MPI_INT, recv_length, 1, MPI_INT, 0, MPI_COMM_WORLD);\n        for (int i = 0; i < size; i++) {\n            queue_length[i] = recv_length[i];\n            queue_front[i] = 0;\n        }\n        MPI_Scatter(queue_length, 1, MPI_INT, &queue_length[rank], 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n        if (queue_length[rank]!= 0) {\n            MPI_Gather(queue, queue_length[rank], MPI_INT, send, queue_length[rank], MPI_INT, 0, MPI_COMM_WORLD);\n            MPI_Scatter(send, queue_length[rank], MPI",
            "int *dist;\n    dist = new int[N];\n    for (int i = 0; i < N; i++) {\n        dist[i] = -1;\n    }\n    dist[source] = 0;\n    bool *v;\n    v = new bool[N];\n    for (int i = 0; i < N; i++) {\n        v[i] = false;\n    }\n    bool changed = true;\n    while (changed) {\n        changed = false;\n        for (int i = 0; i < N; i++) {\n            if (A[i*N+source]!= 0) {\n                if (v[i] == false) {\n                    v[i] = true;\n                    dist[i] = dist[source]+1;\n                    changed = true;\n                }\n            }\n        }\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (A[i*N+j]!= 0) {\n                    if (v[i] == false && dist[j] > dist[i]+1) {\n                        v[i] = true;\n                        dist[i] = dist[j]+1;\n                        changed = true;\n                    }\n                }\n            }\n        }\n    }\n    return dist[dest];\n}",
            "assert(source >= 0 && source < N);\n\tassert(dest >= 0 && dest < N);\n\n\t// TODO: Implement me\n\treturn 0;\n}",
            "// TODO\n}",
            "int *local_A;\n    local_A = new int [N * N];\n    memcpy(local_A, &A[0], sizeof(int) * N * N);\n\n    int *dist, *dist_next, *dist_all, *prev;\n    int *rank_id;\n    int *rank_src, *rank_dest;\n    int *row_id;\n    int *col_id;\n\n    dist = new int [N];\n    dist_next = new int [N];\n    dist_all = new int [N * N];\n    prev = new int [N];\n\n    rank_id = new int [N];\n    row_id = new int [N];\n    col_id = new int [N];\n\n    rank_src = new int [N];\n    rank_dest = new int [N];\n\n    int *rank_id_all, *rank_src_all, *rank_dest_all;\n    int *row_id_all, *col_id_all;\n\n    rank_id_all = new int [N * N];\n    row_id_all = new int [N * N];\n    col_id_all = new int [N * N];\n\n    rank_src_all = new int [N * N];\n    rank_dest_all = new int [N * N];\n\n    int *rank_id_send, *rank_src_send, *rank_dest_send;\n    int *row_id_send, *col_id_send;\n\n    rank_id_send = new int [N * N];\n    row_id_send = new int [N * N];\n    col_id_send = new int [N * N];\n\n    rank_src_send = new int [N * N];\n    rank_dest_send = new int [N * N];\n\n    int *rank_id_recv, *rank_src_recv, *rank_dest_recv;\n    int *row_id_recv, *col_id_recv;\n\n    rank_id_recv = new int [N * N];\n    row_id_recv = new int [N * N];\n    col_id_recv = new int [N * N];\n\n    rank_src_recv = new int [N * N];\n    rank_dest_recv = new int [N * N];\n\n    int count, count_next, count_all;\n\n    int rank, size;\n\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n    int *prev_all, *prev_send, *prev_recv;\n    int *prev_all_2, *prev_send_2, *prev_recv_2;\n\n    prev_all = new int [N * N];\n    prev_all_2 = new int [N * N];\n    prev_send = new int [N * N];\n    prev_send_2 = new int [N * N];\n    prev_recv = new int [N * N];\n    prev_recv_2 = new int [N * N];\n\n    int *prev_all_3, *prev_send_3, *prev_recv_3;\n\n    prev_all_3 = new int [N * N];\n    prev_send_3 = new int [N * N];\n    prev_recv_3 = new int [N * N];\n\n    for (int i = 0; i < N; i++)\n        dist[i] = -1;\n    dist_next[source] = 0;\n    int flag = 1;\n\n    while (flag) {\n        for (int i = 0; i < N; i++) {\n            dist_next[i] = dist[i];\n        }\n\n        count = 0;\n        count_next = 0;\n        count_all = 0;\n\n        for (int i = 0; i < N; i++) {\n            for (int j = 0; j < N; j++) {\n                if (local_A[i * N + j]) {\n                    rank_id[count] = rank;\n                    row_id[count] =",
            "}",
            "int length = 0;\n\tint min_length = INT_MAX;\n\t//printf(\"rank %d received from rank %d\\n\", rank, source);\n\t//MPI_Barrier(MPI_COMM_WORLD);\n\t//printf(\"rank %d after barrier\\n\", rank);\n\t\n\t#pragma omp parallel \n\t{\n\t\tint local_length = INT_MAX;\n\t\t#pragma omp for nowait\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tif(A[i*N + source] == 1){\n\t\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\t\tif(A[i*N + j] == 1){\n\t\t\t\t\t\tlocal_length = 1 + shortestPathLength(A, N, j, dest);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t#pragma omp critical\n\t\t{\n\t\t\tif(local_length < min_length){\n\t\t\t\tmin_length = local_length;\n\t\t\t}\n\t\t}\n\t}\n\n\t//printf(\"rank %d finished\\n\", rank);\n\t//MPI_Barrier(MPI_COMM_WORLD);\n\t\n\tint result = min_length;\n\tMPI_Reduce(&result, &length, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n\treturn length;\n}",
            "int local_source_length = 0;\n    int global_source_length = 0;\n    int local_dest_length = 0;\n    int global_dest_length = 0;\n\n    // TODO\n\n    return global_source_length;\n}",
            "// TODO\n}",
            "int my_rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n\tint my_rows = N/4;\n\tint my_rows_left = my_rows;\n\n\tint my_rows_start = my_rank*my_rows;\n\tint my_rows_end = (my_rank+1)*my_rows;\n\n\tif(my_rank == 3){\n\t\tmy_rows_end = my_rows_end + my_rows_left;\n\t}\n\n\tint min_dist = INT_MAX;\n\tstd::vector<int> distance(N, INT_MAX);\n\tdistance[source] = 0;\n\tbool converged = false;\n\n\tstd::vector<int> pred(N, -1);\n\n\twhile(!converged){\n\t\tconverged = true;\n#pragma omp parallel for shared(A, distance, pred, N, my_rows_start, my_rows_end, source) schedule(dynamic)\n\t\tfor(int u = my_rows_start; u < my_rows_end; u++){\n\t\t\tfor(int v = 0; v < N; v++){\n\t\t\t\tif(A[u*N+v] > 0 && distance[v] > distance[u] + A[u*N+v]){\n\t\t\t\t\tdistance[v] = distance[u] + A[u*N+v];\n\t\t\t\t\tpred[v] = u;\n\t\t\t\t\tconverged = false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tMPI_Barrier(MPI_COMM_WORLD);\n\n\tif(my_rank == 0){\n\t\tint max_dist = INT_MIN;\n\t\tint max_index = -1;\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tif(distance[i] > max_dist){\n\t\t\t\tmax_dist = distance[i];\n\t\t\t\tmax_index = i;\n\t\t\t}\n\t\t}\n\n\t\tint shortest_path_length = max_dist;\n\t\twhile(max_index!= -1){\n\t\t\tmax_index = pred[max_index];\n\t\t\tshortest_path_length--;\n\t\t}\n\n\t\treturn shortest_path_length;\n\t}\n\telse{\n\t\treturn INT_MAX;\n\t}\n}",
            "// You have to implement this.\n\treturn -1;\n}",
            "std::vector<int> dist(N, -1);\n\tint num_thread;\n\tint my_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_thread);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n\n\tif (my_rank == 0) {\n\t\tdist[source] = 0;\n\t\tint frontier = 1;\n\t\twhile (frontier > 0) {\n\t\t\tfrontier = 0;\n\t\t\tfor (int v = 0; v < N; ++v) {\n\t\t\t\tif (dist[v] == -1) continue;\n\t\t\t\tif (v == dest) return dist[v];\n\t\t\t\tfor (int u = 0; u < N; ++u) {\n\t\t\t\t\tif (A[v * N + u] == 1) {\n\t\t\t\t\t\tif (dist[u] == -1) {\n\t\t\t\t\t\t\tdist[u] = dist[v] + 1;\n\t\t\t\t\t\t\t++frontier;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn -1;\n}",
            "// TODO\n    return -1;\n}",
            "//TODO\n}",
            "int numProcs, myRank;\n  MPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &myRank);\n\n  /*  YOUR CODE HERE  */\n  // TODO: \n  // Use MPI and OpenMP to divide the NxN matrix into equal-sized chunks.\n  // Use MPI_Bcast to distribute the source and dest to all processes.\n  // Use OpenMP to compute the shortest path for each chunk.\n  // Use MPI_Reduce to merge the results from all processes.\n  // Use MPI_Reduce to return the result to process 0.\n  return 0;\n}",
            "std::vector<int> visited(N,0);\n\tstd::vector<int> dist(N, 0);\n\tdist[source] = 0;\n\tvisited[source] = 1;\n\n\tint minDistance = 0;\n\n\tfor (int i = 0; i < N; i++){\n\t\tminDistance = INT_MAX;\n\t\t#pragma omp parallel for reduction(min : minDistance)\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (dist[j] == 0 || A[j * N + i] == 1) continue;\n\t\t\tif (dist[i] + 1 < dist[j]){\n\t\t\t\tdist[j] = dist[i] + 1;\n\t\t\t\tvisited[j] = 1;\n\t\t\t}\n\t\t}\n\t\t#pragma omp parallel for reduction(min : minDistance)\n\t\tfor (int j = 0; j < N; j++){\n\t\t\tif (visited[j]!= 0){\n\t\t\t\tvisited[j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dist[dest];\n}",
            "// TODO: Your code here\n}",
            "// TODO\n  std::vector<int> dist(N, std::numeric_limits<int>::max());\n  std::queue<int> Q;\n  int cur_dist;\n  int num_iter;\n\n  dist[source] = 0;\n  Q.push(source);\n\n  while(!Q.empty())\n  {\n    int cur = Q.front();\n    Q.pop();\n    cur_dist = dist[cur];\n    for (size_t i = 0; i < N; i++)\n    {\n      if (A[cur*N+i] == 1 && dist[i] > cur_dist + 1)\n      {\n        dist[i] = cur_dist + 1;\n        Q.push(i);\n      }\n    }\n  }\n\n  return dist[dest];\n}",
            "return 0;\n}",
            "// TODO: implement me!\n    return 0;\n}",
            "int my_shortest_path = -1;\n\tint proc_count, rank;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &proc_count);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint sendcounts[proc_count], displs[proc_count];\n\tfor (int i = 0; i < proc_count; ++i) {\n\t\tsendcounts[i] = N / proc_count;\n\t\tdispls[i] = sendcounts[i] * i;\n\t}\n\n\tint* recvbuf;\n\tint count = sendcounts[rank];\n\n\tMPI_Gatherv(&A[rank * N], count, MPI_INT, &recvbuf, sendcounts, displs, MPI_INT, 0, MPI_COMM_WORLD);\n\n\tif (rank == 0) {\n\n\t\tint* dp = new int[N * N];\n\t\tint* path = new int[N * N];\n\t\tint* visited = new int[N];\n\t\tstd::fill(visited, visited + N, 0);\n\t\tstd::fill(path, path + N * N, -1);\n\t\tdp[0] = 0;\n\t\tpath[0] = 0;\n\t\tint queue[N];\n\n\t\tint front = 0, rear = 0;\n\n\t\tqueue[rear++] = source;\n\n\t\twhile (front!= rear) {\n\t\t\tint curr = queue[front++];\n\t\t\tfor (int i = 0; i < N; ++i) {\n\t\t\t\tif (A[curr * N + i] &&!visited[i]) {\n\t\t\t\t\tvisited[i] = 1;\n\t\t\t\t\tdp[i] = dp[curr] + 1;\n\t\t\t\t\tpath[i] = curr;\n\t\t\t\t\tqueue[rear++] = i;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tint idx = dest;\n\n\t\twhile (idx!= source) {\n\t\t\tmy_shortest_path = dp[idx];\n\t\t\tidx = path[idx];\n\t\t}\n\t\tdelete[] visited;\n\t\tdelete[] path;\n\t\tdelete[] dp;\n\t}\n\tMPI_Bcast(&my_shortest_path, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\treturn my_shortest_path;\n}",
            "std::vector<int> distances(N, INT_MAX);\n    distances[source] = 0;\n\n    for (int i = 0; i < N - 1; i++) {\n        for (size_t u = 0; u < N; u++) {\n            for (size_t v = 0; v < N; v++) {\n                if (A[u * N + v] && distances[u]!= INT_MAX) {\n                    distances[v] = std::min(distances[v], distances[u] + 1);\n                }\n            }\n        }\n    }\n\n    return distances[dest];\n}",
            "/*\n\t * TODO: Implement this function.\n\t * Hint: Use a priority queue data structure.\n\t * Hint: You might find the set of \"near\" nodes useful. A \"near\" node is a node that is one step away from source.\n\t * Hint: You can use a std::set to store the near nodes and a std::unordered_map to store the distance of each node.\n\t * Hint: You can use a C++17 parallel for-loop to process the near nodes in parallel.\n\t */\n\treturn -1;\n}",
            "// TODO\n\n    return 0;\n}",
            "int answer;\n\n  MPI_Bcast(&source, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  if (source == dest) {\n    answer = 0;\n  } else {\n    std::vector<int> queue;\n    std::vector<int> visited;\n\n    queue.push_back(source);\n    visited.push_back(source);\n\n    while (queue.size() > 0) {\n      auto front = queue.front();\n      queue.erase(queue.begin());\n\n      for (size_t i = 0; i < N; i++) {\n        if (A[N * front + i] == 1 &&!isIn(visited, i)) {\n          queue.push_back(i);\n          visited.push_back(i);\n\n          if (i == dest) {\n            answer = queue.size();\n            break;\n          }\n        }\n      }\n    }\n\n    answer = queue.size();\n  }\n\n  return answer;\n}",
            "// TODO: Implement the parallel algorithm here\n  const int nprocs = omp_get_num_procs();\n  const int rank = omp_get_thread_num();\n  std::cout << \"Running on \" << nprocs << \" threads\" << std::endl;\n  int *dist = new int[N];\n  for (size_t i = 0; i < N; i++) {\n    dist[i] = INT_MAX;\n  }\n  std::vector<int> my_dist = std::vector<int>(N, INT_MAX);\n  std::vector<int> my_parent(N, -1);\n  std::vector<int> *my_stack = new std::vector<int>[nprocs];\n  std::vector<int> *my_sources = new std::vector<int>[nprocs];\n  std::vector<int> *my_dests = new std::vector<int>[nprocs];\n  my_stack[rank].push_back(source);\n  dist[source] = 0;\n  my_dist[source] = 0;\n\n  for (int i = 0; i < N; i++) {\n    int min = INT_MAX;\n    for (int j = 0; j < nprocs; j++) {\n      if (my_stack[j].size() == 0) continue;\n      if (my_dist[my_stack[j][0]] < min) {\n        min = my_dist[my_stack[j][0]];\n        source = my_stack[j][0];\n        rank = j;\n      }\n    }\n    my_stack[rank].erase(my_stack[rank].begin());\n    for (int j = 0; j < N; j++) {\n      if (A[source * N + j] && dist[j] > dist[source] + 1) {\n        dist[j] = dist[source] + 1;\n        my_dist[j] = dist[source] + 1;\n        my_parent[j] = source;\n      }\n    }\n    for (int j = 0; j < nprocs; j++) {\n      if (my_stack[j].size() == 0) continue;\n      if (my_dist[my_stack[j][0]] == dist[source] + 1) {\n        my_sources[j].push_back(source);\n        my_dests[j].push_back(my_stack[j][0]);\n      }\n    }\n    for (int j = 0; j < nprocs; j++) {\n      if (my_sources[j].size() == 0) continue;\n      MPI_Send(my_sources[j].data(), my_sources[j].size(), MPI_INT, j, 1, MPI_COMM_WORLD);\n      MPI_Send(my_dests[j].data(), my_dests[j].size(), MPI_INT, j, 2, MPI_COMM_WORLD);\n      my_sources[j].clear();\n      my_dests[j].clear();\n    }\n    for (int j = 0; j < nprocs; j++) {\n      if (j == rank) continue;\n      if (my_stack[j].size() == 0) continue;\n      int source;\n      int size;\n      MPI_Status status;\n      MPI_Recv(&source, 1, MPI_INT, j, 1, MPI_COMM_WORLD, &status);\n      MPI_Get_count(&status, MPI_INT, &size);\n      int *dests = new int[size];\n      MPI_Recv(dests, size, MPI_INT, j, 2, MPI_COMM_WORLD, &status);\n      for (int k = 0; k < size; k++) {\n        if (my_dist[dests[k]] > my_dist[source] + 1) {\n          my_dist[dests[k]] = my_dist[source] + 1;\n          my_parent[dests[k]] = source;\n          my_stack[j].push_back(dests[k]);\n        }\n      }",
            "int rank;\n\tint nProc;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &nProc);\n\n\t// Find a chunk size for each process\n\tsize_t chunkSize = N / nProc;\n\tsize_t leftovers = N % nProc;\n\n\t// Find the start and end points for this process\n\tint procStart = chunkSize * rank + rank * leftovers;\n\tint procEnd = procStart + chunkSize + (rank < leftovers? 1 : 0);\n\n\t// Find the start and end points for the global matrix\n\tint globStart = procStart + source;\n\tint globEnd = globStart + procEnd - procStart;\n\n\t// Allocate enough memory for the local matrix\n\tstd::vector<int> localA(procEnd - procStart);\n\tfor (int i = 0; i < localA.size(); i++) {\n\t\tlocalA[i] = A[i + procStart];\n\t}\n\n\tint minDist = 10000000;\n\n\t// Use a simple BFS to find the shortest path\n\t// The BFS works because the adjacency matrix is symmetric\n\tstd::queue<int> queue;\n\tstd::vector<bool> visited(N, false);\n\tvisited[source] = true;\n\n\tif (globStart <= globEnd) {\n\t\tqueue.push(globStart);\n\t}\n\n\twhile (!queue.empty()) {\n\t\tint cur = queue.front();\n\t\tqueue.pop();\n\n\t\tif (cur == dest) {\n\t\t\treturn visited.size() - 1;\n\t\t}\n\n\t\tfor (int i = 0; i < localA.size(); i++) {\n\t\t\tif (localA[i] &&!visited[procStart + i]) {\n\t\t\t\tqueue.push(procStart + i);\n\t\t\t\tvisited[procStart + i] = true;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn minDist;\n}",
            "auto A_h = A; // copy\n  int length = 0;\n  // TODO: implement this function\n\n  // int count = 0;\n  // for (int i = 0; i < N; i++)\n  // {\n  //   for (int j = 0; j < N; j++)\n  //   {\n  //     if (A[i*N + j]!= 0)\n  //     {\n  //       count++;\n  //     }\n  //   }\n  // }\n\n  // std::cout << \"Number of non-zero entries: \" << count << std::endl;\n  return length;\n}",
            "std::vector<int> distances(N, INT_MAX);\n    // Distances matrix initialized with infinite distances.\n    distances[source] = 0; // Initialize the source distance to 0.\n    // Loop until the shortest path distance is the same on all processes.\n    bool change;\n    do {\n        // Update the shortest path distance with relaxation rules.\n        change = false;\n        for (size_t i = 0; i < N; i++) {\n            for (size_t j = 0; j < N; j++) {\n                // If (i, j) is not a valid vertex or the distance from i to j is infinity, continue.\n                if (i == j || distances[j] == INT_MAX) {\n                    continue;\n                }\n                int d = distances[j] + A[j * N + i];\n                if (d < distances[i]) {\n                    distances[i] = d;\n                    change = true;\n                }\n            }\n        }\n    } while (change);\n    return distances[dest];\n}",
            "// TODO: Fill this in\n}",
            "int rank = 0;\n\tint numProcs = 0;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\tstd::vector<std::vector<int>> B = splitMatrix(A, N, numProcs, rank);\n\n\tint pathLength = -1;\n\tif (B.empty()) {\n\t\treturn pathLength;\n\t}\n\n\t// B is a local graph matrix for the current rank,\n\t// so rank 0 should compute the shortest path for the entire graph\n\tif (rank == 0) {\n\t\tstd::vector<int> dists = {0, 0, 0, 0};\n\t\tint maxIter = 0;\n\t\twhile (true) {\n\t\t\tmaxIter++;\n\t\t\tif (maxIter > 100) {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tdists = dijkstra(B, N, source, dists);\n\t\t\tif (dists[dest]!= -1) {\n\t\t\t\tpathLength = dists[dest];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t}\n\n\t// All ranks send their pathLength to rank 0\n\tMPI_Gather(&pathLength, 1, MPI_INT, &pathLength, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t// Return the shortest path length on rank 0\n\tif (rank == 0) {\n\t\tfor (int i = 1; i < numProcs; i++) {\n\t\t\tif (pathLength > BFS[i]) {\n\t\t\t\tpathLength = BFS[i];\n\t\t\t}\n\t\t}\n\t}\n\treturn pathLength;\n}",
            "int length = 0;\n\tstd::vector<std::vector<int>> visited(N, std::vector<int>(N, 0));\n\tstd::queue<int> q;\n\tq.push(source);\n\tvisited[source][source] = 1;\n\n\twhile (!q.empty()) {\n\t\tint node = q.front();\n\t\tq.pop();\n\t\tif (node == dest)\n\t\t\tbreak;\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (A[node*N + i] == 1 && visited[node][i] == 0) {\n\t\t\t\tvisited[node][i] = 1;\n\t\t\t\tq.push(i);\n\t\t\t}\n\t\t}\n\t}\n\tlength = visited[source][dest];\n\treturn length;\n}",
            "int rank = 0, size = 1;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n  const int numRanks = size;\n  int numRowsPerRank = N / numRanks;\n  int numExtraRows = N % numRanks;\n  int rankOffset = 0;\n  if (rank < numExtraRows) {\n    rankOffset = rank;\n    ++numRowsPerRank;\n  }\n  else {\n    rankOffset = numExtraRows;\n  }\n  int localN = rank < numExtraRows? numRowsPerRank + 1 : numRowsPerRank;\n  std::vector<int> localA(numRowsPerRank * N);\n  for (int r = 0; r < localN; ++r) {\n    for (int c = 0; c < N; ++c) {\n      localA[r * N + c] = A[(r + rankOffset) * N + c];\n    }\n  }\n\n  int answer = -1;\n  if (rank == 0) {\n    if (localN > 1) {\n      std::vector<int> frontier(N, 1);\n      std::vector<int> nextFrontier(N, 0);\n      frontier[source] = 0;\n      for (int k = 0; k < numRanks; ++k) {\n        for (int i = 0; i < localN; ++i) {\n          for (int j = 0; j < N; ++j) {\n            if (localA[i * N + j]!= 0 && frontier[i]!= 0) {\n              nextFrontier[j] = std::min(nextFrontier[j], frontier[i] + 1);\n            }\n          }\n        }\n        std::swap(frontier, nextFrontier);\n      }\n      answer = frontier[dest];\n    }\n    else {\n      answer = 0;\n    }\n  }\n  MPI_Bcast(&answer, 1, MPI_INT, 0, MPI_COMM_WORLD);\n  return answer;\n}",
            "return 0;\n}",
            "return -1;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  // TODO:\n  // 1. Use OpenMP to divide A into chunks.\n  // 2. Use MPI to divide chunks among threads.\n  // 3. Compute shortest path length from source to dest in each chunk.\n  // 4. Merge results on rank 0.\n  //    (Hint: Use MPI_Reduce(sendbuf, recvbuf, count, datatype, op, root, comm) to merge results.)\n  // 5. Return the result.\n}",
            "int num_ranks, rank_id;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank_id);\n\n  std::vector<int> dist_from_source(N, -1);\n  dist_from_source[source] = 0;\n\n  bool changed;\n  do {\n    changed = false;\n\n    #pragma omp parallel for\n    for (size_t i = 0; i < N; i++) {\n      for (size_t j = 0; j < N; j++) {\n        if (dist_from_source[j]!= -1 && A[j*N + i]!= 0) {\n          #pragma omp critical\n          {\n            if (dist_from_source[i] == -1 || dist_from_source[i] > dist_from_source[j] + 1) {\n              dist_from_source[i] = dist_from_source[j] + 1;\n              changed = true;\n            }\n          }\n        }\n      }\n    }\n  } while (changed);\n\n  int length = -1;\n  if (dest < 0 || dest >= N) {\n    MPI_Abort(MPI_COMM_WORLD, 1);\n  }\n  length = dist_from_source[dest];\n\n  int length_total = 0;\n  MPI_Reduce(&length, &length_total, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);\n\n  if (rank_id == 0) {\n    return length_total / num_ranks;\n  }\n  return 0;\n}",
            "// TODO\n}",
            "// Initialize the distance matrix to 0 (except for dest, which is infinity)\n  std::vector<int> distances(N, 1);\n  distances[dest] = 0;\n\n  // Do a BFS for each source, updating distances as we go\n  for (int s = 0; s < N; s++) {\n    if (s == source) {\n      distances[s] = 0;\n    }\n\n    // Do a BFS starting at s. Use a priority queue to store the work queue.\n    // You can assume that std::priority_queue is thread-safe\n    // Use std::greater as the comparator for the priority queue\n    std::priority_queue<int, std::vector<int>, std::greater<int>> queue;\n    queue.push(s);\n\n    while (!queue.empty()) {\n\n      // Dequeue a node from the work queue\n      int u = queue.top();\n      queue.pop();\n\n      // Iterate over the neighbors of u\n      for (int v = 0; v < N; v++) {\n        if (A[u * N + v] == 1) {\n\n          // Check if the distance to v is shorter\n          if (distances[v] > distances[u] + 1) {\n\n            // If so, update the distance and enqueue v\n            distances[v] = distances[u] + 1;\n            queue.push(v);\n          }\n        }\n      }\n    }\n  }\n\n  // Return the distance to dest\n  return distances[dest];\n}",
            "// TODO\n\n}",
            "int rank, size;\n\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\n\tstd::vector<int> D(N, 1000000);\n\tint* Dptr = &D[0];\n\n\tstd::vector<int> Q(N, 0);\n\tint* Qptr = &Q[0];\n\n\t// int* Dptr = (int*) malloc(sizeof(int)*N);\n\t// int* Qptr = (int*) malloc(sizeof(int)*N);\n\n\tint path = 0;\n\n\tif (rank == 0) {\n\n\t\tQ[source] = 1;\n\t\tD[source] = 0;\n\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tMPI_Send(&Q[i], 1, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t\tMPI_Send(&D[i], 1, MPI_INT, i, 1, MPI_COMM_WORLD);\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Recv(&Qptr[i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t\tMPI_Recv(&Dptr[i*N], N, MPI_INT, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\n\t\t#pragma omp parallel for reduction(+:path)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (Qptr[i] == 1) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (Qptr[j] == 0 && A[i*N + j] == 1) {\n\t\t\t\t\t\tif (Dptr[i] + 1 < Dptr[j]) {\n\t\t\t\t\t\t\tDptr[j] = Dptr[i] + 1;\n\t\t\t\t\t\t\tQptr[j] = 1;\n\t\t\t\t\t\t\tpath += Dptr[j];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tQptr[i] = 0;\n\t\t\t}\n\t\t}\n\n\t\tfor (int i = 1; i < size; i++) {\n\t\t\tMPI_Send(&Q[i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD);\n\t\t\tMPI_Send(&D[i*N], N, MPI_INT, i, 1, MPI_COMM_WORLD);\n\t\t}\n\n\t\tMPI_Recv(&Qptr[i*N], N, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tMPI_Recv(&Dptr[i*N], N, MPI_INT, i, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t}\n\telse {\n\t\tMPI_Recv(&Qptr[i*N], N, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\tMPI_Recv(&Dptr[i*N], N, MPI_INT, 0, 1, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\n\t\t#pragma omp parallel for reduction(+:path)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tif (Qptr[i] == 1) {\n\t\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\t\tif (Qptr[j] == 0 && A[i*N + j] == 1) {",
            "// TODO: Your code goes here\n  return 0;\n}",
            "// Your code here\n  return -1;\n}",
            "int num_threads, rank, comm_size;\n\tMPI_Comm_size(MPI_COMM_WORLD, &comm_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tomp_set_num_threads(8);\n\n\tint num_rows = ceil(double(N) / double(comm_size));\n\tint start_row = num_rows * rank;\n\tint end_row = std::min(num_rows * (rank + 1), N);\n\n\tint num_cols = N;\n\tint start_col = 0;\n\tint end_col = N;\n\n\tint source_local = source - rank * num_rows;\n\tint dest_local = dest - rank * num_rows;\n\n\tint* result = new int[num_rows];\n\tfor (int i = 0; i < num_rows; i++)\n\t{\n\t\tresult[i] = -1;\n\t}\n\n\tint* visited = new int[num_rows];\n\tfor (int i = 0; i < num_rows; i++)\n\t{\n\t\tvisited[i] = 0;\n\t}\n\n\tint* visited_row = new int[num_cols];\n\tfor (int i = 0; i < num_cols; i++)\n\t{\n\t\tvisited_row[i] = 0;\n\t}\n\n\tint* frontier = new int[num_cols];\n\tfor (int i = 0; i < num_cols; i++)\n\t{\n\t\tfrontier[i] = 0;\n\t}\n\n\tint count = 0;\n\tint count_row = 0;\n\tint row_index = 0;\n\tint col_index = 0;\n\tint curr_path_length = 0;\n\tint shortest_path_length = 0;\n\n\t// Initializing the frontier with the source\n\tfrontier[source_local] = 1;\n\n\twhile (count_row < num_rows)\n\t{\n\t\t#pragma omp parallel for private(row_index, col_index) shared(frontier, visited, visited_row, result, A, num_rows, num_cols, source_local, dest_local, curr_path_length, count_row, shortest_path_length) num_threads(8)\n\t\tfor (int i = 0; i < num_cols; i++)\n\t\t{\n\t\t\tif (frontier[i] == 1)\n\t\t\t{\n\t\t\t\tvisited_row[i] = 1;\n\t\t\t\tcount_row++;\n\t\t\t\tif (result[i] < 0)\n\t\t\t\t{\n\t\t\t\t\tresult[i] = curr_path_length;\n\t\t\t\t}\n\t\t\t\tif (i == dest_local)\n\t\t\t\t{\n\t\t\t\t\tshortest_path_length = curr_path_length;\n\t\t\t\t}\n\t\t\t\tfor (int j = 0; j < num_rows; j++)\n\t\t\t\t{\n\t\t\t\t\tif (A[i * num_cols + j] == 1)\n\t\t\t\t\t{\n\t\t\t\t\t\tif (visited[j] == 0)\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tvisited[j] = 1;\n\t\t\t\t\t\t\tfrontier[j] = 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcurr_path_length++;\n\t\t}\n\t\tfor (int i = 0; i < num_cols; i++)\n\t\t{\n\t\t\tfrontier[i] = 0;\n\t\t}\n\t\tcurr_path_length = 0;\n\t}\n\n\tint* result_gather = new int[num_rows];\n\n\tMPI_Reduce(result, result_gather, num_rows, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n\n\t// Only on rank 0\n\tif (rank == 0)\n\t{\n\t\tfor (",
            "std::vector<int> dist(N);\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        dist[i] = 0;\n    }\n\n    dist[source] = 1;\n\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            if (A[i * N + j] && dist[j]!= 0) {\n                dist[i] = std::max(dist[i], dist[j] + 1);\n            }\n        }\n    }\n\n    return dist[dest];\n}",
            "// TODO\n    return 0;\n}",
            "// This is just a helper function. You should not modify this code.\n  std::vector<std::vector<int>> Q;\n  std::vector<int> path;\n  Q.emplace_back(1, source);\n  while (Q.size() > 0) {\n    path = Q.back();\n    Q.pop_back();\n    int node = path.back();\n    if (node == dest) {\n      return path.size();\n    }\n    for (int i = 0; i < N; ++i) {\n      if (A[N*node + i] == 1) {\n        std::vector<int> path_copy = path;\n        path_copy.push_back(i);\n        Q.push_back(path_copy);\n      }\n    }\n  }\n  return -1;\n}",
            "std::vector<int> dist(N, std::numeric_limits<int>::max());\n\tdist[source] = 0;\n\t// TODO: compute shortest path lengths from source to all other nodes\n\t// (in parallel with OpenMP) and store them in dist\n\t// You may assume that dist.size() == A.size() == N*N\n\n\treturn dist[dest];\n}",
            "// Your code goes here\n}",
            "std::vector<std::vector<int> > dist_vector (N, std::vector<int>(N, 0));\n    std::vector<std::vector<int> > pred_vector (N, std::vector<int>(N, -1));\n\n    for (int i = 0; i < N; i++)\n    {\n        for (int j = 0; j < N; j++)\n        {\n            dist_vector[i][j] = A[i * N + j];\n            pred_vector[i][j] = -1;\n        }\n    }\n\n\n    int my_rank;\n    int comm_sz;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &comm_sz);\n\n    int* dist_vector_i = &dist_vector[0][0];\n    int* pred_vector_i = &pred_vector[0][0];\n    int* dist_vector_j = &dist_vector[0][0];\n    int* pred_vector_j = &pred_vector[0][0];\n\n    int* dist_vector_i_global = new int[N * N];\n    int* pred_vector_i_global = new int[N * N];\n\n\n    MPI_Gather(dist_vector_i, N * N, MPI_INT, dist_vector_i_global, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Gather(pred_vector_i, N * N, MPI_INT, pred_vector_i_global, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (my_rank == 0)\n    {\n        for (int i = 1; i < comm_sz; i++)\n        {\n            for (int j = 0; j < N; j++)\n            {\n                for (int k = 0; k < N; k++)\n                {\n                    if (dist_vector_i_global[i * N + j] + dist_vector_i_global[j * N + k] < dist_vector_i_global[i * N + k])\n                    {\n                        dist_vector_i_global[i * N + k] = dist_vector_i_global[i * N + j] + dist_vector_i_global[j * N + k];\n                        pred_vector_i_global[i * N + k] = j;\n                    }\n                }\n            }\n        }\n    }\n\n\n    MPI_Bcast(dist_vector_i_global, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n    MPI_Bcast(pred_vector_i_global, N * N, MPI_INT, 0, MPI_COMM_WORLD);\n\n    if (my_rank!= 0)\n    {\n        for (int i = 0; i < N; i++)\n        {\n            for (int j = 0; j < N; j++)\n            {\n                dist_vector_i[i * N + j] = dist_vector_i_global[i * N + j];\n                pred_vector_i[i * N + j] = pred_vector_i_global[i * N + j];\n            }\n        }\n    }\n\n    delete[] dist_vector_i_global;\n    delete[] pred_vector_i_global;\n\n    std::vector<int> dist_vector_o (N, 0);\n    std::vector<int> pred_vector_o (N, -1);\n\n    for (int i = 0; i < N; i++)\n    {\n        for (int j = 0; j < N; j++)\n        {\n            dist_vector_o[i] += dist_vector_i[i * N + j];\n            pred_vector_o[i] += pred_vector_i[i * N + j];\n        }\n    }\n\n\n    int* dist_vector_o_global = new int[N];\n    int* pred_vector_o_global = new int[N];",
            "// TODO: Your code here\n\n\tint num_of_threads;\n\tint rank;\n\tint num_of_processes;\n\tMPI_Status status;\n\t\n\t// Find the number of threads to spawn.\n\tnum_of_threads = omp_get_num_procs();\n\t\n\t// Use MPI to find the number of processes.\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &num_of_processes);\n\t\n\t// Check if the number of threads and processes is the same.\n\tif (num_of_threads!= num_of_processes){\n\t\t\n\t\t// If they aren't the same, give the user a warning and exit the program.\n\t\tprintf(\"Error: the number of threads and processes do not match.\\n\");\n\t\tMPI_Abort(MPI_COMM_WORLD, 1);\n\t\t\n\t}\n\t\n\t// Use OpenMP to allocate each thread to a process.\n\t#pragma omp parallel num_threads(num_of_threads)\n\t{\n\t\t// Find the thread ID.\n\t\tint thread_id = omp_get_thread_num();\n\t\t\n\t\t// Find the chunk size that each thread will handle.\n\t\tint chunk_size = N/num_of_threads;\n\t\t\n\t\t// Create two vectors for each thread to use.\n\t\tstd::vector<int> distance_vec;\n\t\tstd::vector<int> parent_vec;\n\t\t\n\t\t// Initialize the vectors to the size of N.\n\t\tdistance_vec.resize(N);\n\t\tparent_vec.resize(N);\n\t\t\n\t\t// Initialize the vectors to the number -1.\n\t\tstd::fill(distance_vec.begin(), distance_vec.end(), -1);\n\t\tstd::fill(parent_vec.begin(), parent_vec.end(), -1);\n\t\t\n\t\t// Set the starting point to 0.\n\t\tdistance_vec[source] = 0;\n\t\t\n\t\t// The parent of the source point is itself.\n\t\tparent_vec[source] = source;\n\t\t\n\t\t// Find which chunk of the matrix each thread will be working with.\n\t\tint start = thread_id * chunk_size;\n\t\tint end = (thread_id + 1) * chunk_size;\n\t\t\n\t\t// Loop through the matrix.\n\t\tfor (int i = 0; i < N; i++){\n\t\t\t\n\t\t\t// Loop through the elements.\n\t\t\tfor (int j = 0; j < N; j++){\n\t\t\t\t\n\t\t\t\t// Check if the element is not 0 and is not already in the matrix.\n\t\t\t\tif (A[i*N + j]!= 0 && distance_vec[j] == -1){\n\t\t\t\t\t\n\t\t\t\t\t// Set the distance value of the current node to the distance value of its parent + 1.\n\t\t\t\t\tdistance_vec[j] = distance_vec[i] + 1;\n\t\t\t\t\t\n\t\t\t\t\t// Set the parent of the current node to be the parent of the i node.\n\t\t\t\t\tparent_vec[j] = parent_vec[i];\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Create an int to store the minimum distance of the shortest path.\n\t\tint min_distance;\n\t\t\n\t\t// Find the minimum distance of the shortest path.\n\t\tmin_distance = *std::min_element(distance_vec.begin(), distance_vec.end());\n\t\t\n\t\t// Create an int to store the number of nodes with the minimum distance.\n\t\tint min_count;\n\t\t\n\t\t// Find the number of nodes with the minimum distance.\n\t\tmin_count = std::count(distance_vec.begin(), distance_vec.end(), min_distance);\n\t\t\n\t\t// Create an int to store the sum of the shortest path.\n\t\tint shortest_path_sum;\n\t\t\n\t\t// Loop through all of the nodes with the minimum distance.\n\t\tfor (",
            "if (N == 0) {\n\t\treturn 0;\n\t}\n\n\t// Initialize a vector to keep track of visited nodes and the length of their shortest paths\n\tstd::vector<int> lengths;\n\tstd::vector<bool> visited;\n\tstd::vector<int> min_lengths;\n\tstd::vector<int> parent;\n\tint my_min_len = INT_MAX;\n\tint min_len = INT_MAX;\n\tint my_min_path = -1;\n\tint min_path = -1;\n\tint my_len = 0;\n\tint len = 0;\n\tint proc_count, proc_rank;\n\n\tMPI_Comm_size(MPI_COMM_WORLD, &proc_count);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &proc_rank);\n\n\t// Add each node's shortest path length to the vector\n\tfor (int i = 0; i < N; i++) {\n\t\tlengths.push_back(INT_MAX);\n\t\tvisited.push_back(false);\n\t\tmin_lengths.push_back(INT_MAX);\n\t\tparent.push_back(-1);\n\t}\n\n\t// Set the length of the source node to 0\n\tlengths[source] = 0;\n\tmin_lengths[source] = 0;\n\n\t// Find the length of the shortest path from the source node to every node\n\tfor (int i = 0; i < N - 1; i++) {\n\t\t#pragma omp parallel\n\t\t{\n\t\t\tint tid = omp_get_thread_num();\n\t\t\tint num_threads = omp_get_num_threads();\n\n\t\t\t#pragma omp for\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tif (A[source * N + j] == 1) {\n\t\t\t\t\tlen = lengths[source] + 1;\n\t\t\t\t\tmy_len = lengths[j];\n\t\t\t\t\tif (len < my_len) {\n\t\t\t\t\t\tlengths[j] = len;\n\t\t\t\t\t\tparent[j] = source;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Find the minimum length of all the nodes\n\t\t\tfor (int k = 0; k < N; k++) {\n\t\t\t\tif (lengths[k] < min_lengths[k]) {\n\t\t\t\t\tmin_lengths[k] = lengths[k];\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Sum the minimum lengths of all the nodes\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tmin_len = min_len + min_lengths[j];\n\t\t\t}\n\n\t\t\t// Sum the lengths of the shortest paths from the source to all the nodes\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tlen = lengths[j];\n\t\t\t\tmy_len = my_len + len;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Find the minimum of the lengths of the shortest paths\n\tMPI_Allreduce(&min_len, &my_min_len, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\tMPI_Allreduce(&my_len, &min_len, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n\n\t// Find the shortest path from the source to the destination\n\tint my_path = -1;\n\tint path = -1;\n\tfor (int i = 0; i < N; i++) {\n\t\tif (lengths[i] == my_min_len) {\n\t\t\tmy_path = i;\n\t\t}\n\t}\n\n\t// Find the shortest path to the destination\n\tMPI_Allreduce(&my_path, &path, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\n\tif (proc_rank == 0) {",
            "int nthreads = omp_get_max_threads();\n\tint rank;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tstd::vector<int> dist(N);\n\tstd::fill(dist.begin(), dist.end(), INT_MAX);\n\tdist[source] = 0;\n\n\t#pragma omp parallel num_threads(nthreads)\n\t{\n\t\tint tid = omp_get_thread_num();\n\t\t// printf(\"tid: %d\\n\", tid);\n\n\t\t// queue for the BFS\n\t\tstd::queue<int> q;\n\t\tq.push(source);\n\n\t\t// BFS\n\t\twhile (!q.empty()) {\n\t\t\tint u = q.front();\n\t\t\tq.pop();\n\n\t\t\t// for every node adjacent to u\n\t\t\tfor (int v = 0; v < N; v++) {\n\t\t\t\tif (A[u * N + v] == 1) {\n\t\t\t\t\t// if it has not been visited yet\n\t\t\t\t\tif (dist[v] == INT_MAX) {\n\t\t\t\t\t\t// enqueue and set distance\n\t\t\t\t\t\tq.push(v);\n\t\t\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tint length = dist[dest];\n\n\tif (rank == 0) {\n\t\treturn length;\n\t} else {\n\t\tMPI_Send(&length, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n\t}\n\n\t// Send the length from every rank to rank 0\n\treturn 0;\n}",
            "// TODO: Replace this with your code\n\tint shortest = 0;\n\tint *A_local = (int *)malloc(N*N*sizeof(int));\n\tMPI_Bcast(A_local, N*N, MPI_INT, 0, MPI_COMM_WORLD);\n\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; i++) {\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (i == j) {\n\t\t\t\tA_local[i*N + j] = 0;\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (int k = 0; k < N; k++) {\n\t\t#pragma omp parallel for\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tfor (int j = 0; j < N; j++) {\n\t\t\t\tA_local[i*N + j] = std::min(A_local[i*N + j], A_local[i*N + k] + A_local[k*N + j]);\n\t\t\t}\n\t\t}\n\t}\n\n\tint shortest_local = A_local[source*N + dest];\n\tint shortest_total;\n\n\tMPI_Reduce(&shortest_local, &shortest_total, 1, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n\tif (shortest_total == 0) {\n\t\tshortest_total = -1;\n\t}\n\n\treturn shortest_total;\n}",
            "// TODO: FILL THIS IN!\n}",
            "if (source == dest) return 0;\n    std::vector<int> dist(N, INT_MAX);\n    std::vector<int> prev(N, -1);\n    std::vector<bool> inQ(N, true);\n\n    dist[source] = 0;\n    #pragma omp parallel for\n    for (int i = 0; i < N; ++i) {\n        std::vector<int> currQ(1, i);\n        while (!currQ.empty()) {\n            auto u = currQ.back();\n            currQ.pop_back();\n            inQ[u] = false;\n            if (u == dest) break;\n\n            for (int v = 0; v < N; ++v) {\n                if (A[u*N + v] && dist[v] > dist[u] + 1) {\n                    dist[v] = dist[u] + 1;\n                    prev[v] = u;\n                    if (!inQ[v]) {\n                        inQ[v] = true;\n                        currQ.push_back(v);\n                    }\n                }\n            }\n        }\n    }\n\n    std::vector<int> path;\n    int u = dest;\n    while (u!= -1) {\n        path.push_back(u);\n        u = prev[u];\n    }\n\n    // copy shortest path length to rank 0\n    int pathLength = 0;\n    for (int i = 0; i < path.size(); ++i)\n        pathLength = std::max(pathLength, dist[path[i]]);\n\n    // copy shortest path length to rank 0\n    int shortestPathLength = 0;\n    MPI_Reduce(&pathLength, &shortestPathLength, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);\n    return shortestPathLength;\n}",
            "if(N==0){\n\t\t\treturn 0;\n\t\t}\n\t\tint *path, *temp, *result;\n\t\tint *visited, *source_visited;\n\t\tint myID, numProcs;\n\t\tint *global_visited;\n\t\tint i,j,k,l;\n\t\tint count=0;\n\t\tMPI_Request req[N];\n\t\tMPI_Status status[N];\n\t\tMPI_Comm_rank(MPI_COMM_WORLD, &myID);\n\t\tMPI_Comm_size(MPI_COMM_WORLD, &numProcs);\n\t\tint row, col;\n\t\tint *row_to_proc, *col_to_proc, *row_to_proc_copy, *col_to_proc_copy;\n\t\trow_to_proc=new int[N];\n\t\tcol_to_proc=new int[N];\n\t\trow_to_proc_copy=new int[N];\n\t\tcol_to_proc_copy=new int[N];\n\t\tpath=new int[N];\n\t\ttemp=new int[N];\n\t\tvisited=new int[N];\n\t\tsource_visited=new int[N];\n\t\tresult=new int[N];\n\t\tglobal_visited=new int[N*N];\n\t\tif(myID==0){\n\t\t\tfor(i=0;i<N;i++){\n\t\t\t\trow_to_proc[i]=i;\n\t\t\t\tcol_to_proc[i]=i;\n\t\t\t}\n\t\t}\n\n\t\tMPI_Bcast(row_to_proc,N,MPI_INT,0,MPI_COMM_WORLD);\n\t\tMPI_Bcast(col_to_proc,N,MPI_INT,0,MPI_COMM_WORLD);\n\t\tfor(i=0;i<N;i++){\n\t\t\tfor(j=0;j<N;j++){\n\t\t\t\tglobal_visited[i*N+j]=0;\n\t\t\t}\n\t\t}\n\t\tfor(i=0;i<N;i++){\n\t\t\tvisited[i]=0;\n\t\t\tsource_visited[i]=0;\n\t\t}\n\t\trow_to_proc_copy=row_to_proc;\n\t\tcol_to_proc_copy=col_to_proc;\n\n\t\twhile(1){\n\t\t\tif(myID==0){\n\t\t\t\tfor(i=0;i<N;i++){\n\t\t\t\t\tif(row_to_proc_copy[i]==dest){\n\t\t\t\t\t\tresult[i]=count;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse{\n\t\t\t\tfor(i=0;i<N;i++){\n\t\t\t\t\tif(row_to_proc_copy[i]==dest){\n\t\t\t\t\t\tresult[i]=count;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor(i=0;i<N;i++){\n\t\t\t\tpath[i]=i;\n\t\t\t\ttemp[i]=i;\n\t\t\t}\n\t\t\tfor(i=0;i<N;i++){\n\t\t\t\tif(row_to_proc_copy[i]==dest){\n\t\t\t\t\tfor(j=0;j<N;j++){\n\t\t\t\t\t\tif(i==j){\n\t\t\t\t\t\t\tvisited[i]=0;\n\t\t\t\t\t\t\tglobal_visited[i*N+j]=0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse{\n\t\t\t\t\t\t\tvisited[i]=1;\n\t\t\t\t\t\t\tglobal_visited[i*N+j]=1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif(col_to_proc_copy[i]==dest){\n\t\t\t\t\tfor(j=0;j<N;j++){",
            "int const root = 0;\n  int myrank;\n  MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n  // Use a std::vector<int> for storing the path length on each process\n  std::vector<int> pathLengths(N);\n  std::vector<int> newPathLengths(N);\n  // Mark the source as having length 0\n  pathLengths[source] = 0;\n\n  // Send the path length vector to process 0\n  MPI_Send(&pathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD);\n\n  // If not rank 0, then receive the path length vector from process 0\n  if (myrank!= root) {\n    MPI_Recv(&pathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n  // Perform breadth first search, starting from source.\n  // Mark all nodes reachable in 1 step as having length 1\n  std::vector<bool> visited(N, false);\n  visited[source] = true;\n  std::queue<int> queue;\n  queue.push(source);\n  while (!queue.empty()) {\n    int currentVertex = queue.front();\n    queue.pop();\n    // Get all adjacent vertices\n    for (int i = 0; i < N; i++) {\n      // If edge exists and has not been visited\n      if (A[currentVertex * N + i] &&!visited[i]) {\n        visited[i] = true;\n        queue.push(i);\n        // Update the shortest path length to i\n        pathLengths[i] = pathLengths[currentVertex] + 1;\n      }\n    }\n  }\n\n  // Send the path length vector to process 0\n  MPI_Send(&pathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD);\n\n  // If not rank 0, then receive the path length vector from process 0\n  if (myrank!= root) {\n    MPI_Recv(&newPathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n\n  // Perform breadth first search, starting from source.\n  // Mark all nodes reachable in 2 steps as having length 2\n  visited = std::vector<bool>(N, false);\n  visited[source] = true;\n  queue.push(source);\n  while (!queue.empty()) {\n    int currentVertex = queue.front();\n    queue.pop();\n    // Get all adjacent vertices\n    for (int i = 0; i < N; i++) {\n      // If edge exists and has not been visited\n      if (A[currentVertex * N + i] &&!visited[i]) {\n        visited[i] = true;\n        queue.push(i);\n        // Update the shortest path length to i\n        newPathLengths[i] = newPathLengths[currentVertex] + 1;\n      }\n    }\n  }\n\n  // Send the path length vector to process 0\n  MPI_Send(&newPathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD);\n\n  // If not rank 0, then receive the path length vector from process 0\n  if (myrank!= root) {\n    MPI_Recv(&pathLengths[0], N, MPI_INT, root, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n  }\n\n  // Perform breadth first search, starting from source.\n  // Mark all nodes reachable in 3 steps as having length 3\n  visited = std::vector<bool>(N, false);\n  visited[source] = true;\n  queue.push(source);\n  while (!queue.empty()) {\n    int currentVertex = queue.front();\n    queue.pop();\n    // Get all adjacent vertices\n    for (int i = 0; i < N; i++) {\n      // If edge exists and has not been visited\n      if (A[currentVertex *",
            "int result = 0;\n\t#pragma omp parallel for reduction(+:result)\n\tfor (size_t i = 0; i < N; ++i) {\n\t\tif (i == source) {\n\t\t\tresult += 1;\n\t\t} else {\n\t\t\tfor (size_t j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j] == 1) {\n\t\t\t\t\tint local_result = 0;\n\t\t\t\t\t#pragma omp parallel for reduction(+:local_result)\n\t\t\t\t\tfor (size_t k = 0; k < N; ++k) {\n\t\t\t\t\t\tif (A[j * N + k] == 1) {\n\t\t\t\t\t\t\tlocal_result += 1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tresult = std::max(result, local_result);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn result;\n}",
            "int rank, size;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &size);\n\n  if (size!= N) {\n    printf(\"ERROR: number of MPI ranks must match number of nodes in graph.\\n\");\n    MPI_Finalize();\n    exit(1);\n  }\n\n  std::vector<std::vector<int>> work(N, std::vector<int>(N, -1));\n  work[source][source] = 0;\n\n  /* Your code here! */\n\n\n  if (rank == 0) {\n    printf(\"shortest path length from %d to %d: %d\\n\", source, dest, work[dest][dest]);\n  }\n\n  return work[dest][dest];\n}",
            "// TODO\n}",
            "// Your code here\n  int num_procs, rank_id;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank_id);\n\n  int shortestPathLength = 1000000000;\n  int n_threads = omp_get_max_threads();\n\n  if (rank_id == 0) {\n    // std::vector<int> shortest_path_length_per_thread(n_threads);\n    // #pragma omp parallel for num_threads(n_threads) shared(shortest_path_length_per_thread)\n    // for (int i = 0; i < n_threads; i++) {\n    //   std::vector<bool> visited(N, false);\n    //   std::vector<int> distance(N, 1000000000);\n    //   std::vector<int> parent(N);\n\n    //   visited[source] = true;\n    //   distance[source] = 0;\n\n    //   std::queue<int> q;\n    //   q.push(source);\n\n    //   while (!q.empty()) {\n    //     int u = q.front();\n    //     q.pop();\n\n    //     for (int i = 0; i < N; i++) {\n    //       if (A[u*N+i] &&!visited[i]) {\n    //         visited[i] = true;\n    //         distance[i] = distance[u] + 1;\n    //         parent[i] = u;\n    //         q.push(i);\n    //       }\n    //     }\n    //   }\n\n    //   if (distance[dest] < shortestPathLength) {\n    //     shortestPathLength = distance[dest];\n    //   }\n\n    //   shortest_path_length_per_thread[i] = shortestPathLength;\n    // }\n\n    // std::cout << \"shortest path length per thread: \\n\";\n    // for (int i = 0; i < n_threads; i++) {\n    //   std::cout << shortest_path_length_per_thread[i] << \"\\n\";\n    // }\n  }\n\n  MPI_Bcast(&shortestPathLength, 1, MPI_INT, 0, MPI_COMM_WORLD);\n\n  return shortestPathLength;\n}",
            "int result = std::numeric_limits<int>::max();\n\n\t// TODO: implement\n\n\treturn result;\n}",
            "if (source == dest) return 0;\n    // YOUR CODE GOES HERE\n    return 0;\n}",
            "int pathLength = -1;\n\n\t#pragma omp parallel\n\t{\n\t\tint myPathLength = -1;\n\n\t\t#pragma omp for schedule(dynamic)\n\t\tfor (int i = 0; i < N; i++) {\n\t\t\tint nextSource = i;\n\t\t\tint nextDest = i;\n\t\t\tint nextPathLength = 0;\n\n\t\t\twhile (A[nextSource * N + nextDest] && nextSource!= dest) {\n\t\t\t\tnextSource = nextDest;\n\t\t\t\tnextDest = A[nextSource * N + nextDest];\n\t\t\t\tnextPathLength++;\n\t\t\t}\n\n\t\t\tif (A[nextSource * N + nextDest] && nextSource == dest) {\n\t\t\t\t#pragma omp critical\n\t\t\t\tif (myPathLength < nextPathLength || myPathLength == -1) {\n\t\t\t\t\tmyPathLength = nextPathLength;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp critical\n\t\tif (pathLength < myPathLength || pathLength == -1) {\n\t\t\tpathLength = myPathLength;\n\t\t}\n\t}\n\n\treturn pathLength;\n}",
            "int local_N=N/omp_get_num_threads();\n  int shortestLength=-1;\n  int currentLength;\n  std::vector<bool> visited(N);\n\n  #pragma omp parallel\n  {\n    int local_length=-1;\n    int local_source=local_N*omp_get_thread_num()+source;\n    int local_dest=local_N*omp_get_thread_num()+dest;\n    std::vector<int> parents;\n    parents.resize(N);\n    std::fill(parents.begin(),parents.end(),-1);\n\n    #pragma omp for schedule(static)\n    for(int i=0;i<local_N;i++){\n      if(i==local_source){\n        visited[i]=true;\n        parents[i]=i;\n      }\n    }\n\n    while(local_length==-1){\n      #pragma omp for schedule(static)\n      for(int i=0;i<local_N;i++){\n        for(int j=0;j<local_N;j++){\n          if(A[local_N*i+j]!=0 && visited[j] &&!visited[i]){\n            visited[i]=true;\n            parents[i]=j;\n          }\n        }\n      }\n\n      currentLength=0;\n      #pragma omp for schedule(static)\n      for(int i=0;i<local_N;i++){\n        if(parents[i]!=-1)\n          currentLength+=1;\n        else if(i==local_dest)\n          currentLength=-1;\n      }\n\n      if(currentLength==-1){\n        local_length=currentLength;\n      }\n\n      if(local_length==-1){\n        #pragma omp single\n        shortestLength=currentLength;\n      }\n    }\n  }\n\n  return shortestLength;\n}",
            "int length = -1; // initialize length\n    std::vector<int> visited(N, false); // keep track of visited nodes\n    std::vector<int> distance(N, INT_MAX); // initialize distance to INT_MAX\n    distance[source] = 0;\n    std::vector<int> parent(N, -1); // keep track of the path\n    // create the queue of the nodes to visit\n    std::queue<int> Q;\n    Q.push(source);\n    visited[source] = true;\n    while (!Q.empty()) {\n        int n = Q.front();\n        Q.pop();\n        for (int i = 0; i < N; i++) {\n            if (A[n * N + i] &&!visited[i]) { // if there is a link and node i is not visited\n                visited[i] = true;\n                distance[i] = distance[n] + 1; // increase distance from n to i by 1\n                parent[i] = n; // set the parent of node i to node n\n                Q.push(i); // add node i to queue\n            }\n        }\n    }\n    // update the length if the source and dest are connected and dest is visited\n    if (distance[dest] < INT_MAX && visited[dest]) {\n        length = distance[dest];\n    }\n    return length;\n}",
            "// TODO: write your code here\n  return -1;\n}",
            "int length = 10000;\n\tstd::vector<int> Q;\n\tstd::vector<int> visited(N);\n\tstd::vector<int> parent(N);\n\tstd::vector<int> rank(N);\n\tstd::vector<int> recv_buffer;\n\tstd::vector<int> send_buffer;\n\n\t#pragma omp parallel num_threads(N)\n\t{\n\t\tint rank_id = omp_get_thread_num();\n\t\t//printf(\"%d: start\\n\", rank_id);\n\t\t//printf(\"%d: parent: %d\\n\", rank_id, parent[rank_id]);\n\t\t//printf(\"%d: visited: %d\\n\", rank_id, visited[rank_id]);\n\t\t//printf(\"%d: rank: %d\\n\", rank_id, rank[rank_id]);\n\n\t\t#pragma omp barrier\n\n\t\tif (rank_id == source)\n\t\t{\n\t\t\tQ.push_back(source);\n\t\t\tvisited[source] = 1;\n\t\t}\n\n\t\twhile (Q.size() > 0)\n\t\t{\n\t\t\tint u = Q.back();\n\t\t\tQ.pop_back();\n\n\t\t\tfor (int v = 0; v < N; v++)\n\t\t\t{\n\t\t\t\tif (A[u*N + v] == 1 && visited[v] == 0)\n\t\t\t\t{\n\t\t\t\t\tQ.push_back(v);\n\t\t\t\t\tvisited[v] = 1;\n\t\t\t\t\tparent[v] = u;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t#pragma omp barrier\n\n\t\t\tif (u == dest)\n\t\t\t{\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\t#pragma omp single\n\t\t{\n\t\t\trecv_buffer.resize(N);\n\t\t\tsend_buffer.resize(N);\n\t\t\tfor (int i = 0; i < N; i++)\n\t\t\t{\n\t\t\t\trecv_buffer[i] = parent[i];\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\t#pragma omp master\n\t\t{\n\t\t\tfor (int i = 0; i < N; i++)\n\t\t\t{\n\t\t\t\trank[i] = i;\n\t\t\t}\n\t\t\tint flag = 0;\n\t\t\twhile (flag == 0)\n\t\t\t{\n\t\t\t\tflag = 1;\n\t\t\t\tfor (int i = 1; i < N; i++)\n\t\t\t\t{\n\t\t\t\t\tif (rank[i] < rank[i-1])\n\t\t\t\t\t{\n\t\t\t\t\t\tint temp = rank[i];\n\t\t\t\t\t\trank[i] = rank[i-1];\n\t\t\t\t\t\trank[i-1] = temp;\n\n\t\t\t\t\t\tint temp1 = recv_buffer[i];\n\t\t\t\t\t\trecv_buffer[i] = recv_buffer[i-1];\n\t\t\t\t\t\trecv_buffer[i-1] = temp1;\n\n\t\t\t\t\t\tint temp2 = send_buffer[i];\n\t\t\t\t\t\tsend_buffer[i] = send_buffer[i-1];\n\t\t\t\t\t\tsend_buffer[i-1] = temp2;\n\n\t\t\t\t\t\tflag = 0;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (int i = 0; i < N; i++)\n\t\t\t{\n\t\t\t\tparent[i] = recv_buffer[i];\n\t\t\t}\n\t\t}\n\n\t\t#pragma omp barrier\n\n\t\t//printf(\"%d: parent: %d\\n\", rank_id, parent[rank_id]);\n\t\t//printf(\"%d: visited: %d\\n\", rank_id, visited[rank_id]);\n\t\t//printf(\"%d: rank:",
            "int* dist = new int[N];\n\tfor (int i = 0; i < N; i++) {\n\t\tdist[i] = std::numeric_limits<int>::max();\n\t}\n\tdist[source] = 0;\n\tstd::vector<int> Q = { source };\n\twhile (!Q.empty()) {\n\t\tint u = Q.back();\n\t\tQ.pop_back();\n\t\tfor (int v = 0; v < N; v++) {\n\t\t\tif (A[v + u * N] > 0 && dist[v] > dist[u] + 1) {\n\t\t\t\tdist[v] = dist[u] + 1;\n\t\t\t\tQ.push_back(v);\n\t\t\t}\n\t\t}\n\t}\n\n\tint ret = std::numeric_limits<int>::max();\n\tfor (int i = 0; i < N; i++) {\n\t\tret = std::min(ret, dist[i]);\n\t}\n\n\tdelete[] dist;\n\n\treturn ret;\n}",
            "// TODO: implement this function\n    return 0;\n}",
            "int myrank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\n    int mysize;\n    MPI_Comm_size(MPI_COMM_WORLD, &mysize);\n\n    int* dist = new int[N];\n    for (int i = 0; i < N; i++) dist[i] = INT_MAX;\n    dist[source] = 0;\n\n    int* dist_copy = new int[N];\n    memcpy(dist_copy, dist, sizeof(int) * N);\n\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (A[i * N + j]!= 0 && dist[j] + 1 < dist[i]) {\n                dist[i] = dist[j] + 1;\n            }\n        }\n    }\n\n    MPI_Reduce(MPI_IN_PLACE, dist_copy, N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n    if (myrank == 0) {\n        int result = dist_copy[dest];\n        delete[] dist_copy;\n        delete[] dist;\n        return result;\n    } else {\n        delete[] dist_copy;\n        delete[] dist;\n        return 0;\n    }\n}",
            "}",
            "// BEGIN_YOUR_CODE\n  int ans=INT_MAX;\n  if(source==dest) return 0;\n  std::vector<int> dist(N,INT_MAX);\n  std::vector<bool> vis(N,0);\n  std::vector<std::pair<int,int>> q;\n  dist[source]=0;\n  vis[source]=true;\n  q.push_back({0,source});\n  while(!q.empty()){\n    int u=q.back().second;\n    int d=q.back().first;\n    q.pop_back();\n    for(int i=0;i<N;++i){\n      if(A[u*N+i]&&!vis[i]){\n        dist[i]=d+1;\n        vis[i]=true;\n        q.push_back({d+1,i});\n      }\n    }\n  }\n  return dist[dest];\n  // END_YOUR_CODE\n}",
            "return 0;\n}",
            "int* distances = new int[N];\n\t#pragma omp parallel for\n\tfor (int i = 0; i < N; ++i) {\n\t\tdistances[i] = std::numeric_limits<int>::max();\n\t}\n\tdistances[source] = 0;\n\n\tbool* changed = new bool[N];\n\tfor (int i = 0; i < N; ++i) {\n\t\tchanged[i] = true;\n\t}\n\n\tint it = 0;\n\twhile (it < N) {\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tfor (int j = 0; j < N; ++j) {\n\t\t\t\tif (A[i * N + j]!= 0 && distances[i]!= std::numeric_limits<int>::max() &&\n\t\t\t\t\t\tdistances[i] + 1 < distances[j]) {\n\t\t\t\t\tdistances[j] = distances[i] + 1;\n\t\t\t\t\tchanged[j] = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor (int i = 0; i < N; ++i) {\n\t\t\tchanged[i] = false;\n\t\t}\n\t\t++it;\n\t}\n\n\tdelete[] changed;\n\treturn distances[dest];\n}",
            "// TODO\n    return -1;\n}",
            "int numOfRanks, rank, rootRank = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numOfRanks);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n\tint* dist = new int[N];\n\tstd::vector<int> pred(N, -1);\n\tstd::vector<bool> visited(N, false);\n\n\tdist[source] = 0;\n\tvisited[source] = true;\n\tpred[source] = -1;\n\n\tfor (int i = 0; i < N; i++) {\n\t\tint min = INFINITY;\n\t\tint u;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (!visited[j] && dist[j] < min) {\n\t\t\t\tu = j;\n\t\t\t\tmin = dist[j];\n\t\t\t}\n\t\t}\n\t\tvisited[u] = true;\n\t\tfor (int j = 0; j < N; j++) {\n\t\t\tif (A[u * N + j] &&!visited[j]) {\n\t\t\t\tif (dist[u] + A[u * N + j] < dist[j]) {\n\t\t\t\t\tdist[j] = dist[u] + A[u * N + j];\n\t\t\t\t\tpred[j] = u;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t\n\tint shortestPathLength = dist[dest];\n\t\n\tif (rank == rootRank) {\n\t\tfor (int i = 1; i < numOfRanks; i++) {\n\t\t\tMPI_Recv(&shortestPathLength, 1, MPI_INT, i, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t\t}\n\t}\n\telse {\n\t\tMPI_Send(&shortestPathLength, 1, MPI_INT, rootRank, 0, MPI_COMM_WORLD);\n\t}\n\n\tint u = dest;\n\tstd::vector<int> path;\n\twhile (pred[u]!= -1) {\n\t\tpath.push_back(u);\n\t\tu = pred[u];\n\t}\n\tpath.push_back(u);\n\n\tdelete[] dist;\n\treturn shortestPathLength;\n}",
            "// TODO: YOUR CODE HERE\n}",
            "int length = 0;\n\n\t// TODO: your code here\n\treturn length;\n}",
            "assert(A.size() == N * N);\n    assert(source < N && dest < N);\n    // TODO\n}",
            "int num_processes, rank;\n  MPI_Comm_size(MPI_COMM_WORLD, &num_processes);\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n  std::vector<int> num_paths(num_processes);\n  std::vector<int> local_paths;\n\n  #pragma omp parallel\n  {\n    int local_threads = omp_get_num_threads();\n    int local_rank = omp_get_thread_num();\n\n    // 1. Local initialization of shortest path lengths to INF\n    if (rank == 0) {\n      for (int i = 0; i < N; i++) {\n        num_paths[i] = std::numeric_limits<int>::max();\n      }\n    }\n\n    // 2. Local computation of shortest path lengths from source\n    #pragma omp for\n    for (int i = 0; i < N; i++) {\n      if (A[source * N + i] == 1) {\n        local_paths.push_back(i);\n      }\n    }\n    // 3. Local reduction of shortest path lengths\n    // 4. Local update of shortest path lengths\n    for (int i = 0; i < local_paths.size(); i++) {\n      for (int j = 0; j < local_paths.size(); j++) {\n        if (A[local_paths[i] * N + local_paths[j]] == 1) {\n          if (num_paths[local_paths[i]] > num_paths[local_paths[j]] + 1) {\n            num_paths[local_paths[i]] = num_paths[local_paths[j]] + 1;\n          }\n        }\n      }\n    }\n    // 5. Local computation of shortest path lengths to dest\n    #pragma omp for\n    for (int i = 0; i < N; i++) {\n      if (A[dest * N + i] == 1) {\n        local_paths.push_back(i);\n      }\n    }\n    // 6. Local reduction of shortest path lengths\n    // 7. Local update of shortest path lengths\n    for (int i = 0; i < local_paths.size(); i++) {\n      for (int j = 0; j < local_paths.size(); j++) {\n        if (A[local_paths[i] * N + local_paths[j]] == 1) {\n          if (num_paths[local_paths[i]] > num_paths[local_paths[j]] + 1) {\n            num_paths[local_paths[i]] = num_paths[local_paths[j]] + 1;\n          }\n        }\n      }\n    }\n  }\n  // 8. MPI reduction of shortest path lengths\n  MPI_Reduce(&num_paths[0], &num_paths[0], N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\n  // 9. Return shortest path length\n  if (rank == 0) {\n    return num_paths[dest];\n  }\n  return -1;\n}",
            "// TODO: Replace this with your code\n  return -1;\n}",
            "/*\n       Your code goes here\n    */\n    //TODO: Implement this function\n    return 0;\n}",
            "// Your code here\n}",
            "// TODO: Implement\n    int rank = 0;\n    int size = 0;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &size);\n    int local_source = source / size;\n    int local_dest = dest / size;\n    if (rank == 0) {\n        std::vector<int> dist(A.size(), INT_MAX);\n        dist[source] = 0;\n        std::vector<bool> visit(A.size(), false);\n        visit[source] = true;\n        for (size_t i = 0; i < size - 1; i++) {\n            for (size_t j = 0; j < A.size(); j++) {\n                if (!visit[j]) {\n                    continue;\n                }\n                for (size_t k = 0; k < A.size(); k++) {\n                    if (!visit[k] && A[j * A.size() + k] == 1) {\n                        dist[k] = dist[j] + 1;\n                        visit[k] = true;\n                    }\n                }\n            }\n        }\n        int global_dist = INT_MAX;\n        int global_dest = INT_MAX;\n        for (size_t j = 0; j < A.size(); j++) {\n            if (dist[j] < global_dist) {\n                global_dist = dist[j];\n                global_dest = j;\n            }\n        }\n        return global_dist;\n    }\n    else if (rank == 0) {\n        std::vector<int> dist(A.size(), INT_MAX);\n        dist[source] = 0;\n        std::vector<bool> visit(A.size(), false);\n        visit[source] = true;\n        for (size_t i = 0; i < size - 1; i++) {\n            for (size_t j = 0; j < A.size(); j++) {\n                if (!visit[j]) {\n                    continue;\n                }\n                for (size_t k = 0; k < A.size(); k++) {\n                    if (!visit[k] && A[j * A.size() + k] == 1) {\n                        dist[k] = dist[j] + 1;\n                        visit[k] = true;\n                    }\n                }\n            }\n        }\n        int global_dist = INT_MAX;\n        int global_dest = INT_MAX;\n        for (size_t j = 0; j < A.size(); j++) {\n            if (dist[j] < global_dist) {\n                global_dist = dist[j];\n                global_dest = j;\n            }\n        }\n        return global_dist;\n    }\n    return -1;\n}",
            "// TODO: Your code here\n\tint numRank, rank, length = 0;\n\tMPI_Comm_size(MPI_COMM_WORLD, &numRank);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\t\n\tif (source == dest) {\n\t\tlength = 0;\n\t}\n\telse {\n\t\tint sourceIndex = source;\n\t\tint destIndex = dest;\n\t\t\n\t\tstd::vector<int> dist;\n\t\tdist.resize(N);\n\t\tdist[0] = -1;\n\t\tdist[source] = 0;\n\t\t\n\t\twhile (destIndex!= sourceIndex && sourceIndex < N) {\n\t\t\t\n\t\t\tfor (size_t i = 0; i < N; i++) {\n\t\t\t\tif (A[sourceIndex*N + i] == 1) {\n\t\t\t\t\tif (dist[i] == -1) {\n\t\t\t\t\t\tdist[i] = dist[sourceIndex] + 1;\n\t\t\t\t\t}\n\t\t\t\t\telse if (dist[sourceIndex] + 1 < dist[i]) {\n\t\t\t\t\t\tdist[i] = dist[sourceIndex] + 1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tsourceIndex++;\n\t\t}\n\t\t\n\t\tlength = dist[dest];\n\t}\n\t\n\tint length_global = 0;\n\tMPI_Allreduce(&length, &length_global, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\treturn length_global;\n}",
            "int pathLength = 1000; // arbitrary large number\n\n    // TODO: implement the shortest path algorithm\n\n    return pathLength;\n}",
            "int p;\n    MPI_Comm_size(MPI_COMM_WORLD, &p);\n    MPI_Comm comm;\n    int rank;\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n    int *A_arr = new int[N * N];\n    for (int i = 0; i < N; ++i) {\n        for (int j = 0; j < N; ++j) {\n            A_arr[i * N + j] = A[i * N + j];\n        }\n    }\n    int *dist = new int[N];\n    std::fill(dist, dist + N, INT_MAX);\n    dist[source] = 0;\n    int *changed = new int[p];\n    for (int i = 0; i < p; ++i) {\n        changed[i] = 1;\n    }\n    int iter = 0;\n    while (changed[rank]) {\n        changed[rank] = 0;\n        for (int i = 0; i < N; ++i) {\n            if (A_arr[N * rank + i] && dist[i] + 1 < dist[rank]) {\n                dist[rank] = dist[i] + 1;\n                changed[rank] = 1;\n            }\n        }\n        for (int i = 0; i < N; ++i) {\n            if (A_arr[i * N + rank] && dist[i] + 1 < dist[rank]) {\n                dist[rank] = dist[i] + 1;\n                changed[rank] = 1;\n            }\n        }\n        ++iter;\n    }\n    delete[] A_arr;\n    int *out = new int[p];\n    MPI_Gather(dist + source, 1, MPI_INT, out, 1, MPI_INT, 0, MPI_COMM_WORLD);\n    int res = INT_MAX;\n    if (rank == 0) {\n        for (int i = 0; i < p; ++i) {\n            if (out[i] < res) {\n                res = out[i];\n            }\n        }\n    }\n    delete[] dist;\n    delete[] changed;\n    delete[] out;\n    return res;\n}",
            "int* local_cost = (int*)malloc(sizeof(int)*N);\n\tfor (int i=0; i<N; i++) {\n\t\tlocal_cost[i] = INT_MAX;\n\t}\n\n\tint world_size, world_rank;\n\tMPI_Comm_size(MPI_COMM_WORLD, &world_size);\n\tMPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n\n\tint start = world_rank * N/world_size;\n\tint end = (world_rank+1) * N/world_size;\n\tint* local_path = (int*)malloc(sizeof(int)*N);\n\tfor (int i=0; i<N; i++) {\n\t\tlocal_path[i] = INT_MAX;\n\t}\n\tint* local_dist = (int*)malloc(sizeof(int)*N);\n\tfor (int i=0; i<N; i++) {\n\t\tlocal_dist[i] = INT_MAX;\n\t}\n\n\tfor (int i=0; i<N; i++) {\n\t\tlocal_cost[i] = A[source*N + i];\n\t\tif (local_cost[i]!= INT_MAX) {\n\t\t\tlocal_path[i] = source;\n\t\t\tlocal_dist[i] = 0;\n\t\t}\n\t}\n\n\tint k = 0;\n\twhile (k < N) {\n\n\t\t#pragma omp parallel\n\t\t{\n\t\t\tfor (int i=start; i<end; i++) {\n\t\t\t\tfor (int j=0; j<N; j++) {\n\t\t\t\t\tif (A[i*N+j]!= INT_MAX && local_dist[i]!= INT_MAX && local_dist[i] + local_cost[i] < local_dist[j]) {\n\t\t\t\t\t\tlocal_dist[j] = local_dist[i] + local_cost[i];\n\t\t\t\t\t\tlocal_path[j] = i;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (int i=0; i<N; i++) {\n\t\t\tlocal_cost[i] = INT_MAX;\n\t\t}\n\t\tfor (int i=start; i<end; i++) {\n\t\t\tlocal_cost[i] = local_dist[i]!= INT_MAX? A[i*N + local_path[i]] : INT_MAX;\n\t\t}\n\n\t\tk++;\n\t}\n\n\t// merge results from all processes\n\tint* all_dist = (int*)malloc(sizeof(int)*N);\n\tint* all_path = (int*)malloc(sizeof(int)*N);\n\tfor (int i=0; i<N; i++) {\n\t\tall_dist[i] = INT_MAX;\n\t}\n\tfor (int i=0; i<N; i++) {\n\t\tall_path[i] = INT_MAX;\n\t}\n\n\tMPI_Allreduce(local_dist, all_dist, N, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\tMPI_Allreduce(local_path, all_path, N, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n\n\tint length = all_dist[dest];\n\tif (world_rank == 0) {\n\t\tfree(local_cost);\n\t\tfree(local_path);\n\t\tfree(local_dist);\n\t}\n\tfree(all_dist);\n\tfree(all_path);\n\n\treturn length;\n}",
            "// TODO: Complete this function\n    int ans = 0;\n    int tag = 0;\n    int* dp = new int[N];\n    int* parent = new int[N];\n    int* msg = new int[2];\n    MPI_Request req;\n\n    for (int i = 0; i < N; i++) {\n        dp[i] = INT_MAX;\n        parent[i] = -1;\n    }\n    dp[source] = 0;\n\n    for (int i = 0; i < N; i++) {\n        int next = -1;\n        int next_dist = INT_MAX;\n        int max_dist = INT_MAX;\n        for (int j = 0; j < N; j++) {\n            if (dp[j] < max_dist && A[j * N + i]!= 0) {\n                next = j;\n                next_dist = dp[j] + 1;\n                max_dist = next_dist;\n            }\n        }\n        if (next!= -1) {\n            parent[next] = i;\n            dp[next] = next_dist;\n        }\n    }\n\n    int my_rank;\n    int rank_count;\n    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n    MPI_Comm_size(MPI_COMM_WORLD, &rank_count);\n\n    if (my_rank!= 0) {\n        MPI_Send(dp, N, MPI_INT, 0, 0, MPI_COMM_WORLD);\n    } else {\n        for (int i = 1; i < rank_count; i++) {\n            MPI_Recv(dp, N, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n        }\n        ans = dp[dest];\n        if (ans == INT_MAX) {\n            ans = -1;\n        }\n    }\n\n    delete[] dp;\n    delete[] parent;\n    delete[] msg;\n\n    return ans;\n}",
            "int length = 0;\n\t// TODO: Compute shortest path length using MPI and OpenMP.\n\treturn length;\n}",
            "// Your code here\n\tint ans = INT_MAX;\n\tstd::vector<std::vector<int>> graph(N, std::vector<int>(N));\n\tstd::vector<std::vector<int>> distance(N, std::vector<int>(N));\n\tgraph = A;\n\tdistance = A;\n\tint rank, size;\n\tMPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\tMPI_Comm_size(MPI_COMM_WORLD, &size);\n\tif(rank == 0){\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tfor(int j = 0; j < N; j++){\n\t\t\t\tdistance[i][j] = graph[i][j];\n\t\t\t}\n\t\t}\n\t}\n\tint count = 0;\n\tfor(int i = 0; i < N; i++){\n\t\tif(graph[source][i] == 1 && i!= source){\n\t\t\tcount++;\n\t\t}\n\t}\n\tif(rank == 0){\n\t\tfor(int i = 0; i < count; i++){\n\t\t\tMPI_Send(&distance[source][i], 1, MPI_INT, i + 1, 0, MPI_COMM_WORLD);\n\t\t}\n\t}else{\n\t\tMPI_Recv(&distance[source][rank - 1], 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n\t}\n\tfor(int i = 0; i < count; i++){\n\t\tfor(int j = 0; j < N; j++){\n\t\t\tif(distance[source][i] + graph[i][j] < distance[source][j]){\n\t\t\t\tdistance[source][j] = distance[source][i] + graph[i][j];\n\t\t\t}\n\t\t}\n\t}\n\tstd::vector<int> local_ans(N, INT_MAX);\n\tif(rank == 0){\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tlocal_ans[i] = distance[source][i];\n\t\t}\n\t}else{\n\t\tlocal_ans[rank - 1] = distance[source][rank - 1];\n\t}\n\tstd::vector<int> global_ans(N, INT_MAX);\n\tMPI_Reduce(local_ans.data(), global_ans.data(), N, MPI_INT, MPI_MIN, 0, MPI_COMM_WORLD);\n\tif(rank == 0){\n\t\tfor(int i = 0; i < N; i++){\n\t\t\tif(global_ans[i]!= INT_MAX){\n\t\t\t\tans = std::min(ans, global_ans[i]);\n\t\t\t}\n\t\t}\n\t}\n\treturn ans;\n}",
            "std::vector<int> visited(N);\n  std::fill(visited.begin(), visited.end(), -1);\n  visited[source] = 0;\n  int rank = 0;\n  int worldSize = 1;\n  MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n  MPI_Comm_size(MPI_COMM_WORLD, &worldSize);\n  MPI_Status status;\n\n  int found = 0;\n  int length;\n  int shortestLength = std::numeric_limits<int>::max();\n\n  int level = 1;\n  std::vector<int> nodes;\n\n  int localSize = (int)N / worldSize;\n  int numLocalNodes = 0;\n  if (rank == 0) {\n    numLocalNodes = localSize;\n    for (int i = 1; i < worldSize; ++i) {\n      MPI_Send(&numLocalNodes, 1, MPI_INT, i, 0, MPI_COMM_WORLD);\n    }\n  } else {\n    MPI_Recv(&numLocalNodes, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &status);\n  }\n\n  while (found == 0) {\n    if (rank == 0) {\n      for (int i = 0; i < numLocalNodes; ++i) {\n        nodes.push_back(i);\n      }\n    } else {\n      for (int i = 0; i < numLocalNodes; ++i) {\n        nodes.push_back(localSize * rank + i);\n      }\n    }\n\n    MPI_Bcast(&nodes[0], numLocalNodes, MPI_INT, 0, MPI_COMM_WORLD);\n\n    #pragma omp parallel for\n    for (int i = 0; i < nodes.size(); ++i) {\n      int node = nodes[i];\n      if (visited[node] == level) {\n        for (int j = 0; j < N; ++j) {\n          if (A[node * N + j] > 0 && visited[j] == -1) {\n            visited[j] = level + 1;\n            if (j == dest) {\n              length = level + 1;\n              found = 1;\n              #pragma omp critical\n              {\n                if (length < shortestLength) {\n                  shortestLength = length;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n\n    level++;\n    MPI_Allreduce(&found, &found, 1, MPI_INT, MPI_MIN, MPI_COMM_WORLD);\n    nodes.clear();\n  }\n\n  if (rank == 0) {\n    return shortestLength;\n  }\n\n  return 0;\n}",
            "// Your code goes here!\n\treturn 0;\n}",
            "int length = 0;\n    std::vector<int> distance(N, std::numeric_limits<int>::max());\n    std::vector<int> previous(N, -1);\n    std::vector<bool> visited(N, false);\n\n    distance[source] = 0;\n    previous[source] = source;\n    visited[source] = true;\n\n    bool has_updated = true;\n\n    while (has_updated) {\n        has_updated = false;\n\n        #pragma omp parallel for\n        for (size_t i = 0; i < N; ++i) {\n            #pragma omp critical\n            if (!visited[i] && distance[i] == std::numeric_limits<int>::max()) {\n                distance[i] = distance[previous[i]] + 1;\n                previous[i] = previous[previous[i]];\n                has_updated = true;\n                visited[i] = true;\n            }\n        }\n    }\n\n    return distance[dest];\n}",
            "std::vector<std::vector<int>> paths(N, std::vector<int>(N, -1));\n    std::vector<int> Q;\n    Q.push_back(source);\n    paths[source][source] = 0;\n    while (Q.size() > 0) {\n        int u = Q.back();\n        Q.pop_back();\n\n        for (int v = 0; v < N; v++) {\n            if (paths[u][v] == -1 && A[u * N + v] > 0) {\n                Q.push_back(v);\n                paths[u][v] = paths[u][source] + 1;\n            }\n        }\n    }\n\n    return paths[source][dest];\n}",
            "const int root = 0;\n\n    int n_procs = 0;\n    int rank = 0;\n\n    MPI_Comm_size(MPI_COMM_WORLD, &n_procs);\n    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n\n    // initialize the buffer\n    std::vector<int> buffer(n_procs);\n    int* buffer_ptr = buffer.data();\n\n    if (rank == root) {\n        std::vector<int> dist(N, -1);\n        dist[source] = 0;\n\n        // queue of nodes to expand\n        std::queue<int> Q;\n        Q.push(source);\n\n        // start the BFS\n        while (!Q.empty()) {\n            // pop the first node from the queue\n            int node = Q.front();\n            Q.pop();\n\n            // find all the neighbors of the current node\n            for (size_t i = 0; i < N; i++) {\n                // if the neighbor is not seen before\n                if (dist[i] == -1 && A[node * N + i] == 1) {\n                    // add it to the queue and mark as seen\n                    Q.push(i);\n                    dist[i] = dist[node] + 1;\n                }\n            }\n        }\n\n        for (int i = 0; i < n_procs; i++) {\n            buffer[i] = dist[i];\n        }\n    }\n\n    // send the buffer to the root\n    MPI_Gather(buffer_ptr, n_procs, MPI_INT, buffer_ptr, n_procs, MPI_INT, root, MPI_COMM_WORLD);\n\n    int shortest_path_length = 0;\n\n    if (rank == root) {\n        // find the shortest path length to the destination\n        for (int i = 0; i < n_procs; i++) {\n            if (buffer[i] >= 0) {\n                shortest_path_length = std::min(shortest_path_length, buffer[i]);\n            }\n        }\n    }\n\n    return shortest_path_length;\n}",
            "// TODO\n    return -1;\n}",
            "int n_threads = omp_get_max_threads();\n  int n_ranks = omp_get_num_threads();\n  int n_threads_per_rank = n_threads / n_ranks;\n  int my_rank = omp_get_thread_num() / n_threads_per_rank;\n  int my_rank_thread = omp_get_thread_num() % n_threads_per_rank;\n\n  int *q = new int[n_threads_per_rank];\n  int *d = new int[n_threads_per_rank];\n\n  for (int i = 0; i < n_threads_per_rank; ++i) {\n    q[i] = source;\n    d[i] = -1;\n  }\n\n  d[my_rank_thread] = 0;\n\n  bool changed = true;\n  int level = 0;\n\n  while (changed) {\n    changed = false;\n\n    for (int i = 0; i < n_threads_per_rank; ++i) {\n      for (int j = 0; j < A[q[i]][i]; ++j) {\n        if (d[i] + 1 < d[j]) {\n          d[j] = d[i] + 1;\n          changed = true;\n        }\n      }\n    }\n    ++level;\n  }\n  return d[dest];\n}"
        ]
    }
]