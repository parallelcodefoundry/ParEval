{"section_title": "1 Overview of the OpenMP API", "chunk": "1 1 Overview of the OpenMP API \n The collection of compiler directives, library routines, and environment variables that this \n document describes collectively define the specification of the OpenMP Application Program \n Interface (OpenMP API) for parallelism in C, C++ and Fortran programs.\n This specification provides a model for parallel programming that is portable across architectures \n from different vendors.Compilers from numerous vendors support the OpenMP API.More \n information about the OpenMP API can be found at the following web site \n http://www.openmp.org \n The directives, library routines, environment variables, and tool support that this document defines \n allow users to create, to manage, to debug and to analyze parallel programs while permitting \n portability."}
{"section_title": "1 Overview of the OpenMP API", "chunk": "More \n information about the OpenMP API can be found at the following web site \n http://www.openmp.org \n The directives, library routines, environment variables, and tool support that this document defines \n allow users to create, to manage, to debug and to analyze parallel programs while permitting \n portability.The directives extend the C, C++ and Fortran base languages with single program \n multiple data (SPMD) constructs, tasking constructs, device constructs, work-distribution \n constructs, and synchronization constructs, and they provide support for sharing, mapping and \n privatizing data.The functionality to control the runtime environment is provided by library \n routines and environment variables.Compilers that support the OpenMP API often include \n command line options to enable or to disable interpretation of some or all OpenMP directives.\n"}
{"section_title": "1.1 Scope", "chunk": "18 The OpenMP API covers only user-directed parallelization, wherein the programmer explicitly \n specifies the actions to be taken by the compiler and runtime system in order to execute the program \n in parallel.OpenMP-compliant implementations are not required to check for data dependences, \n data conflicts, race conditions, or deadlocks.Compliant implementations also are not required to \n check for any code sequences that cause a program to be classified as non-conforming.Application \n developers are responsible for correctly using the OpenMP API to produce a conforming program.\n The OpenMP API does not cover compiler-generated automatic parallelization.\n \n"}
{"section_title": "1.2 Glossary", "chunk": ""}
{"section_title": "1.2.1 Threading Concepts", "chunk": "3 thread An execution entity with a stack and associated threadprivate memory.\n OpenMP thread A thread that is managed by the OpenMP implementation.\n thread number A number that the OpenMP implementation assigns to an OpenMP thread.For \n threads within the same team, zero identifies the primary thread and consecutive \n numbers identify the other threads of this team.\n idle thread An OpenMP thread that is not currently part of any parallel region.\n thread-safe routine A routine that performs the intended function even when executed concurrently (by \n more than one thread).\n processor Implementation-defined hardware unit on which one or more OpenMP threads can \n execute.\n device An implementation-defined logical execution engine.\n COMMENT: A device could have one or more processors.\n host device The device on which the OpenMP program begins execution."}
{"section_title": "1.2.1 Threading Concepts", "chunk": "\n host device The device on which the OpenMP program begins execution.\n target device A device with respect to which the current device performs an operation, as specified \n by a device construct or an OpenMP device memory routine.\n parent device For a given target region, the device on which the corresponding target \n construct was encountered.\n"}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "21 base language A programming language that serves as the foundation of the OpenMP specification.\n COMMENT: See Section 1.7 for a listing of current base languages for \n the OpenMP API.\n base program A program written in a base language.\n preprocessed code For C/C++, a sequence of preprocessing tokens that result from the first six phases of \n translation, as defined by the base language.\n program order An ordering of operations performed by the same thread as determined by the \n execution sequence of operations specified by the base language.\n OpenMP API \u2013 Version 5.2 November 2021 \n COMMENT: For versions of C and C++ that include base language \n support for threading, program order corresponds to the sequenced before \n relation between operations performed by the same thread.\n structured block For C/C++, an executable statement, possibly compound, with a single entry at the \n top and a single exit at the bottom, or an OpenMP construct."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n structured block For C/C++, an executable statement, possibly compound, with a single entry at the \n top and a single exit at the bottom, or an OpenMP construct.\n For Fortran, a strictly structured block or a loosely structured block.\nstructured block \nsequence \n For C/C++, a sequence of zero or more executable statements (including OpenMP \n constructs) that together have a single entry at the top and a single exit at the bottom.\n For Fortran, a block of zero or more executable constructs (including OpenMP \n constructs) with a single entry at the top and a single exit at the bottom.\nstrictly structured \nblock \n A single Fortran BLOCK construct, with a single entry at the top and a single exit at \n the bottom.\nloosely structured \nblock \n A block of zero or more executable constructs (including OpenMP constructs), \n where the first executable construct (if any) is not a Fortran BLOCK construct, with a \n single entry at the top and a single exit at the bottom."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\nloosely structured \nblock \n A block of zero or more executable constructs (including OpenMP constructs), \n where the first executable construct (if any) is not a Fortran BLOCK construct, with a \n single entry at the top and a single exit at the bottom.\n compilation unit For C/C++, a translation unit.\n For Fortran, a program unit.\n enclosing context For C/C++, the innermost scope enclosing an OpenMP directive.\n For Fortran, the innermost scoping unit enclosing an OpenMP directive.\n directive A base language mechanism to specify OpenMP program behavior.\n COMMENT: See Section 3.1 for a description of OpenMP directive \n syntax in each base language.\n white space A non-empty sequence of space and/or horizontal tab characters.\n OpenMP program A program that consists of a base program that is annotated with OpenMP directives \n or that calls OpenMP API runtime library routines."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n OpenMP program A program that consists of a base program that is annotated with OpenMP directives \n or that calls OpenMP API runtime library routines.\n conforming program An OpenMP program that follows all rules and restrictions of the OpenMP \n specification.\n implementation code Implicit code that is introduced by the OpenMP implementation.\n metadirective A directive that conditionally resolves to another directive.\n declarative directive An OpenMP directive that may only be placed in a declarative context and results in \n one or more declarations only; it is not associated with the immediate execution of \n any user code or implementation code.For C++, if a declarative directive applies to a \n function declaration or definition and it is specified with one or more C++ attribute \n specifiers, the specified attributes must be applied to the function as permitted by the \nCHAPTER 1.OVERVIEW OF THE OPENMP API 3 \n base language."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "OVERVIEW OF THE OPENMP API 3 \n base language.For Fortran, a declarative directive must appear after any USE, \n IMPORT, and IMPLICIT statements in a declarative context.\n executable directive An OpenMP directive that appears in an executable context and results in \n implementation code and/or prescribes the manner in which associated user code \n must execute.\n informational directive An OpenMP directive that is neither declarative nor executable, but otherwise \n conveys user code properties to the compiler.\n utility directive An OpenMP directive that facilitates interactions with the compiler and/or supports \n code readability; it may be either informational or executable.\n stand-alone directive An OpenMP construct in which no user code is associated, but may produce \n implementation code.\n construct An OpenMP executable directive and its paired end directive (if any) and the \n associated structured block (if any) not including the code in any called routines."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n construct An OpenMP executable directive and its paired end directive (if any) and the \n associated structured block (if any) not including the code in any called routines.\n That is, the lexical extent of an executable directive.\n subsidiary directive An OpenMP directive that is not an executable directive and that appears only as part \n of an OpenMP construct.\n combined construct A construct that is a shortcut for specifying one construct immediately nested inside \n another construct.A combined construct is semantically identical to that of \n explicitly specifying the first construct containing one instance of the second \n construct and no other statements.\n composite construct A construct that is composed of two constructs but does not have identical semantics \n to specifying one of the constructs immediately nested inside the other."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n composite construct A construct that is composed of two constructs but does not have identical semantics \n to specifying one of the constructs immediately nested inside the other.A composite \n construct either adds semantics not included in the constructs from which it is \n composed or provides an effective nesting of the one construct inside the other that \n would otherwise be non-conforming.\n constituent construct For a given combined or composite construct, a construct from which it, or any one \n of its constituent constructs, is composed.\n COMMENT: The constituent constructs of a \n target teams distribute parallel for simd construct are the \n following constructs: target, \n teams distribute parallel for simd, teams, \n distribute parallel for simd, distribute, \n parallel for simd, parallel, for simd, for, and simd."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n COMMENT: The constituent constructs of a \n target teams distribute parallel for simd construct are the \n following constructs: target, \n teams distribute parallel for simd, teams, \n distribute parallel for simd, distribute, \n parallel for simd, parallel, for simd, for, and simd.\n leaf construct For a given combined or composite construct, a constituent construct that is not itself \n a combined or composite construct.\n COMMENT: The leaf constructs of a \n target teams distribute parallel for simd construct are the \n OpenMP API \u2013 Version 5.2 November 2021 \n following constructs: target, teams, distribute, parallel, \n for, and simd.\ncombined target \nconstruct \n A combined construct that is composed of a target construct along with another \n construct.\n region All code encountered during a specific instance of the execution of a given construct, \n structured block sequence or OpenMP library routine."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n region All code encountered during a specific instance of the execution of a given construct, \n structured block sequence or OpenMP library routine.A region includes any code in \n called routines as well as any implementation code.The generation of a task at the \n point where a task generating construct is encountered is a part of the region of the \n encountering thread.However, an explicit task region that corresponds to a task \n generating construct is not part of the region of the encountering thread unless it is \n an included task region.The point where a target or teams directive is \n encountered is a part of the region of the encountering thread, but the region that \n corresponds to the target or teams directive is not.\n COMMENTS: \n A region may also be thought of as the dynamic or runtime extent of a \n construct or of an OpenMP library routine.\n During the execution of an OpenMP program, a construct may give rise \n to many regions."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n During the execution of an OpenMP program, a construct may give rise \n to many regions.\n active parallel region A parallel region that is executed by a team consisting of more than one thread.\n inactive parallel region A parallel region that is executed by a team of only one thread.\n active target region A target region that is executed on a device other than the device that encountered \n the target construct.\n inactive target region A target region that is executed on the same device that encountered the target \n construct.\n sequential part All code encountered during the execution of an initial task region that is not part of \n a parallel region corresponding to a parallel construct or a task region \n corresponding to a task construct.\n COMMENTS: \n A sequential part is enclosed by an implicit parallel region."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n COMMENTS: \n A sequential part is enclosed by an implicit parallel region.\n Executable statements in called routines may be in both a sequential part \n and any number of explicit parallel regions at different points in the \n program execution.\n primary thread An OpenMP thread that has thread number 0.A primary thread may be an initial \n thread or the thread that encounters a parallel construct, creates a team, \n generates a set of implicit tasks, and then executes one of those tasks as thread \n number 0.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 5 \n worker thread An OpenMP thread that is not the primary thread of a team and that executes one of \n the implicit tasks of a parallel region.\n parent thread The thread that encountered the parallel construct and generated a parallel \n region is the parent thread of each of the threads in the team of that parallel \n region."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n parent thread The thread that encountered the parallel construct and generated a parallel \n region is the parent thread of each of the threads in the team of that parallel \n region.The primary thread of a parallel region is the same thread as its parent \n thread with respect to any resources associated with an OpenMP thread.\n child thread When a thread encounters a parallel construct, each of the threads in the \n generated parallel region\u2019s team are child threads of the encountering thread.\n The target or teams region\u2019s initial thread is not a child thread of the thread that \n encountered the target or teams construct.\n ancestor thread For a given thread, its parent thread or one of its parent thread\u2019s ancestor threads.\n descendent thread For a given thread, one of its child threads or one of its child threads\u2019 descendent \n threads.\n team A set of one or more threads participating in the execution of a parallel region."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n team A set of one or more threads participating in the execution of a parallel region.\n COMMENTS: \n For an active parallel region, the team comprises the primary thread and \n at least one additional thread.\n For an inactive parallel region, the team comprises only the primary \n thread.\n league The set of teams created by a teams construct.\n contention group An initial thread and its descendent threads.\n implicit parallel region An inactive parallel region that is not generated from a parallel construct.\n Implicit parallel regions surround the whole OpenMP program, all target regions, \n and all teams regions.\n initial thread The thread that executes an implicit parallel region.\n initial team The team that comprises an initial thread executing an implicit parallel region.\n nested construct A construct (lexically) enclosed by another construct."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n nested construct A construct (lexically) enclosed by another construct.\n closely nested construct A construct nested inside another construct with no other construct nested between \n them.\n explicit region A region that corresponds to either a construct of the same name or a library routine \n call that explicitly appears in the program.\n nested region A region (dynamically) enclosed by another region.That is, a region generated from \n the execution of another region or one of its nested regions.\n OpenMP API \u2013 Version 5.2 November 2021 \n COMMENT: Some nestings are conforming and some are not.See \n Section 17.1 for the restrictions on nesting.\n closely nested region A region nested inside another region with no parallel region nested between \n them.\n strictly nested region A region nested inside another region with no other explicit region nested between \n them.\n all threads All OpenMP threads participating in the OpenMP program."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n all threads All OpenMP threads participating in the OpenMP program.\n current team All threads in the team executing the innermost enclosing parallel region.\n encountering thread For a given region, the thread that encounters the corresponding construct.\n all tasks All tasks participating in the OpenMP program.\n current team tasks All tasks encountered by the corresponding team.The implicit tasks constituting the \n parallel region and any descendent tasks encountered during the execution of \n these implicit tasks are included in this set of tasks.\n generating task For a given region, the task for which execution by a thread generated the region.\n binding thread set The set of threads that are affected by, or provide the context for, the execution of a \n region."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n binding thread set The set of threads that are affected by, or provide the context for, the execution of a \n region.\n The binding thread set for a given region can be all threads on a specified set of \n devices, all threads in a contention group, all primary threads executing an enclosing \n teams region, the current team, or the encountering thread.\n COMMENT: The binding thread set for a particular region is described in \n its corresponding subsection of this specification.\n binding task set The set of tasks that are affected by, or provide the context for, the execution of a \n region.\n The binding task set for a given region can be all tasks, the current team tasks, all \n tasks of the current team that are generated in the region, the binding implicit task, or \n the generating task.\n COMMENT: The binding task set for a particular region (if applicable) is \n described in its corresponding subsection of this specification."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n COMMENT: The binding task set for a particular region (if applicable) is \n described in its corresponding subsection of this specification.\n binding region The enclosing region that determines the execution context and limits the scope of \n the effects of the bound region is called the binding region.\n Binding region is not defined for regions for which the binding thread set is all \n threads or the encountering thread, nor is it defined for regions for which the binding \n task set is all tasks.\n orphaned construct A construct that gives rise to a region for which the binding thread set is the current \n team, but is not nested within another construct that gives rise to the binding region.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 7 \nwork-distribution \nconstruct \n A construct that is cooperatively executed by threads in the binding thread set of the \n corresponding region."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "OVERVIEW OF THE OPENMP API 7 \nwork-distribution \nconstruct \n A construct that is cooperatively executed by threads in the binding thread set of the \n corresponding region.\n worksharing construct A work-distribution construct that is executed by the thread team of the innermost \n enclosing parallel region and includes, by default, an implicit barrier.\n device construct An OpenMP construct that accepts the device clause.\n cancellable construct An OpenMP construct that can be cancelled.\n device routine A function (for C/C++ and Fortran) or subroutine (for Fortran) that can be executed \n on a target device, as part of a target region.\n target variant A version of a device routine that can only be executed as part of a target region.\nforeign runtime \nenvironment \n A runtime environment that exists outside the OpenMP runtime with which the \n OpenMP implementation may interoperate."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\nforeign runtime \nenvironment \n A runtime environment that exists outside the OpenMP runtime with which the \n OpenMP implementation may interoperate.\nforeign execution \ncontext \n A context that is instantiated from a foreign runtime environment in order to facilitate \n execution on a given device.\n foreign task A unit of work executed in a foreign execution context.\nindirect device \ninvocation \n An indirect call to the device version of a procedure on a device other than the host \n device, through a function pointer (C/C++), a pointer to a member function (C++) or \n a procedure pointer (Fortran) that refers to the host version of the procedure.\n place An unordered set of processors on a device.\n place list The ordered list that describes all OpenMP places available to the execution \n environment.\n place partition An ordered list that corresponds to a contiguous interval in the OpenMP place list."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n place partition An ordered list that corresponds to a contiguous interval in the OpenMP place list.It \n describes the places currently available to the execution environment for a given \n parallel region.\n place number A number that uniquely identifies a place in the place list, with zero identifying the \n first place in the place list, and each consecutive whole number identifying the next \n place in the place list.\n thread affinity A binding of threads to places within the current place partition.\n SIMD instruction A single machine instruction that can operate on multiple data elements.\n SIMD lane A software or hardware mechanism capable of processing one data element from a \n SIMD instruction.\n SIMD chunk A set of iterations executed concurrently, each by a SIMD lane, by a single thread by \n means of SIMD instructions.\n memory A storage resource to store and to retrieve variables accessible by OpenMP threads."}
{"section_title": "1.2.2 OpenMP Language Terminology", "chunk": "\n memory A storage resource to store and to retrieve variables accessible by OpenMP threads.\n OpenMP API \u2013 Version 5.2 November 2021 \n memory space A representation of storage resources from which memory can be allocated or \n deallocated.More than one memory space may exist.\n memory allocator An OpenMP object that fulfills requests to allocate and to deallocate memory for \n program variables from the storage resources of its associated memory space.\n handle An opaque reference that uniquely identifies an abstraction.\n"}
{"section_title": "1.2.3 Loop Terminology", "chunk": "7 canonical loop nest A loop nest that complies with the rules and restrictions defined in Section 4.4.1.\nloop-associated \ndirective \n An OpenMP executable directive for which the associated user code must be a \n canonical loop nest.\n associated loop A loop from a canonical loop nest that is controlled by a given loop-associated \n directive.\n loop nest depth For a canonical loop nest, the maximal number of loops, including the outermost \n loop, that can be associated with a loop-associated directive.\n logical iteration space For a loop-associated directive, the sequence 0,...,N \u2212 1 where N is the number of \n iterations of the loops associated with the directive.The logical numbering denotes \n the sequence in which the iterations would be executed if the set of associated loops \n were executed sequentially."}
{"section_title": "1.2.3 Loop Terminology", "chunk": "The logical numbering denotes \n the sequence in which the iterations would be executed if the set of associated loops \n were executed sequentially.\n logical iteration An iteration from the associated loops of a loop-associated directive, designated by a \n logical number from the logical iteration space of the associated loops.\nlogical iteration vector \nspace \n For a loop-associated directive with n associated nested loops, the set of n-tuples \n(i1, ..., in).For the k \nth 21 associated loop, from outermost to innermost, ik is its \n logical iteration number as if it was the only associated loop.\n logical iteration vector An iteration from the associated nested loops of a loop-associated directive, where n \n is the number of associated loops, designated by an n-tuple from the logical iteration \n vector space of the associated loops.\n lexicographic order The total order of two logical iteration vectors \u03c9a = (i1, ..., in) and \n \u03c9b = (j1, ..."}
{"section_title": "1.2.3 Loop Terminology", "chunk": "., jn), denoted by \u03c9a \u2264lex \u03c9b, where either \u03c9a = \u03c9b or \n \u2203m \u2208 {1, ..., n} such that im < jm and ik = jk for all k \u2208 {1, ..., m \u2212 1}.\n product order The partial order of two logical iteration vectors \u03c9a = (i1, ..., in) and \n \u03c9b = (j1, ..., jn), denoted by \u03c9a \u2264product \u03c9b, where ik \u2264 jk for all k \u2208 {1, ..., n}.\nloop transformation \nconstruct \n A construct that is replaced by the loops that result from applying the transformation \n as defined by its directive to its associated loops.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 9 \n generated loop A loop that is generated by a loop transformation construct and is one of the \n resulting loops that replace the construct.\n SIMD loop A loop that includes at least one SIMD chunk.\n non-rectangular loop For a loop nest, a loop for which a loop bound references the iteration variable of a \n surrounding loop in the loop nest.\n perfectly nested loop A loop that has no intervening code between it and the body of its surrounding loop."}
{"section_title": "1.2.3 Loop Terminology", "chunk": "\n perfectly nested loop A loop that has no intervening code between it and the body of its surrounding loop.\n The outermost loop of a loop nest is always perfectly nested.\n doacross loop nest A loop nest, consisting of loops that may be associated with the same \n loop-associated directive, that has cross-iteration dependences.An iteration is \n dependent on one or more lexicographically earlier iterations.\n COMMENT: The ordered clause parameter on a worksharing-loop \n directive identifies the loops associated with the doacross loop nest.\n"}
{"section_title": "1.2.4 Synchronization Terminology", "chunk": "14 barrier A point in the execution of a program encountered by a team of threads, beyond \n which no thread in the team may execute until all threads in the team have reached \n the barrier and all explicit tasks generated by the team have executed to completion.\n If cancellation has been requested, threads may proceed to the end of the canceled \n region even if some threads in the team have not reached the barrier.\n cancellation An action that cancels (that is, aborts) an OpenMP region and causes executing \n implicit or explicit tasks to proceed to the end of the canceled region.\n cancellation point A point at which implicit and explicit tasks check if cancellation has been requested.\n If cancellation has been observed, they perform the cancellation.\n flush An operation that a thread performs to enforce consistency between its view and \n other threads\u2019 view of memory.\n device-set The set of devices for which a flush operation may enforce memory consistency."}
{"section_title": "1.2.4 Synchronization Terminology", "chunk": "\n device-set The set of devices for which a flush operation may enforce memory consistency.\n flush property A property that determines the manner in which a flush operation enforces memory \n consistency.The defined flush properties are: \n \u2022 strong: flushes a set of variables from the current thread\u2019s temporary view of the \n memory to the memory; \n \u2022 release: orders memory operations that precede the flush before memory \n operations performed by a different thread with which it synchronizes; \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 acquire: orders memory operations that follow the flush after memory operations \n performed by a different thread that synchronizes with it.\n COMMENT: Any flush operation has one or more flush properties.\n strong flush A flush operation that has the strong flush property.\n release flush A flush operation that has the release flush property.\n acquire flush A flush operation that has the acquire flush property."}
{"section_title": "1.2.4 Synchronization Terminology", "chunk": "\n acquire flush A flush operation that has the acquire flush property.\n atomic operation An operation that is specified by an atomic construct or is implicitly performed by \n the OpenMP implementation and that atomically accesses and/or modifies a specific \n storage location.\n atomic read An atomic operation that is specified by an atomic construct on which the read \n clause is present.\n atomic write An atomic operation that is specified by an atomic construct on which the write \n clause is present.\n atomic update An atomic operation that is specified by an atomic construct on which the \n update clause is present.\natomic captured \nupdate \n An atomic update operation that is specified by an atomic construct on which the \n capture clause is present.\natomic conditional \nupdate \n An atomic update operation that is specified by an atomic construct on which the \n compare clause is present."}
{"section_title": "1.2.4 Synchronization Terminology", "chunk": "\natomic conditional \nupdate \n An atomic update operation that is specified by an atomic construct on which the \n compare clause is present.\n read-modify-write An atomic operation that reads and writes to a given storage location.\n COMMENT: Any atomic update is a read-modify-write operation.\nsequentially consistent \natomic construct \n An atomic construct for which the seq_cst clause is specified.\nnon-sequentially \nconsistent atomic \nconstruct \n An atomic construct for which the seq_cst clause is not specified \nsequentially consistent \natomic operation \n An atomic operation that is specified by a sequentially consistent atomic construct.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 11 \n"}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "2 task A specific instance of executable code and its data environment that the OpenMP \n implementation can schedule for execution by threads.\n task region A region consisting of all code encountered during the execution of a task.\n implicit task A task generated by an implicit parallel region or generated when a parallel \n construct is encountered during execution.\n binding implicit task The implicit task of the current thread team assigned to the encountering thread.\n explicit task A task that is not an implicit task.\n initial task An implicit task associated with an implicit parallel region.\n current task For a given thread, the task corresponding to the task region in which it is executing.\n encountering task For a given region, the current task of the encountering thread.\n child task A task is a child task of its generating task region.A child task region is not part of \n its generating task region."}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "A child task region is not part of \n its generating task region.\n sibling tasks Tasks that are child tasks of the same task region.\n descendent task A task that is the child task of a task region or of one of its descendent task regions.\n task completion A condition that is satisfied when a thread reaches the end of the executable code that \n is associated with the task and any allow-completion event that is created for the task \n has been fulfilled.\n COMMENT: Completion of the initial task that is generated when the \n program begins occurs at program exit.\n task scheduling point A point during the execution of the current task region at which it can be suspended \n to be resumed later; or the point of task completion, after which the executing thread \n may switch to a different task region.\n task switching The act of a thread switching from the execution of one task to another task."}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "\n task switching The act of a thread switching from the execution of one task to another task.\n tied task A task that, when its task region is suspended, can be resumed only by the same \n thread that was executing it before suspension.That is, the task is tied to that thread.\n untied task A task that, when its task region is suspended, can be resumed by any thread in the \n team.That is, the task is not tied to any thread.\n undeferred task A task for which execution is not deferred with respect to its generating task region.\n That is, its generating task region is suspended until execution of the structured block \n associated with the undeferred task is completed.\n included task A task for which execution is sequentially included in the generating task region.\n That is, an included task is undeferred and executed by the encountering thread."}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "\n That is, an included task is undeferred and executed by the encountering thread.\n OpenMP API \u2013 Version 5.2 November 2021 \n merged task A task for which the data environment, inclusive of ICVs, is the same as that of its \n generating task region.\n mergeable task A task that may be a merged task if it is an undeferred task or an included task.\n final task A task that forces all of its child tasks to become final and included tasks.\n detachable task An explicit task that only completes after an associated event variable that represents \n an allow-completion event is fulfilled and execution of the associated structured \n block has completed.\n task dependence An ordering relation between two sibling tasks: the dependent task and a previously \n generated predecessor task.The task dependence is fulfilled when the predecessor \n task has completed.\n dependent task A task that because of a task dependence cannot be executed until its predecessor \n tasks have completed."}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "\n dependent task A task that because of a task dependence cannot be executed until its predecessor \n tasks have completed.\nmutually exclusive \ntasks \n Tasks that may be executed in any order, but not at the same time.\n predecessor task A task that must complete before its dependent tasks can be executed.\ntask synchronization \nconstruct \n A taskwait, taskgroup, or a barrier construct.\ntask generating \nconstruct \n A construct that generates one or more explicit tasks that are child tasks of the \n encountering task.\n target task A mergeable and untied task that is generated by a device construct or a call to a \n device memory routine and that coordinates activity between the current device and \n the target device."}
{"section_title": "1.2.5 Tasking Terminology", "chunk": "\n target task A mergeable and untied task that is generated by a device construct or a call to a \n device memory routine and that coordinates activity between the current device and \n the target device.\n taskgroup set A set of tasks that are logically grouped by a taskgroup region, such that a task is \n a member of the taskgroup set if and only if its task region is nested in the \n taskgroup region and it binds to the same parallel region as the taskgroup \n region.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 13 \n"}
{"section_title": "1.2.6 Data Terminology", "chunk": "2 variable A named data storage block, for which the value can be defined and redefined during \n the execution of a program.\n COMMENT: An array element or structure element is a variable that is \n part of another variable.\n scalar variable For C/C++, a scalar variable, as defined by the base language.\n For Fortran, a scalar variable with intrinsic type, as defined by the base language, \n excluding character type.\n aggregate variable A variable, such as an array or structure, composed of other variables.For Fortran, a \n variable of character type is considered an aggregate variable.\n array section A designated subset of the elements of an array that is specified using a subscript \n notation that can select more than one element.\n array item An array, an array section, or an array element.\n shape-operator For C/C++, an array shaping operator that reinterprets a pointer expression as an \n array with one or more specified dimensions."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n shape-operator For C/C++, an array shaping operator that reinterprets a pointer expression as an \n array with one or more specified dimensions.\n implicit array For C/C++, the set of array elements of non-array type T that may be accessed by \n applying a sequence of [] operators to a given pointer that is either a pointer to type T \n or a pointer to a multidimensional array of elements of type T.\n For Fortran, the set of array elements for a given array pointer.\n COMMENT: For C/C++, the implicit array for pointer p with type T \n (*)[10] consists of all accessible elements p[i][j], for all i and j=0,1,...,9.\n base pointer For C/C++, an lvalue pointer expression that is used by a given lvalue expression or \n array section to refer indirectly to its storage, where the lvalue expression or array \n section is part of the implicit array for that lvalue pointer expression."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n base pointer For C/C++, an lvalue pointer expression that is used by a given lvalue expression or \n array section to refer indirectly to its storage, where the lvalue expression or array \n section is part of the implicit array for that lvalue pointer expression.\n For Fortran, a data pointer that appears last in the designator for a given variable or \n array section, where the variable or array section is part of the pointer target for that \n data pointer.\n COMMENT: For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \n pointer type declaration and identifiers xi have an array type declaration, \n the base pointer is: (*p0).x0[k1].p1->p2.\n named pointer For C/C++, the base pointer of a given lvalue expression or array section, or the base \n pointer of one of its named pointers."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n named pointer For C/C++, the base pointer of a given lvalue expression or array section, or the base \n pointer of one of its named pointers.\n OpenMP API \u2013 Version 5.2 November 2021 \n For Fortran, the base pointer of a given variable or array section, or the base pointer \n of one of its named pointers.\n COMMENT: For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \n pointer type declaration and identifiers xi have an array type declaration, \n the named pointers are: p0, (*p0).x0[k1].p1, and (*p0).x0[k1].p1->p2.\n containing array For C/C++, a non-subscripted array (a containing array) to which a series of zero or \n more array subscript operators and/or .(dot) operators are applied to yield a given \n lvalue expression or array section for which storage is contained by the array."}
{"section_title": "1.2.6 Data Terminology", "chunk": "(dot) operators are applied to yield a given \n lvalue expression or array section for which storage is contained by the array.\n For Fortran, an array (a containing array) without the POINTER attribute and \n without a subscript list to which a series of zero or more array subscript operators \n and/or component selectors are applied to yield a given variable or array section for \n which storage is contained by the array.\n COMMENT: An array is a containing array of itself.For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \n pointer type declaration and identifiers xi have an array type declaration, \n the containing arrays are: (*p0).x0[k1].p1->p2[k2].x1 and \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2.\n containing structure For C/C++, a structure to which a series of zero or more ."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n containing structure For C/C++, a structure to which a series of zero or more .(dot) operators and/or \n array subscript operators are applied to yield a given lvalue expression or array \n section for which storage is contained by the structure.\n For Fortran, a structure to which a series of zero or more component selectors and/or \n array subscript selectors are applied to yield a given variable or array section for \n which storage is contained by the structure.\n COMMENT: A structure is a containing structure of itself.For C/C++, a \n structure pointer p to which the -> operator applies is equivalent to the \n application of a .(dot) operator to (*p) for the purposes of determining \n containing structures."}
{"section_title": "1.2.6 Data Terminology", "chunk": "(dot) operator to (*p) for the purposes of determining \n containing structures.\n For the array section (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where \n identifiers pi have a pointer type declaration and identifiers xi have an \n array type declaration, the containing structures are: *(*p0).x0[k1].p1, \n (*(*p0).x0[k1].p1).p2[k2] and (*(*p0).x0[k1].p1).p2[k2].x1[k3] \n base array For C/C++, a containing array of a given lvalue expression or array section that does \n not appear in the expression of any of its other containing arrays.\n For Fortran, a containing array of a given variable or array section that does not \n appear in the designator of any of its other containing arrays.\n COMMENT: For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \nCHAPTER 1.OVERVIEW OF THE OPENMP API 15 \n pointer type declaration and identifiers xi have an array type declaration, \n the base array is: (*p0).x0[k1].p1->p2[k2].x1[k3].x2."}
{"section_title": "1.2.6 Data Terminology", "chunk": "OVERVIEW OF THE OPENMP API 15 \n pointer type declaration and identifiers xi have an array type declaration, \n the base array is: (*p0).x0[k1].p1->p2[k2].x1[k3].x2.\n named array For C/C++, a containing array of a given lvalue expression or array section, or a \n containing array of one of its named pointers.\n For Fortran, a containing array of a given variable or array section, or a containing \n array of one of its named pointers.\n COMMENT: For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \n pointer type declaration and identifiers xi have an array type declaration, \n the named arrays are: (*p0).x0, (*p0).x0[k1].p1->p2[k2].x1, and \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2.\n base expression The base array of a given array section or array element, if it exists; otherwise, the \n base pointer of the array section or array element."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n base expression The base array of a given array section or array element, if it exists; otherwise, the \n base pointer of the array section or array element.\n COMMENT: For the array section \n (*p0).x0[k1].p1->p2[k2].x1[k3].x2[4][0:n], where identifiers pi have a \n pointer type declaration and identifiers xi have an array type declaration, \n the base expression is: (*p0).x0[k1].p1->p2[k2].x1[k3].x2.\n More examples for C/C++: \n \u2022 The base expression for x[i] and for x[i:n] is x, if x is an array or pointer.\n \u2022 The base expression for x[5][i] and for x[5][i:n] is x, if x is a pointer to \n an array or x is 2-dimensional array.\n \u2022 The base expression for y[5][i] and for y[5][i:n] is y[5], if y is an array \n of pointers or y is a pointer to a pointer.\n Examples for Fortran: \n \u2022 The base expression for x(i) and for x(i:j) is x."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n Examples for Fortran: \n \u2022 The base expression for x(i) and for x(i:j) is x.\n base variable For a given data entity that is a variable or array section, a variable denoted by a base \n language identifier that is either the data entity or is a containing array or containing \n structure of the data entity.\n COMMENT: \n Examples for C/C++: \n \u2022 The data entities x, x[i], x[:n], x[i].y[j] and x[i].y[:n], where x and y \n have array type declarations, all have the base variable x.\n \u2022 The lvalue expressions and array sections p[i], p[:n], p[i].y[j] and \n p[i].y[:n], where p has a pointer type and p[i].y has an array type, has a \n base pointer p but does not have a base variable.\n OpenMP API \u2013 Version 5.2 November 2021 \n Examples for Fortran: \n \u2022 The data objects x, x(i), x(:n), x(i)%y(j) and x(i)%y(:n), where x and y \n have array type declarations, all have the base variable x."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Examples for Fortran: \n \u2022 The data objects x, x(i), x(:n), x(i)%y(j) and x(i)%y(:n), where x and y \n have array type declarations, all have the base variable x.\n \u2022 The data objects p(i), p(:n), p(i)%y(j) and p(i)%y(:n), where p has a \n pointer type and p(i)%y has an array type, has a base pointer p but does \n not have a base variable.\n \u2022 For the associated pointer p, p is both its base variable and base pointer.\n attached pointer A pointer variable in a device data environment to which the effect of a map clause \n assigns the address of an object, minus some offset, that is created in the device data \n environment.The pointer is an attached pointer for the remainder of its lifetime in \n the device data environment.\nsimply contiguous \narray section \n An array section that statically can be determined to have contiguous storage or that, \n in Fortran, has the CONTIGUOUS attribute."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\nsimply contiguous \narray section \n An array section that statically can be determined to have contiguous storage or that, \n in Fortran, has the CONTIGUOUS attribute.\n structure A structure is a variable that contains one or more variables.\n For C/C++: Implemented using struct types.\n For C++: Implemented using class types.\n For Fortran: Implemented using derived types.\n string literal For C/C++, a string literal.\n For Fortran, a character literal constant.\n private variable With respect to a given set of task regions or SIMD lanes that bind to the same \n parallel region, a variable for which the name provides access to a different \n block of storage for each task region or SIMD lane.\n A variable that is part of another variable (as an array element or a structure element) \n cannot be made private independently of other components.If a variable is \n privatized, its components are also private."}
{"section_title": "1.2.6 Data Terminology", "chunk": "If a variable is \n privatized, its components are also private.\n shared variable With respect to a given set of task regions that bind to the same parallel region, a \n variable for which the name provides access to the same block of storage for each \n task region.\n A variable that is part of another variable (as an array element or a structure element) \n cannot be shared independently of the other components, except for static data \n members of C++ classes.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 17 \n threadprivate variable A variable that is replicated, one instance per thread, by the OpenMP \n implementation.Its name then provides access to a different block of storage for each \n thread.\n A variable that is part of another variable (as an array element or a structure element) \n cannot be made threadprivate independently of the other components, except for \n static data members of C++ classes."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n A variable that is part of another variable (as an array element or a structure element) \n cannot be made threadprivate independently of the other components, except for \n static data members of C++ classes.If a variable is made threadprivate, its \n components are also threadprivate.\n threadprivate memory The set of threadprivate variables associated with each thread.\n data environment The variables associated with the execution of a given region.\ndevice data \nenvironment \n The initial data environment associated with a device.\n device address An address of an object that may be referenced on a target device.\n device pointer An implementation-defined handle that refers to a device address.\n mapped variable An original variable in a data environment with a corresponding variable in a device \n data environment.\n COMMENT: The original and corresponding variables may share storage."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n COMMENT: The original and corresponding variables may share storage.\n mapping operation An operation that establishes or removes a correspondence between a variable in one \n data environment and another variable in a device data environment.\n mapper An operation that defines how variables of given type are to be mapped or updated \n with respect to a device data environment.\n user-defined mapper A mapper that is defined by a declare mapper directive.\n map-type decay The process that determines the final map types of the map operations that result \n from mapping a variable with a user-defined mapper.\n mappable type A type that is valid for a mapped variable.If a type is composed from other types \n (such as the type of an array element or a structure element) and any of the other \n types are not mappable then the type is not mappable.\n COMMENT: Pointer types are mappable but the memory block to which \n the pointer refers is not mapped."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n COMMENT: Pointer types are mappable but the memory block to which \n the pointer refers is not mapped.\n For C, the type must be a complete type.\n For C++, the type must be a complete type.\n In addition, for class types: \n \u2022 All member functions accessed in any target region must appear in a declare \n target directive.\n OpenMP API \u2013 Version 5.2 November 2021 \n For Fortran, no restrictions on the type except that for derived types: \n \u2022 All type-bound procedures accessed in any target region must appear in a \n declare target directive.\n defined For variables, the property of having a valid value.\n For C, for the contents of variables, the property of having a valid value.\n For C++, for the contents of variables of POD (plain old data) type, the property of \n having a valid value.\n For variables of non-POD class type, the property of having been constructed but not \n subsequently destructed."}
{"section_title": "1.2.6 Data Terminology", "chunk": "\n For variables of non-POD class type, the property of having been constructed but not \n subsequently destructed.\n For Fortran, for the contents of variables, the property of having a valid value.For \n the allocation or association status of variables, the property of having a valid status.\n COMMENT: Programs that rely upon variables that are not defined are \n non-conforming programs.\n class type For C++, variables declared with one of the class, struct, or union keywords.\n static storage duration For C/C++, the lifetime of an object with static storage duration, as defined by the \n base language.\n For Fortran, the lifetime of a variable with a SAVE attribute, implicit or explicit, a \n common block object or a variable declared in a module.\n NULL A null pointer.For C, the value NULL.For C++, the value NULL or the value \n nullptr.For Fortran, the value C_NULL_PTR.\n non-null value A value that is not NULL.\n non-null pointer A pointer that is not NULL.\n"}
{"section_title": "1.2.7 Implementation Terminology", "chunk": "supported active levels \nof parallelism \n An implementation-defined maximum number of active parallel regions that may \n enclose any region of code in the program.\n OpenMP API support Support of at least one active level of parallelism.\nnested parallelism \nsupport \n Support of more than one active level of parallelism.\ninternal control \nvariable \n A conceptual variable that specifies runtime behavior of a set of threads or tasks in \n an OpenMP program.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 19 \n COMMENT: The acronym ICV is used interchangeably with the term \n internal control variable throughout this specification.\nOpenMP Additional \nDefinitions document \n A document that exists outside of the OpenMP specification and defines additional \n values that may be used in a conforming program.The OpenMP Additional \n Definitions document is available at http://www.openmp.org/."}
{"section_title": "1.2.7 Implementation Terminology", "chunk": "The OpenMP Additional \n Definitions document is available at http://www.openmp.org/.\ncompliant \nimplementation \n An implementation of the OpenMP specification that compiles and executes any \n conforming program as defined by the specification.\n COMMENT: A compliant implementation may exhibit unspecified \n behavior when compiling or executing a non-conforming program.\n unspecified behavior A behavior or result that is not specified by the OpenMP specification or not known \n prior to the compilation or execution of an OpenMP program.\n Such unspecified behavior may result from: \n \u2022 Issues documented by the OpenMP specification as having unspecified behavior.\n \u2022 A non-conforming program.\n \u2022 A conforming program exhibiting an implementation-defined behavior.\n implementation defined Behavior that must be documented by the implementation, and is allowed to vary \n among different compliant implementations."}
{"section_title": "1.2.7 Implementation Terminology", "chunk": "\n implementation defined Behavior that must be documented by the implementation, and is allowed to vary \n among different compliant implementations.An implementation is allowed to define \n this behavior as unspecified.\n COMMENT: All features that have implementation-defined behavior are \n documented in Appendix A.\n deprecated For a construct, clause, or other feature, the property that it is normative in the \n current specification but is considered obsolescent and will be removed in the future.\n Deprecated features may not be fully specified.In general, a deprecated feature was \n fully specified in the version of the specification immediately prior to the one in \n which it is deprecated.In most cases, a new feature replaces the deprecated feature.\n Unless otherwise specified, whether any modifications provided by the replacement \n feature apply to the deprecated feature is implementation defined.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "1.2.8 Tool Terminology", "chunk": "2 tool Code that can observe and/or modify the execution of an application.\n first-party tool A tool that executes in the address space of the program that it is monitoring.\n third-party tool A tool that executes as a separate process from the process that it is monitoring and \n potentially controlling.\n activated tool A first-party tool that successfully completed its initialization.\n event A point of interest in the execution of a thread.\n native thread A thread defined by an underlying thread implementation.\n tool callback A function that a tool provides to an OpenMP implementation to invoke when an \n associated event occurs.\n registering a callback Providing a tool callback to an OpenMP implementation.\ndispatching a callback \nat an event \n Processing a callback when an associated event occurs in a manner consistent with \n the return code provided when a first-party tool registered the callback."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "\ndispatching a callback \nat an event \n Processing a callback when an associated event occurs in a manner consistent with \n the return code provided when a first-party tool registered the callback.\n thread state An enumeration type that describes the current OpenMP activity of a thread.A \n thread can be in only one state at any time.\n wait identifier A unique opaque handle associated with each data object (for example, a lock) that \n the OpenMP runtime uses to enforce mutual exclusion and potentially to cause a \n thread to wait actively or passively.\n frame A storage area on a thread\u2019s stack associated with a procedure invocation.A frame \n includes space for one or more saved registers and often also includes space for saved \n arguments, local variables, and padding for alignment."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "A frame \n includes space for one or more saved registers and often also includes space for saved \n arguments, local variables, and padding for alignment.\ncanonical frame \naddress \n An address associated with a procedure frame on a call stack that was the value of the \n stack pointer immediately prior to calling the procedure for which the frame \n represents the invocation.\n runtime entry point A function interface provided by an OpenMP runtime for use by a tool.A runtime \n entry point is typically not associated with a global function symbol.\n trace record A data structure in which to store information associated with an occurrence of an \n event.\n native trace record A trace record for an OpenMP device that is in a device-specific format.\n signal A software interrupt delivered to a thread.\n signal handler A function called asynchronously when a signal is delivered to a thread.\nCHAPTER 1."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "\nCHAPTER 1.OVERVIEW OF THE OPENMP API 21 \n async signal safe The guarantee that interruption by signal delivery will not interfere with a set of \n operations.An async signal safe runtime entry point is safe to call from a signal \n handler.\n code block A contiguous region of memory that contains code of an OpenMP program to be \n executed on a device.\n OMPT An interface that helps a first-party tool monitor the execution of an OpenMP \n program.\n OMPT interface state A state that indicates the permitted interactions between a first-party tool and the \n OpenMP implementation.\n OMPT active An OMPT interface state in which the OpenMP implementation is prepared to accept \n runtime calls from a first-party tool and will dispatch any registered callbacks and in \n which a first-party tool can invoke runtime entry points if not otherwise restricted."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "\n OMPT active An OMPT interface state in which the OpenMP implementation is prepared to accept \n runtime calls from a first-party tool and will dispatch any registered callbacks and in \n which a first-party tool can invoke runtime entry points if not otherwise restricted.\n OMPT pending An OMPT interface state in which the OpenMP implementation can only call \n functions to initialize a first-party tool and in which a first-party tool cannot invoke \n runtime entry points.\n OMPT inactive An OMPT interface state in which the OpenMP implementation will not make any \n callbacks and in which a first-party tool cannot invoke runtime entry points.\n OMPD An interface that helps a third-party tool inspect the OpenMP state of a program that \n has begun execution.\n OMPD library A dynamically loadable library that implements the OMPD interface.\n image file An executable or shared library."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "\n image file An executable or shared library.\n address space A collection of logical, virtual, or physical memory address ranges that contain code, \n stack, and/or data.Address ranges within an address space need not be contiguous.\n An address space consists of one or more segments.\n segment A portion of an address space associated with a set of address ranges.\n OpenMP architecture The architecture on which an OpenMP region executes.\n tool architecture The architecture on which an OMPD tool executes.\n OpenMP process A collection of one or more threads and address spaces.A process may contain \n threads and address spaces for multiple OpenMP architectures.At least one thread \n in an OpenMP process is an OpenMP thread.A process may be live or a core file.\n address space handle A handle that refers to an address space within an OpenMP process.\n thread handle A handle that refers to an OpenMP thread."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "\n thread handle A handle that refers to an OpenMP thread.\n parallel handle A handle that refers to an OpenMP parallel region.\n OpenMP API \u2013 Version 5.2 November 2021 \n task handle A handle that refers to an OpenMP task region.\n descendent handle An output handle that is returned from the OMPD library in a function that accepts \n an input handle: the output handle is a descendent of the input handle.\n ancestor handle An input handle that is passed to the OMPD library in a function that returns an \n output handle: the input handle is an ancestor of the output handle.For a given \n handle, the ancestors of the handle are also the ancestors of the handle\u2019s descendent.\n COMMENT: A tool cannot use a handle in an OMPD call if any ancestor \n of the handle has been released, except for OMPD calls that release it.\n tool context An opaque reference provided by a tool to an OMPD library.A tool context uniquely \n identifies an abstraction."}
{"section_title": "1.2.8 Tool Terminology", "chunk": "A tool context uniquely \n identifies an abstraction.\n address space context A tool context that refers to an address space within a process.\n thread context A tool context that refers to a native thread.\n native thread identifier An identifier for a native thread defined by a thread implementation.\n"}
{"section_title": "1.3 Execution Model", "chunk": "15 The OpenMP API uses the fork-join model of parallel execution.Multiple threads of execution \n perform tasks defined implicitly or explicitly by OpenMP directives.The OpenMP API is intended \n to support programs that will execute correctly both as parallel programs (multiple threads of \n execution and a full OpenMP support library) and as sequential programs (directives ignored and a \n simple OpenMP stubs library).However, a conforming OpenMP program may execute correctly as \n a parallel program but not as a sequential program, or may produce different results when executed \n as a parallel program compared to when it is executed as a sequential program.Further, using \n different numbers of threads may result in different numeric results because of changes in the \n association of numeric operations.For example, a serial addition reduction may have a different \n pattern of addition associations than a parallel reduction."}
{"section_title": "1.3 Execution Model", "chunk": "For example, a serial addition reduction may have a different \n pattern of addition associations than a parallel reduction.These different associations may change \n the results of floating-point addition.\n An OpenMP program begins as a single thread of execution, called an initial thread.An initial \n thread executes sequentially, as if the code encountered is part of an implicit task region, called an \n initial task region, that is generated by the implicit parallel region surrounding the whole program.\n The thread that executes the implicit parallel region that surrounds the whole program executes on \n the host device.An implementation may support other devices besides the host device.If \n supported, these devices are available to the host device for offloading code and data.Each device \n has its own threads that are distinct from threads that execute on another device.Threads cannot \n migrate from one device to another device."}
{"section_title": "1.3 Execution Model", "chunk": "Threads cannot \n migrate from one device to another device.Each device is identified by a device number.The \n device number for the host device is the value of the total number of non-host devices, while each \nCHAPTER 1.OVERVIEW OF THE OPENMP API 23 \n non-host device has a unique device number that is greater than or equal to zero and less than the \n device number for the host device.Additionally, the constant omp_initial_device can be \n used as an alias for the host device and the constant omp_invalid_device can be used to \n specify an invalid device number.A conforming device number is either a non-negative integer that \n is less than or equal to omp_get_num_devices() or equal to omp_initial_device or \n omp_invalid_device.\n When a target construct is encountered, a new target task is generated.The target task region \n encloses the target region.The target task is complete after the execution of the target region \n is complete."}
{"section_title": "1.3 Execution Model", "chunk": "The target task is complete after the execution of the target region \n is complete.\n When a target task executes, the enclosed target region is executed by an initial thread.The \n initial thread executes sequentially, as if the target region is part of an initial task region that is \n generated by an implicit parallel region.The initial thread may execute on the requested target \n device, if it is available and supported.If the target device does not exist or the implementation \n does not support it, all target regions associated with that device execute on the host device.\n The implementation must ensure that the target region executes as if it were executed in the data \n environment of the target device unless an if clause is present and the if clause expression \n evaluates to false.\n The teams construct creates a league of teams, where each team is an initial team that comprises \n an initial thread that executes the teams region."}
{"section_title": "1.3 Execution Model", "chunk": "\n The teams construct creates a league of teams, where each team is an initial team that comprises \n an initial thread that executes the teams region.Each initial thread executes sequentially, as if the \n code encountered is part of an initial task region that is generated by an implicit parallel region \n associated with each team.Whether the initial threads concurrently execute the teams region is \n unspecified, and a program that relies on their concurrent execution for the purposes of \n synchronization may deadlock.\n If a construct creates a data environment, the data environment is created at the time the construct is \n encountered.The description of a construct defines whether it creates a data environment.\n When any thread encounters a parallel construct, the thread creates a team of itself and zero or \n more additional threads and becomes the primary thread of the new team.A set of implicit tasks, \n one per thread, is generated."}
{"section_title": "1.3 Execution Model", "chunk": "A set of implicit tasks, \n one per thread, is generated.The code for each task is defined by the code inside the parallel \n construct.Each task is assigned to a different thread in the team and becomes tied; that is, it is \n always executed by the thread to which it is initially assigned.The task region of the task being \n executed by the encountering thread is suspended, and each member of the new team executes its \n implicit task.An implicit barrier occurs at the end of the parallel region.Only the primary \n thread resumes execution beyond the end of the parallel construct, resuming the task region \n that was suspended upon encountering the parallel construct.Any number of parallel \n constructs can be specified in a single program.\n parallel regions may be arbitrarily nested inside each other."}
{"section_title": "1.3 Execution Model", "chunk": "\n parallel regions may be arbitrarily nested inside each other.If nested parallelism is disabled, or \n is not supported by the OpenMP implementation, then the new team that is created by a thread that \n encounters a parallel construct inside a parallel region will consist only of the \n encountering thread.However, if nested parallelism is supported and enabled, then the new team \n OpenMP API \u2013 Version 5.2 November 2021 \n can consist of more than one thread.A parallel construct may include a proc_bind clause to \n specify the places to use for the threads in the team within the parallel region.\n When any team encounters a worksharing construct, the work inside the construct is divided among \n the members of the team, and executed cooperatively instead of being executed by every thread.An \n implicit barrier occurs at the end of any region that corresponds to a worksharing construct for \n which the nowait clause is not specified."}
{"section_title": "1.3 Execution Model", "chunk": "An \n implicit barrier occurs at the end of any region that corresponds to a worksharing construct for \n which the nowait clause is not specified.Redundant execution of code by every thread in the \n team resumes after the end of the worksharing construct.\n When any thread encounters a task generating construct, one or more explicit tasks are generated.\n Execution of explicitly generated tasks is assigned to one of the threads in the current team, subject \n to the thread\u2019s availability to execute work.Thus, execution of the new task could be immediate, or \n deferred until later according to task scheduling constraints and thread availability.Threads are \n allowed to suspend the current task region at a task scheduling point in order to execute a different \n task.If the suspended task region is for a tied task, the initially assigned thread later resumes \n execution of the suspended task region."}
{"section_title": "1.3 Execution Model", "chunk": "If the suspended task region is for a tied task, the initially assigned thread later resumes \n execution of the suspended task region.If the suspended task region is for an untied task, then any \n thread may resume its execution.Completion of all explicit tasks bound to a given parallel region is \n guaranteed before the primary thread leaves the implicit barrier at the end of the region.\n Completion of a subset of all explicit tasks bound to a given parallel region may be specified \n through the use of task synchronization constructs.Completion of all explicit tasks bound to the \n implicit parallel region is guaranteed by the time the program exits.\n When any thread encounters a simd construct, the iterations of the loop associated with the \n construct may be executed concurrently using the SIMD lanes that are available to the thread."}
{"section_title": "1.3 Execution Model", "chunk": "\n When any thread encounters a simd construct, the iterations of the loop associated with the \n construct may be executed concurrently using the SIMD lanes that are available to the thread.\n When a loop construct is encountered, the iterations of the loop associated with the construct are \n executed in the context of its encountering threads, as determined according to its binding region.If \n the loop region binds to a teams region, the region is encountered by the set of primary threads \n that execute the teams region.If the loop region binds to a parallel region, the region is \n encountered by the team of threads that execute the parallel region.Otherwise, the region is \n encountered by a single thread.\n If the loop region binds to a teams region, the encountering threads may continue execution \n after the loop region without waiting for all iterations to complete; the iterations are guaranteed to \n complete before the end of the teams region."}
{"section_title": "1.3 Execution Model", "chunk": "\n If the loop region binds to a teams region, the encountering threads may continue execution \n after the loop region without waiting for all iterations to complete; the iterations are guaranteed to \n complete before the end of the teams region.Otherwise, all iterations must complete before the \n encountering threads continue execution after the loop region.All threads that encounter the \n loop construct may participate in the execution of the iterations.Only one of these threads may \n execute any given iteration.\n The cancel construct can alter the previously described flow of execution in an OpenMP region.\n The effect of the cancel construct depends on its construct-type-clause.If a task encounters a \n cancel construct with a taskgroup construct-type-clause, then the task activates cancellation \n and continues execution at the end of its task region, which implies completion of that task."}
{"section_title": "1.3 Execution Model", "chunk": "If a task encounters a \n cancel construct with a taskgroup construct-type-clause, then the task activates cancellation \n and continues execution at the end of its task region, which implies completion of that task.Any \n other task in that taskgroup that has begun executing completes execution unless it encounters a \n cancellation point construct, in which case it continues execution at the end of its task \n region, which implies its completion.Other tasks in that taskgroup region that have not begun \nCHAPTER 1.OVERVIEW OF THE OPENMP API 25 \n execution are aborted, which implies their completion.\n For all other construct-type-clause values, if a thread encounters a cancel construct, it activates \n cancellation of the innermost enclosing region of the type specified and the thread continues \n execution at the end of that region."}
{"section_title": "1.3 Execution Model", "chunk": "\n For all other construct-type-clause values, if a thread encounters a cancel construct, it activates \n cancellation of the innermost enclosing region of the type specified and the thread continues \n execution at the end of that region.Threads check if cancellation has been activated for their region \n at cancellation points and, if so, also resume execution at the end of the canceled region.\n If cancellation has been activated, regardless of construct-type-clause, threads that are waiting \n inside a barrier other than an implicit barrier at the end of the canceled region exit the barrier and \n resume execution at the end of the canceled region.This action can occur before the other threads \n reach that barrier.\n When compile-time error termination is performed, the effect is as if an error directive for which \n sev-level is fatal and action-time is compilation is encountered."}
{"section_title": "1.3 Execution Model", "chunk": "\n When compile-time error termination is performed, the effect is as if an error directive for which \n sev-level is fatal and action-time is compilation is encountered.When runtime error \n termination is performed, the effect is as if an error directive for which sev-level is fatal and \n action-time is execution is encountered.\n Synchronization constructs and library routines are available in the OpenMP API to coordinate \n tasks and data access in parallel regions.In addition, library routines and environment \n variables are available to control or to query the runtime environment of OpenMP programs.\n The OpenMP specification makes no guarantee that input or output to the same file is synchronous \n when executed in parallel.In this case, the programmer is responsible for synchronizing input and \n output processing with the assistance of OpenMP synchronization constructs or library routines."}
{"section_title": "1.3 Execution Model", "chunk": "In this case, the programmer is responsible for synchronizing input and \n output processing with the assistance of OpenMP synchronization constructs or library routines.\n For the case where each thread accesses a different file, the programmer does not need to \n synchronize access.\n All concurrency semantics defined by the base language with respect to threads of execution apply \n to OpenMP threads, unless specified otherwise.\n"}
{"section_title": "1.4 Memory Model", "chunk": ""}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "26 The OpenMP API provides a relaxed-consistency, shared-memory model.All OpenMP threads \n have access to a place to store and to retrieve variables, called the memory.A given storage location \n in the memory may be associated with one or more devices, such that only threads on associated \n devices have access to it.In addition, each thread is allowed to have its own temporary view of the \n memory.The temporary view of memory for each thread is not a required part of the OpenMP \n memory model, but can represent any kind of intervening structure, such as machine registers, \n cache, or other local storage, between the thread and the memory.The temporary view of memory \n allows the thread to cache variables and thereby to avoid going to memory for every reference to a \n variable.Each thread also has access to another type of memory that must not be accessed by other \n threads, called threadprivate memory."}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "Each thread also has access to another type of memory that must not be accessed by other \n threads, called threadprivate memory.\n OpenMP API \u2013 Version 5.2 November 2021 \n A directive that accepts data-sharing attribute clauses determines two kinds of access to variables \n used in the directive\u2019s associated structured block: shared and private.Each variable referenced in \n the structured block has an original variable, which is the variable by the same name that exists in \n the program immediately outside the construct.Each reference to a shared variable in the structured \n block becomes a reference to the original variable.For each private variable referenced in the \n structured block, a new version of the original variable (of the same type and size) is created in \n memory for each task or SIMD lane that contains code associated with the directive.Creation of \n the new version does not alter the value of the original variable."}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "Creation of \n the new version does not alter the value of the original variable.However, the impact of attempts to \n access the original variable from within the region corresponding to the directive is unspecified; see \n Section 5.4.3 for additional details.References to a private variable in the structured block refer to \n the private version of the original variable for the current task or SIMD lane.The relationship \n between the value of the original variable and the initial or final value of the private version \n depends on the exact clause that specifies it.Details of this issue, as well as other issues with \n privatization, are provided in Chapter 5.\n The minimum size at which a memory update may also read and write back adjacent variables that \n are part of another variable (as array elements or structure elements) is implementation defined but \n is no larger than the base language requires."}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "\n The minimum size at which a memory update may also read and write back adjacent variables that \n are part of another variable (as array elements or structure elements) is implementation defined but \n is no larger than the base language requires.\n A single access to a variable may be implemented with multiple load or store instructions and, thus, \n is not guaranteed to be atomic with respect to other accesses to the same variable.Accesses to \n variables smaller than the implementation-defined minimum size or to C or C++ bit-fields may be \n implemented by reading, modifying, and rewriting a larger unit of memory, and may thus interfere \n with updates of variables or fields in the same unit of memory.\n Two memory operations are considered unordered if the order in which they must complete, as seen \n by their affected threads, is not specified by the memory consistency guarantees listed in \n Section 1.4.6."}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "\n Two memory operations are considered unordered if the order in which they must complete, as seen \n by their affected threads, is not specified by the memory consistency guarantees listed in \n Section 1.4.6.If multiple threads write to the same memory unit (defined consistently with the \n above access considerations) then a data race occurs if the writes are unordered.Similarly, if at \n least one thread reads from a memory unit and at least one thread writes to that same memory unit \n then a data race occurs if the read and write are unordered.If a data race occurs then the result of \n the program is unspecified.\n A private variable in a task region that subsequently generates an inner nested parallel region is \n permitted to be made shared for implicit tasks in the inner parallel region.A private variable in \n a task region can also be shared by an explicit task region generated during its execution."}
{"section_title": "1.4.1 Structure of the OpenMP Memory Model", "chunk": "A private variable in \n a task region can also be shared by an explicit task region generated during its execution.However, \n the programmer must use synchronization that ensures that the lifetime of the variable does not end \n before completion of the explicit task region sharing it.Any other access by one task to the private \n variables of another task results in unspecified behavior.\n A storage location in memory that is associated with a given device has a device address that may \n be dereferenced by a thread executing on that device, but it may not be generally accessible from \n other devices.A different device may obtain a device pointer that refers to this device address.The \n manner in which a program can obtain the referenced device address from a device pointer, outside \n of mechanisms specified by OpenMP, is implementation defined.\nCHAPTER 1.OVERVIEW OF THE OPENMP API 27 \n"}
{"section_title": "1.4.2 Device Data Environments", "chunk": "2 When an OpenMP program begins, an implicit target data region for each device surrounds \n the whole program.Each device has a device data environment that is defined by its implicit \n target data region.Any declare target directives and directives that accept data-mapping \n attribute clauses determine how an original variable in a data environment is mapped to a \n corresponding variable in a device data environment.\n When an original variable is mapped to a device data environment and a corresponding variable is \n not present in the device data environment, a new corresponding variable (of the same type and size \n as the original variable) is created in the device data environment.Conversely, the original variable \n becomes the new variable\u2019s corresponding variable in the device data environment of the device \n that performs a mapping operation.\n The corresponding variable in the device data environment may share storage with the original \n variable."}
{"section_title": "1.4.2 Device Data Environments", "chunk": "\n The corresponding variable in the device data environment may share storage with the original \n variable.Writes to the corresponding variable may alter the value of the original variable.The \n impact of this possibility on memory consistency is discussed in Section 1.4.6.When a task \n executes in the context of a device data environment, references to the original variable refer to the \n corresponding variable in the device data environment.If an original variable is not currently \n mapped and a corresponding variable does not exist in the device data environment then accesses to \n the original variable result in unspecified behavior unless the unified_shared_memory \n clause is specified on a requires directive for the compilation unit.\n The relationship between the value of the original variable and the initial or final value of the \n corresponding variable depends on the map-type."}
{"section_title": "1.4.2 Device Data Environments", "chunk": "\n The relationship between the value of the original variable and the initial or final value of the \n corresponding variable depends on the map-type.Details of this issue, as well as other issues with \n mapping a variable, are provided in Section 5.8.3.\n The original variable in a data environment and a corresponding variable in a device data \n environment may share storage.Without intervening synchronization data races can occur.\n If a variable has a corresponding variable with which it does not share storage, a write to a storage \n location designated by the variable causes the value at the corresponding storage location to \n become undefined.\n"}
{"section_title": "1.4.3 Memory Management", "chunk": "29 The host device, and other devices that an implementation may support, have attached storage \n resources where program variables are stored.These resources can have different traits.A memory \n space in an OpenMP program represents a set of these storage resources.Memory spaces are \n defined according to a set of traits, and a single resource may be exposed as multiple memory \n spaces with different traits or may be part of multiple memory spaces.In any device, at least one \n memory space is guaranteed to exist.\n An OpenMP program can use a memory allocator to allocate memory in which to store variables.\n This memory will be allocated from the storage resources of the memory space associated with the \n memory allocator.Memory allocators are also used to deallocate previously allocated memory."}
{"section_title": "1.4.3 Memory Management", "chunk": "Memory allocators are also used to deallocate previously allocated memory.\n OpenMP API \u2013 Version 5.2 November 2021 \n When an OpenMP memory allocator is not used to allocate memory, OpenMP does not prescribe \n the storage resource for the allocation; the memory for the variables may be allocated in any storage \n resource.\n"}
{"section_title": "1.4.4 The Flush Operation", "chunk": "5 The memory model has relaxed-consistency because a thread\u2019s temporary view of memory is not \n required to be consistent with memory at all times.A value written to a variable can remain in the \n thread\u2019s temporary view until it is forced to memory at a later time.Likewise, a read from a \n variable may retrieve the value from the thread\u2019s temporary view, unless it is forced to read from \n memory.OpenMP flush operations are used to enforce consistency between a thread\u2019s temporary \n view of memory and memory, or between multiple threads\u2019 views of memory.\n A flush operation has an associated device-set that constrains the threads with which it enforces \n memory consistency.Consistency is only guaranteed to be enforced between the view of memory \n of its thread and the view of memory of other threads executing on devices in its device-set.Unless \n otherwise stated, the device-set of a flush operation only includes the current device."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "Unless \n otherwise stated, the device-set of a flush operation only includes the current device.\n If a flush operation is a strong flush, it enforces consistency between a thread\u2019s temporary view and \n memory.A strong flush operation is applied to a set of variables called the flush-set.A strong flush \n restricts how an implementation may reorder memory operations.Implementations must not \n reorder the code for a memory operation for a given variable, or the code for a flush operation for \n the variable, with respect to a strong flush operation that refers to the same variable.\n If a thread has performed a write to its temporary view of a shared variable since its last strong flush \n of that variable then, when it executes another strong flush of the variable, the strong flush does not \n complete until the value of the variable has been written to the variable in memory."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "\n If a thread has performed a write to its temporary view of a shared variable since its last strong flush \n of that variable then, when it executes another strong flush of the variable, the strong flush does not \n complete until the value of the variable has been written to the variable in memory.If a thread \n performs multiple writes to the same variable between two strong flushes of that variable, the strong \n flush ensures that the value of the last write is written to the variable in memory.A strong flush of a \n variable executed by a thread also causes its temporary view of the variable to be discarded, so that \n if its next memory operation for that variable is a read, then the thread will read from memory and \n capture the value in its temporary view.When a thread executes a strong flush, no later memory \n operation by that thread for a variable involved in that strong flush is allowed to start until the strong \n flush completes."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "When a thread executes a strong flush, no later memory \n operation by that thread for a variable involved in that strong flush is allowed to start until the strong \n flush completes.The completion of a strong flush executed by a thread is defined as the point at \n which all writes to the flush-set performed by the thread before the strong flush are visible in \n memory to all other threads, and at which that thread\u2019s temporary view of the flush-set is discarded.\n A strong flush operation provides a guarantee of consistency between a thread\u2019s temporary view \n and memory.Therefore, a strong flush can be used to guarantee that a value written to a variable by \n one thread may be read by a second thread.To accomplish this, the programmer must ensure that \n the second thread has not written to the variable since its last strong flush of the variable, and that \n the following sequence of events are completed in this specific order: \n 1."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "To accomplish this, the programmer must ensure that \n the second thread has not written to the variable since its last strong flush of the variable, and that \n the following sequence of events are completed in this specific order: \n 1.The value is written to the variable by the first thread; \n 2.The variable is flushed, with a strong flush, by the first thread; \nCHAPTER 1.OVERVIEW OF THE OPENMP API 29 \n 3.The variable is flushed, with a strong flush, by the second thread; and \n 4.The value is read from the variable by the second thread.\n If a flush operation is a release flush or acquire flush, it can enforce consistency between the views \n of memory of two synchronizing threads."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "\n If a flush operation is a release flush or acquire flush, it can enforce consistency between the views \n of memory of two synchronizing threads.A release flush guarantees that any prior operation that \n writes or reads a shared variable will appear to be completed before any operation that writes or \n reads the same shared variable and follows an acquire flush with which the release flush \n synchronizes (see Section 1.4.5 for more details on flush synchronization).A release flush will \n propagate the values of all shared variables in its temporary view to memory prior to the thread \n performing any subsequent atomic operation that may establish a synchronization."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "A release flush will \n propagate the values of all shared variables in its temporary view to memory prior to the thread \n performing any subsequent atomic operation that may establish a synchronization.An acquire flush \n will discard any value of a shared variable in its temporary view to which the thread has not written \n since last performing a release flush, and it will load any value of a shared variable propagated by a \n release flush that synchronizes with it into its temporary view so that it may be subsequently read.\n Therefore, release and acquire flushes may also be used to guarantee that a value written to a \n variable by one thread may be read by a second thread.To accomplish this, the programmer must \n ensure that the second thread has not written to the variable since its last acquire flush, and that the \n following sequence of events happen in this specific order: \n 1.The value is written to the variable by the first thread; \n 2."}
{"section_title": "1.4.4 The Flush Operation", "chunk": "The value is written to the variable by the first thread; \n 2.The first thread performs a release flush; \n 3.The second thread performs an acquire flush; and \n 4.The value is read from the variable by the second thread.\n \n Note \u2013 OpenMP synchronization operations, described in Chapter 15 and in Section 18.9, are \n recommended for enforcing this order.Synchronization through variables is possible but is not \n recommended because the proper timing of flushes is difficult.\n \n The flush properties that define whether a flush operation is a strong flush, a release flush, or an \n acquire flush are not mutually disjoint.A flush operation may be a strong flush and a release flush; \n it may be a strong flush and an acquire flush; it may be a release flush and an acquire flush; or it \n may be all three.\n"}
{"section_title": "1.4.5 Flush Synchronization and Happens Before", "chunk": "31 OpenMP supports thread synchronization with the use of release flushes and acquire flushes.For \n any such synchronization, a release flush is the source of the synchronization and an acquire flush is \n the sink of the synchronization, such that the release flush synchronizes with the acquire flush.\n A release flush has one or more associated release sequences that define the set of modifications \n that may be used to establish a synchronization.A release sequence starts with an atomic operation \n that follows the release flush and modifies a shared variable and additionally includes any \n OpenMP API \u2013 Version 5.2 November 2021 \n read-modify-write atomic operations that read a value taken from some modification in the release \n sequence.The following rules determine the atomic operation that starts an associated release \n sequence.\n \u2022 If a release flush is performed on entry to an atomic operation, that atomic operation starts its \n release sequence."}
{"section_title": "1.4.5 Flush Synchronization and Happens Before", "chunk": "\n \u2022 If a release flush is performed on entry to an atomic operation, that atomic operation starts its \n release sequence.\n \u2022 If a release flush is performed in an implicit flush region, an atomic operation that is provided \n by the implementation and that modifies an internal synchronization variable starts its release \n sequence.\n \u2022 If a release flush is performed by an explicit flush region, any atomic operation that modifies a \n shared variable and follows the flush region in its thread\u2019s program order starts an associated \n release sequence.\n An acquire flush is associated with one or more prior atomic operations that read a shared variable \n and that may be used to establish a synchronization.The following rules determine the associated \n atomic operation that may establish a synchronization.\n \u2022 If an acquire flush is performed on exit from an atomic operation, that atomic operation is its \n associated atomic operation."}
{"section_title": "1.4.5 Flush Synchronization and Happens Before", "chunk": "\n \u2022 If an acquire flush is performed on exit from an atomic operation, that atomic operation is its \n associated atomic operation.\n \u2022 If an acquire flush is performed in an implicit flush region, an atomic operation that is \n provided by the implementation and that reads an internal synchronization variable is its \n associated atomic operation.\n \u2022 If an acquire flush is performed by an explicit flush region, any atomic operation that reads a \n shared variable and precedes the flush region in its thread\u2019s program order is an associated \n atomic operation.\n A release flush synchronizes with an acquire flush if the following conditions are satisfied: \n \u2022 An atomic operation associated with the acquire flush reads a value written by a modification \n from a release sequence associated with the release flush; and \n \u2022 The device on which each flush is performed is in both of their respective device-sets."}
{"section_title": "1.4.5 Flush Synchronization and Happens Before", "chunk": "\n A release flush synchronizes with an acquire flush if the following conditions are satisfied: \n \u2022 An atomic operation associated with the acquire flush reads a value written by a modification \n from a release sequence associated with the release flush; and \n \u2022 The device on which each flush is performed is in both of their respective device-sets.\n An operation X simply happens before an operation Y if any of the following conditions are \n satisfied: \n 1.X and Y are performed by the same thread, and X precedes Y in the thread\u2019s program order; \n 2.X synchronizes with Y according to the flush synchronization conditions explained above or \n according to the base language\u2019s definition of synchronizes with, if such a definition exists; or \n 3.Another operation, Z, exists such that X simply happens before Z and Z simply happens before Y.\n An operation X happens before an operation Y if any of the following conditions are satisfied: \n 1."}
{"section_title": "1.4.5 Flush Synchronization and Happens Before", "chunk": "\n An operation X happens before an operation Y if any of the following conditions are satisfied: \n 1.X happens before Y according to the base language\u2019s definition of happens before, if such a \n definition exists; or \nCHAPTER 1.OVERVIEW OF THE OPENMP API 31 \n 2.X simply happens before Y.\n A variable with an initial value is treated as if the value is stored to the variable by an operation that \n happens before all operations that access or modify the variable in the program.\n"}
{"section_title": "1.4.6 OpenMP Memory Consistency", "chunk": "5 The following rules guarantee an observable completion order for a given pair of memory \n operations in race-free programs, as seen by all affected threads.If both memory operations are \n strong flushes, the affected threads are all threads on devices in both of their respective device-sets.\n If exactly one of the memory operations is a strong flush, the affected threads are all threads on \n devices in its device-set.Otherwise, the affected threads are all threads.\n \u2022 If two operations performed by different threads are sequentially consistent atomic operations or \n they are strong flushes that flush the same variable, then they must be completed as if in some \n sequential order, seen by all affected threads."}
{"section_title": "1.4.6 OpenMP Memory Consistency", "chunk": "\n \u2022 If two operations performed by different threads are sequentially consistent atomic operations or \n they are strong flushes that flush the same variable, then they must be completed as if in some \n sequential order, seen by all affected threads.\n \u2022 If two operations performed by the same thread are sequentially consistent atomic operations or \n they access, modify, or, with a strong flush, flush the same variable, then they must be completed \n as if in that thread\u2019s program order, as seen by all affected threads.\n \u2022 If two operations are performed by different threads and one happens before the other, then they \n must be completed as if in that happens before order, as seen by all affected threads, if: \n \u2013 both operations access or modify the same variable; \n \u2013 both operations are strong flushes that flush the same variable; or \n \u2013 both operations are sequentially consistent atomic operations."}
{"section_title": "1.4.6 OpenMP Memory Consistency", "chunk": "\n \u2022 If two operations are performed by different threads and one happens before the other, then they \n must be completed as if in that happens before order, as seen by all affected threads, if: \n \u2013 both operations access or modify the same variable; \n \u2013 both operations are strong flushes that flush the same variable; or \n \u2013 both operations are sequentially consistent atomic operations.\n \u2022 Any two atomic memory operations from different atomic regions must be completed as if in \n the same order as the strong flushes implied in their respective regions, as seen by all affected \n threads.\n The flush operation can be specified using the flush directive, and is also implied at various \n locations in an OpenMP program: see Section 15.8.5 for details.\n \n Note \u2013 Since flush operations by themselves cannot prevent data races, explicit flush operations \n are only useful in combination with non-sequentially consistent atomic directives."}
{"section_title": "1.4.6 OpenMP Memory Consistency", "chunk": "\n \n Note \u2013 Since flush operations by themselves cannot prevent data races, explicit flush operations \n are only useful in combination with non-sequentially consistent atomic directives.\n \n OpenMP programs that: \n \u2022 Do not use non-sequentially consistent atomic directives; \n \u2022 Do not rely on the accuracy of a false result from omp_test_lock and \n omp_test_nest_lock; and \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 Correctly avoid data races as required in Section 1.4.1, \n behave as though operations on shared variables were simply interleaved in an order consistent with \n the order in which they are performed by each thread.The relaxed consistency model is invisible \n for such programs, and any explicit flush operations in such programs are redundant.\n"}
{"section_title": "1.5 Tool Interfaces", "chunk": "6 The OpenMP API includes two tool interfaces, OMPT and OMPD, to enable development of \n high-quality, portable, tools that support monitoring, performance, or correctness analysis and \n debugging of OpenMP programs developed using any implementation of the OpenMP API.\n An implementation of the OpenMP API may differ from the abstract execution model described by \n its specification.The ability of tools that use the OMPT or OMPD interfaces to observe such \n differences does not constrain implementations of the OpenMP API in any way.\n"}
{"section_title": "1.5.1 OMPT", "chunk": "13 The OMPT interface, which is intended for first-party tools, provides the following: \n \u2022 A mechanism to initialize a first-party tool; \n \u2022 Routines that enable a tool to determine the capabilities of an OpenMP implementation; \n \u2022 Routines that enable a tool to examine OpenMP state information associated with a thread; \n \u2022 Mechanisms that enable a tool to map implementation-level calling contexts back to their \n source-level representations; \n \u2022 A callback interface that enables a tool to receive notification of OpenMP events; \n \u2022 A tracing interface that enables a tool to trace activity on OpenMP target devices; and \n \u2022 A runtime library routine that an application can use to control a tool.\n OpenMP implementations may differ with respect to the thread states that they support, the mutual \n exclusion implementations that they employ, and the OpenMP events for which tool callbacks are \n invoked."}
{"section_title": "1.5.1 OMPT", "chunk": "\n OpenMP implementations may differ with respect to the thread states that they support, the mutual \n exclusion implementations that they employ, and the OpenMP events for which tool callbacks are \n invoked.For some OpenMP events, OpenMP implementations must guarantee that a registered \n callback will be invoked for each occurrence of the event.For other OpenMP events, OpenMP \n implementations are permitted to invoke a registered callback for some or no occurrences of the \n event; for such OpenMP events, however, OpenMP implementations are encouraged to invoke tool \n callbacks on as many occurrences of the event as is practical.Section 19.2.4 specifies the subset of \n OMPT callbacks that an OpenMP implementation must support for a minimal implementation of \n the OMPT interface."}
{"section_title": "1.5.1 OMPT", "chunk": "Section 19.2.4 specifies the subset of \n OMPT callbacks that an OpenMP implementation must support for a minimal implementation of \n the OMPT interface.\n With the exception of the omp_control_tool runtime library routine for tool control, all other \n routines in the OMPT interface are intended for use only by tools and are not visible to \nCHAPTER 1.OVERVIEW OF THE OPENMP API 33 \n applications.For that reason, a Fortran binding is provided only for omp_control_tool; all \n other OMPT functionality is described with C syntax only.\n"}
{"section_title": "1.5.2 OMPD", "chunk": "4 The OMPD interface is intended for third-party tools, which run as separate processes.An \n OpenMP implementation must provide an OMPD library that can be dynamically loaded and used \n by a third-party tool.A third-party tool, such as a debugger, uses the OMPD library to access \n OpenMP state of a program that has begun execution.OMPD defines the following: \n \u2022 An interface that an OMPD library exports, which a tool can use to access OpenMP state of a \n program that has begun execution; \n \u2022 A callback interface that a tool provides to the OMPD library so that the library can use it to \n access the OpenMP state of a program that has begun execution; and \n \u2022 A small number of symbols that must be defined by an OpenMP implementation to help the tool \n find the correct OMPD library to use for that OpenMP implementation and to facilitate \n notification of events.\n Chapter 20 describes OMPD in detail.\n"}
{"section_title": "1.6 OpenMP Compliance", "chunk": "17 The OpenMP API defines constructs that operate in the context of the base language that is \n supported by an implementation.If the implementation of the base language does not support a \n language construct that appears in this document, a compliant OpenMP implementation is not \n required to support it, with the exception that for Fortran, the implementation must allow case \n insensitivity for directive and API routines names, and must allow identifiers of more than six \n characters.An implementation of the OpenMP API is compliant if and only if it compiles and \n executes all other conforming programs, and supports the tool interfaces, according to the syntax \n and semantics laid out in Chapters 1 through 20.Appendices A and B as well as sections designated \n as Notes (see Section 1.8) are for information purposes only and are not part of the specification."}
{"section_title": "1.6 OpenMP Compliance", "chunk": "Appendices A and B as well as sections designated \n as Notes (see Section 1.8) are for information purposes only and are not part of the specification.\n All library, intrinsic and built-in routines provided by the base language must be thread-safe in a \n compliant implementation.In addition, the implementation of the base language must also be \n thread-safe.For example, ALLOCATE and DEALLOCATE statements must be thread-safe in \n Fortran.Unsynchronized concurrent use of such routines by different threads must produce correct \n results (although not necessarily the same as serial execution results, as in the case of random \n number generation routines).\n Starting with Fortran 90, variables with explicit initialization have the SAVE attribute implicitly.\n This is not the case in Fortran 77.However, a compliant OpenMP Fortran implementation must \n give such a variable the SAVE attribute, regardless of the underlying base language version."}
{"section_title": "1.6 OpenMP Compliance", "chunk": "However, a compliant OpenMP Fortran implementation must \n give such a variable the SAVE attribute, regardless of the underlying base language version.\n OpenMP API \u2013 Version 5.2 November 2021 \n Appendix A lists certain aspects of the OpenMP API that are implementation defined.A compliant \n implementation must define and document its behavior for each of the items in Appendix A.\n"}
{"section_title": "1.7 Normative References", "chunk": "4 \u2022 ISO/IEC 9899:1990, Information Technology - Programming Languages - C.\n This OpenMP API specification refers to ISO/IEC 9899:1990 as C90.\n \u2022 ISO/IEC 9899:1999, Information Technology - Programming Languages - C.\n This OpenMP API specification refers to ISO/IEC 9899:1999 as C99.\n \u2022 ISO/IEC 9899:2011, Information Technology - Programming Languages - C.\n This OpenMP API specification refers to ISO/IEC 9899:2011 as C11.\n \u2022 ISO/IEC 9899:2018, Information Technology - Programming Languages - C.\n This OpenMP API specification refers to ISO/IEC 9899:2018 as C18.\n \u2022 ISO/IEC 14882:1998, Information Technology - Programming Languages - C++.\n This OpenMP API specification refers to ISO/IEC 14882:1998 as C++98.\n \u2022 ISO/IEC 14882:2011, Information Technology - Programming Languages - C++.\n This OpenMP API specification refers to ISO/IEC 14882:2011 as C++11.\n \u2022 ISO/IEC 14882:2014, Information Technology - Programming Languages - C++."}
{"section_title": "1.7 Normative References", "chunk": "\n \u2022 ISO/IEC 14882:2014, Information Technology - Programming Languages - C++.\n This OpenMP API specification refers to ISO/IEC 14882:2014 as C++14.\n \u2022 ISO/IEC 14882:2017, Information Technology - Programming Languages - C++.\n This OpenMP API specification refers to ISO/IEC 14882:2017 as C++17.\n \u2022 ISO/IEC 14882:2020, Information Technology - Programming Languages - C++.\n This OpenMP API specification refers to ISO/IEC 14882:2020 as C++20.\n \u2022 ISO/IEC 1539:1980, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539:1980 as Fortran 77.\n \u2022 ISO/IEC 1539:1991, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539:1991 as Fortran 90.\n \u2022 ISO/IEC 1539-1:1997, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539-1:1997 as Fortran 95.\nCHAPTER 1."}
{"section_title": "1.7 Normative References", "chunk": "\nCHAPTER 1.OVERVIEW OF THE OPENMP API 35 \n \u2022 ISO/IEC 1539-1:2004, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539-1:2004 as Fortran 2003.\n \u2022 ISO/IEC 1539-1:2010, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539-1:2010 as Fortran 2008.\n \u2022 ISO/IEC 1539-1:2018, Information Technology - Programming Languages - Fortran.\n This OpenMP API specification refers to ISO/IEC 1539-1:2018 as Fortran 2018.While future \n versions of the OpenMP specification are expected to address the following features, currently \n their use may result in unspecified behavior."}
{"section_title": "1.7 Normative References", "chunk": "While future \n versions of the OpenMP specification are expected to address the following features, currently \n their use may result in unspecified behavior.\n \u2013 Declared type of a polymorphic allocatable component in structure constructor \n \u2013 SELECT RANK construct \n \u2013 Assumed-rank dummy argument \n \u2013 Assumed-type dummy argument \n \u2013 Interoperable procedure enhancements \n Where this OpenMP API specification refers to C, C++ or Fortran, reference is made to the base \n language supported by the implementation.\n"}
{"section_title": "1.8 Organization of this Document", "chunk": "17 The remainder of this document is structured as normative chapters that define the directives, \n including their syntax and semantics, the runtime routines and the tool interfaces that comprise the \n OpenMP API.The document also includes appendices that facilitate maintaining a compliant \n implementation of the API.\n Some sections of this document only apply to programs written in a certain base language.Text that \n applies only to programs for which the base language is C or C++ is shown as follows: \nC / C++ \n C/C++ specific text...\nC / C++ \n Text that applies only to programs for which the base language is C only is shown as follows: \nC \n C specific text...\nC \n Text that applies only to programs for which the base language is C++ only is shown as follows: \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n C++ specific text...\nC++ \n Text that applies only to programs for which the base language is Fortran is shown as follows: \nFortran \n Fortran specific text..."}
{"section_title": "1.8 Organization of this Document", "chunk": "\nC++ \n Text that applies only to programs for which the base language is Fortran is shown as follows: \nFortran \n Fortran specific text...\nFortran \n Where an entire page consists of base language specific text, a marker is shown at the top of the \n page.For Fortran-specific text, the marker is: \nFortran (cont.) \n For C/C++-specific text, the marker is: \nC/C++ (cont.) \n Some text is for information only, and is not part of the normative specification.Such text is \n designated as a note or comment, like this: \n \n Note \u2013 Non-normative text...\n \n COMMENT: Non-normative text...\nCHAPTER 1.OVERVIEW OF THE OPENMP API 37 \n"}
{"section_title": "2 Internal Control Variables", "chunk": "2 An OpenMP implementation must act as if internal control variables (ICVs) control the behavior of \n an OpenMP program.These ICVs store information such as the number of threads to use for future \n parallel regions.One copy exists of each ICV per instance of its scope.Possible ICV scopes \n are: global; device; implicit task; and data environment.If an ICV has global scope then one copy \n exists for the whole program.The ICVs are given values at various times (described below) during \n the execution of the program.They are initialized by the implementation itself and may be given \n values through OpenMP environment variables and through calls to OpenMP API routines.The \n program can retrieve the values of these ICVs only through OpenMP API routines."}
{"section_title": "2 Internal Control Variables", "chunk": "The \n program can retrieve the values of these ICVs only through OpenMP API routines.\n For purposes of exposition, this document refers to the ICVs by certain names, but an \n implementation is not required to use these names or to offer any way to access the variables other \n than through the ways shown in Section 2.2.\n"}
{"section_title": "2.1 ICV Descriptions", "chunk": "14 Table 2.1 shows the scope and description of each ICV."}
{"section_title": "2.1 ICV Descriptions", "chunk": "14 Table 2.1 shows the scope and description of each ICV.\nTABLE 2.1: ICV Scopes and Descriptions \nICV Scope Description \nactive-levels-var data environment Number of nested active parallel regions \nsuch that all parallel regions are enclosed by \nthe outermost initial task region on the device \naffinity-format-var device Controls the thread affinity format when display\ufffeing thread affinity \nbind-var data environment Controls the binding of OpenMP threads to \nplaces; when binding is requested, indicates that \nthe execution environment is advised not to move \nthreads between places; can also provide default \nthread affinity policies \ncancel-var global Controls the desired behavior of the cancel \nconstruct and cancellation points \n \nICV Scope Description \ndebug-var global Controls whether an OpenMP implementation \nwill collect information that an OMPD library \ncan access to satisfy requests from a tool \ndef-allocator-var implicit task Controls the memory allocator used by memory \nallocation routines, directives and clauses that do \nnot specify one explicitly \ndefault-device-var data environment Controls the default target device \ndisplay-affinity-var global Controls the display of thread affinity \ndyn-var data environment Enables dynamic adjustment of the number of \nthreads used for encountered parallel regions \nexplicit-task-var data environment Whether a given task is an explicit task \nfinal-task-var data environment Whether a given task is a final task \nlevels-var data environment Number of nested parallel regions such that \nall parallel regions are enclosed by the outer\ufffemost initial task region on the device \nmax-active-levels-var data environment Controls the maximum number of nested ac\ufffetive parallel regions when the innermost \nparallel region is generated by a given task \nmax-task-priority-var global Controls the maximum value that can be speci\ufffefied in the priority clause \nnteams-var device Controls the number of teams requested for en\ufffecountered teams regions \nnthreads-var data environment Controls the number of threads requested for \nencountered parallel regions \nnum-procs-var device The number of processors available on the device \nplace-partition-var implicit task Controls the place partition available for encoun\ufffetered parallel regions \nrun-sched-var data environment Controls the schedule used for worksharing-loop \nregions that specify the runtime schedule kind \nstacksize-var device Controls the stack size for threads that the \nOpenMP implementation creates \ntarget-offload-var global Controls the offloading behavior \nteam-size-var data environment Size of the current team \nteams-thread-limit-var device Controls the maximum number of threads in each \ncontention group that a teams construct creates \nthread-limit-var data environment Controls the maximum number of threads that \nparticipate in the contention group \nCHAPTER 2."}
{"section_title": "2.1 ICV Descriptions", "chunk": "\nTABLE 2.1: ICV Scopes and Descriptions \nICV Scope Description \nactive-levels-var data environment Number of nested active parallel regions \nsuch that all parallel regions are enclosed by \nthe outermost initial task region on the device \naffinity-format-var device Controls the thread affinity format when display\ufffeing thread affinity \nbind-var data environment Controls the binding of OpenMP threads to \nplaces; when binding is requested, indicates that \nthe execution environment is advised not to move \nthreads between places; can also provide default \nthread affinity policies \ncancel-var global Controls the desired behavior of the cancel \nconstruct and cancellation points \n \nICV Scope Description \ndebug-var global Controls whether an OpenMP implementation \nwill collect information that an OMPD library \ncan access to satisfy requests from a tool \ndef-allocator-var implicit task Controls the memory allocator used by memory \nallocation routines, directives and clauses that do \nnot specify one explicitly \ndefault-device-var data environment Controls the default target device \ndisplay-affinity-var global Controls the display of thread affinity \ndyn-var data environment Enables dynamic adjustment of the number of \nthreads used for encountered parallel regions \nexplicit-task-var data environment Whether a given task is an explicit task \nfinal-task-var data environment Whether a given task is a final task \nlevels-var data environment Number of nested parallel regions such that \nall parallel regions are enclosed by the outer\ufffemost initial task region on the device \nmax-active-levels-var data environment Controls the maximum number of nested ac\ufffetive parallel regions when the innermost \nparallel region is generated by a given task \nmax-task-priority-var global Controls the maximum value that can be speci\ufffefied in the priority clause \nnteams-var device Controls the number of teams requested for en\ufffecountered teams regions \nnthreads-var data environment Controls the number of threads requested for \nencountered parallel regions \nnum-procs-var device The number of processors available on the device \nplace-partition-var implicit task Controls the place partition available for encoun\ufffetered parallel regions \nrun-sched-var data environment Controls the schedule used for worksharing-loop \nregions that specify the runtime schedule kind \nstacksize-var device Controls the stack size for threads that the \nOpenMP implementation creates \ntarget-offload-var global Controls the offloading behavior \nteam-size-var data environment Size of the current team \nteams-thread-limit-var device Controls the maximum number of threads in each \ncontention group that a teams construct creates \nthread-limit-var data environment Controls the maximum number of threads that \nparticipate in the contention group \nCHAPTER 2.INTERNAL CONTROL VARIABLES 39 \nICV Scope Description \nthread-num-var data environment Thread number of an implicit task within its \nbinding team \ntool-libraries-var global List of absolute paths to tool libraries \ntool-var global Indicates that a tool will be registered \ntool-verbose-init-var global Controls whether an OpenMP implementation \nwill verbosely log the registration of a tool \nwait-policy-var device Controls the desired behavior of waiting threads \n"}
{"section_title": "2.2 ICV Initialization", "chunk": "2 Table 2.2 shows the ICVs, associated environment variables, and initial values."}
{"section_title": "2.2 ICV Initialization", "chunk": "2 Table 2.2 shows the ICVs, associated environment variables, and initial values.\nTABLE 2.2: ICV Initial Values \nICV Environment Variable Initial Value \nactive-levels-var (none) Zero \naffinity-format-var OMP_AFFINITY_FORMAT Implementation defined \nbind-var OMP_PROC_BIND Implementation defined \ncancel-var OMP_CANCELLATION False \ndebug-var OMP_DEBUG disabled \ndef-allocator-var OMP_ALLOCATOR Implementation defined \ndefault-device-var OMP_DEFAULT_DEVICE See below \ndisplay-affinity-var OMP_DISPLAY_AFFINITY False \ndyn-var OMP_DYNAMIC Implementation defined \nexplicit-task-var (none) False \nfinal-task-var (none) False \nlevels-var (none) Zero \nmax-active-levels-var OMP_MAX_ACTIVE_LEVELS, \nOMP_NESTED, OMP_NUM_THREADS, \nOMP_PROC_BIND \nImplementation defined \nmax-task-priority-var OMP_MAX_TASK_PRIORITY Zero \nnteams-var OMP_NUM_TEAMS Zero \nnthreads-var OMP_NUM_THREADS Implementation defined \nnum-procs-var (none) Implementation defined \nplace-partition-var OMP_PLACES Implementation defined \nrun-sched-var OMP_SCHEDULE Implementation defined \nstacksize-var OMP_STACKSIZE Implementation defined \n OpenMP API \u2013 Version 5.2 November 2021 \nICV Environment Variable Initial Value \ntarget-offload-var OMP_TARGET_OFFLOAD default \nteam-size-var (none) One \nteams-thread-limit-var OMP_TEAMS_THREAD_LIMIT Zero \nthread-limit-var OMP_THREAD_LIMIT Implementation defined \nthread-num-var (none) Zero \ntool-libraries-var OMP_TOOL_LIBRARIES empty string \ntool-var OMP_TOOL enabled \ntool-verbose-init-var OMP_TOOL_VERBOSE_INIT disabled \nwait-policy-var OMP_WAIT_POLICY Implementation defined \n If an ICV has an associated environment variable and that ICV does not have global scope then the \n ICV has a set of associated device-specific environment variables that extend the associated \n environment variable with the following syntax: \n <ENVIRONMENT VARIABLE>_DEV[_<device>] \n where <ENVIRONMENT VARIABLE> is the associated environment variable and <device> is the \n device number as specified in the device clause (see Section 13.2)."}
{"section_title": "2.2 ICV Initialization", "chunk": "\nTABLE 2.2: ICV Initial Values \nICV Environment Variable Initial Value \nactive-levels-var (none) Zero \naffinity-format-var OMP_AFFINITY_FORMAT Implementation defined \nbind-var OMP_PROC_BIND Implementation defined \ncancel-var OMP_CANCELLATION False \ndebug-var OMP_DEBUG disabled \ndef-allocator-var OMP_ALLOCATOR Implementation defined \ndefault-device-var OMP_DEFAULT_DEVICE See below \ndisplay-affinity-var OMP_DISPLAY_AFFINITY False \ndyn-var OMP_DYNAMIC Implementation defined \nexplicit-task-var (none) False \nfinal-task-var (none) False \nlevels-var (none) Zero \nmax-active-levels-var OMP_MAX_ACTIVE_LEVELS, \nOMP_NESTED, OMP_NUM_THREADS, \nOMP_PROC_BIND \nImplementation defined \nmax-task-priority-var OMP_MAX_TASK_PRIORITY Zero \nnteams-var OMP_NUM_TEAMS Zero \nnthreads-var OMP_NUM_THREADS Implementation defined \nnum-procs-var (none) Implementation defined \nplace-partition-var OMP_PLACES Implementation defined \nrun-sched-var OMP_SCHEDULE Implementation defined \nstacksize-var OMP_STACKSIZE Implementation defined \n OpenMP API \u2013 Version 5.2 November 2021 \nICV Environment Variable Initial Value \ntarget-offload-var OMP_TARGET_OFFLOAD default \nteam-size-var (none) One \nteams-thread-limit-var OMP_TEAMS_THREAD_LIMIT Zero \nthread-limit-var OMP_THREAD_LIMIT Implementation defined \nthread-num-var (none) Zero \ntool-libraries-var OMP_TOOL_LIBRARIES empty string \ntool-var OMP_TOOL enabled \ntool-verbose-init-var OMP_TOOL_VERBOSE_INIT disabled \nwait-policy-var OMP_WAIT_POLICY Implementation defined \n If an ICV has an associated environment variable and that ICV does not have global scope then the \n ICV has a set of associated device-specific environment variables that extend the associated \n environment variable with the following syntax: \n <ENVIRONMENT VARIABLE>_DEV[_<device>] \n where <ENVIRONMENT VARIABLE> is the associated environment variable and <device> is the \n device number as specified in the device clause (see Section 13.2).\n Semantics \n \u2022 The initial value of dyn-var is implementation defined if the implementation supports dynamic \n adjustment of the number of threads; otherwise, the initial value is false."}
{"section_title": "2.2 ICV Initialization", "chunk": "\n Semantics \n \u2022 The initial value of dyn-var is implementation defined if the implementation supports dynamic \n adjustment of the number of threads; otherwise, the initial value is false.\n \u2022 If target-offload-var is mandatory and the number of non-host devices is zero then the \n default-device-var is initialized to omp_invalid_device.Otherwise, the initial value is an \n implementation-defined non-negative integer that is less than or, if target-offload-var is not \n mandatory, equal to omp_get_initial_device().\n \u2022 The value of the nthreads-var ICV is a list.\n \u2022 The value of the bind-var ICV is a list.\n The host and non-host device ICVs are initialized before any OpenMP API construct or OpenMP \n API routine executes.After the initial values are assigned, the values of any OpenMP environment \n variables that were set by the user are read and the associated ICVs are modified accordingly."}
{"section_title": "2.2 ICV Initialization", "chunk": "After the initial values are assigned, the values of any OpenMP environment \n variables that were set by the user are read and the associated ICVs are modified accordingly.If no \n <device> number is specified on the device-specific environment variable then the value is applied \n to all non-host devices.\n Cross References \n \u2022 OMP_AFFINITY_FORMAT, see Section 21.2.5 \n \u2022 OMP_ALLOCATOR, see Section 21.5.1 \n \u2022 OMP_CANCELLATION, see Section 21.2.6 \nCHAPTER 2."}
{"section_title": "2.2 ICV Initialization", "chunk": "\n Cross References \n \u2022 OMP_AFFINITY_FORMAT, see Section 21.2.5 \n \u2022 OMP_ALLOCATOR, see Section 21.5.1 \n \u2022 OMP_CANCELLATION, see Section 21.2.6 \nCHAPTER 2.INTERNAL CONTROL VARIABLES 41 \n \u2022 OMP_DEBUG, see Section 21.4.1 \n \u2022 OMP_DEFAULT_DEVICE, see Section 21.2.7 \n \u2022 OMP_DISPLAY_AFFINITY, see Section 21.2.4 \n \u2022 OMP_DYNAMIC, see Section 21.1.1 \n \u2022 OMP_MAX_ACTIVE_LEVELS, see Section 21.1.4 \n \u2022 OMP_MAX_TASK_PRIORITY, see Section 21.2.9 \n \u2022 OMP_NESTED (Deprecated), see Section 21.1.5 \n \u2022 OMP_NUM_TEAMS, see Section 21.6.1 \n \u2022 OMP_NUM_THREADS, see Section 21.1.2 \n \u2022 OMP_PLACES, see Section 21.1.6 \n \u2022 OMP_PROC_BIND, see Section 21.1.7 \n \u2022 OMP_SCHEDULE, see Section 21.2.1 \n \u2022 OMP_STACKSIZE, see Section 21.2.2 \n \u2022 OMP_TARGET_OFFLOAD, see Section 21.2.8 \n \u2022 OMP_TEAMS_THREAD_LIMIT, see Section 21.6.2 \n \u2022 OMP_THREAD_LIMIT, see Section 21.1.3 \n \u2022 OMP_TOOL, see Section 21.3.1 \n \u2022 OMP_TOOL_LIBRARIES, see Section 21.3.2 \n \u2022 OMP_WAIT_POLICY, see Section 21.2.3 \n"}
{"section_title": "2.3 Modifying and Retrieving ICV Values", "chunk": "21 Table 2.3 shows methods for modifying and retrieving the ICV values.If (none) is listed for an \n ICV, the OpenMP API does not support its modification or retrieval.Calls to OpenMP API routines \n retrieve or modify data environment scoped ICVs in the data environment of their binding tasks."}
{"section_title": "2.3 Modifying and Retrieving ICV Values", "chunk": "Calls to OpenMP API routines \n retrieve or modify data environment scoped ICVs in the data environment of their binding tasks.\nTABLE 2.3: Ways to Modify and to Retrieve ICV Values \nICV Ways to Modify Value Ways to Retrieve Value \nactive-levels-var (none) omp_get_active_level \naffinity-format-var omp_set_affinity_format omp_get_affinity_format \nbind-var (none) omp_get_proc_bind \ncancel-var (none) omp_get_cancellation \n OpenMP API \u2013 Version 5.2 November 2021 \nICV Ways to Modify Value Ways to Retrieve Value \ndebug-var (none) (none) \ndef-allocator-var omp_set_default_allocator omp_get_default_allocator \ndefault-device-var omp_set_default_device omp_get_default_device \ndisplay-affinity-var (none) (none) \ndyn-var omp_set_dynamic omp_get_dynamic \nexplicit-task-var (none) omp_in_explicit_task \nfinal-task-var (none) omp_in_final \nlevels-var (none) omp_get_level \nmax-active-levels-var omp_set_max_active_levels, \nomp_set_nested \nomp_get_max_active_levels \nmax-task-priority-var (none) omp_get_max_task_priority \nnteams-var omp_set_num_teams omp_get_max_teams \nnthreads-var omp_set_num_threads omp_get_max_threads \nnum-procs-var (none) omp_get_num_procs \nplace-partition-var (none) omp_get_partition_num_places, \nomp_get_partition_place_nums, \nomp_get_place_num_procs, \nomp_get_place_proc_ids \nrun-sched-var omp_set_schedule omp_get_schedule \nstacksize-var (none) (none) \ntarget-offload-var (none) (none) \nteam-size-var (none) omp_get_num_threads \nteams-thread-limit-var omp_set_teams_thread_limit omp_get_teams_thread_limit \nthread-limit-var thread_limit omp_get_thread_limit \nthread-num-var (none) omp_get_thread_num \ntool-libraries-var (none) (none) \ntool-var (none) (none) \ntool-verbose-init-var (none) (none) \nwait-policy-var (none) (none) \n Semantics \n \u2022 The value of the bind-var ICV is a list."}
{"section_title": "2.3 Modifying and Retrieving ICV Values", "chunk": "\nTABLE 2.3: Ways to Modify and to Retrieve ICV Values \nICV Ways to Modify Value Ways to Retrieve Value \nactive-levels-var (none) omp_get_active_level \naffinity-format-var omp_set_affinity_format omp_get_affinity_format \nbind-var (none) omp_get_proc_bind \ncancel-var (none) omp_get_cancellation \n OpenMP API \u2013 Version 5.2 November 2021 \nICV Ways to Modify Value Ways to Retrieve Value \ndebug-var (none) (none) \ndef-allocator-var omp_set_default_allocator omp_get_default_allocator \ndefault-device-var omp_set_default_device omp_get_default_device \ndisplay-affinity-var (none) (none) \ndyn-var omp_set_dynamic omp_get_dynamic \nexplicit-task-var (none) omp_in_explicit_task \nfinal-task-var (none) omp_in_final \nlevels-var (none) omp_get_level \nmax-active-levels-var omp_set_max_active_levels, \nomp_set_nested \nomp_get_max_active_levels \nmax-task-priority-var (none) omp_get_max_task_priority \nnteams-var omp_set_num_teams omp_get_max_teams \nnthreads-var omp_set_num_threads omp_get_max_threads \nnum-procs-var (none) omp_get_num_procs \nplace-partition-var (none) omp_get_partition_num_places, \nomp_get_partition_place_nums, \nomp_get_place_num_procs, \nomp_get_place_proc_ids \nrun-sched-var omp_set_schedule omp_get_schedule \nstacksize-var (none) (none) \ntarget-offload-var (none) (none) \nteam-size-var (none) omp_get_num_threads \nteams-thread-limit-var omp_set_teams_thread_limit omp_get_teams_thread_limit \nthread-limit-var thread_limit omp_get_thread_limit \nthread-num-var (none) omp_get_thread_num \ntool-libraries-var (none) (none) \ntool-var (none) (none) \ntool-verbose-init-var (none) (none) \nwait-policy-var (none) (none) \n Semantics \n \u2022 The value of the bind-var ICV is a list.The runtime call omp_get_proc_bind retrieves the \n value of the first element of this list."}
{"section_title": "2.3 Modifying and Retrieving ICV Values", "chunk": "The runtime call omp_get_proc_bind retrieves the \n value of the first element of this list.\n \u2022 The value of the nthreads-var ICV is a list.The runtime call omp_set_num_threads sets \n the value of the first element of this list, and omp_get_max_threads retrieves the value of \n the first element of this list.\n \u2022 Detailed values in the place-partition-var ICV are retrieved using the listed runtime calls.\nCHAPTER 2.INTERNAL CONTROL VARIABLES 43 \n \u2022 The thread_limit clause sets the thread-limit-var ICV for the region of the construct on \n which it appears."}
{"section_title": "2.3 Modifying and Retrieving ICV Values", "chunk": "INTERNAL CONTROL VARIABLES 43 \n \u2022 The thread_limit clause sets the thread-limit-var ICV for the region of the construct on \n which it appears.\n Cross References \n \u2022 omp_get_active_level, see Section 18.2.20 \n \u2022 omp_get_affinity_format, see Section 18.3.9 \n \u2022 omp_get_cancellation, see Section 18.2.8 \n \u2022 omp_get_default_allocator, see Section 18.13.5 \n \u2022 omp_get_default_device, see Section 18.7.3 \n \u2022 omp_get_dynamic, see Section 18.2.7 \n \u2022 omp_get_level, see Section 18.2.17 \n \u2022 omp_get_max_active_levels, see Section 18.2.16 \n \u2022 omp_get_max_task_priority, see Section 18.5.1 \n \u2022 omp_get_max_teams, see Section 18.4.4 \n \u2022 omp_get_max_threads, see Section 18.2.3 \n \u2022 omp_get_num_procs, see Section 18.7.1 \n \u2022 omp_get_num_threads, see Section 18.2.2 \n \u2022 omp_get_partition_num_places, see Section 18.3.6 \n \u2022 omp_get_partition_place_nums, see Section 18.3.7 \n \u2022 omp_get_place_num_procs, see Section 18.3.3 \n \u2022 omp_get_place_proc_ids, see Section 18.3.4 \n \u2022 omp_get_proc_bind, see Section 18.3.1 \n \u2022 omp_get_schedule, see Section 18.2.12 \n \u2022 omp_get_supported_active_levels, see Section 18.2.14 \n \u2022 omp_get_teams_thread_limit, see Section 18.4.6 \n \u2022 omp_get_thread_limit, see Section 18.2.13 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 omp_in_final, see Section 18.5.3 \n \u2022 omp_set_affinity_format, see Section 18.3.8 \n \u2022 omp_set_default_allocator, see Section 18.13.4 \n \u2022 omp_set_default_device, see Section 18.7.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 omp_set_dynamic, see Section 18.2.6 \n \u2022 omp_set_max_active_levels, see Section 18.2.15 \n \u2022 omp_set_nested (Deprecated), see Section 18.2.9 \n \u2022 omp_set_num_teams, see Section 18.4.3 \n \u2022 omp_set_num_threads, see Section 18.2.1 \n \u2022 omp_set_schedule, see Section 18.2.11 \n \u2022 omp_set_teams_thread_limit, see Section 18.4.5 \n \u2022 thread_limit clause, see Section 13.3 \n"}
{"section_title": "2.4 How the Per-Data Environment ICVs Work", "chunk": "10 When a task construct, a parallel construct or a teams construct is encountered, each \n generated task inherits the values of the data environment scoped ICVs from each generating task\u2019s \n ICV values.\n When a parallel construct is encountered, the value of each ICV with implicit task scope is \n inherited from the implicit binding task of the generating task unless otherwise specified.\n When a task construct is encountered, the generated task inherits the value of nthreads-var from \n the generating task\u2019s nthreads-var value.When a parallel construct is encountered, and the \n generating task\u2019s nthreads-var list contains a single element, the generated implicit tasks inherit \n that list as the value of nthreads-var."}
{"section_title": "2.4 How the Per-Data Environment ICVs Work", "chunk": "When a parallel construct is encountered, and the \n generating task\u2019s nthreads-var list contains a single element, the generated implicit tasks inherit \n that list as the value of nthreads-var.When a parallel construct is encountered, and the \n generating task\u2019s nthreads-var list contains multiple elements, the generated implicit tasks inherit \n the value of nthreads-var as the list obtained by deletion of the first element from the generating \n task\u2019s nthreads-var value.The bind-var ICV is handled in the same way as the nthreads-var ICV.\n When a target task executes an active target region, the generated initial task uses the values of \n the data environment scoped ICVs from the device data environment ICV values of the device that \n will execute the region."}
{"section_title": "2.4 How the Per-Data Environment ICVs Work", "chunk": "\n When a target task executes an active target region, the generated initial task uses the values of \n the data environment scoped ICVs from the device data environment ICV values of the device that \n will execute the region.\n When a target task executes an inactive target region, the generated initial task uses the values \n of the data environment scoped ICVs from the data environment of the task that encountered the \n target construct.\n If a target construct with a thread_limit clause is encountered, the thread-limit-var ICV \n from the data environment of the generated initial task is instead set to an implementation defined \n value between one and the value specified in the clause.\n If a target construct with no thread_limit clause is encountered, the thread-limit-var ICV \n from the data environment of the generated initial task is set to an implementation defined value \n that is greater than zero.\nCHAPTER 2."}
{"section_title": "2.4 How the Per-Data Environment ICVs Work", "chunk": "\nCHAPTER 2.INTERNAL CONTROL VARIABLES 45 \n If a teams construct with a thread_limit clause is encountered, the thread-limit-var ICV \n from the data environment of the initial task for each team is instead set to an implementation \n defined value between one and the value specified in the clause.\n If a teams construct with no thread_limit clause is encountered, the thread-limit-var ICV \n from the data environment of the initial task of each team is set to an implementation defined value \n that is greater than zero and does not exceed teams-thread-limit-var, if teams-thread-limit-var is \n greater than zero.\n When encountering a worksharing-loop region for which the runtime schedule kind is specified, \n all implicit task regions that constitute the binding parallel region must have the same value for \n run-sched-var in their data environments.Otherwise, the behavior is unspecified.\n"}
{"section_title": "2.5 ICV Override Relationships", "chunk": "12 Table 2.4 shows the override relationships among construct clauses and ICVs.The table only lists \n ICVs that can be overridden by a clause.\nTABLE 2.4: ICV Override Relationships \nICV construct clause, if used \nbind-var proc_bind \ndef-allocator-var allocate, allocator \nnteams-var num_teams \nnthreads-var num_threads \nrun-sched-var schedule \nteams-thread-limit-var thread_limit \n Semantics \n \u2022 The num_threads clause overrides the value of the first element of the nthreads-var ICV.\n \u2022 If a schedule clause specifies a modifier then that modifier overrides any modifier that is \n specified in the run-sched-var ICV.\n \u2022 If bind-var is not set to false then the proc_bind clause overrides the value of the first element \n of the bind-var ICV; otherwise, the proc_bind clause has no effect."}
{"section_title": "2.5 ICV Override Relationships", "chunk": "\n \u2022 If bind-var is not set to false then the proc_bind clause overrides the value of the first element \n of the bind-var ICV; otherwise, the proc_bind clause has no effect.\n Cross References \n \u2022 allocate clause, see Section 6.6 \n \u2022 allocator clause, see Section 6.4 \n \u2022 num_teams clause, see Section 10.2.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 proc_bind clause, see Section 10.1.4 \n \u2022 schedule clause, see Section 11.5.3 \n \u2022 thread_limit clause, see Section 13.3 \nCHAPTER 2.INTERNAL CONTROL VARIABLES 47 \n"}
{"section_title": "3 Directive and Construct Syntax", "chunk": "2 This chapter describes the syntax of OpenMP directives, clauses and any related base language \n code.OpenMP directives are specified with various base-language mechanisms that allow \n compilers to ignore OpenMP directives and conditionally compiled code if support of the OpenMP \n API is not provided or enabled.A compliant implementation must provide an option or interface \n that ensures that underlying support of all OpenMP directives and OpenMP conditional \n compilation mechanisms is enabled.In the remainder of this document, the phrase OpenMP \n compilation is used to mean a compilation with these OpenMP features enabled.\n Restrictions \n The following restrictions apply to OpenMP directives: \n \u2022 Unless otherwise specified, a program must not depend on any ordering of the evaluations of the \n expressions that appear in the clauses specified on a directive."}
{"section_title": "3 Directive and Construct Syntax", "chunk": "\n Restrictions \n The following restrictions apply to OpenMP directives: \n \u2022 Unless otherwise specified, a program must not depend on any ordering of the evaluations of the \n expressions that appear in the clauses specified on a directive.\n \u2022 Unless otherwise specified, a program must not depend on any side effects of the evaluations of \n the expressions that appear in the clauses specified on a directive.\n Restrictions on explicit OpenMP regions (that arise from executable directives) are as follows: \nC++ \n \u2022 A throw executed inside a region that arises from a thread-limiting directive must cause \n execution to resume within the same region, and the same thread that threw the exception must \n catch it.If the directive is also exception-aborting then whether the exception is caught or the \n throw results in runtime error termination is implementation defined.\nC++ \nFortran \n \u2022 A directive may not appear in a pure procedure unless it is pure."}
{"section_title": "3 Directive and Construct Syntax", "chunk": "\nC++ \nFortran \n \u2022 A directive may not appear in a pure procedure unless it is pure.\n \u2022 A directive may not appear in a WHERE, FORALL or DO CONCURRENT construct.\n \u2022 If more than one image is executing the program, any image control statement, ERROR STOP \n statement, FAIL IMAGE statement, collective subroutine call or access to a coindexed object that \n appears in an explicit OpenMP region will result in unspecified behavior.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "3.1 Directive Format", "chunk": "2 This section defines several categories of directives and constructs.OpenMP directives are \n specified with a directive-specification.A directive-specification consists of the directive-specifier \n and any clauses that may optionally be associated with the OpenMP directive: \n directive-specifier [[,] clause[ [,] clause] ...] \n The directive-specifier is: \n directive-name \n or for argument-modified directives: \n directive-name[(directive-arguments)] \nC / C++ \n White space in a directive-name is not optional.\nC / C++ \n Some OpenMP directives specify a paired end directive, where the directive-name of the paired \n end directives is: \n \u2022 If directive-name starts with begin, the end-directive-name replaces begin with end \n \u2022 otherwise it is end directive-name unless otherwise specified."}
{"section_title": "3.1 Directive Format", "chunk": "\nC / C++ \n Some OpenMP directives specify a paired end directive, where the directive-name of the paired \n end directives is: \n \u2022 If directive-name starts with begin, the end-directive-name replaces begin with end \n \u2022 otherwise it is end directive-name unless otherwise specified.\n The directive-specification of a paired end directive may include one or more optional end-clause: \n directive-specifier [[,] end-clause[ [,] end-clause]...] \n where end-clause has the end-clause property, which explicitly allows it on a paired end directive.\nC / C++ \n An OpenMP directive may be specified as a pragma directive: \n #pragma omp directive-specification new-line \n or a pragma operator: \n _Pragma(\"omp directive-specification\") \n The use of omp as the first preprocessing token of a pragma directive is reserved for OpenMP \n directives that are defined in this specification."}
{"section_title": "3.1 Directive Format", "chunk": "\nC / C++ \n An OpenMP directive may be specified as a pragma directive: \n #pragma omp directive-specification new-line \n or a pragma operator: \n _Pragma(\"omp directive-specification\") \n The use of omp as the first preprocessing token of a pragma directive is reserved for OpenMP \n directives that are defined in this specification.The use of ompx as the first preprocessing token of \n a pragma directive is reserved for implementation-defined extensions to the OpenMP directives.\nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 49 \n \n Note \u2013 In this directive, directive-name is depobj, directive-arguments is o.directive-specifier is \n depobj(o) and directive-specification is depobj(o) depend(inout: d).\n #pragma omp depobj(o) depend(inout: d) \n \n White space can be used before and after the #.Preprocessing tokens in directive-specification of \n #pragma and _Pragma pragmas are subject to macro expansion."}
{"section_title": "3.1 Directive Format", "chunk": "Preprocessing tokens in directive-specification of \n #pragma and _Pragma pragmas are subject to macro expansion.\nC / C++ \nC++ \n In C++11 and higher, an OpenMP directive may be specified as a C++ attribute specifier: \n [[ omp :: directive-attr ]] \n or \n [[ using omp : directive-attr ]] \n where directive-attr is \n directive( directive-specification ) \n or \n sequence( [omp::]directive-attr [[, [omp::]directive-attr] ...] ) \n Multiple attributes on the same statement are allowed.Attribute directives that apply to the same \n statement are unordered unless the sequence attribute is specified, in which case the right-to-left \n ordering applies.The omp:: namespace qualifier within a sequence attribute is optional.The \n application of multiple attributes in a sequence attribute is ordered as if each directive had been \n specified as a pragma directive on subsequent lines."}
{"section_title": "3.1 Directive Format", "chunk": "The \n application of multiple attributes in a sequence attribute is ordered as if each directive had been \n specified as a pragma directive on subsequent lines.\n \n Note \u2013 This example shows the expected transformation: \n [[ omp::sequence(directive(parallel), directive(for)) ]] \n for(...) {} \n // becomes \n #pragma omp parallel \n #pragma omp for \n for(...) {} \n \n The use of omp as the attribute namespace of an attribute specifier, or as the optional namespace \n qualifier within a sequence attribute, is reserved for OpenMP directives that are defined in this \n specification.The use of ompx as the attribute namespace of an attribute specifier, or as the \n OpenMP API \u2013 Version 5.2 November 2021 \n optional namespace qualifier within a sequence attribute, is reserved for implementation-defined \n extensions to the OpenMP directives.\n The pragma and attribute forms are interchangeable for any OpenMP directive."}
{"section_title": "3.1 Directive Format", "chunk": "\n The pragma and attribute forms are interchangeable for any OpenMP directive.Some OpenMP \n directives may be composed of consecutive attribute specifiers if specified in their syntax.Any two \n consecutive attribute specifiers may be reordered or expressed as a single attribute specifier, as \n permitted by the base language, without changing the behavior of the OpenMP directive.\nC++ \nC / C++ \n Directives are case-sensitive.Each expression used in the OpenMP syntax inside of a clause must \n be a valid assignment-expression of the base language unless otherwise specified.\nC / C++ \nC++ \n Directives may not appear in constexpr functions or in constant expressions.\nC++ \nFortran \n An OpenMP directive for Fortran is specified with a stylized comment as follows: \n sentinel directive-specification \n All OpenMP compiler directives must begin with a directive sentinel."}
{"section_title": "3.1 Directive Format", "chunk": "\nC++ \nFortran \n An OpenMP directive for Fortran is specified with a stylized comment as follows: \n sentinel directive-specification \n All OpenMP compiler directives must begin with a directive sentinel.The format of a sentinel \n differs between fixed form and free form source files, as described in Section 3.1.1 and \n Section 3.1.2.In order to simplify the presentation, free form is used for the syntax of OpenMP \n directives for Fortran throughout this document, except as noted.\n Directives are case insensitive.Directives cannot be embedded within continued statements, and \n statements cannot be embedded within directives.Each expression used in the OpenMP syntax \n inside of a clause must be a valid expression of the base language unless otherwise specified.\nFortran \n A directive may be categorized as one of the following: \n \u2022 meta \n \u2022 declarative \n \u2022 executable \n \u2022 informational \n \u2022 utility \n \u2022 subsidiary \nCHAPTER 3."}
{"section_title": "3.1 Directive Format", "chunk": "\nFortran \n A directive may be categorized as one of the following: \n \u2022 meta \n \u2022 declarative \n \u2022 executable \n \u2022 informational \n \u2022 utility \n \u2022 subsidiary \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 51 \n Base language code can be associated with directives.The directive\u2019s association can be \n categorized as: \n \u2022 none \n \u2022 block-associated \n \u2022 loop-associated \n \u2022 declaration-associated \n \u2022 delimited \n \u2022 separating \n A directive and its associated base language code constitute a syntactic formation that follows the \n syntax given below.The end-directive in a specified formation refers to the paired end directive for \n the directive.An OpenMP construct is a formation for which the directive is executable.\n Directives with an association of none are not associated with any base language code."}
{"section_title": "3.1 Directive Format", "chunk": "\n Directives with an association of none are not associated with any base language code.The \n resulting formation therefore has the following syntax: \n directive \n Formations that result from a block-associated directive have the following syntax: \nC / C++ \n directive \n structured-block \nC / C++ \nFortran \n directive \n structured-block \n [end-directive] \n If structured-block is a loosely structured block, end-directive is required.If structured-block is a \n strictly structured block, end-directive is optional.An end-directive that immediately follows a \n directive and its associated strictly structured block is always paired with that directive.\nFortran \n Loop-associated directives are block-associated directives for which the associated structured-block \n is loop-nest, a canonical loop nest.\nFortran \n For a loop-associated directive, the paired end directive is optional."}
{"section_title": "3.1 Directive Format", "chunk": "\nFortran \n For a loop-associated directive, the paired end directive is optional.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n Formations that result from a declaration-associated directive have the following syntax: \n declaration-associated-specification \n where declaration-associated-specification is either: \n directive \n function-definition-or-declaration \n or: \n directive \n declaration-associated-specification \n In all cases the directive is associated with the function-definition-or-declaration.\nC / C++ \nFortran \n The formation that results from a declaration-associated directive in Fortran has the same syntax as \n the formation for a directive with an association of none.\n If a directive appears in the specification part of a module then the behavior is as if that directive \n appears after any references to that module."}
{"section_title": "3.1 Directive Format", "chunk": "\n If a directive appears in the specification part of a module then the behavior is as if that directive \n appears after any references to that module.\nFortran \n The formation that results from a delimited directive has the following syntax: \n directive \n base-language-code \n end-directive \n Separating directives may be used to separate a structured-block into multiple \n structured-block-sequences.\n Separating directives and the containing structured block have the following syntax: \n structured-block-sequence \n directive \n structured-block-sequence \n [directive \n structured-block-sequence ...] \n wrapped in a single compound statement for C/C++ or optionally wrapped in a single BLOCK \n construct for Fortran.\nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 53 \n Restrictions \n Restrictions to directive format are as follows: \n \u2022 Orphaned separating directives are prohibited."}
{"section_title": "3.1 Directive Format", "chunk": "DIRECTIVE AND CONSTRUCT SYNTAX 53 \n Restrictions \n Restrictions to directive format are as follows: \n \u2022 Orphaned separating directives are prohibited.That is, the separating directives must appear \n within the structured block associated with the same construct with which it is associated and \n must not be encountered elsewhere in the region of that associated construct.\n \u2022 A stand-alone directive may be placed only at a point where a base language executable \n statement is allowed.\nFortran \n \u2022 OpenMP directives, except simd and declarative directives, may not appear in pure procedures.\n \u2022 OpenMP directives may not appear in the WHERE, FORALL or DO CONCURRENT constructs.\nFortran \nC++ \n \u2022 A directive that uses the attribute syntax cannot be applied to the same statement or associated \n declaration as a directive that uses the pragma syntax.\n \u2022 For any directive that has a paired end directive, both directives must use either the attribute \n syntax or the pragma syntax."}
{"section_title": "3.1 Directive Format", "chunk": "\n \u2022 For any directive that has a paired end directive, both directives must use either the attribute \n syntax or the pragma syntax.\n \u2022 Neither a stand-alone directive nor a declarative directive may be used in place of a substatement \n in a selection statement or iteration statement, or in place of the statement that follows a label.\nC++ \nC \n \u2022 Neither a stand-alone directive nor a declarative directive may be used in place of a substatement \n in a selection statement, in place of the loop body in an iteration statement, or in place of the \n statement that follows a label.\nC \nFortran \n"}
{"section_title": "3.1.1 Fixed Source Form Directives", "chunk": "20 The following sentinels are recognized in fixed form source files: \n !$omp | c$omp | *$omp | !$omx | c$omx | *$omx \n The sentinels that end with omp are reserved for OpenMP directives that are defined in this \n specification.The sentinels that end with omx are reserved for implementation-defined extensions \n to the OpenMP directives.\n OpenMP API \u2013 Version 5.2 November 2021 \n Sentinels must start in column 1 and appear as a single word with no intervening characters.\n Fortran fixed form line length, white space, continuation, and column rules apply to the directive \n line.Initial directive lines must have a space or a zero in column 6, and continuation directive lines \n must have a character other than a space or a zero in column 6.\n Comments may appear on the same line as a directive.The exclamation point initiates a comment \n when it appears after column 6.The comment extends to the end of the source line and is ignored."}
{"section_title": "3.1.1 Fixed Source Form Directives", "chunk": "The comment extends to the end of the source line and is ignored.\n If the first non-blank character after the directive sentinel of an initial or continuation directive line \n is an exclamation point, the line is ignored.\n \n Note \u2013 In the following example, the three formats for specifying the directive are equivalent (the \n first line represents the position of the first 9 columns): \n c23456789 \n !$omp parallel do shared(a,b,c) \n \n c$omp parallel do \n c$omp+shared(a,b,c) \n \n c$omp paralleldoshared(a,b,c) \n \nFortran \nFortran \n"}
{"section_title": "3.1.2 Free Source Form Directives", "chunk": "21 The following sentinels are recognized in free form source files: \n !$omp | !$ompx \n The !$omp sentinel is reserved for OpenMP directives that are defined in this specification.The \n !$ompx sentinel is reserved for implementation-defined extensions to the OpenMP directives.\n The sentinel can appear in any column as long as it is preceded only by white space.It must appear \n as a single word with no intervening white space.Fortran free form line length and white space \n rules apply to the directive line.Initial directive lines must have a space after the sentinel.The \n initial line of a directive must not be a continuation line for a base language statement.Fortran free \n form continuation rules apply."}
{"section_title": "3.1.2 Free Source Form Directives", "chunk": "Fortran free \n form continuation rules apply.Thus, continued directive lines must have an ampersand (&) as the \n last non-blank character on the line, prior to any comment placed inside the directive; continuation \n directive lines can have an ampersand after the directive sentinel with optional white space before \n and after the ampersand.\n Comments may appear on the same line as a directive.The exclamation point (!) initiates a \n comment.The comment extends to the end of the source line and is ignored.If the first non-blank \n character after the directive sentinel is an exclamation point, the line is ignored.\nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 55 \n One or more blanks or horizontal tabs are optional to separate adjacent keywords in \n directive-names unless otherwise specified."}
{"section_title": "3.1.2 Free Source Form Directives", "chunk": "DIRECTIVE AND CONSTRUCT SYNTAX 55 \n One or more blanks or horizontal tabs are optional to separate adjacent keywords in \n directive-names unless otherwise specified.\n \n Note \u2013 In the following example the three formats for specifying the directive are equivalent (the \n first line represents the position of the first 9 columns): \n !23456789 \n !$omp parallel do & \n !$omp shared(a,b,c) \n \n !$omp parallel & \n !$omp&do shared(a,b,c) \n \n !$omp paralleldo shared(a,b,c) \n \nFortran \n"}
{"section_title": "3.2 Clause Format", "chunk": "16 This section defines the format and categories of OpenMP clauses.OpenMP clauses are specified \n as part of a directive-specification.Clauses are optional and, thus, may be omitted from a \n directive-specification unless otherwise specified.The order in which clauses appear on directives \n is not significant unless otherwise specified.A clause-specification specifies each OpenMP clause \n in a directive-specification where clause-specification for inarguable clauses is simply: \n clause-name \n Inarguable clauses often form natural groupings that have similar semantic effect and so are \n frequently specified as a clause grouping.For argument-modified clauses, clause-specification is: \n clause-name[(clause-argument-specification [; clause-argument-specification [;...]])] \nC / C++ \n White space in a clause-name is prohibited.White space within a clause-argument-specification \n and between another clause-argument-specification is optional."}
{"section_title": "3.2 Clause Format", "chunk": "White space within a clause-argument-specification \n and between another clause-argument-specification is optional.\nC / C++ \n An implementation may allow clauses with clause names that start with the ompx_ prefix for use \n on any OpenMP directive, and the format and semantics of any such clause is implementation \n defined.All other clause names are reserved.\n For argument-modified clauses, the first clause-argument-specification is required unless otherwise \n explicitly stated while additional ones are only permitted on clauses that explicitly allow them.\n When the first one is omitted, the syntax is identical to an inarguable clause.Clause arguments may \n be unmodified or modified.For an unmodified argument, clause-argument-specification is: \n OpenMP API \u2013 Version 5.2 November 2021 \n clause-argument-list \n Unless otherwise specified, modified arguments are pre-modified, for which the format is: \n [modifier-specification [[, modifier-specification] ,..."}
{"section_title": "3.2 Clause Format", "chunk": "For an unmodified argument, clause-argument-specification is: \n OpenMP API \u2013 Version 5.2 November 2021 \n clause-argument-list \n Unless otherwise specified, modified arguments are pre-modified, for which the format is: \n [modifier-specification [[, modifier-specification] ,...] :]clause-argument-list \n A few modified arguments are explicitly specified as post-modified, for which the format is: \n clause-argument-list[: modifier-specification [[, modifier-specification] ,...]] \n For many OpenMP clauses, clause-argument-list is an OpenMP argument list, which is a \n comma-separated list of a specific kind of list items (see Section 3.2.1), in which case the format of \n clause-argument-list is: \n argument-name \n For all other OpenMP clauses, clause-argument-list is a comma-separated list of arguments so the \n format is: \n argument-name [, argument-name [,..."}
{"section_title": "3.2 Clause Format", "chunk": "]] \n For many OpenMP clauses, clause-argument-list is an OpenMP argument list, which is a \n comma-separated list of a specific kind of list items (see Section 3.2.1), in which case the format of \n clause-argument-list is: \n argument-name \n For all other OpenMP clauses, clause-argument-list is a comma-separated list of arguments so the \n format is: \n argument-name [, argument-name [,...]] \n In most of these cases, the list only has a single item so the format of clause-argument-list is again: \n argument-name \n In all cases, white space in clause-argument-list is optional.\n Clause argument modifiers may be simple or complex.Almost all clause arguments are simple, for \n which the format of modifier-specification is: \n modifier-name \n The format of a complex modifier is: \n modifier-name(modifier-parameter-specification) \n where modifier-parameter-specification is a comma-separated list of arguments as defined above for \n clause-argument-list."}
{"section_title": "3.2 Clause Format", "chunk": "Almost all clause arguments are simple, for \n which the format of modifier-specification is: \n modifier-name \n The format of a complex modifier is: \n modifier-name(modifier-parameter-specification) \n where modifier-parameter-specification is a comma-separated list of arguments as defined above for \n clause-argument-list.The position of each modifier-argument-name in the list is significant.\n Each argument-name and modifier-name is an OpenMP term that may be used in the definitions of \n the clause and any directives on which the clause may appear.Syntactically, each of these terms is \n one of the following: \n \u2022 keyword: An OpenMP keyword \n \u2022 OpenMP identifier: An OpenMP identifier \n \u2022 OpenMP argument list: An OpenMP argument list \n \u2022 expression: An expression of some OpenMP type \n \u2022 OpenMP stylized expression: An OpenMP stylized expression \nCHAPTER 3."}
{"section_title": "3.2 Clause Format", "chunk": "Syntactically, each of these terms is \n one of the following: \n \u2022 keyword: An OpenMP keyword \n \u2022 OpenMP identifier: An OpenMP identifier \n \u2022 OpenMP argument list: An OpenMP argument list \n \u2022 expression: An expression of some OpenMP type \n \u2022 OpenMP stylized expression: An OpenMP stylized expression \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 57 \n A particular lexical instantiation of an argument specifies a parameter of the clause, while a lexical \n instantiation of a modifier and its parameters affects how or when the argument is applied.\n The order of arguments must match the order in the clause-specification.The order of modifiers in \n a clause-argument-specification is not significant unless otherwise specified.\n General syntactic properties govern the use of clauses, clause and directive arguments, and \n modifiers in an OpenMP directive.These properties are summarized in Table 3.1, along with the \n respective default properties for clauses, arguments and modifiers."}
{"section_title": "3.2 Clause Format", "chunk": "These properties are summarized in Table 3.1, along with the \n respective default properties for clauses, arguments and modifiers.\nTABLE 3.1: Syntactic Properties for Clauses, Arguments and Modifiers \nProperty Property Description Inverse \nProperty \nClause \ndefaults \nArgument \ndefaults \nModifier \ndefaults \nrequired must be present optional optional required optional \nunique may appear at most once repeatable repeatable unique unique \nexclusive must appear alone compatible compatible compatible compatible \nultimate must lexically appear last \n(or first for a modifier in \na post-modified clause) \nfree free free free \n A clause, argument or modifier with a given property implies that it does not have the \n corresponding inverse property, and vice versa.The ultimate property implies the unique property.\n If all arguments and modifiers of an argument-modified clause or directive are optional and omitted \n then the parentheses of the syntax for the clause or directive is also omitted."}
{"section_title": "3.2 Clause Format", "chunk": "\n If all arguments and modifiers of an argument-modified clause or directive are optional and omitted \n then the parentheses of the syntax for the clause or directive is also omitted.\n Arguments and modifiers that are expressions may additionally have any of the following value \n properties: constant, positive, non-negative, and region-invariant.\n \n Note \u2013 In this example, clause-specification is depend(inout: d), clause-name is depend \n and clause-argument-specification is inout: d.The depend clause has an argument for which \n argument-name is locator-list, which syntactically is the OpenMP locator list d in the example.\n Similarly, the depend clause accepts a simple clause modifier with the name \n task-dependence-type.Syntactically, task-dependence-type is the keyword inout in the example.\n #pragma omp depobj(o) depend(inout: d) \n \n The clauses that a directive accepts may form sets."}
{"section_title": "3.2 Clause Format", "chunk": "\n #pragma omp depobj(o) depend(inout: d) \n \n The clauses that a directive accepts may form sets.These sets may imply restrictions on their use \n on that directive or may otherwise capture properties for the clauses on the directive.While specific \n properties may be defined for a clause set on a particular directive, the following clause-set \n properties have general meanings and implications as indicated by the restrictions below: required, \n unique, and exclusive.\n OpenMP API \u2013 Version 5.2 November 2021 \n All clauses that are specified as a clause grouping form a clause set for which properties are \n specified with the specification of the grouping.Some directives accept a clause grouping for which \n each member is a directive-name of a directive that has a specific property.These groupings are \n required, unique and exclusive unless otherwise specified."}
{"section_title": "3.2 Clause Format", "chunk": "These groupings are \n required, unique and exclusive unless otherwise specified.\n Restrictions \n Restrictions to clauses and clause sets are as follows: \n \u2022 A required clause for a directive must appear on the directive.\n \u2022 A unique clause for a directive may appear at most once on the directive.\n \u2022 An exclusive clause for a directive must not appear if a clause with a different clause-name also \n appears on the directive.\n \u2022 An ultimate clause for a directive must be the lexically last clause to appear on the directive.\n \u2022 If a clause set has the required property, at least one clause in the set must be present on the \n directive for which the clause set is specified.\n \u2022 If a clause is a member of a set that has the unique property for a directive then the clause has the \n unique property for that directive regardless of whether it has the unique property when it is not \n part of such a set."}
{"section_title": "3.2 Clause Format", "chunk": "\n \u2022 If a clause is a member of a set that has the unique property for a directive then the clause has the \n unique property for that directive regardless of whether it has the unique property when it is not \n part of such a set.\n \u2022 If one clause of a clause set with the exclusive property appears on a directive, no other clauses \n with a different clause-name in that set may appear on the directive.\n \u2022 A required argument must appear in the clause-specification.\n \u2022 A unique argument may appear at most once in a clause-argument-specification.\n \u2022 An exclusive argument must not appear if an argument with a different argument-name appears \n in the clause-argument-specification.\n \u2022 A required modifier must appear in the clause-argument-specification.\n \u2022 A unique modifier may appear at most once in a clause-argument-specification."}
{"section_title": "3.2 Clause Format", "chunk": "\n \u2022 A unique modifier may appear at most once in a clause-argument-specification.\n \u2022 An exclusive modifier must not appear if a modifier with a different modifier-name also appears \n in the clause-argument-specification.\n \u2022 If a clause is pre-modified, an ultimate modifier must be the last modifier in a \n clause-argument-specification in which any modifier appears.\n \u2022 If a clause is post-modified, an ultimate modifier must be the first modifier in a \n clause-argument-specification in which any modifier appears.\n \u2022 A modifier that is an expression must neither lexically match the name of a simple modifier \n defined for the clause that is an OpenMP keyword nor modifier-name parenthesized-tokens, \n where modifier-name is the modifier-name of a complex modifier defined for the clause and \n parenthesized-tokens is a token sequence that starts with ( and ends with ).\nCHAPTER 3."}
{"section_title": "3.2 Clause Format", "chunk": "\nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 59 \n \u2022 A constant argument or parameter must be a compile-time constant.\n \u2022 A positive argument or parameter must be greater than zero; a non-negative argument or \n parameter must be greater than or equal to zero.\n \u2022 A region-invariant argument or parameter must have the same value throughout any given \n execution of the construct or, for declarative directives, execution of the function or subroutine \n with which the declaration is associated.\n Cross References \n \u2022 Directive Format, see Section 3.1 \n \u2022 OpenMP Argument Lists, see Section 3.2.1 \n \u2022 OpenMP Stylized Expressions, see Section 4.2 \n \u2022 OpenMP Types and Identifiers, see Section 4.1 \n"}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "13 The OpenMP API defines several kinds of lists, each of which can be used as syntactic instances of \n clause arguments.A list of any OpenMP type consists of a comma-separated collection of \n expressions of that OpenMP type.A variable list consists of a comma-separated collection of one \n or more variable list items.An extended list consists of a comma-separated collection of one or \n more extended list items.A locator list consists of a comma-separated collection of one or more \n locator list items.A parameter list consists of a comma-separated collection of one or more \n parameter list items.A type-name list consists of a comma-separated collection of one or more \n type-name list items.A directive-name list consists of a comma-separated collection of one or more \n directive-name list items, each of which is the directive-name of some OpenMP directive."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "A directive-name list consists of a comma-separated collection of one or more \n directive-name list items, each of which is the directive-name of some OpenMP directive.A foreign \n runtime preference list consists of a comma-separated collection of one or more foreign-runtime list \n items each of which is an OpenMP foreign-runtime identifier; the order of list items on a foreign \n runtime preference list is significant.An OpenMP operation list consists of a comma-separated \n collection of one or more OpenMP operation list items, each of which is an OpenMP operation \n defined in Section 3.2.3; the order of the list items in an OpenMP operation list is significant.\nC / C++ \n A variable list item is a variable or an array section.An extended list item is a variable list item or a \n function name.A locator list item is any lvalue expression including variables, array sections, and \n reserved locators.A parameter list item is the name of a function parameter."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "A parameter list item is the name of a function parameter.A type-name list item \n is a type name.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n A variable list item is one of the following: \n \u2022 a variable that is not coindexed and that is not a substring; \n \u2022 an array section that is not coindexed and that does not contain an element that is a substring; \n \u2022 a named constant; \n \u2022 an associate name that may appear in a variable definition context; or \n \u2022 a common block name (enclosed in slashes).\n An extended list item is a variable list item or a procedure name.A locator list item is a variable list \n item, or a reserved locator.A parameter list item is a dummy argument of a subroutine or function.\n A type-name list item is a type specifier that must not be CLASS(*) or an abstract type.\n A named constant as a list item can appear only in clauses where it is explicitly allowed."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "\n A named constant as a list item can appear only in clauses where it is explicitly allowed.\n When a named common block appears in an OpenMP argument list, it has the same meaning and \n restrictions as if every explicit member of the common block appeared in the list.An explicit \n member of a common block is a variable that is named in a COMMON statement that specifies the \n common block name and is declared in the same scoping unit in which the clause appears.Named \n common blocks do not include the blank common block.\n Although variables in common blocks can be accessed by use association or host association, \n common block names cannot.As a result, a common block name specified in a clause must be \n declared to be a common block in the same scoping unit in which the clause appears.\n If a list item that appears in a directive or clause is an optional dummy argument that is not present, \n the directive or clause for that list item is ignored."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "\n If a list item that appears in a directive or clause is an optional dummy argument that is not present, \n the directive or clause for that list item is ignored.\n If the variable referenced inside a construct is an optional dummy argument that is not present, any \n explicitly determined, implicitly determined, or predetermined data-sharing and data-mapping \n attribute rules for that variable are ignored.Otherwise, if the variable is an optional dummy \n argument that is present, it is present inside the construct.\nFortran \n Restrictions \n The restrictions to OpenMP lists are as follows: \n \u2022 Unless otherwise specified, OpenMP list items must be directive-wide unique, i.e., a list item can \n only appear once in one OpenMP list of all arguments, clauses, and modifiers of the directive.\n \u2022 All list items must be visible, according to the scoping rules of the base language."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "\n \u2022 All list items must be visible, according to the scoping rules of the base language.\nC \n \u2022 Unless otherwise specified, a variable that is part of another variable (as an array element or a \n structure element) cannot be a variable list item, an extended list item or a locator list item.\nC \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 61 \nC++ \n \u2022 Unless otherwise specified, a variable that is part of another variable (as an array element or a \n structure element) cannot be a variable list item, an extended list item or locator list item except \n if the list appears on a clause that is associated with a construct within a class non-static member \n function and the variable is an accessible data member of the object for which the non-static \n member function is invoked."}
{"section_title": "3.2.1 OpenMP Argument Lists", "chunk": "DIRECTIVE AND CONSTRUCT SYNTAX 61 \nC++ \n \u2022 Unless otherwise specified, a variable that is part of another variable (as an array element or a \n structure element) cannot be a variable list item, an extended list item or locator list item except \n if the list appears on a clause that is associated with a construct within a class non-static member \n function and the variable is an accessible data member of the object for which the non-static \n member function is invoked.\nC++ \nFortran \n \u2022 Unless otherwise specified, a variable that is part of another variable (as an array element or a \n structure element) cannot be a variable list item, an extended list item or locator list item.\nFortran \n"}
{"section_title": "3.2.2 Reserved Locators", "chunk": "9 On some directives, some clauses accept the use of reserved locators as special identifiers that \n represent system storage not necessarily bound to any base language storage item.Reserved \n locators may only appear in clauses and directives where they are explicitly allowed and may not \n otherwise be referenced in the program.The list of reserved locators is: \n omp_all_memory \n The reserved locator omp_all_memory is a reserved identifier that denotes a list item treated as \n having storage that corresponds to the storage of all other objects in memory.\n"}
{"section_title": "3.2.3 OpenMP Operations", "chunk": "17 On some directives, some clauses accept the use of OpenMP operations.An OpenMP operation \n named <generic_name> is a special expression that may be specified in an OpenMP operation list \n and that is used to construct an object of the <generic_name> OpenMP type (see Section 4.1).In \n general, the format of an OpenMP operation is the following: \n <generic_name>(operation-parameter-specification) \n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n"}
{"section_title": "3.2.4 Array Shaping", "chunk": "2 If an expression has a type of pointer to T, then a shape-operator can be used to specify the extent of \n that pointer.In other words, the shape-operator is used to reinterpret, as an n-dimensional array, the \n region of memory to which that expression points.\n Formally, the syntax of the shape-operator is as follows: \n shaped-expression := ([s1][s2]...[sn])cast-expression \n The result of applying the shape-operator to an expression is an lvalue expression with an \n n-dimensional array type with dimensions s1 \u00d7 s2 ...\u00d7 sn and element type T.\n The precedence of the shape-operator is the same as a type cast.\nEach si 10 is an integral type expression that must evaluate to a positive integer.\n Restrictions \n Restrictions to the shape-operator are as follows: \n \u2022 The type T must be a complete type.\n \u2022 The shape-operator can appear only in clauses for which it is explicitly allowed.\n \u2022 The result of a shape-operator must be a named array of a list item."}
{"section_title": "3.2.4 Array Shaping", "chunk": "\n \u2022 The result of a shape-operator must be a named array of a list item.\n \u2022 The type of the expression upon which a shape-operator is applied must be a pointer type.\nC++ \n \u2022 If the type T is a reference to a type T\u2019, then the type will be considered to be T\u2019 for all purposes \n of the designated array.\nC++ \nC / C++ \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 63 \n"}
{"section_title": "3.2.5 Array Sections", "chunk": "2 An array section designates a subset of the elements in an array.\nC / C++ \n To specify an array section in an OpenMP directive, array subscript expressions are extended with \n one of the following syntaxes: \n [ lower-bound : length : stride] \n [ lower-bound : length : ] \n [ lower-bound : length ] \n [ lower-bound : : stride] \n [ lower-bound : : ] \n [ lower-bound : ] \n [ : length : stride] \n [ : length : ] \n [ : length ] \n [ : : stride] \n [ : : ] \n [ : ] \n The array section must be a subset of the original array.\n Array sections are allowed on multidimensional arrays.Base language array subscript expressions \n can be used to specify length-one dimensions of multidimensional array sections.\n Each of the lower-bound, length, and stride expressions if specified must be an integral type \n expression of the base language.When evaluated they represent a set of integer values as follows: \n { lower-bound, lower-bound + stride, lower-bound + 2 * stride,..."}
{"section_title": "3.2.5 Array Sections", "chunk": "When evaluated they represent a set of integer values as follows: \n { lower-bound, lower-bound + stride, lower-bound + 2 * stride,..., lower-bound + ((length - 1) * \n stride) } \n The length must evaluate to a non-negative integer.\n The stride must evaluate to a positive integer.\n When the size of the array dimension is not known, the length must be specified explicitly.\n When the stride is absent it defaults to 1.\n When the length is absent it defaults to d(size \u2212 lower-bound)/stridee, where size is the size of the \n array dimension.\n When the lower-bound is absent it defaults to 0.\n OpenMP API \u2013 Version 5.2 November 2021 \nC/C++ (cont.) \n The precedence of a subscript operator that uses the array section syntax is the same as the \n precedence of a subscript operator that does not use the array section syntax."}
{"section_title": "3.2.5 Array Sections", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nC/C++ (cont.) \n The precedence of a subscript operator that uses the array section syntax is the same as the \n precedence of a subscript operator that does not use the array section syntax.\n \n Note \u2013 The following are examples of array sections: \n a[0:6] \n a[0:6:1] \n a[1:10] \n a[1:] \n a[:10:2] \n b[10][:][:] \n b[10][:][:0] \n c[42][0:6][:] \n c[42][0:6:2][:] \n c[1:10][42][0:6] \n S.c[:100] \n p->y[:10] \n this->a[:N] \n (p+10)[:N] \n Assume a is declared to be a 1-dimensional array with dimension size 11.The first two examples \n are equivalent, and the third and fourth examples are equivalent.The fifth example specifies a stride \n of 2 and therefore is not contiguous.\n Assume b is declared to be a pointer to a 2-dimensional array with dimension sizes 10 and 10.The \n sixth example refers to all elements of the 2-dimensional array given by b[10].The seventh \n example is a zero-length array section."}
{"section_title": "3.2.5 Array Sections", "chunk": "The seventh \n example is a zero-length array section.\n Assume c is declared to be a 3-dimensional array with dimension sizes 50, 50, and 50.The eighth \n example is contiguous, while the ninth and tenth examples are not contiguous.\n The final four examples show array sections that are formed from more general base expressions.\n The following are examples that are non-conforming array sections: \n s[:10].x \n p[:10]->y \n *(xp[:10]) \n For all three examples, a base language operator is applied in an undefined manner to an array \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 65 \n section.The only operator that may be applied to an array section is a subscript operator for which \n the array section appears as the postfix expression.\n \n \nC / C++ \nFortran \n Fortran has built-in support for array sections although some restrictions apply to their use in \n OpenMP directives, as enumerated in the following section."}
{"section_title": "3.2.5 Array Sections", "chunk": "\n \n \nC / C++ \nFortran \n Fortran has built-in support for array sections although some restrictions apply to their use in \n OpenMP directives, as enumerated in the following section.\nFortran \n Restrictions \n Restrictions to array sections are as follows: \n \u2022 An array section can appear only in clauses for which it is explicitly allowed.\n \u2022 A stride expression may not be specified unless otherwise stated.\nC / C++ \n \u2022 An element of an array section with a non-zero size must have a complete type.\n \u2022 The base expression of an array section must have an array or pointer type.\n \u2022 If a consecutive sequence of array subscript expressions appears in an array section, and the first \n subscript expression in the sequence uses the extended array section syntax defined in this \n section, then only the last subscript expression in the sequence may select array elements that \n have a pointer type."}
{"section_title": "3.2.5 Array Sections", "chunk": "\n \u2022 If a consecutive sequence of array subscript expressions appears in an array section, and the first \n subscript expression in the sequence uses the extended array section syntax defined in this \n section, then only the last subscript expression in the sequence may select array elements that \n have a pointer type.\nC / C++ \nC++ \n \u2022 If the type of the base expression of an array section is a reference to a type T, then the type will \n be considered to be T for all purposes of the array section.\n \u2022 An array section cannot be used in an overloaded [] operator.\nC++ \nFortran \n \u2022 If a stride expression is specified, it must be positive.\n \u2022 The upper bound for the last dimension of an assumed-size dummy array must be specified.\n \u2022 If a list item is an array section with vector subscripts, the first array element must be the lowest \n in the array element order of the array section."}
{"section_title": "3.2.5 Array Sections", "chunk": "\n \u2022 If a list item is an array section with vector subscripts, the first array element must be the lowest \n in the array element order of the array section.\n \u2022 If a list item is an array section, the last part-ref of the list item must have a section subscript list.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "3.2.6 iterator Modifier", "chunk": "2 Modifiers \nName Modifies Type Properties \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \nunique \n \n Clauses \n affinity, depend, from, map, to \n An iterator modifier is a unique, complex modifier that defines a set of iterators, each of which is an \n iterator-identifier and an associated set of values.An iterator-identifier expands to those values in \n the clause argument for which it is specified.Each member of the modifier-parameter-specification \n list of an iterator modifier is an iterator-specifier with this format: \nC / C++ \n [ iterator-type ] iterator-identifier = range-specification \nC / C++ \nFortran \n [ iterator-type :: ] iterator-identifier = range-specification \nFortran \n where: \n \u2022 iterator-identifier is a base-language identifier.\n \u2022 iterator-type is a type that is permitted in a type-name list."}
{"section_title": "3.2.6 iterator Modifier", "chunk": "\n \u2022 iterator-type is a type that is permitted in a type-name list.\n \u2022 range-specification is of the form begin:end[:step], where begin and end are expressions for \n which their types can be converted to iterator-type and step is an integral expression.\nC / C++ \n In an iterator-specifier, if the iterator-type is not specified then that iterator is of int type.\nC / C++ \nFortran \n In an iterator-specifier, if the iterator-type is not specified then that iterator has default integer type.\nFortran \n In a range-specification, if the step is not specified its value is implicitly defined to be 1.\n An iterator only exists in the context of the clause argument that it modifies.An iterator also hides \n all accessible symbols with the same name in the context of that clause argument.\n The use of a variable in an expression that appears in the range-specification causes an implicit \n reference to the variable in all enclosing constructs.\nCHAPTER 3."}
{"section_title": "3.2.6 iterator Modifier", "chunk": "\nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 67 \nC / C++ \n The values of the iterator are the set of values i0, ..., iN\u22121 where: \n \u2022 i0 = (iterator-type) begin; \n \u2022 ij = (iterator-type) (ij\u22121 + step), where j \u2265 1; and \n \u2022 if step > 0, \n \u2013 i0 < (iterator-type) end; \n \u2013 iN\u22121 < (iterator-type) end; and \n \u2013 (iterator-type) (iN\u22121 + step) \u2265 (iterator-type) end; \n \u2022 if step < 0, \n \u2013 i0 > (iterator-type) end; \n \u2013 iN\u22121 > (iterator-type) end; and \n \u2013 (iterator-type) (iN\u22121 + step) \u2264 (iterator-type) end.\nC / C++ \nFortran \n The values of the iterator are the set of values i1, ..., iN where: \n \u2022 i1 = begin; \n \u2022 ij = ij\u22121 + step, where j \u2265 2; and \n \u2022 if step > 0, \n \u2013 i1 \u2264 end; \n \u2013 iN \u2264 end; and \n \u2013 iN + step > end; \n \u2022 if step < 0, \n \u2013 i1 \u2265 end; \n \u2013 iN \u2265 end; and \n \u2013 iN + step < end.\nFortran \n The set of values will be empty if no possible value complies with the conditions above."}
{"section_title": "3.2.6 iterator Modifier", "chunk": "\nFortran \n The set of values will be empty if no possible value complies with the conditions above.\n If an iterator-identifier appears in a list-item expression of the modified argument, the effect is as if \n the list item is instantiated within the clause for each member of the iterator value set, substituting \n each occurrence of iterator-identifier in the list-item expression with the iterator value.If the \n iterator value set is empty then the effect is as if the list item was not specified.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to iterator modifiers are as follows: \n \u2022 The iterator-type must not declare a new type.\n \u2022 For each value i in an iterator value set, the mathematical result of i + step must be \n representable in iterator-type.\nC / C++ \n \u2022 The iterator-type must be an integral or pointer type.\n \u2022 The iterator-type must not be const qualified.\nC / C++ \nFortran \n \u2022 The iterator-type must be an integer type."}
{"section_title": "3.2.6 iterator Modifier", "chunk": "\nC / C++ \nFortran \n \u2022 The iterator-type must be an integer type.\nFortran \n \u2022 If the step expression of a range-specification equals zero, the behavior is unspecified.\n \u2022 Each iterator-identifier can only be defined once in the modifier-parameter-specification.\n \u2022 Iterators cannot appear in the range-specification.\n Cross References \n \u2022 affinity clause, see Section 12.5.1 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 from clause, see Section 5.9.2 \n \u2022 map clause, see Section 5.8.3 \n \u2022 to clause, see Section 5.9.1 \n"}
{"section_title": "3.3 Conditional Compilation", "chunk": "19 In implementations that support a preprocessor, the _OPENMP macro name is defined to have the \n decimal value yyyymm where yyyy and mm are the year and month designations of the version of \n the OpenMP API that the implementation supports.\n If a #define or a #undef preprocessing directive in user code defines or undefines the \n _OPENMP macro name, the behavior is unspecified.\nFortran \n The OpenMP API requires Fortran lines to be compiled conditionally, as described in the following \n sections.\nFortran \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 69 \nFortran \n"}
{"section_title": "3.3.1 Fixed Source Form Conditional Compilation Sentinels", "chunk": "2 The following conditional compilation sentinels are recognized in fixed form source files: \n !$ | *$ | c$ \n To enable conditional compilation, a line with a conditional compilation sentinel must satisfy the \n following criteria: \n \u2022 The sentinel must start in column 1 and appear as a single word with no intervening white space; \n \u2022 After the sentinel is replaced with two spaces, initial lines must have a space or zero in column 6 \n and only white space and numbers in columns 1 through 5; and \n \u2022 After the sentinel is replaced with two spaces, continuation lines must have a character other than \n a space or zero in column 6 and only white space in columns 1 through 5.\n If these criteria are met, the sentinel is replaced by two spaces.If these criteria are not met, the line \n is left unchanged."}
{"section_title": "3.3.1 Fixed Source Form Conditional Compilation Sentinels", "chunk": "If these criteria are not met, the line \n is left unchanged.\n \n Note \u2013 In the following example, the two forms for specifying conditional compilation in fixed \n source form are equivalent (the first line represents the position of the first 9 columns): \n c23456789 \n !$ 10 iam = omp_get_thread_num() + \n !$ & index \n \n #ifdef _OPENMP \n 10 iam = omp_get_thread_num() + \n & index \n #endif \n \n \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n"}
{"section_title": "3.3.2 Free Source Form Conditional Compilation Sentinel", "chunk": "2 The following conditional compilation sentinel is recognized in free form source files: \n !$ \n To enable conditional compilation, a line with a conditional compilation sentinel must satisfy the \n following criteria: \n \u2022 The sentinel can appear in any column but must be preceded only by white space; \n \u2022 The sentinel must appear as a single word with no intervening white space; \n \u2022 Initial lines must have a blank character after the sentinel; and \n \u2022 Continued lines must have an ampersand as the last non-blank character on the line, prior to any \n comment appearing on the conditionally compiled line.\n Continuation lines can have an ampersand after the sentinel, with optional white space before and \n after the ampersand.If these criteria are met, the sentinel is replaced by two spaces.If these criteria \n are not met, the line is left unchanged."}
{"section_title": "3.3.2 Free Source Form Conditional Compilation Sentinel", "chunk": "If these criteria \n are not met, the line is left unchanged.\n \n Note \u2013 In the following example, the two forms for specifying conditional compilation in free \n source form are equivalent (the first line represents the position of the first 9 columns): \n c23456789 \n !$ iam = omp_get_thread_num() + & \n !$& index \n \n #ifdef _OPENMP \n iam = omp_get_thread_num() + & \n index \n #endif \n \n \nFortran \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 71 \n"}
{"section_title": "3.4 if Clause", "chunk": "2 Name: if Properties: default \n Arguments \nName Type Properties \nif-expression expression of logical type default 4 \n Modifiers \nName Modifies Type Properties \ndirective-name\ufffemodifier \nif-expression Keyword: \ndirective-name \n unique \n Directives \n cancel, parallel, simd, target, target data, target enter data, target \n exit data, target update, task, taskloop \n Semantics \n If no directive-name-modifier is specified then the effect is as if a directive-name-modifier was \n specified with the directive-name of the directive on which the clause appears.\n The effect of the if clause depends on the construct to which it is applied.If the construct is not a \n combined or composite construct then the effect is described in the section that describes that \n construct.For combined or composite constructs, the if clause only applies to the semantics of the \n construct named in the directive-name-modifier."}
{"section_title": "3.4 if Clause", "chunk": "For combined or composite constructs, the if clause only applies to the semantics of the \n construct named in the directive-name-modifier.For a combined or composite construct, if no \n directive-name-modifier is specified then the if clause applies to all constituent constructs to \n which an if clause can apply.\n Restrictions \n Restrictions to the if clause are as follows: \n \u2022 At most one if clause can be specified that applies to the semantics of any construct or \n constituent construct of a directive-specification.\n \u2022 The directive-name-modifier must specify the directive-name of the construct or of a constituent \n construct of the directive-specification on which the if clause appears."}
{"section_title": "3.4 if Clause", "chunk": "\n \u2022 The directive-name-modifier must specify the directive-name of the construct or of a constituent \n construct of the directive-specification on which the if clause appears.\n Cross References \n \u2022 cancel directive, see Section 16.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 simd directive, see Section 10.4 \n \u2022 target data directive, see Section 13.5 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "3.5 destroy Clause", "chunk": "6 Name: destroy Properties: default \n Arguments \nName Type Properties \ndestroy-var variable of OpenMP variable type default 8 \n Directives \n depobj, interop \n Additional information \n When the destroy clause appears on the depobj construct, the destroy-var argument may be \n omitted.This syntax has been deprecated.\n Semantics \n If the destroy clause appears on a depobj construct and destroy-var is not specified, the effect \n is as if destroy-var refers to the same OpenMP depend object as the depobj argument of the \n construct.The syntax of the destroy clause on the depobj construct that does not specify \n destroy-var has been deprecated.When the destroy clause appears on a depobj construct, the \n state of destroy-var is set to uninitialized."}
{"section_title": "3.5 destroy Clause", "chunk": "When the destroy clause appears on a depobj construct, the \n state of destroy-var is set to uninitialized.\n When the destroy clause appears on an interop construct, the interop-type is inferred based \n on the interop-type used to initialize destroy-var, and destroy-var is set to the value of \n omp_interop_none after resources associated with destroy-var are released.The object \n referred to by destroy-var is unusable after destruction and the effect of using values associated \n with it is unspecified until it is initialized again by another interop construct.\n Restrictions \n \u2022 destroy-var must be non-const.\n \u2022 If the destroy clause appears on a depobj construct, destroy-var must refer to the same \n depend object as the depobj argument of the construct.\n \u2022 If the destroy clause appears on an interop construct destroy-var must refer to a variable of \n OpenMP interop type."}
{"section_title": "3.5 destroy Clause", "chunk": "\n \u2022 If the destroy clause appears on an interop construct destroy-var must refer to a variable of \n OpenMP interop type.\n Cross References \n \u2022 depobj directive, see Section 15.9.4 \n \u2022 interop directive, see Section 14.1 \nCHAPTER 3.DIRECTIVE AND CONSTRUCT SYNTAX 73 \n"}
{"section_title": "4 Base Language Formats and Restrictions", "chunk": "2 Restrictions \n This section defines concepts and restrictions on base language code used in OpenMP.The concepts \n help support base language neutrality for OpenMP directives and their associated semantics.\n Restrictions \n The following restrictions apply generally for base language code in an OpenMP program: \n \u2022 Programs must not declare names that begin with the omp_ or ompx_ prefix, as these are \n reserved for the OpenMP implementation.\nC++ \n \u2022 Programs must not declare a namespace with the omp or ompx names, as these are reserved for \n the OpenMP implementation.\nC++ \n"}
{"section_title": "4.1 OpenMP Types and Identifiers", "chunk": "12 An OpenMP identifier is a special identifier for use within OpenMP directives and clauses for some \n specific purpose.For example, OpenMP reduction identifiers specify the combiner operation to use \n in a reduction, OpenMP mapper identifiers specify the name of a user-defined mapper, and \n OpenMP foreign runtime identifiers specify the name of a foreign runtime.\n Generic OpenMP types specify the type of expression or variable that is used in OpenMP contexts \n regardless of the base language.These types support the definition of many important OpenMP \n concepts independently of the base language in which they are used.\n The assignable OpenMP type instance is defined to facilitate base language neutrality.An \n assignable OpenMP type instance can be used as an argument of an OpenMP construct in order for \n the implementation to modify the value of that instance.\nC / C++ \n An assignable OpenMP type instance is an lvalue expression of that OpenMP type."}
{"section_title": "4.1 OpenMP Types and Identifiers", "chunk": "\nC / C++ \n An assignable OpenMP type instance is an lvalue expression of that OpenMP type.\nC / C++ \nFortran \n An assignable OpenMP type instance is a variable of that OpenMP type.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n The OpenMP logical type supports logical variables and expressions in any base language.\nC / C++ \n Any OpenMP logical expression is a scalar expression.This document uses true as a generic term \n for a non-zero integer value and false as a generic term for an integer value of zero.\nC / C++ \nFortran \n Any OpenMP logical expression is a scalar logical expression.This document uses true as a generic \n term for a logical value of .TRUE.and false as a generic term for a logical value of .FALSE..\nFortran \n The OpenMP integer type supports integer variables and expressions in any base language.\nC / C++ \n Any OpenMP integer expression is an integer expression.\nC / C++ \nFortran \n Any OpenMP integer expression is a scalar integer expression."}
{"section_title": "4.1 OpenMP Types and Identifiers", "chunk": "\nC / C++ \nFortran \n Any OpenMP integer expression is a scalar integer expression.\nFortran \n The OpenMP string type supports character string variables and expressions in any base language.\nC / C++ \n Any OpenMP string expression is an expression of type qualified or unqualified const char * \n or char * pointing to a null-terminated character string.\nC / C++ \nFortran \n Any OpenMP string expression is a character string of default kind.\nFortran \n OpenMP function identifiers support procedure names in any base language.Regardless of the base \n language, any OpenMP function identifier is the name of a procedure as a base language identifier.\n Each OpenMP type other than those specifically defined in this section has a generic name, \n <generic_name>, by which it is referred throughout this document and that is used to construct the \n base language construct that corresponds to that OpenMP type."}
{"section_title": "4.1 OpenMP Types and Identifiers", "chunk": "\n Each OpenMP type other than those specifically defined in this section has a generic name, \n <generic_name>, by which it is referred throughout this document and that is used to construct the \n base language construct that corresponds to that OpenMP type.\nC / C++ \n A variable of <generic_name> OpenMP type is a variable of type omp_<generic_name>_t.\nC / C++ \nFortran \n A variable of <generic_name> OpenMP type is a scalar integer variable of kind \n omp_<generic_name>_kind.\nFortran \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 75 \n Cross References \n \u2022 OpenMP Foreign Runtime Identifiers, see Section 14.1.1 \n \u2022 OpenMP Reduction Identifiers, see Section 5.5.1 \n \u2022 mapper modifier, see Section 5.8.2 \n"}
{"section_title": "4.2 OpenMP Stylized Expressions", "chunk": "6 An OpenMP stylized expression is a base language expression that is subject to restrictions that \n enable its use within an OpenMP implementation.These expressions often make use of special \n variable identifiers that the implementation binds to well-defined internal state.\n Cross References \n \u2022 OpenMP Combiner Expressions, see Section 5.5.2.1 \n \u2022 OpenMP Initializer Expressions, see Section 5.5.2.2 \n"}
{"section_title": "4.3 Structured Blocks", "chunk": "13 This section specifies the concept of a structured block.A structured block: \n \u2022 may contain infinite loops where the point of exit is never reached; \n \u2022 may halt due to an IEEE exception; \nC / C++ \n \u2022 may contain calls to exit(), _Exit(), quick_exit(), abort() or functions with a \n _Noreturn specifier (in C) or a noreturn attribute (in C/C++); \n \u2022 may be an expression statement, iteration statement, selection statement, or try block, provided \n that the corresponding compound statement obtained by enclosing it in { and } would be a \n structured block; and \nC / C++ \nFortran \n \u2022 may contain STOP or ERROR STOP statements.\nFortran \nC / C++ \n A structured block sequence that consists of no statements or more than one statement may appear \n only for executable directives that explicitly allow it."}
{"section_title": "4.3 Structured Blocks", "chunk": "\nFortran \nC / C++ \n A structured block sequence that consists of no statements or more than one statement may appear \n only for executable directives that explicitly allow it.The corresponding compound statement \n obtained by enclosing the sequence in { and } must be a structured block and the structured block \n sequence then should be considered to be a structured block with all of its restrictions.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to structured blocks are as follows: \n \u2022 Entry to a structured block must not be the result of a branch.\n \u2022 The point of exit cannot be a branch out of the structured block.\nC / C++ \n \u2022 The point of entry to a structured block must not be a call to setjmp.\n \u2022 longjmp must not violate the entry/exit criteria of structured blocks.\nC / C++ \nC++ \n \u2022 throw, co_await, co_yield and co_return must not violate the entry/exit criteria of \n structured blocks."}
{"section_title": "4.3 Structured Blocks", "chunk": "\nC / C++ \nC++ \n \u2022 throw, co_await, co_yield and co_return must not violate the entry/exit criteria of \n structured blocks.\nC++ \nFortran \n \u2022 If a BLOCK construct appears in a structured block, that BLOCK construct must not contain any \n ASYNCHRONOUS or VOLATILE statements, nor any specification statements that include the \n ASYNCHRONOUS or VOLATILE attributes.\nFortran \n"}
{"section_title": "4.3.1 OpenMP Context-Specific Structured Blocks", "chunk": "13 An OpenMP context-specific structured block consists of statements that conform to specific \n restrictions so that OpenMP can treat them as a structured block or a structured block sequence.\n The restrictions depend on the context in which the context-specific structured block can be used.\n"}
{"section_title": "4.3.1.1 OpenMP Allocator Structured Blocks", "chunk": "Fortran \n An OpenMP allocator structured block consists of allocate-stmt, where allocate-stmt is a Fortran \n ALLOCATE statement.Allocator structured blocks are considered strictly structured blocks for the \n purpose of the allocators construct.\nFortran \n Cross References \n \u2022 allocators directive, see Section 6.7 \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 77 \n"}
{"section_title": "4.3.1.2 OpenMP Function Dispatch Structured Blocks", "chunk": "2 An OpenMP function dispatch structured block is a context-specific structured block that identifies \n the location of a function dispatch.\nC / C++ \n A function dispatch structured block is an expression statement with one of the following forms: \n lvalue-expression = target-call ( [expression-list] ); \n or \n target-call ( [expression-list] ); \nC / C++ \nFortran \n A function dispatch structured block is an expression statement with one of the following forms: \n expression = target-call ( [arguments] ) \n or \n CALL target-call [ ( [arguments] )] \n For purposes of the dispatch construct, the expression statement is considered a strictly \n structured block.\nFortran \n Restrictions \n Restrictions to the function dispatch structured blocks are as follows: \nC++ \n \u2022 The target-call expression can only be a direct call.\nC++ \nFortran \n \u2022 target-call must be a procedure name.\n \u2022 target-call must not be a procedure pointer."}
{"section_title": "4.3.1.2 OpenMP Function Dispatch Structured Blocks", "chunk": "\n \u2022 target-call must not be a procedure pointer.\nFortran \n Cross References \n \u2022 dispatch directive, see Section 7.6 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "2 An OpenMP atomic structured block is a context-specific structured block that can appear in an \n atomic construct.The form of an atomic structured block depends on the atomic semantics that \n the directive enforces.\n In the following definitions: \nC / C++ \n \u2022 x, r (result), and v (as applicable) are lvalue expressions with scalar type.\n \u2022 e (expected) is an expression with scalar type, \n \u2022 d (desired) is an expression with scalar type.\n \u2022 e and v may refer to, or access, the same storage location.\n \u2022 expr is an expression with scalar type.\n \u2022 The order operation, ordop, is one of <, or >.\n \u2022 binop is one of +, *, -, /, &, ^, |, <<, or >>.\n \u2022 == comparisons are performed by comparing the value representation of operand values for \n equality after the usual arithmetic conversions; if the object representation does not have any \n padding bits, the comparison is performed as if with memcmp."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 == comparisons are performed by comparing the value representation of operand values for \n equality after the usual arithmetic conversions; if the object representation does not have any \n padding bits, the comparison is performed as if with memcmp.\n \u2022 For forms that allow multiple occurrences of x, the number of times that x is evaluated is \n unspecified but will be at least one.\n \u2022 For forms that allow multiple occurrences of expr, the number of times that expr is evaluated is \n unspecified but will be at least one.\n \u2022 The number of times that r is evaluated is unspecified but will be at least one.\n \u2022 Whether d is evaluated if x == e evaluates to false is unspecified.\nC / C++ \nFortran \n \u2022 x, v, d and e (as applicable) are scalar variables of intrinsic type.\n \u2022 expr is a scalar expression.\n \u2022 expr-list is a comma-separated, non-empty list of scalar expressions.\n \u2022 intrinsic-procedure-name is one of MAX, MIN, IAND, IOR, or IEOR."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 intrinsic-procedure-name is one of MAX, MIN, IAND, IOR, or IEOR.\n \u2022 operator is one of +, *, -, /, .AND., .OR., .EQV., or .NEQV..\n \u2022 equalop is ==, .EQ., or .EQV..\n \u2022 == or .EQ.comparisons are performed by comparing the physical representation of operand \n values for equality after the usual conversions as described in the base language, while ignoring \n padding bits, if any.\nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 79 \n \u2022 .EQV.comparisons are performed as described in the base language.\n \u2022 For forms that allow multiple occurrences of x, the number of times that x is evaluated is \n unspecified but will be at least one.\n \u2022 For forms that allow multiple occurrences of expr, the number of times that expr is evaluated is \n unspecified but will be at least one.\n \u2022 The number of times that r is evaluated is unspecified but will be at least one.\n \u2022 Whether d is evaluated if x equalop e evaluates to false is unspecified."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 Whether d is evaluated if x equalop e evaluates to false is unspecified.\nFortran \n A read-atomic structured block can be specified for atomic directives that enforce atomic read \n semantics but not capture semantics.\nC / C++ \n A read-atomic structured block is read-expr-stmt, a read expression statement that has the following \n form: \n v = x; \nC / C++ \nFortran \n A read-atomic structured block is read-statement, a read statement that has the following form: \n v = x \nFortran \n A write-atomic structured block can be specified for atomic directives that enforce atomic write \n semantics but not capture semantics."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\nC / C++ \n A read-atomic structured block is read-expr-stmt, a read expression statement that has the following \n form: \n v = x; \nC / C++ \nFortran \n A read-atomic structured block is read-statement, a read statement that has the following form: \n v = x \nFortran \n A write-atomic structured block can be specified for atomic directives that enforce atomic write \n semantics but not capture semantics.\nC / C++ \n A write-atomic structured block is write-expr-stmt, a write expression statement that has the \n following form: \n x = expr; \nC / C++ \nFortran \n A write-atomic structured block is write-statement, a write statement that has the following form: \n x = expr \nFortran \n An update-atomic structured block can be specified for atomic directives that enforce atomic \n update semantics but not capture semantics."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\nC / C++ \n A write-atomic structured block is write-expr-stmt, a write expression statement that has the \n following form: \n x = expr; \nC / C++ \nFortran \n A write-atomic structured block is write-statement, a write statement that has the following form: \n x = expr \nFortran \n An update-atomic structured block can be specified for atomic directives that enforce atomic \n update semantics but not capture semantics.\n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n An update-atomic structured block is update-expr-stmt, an update expression statement that has one \n of the following forms: \n x++; \n x--; \n ++x; \n --x; \n x binop= expr; \n x = x binop expr; \n x = expr binop x; \nC / C++ \nFortran \n An update-atomic structured block is update-statement, an update statement that has one of the \n following forms: \n x = x operator expr \n x = expr operator x \n x = intrinsic-procedure-name (x, expr-list) \n x = intrinsic-procedure-name (expr-list, x) \nFortran \n A conditional-update-atomic structured block can be specified for atomic directives that enforce \n atomic conditional update semantics but not capture semantics."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n An update-atomic structured block is update-expr-stmt, an update expression statement that has one \n of the following forms: \n x++; \n x--; \n ++x; \n --x; \n x binop= expr; \n x = x binop expr; \n x = expr binop x; \nC / C++ \nFortran \n An update-atomic structured block is update-statement, an update statement that has one of the \n following forms: \n x = x operator expr \n x = expr operator x \n x = intrinsic-procedure-name (x, expr-list) \n x = intrinsic-procedure-name (expr-list, x) \nFortran \n A conditional-update-atomic structured block can be specified for atomic directives that enforce \n atomic conditional update semantics but not capture semantics.\nC / C++ \n A conditional-update-atomic structured block is either cond-expr-stmt, a conditional expression \n statement that has one of the following forms: \n x = expr ordop x ? expr : x; \n x = x ordop expr ? expr : x; \n x = x == e ? d : x; \n or cond-update-stmt, a conditional update statement that has one of the following forms: \n if(expr ordop x) { x = expr; } \n if(x ordop expr) { x = expr; } \n if(x == e) { x = d; } \nC / C++ \nCHAPTER 4."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\nC / C++ \n A conditional-update-atomic structured block is either cond-expr-stmt, a conditional expression \n statement that has one of the following forms: \n x = expr ordop x ? expr : x; \n x = x ordop expr ? expr : x; \n x = x == e ? d : x; \n or cond-update-stmt, a conditional update statement that has one of the following forms: \n if(expr ordop x) { x = expr; } \n if(x ordop expr) { x = expr; } \n if(x == e) { x = d; } \nC / C++ \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 81 \nFortran \n A conditional-update-atomic structured block is conditional-update-statement, a conditional update \n statement that has one of the following forms: \n if (x equalop e) then \n x = d \n end if \n or \n if (x equalop e) x = d \n read-atomic, write-atomic, update-atomic, and conditional-update-atomic structured blocks are \n considered strictly structured blocks for the purpose of the atomic construct."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "BASE LANGUAGE FORMATS AND RESTRICTIONS 81 \nFortran \n A conditional-update-atomic structured block is conditional-update-statement, a conditional update \n statement that has one of the following forms: \n if (x equalop e) then \n x = d \n end if \n or \n if (x equalop e) x = d \n read-atomic, write-atomic, update-atomic, and conditional-update-atomic structured blocks are \n considered strictly structured blocks for the purpose of the atomic construct.\nFortran \n A capture-atomic structured block can be specified for atomic directives that enforce capture \n semantics.They are further categorized as write-capture-atomic, update-capture-atomic, and \n conditional-update-capture-atomic structured blocks, which can be specified for atomic \n directives that enforce write, update or conditional update atomic semantics in addition to capture \n semantics."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "They are further categorized as write-capture-atomic, update-capture-atomic, and \n conditional-update-capture-atomic structured blocks, which can be specified for atomic \n directives that enforce write, update or conditional update atomic semantics in addition to capture \n semantics.\nC / C++ \n A capture-atomic structured block is capture-stmt, a capture statement that has one of the following \n forms: \n v = expr-stmt \n { v = x; expr-stmt } \n { expr-stmt v = x; } \n If expr-stmt is write-expr-stmt or expr-stmt is update-expr-stmt as specified above then it is an \n update-capture-atomic structured block.If expr-stmt is cond-expr-stmt as specified above then it is \n a conditional-update-capture-atomic structured block."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "If expr-stmt is cond-expr-stmt as specified above then it is \n a conditional-update-capture-atomic structured block.In addition, a \n conditional-update-capture-atomic structured block can have one of the following forms: \n { v = x; cond-update-stmt } \n { cond-update-stmt v = x; } \n if(x == e) { x = d; } else { v = x; } \n { r = x == e; if(r) { x = d; } } \n { r = x == e; if(r) { x = d; } else { v = x; } } \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n A capture-atomic structured block has one of the following forms: \n statement \n capture-statement \n or \n capture-statement \n statement \n where capture-statement has the following form: \n v = x \n If statement is write-statement as specified above then it is a write-capture-atomic structured block.\n If statement is update-statement as specified above then it is an update-capture-atomic structured \n block."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n If statement is update-statement as specified above then it is an update-capture-atomic structured \n block.If statement is conditional-update-statement as specified above then it is a \n conditional-update-capture-atomic structured block.In addition, for a \n conditional-update-capture-atomic structured block, statement can have the following form: \n x = expr \n In addition, a conditional-update-capture-atomic structured block can have the following form: \n if (x equalop e) then \n x = d \n else \n v = x \n end if \n All capture-atomic structured blocks are considered loosely structured blocks for the purpose of the \n atomic construct.\nFortran \n Restrictions \n Restrictions to OpenMP atomic structured blocks are as follows: \nC / C++ \n \u2022 In forms where e is assigned it must be an lvalue.\n \u2022 r must be of integral type.\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of x must designate \n the same storage location."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of x must designate \n the same storage location.\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of r must designate \n the same storage location.\nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 83 \n \u2022 During the execution of an atomic region, multiple syntactic occurrences of expr must evaluate \n to the same value.\n \u2022 None of v, x, r, d and expr (as applicable) may access the storage location designated by any \n other symbol in the list.\n \u2022 In forms that capture the original value of x in v, v and e may not refer to, or access, the same \n storage location.\n \u2022 binop, binop=, ordop, ==, ++, and -- are not overloaded operators.\n \u2022 The expression x binop expr must be numerically equivalent to x binop (expr).This requirement \n is satisfied if the operators in expr have precedence greater than binop, or by using parentheses \n around expr or subexpressions of expr."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "This requirement \n is satisfied if the operators in expr have precedence greater than binop, or by using parentheses \n around expr or subexpressions of expr.\n \u2022 The expression expr binop x must be numerically equivalent to (expr) binop x.This requirement \n is satisfied if the operators in expr have precedence equal to or greater than binop, or by using \n parentheses around expr or subexpressions of expr.\n \u2022 The expression x ordop expr must be numerically equivalent to x ordop (expr).This requirement \n is satisfied if the operators in expr have precedence greater than ordop, or by using parentheses \n around expr or subexpressions of expr.\n \u2022 The expression expr ordop x must be numerically equivalent to (expr) ordop x.This requirement \n is satisfied if the operators in expr have precedence equal to or greater than ordop, or by using \n parentheses around expr or subexpressions of expr.\n \u2022 The expression x == e must be numerically equivalent to x == (e)."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 The expression x == e must be numerically equivalent to x == (e).This requirement is satisfied \n if the operators in e have precedence equal to or greater than ==, or by using parentheses around \n e or subexpressions of e.\nC / C++ \nFortran \n \u2022 x must not have the ALLOCATABLE attribute.\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of x must designate \n the same storage location.\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of r must designate \n the same storage location.\n \u2022 During the execution of an atomic region, multiple syntactic occurrences of expr must evaluate \n to the same value.\n \u2022 None of v, expr, and expr-list (as applicable) may access the same storage location as x.\n \u2022 None of x, expr, and expr-list (as applicable) may access the same storage location as v.\n \u2022 In forms that capture the original value of x in v, v may not access the same storage location as e."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "\n \u2022 In forms that capture the original value of x in v, v may not access the same storage location as e.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If intrinsic-procedure-name refers to IAND, IOR, or IEOR, exactly one expression must appear \n in expr-list.\n \u2022 The expression x operator expr must be, depending on its type, either mathematically or logically \n equivalent to x operator (expr).This requirement is satisfied if the operators in expr have \n precedence greater than operator, or by using parentheses around expr or subexpressions of expr.\n \u2022 The expression expr operator x must be, depending on its type, either mathematically or \n logically equivalent to (expr) operator x.This requirement is satisfied if the operators in expr \n have precedence equal to or greater than operator, or by using parentheses around expr or \n subexpressions of expr."}
{"section_title": "4.3.1.3 OpenMP Atomic Structured Blocks", "chunk": "This requirement is satisfied if the operators in expr \n have precedence equal to or greater than operator, or by using parentheses around expr or \n subexpressions of expr.\n \u2022 The expression x equalop e must be, depending on its type, either mathematically or logically \n equivalent to x equalop (e).This requirement is satisfied if the operators in e have precedence \n equal to or greater than equalop, or by using parentheses around e or subexpressions of e.\n \u2022 intrinsic-procedure-name must refer to the intrinsic procedure name and not to other program \n entities.\n \u2022 operator must refer to the intrinsic operator and not to a user-defined operator.\n \u2022 All assignments must be intrinsic assignments.\nFortran \n Cross References \n \u2022 atomic directive, see Section 15.8.4 \n"}
{"section_title": "4.4 Loop Concepts", "chunk": "20 OpenMP semantics frequently involve loops that occur in the base language code.As detailed in \n this section, OpenMP defines several concepts that facilitate the specification of those semantics \n and their associated syntax.\n"}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "24 A loop nest has canonical loop nest form if it conforms to loop-nest in the following grammar: \n Symbol Meaning \n loop-nest One of the following: \nC / C++ \n for (init-expr; test-expr; incr-expr) \n loop-body \nC / C++ \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 85 \n or \nC++ \n for (range-decl: range-expr) \n loop-body \n A range-based for loop is equivalent to a regular for loop using iterators, as \n defined in the base language.A range-based for loop has no iteration variable.\nC++ \n or \nFortran \n DO [ label ] var = lb , ub [ , incr ] \n [intervening-code] \n loop-body \n [intervening-code] \n [ label ] END DO \n If the loop-nest is a nonblock-do-construct, it is treated as a block-do-construct for \n each DO construct.\n The value of incr is the increment of the loop.If not specified, its value is assumed to \n be 1."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "If not specified, its value is assumed to \n be 1.\nFortran \n or \n loop-transformation-construct \n or \n generated-canonical-loop \n loop-body One of the following: \n loop-nest \n or \nC / C++ \n { \n [intervening-code] \n loop-body \n [intervening-code] \n } \nC / C++ \n or \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n BLOCK \n [intervening-code] \n loop-body \n [intervening-code] \n END BLOCK \nFortran \n or if none of the previous productions match \n final-loop-body \nloop-transformation\ufffeconstruct \n A loop transformation construct.\ngenerated-canonical\ufffeloop \n A generated loop from a loop transformation construct that has canonical loop nest \n form and for which the loop body matches loop-body.\n intervening-code A non-empty structured block sequence that does not contain OpenMP directives or \n calls to the OpenMP runtime API in its corresponding region, referred to as \n intervening code."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\n intervening-code A non-empty structured block sequence that does not contain OpenMP directives or \n calls to the OpenMP runtime API in its corresponding region, referred to as \n intervening code.If intervening code is present, then a loop at the same depth within \n the loop nest is not a perfectly nested loop.\nC / C++ \n It must not contain iteration statements, continue statements or break statements \n that apply to the enclosing loop.\nC / C++ \nFortran \n It must not contain loops, array expressions, CYCLE statements or EXIT statements.\nFortran \n final-loop-body A structured block that terminates the scope of loops in the loop nest.If the loop nest \n is associated with a loop-associated directive, loops in this structured block cannot be \n associated with that directive.\nC / C++ \n init-expr One of the following: \n var = lb \n integer-type var = lb \nCHAPTER 4."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\nC / C++ \n init-expr One of the following: \n var = lb \n integer-type var = lb \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 87 \nC \n pointer-type var = lb \nC \nC++ \n random-access-iterator-type var = lb \nC++ \n test-expr One of the following: \n var relational-op ub \n ub relational-op var \n relational-op One of the following: \n < \n <= \n > \n >= \n != \n incr-expr One of the following: \n ++var \n var++ \n - - var \n var - - \n var += incr \n var - = incr \n var = var + incr \n var = incr + var \n var = var - incr \n The value of incr, respectively 1 and -1 for the increment and decrement operators, is \n the increment of the loop.\nC / C++ \n var One of the following: \nC / C++ \n A variable of a signed or unsigned integer type.\n C / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC \n A variable of a pointer type.\n C \nC++ \n A variable of a random access iterator type.\n C++ \nFortran \n A scalar variable of integer type."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\n C++ \nFortran \n A scalar variable of integer type.\nFortran \n var is the iteration variable of the loop.It must not be modified during the execution \n of intervening-code or loop-body in the loop.\n lb, ub One of the following: \n Expressions of a type compatible with the type of var that are loop invariant with \n respect to the outermost loop.\n or \n One of the following: \n var-outer \n var-outer + a2 \n a2 + var-outer \n var-outer - a2 \n where var-outer is of a type compatible with the type of var.\n or \n If var is of an integer type, one of the following: \n a2 - var-outer \n a1 * var-outer \n a1 * var-outer + a2 \n a2 + a1 * var-outer \n a1 * var-outer - a2 \n a2 - a1 * var-outer \n var-outer * a1 \n var-outer * a1 + a2 \n a2 + var-outer * a1 \n var-outer * a1 - a2 \n a2 - var-outer * a1 \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 89 \n where var-outer is of an integer type.\n lb and ub are loop bounds."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\n lb and ub are loop bounds.A loop for which lb or ub refers to var-outer is a \n non-rectangular loop.If var is of an integer type, var-outer must be of an integer \n type with the same signedness and bit precision as the type of var.\n The coefficient in a loop bound is 0 if the bound does not refer to var-outer.If a loop \n bound matches a form in which a1 appears, the coefficient is -a1 if the product of \n var-outer and a1 is subtracted from a2, and otherwise the coefficient is a1.For other \n matched forms where a1 does not appear, the coefficient is \u22121 if var-outer is \n subtracted from a2, and otherwise the coefficient is 1.\n a1, a2, incr Integer expressions that are loop invariant with respect to the outermost loop of the \n loop nest.\n If the loop is associated with a loop-associated directive, the expressions are \n evaluated before the construct formed from that directive.\n var-outer The loop iteration variable of a surrounding loop in the loop nest."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\n var-outer The loop iteration variable of a surrounding loop in the loop nest.\nC++ \n range-decl A declaration of a variable as defined by the base language for range-based for \n loops.\n range-expr An expression that is valid as defined by the base language for range-based for \n loops.It must be invariant with respect to the outermost loop of the loop nest and the \n iterator derived from it must be a random access iterator.\nC++ \n Restrictions \n Restrictions to canonical loop nests are as follows: \nC / C++ \n \u2022 If test-expr is of the form var relational-op b and relational-op is < or <= then incr-expr must \n cause var to increase on each iteration of the loop.If test-expr is of the form var relational-op b \n and relational-op is > or >= then incr-expr must cause var to decrease on each iteration of the \n loop.Increase and decrease are using the order induced by relational-op."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "Increase and decrease are using the order induced by relational-op.\n \u2022 If test-expr is of the form ub relational-op var and relational-op is < or <= then incr-expr must \n cause var to decrease on each iteration of the loop.If test-expr is of the form ub relational-op \n var and relational-op is > or >= then incr-expr must cause var to increase on each iteration of the \n loop.Increase and decrease are using the order induced by relational-op.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If relational-op is != then incr-expr must cause var to always increase by 1 or always decrease \n by 1 and the increment must be a constant expression.\n \u2022 final-loop-body must not contain any break statement that would cause the termination of the \n innermost loop.\nC / C++ \nFortran \n \u2022 final-loop-body must not contain any EXIT statement that would cause the termination of the \n innermost loop.\nFortran \n \u2022 A loop-nest must also be a structured block."}
{"section_title": "4.4.1 Canonical Loop Nest Form", "chunk": "\nFortran \n \u2022 A loop-nest must also be a structured block.\n \u2022 For a non-rectangular loop, if var-outer is referenced in lb and ub then they must both refer to the \n same iteration variable.\n \u2022 For a non-rectangular loop, let alb and aub be the respective coefficients in lb and ub, incrinner \n the increment of the non-rectangular loop and incrouter the increment of the loop referenced by \n var-outer.incrinner(aub \u2212 alb) must be a multiple of incrouter.\n \u2022 The loop iteration variable may not appear in a threadprivate directive.\n Cross References \n \u2022 Loop Transformation Constructs, see Chapter 9 \n \u2022 threadprivate directive, see Section 5.2 \n"}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": "18 A loop-associated directive controls some number of the outermost loops of an associated loop \n nest, called the associated loops, in accordance with its specified clauses.These associated loops \n and their loop iteration variables form an OpenMP loop-iteration space.OpenMP loop-iteration \n vectors allow other directives to refer to points in that loop-iteration space.\n A loop transformation construct that appears inside a loop nest is replaced according to its \n semantics before any loop can be associated with a loop-associated directive that is applied to the \n loop nest.The depth of the loop nest is determined according to the loops in the loop nest, after any \n such replacements have taken place.A loop counts towards the depth of the loop nest if it is a base \n language loop statement or generated loop and it matches loop-nest while applying the production \n rules for canonical loop nest form to the loop nest."}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": "A loop counts towards the depth of the loop nest if it is a base \n language loop statement or generated loop and it matches loop-nest while applying the production \n rules for canonical loop nest form to the loop nest.\n The canonical loop nest form allows the iteration count of all associated loops to be computed \n before executing the outermost loop.\n For any associated loop, the iteration count is computed as follows: \nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 91 \nC / C++ \n \u2022 If var has a signed integer type and the var operand of test-expr after usual arithmetic \n conversions has an unsigned integer type then the loop iteration count is computed from lb, \n test-expr and incr using an unsigned integer type corresponding to the type of var.\n \u2022 Otherwise, if var has an integer type then the loop iteration count is computed from lb, test-expr \n and incr using the type of var."}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": "\n \u2022 Otherwise, if var has an integer type then the loop iteration count is computed from lb, test-expr \n and incr using the type of var.\nC / C++ \nC \n \u2022 If var has a pointer type then the loop iteration count is computed from lb, test-expr and incr \n using the type ptrdiff_t.\nC \nC++ \n \u2022 If var has a random access iterator type then the loop iteration count is computed from lb, \n test-expr and incr using the type \n std::iterator_traits<random-access-iterator-type>::difference_type.\n \u2022 For range-based for loops, the loop iteration count is computed from range-expr using the type \n std::iterator_traits<random-access-iterator-type>::difference_type where \n random-access-iterator-type is the iterator type derived from range-expr.\nC++ \nFortran \n \u2022 The loop iteration count is computed from lb, ub and incr using the type of var."}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": "\nC++ \nFortran \n \u2022 The loop iteration count is computed from lb, ub and incr using the type of var.\nFortran \n The behavior is unspecified if any intermediate result required to compute the iteration count \n cannot be represented in the type determined above.\n No synchronization is implied during the evaluation of the lb, ub, incr or range-expr expressions.\n Whether, in what order, or how many times any side effects within the lb, ub, incr, or range-expr \n expressions occur is unspecified.\n Let the number of loops associated with a construct be n.The OpenMP loop-iteration space is the \nn-dimensional space defined by the values of vari 21 , 1 \u2264 i \u2264 n, the iteration variables of the associated \n loops, with i = 1 referring to the outermost loop of the loop nest.An OpenMP loop-iteration vector, \n which may be used as an argument of OpenMP directives and clauses, then has the form: \n var1 [\u00b1 offset1], var2 [\u00b1 offset2], .."}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": ".., varn [\u00b1 offsetn] \nwhere offseti 25 is a compile-time constant non-negative OpenMP integer expression that facilitates \n identification of relative points in the loop-iteration space.\n OpenMP API \u2013 Version 5.2 November 2021 \n The iterations of some number of associated loops can be collapsed into one larger iteration space \n that is called the logical iteration space.The particular integer type used to compute the iteration \n count for the collapsed loop is implementation defined, but its bit precision must be at least that of \n the widest type that the implementation would use for the iteration count of each loop if it was the \n only associated loop.OpenMP defines a special loop-iteration vector, omp_cur_iteration, for \nwhich offset 6 i = 0 \u2200 i."}
{"section_title": "4.4.2 OpenMP Loop-Iteration Spaces and Vectors", "chunk": "OpenMP defines a special loop-iteration vector, omp_cur_iteration, for \nwhich offset 6 i = 0 \u2200 i.This loop-iteration vector enables identification of relative points in the \n logical iteration space as: \n omp_cur_iteration [\u00b1 logical_offset] \n where logical_offset is a compile-time constant non-negative OpenMP integer expression.\n For directives that result in the execution of a collapsed logical iteration space, the number of times \n that any intervening code between any two loops of the same logical iteration space will be \n executed is unspecified but will be the same for all intervening code at the same depth, at least once \n per iteration of the loop that encloses the intervening code and at most once per logical iteration.If \n the iteration count of any loop is zero and that loop does not enclose the intervening code, the \n behavior is unspecified.\n"}
{"section_title": "4.4.3 collapse Clause", "chunk": "17 Name: collapse Properties: unique \n Arguments \nName Type Properties \nn expression of integer type default 19 \n Directives \n distribute, do, for, loop, simd, taskloop \n Semantics \n The collapse clause associates one or more loops with the directive on which it appears for the \n purpose of identifying the portion of the depth of the canonical loop nest to which to apply the \n semantics of the directive.The argument n specifies the number of loops of the associated loop nest \n to which to apply those semantics.On all directives on which the collapse clause may appear, \n the effect is as if a value of one was specified for n if the collapse clause is not specified.\n Restrictions \n \u2022 n must not evaluate to a value greater than the depth of the associated loop nest.\nCHAPTER 4."}
{"section_title": "4.4.3 collapse Clause", "chunk": "\nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 93 \n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 simd directive, see Section 10.4 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "4.4.4 ordered Clause", "chunk": "10 Name: ordered Properties: unique \n Arguments \nName Type Properties \nn expression of integer type optional, constant, posi\ufffetive \n \n Directives \n do, for, simd \n Semantics \n The ordered clause associates one or more loops with the directive on which it appears for the \n purpose of identifying cross-iteration dependences.The argument n specifies the number of loops \n of the associated loop to use for that purpose.If n is not specified then the behavior is as if n is \n specified with the same value as is specified for the collapse clause on the construct.\n Restrictions \n \u2022 None of the associated loops may be non-rectangular loops.\n \u2022 The ordered clause must not appear on a worksharing-loop directive if the associated loops \n include the generated loops of a tile directive.\n \u2022 n must not evaluate to a value greater than the depth of the associated loop nest.\n \u2022 If n is explicitly specified, the associated loops must be perfectly nested."}
{"section_title": "4.4.4 ordered Clause", "chunk": "\n \u2022 If n is explicitly specified, the associated loops must be perfectly nested.\n \u2022 If n is explicitly specified and the collapse clause is also specified for the ordered clause on \n the same construct, n must be greater than or equal to the n specified for the collapse clause.\n \u2022 If n is explicitly specified, a linear clause must not be specified on the same directive.\nC++ \n \u2022 If n is explicitly specified, none of the associated loops may be a range-based for loop.\nC++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 simd directive, see Section 10.4 \n \u2022 tile directive, see Section 9.1 \n"}
{"section_title": "4.4.5 Consistent Loop Schedules", "chunk": "9 For constructs formed from loop-associated directives that have consistent schedules, the \n implementation will guarantee that memory effects of a logical iteration in the first loop nest \n happen before the execution of the same logical iteration in the second loop nest.\n Two constructs formed from loop-associated directives have consistent schedules if all of the \n following conditions hold: \n \u2022 The constructs have the same directive-name; \n \u2022 The regions that correspond to the two constructs have the same binding region; \n \u2022 The constructs have the same reproducible schedule; \n \u2022 The associated loop nests have identical logical iteration vector spaces; and \n \u2022 The associated loop nests are either both rectangular or both non-rectangular.\nCHAPTER 4.BASE LANGUAGE FORMATS AND RESTRICTIONS 95 \n"}
{"section_title": "5 Data Environment", "chunk": "2 This chapter presents directives and clauses for controlling data environments.These clauses and \n directives include the data-environment attribute clauses, which explicitly determine the attributes \n of list items specified in a list parameter.The data-environment attribute clauses form a general \n clause set for which certain restrictions apply to their use on directives that accept any members of \n the set.In addition, these clauses are divided into two subsets that also form general clause sets: \n data-sharing attribute clauses and data-mapping attribute clauses.Data-sharing attribute clauses \n control the data-sharing attributes of variables in a construct, indicating whether a variable is \n shared or private in the outermost scope of the construct.Data-mapping attribute clauses control \n the data-mapping attributes of variables in a data environment, indicating whether a variable is \n mapped from the data environment to another device data environment."}
{"section_title": "5 Data Environment", "chunk": "Data-mapping attribute clauses control \n the data-mapping attributes of variables in a data environment, indicating whether a variable is \n mapped from the data environment to another device data environment.Additional restrictions \n apply to the use of these sets on directives that accept any members of them.\n"}
{"section_title": "5.1 Data-Sharing Attribute Rules", "chunk": "14 This section describes how the data-sharing attributes of variables referenced in data environments \n are determined.The following two cases are described separately: \n \u2022 Section 5.1.1 describes the data-sharing attribute rules for variables referenced in a construct.\n \u2022 Section 5.1.2 describes the data-sharing attribute rules for variables referenced in a region, but \n outside any construct.\n"}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "20 The data-sharing attributes of variables that are referenced in a construct can be predetermined, \n explicitly determined, or implicitly determined, according to the rules outlined in this section.\n Specifying a variable in a copyprivate clause or a data-sharing attribute clause other than the \n private clause on an enclosed construct causes an implicit reference to the variable in the \n enclosing construct.Specifying a variable in a map clause of an enclosed construct may cause an \n implicit reference to the variable in the enclosing construct.Such implicit references are also \n subject to the data-sharing attribute rules outlined in this section.\nFortran \n A type parameter inquiry or complex part designator that is referenced in a construct is treated as if \n its designator is referenced.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Certain variables and objects have predetermined data-sharing attributes for the construct in which \n they are referenced."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Certain variables and objects have predetermined data-sharing attributes for the construct in which \n they are referenced.The first matching rule from the following list of predetermined data-sharing \n attribute rules applies for variables and objects that are referenced in a construct.\nFortran \n \u2022 Variables declared within a BLOCK construct inside a construct that do not have the SAVE \n attribute are private.\nFortran \n \u2022 Variables and common blocks (in Fortran) that appear as arguments in threadprivate \n directives or variables with the _Thread_local (in C) or thread_local (in C++) \n storage-class specifier are threadprivate.\nC \n \u2022 Variables with automatic storage duration that are declared in a scope inside the construct are \n private.\nC \nC++ \n \u2022 Variables of non-reference type with automatic storage duration that are declared in a scope \n inside the construct are private."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\nC \nC++ \n \u2022 Variables of non-reference type with automatic storage duration that are declared in a scope \n inside the construct are private.\nC++ \nC / C++ \n \u2022 Objects with dynamic storage duration are shared.\nC / C++ \n \u2022 The loop iteration variable in the associated loop of a simd construct with just one associated \n loop is linear with a linear-step that is the increment of the associated loop.\n \u2022 The loop iteration variables in the associated loops of a simd construct with multiple associated \n loops are lastprivate.\n \u2022 The loop iteration variable in any associated loop of a loop construct is lastprivate.\n \u2022 The loop iteration variable in any associated loop of a loop-associated construct is otherwise \n private.\nC++ \n \u2022 The implicitly declared variables of a range-based for loop are private.\nC++ \nFortran \n \u2022 Loop iteration variables inside parallel, teams, or task generating constructs are private in \n the innermost such construct that encloses the loop."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\nC++ \nFortran \n \u2022 Loop iteration variables inside parallel, teams, or task generating constructs are private in \n the innermost such construct that encloses the loop.\n \u2022 Implied-do, FORALL and DO CONCURRENT indices are private.\nFortran \nCHAPTER 5.DATA ENVIRONMENT 97 \nC / C++ \n \u2022 Variables with static storage duration that are declared in a scope inside the construct are shared.\n \u2022 If a list item in a map clause on the target construct has a base pointer, and the base pointer is \n a scalar variable that does not appear in a map clause on the construct, the base pointer is \n firstprivate.\n \u2022 If a list item in a reduction or in_reduction clause on the construct has a base pointer \n then the base pointer is private.\n \u2022 Static data members are shared.\n \u2022 The __func__ variable and similar function-local predefined variables are shared.\nC / C++ \nFortran \n \u2022 Cray pointees have the same data-sharing attribute as the storage with which their Cray pointers \n are associated."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\nC / C++ \nFortran \n \u2022 Cray pointees have the same data-sharing attribute as the storage with which their Cray pointers \n are associated.Cray pointer support has been deprecated.\n \u2022 Assumed-size arrays and named constants are shared.\n \u2022 An associate name that may appear in a variable definition context is shared if its association \n occurs outside of the construct and otherwise it has the same data-sharing attribute as the \n selector with which it is associated.\nFortran \n Variables with predetermined data-sharing attributes may not be listed in data-sharing attribute \n clauses, except for the cases listed below.For these exceptions only, listing a predetermined \n variable in a data-sharing attribute clause is allowed and overrides the variable\u2019s predetermined \n data-sharing attributes.\n \u2022 The loop iteration variable in any associated loop of a loop-associated construct may be listed in \n a private or lastprivate clause."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\n \u2022 The loop iteration variable in any associated loop of a loop-associated construct may be listed in \n a private or lastprivate clause.\n \u2022 If a simd construct has just one associated loop then its loop iteration variable may be listed in a \n linear clause with a linear-step that is the increment of the associated loop.\nC / C++ \n \u2022 Variables with const-qualified type with no mutable members may be listed in a \n firstprivate clause, even if they are static data members.\n \u2022 The __func__ variable and similar function-local predefined variables may be listed in a \n shared or firstprivate clause.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n \u2022 Loop iteration variables of loops that are not associated with any OpenMP directive may be \n listed in data-sharing attribute clauses on the surrounding teams, parallel or task generating \n construct, and on enclosed constructs, subject to other restrictions.\n \u2022 Assumed-size arrays may be listed in a shared clause."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\n \u2022 Assumed-size arrays may be listed in a shared clause.\n \u2022 Named constants may be listed in a shared or firstprivate clause.\nFortran \n Additional restrictions on the variables that may appear in individual clauses are described with \n each clause in Section 5.4.\n Variables with explicitly determined data-sharing attributes are those that are referenced in a given \n construct and are listed in a data-sharing attribute clause on the construct.\n Variables with implicitly determined data-sharing attributes are those that are referenced in a given \n construct and do not have predetermined or explicitly determined data-sharing attributes in that \n construct.\n Rules for variables with implicitly determined data-sharing attributes are as follows: \n \u2022 In a parallel, teams, or task generating construct, the data-sharing attributes of these \n variables are determined by the default clause, if present (see Section 5.4.1)."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\n Rules for variables with implicitly determined data-sharing attributes are as follows: \n \u2022 In a parallel, teams, or task generating construct, the data-sharing attributes of these \n variables are determined by the default clause, if present (see Section 5.4.1).\n \u2022 In a parallel construct, if no default clause is present, these variables are shared.\n \u2022 For constructs other than task generating constructs, if no default clause is present, these \n variables reference the variables with the same names that exist in the enclosing context.\n \u2022 In a target construct, variables that are not mapped after applying data-mapping attribute \n rules (see Section 5.8) are firstprivate.\nC++ \n \u2022 In an orphaned task generating construct, if no default clause is present, formal arguments \n passed by reference are firstprivate.\nC++ \nFortran \n \u2022 In an orphaned task generating construct, if no default clause is present, dummy arguments \n are firstprivate.\nFortran \nCHAPTER 5."}
{"section_title": "5.1.1 Variables Referenced in a Construct", "chunk": "\nFortran \nCHAPTER 5.DATA ENVIRONMENT 99 \n \u2022 In a task generating construct, if no default clause is present, a variable for which the \n data-sharing attribute is not determined by the rules above and that in the enclosing context is \n determined to be shared by all implicit tasks bound to the current team is shared.\n \u2022 In a task generating construct, if no default clause is present, a variable for which the \n data-sharing attribute is not determined by the rules above is firstprivate.\n A program is non-conforming if a variable in a task generating construct is implicitly determined to \n be firstprivate according to the above rules but is not permitted to appear in a firstprivate \n clause according to the restrictions specified in Section 5.4.4.\n"}
{"section_title": "5.1.2 Variables Referenced in a Region but not in a Construct", "chunk": "10 Construct \n The data-sharing attributes of variables that are referenced in a region, but not in the corresponding \n construct, are determined as follows: \nC / C++ \n \u2022 Variables with static storage duration that are declared in called routines in the region are shared.\n \u2022 File-scope or namespace-scope variables referenced in called routines in the region are shared \n unless they appear as arguments in a threadprivate directive.\n \u2022 Objects with dynamic storage duration are shared.\n \u2022 Static data members are shared unless they appear as arguments in a threadprivate \n directive.\n \u2022 In C++, formal arguments of called routines in the region that are passed by reference have the \n same data-sharing attributes as the associated actual arguments.\n \u2022 Other variables declared in called routines in the region are private."}
{"section_title": "5.1.2 Variables Referenced in a Region but not in a Construct", "chunk": "\n \u2022 Other variables declared in called routines in the region are private.\nC / C++ \nFortran \n \u2022 Local variables declared in called routines in the region and that have the SAVE attribute, or that \n are data initialized, are shared unless they appear as arguments in a threadprivate directive.\n \u2022 Variables belonging to common blocks, or accessed by host or use association, and referenced in \n called routines in the region are shared unless they appear as arguments in a threadprivate \n directive.\n \u2022 Dummy arguments of called routines in the region that have the VALUE attribute are private.\n \u2022 A dummy argument of a called routine in the region that does not have the VALUE attribute is \n private if the associated actual argument is not shared."}
{"section_title": "5.1.2 Variables Referenced in a Region but not in a Construct", "chunk": "\n \u2022 A dummy argument of a called routine in the region that does not have the VALUE attribute is \n private if the associated actual argument is not shared.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 A dummy argument of a called routine in the region that does not have the VALUE attribute is \n shared if the actual argument is shared and it is a scalar variable, structure, an array that is not a \n pointer or assumed-shape array, or a simply contiguous array section.Otherwise, the \n data-sharing attribute of the dummy argument is implementation defined if the associated actual \n argument is shared.\n \u2022 Cray pointees have the same data-sharing attribute as the storage with which their Cray pointers \n are associated.Cray pointer support has been deprecated.\n \u2022 Implied-do indices, DO CONCURRENT indices, FORALL indices, and other local variables \n declared in called routines in the region are private.\nFortran \n"}
{"section_title": "5.2 threadprivate Directive", "chunk": "Name: threadprivate Association: none \nCategory: declarative Properties: default 11 \n Arguments \n threadprivate(list) \nName Type Properties \nlist list of variable list item type default 14 \n Semantics \n The threadprivate directive specifies that variables are replicated, with each thread having its \n own copy.Unless otherwise specified, each copy of a threadprivate variable is initialized once, in \n the manner specified by the program, but at an unspecified point in the program prior to the first \n reference to that copy.The storage of all copies of a threadprivate variable is freed according to \n how static variables are handled in the base language, but at an unspecified point in the program.\nC++ \n Each copy of a block-scope threadprivate variable that has a dynamic initializer is initialized the \n first time its thread encounters its definition; if its thread does not encounter its definition, its \n initialization is unspecified."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\nC++ \n Each copy of a block-scope threadprivate variable that has a dynamic initializer is initialized the \n first time its thread encounters its definition; if its thread does not encounter its definition, its \n initialization is unspecified.\nC++ \n The content of a threadprivate variable can change across a task scheduling point if the executing \n thread switches to another task that modifies the variable.For more details on task scheduling, see \n Section 1.3 and Chapter 12.\n In parallel regions, references by the primary thread are to the copy of the variable in the thread \n that encountered the parallel region.\n During a sequential part, references are to the initial thread\u2019s copy of the variable.The values of \n data in the initial thread\u2019s copy of a threadprivate variable are guaranteed to persist between any \nCHAPTER 5."}
{"section_title": "5.2 threadprivate Directive", "chunk": "The values of \n data in the initial thread\u2019s copy of a threadprivate variable are guaranteed to persist between any \nCHAPTER 5.DATA ENVIRONMENT 101 \n two consecutive references to the variable in the program, provided that no teams construct that is \n not nested inside of a target construct is encountered between the references and that the initial \n thread is not executing code inside of a teams region.For initial threads that are executing code \n inside of a teams region, the values of data in the copies of a threadprivate variable of those initial \n threads are guaranteed to persist between any two consecutive references to the variable inside that \n teams region."}
{"section_title": "5.2 threadprivate Directive", "chunk": "For initial threads that are executing code \n inside of a teams region, the values of data in the copies of a threadprivate variable of those initial \n threads are guaranteed to persist between any two consecutive references to the variable inside that \n teams region.\n The values of data in the threadprivate variables of threads that are not initial threads are \n guaranteed to persist between two consecutive active parallel regions only if all of the \n following conditions hold: \n \u2022 Neither parallel region is nested inside another explicit parallel region; \n \u2022 The sizes of the thread teams used to execute both parallel regions are the same; \n \u2022 The thread affinity policies used to execute both parallel regions are the same; \n \u2022 The value of the dyn-var internal control variable in the enclosing task region is false at entry to \n both parallel regions; \n \u2022 No teams construct that is not nested inside of a target construct is encountered between the \n parallel regions; \n \u2022 No construct with an order clause that specifies concurrent is encountered between the \n parallel regions; and \n \u2022 Neither the omp_pause_resource nor omp_pause_resource_all routine is called."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n The values of data in the threadprivate variables of threads that are not initial threads are \n guaranteed to persist between two consecutive active parallel regions only if all of the \n following conditions hold: \n \u2022 Neither parallel region is nested inside another explicit parallel region; \n \u2022 The sizes of the thread teams used to execute both parallel regions are the same; \n \u2022 The thread affinity policies used to execute both parallel regions are the same; \n \u2022 The value of the dyn-var internal control variable in the enclosing task region is false at entry to \n both parallel regions; \n \u2022 No teams construct that is not nested inside of a target construct is encountered between the \n parallel regions; \n \u2022 No construct with an order clause that specifies concurrent is encountered between the \n parallel regions; and \n \u2022 Neither the omp_pause_resource nor omp_pause_resource_all routine is called.\n If these conditions all hold, and if a threadprivate variable is referenced in both regions, then threads \n with the same thread number in their respective regions reference the same copy of that variable."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n If these conditions all hold, and if a threadprivate variable is referenced in both regions, then threads \n with the same thread number in their respective regions reference the same copy of that variable.\nC / C++ \n If the above conditions hold, the storage duration, lifetime, and value of a thread\u2019s copy of a \n threadprivate variable that does not appear in any copyin clause on the corresponding construct \n of the second region spans the two consecutive active parallel regions.Otherwise, the storage \n duration, lifetime, and value of a thread\u2019s copy of the variable in the second region is unspecified."}
{"section_title": "5.2 threadprivate Directive", "chunk": "Otherwise, the storage \n duration, lifetime, and value of a thread\u2019s copy of the variable in the second region is unspecified.\nC / C++ \nFortran \n If the above conditions hold, the definition, association, or allocation status of a thread\u2019s copy of a \n threadprivate variable or a variable in a threadprivate common block that is not affected by any \n copyin clause that appears on the corresponding construct of the second region (a variable is \n affected by a copyin clause if the variable appears in the copyin clause or it is in a common \n block that appears in the copyin clause) spans the two consecutive active parallel regions.\n Otherwise, the definition and association status of a thread\u2019s copy of the variable in the second \n region are undefined, and the allocation status of an allocatable variable are implementation defined."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n Otherwise, the definition and association status of a thread\u2019s copy of the variable in the second \n region are undefined, and the allocation status of an allocatable variable are implementation defined.\n If a threadprivate variable or a variable in a threadprivate common block is not affected by any \n copyin clause that appears on the corresponding construct of the first parallel region in \n OpenMP API \u2013 Version 5.2 November 2021 \n which it is referenced, the thread\u2019s copy of the variable inherits the declared type parameter and the \n default parameter values from the original variable.The variable or any subobject of the variable is \n initially defined or undefined according to the following rules: \n \u2022 If it has the ALLOCATABLE attribute, each copy created has an initial allocation status of \n unallocated; \n \u2022 If it has the POINTER attribute, each copy has the same association status as the initial \n association status."}
{"section_title": "5.2 threadprivate Directive", "chunk": "The variable or any subobject of the variable is \n initially defined or undefined according to the following rules: \n \u2022 If it has the ALLOCATABLE attribute, each copy created has an initial allocation status of \n unallocated; \n \u2022 If it has the POINTER attribute, each copy has the same association status as the initial \n association status.\n \u2022 If it does not have either the POINTER or the ALLOCATABLE attribute: \n \u2013 If it is initially defined, either through explicit initialization or default initialization, each copy \n created is so defined; \n \u2013 Otherwise, each copy created is undefined.\nFortran \nC++ \n The order in which any constructors for different threadprivate variables of class type are called is \n unspecified.The order in which any destructors for different threadprivate variables of class type \n are called is unspecified."}
{"section_title": "5.2 threadprivate Directive", "chunk": "The order in which any destructors for different threadprivate variables of class type \n are called is unspecified.\nC++ \n Restrictions \n Restrictions to the threadprivate directive are as follows: \n \u2022 A thread must not reference another thread\u2019s copy of a threadprivate variable.\n \u2022 A threadprivate variable must not appear as the base variable of a list item in any clause except \n for the copyin and copyprivate clauses.\n \u2022 A program in which an untied task accesses threadprivate storage is non-conforming.\nC / C++ \n \u2022 Each list item must be a file-scope, namespace-scope, or static block-scope variable.\n \u2022 No list item may have an incomplete type.\n \u2022 The address of a threadprivate variable must not be an address constant.\n \u2022 If the value of a variable referenced in an explicit initializer of a threadprivate variable is \n modified prior to the first reference to any instance of the threadprivate variable, the behavior is \n unspecified."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n \u2022 If the value of a variable referenced in an explicit initializer of a threadprivate variable is \n modified prior to the first reference to any instance of the threadprivate variable, the behavior is \n unspecified.\n \u2022 A variable that is part of another variable (as an array element or a structure element) cannot \n appear in a threadprivate directive unless it is a static data member of a C++ class.\n \u2022 A threadprivate directive for file-scope variables must appear outside any definition or \n declaration, and must lexically precede all references to any of the variables in its list.\nCHAPTER 5.DATA ENVIRONMENT 103 \n \u2022 A threadprivate directive for namespace-scope variables must appear outside any \n definition or declaration other than the namespace definition itself and must lexically precede all \n references to any of the variables in its list."}
{"section_title": "5.2 threadprivate Directive", "chunk": "DATA ENVIRONMENT 103 \n \u2022 A threadprivate directive for namespace-scope variables must appear outside any \n definition or declaration other than the namespace definition itself and must lexically precede all \n references to any of the variables in its list.\n \u2022 Each variable in the list of a threadprivate directive at file, namespace, or class scope must \n refer to a variable declaration at file, namespace, or class scope that lexically precedes the \n directive.\n \u2022 A threadprivate directive for static block-scope variables must appear in the scope of the \n variable and not in a nested scope.The directive must lexically precede all references to any of \n the variables in its list.\n \u2022 Each variable in the list of a threadprivate directive in block scope must refer to a variable \n declaration in the same scope that lexically precedes the directive.The variable must have static \n storage duration."}
{"section_title": "5.2 threadprivate Directive", "chunk": "The variable must have static \n storage duration.\n \u2022 If a variable is specified in a threadprivate directive in one translation unit, it must be \n specified in a threadprivate directive in every translation unit in which it is declared.\nC / C++ \nC++ \n \u2022 A threadprivate directive for static class member variables must appear in the class \n definition, in the same scope in which the member variables are declared, and must lexically \n precede all references to any of the variables in its list.\n \u2022 A threadprivate variable must not have an incomplete type or a reference type."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n \u2022 A threadprivate variable must not have an incomplete type or a reference type.\n \u2022 A threadprivate variable with class type must have: \n \u2013 An accessible, unambiguous default constructor in the case of default initialization without a \n given initializer; \n \u2013 An accessible, unambiguous constructor that accepts the given argument in the case of direct \n initialization; and \n \u2013 An accessible, unambiguous copy constructor in the case of copy initialization with an explicit \n initializer.\nC++ \nFortran \n \u2022 Each list item must be a named variable or a named common block; a named common block \n must appear between slashes.\n \u2022 The list argument must not include any corrays associate names.\n \u2022 The threadprivate directive must appear in the declaration section of a scoping unit in \n which the common block or variable is declared."}
{"section_title": "5.2 threadprivate Directive", "chunk": "\n \u2022 The threadprivate directive must appear in the declaration section of a scoping unit in \n which the common block or variable is declared.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If a threadprivate directive that specifies a common block name appears in one program \n unit, then such a directive must also appear in every other program unit that contains a COMMON \n statement that specifies the same name.It must appear after the last such COMMON statement in \n the program unit.\n \u2022 If a threadprivate variable or a threadprivate common block is declared with the BIND attribute, \n the corresponding C entities must also be specified in a threadprivate directive in the C \n program.\n \u2022 A variable may only appear as an argument in a threadprivate directive in the scope in \n which it is declared.It must not be an element of a common block or appear in an \n EQUIVALENCE statement."}
{"section_title": "5.2 threadprivate Directive", "chunk": "It must not be an element of a common block or appear in an \n EQUIVALENCE statement.\n \u2022 A variable that appears as an argument in a threadprivate directive must be declared in the \n scope of a module or have the SAVE attribute, either explicitly or implicitly.\n \u2022 The effect of an access to a threadprivate variable in a DO CONCURRENT construct is unspecified.\nFortran \n Cross References \n \u2022 Determining the Number of Threads for a parallel Region, see Section 10.1.1 \n \u2022 copyin clause, see Section 5.7.1 \n \u2022 dyn-var ICV, see Table 2.1 \n \u2022 order clause, see Section 10.3 \n"}
{"section_title": "5.3 List Item Privatization", "chunk": "20 Some data-sharing attribute clauses, including reduction clauses, specify that list items that appear \n in their list argument may be privatized for the construct on which they appear.Each task that \n references a privatized list item in any statement in the construct receives at least one new list item \n if the construct has one or more associated loops, and otherwise each such task receives one new \n list item.Each SIMD lane used in a simd construct that references a privatized list item in any \n statement in the construct receives at least one new list item.Language-specific attributes for new \n list items are derived from the corresponding original list item.Inside the construct, all references to \n the original list item are replaced by references to a new list item received by the task or SIMD lane."}
{"section_title": "5.3 List Item Privatization", "chunk": "Inside the construct, all references to \n the original list item are replaced by references to a new list item received by the task or SIMD lane.\n If the construct has one or more associated loops then, within the same logical iteration of the \n loops, the same new list item replaces all references to the original list item.For any two logical \n iterations, if the references to the original list item are replaced by the same list item then the logical \n iterations must execute in some sequential order.\n In the rest of the region, whether references are to a new list item or the original list item is \n unspecified.Therefore, if an attempt is made to reference the original item, its value after the \nCHAPTER 5.DATA ENVIRONMENT 105 \n region is also unspecified.If a task or a SIMD lane does not reference a privatized list item, \n whether the task or SIMD lane receives a new list item is unspecified."}
{"section_title": "5.3 List Item Privatization", "chunk": "If a task or a SIMD lane does not reference a privatized list item, \n whether the task or SIMD lane receives a new list item is unspecified.\n The value and/or allocation status of the original list item will change only: \n \u2022 If accessed and modified via a pointer; \n \u2022 If possibly accessed in the region but outside of the construct; \n \u2022 As a side effect of directives or clauses; or \nFortran \n \u2022 If accessed and modified via construct association.\nFortran \nC++ \n If the construct is contained in a member function, whether accesses anywhere in the region \n through the implicit this pointer refer to the new list item or the original list item is unspecified.\nC++ \nC / C++ \n A new list item of the same type, with automatic storage duration, is allocated for the construct.\n The storage and thus lifetime of these list items last until the block in which they are created exits.\n The size and alignment of the new list item are determined by the type of the variable."}
{"section_title": "5.3 List Item Privatization", "chunk": "\n The size and alignment of the new list item are determined by the type of the variable.This \n allocation occurs once for each task generated by the construct and once for each SIMD lane used \n by the construct.\n The new list item is initialized, or has an undefined initial value, as if it had been locally declared \n without an initializer.\nC / C++ \nC++ \n If the type of a list item is a reference to a type T then the type will be considered to be T for all \n purposes of the clause.\n The order in which any default constructors for different private variables of class type are called is \n unspecified.The order in which any destructors for different private variables of class type are \n called is unspecified.\nC++ \nFortran \n If any statement of the construct references a list item, a new list item of the same type and type \n parameters is allocated."}
{"section_title": "5.3 List Item Privatization", "chunk": "\nC++ \nFortran \n If any statement of the construct references a list item, a new list item of the same type and type \n parameters is allocated.This allocation occurs once for each task generated by the construct and \n once for each SIMD lane used by the construct.If the type of the list item has default initialization, \n the new list item has default initialization.Otherwise, the initial value of the new list item is \n undefined.The initial status of a private pointer is undefined."}
{"section_title": "5.3 List Item Privatization", "chunk": "The initial status of a private pointer is undefined.\n OpenMP API \u2013 Version 5.2 November 2021 \n For a list item or the subobject of a list item with the ALLOCATABLE attribute: \n \u2022 If the allocation status is unallocated, the new list item or the subobject of the new list item will \n have an initial allocation status of unallocated; \n \u2022 If the allocation status is allocated, the new list item or the subobject of the new list item will \n have an initial allocation status of allocated; and \n \u2022 If the new list item or the subobject of the new list item is an array, its bounds will be the same as \n those of the original list item or the subobject of the original list item.\n A privatized list item may be storage-associated with other variables when the data-sharing \n attribute clause is encountered.Storage association may exist because of base language constructs \n such as EQUIVALENCE or COMMON."}
{"section_title": "5.3 List Item Privatization", "chunk": "Storage association may exist because of base language constructs \n such as EQUIVALENCE or COMMON.If A is a variable that is privatized by a construct and B is a \n variable that is storage-associated with A then: \n \u2022 The contents, allocation, and association status of B are undefined on entry to the region; \n \u2022 Any definition of A, or of its allocation or association status, causes the contents, allocation, and \n association status of B to become undefined; and \n \u2022 Any definition of B, or of its allocation or association status, causes the contents, allocation, and \n association status of A to become undefined.\n A privatized list item may be a selector of an ASSOCIATE or SELECT TYPE construct.If the \n construct association is established prior to a parallel region, the association between the \n associate name and the original list item will be retained in the region."}
{"section_title": "5.3 List Item Privatization", "chunk": "If the \n construct association is established prior to a parallel region, the association between the \n associate name and the original list item will be retained in the region.\n Finalization of a list item of a finalizable type or subobjects of a list item of a finalizable type \n occurs at the end of the region.The order in which any final subroutines for different variables of a \n finalizable type are called is unspecified.\nFortran \n If a list item appears in both firstprivate and lastprivate clauses, the update required \n for the lastprivate clause occurs after all initializations for the firstprivate clause.\n Restrictions \n The following restrictions apply to any list item that is privatized unless otherwise stated for a given \n data-sharing attribute clause: \nC++ \n \u2022 A variable of class type (or array thereof) that is privatized requires an accessible, unambiguous \n default constructor for the class type.\nC++ \nCHAPTER 5."}
{"section_title": "5.3 List Item Privatization", "chunk": "\nC++ \nCHAPTER 5.DATA ENVIRONMENT 107 \nC / C++ \n \u2022 A variable that is privatized must not have a const-qualified type unless it is of class type with \n a mutable member.This restriction does not apply to the firstprivate clause.\n \u2022 A variable that is privatized must not have an incomplete type or be a reference to an incomplete \n type.\nC / C++ \nFortran \n \u2022 Variables that appear in namelist statements, in variable format expressions, and in expressions \n for statement function definitions, must not be privatized.\n \u2022 Pointers with the INTENT(IN) attribute must not be privatized.This restriction does not apply \n to the firstprivate clause.\n \u2022 A private variable must not be coindexed or appear as an actual argument to a procedure where \n the corresponding dummy argument is a coarray.\n \u2022 Assumed-size arrays must not be privatized in a target, teams, or distribute construct.\nFortran \n"}
{"section_title": "5.4 Data-Sharing Attribute Clauses", "chunk": "13 Several constructs accept clauses that allow a user to control the data-sharing attributes of variables \n referenced in the construct.Not all of the clauses listed in this section are valid on all directives.\n The set of clauses that is valid on a particular directive is described with the directive.The \n reduction data-sharing attribute clauses are explained in Section 5.5.\n A list item may be specified in both firstprivate and lastprivate clauses.\nC++ \n If a variable referenced in a data-sharing attribute clause has a type derived from a template and the \n program does not otherwise reference that variable, any behavior related to that variable is \n unspecified.\nC++ \nFortran \n If individual members of a common block appear in a data-sharing attribute clause other than the \n shared clause, the variables no longer have a Fortran storage association with the common block.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.4.1 default Clause", "chunk": "2 Name: default Properties: unique \n Arguments \nName Type Properties \ndata-sharing-attribute Keyword: firstprivate, none, \nprivate, shared \n default \n Directives \n parallel, task, taskloop, teams \n Semantics \n The default clause determines the implicit data-sharing attribute of certain variables that are \n referenced in the construct, in accordance with the rules given in Section 5.1.1.\n If data-sharing-attribute is not none, the data-sharing attribute of all variables referenced in the \n construct that have implicitly determined data-sharing attributes will be data-sharing-attribute.If \n data-sharing-attribute is none, the data-sharing attribute is not implicitly determined."}
{"section_title": "5.4.1 default Clause", "chunk": "If \n data-sharing-attribute is none, the data-sharing attribute is not implicitly determined.\n Restrictions \n Restrictions to the default clause are as follows: \n \u2022 If data-sharing-attribute is none, each variable that is referenced in the construct and does not \n have a predetermined data-sharing attribute must have its data-sharing attribute explicitly \n determined by being listed in a data-sharing attribute clause.\nC / C++ \n \u2022 If data-sharing-attribute is firstprivate or private, each variable with static storage \n duration that is declared in a namespace or global scope, is referenced in the construct, and does \n not have a predetermined data-sharing attribute must have its data-sharing attribute explicitly \n determined by being listed in a data-sharing attribute clause."}
{"section_title": "5.4.1 default Clause", "chunk": "\nC / C++ \n \u2022 If data-sharing-attribute is firstprivate or private, each variable with static storage \n duration that is declared in a namespace or global scope, is referenced in the construct, and does \n not have a predetermined data-sharing attribute must have its data-sharing attribute explicitly \n determined by being listed in a data-sharing attribute clause.\nC / C++ \n Cross References \n \u2022 parallel directive, see Section 10.1 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \nCHAPTER 5.DATA ENVIRONMENT 109 \n"}
{"section_title": "5.4.2 shared Clause", "chunk": "Name: shared Properties: data-environment attribute, data\ufffesharing attribute 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Directives \n parallel, task, taskloop, teams \n Semantics \n The shared clause declares one or more list items to be shared by tasks generated by the construct \n on which it appears.All references to a list item within a task refer to the storage area of the \n original variable at the point the directive was encountered.\n The programmer must ensure, by adding proper synchronization, that storage shared by an explicit \n task region does not reach the end of its lifetime before the explicit task region completes its \n execution.\nFortran \n The association status of a shared pointer becomes undefined upon entry to and exit from the \n construct if it is associated with a target or a subobject of a target that appears as a privatized list \n item in a data-sharing attribute clause on the construct."}
{"section_title": "5.4.2 shared Clause", "chunk": "\nFortran \n The association status of a shared pointer becomes undefined upon entry to and exit from the \n construct if it is associated with a target or a subobject of a target that appears as a privatized list \n item in a data-sharing attribute clause on the construct.A reference to the shared storage that is \n associated with the dummy argument by any other task must be synchronized with the reference to \n the procedure to avoid possible data races.\nFortran \n Cross References \n \u2022 parallel directive, see Section 10.1 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.4.3 private Clause", "chunk": "Name: private Properties: data-environment attribute, data\ufffesharing attribute, privatization 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Directives \n distribute, do, for, loop, parallel, scope, sections, simd, single, target, \n task, taskloop, teams \n Semantics \n The private clause specifies that its list items are to be privatized according to Section 5.3.Each \n task or SIMD lane that references a list item in the construct receives only one new list item, unless \n the construct has one or more associated loops and an order clause that specifies concurrent \n is also present.\n Restrictions \n Restrictions to the private clause are as specified in Section 5.3."}
{"section_title": "5.4.3 private Clause", "chunk": "\n Restrictions \n Restrictions to the private clause are as specified in Section 5.3.\n Cross References \n \u2022 List Item Privatization, see Section 5.3 \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 parallel directive, see Section 10.1 \n \u2022 scope directive, see Section 11.2 \n \u2022 sections directive, see Section 11.3 \n \u2022 simd directive, see Section 10.4 \n \u2022 single directive, see Section 11.1 \n \u2022 target directive, see Section 13.8 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \nCHAPTER 5.DATA ENVIRONMENT 111 \n"}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "Name: firstprivate Properties: data-environment attribute, data\ufffesharing attribute, privatization 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Directives \n distribute, do, for, parallel, scope, sections, single, target, task, \n taskloop, teams \n Semantics \n The firstprivate clause provides a superset of the functionality provided by the private \n clause.A list item that appears in a firstprivate clause is subject to the private clause \n semantics described in Section 5.4.3, except as noted.In addition, the new list item is initialized \n from the original list item that exists before the construct.The initialization of the new list item is \n done once for each task that references the list item in any statement in the construct.The \n initialization is done prior to the execution of the construct."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "The \n initialization is done prior to the execution of the construct.\n For a firstprivate clause on a construct that is not a work-distribution construct, the initial \n value of the new list item is the value of the original list item that exists immediately prior to the \n construct in the task region where the construct is encountered unless otherwise specified.For a \n firstprivate clause on a work-distribution construct, the initial value of the new list item for \n each implicit task of the threads that execute the construct is the value of the original list item that \n exists in the implicit task immediately prior to the point in time that the construct is encountered \n unless otherwise specified.\n To avoid data races, concurrent updates of the original list item must be synchronized with the read \n of the original list item that occurs as a result of the firstprivate clause."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n To avoid data races, concurrent updates of the original list item must be synchronized with the read \n of the original list item that occurs as a result of the firstprivate clause.\nC / C++ \n For variables of non-array type, the initialization occurs by copy assignment.For an array of \n elements of non-array type, each element is initialized as if by assignment from an element of the \n original array to the corresponding element of the new array.\nC / C++ \nC++ \n For each variable of class type: \n \u2022 If the firstprivate clause is not on a target construct then a copy constructor is invoked \n to perform the initialization; and \n \u2022 If the firstprivate clause is on a target construct then how many copy constructors, if \n any, are invoked is unspecified.\n OpenMP API \u2013 Version 5.2 November 2021 \n If copy constructors are called, the order in which copy constructors for different variables of class \n type are called is unspecified."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If copy constructors are called, the order in which copy constructors for different variables of class \n type are called is unspecified.\nC++ \nFortran \n If the original list item does not have the POINTER attribute, initialization of the new list items \n occurs as if by intrinsic assignment unless the original list item has a compatible type-bound \n defined assignment, in which case initialization of the new list items occurs as if by the defined \n assignment.If the original list item that does not have the POINTER attribute has the allocation \n status of unallocated, the new list items will have the same status.\n If the original list item has the POINTER attribute, the new list items receive the same association \n status as the original list item, as if by pointer assignment.\n The list items that appear in a firstprivate clause may include named constants."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n The list items that appear in a firstprivate clause may include named constants.\nFortran \n Restrictions \n Restrictions to the firstprivate clause are as follows: \n \u2022 A list item that is private within a parallel region must not appear in a firstprivate \n clause on a worksharing construct if any of the worksharing regions that arise from the \n worksharing construct ever bind to any of the parallel regions that arise from the \n parallel construct.\n \u2022 A list item that is private within a teams region must not appear in a firstprivate clause \n on a distribute construct if any of the distribute regions that arise from the \n distribute construct ever bind to any of the teams regions that arise from the teams \n construct."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n \u2022 A list item that is private within a teams region must not appear in a firstprivate clause \n on a distribute construct if any of the distribute regions that arise from the \n distribute construct ever bind to any of the teams regions that arise from the teams \n construct.\n \u2022 A list item that appears in a reduction clause of a parallel construct must not appear in a \n firstprivate clause on a worksharing, task, or taskloop construct if any of the \n worksharing or task regions that arise from the worksharing, task, or taskloop construct \n ever bind to any of the parallel regions that arise from the parallel construct.\n \u2022 A list item that appears in a reduction clause of a teams construct must not appear in a \n firstprivate clause on a distribute construct if any of the distribute regions that \n arise from the distribute construct ever bind to any of the teams regions that arise from the \n teams construct."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n \u2022 A list item that appears in a reduction clause of a teams construct must not appear in a \n firstprivate clause on a distribute construct if any of the distribute regions that \n arise from the distribute construct ever bind to any of the teams regions that arise from the \n teams construct.\n \u2022 A list item that appears in a reduction clause of a worksharing construct must not appear in a \n firstprivate clause in a task construct encountered during execution of any of the \n worksharing regions that arise from the worksharing construct.\nCHAPTER 5.DATA ENVIRONMENT 113 \nC++ \n \u2022 A variable of class type (or array thereof) that appears in a firstprivate clause requires an \n accessible, unambiguous copy constructor for the class type.\n \u2022 If the original list item in a firstprivate clause on a work-distribution construct has a \n reference type then it must bind to the same object for all threads in the binding thread set of the \n work-distribution region."}
{"section_title": "5.4.4 firstprivate Clause", "chunk": "\n \u2022 If the original list item in a firstprivate clause on a work-distribution construct has a \n reference type then it must bind to the same object for all threads in the binding thread set of the \n work-distribution region.\nC++ \nFortran \n \u2022 If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is \n unspecified.\nFortran \n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 private clause, see Section 5.4.3 \n \u2022 scope directive, see Section 11.2 \n \u2022 sections directive, see Section 11.3 \n \u2022 single directive, see Section 11.1 \n \u2022 target directive, see Section 13.8 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "Name: lastprivate Properties: data-environment attribute, data\ufffesharing attribute, privatization 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Modifiers \nName Modifies Type Properties \nlastprivate\ufffemodifier \n list Keyword: conditional default \n Directives \n distribute, do, for, loop, sections, simd, taskloop \n Semantics \n The lastprivate clause provides a superset of the functionality provided by the private \n clause.A list item that appears in a lastprivate clause is subject to the private clause \n semantics described in Section 5.4.3.In addition, when a lastprivate clause without the \n conditional modifier appears on a directive and the list item is not an iteration variable of any \n associated loop, the value of each new list item from the sequentially last iteration of the associated \n loops, or the lexically last structured block sequence associated with a sections construct, is \n assigned to the original list item."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "In addition, when a lastprivate clause without the \n conditional modifier appears on a directive and the list item is not an iteration variable of any \n associated loop, the value of each new list item from the sequentially last iteration of the associated \n loops, or the lexically last structured block sequence associated with a sections construct, is \n assigned to the original list item.When the conditional modifier appears on the clause or the \n list item is an iteration variable of one of the associated loops, if sequential execution of the loop \n nest would assign a value to the list item then the original list item is assigned the value that the list \n item would have after sequential execution of the loop nest.\nC++ \n For class types, the copy assignment operator is invoked.The order in which copy assignment \n operators for different variables of the same class type are invoked is unspecified."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "The order in which copy assignment \n operators for different variables of the same class type are invoked is unspecified.\nC++ \nC / C++ \n For an array of elements of non-array type, each element is assigned to the corresponding element \n of the original array.\nC / C++ \nFortran \n If the original list item does not have the POINTER attribute, its update occurs as if by intrinsic \n assignment unless it has a type bound procedure as a defined assignment.\n If the original list item has the POINTER attribute, its update occurs as if by pointer assignment.\nFortran \nCHAPTER 5.DATA ENVIRONMENT 115 \n When the conditional modifier does not appear on the lastprivate clause, any list item \n that is not an iteration variable of the associated loops and that is not assigned a value by the \n sequentially last iteration of the loops, or by the lexically last structured block sequence associated \n with a sections construct, has an unspecified value after the construct."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "DATA ENVIRONMENT 115 \n When the conditional modifier does not appear on the lastprivate clause, any list item \n that is not an iteration variable of the associated loops and that is not assigned a value by the \n sequentially last iteration of the loops, or by the lexically last structured block sequence associated \n with a sections construct, has an unspecified value after the construct.When the \n conditional modifier does not appear on the lastprivate clause, a list item that is the \n iteration variable of an associated loop and that would not be assigned a value during sequential \n execution of the loop nest has an unspecified value after the construct.Unassigned subcomponents \n also have unspecified values after the construct.\n If the lastprivate clause is used on a construct to which neither the nowait nor the \n nogroup clauses are applied, the original list item becomes defined at the end of the construct."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "\n If the lastprivate clause is used on a construct to which neither the nowait nor the \n nogroup clauses are applied, the original list item becomes defined at the end of the construct.To \n avoid data races, concurrent reads or updates of the original list item must be synchronized with the \n update of the original list item that occurs as a result of the lastprivate clause.\n Otherwise, if the lastprivate clause is used on a construct to which the nowait or the \n nogroup clauses are applied, accesses to the original list item may create a data race.To avoid \n this data race, if an assignment to the original list item occurs then synchronization must be inserted \n to ensure that the assignment completes and the original list item is flushed to memory."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "To avoid \n this data race, if an assignment to the original list item occurs then synchronization must be inserted \n to ensure that the assignment completes and the original list item is flushed to memory.\n If a list item that appears in a lastprivate clause with the conditional modifier is \n modified in the region by an assignment outside the construct or not to the list item then the value \n assigned to the original list item is unspecified.\n Restrictions \n Restrictions to the lastprivate clause are as follows: \n \u2022 A list item must not appear in a lastprivate clause on a work-distribution construct if the \n corresponding region binds to the region of a parallelism-generating construct in which the list \n item is private.\n \u2022 A list item that appears in a lastprivate clause with the conditional modifier must be a \n scalar variable."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "\n \u2022 A list item that appears in a lastprivate clause with the conditional modifier must be a \n scalar variable.\nC++ \n \u2022 A variable of class type (or array thereof) that appears in a lastprivate clause requires an \n accessible, unambiguous default constructor for the class type, unless the list item is also \n specified in a firstprivate clause.\n \u2022 A variable of class type (or array thereof) that appears in a lastprivate clause requires an \n accessible, unambiguous copy assignment operator for the class type.\n \u2022 If an original list item in a lastprivate clause on a work-distribution construct has a \n reference type then it must bind to the same object for all threads in the binding thread set of the \n work-distribution region.\nC++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n \u2022 A variable that appears in a lastprivate clause must be definable."}
{"section_title": "5.4.5 lastprivate Clause", "chunk": "\nC++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n \u2022 A variable that appears in a lastprivate clause must be definable.\n \u2022 If the original list item has the ALLOCATABLE attribute, the corresponding list item of which the \n value is assigned to the original item must have an allocation status of allocated upon exit from \n the sequentially last iteration or lexically last structured block sequence associated with a \n sections construct.\n \u2022 If the list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is \n unspecified.\nFortran \n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 private clause, see Section 5.4.3 \n \u2022 sections directive, see Section 11.3 \n \u2022 simd directive, see Section 10.4 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "5.4.6 linear Clause", "chunk": "Name: linear Properties: data-environment attribute, data\ufffesharing attribute, privatization, post-modified 18 \n Arguments \nName Type Properties \nlist list of variable list item type default 20 \n Modifiers \nName Modifies Type Properties \nstep-simple\ufffemodifier \nlist OpenMP integer expression exclusive, re\ufffegion-invariant, \nunique \nstep-complex\ufffemodifier \nlist Complex, name: step Ar\ufffeguments: \nlinear-step expression of in\ufffeteger type (region-invariant) \nunique \nlinear-modifier list Keyword: ref, uval, val unique \n \nCHAPTER 5.DATA ENVIRONMENT 117 \n Directives \n declare simd, do, for, simd \n Additional information \n list and linear-modifier may instead be specified as linear-modifier(list) for linear clauses that \n appear on a declare simd directive.This syntax has been deprecated.\n Semantics \n The linear clause provides a superset of the functionality provided by the private clause."}
{"section_title": "5.4.6 linear Clause", "chunk": "\n Semantics \n The linear clause provides a superset of the functionality provided by the private clause.A \n list item that appears in a linear clause is subject to the private clause semantics described in \n Section 5.4.3, except as noted.If the step-simple-modifier is specified, the behavior is as if the \n step-complex-modifier is instead specified with step-simple-modifier as its linear-step argument.If \n linear-step is not specified, it is assumed to be 1.\n When a linear clause is specified on a construct, the value of the new list item on each logical \n iteration of the associated loops corresponds to the value of the original list item before entering the \n construct plus the logical number of the iteration times linear-step.The value corresponding to the \n sequentially last logical iteration of the associated loops is assigned to the original list item."}
{"section_title": "5.4.6 linear Clause", "chunk": "The value corresponding to the \n sequentially last logical iteration of the associated loops is assigned to the original list item.\n When a linear clause is specified on a declare simd directive, the list items refer to \n parameters of the procedure to which the directive applies.For a given call to the procedure, the \n clause determines whether the SIMD version generated by the directive may be called.If the clause \n does not specify the ref linear-modifier, the SIMD version requires that the value of the \n corresponding argument at the callsite is equal to the value of the argument from the first lane plus \n the logical number of the lane times the linear-step."}
{"section_title": "5.4.6 linear Clause", "chunk": "If the clause \n does not specify the ref linear-modifier, the SIMD version requires that the value of the \n corresponding argument at the callsite is equal to the value of the argument from the first lane plus \n the logical number of the lane times the linear-step.If the clause specifies the ref linear-modifier, \n the SIMD version requires that the storage locations of the corresponding arguments at the callsite \n from each SIMD lane correspond to locations within a hypothetical array of elements of the same \n type, indexed by the logical number of the lane times the linear-step.\n Restrictions \n Restrictions to the linear clause are as follows: \n \u2022 Only a loop iteration variable of a loop that is associated with the construct may appear as a list \n item in a linear clause if a reduction clause with the inscan modifier also appears on \n the construct.\n \u2022 A linear-modifier may be specified as ref or uval only on a declare simd directive."}
{"section_title": "5.4.6 linear Clause", "chunk": "\n \u2022 A linear-modifier may be specified as ref or uval only on a declare simd directive.\n \u2022 For a linear clause that appears on a loop-associated construct, the difference between the \n value of a list item at the end of a logical iteration and its value at the beginning of the logical \n iteration must be equal to linear-step.\n \u2022 If linear-modifier is uval for a list item in a linear clause that is specified on a \n declare simd directive and the list item is modified during a call to the SIMD version of the \n procedure, the program must not depend on the value of the list item upon return from the \n procedure.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If linear-modifier is uval for a list item in a linear clause that is specified on a \n declare simd directive, the program must not depend on the storage of the argument in the \n procedure being the same as the storage of the corresponding argument at the callsite."}
{"section_title": "5.4.6 linear Clause", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If linear-modifier is uval for a list item in a linear clause that is specified on a \n declare simd directive, the program must not depend on the storage of the argument in the \n procedure being the same as the storage of the corresponding argument at the callsite.\nC \n \u2022 All list items must be of integral or pointer type.\n \u2022 If specified, linear-modifier must be val.\nC \nC++ \n \u2022 If linear-modifier is not ref, all list items must be of integral or pointer type, or must be a \n reference to an integral or pointer type.\n \u2022 If linear-modifier is ref or uval, all list items must be of a reference type.\n \u2022 If a list item in a linear clause on a worksharing construct has a reference type then it must \n bind to the same object for all threads of the team."}
{"section_title": "5.4.6 linear Clause", "chunk": "\n \u2022 If a list item in a linear clause on a worksharing construct has a reference type then it must \n bind to the same object for all threads of the team.\n \u2022 If a list item in a linear clause that is specified on a declare simd directive is of a reference \n type and linear-modifier is not ref, the difference between the value of the argument on exit \n from the function and its value on entry to the function must be the same for all SIMD lanes.\nC++ \nFortran \n \u2022 If linear-modifier is not ref, all list items must be of type integer.\n \u2022 If linear-modifier is ref or uval, all list items must be dummy arguments without the VALUE \n attribute.\n \u2022 List items must not be Cray pointers or variables that have the POINTER attribute.Cray pointer \n support has been deprecated."}
{"section_title": "5.4.6 linear Clause", "chunk": "Cray pointer \n support has been deprecated.\n \u2022 If linear-modifier is not ref and a list item has the ALLOCATABLE attribute, the allocation \n status of the list item in the sequentially last iteration must be allocated upon exit from that \n iteration.\n \u2022 If linear-modifier is ref, list items must be polymorphic variables, assumed-shape arrays, or \n variables with the ALLOCATABLE attribute.\n \u2022 If a list item in a linear clause that is specified on a declare simd directive is a dummy \n argument without the VALUE attribute and linear-modifier is not ref, the difference between the \n value of the argument on exit from the procedure and its value on entry to the procedure must be \n the same for all SIMD lanes.\n \u2022 A common block name must not appear in a linear clause.\nFortran \nCHAPTER 5."}
{"section_title": "5.4.6 linear Clause", "chunk": "\nFortran \nCHAPTER 5.DATA ENVIRONMENT 119 \n Cross References \n \u2022 declare simd directive, see Section 7.7 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 private clause, see Section 5.4.3 \n \u2022 simd directive, see Section 10.4 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "5.4.7 is_device_ptr Clause", "chunk": "Name: is_device_ptr Properties: data-environment attribute, data\ufffesharing attribute 9 \n Arguments \nName Type Properties \nlist list of variable list item type default 11 \n Directives \n dispatch, target \n Semantics \n The is_device_ptr clause indicates that its list items are device pointers.Support for device \n pointers created outside of OpenMP, specifically outside of any OpenMP mechanism that returns a \n device pointer, is implementation defined.\n If the is_device_ptr clause is specified on a target construct, each list item privatized \n inside the construct and the new list item is initialized to the device address to which the original \n list item refers.\nFortran \n If the is_device_ptr clause is specified on a target construct, if any list item is not of type \n C_PTR, the behavior is as if the list item appeared in a has_device_addr clause.Support for \n such list items in an is_device_ptr clause is deprecated."}
{"section_title": "5.4.7 is_device_ptr Clause", "chunk": "Support for \n such list items in an is_device_ptr clause is deprecated.\nFortran \n Restrictions \n Restrictions to the is_device_ptr clause are as follows: \n \u2022 Each list item must be a valid device pointer for the device data environment.\nC \n \u2022 Each list item must have a type of pointer or array.\nC \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n \u2022 Each list item must have a type of pointer, array, reference to pointer or reference to array.\nC++ \nFortran \n \u2022 Each list item must be of type C_PTR unless the clause appears on a target directive; the use \n of list items on the target directive that are not of type C_PTR has been deprecated.\nFortran \n Cross References \n \u2022 dispatch directive, see Section 7.6 \n \u2022 has_device_addr clause, see Section 5.4.9 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "5.4.8 use_device_ptr Clause", "chunk": "Name: use_device_ptr Properties: data-environment attribute, data\ufffesharing attribute 9 \n Arguments \nName Type Properties \nlist list of variable list item type default 11 \n Directives \n target data \n Semantics \nC / C++ \n If a list item that appears in a use_device_ptr clause is a pointer to an object that is mapped to \n the device data environment, references to the list item in the structured block that is associated \n with the construct on which the clause appears are converted into references to a device pointer that \n is local to the structured block and that refers to the device address of the corresponding object.If \n the list item does not point to a mapped object, it must contain a valid device address for the target \n device, and the list item references are instead converted to references to a local device pointer that \n refers to this device address.\nC / C++ \nCHAPTER 5."}
{"section_title": "5.4.8 use_device_ptr Clause", "chunk": "\nC / C++ \nCHAPTER 5.DATA ENVIRONMENT 121 \nFortran \n If a list item that appears in a use_device_ptr clause is of type C_PTR and points to a data \n entity that is mapped to the device data environment, references to the list item in the structured \n block that is associated with the construct on which the clause appears are converted into references \n to a device pointer that is local to the structured block and that refers to the device address of the \n corresponding entity.If a list item of type C_PTR does not point to a mapped object, it must \n contain a valid device address for the target device, and the list item references are instead \n converted to references to a local device pointer that refers to this device address.If a list item in a \n use_device_ptr clause is not of type C_PTR, the behavior is as if the list item appeared in a \n use_device_addr clause.Support for such list items in a use_device_ptr clause is \n deprecated."}
{"section_title": "5.4.8 use_device_ptr Clause", "chunk": "Support for such list items in a use_device_ptr clause is \n deprecated.\nFortran \n Restrictions \n Restrictions to the use_device_ptr clause are as follows: \n \u2022 Each list item must not be a structure element.\nC / C++ \n \u2022 Each list item must be a pointer for which the value is the address of an object that has \n corresponding storage in the device data environment or is accessible on the target device.\nC / C++ \nFortran \n \u2022 The value of a list item that is of type C_PTR must be the address of a data entity that has \n corresponding storage in the device data environment or is accessible on the target device.\nFortran \n Cross References \n \u2022 target data directive, see Section 13.5 \n"}
{"section_title": "5.4.9 has_device_addr Clause", "chunk": "Name: has_device_addr Properties: data-environment attribute, data\ufffesharing attribute 21 \n Arguments \nName Type Properties \nlist list of variable list item type default 23 \n Directives \n target \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The has_device_addr clause indicates that its list items already have device addresses and \n therefore they may be directly accessed from a target device.If the device address of a list item is \n not for the device on which the region that is associated with the construct on which the clause \n appears executes, accessing the list item inside the region results in unspecified behavior.The list \n items may include array sections.\n Restrictions \n Restrictions to the has_device_addr clause are as follows: \n \u2022 Each list item must have a valid device address for the device data environment.\n Cross References \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "5.4.10 use_device_addr Clause", "chunk": "Name: use_device_addr Properties: data-environment attribute, data\ufffesharing attribute 13 \n Arguments \nName Type Properties \nlist list of variable list item type default 15 \n Directives \n target data \n Semantics \n If a list item has corresponding storage in the device data environment, references to the list item in \n the structured block that is associated with the construct on which the use_device_addr clause \n appears are converted into references to the corresponding list item.If the list item is not a mapped \n list item, it is assumed to be accessible on the target device.Inside the structured block, the list item \n has a device address and its storage may not be accessible from the host device.The list items that \n appear in a use_device_addr clause may include array sections."}
{"section_title": "5.4.10 use_device_addr Clause", "chunk": "The list items that \n appear in a use_device_addr clause may include array sections.\nC / C++ \n If a list item in a use_device_addr clause is an array section that has a base pointer, the effect \n of the clause is to convert the base pointer to a pointer that is local to the structured block and that \n contains the device address.This conversion may be elided if the list item was not already mapped.\nC / C++ \nCHAPTER 5.DATA ENVIRONMENT 123 \n Restrictions \n Restrictions to the use_device_addr clause are as follows: \n \u2022 Each list item must have a corresponding list item in the device data environment or be \n accessible on the target device.\n \u2022 Each list item must not be a structure element.\nC / C++ \n \u2022 If a list item is an array section, the base expression must be a base language identifier.\nC / C++ \nFortran \n \u2022 If a list item is an array section, the designator of the base expression must be a name without any \n selectors."}
{"section_title": "5.4.10 use_device_addr Clause", "chunk": "\nC / C++ \nFortran \n \u2022 If a list item is an array section, the designator of the base expression must be a name without any \n selectors.\nFortran \n Cross References \n \u2022 target data directive, see Section 13.5 \n"}
{"section_title": "5.5 Reduction Clauses and Directives", "chunk": "12 The reduction clauses are data-sharing attribute clauses that can be used to perform some forms of \n recurrence calculations in parallel.Reduction clauses include reduction scoping clauses and \n reduction participating clauses.Reduction scoping clauses define the region in which a reduction is \n computed.Reduction participating clauses define the participants in the reduction.\n"}
{"section_title": "5.5.1 OpenMP Reduction Identifiers", "chunk": "17 The syntax of an OpenMP reduction identifier is defined as follows: \nC \n A reduction identifier is either an identifier or one of the following operators: +, - (deprecated), *, \n &, |, ^, && and ||.\nC \nC++ \n A reduction identifier is either an id-expression or one of the following operators: +, \n - (deprecated), *, &, |, ^, && and ||.\nC++ \nFortran \n A reduction identifier is either a base language identifier, or a user-defined operator, or one of the \n following operators: +, - (deprecated), *, .and., .or., .eqv., .neqv., or one of the \n following intrinsic procedure names: max, min, iand, ior, ieor.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.5.2 OpenMP Reduction Expressions", "chunk": "2 A reduction expression is an OpenMP stylized expression that is relevant to reduction clauses.It is \n either a combiner expression or an initializer expression.\n Restrictions \n Restrictions to reduction expressions are as follows: \n \u2022 If execution of a reduction expression results in the execution of an OpenMP construct or an \n OpenMP API call, the behavior is unspecified.\nC / C++ \n \u2022 If a reduction expression corresponds to a reduction identifier that is used in a target region, a \n declare target directive must be specified for any function that can be accessed through the \n expression.\nC / C++ \nFortran \n \u2022 Any subroutine or function used in a reduction expression must be an intrinsic function, or must \n have an accessible interface.\n \u2022 Any user-defined operator, defined assignment or extended operator used in a reduction \n expression must have an accessible interface."}
{"section_title": "5.5.2 OpenMP Reduction Expressions", "chunk": "\n \u2022 Any user-defined operator, defined assignment or extended operator used in a reduction \n expression must have an accessible interface.\n \u2022 If any subroutine, function, user-defined operator, defined assignment or extended operator is \n used in a reduction expression, it must be accessible to the subprogram in which the \n corresponding reduction clause is specified.\n \u2022 Any subroutine used in a reduction expression must not have any alternate returns appear in the \n argument list.\n \u2022 If the list item in the corresponding reduction clause is an array or array section, any \n procedure used in a reduction expression must either be elemental or have dummy arguments that \n are scalar.\n \u2022 Any procedure called in the region of a reduction expression must be pure and may not reference \n any host-associated variables."}
{"section_title": "5.5.2 OpenMP Reduction Expressions", "chunk": "\n \u2022 Any procedure called in the region of a reduction expression must be pure and may not reference \n any host-associated variables.\n \u2022 If a reduction expression corresponds to a reduction identifier that is used in a target region, a \n declare target directive must be specified for any function or subroutine that can be \n accessed through the expression.\nFortran \nCHAPTER 5.DATA ENVIRONMENT 125 \n"}
{"section_title": "5.5.2.1 OpenMP Combiner Expressions", "chunk": "2 A combiner expression specifies how a reduction combines partial results into a single value.\nFortran \n A combiner expression is an assignment statement or a subroutine name followed by an argument \n list.\nFortran \n In the definition of a combiner expression, omp_in and omp_out correspond to two special \n variable identifiers that refer to storage of the type of the reduction list item to which the reduction \n applies.If the list item is an array or array section, the identifiers to which omp_in and omp_out \n correspond each refer to an array element.Each of the two special variable identifiers denotes one \n of the values to be combined before executing the combiner expression.The special omp_out \n identifier refers to the storage that holds the resulting combined value after executing the combiner \n expression.The number of times that the combiner expression is executed and the order of these \n executions for any reduction clause are unspecified."}
{"section_title": "5.5.2.1 OpenMP Combiner Expressions", "chunk": "The number of times that the combiner expression is executed and the order of these \n executions for any reduction clause are unspecified.\nFortran \n If the combiner expression is a subroutine name with an argument list, the combiner expression is \n evaluated by calling the subroutine with the specified argument list.If the combiner expression is an \n assignment statement, the combiner expression is evaluated by executing the assignment statement.\n If a generic name is used in a combiner expression and the list item in the corresponding reduction \n clause is an array or array section, it is resolved to the specific procedure that is elemental or only \n has scalar dummy arguments.\nFortran \n Restrictions \n Restrictions to combiner expressions are as follows: \n \u2022 The only variables allowed in a combiner expression are omp_in and omp_out.\nFortran \n \u2022 Any selectors in the designator of omp_in and omp_out must be component selectors.\nFortran \n"}
{"section_title": "5.5.2.2 OpenMP Initializer Expressions", "chunk": "24 An initializer expression determines the initializer for the private copies of reduction list items.If \n the initialization of the copies is not determined a priori, the syntax of an initializer expression is as \n follows: \nC \n omp_priv = initializer \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n or \nC++ \n omp_priv initializer \nC++ \n or \nC / C++ \n function-name(argument-list) \nC / C++ \n or \nFortran \n omp_priv = expression \n or \n subroutine-name(argument-list) \nFortran \n In the definition of an initializer expression, the omp_priv special variable identifier refers to the \n storage to be initialized.The special variable identifier omp_orig can be used in an initializer \n expression to refer to the storage of the original variable to be reduced.The number of times that an \n initializer expression is evaluated and the order of these evaluations are unspecified."}
{"section_title": "5.5.2.2 OpenMP Initializer Expressions", "chunk": "The number of times that an \n initializer expression is evaluated and the order of these evaluations are unspecified.\nC / C++ \n If an initializer expression is a function name with an argument list, it is evaluated by calling the \n function with the specified argument list.Otherwise, an initializer expression specifies how \n omp_priv is declared and initialized.\nC / C++ \nFortran \n If an initializer expression is a subroutine name with an argument list, the initializer-expr is \n evaluated by calling the subroutine with the specified argument list.If an initializer expression is an \n assignment statement, the initializer expression is evaluated by executing the assignment statement.\nFortran \nC \n The a priori initialization of private copies that are created for reductions follows the rules for \n initialization of objects with static storage duration.\nC \nCHAPTER 5."}
{"section_title": "5.5.2.2 OpenMP Initializer Expressions", "chunk": "\nC \nCHAPTER 5.DATA ENVIRONMENT 127 \nC++ \n The a priori initialization of private copies that are created for reductions follows the rules for \n default-initialization.\nC++ \nFortran \n The rules for a priori initialization of private copies that are created for reductions are as follows: \n \u2022 For complex, real, or integer types, the value 0 will be used.\n \u2022 For logical types, the value .false.will be used.\n \u2022 For derived types for which default initialization is specified, default initialization will be used.\n \u2022 Otherwise, the behavior is unspecified.\nFortran \n Restrictions \n Restrictions to initializer expressions are as follows: \n \u2022 The only variables allowed in an initializer expression are omp_priv and omp_orig.\n \u2022 If an initializer expression modifies the variable omp_orig, the behavior is unspecified.\nC \n \u2022 If an initializer expression is a function name with an argument list, one of the arguments must \n be the address of omp_priv."}
{"section_title": "5.5.2.2 OpenMP Initializer Expressions", "chunk": "\nC \n \u2022 If an initializer expression is a function name with an argument list, one of the arguments must \n be the address of omp_priv.\nC \nC++ \n \u2022 If an initializer expression is a function name with an argument list, one of the arguments must \n be omp_priv or the address of omp_priv.\nC++ \nFortran \n \u2022 If an initializer expression is a subroutine name with an argument list, one of the arguments must \n be omp_priv.\nFortran \n"}
{"section_title": "5.5.3 Implicitly Declared OpenMP Reduction Identifiers", "chunk": "C / C++ \n Table 5.1 lists each reduction identifier that is implicitly declared at every scope for arithmetic types \n and its semantic initializer value.The actual initializer value is that value as expressed in the data \n type of the reduction list item."}
{"section_title": "5.5.3 Implicitly Declared OpenMP Reduction Identifiers", "chunk": "The actual initializer value is that value as expressed in the data \n type of the reduction list item.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 5.1: Implicitly Declared C/C++ Reduction Identifiers \nIdentifier Initializer Combiner \n+ omp_priv = 0 omp_out += omp_in \n- (depre\ufffecated) \nomp_priv = 0 omp_out += omp_in \n* omp_priv = 1 omp_out *= omp_in \n& omp_priv = ~ 0 omp_out &= omp_in \n| omp_priv = 0 omp_out |= omp_in \n^ omp_priv = 0 omp_out ^= omp_in \n&& omp_priv = 1 omp_out = omp_in && omp_out \n|| omp_priv = 0 omp_out = omp_in || omp_out \nmax omp_priv = Minimal \nrepresentable number in the \nreduction list item type \nomp_out = omp_in > omp_out ? \nomp_in : omp_out \nmin omp_priv = Maximal \nrepresentable number in the \nreduction list item type \nomp_out = omp_in < omp_out ? \nomp_in : omp_out \nC / C++ \nFortran \n Table 5.2 lists each reduction identifier that is implicitly declared for numeric and logical types and \n its semantic initializer value."}
{"section_title": "5.5.3 Implicitly Declared OpenMP Reduction Identifiers", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 5.1: Implicitly Declared C/C++ Reduction Identifiers \nIdentifier Initializer Combiner \n+ omp_priv = 0 omp_out += omp_in \n- (depre\ufffecated) \nomp_priv = 0 omp_out += omp_in \n* omp_priv = 1 omp_out *= omp_in \n& omp_priv = ~ 0 omp_out &= omp_in \n| omp_priv = 0 omp_out |= omp_in \n^ omp_priv = 0 omp_out ^= omp_in \n&& omp_priv = 1 omp_out = omp_in && omp_out \n|| omp_priv = 0 omp_out = omp_in || omp_out \nmax omp_priv = Minimal \nrepresentable number in the \nreduction list item type \nomp_out = omp_in > omp_out ? \nomp_in : omp_out \nmin omp_priv = Maximal \nrepresentable number in the \nreduction list item type \nomp_out = omp_in < omp_out ? \nomp_in : omp_out \nC / C++ \nFortran \n Table 5.2 lists each reduction identifier that is implicitly declared for numeric and logical types and \n its semantic initializer value.The actual initializer value is that value as expressed in the data type \n of the reduction list item."}
{"section_title": "5.5.3 Implicitly Declared OpenMP Reduction Identifiers", "chunk": "The actual initializer value is that value as expressed in the data type \n of the reduction list item.\nTABLE 5.2: Implicitly Declared Fortran Reduction Identifiers \nIdentifier Initializer Combiner \n+ omp_priv = 0 omp_out = omp_in + omp_out \n- (depre\ufffecated) \nomp_priv = 0 omp_out = omp_in + omp_out \n* omp_priv = 1 omp_out = omp_in * omp_out \ntable continued on next page \nCHAPTER 5.DATA ENVIRONMENT 129 \ntable continued from previous page \nIdentifier Initializer Combiner \n.and.omp_priv = .true.omp_out = omp_in .and.omp_out \n.or.omp_priv = .false.omp_out = omp_in .or.omp_out \n.eqv.omp_priv = .true.omp_out = omp_in .eqv.omp_out \n.neqv.omp_priv = .false.omp_out = omp_in .neqv."}
{"section_title": "5.5.3 Implicitly Declared OpenMP Reduction Identifiers", "chunk": "omp_out = omp_in .neqv.omp_out \nmax omp_priv = Minimal \nrepresentable number in the \nreduction list item type \nomp_out = max(omp_in, omp_out) \nmin omp_priv = Maximal \nrepresentable number in the \nreduction list item type \nomp_out = min(omp_in, omp_out) \niand omp_priv = All bits on omp_out = iand(omp_in, omp_out) \nior omp_priv = 0 omp_out = ior(omp_in, omp_out) \nieor omp_priv = 0 omp_out = ieor(omp_in, omp_out) \nFortran \n"}
{"section_title": "5.5.4 initializer Clause", "chunk": "2 Name: initializer Properties: unique \n Arguments \nName Type Properties \ninitializer-expr expression of initializer type default 4 \n Directives \n declare reduction \n Semantics \n The initializer clause can be used to specify initializer-expr as the initializer expression for a \n user-defined reduction.\n Cross References \n \u2022 declare reduction directive, see Section 5.5.11 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "2 The clause-specification of a reduction clause has a clause-argument-specification that specifies an \n OpenMP variable list argument and has a required reduction-identifier modifier that specifies the \n reduction identifier to use for the reduction.The reduction identifier must match a previously \n declared reduction identifier of the same name and type for each of the list items.This match is \n done by means of a name lookup in the base language.\n The list items that appear in a reduction clause may include array sections.\nC++ \n If the type is a derived class then any reduction identifier that matches its base classes is also a \n match if no specific match for the type has been specified.\n If the reduction identifier is not an id-expression then it is implicitly converted to one by prepending \n the keyword operator (for example, + becomes operator+).\n If the reduction identifier is qualified then a qualified name lookup is used to find the declaration."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "\n If the reduction identifier is qualified then a qualified name lookup is used to find the declaration.\n If the reduction identifier is unqualified then an argument-dependent name lookup must be \n performed using the type of each list item.\nC++ \n If a list item is an array or array section, it will be treated as if a reduction clause would be applied \n to each separate element of the array section.\n If a list item is an array section, the elements of any copy of the array section will be stored \n contiguously.\nFortran \n If the original list item has the POINTER attribute, any copies of the list item are associated with \n private targets.\nFortran \n Any copies of a list item associated with the reduction are initialized with the initializer value of the \n reduction identifier.Any copies are combined using the combiner associated with the reduction \n identifier."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "Any copies are combined using the combiner associated with the reduction \n identifier.\n Execution Model Events \n The reduction-begin event occurs before a task begins to perform loads and stores that belong to the \n implementation of a reduction and the reduction-end event occurs after the task has completed \n loads and stores associated with the reduction.If a task participates in multiple reductions, each \n reduction may be bracketed by its own pair of reduction-begin/reduction-end events or multiple \n reductions may be bracketed by a single pair of events.The interval defined by a pair of \n reduction-begin/reduction-end events may not contain a task scheduling point.\nCHAPTER 5.DATA ENVIRONMENT 131 \n Tool Callbacks \n A thread dispatches a registered ompt_callback_reduction with \n ompt_sync_region_reduction in its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a reduction-begin event in that thread."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "DATA ENVIRONMENT 131 \n Tool Callbacks \n A thread dispatches a registered ompt_callback_reduction with \n ompt_sync_region_reduction in its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a reduction-begin event in that thread.Similarly, a thread \n dispatches a registered ompt_callback_reduction with \n ompt_sync_region_reduction in its kind argument and ompt_scope_end as its \n endpoint argument for each occurrence of a reduction-end event in that thread.These callbacks \n occur in the context of the task that performs the reduction and has the type signature \n ompt_callback_sync_region_t.\n Restrictions \n Restrictions common to reduction clauses are as follows: \n \u2022 Any array element must be specified at most once in all list items on a directive.\n \u2022 For a reduction identifier declared in a declare reduction directive, the directive must \n appear before its use in a reduction clause."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "\n \u2022 For a reduction identifier declared in a declare reduction directive, the directive must \n appear before its use in a reduction clause.\n \u2022 If a list item is an array section, it must specify contiguous storage, it cannot be a zero-length \n array section and its base expression must be a base language identifier.\n \u2022 If a list item is an array section or an array element, accesses to the elements of the array outside \n the specified array section or array element result in unspecified behavior.\nC / C++ \n \u2022 The type of a list item that appears in a reduction clause must be valid for the reduction identifier.\n For a max or min reduction in C, the type of the list item must be an allowed arithmetic data \n type: char, int, float, double, or _Bool, possibly modified with long, short, \n signed, or unsigned."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "\n For a max or min reduction in C, the type of the list item must be an allowed arithmetic data \n type: char, int, float, double, or _Bool, possibly modified with long, short, \n signed, or unsigned.For a max or min reduction in C++, the type of the list item must be \n an allowed arithmetic data type: char, wchar_t, int, float, double, or bool, possibly \n modified with long, short, signed, or unsigned.\n \u2022 A list item that appears in a reduction clause must not be const-qualified.\n \u2022 The reduction identifier for any list item must be unambiguous and accessible.\nC / C++ \nFortran \n \u2022 The type, type parameters and rank of a list item that appears in a reduction clause must be valid \n for the combiner expression and the initializer expression.\n \u2022 A list item that appears in a reduction clause must be definable.\n \u2022 A procedure pointer must not appear in a reduction clause.\n \u2022 A pointer with the INTENT(IN) attribute must not appear in a reduction clause."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "\n \u2022 A pointer with the INTENT(IN) attribute must not appear in a reduction clause.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 An original list item with the POINTER attribute or any pointer component of an original list \n item that is referenced in a combiner expression must be associated at entry to the construct that \n contains the reduction clause.Additionally, the list item or the pointer component of the list item \n must not be deallocated, allocated, or pointer assigned within the region.\n \u2022 An original list item with the ALLOCATABLE attribute or any allocatable component of an \n original list item that corresponds to a special variable identifier in the combiner expression or \n the initializer expression must be in the allocated state at entry to the construct that contains the \n reduction clause.Additionally, the list item or the allocatable component of the list item must be \n neither deallocated nor allocated, explicitly or implicitly, within the region."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "Additionally, the list item or the allocatable component of the list item must be \n neither deallocated nor allocated, explicitly or implicitly, within the region.\n \u2022 If the reduction identifier is defined in a declare reduction directive, the declare \n reduction directive must be in the same subprogram, or accessible by host or use association.\n \u2022 If the reduction identifier is a user-defined operator, the same explicit interface for that operator \n must be accessible at the location of the declare reduction directive that defines the \n reduction identifier.\n \u2022 If the reduction identifier is defined in a declare reduction directive, any procedure \n referenced in the initializer clause or the combiner expression must be an intrinsic \n function, or must have an explicit interface where the same explicit interface is accessible as at \n the declare reduction directive."}
{"section_title": "5.5.5 Properties Common to All Reduction Clauses", "chunk": "\n \u2022 If the reduction identifier is defined in a declare reduction directive, any procedure \n referenced in the initializer clause or the combiner expression must be an intrinsic \n function, or must have an explicit interface where the same explicit interface is accessible as at \n the declare reduction directive.\nFortran \n Cross References \n \u2022 ompt_callback_sync_region_t, see Section 19.5.2.13 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n"}
{"section_title": "5.5.6 Reduction Scoping Clauses", "chunk": "24 Reduction scoping clauses define the region in which a reduction is computed by tasks or SIMD \n lanes.All properties common to all reduction clauses, which are defined in Section 5.5.5, apply to \n reduction scoping clauses.\n The number of copies created for each list item and the time at which those copies are initialized \n are determined by the particular reduction scoping clause that appears on the construct.The time at \n which the original list item contains the result of the reduction is determined by the particular \n reduction scoping clause.To avoid data races, concurrent reads or updates of the original list item \n must be synchronized with that update of the original list item, which may occur after the construct \n on which the reduction scoping clause appears, for example, due to the use of the nowait clause.\n The location in the OpenMP program at which values are combined and the order in which values \n are combined are unspecified."}
{"section_title": "5.5.6 Reduction Scoping Clauses", "chunk": "\n The location in the OpenMP program at which values are combined and the order in which values \n are combined are unspecified.Thus, when comparing sequential and parallel executions, or when \n comparing one parallel execution to another (even if the number of threads used is the same), \nCHAPTER 5.DATA ENVIRONMENT 133 \n bitwise-identical results are not guaranteed.Similarly, side effects (such as floating-point \n exceptions) may not be identical and may not occur at the same location in the OpenMP program.\n"}
{"section_title": "5.5.7 Reduction Participating Clauses", "chunk": "4 A reduction participating clause specifies a task or a SIMD lane as a participant in a reduction \n defined by a reduction scoping clause.All properties common to all reduction clauses, which are \n defined in Section 5.5.5, apply to reduction participating clauses.\n Accesses to the original list item may be replaced by accesses to copies of the original list item \n created by a region that corresponds to a construct with a reduction scoping clause.\n In any case, the final value of the reduction must be determined as if all tasks or SIMD lanes that \n participate in the reduction are executed sequentially in some arbitrary order.\n"}
{"section_title": "5.5.8 reduction Clause", "chunk": "Name: reduction Properties: data-environment attribute, data\ufffesharing attribute, privatization, reduction \nscoping, reduction participating \n \n Arguments \nName Type Properties \nlist list of variable list item type default 14 \n Modifiers \nName Modifies Type Properties \nreduction\ufffeidentifier \nlist An OpenMP reduction iden\ufffetifier \nrequired, ultimate \nreduction-modifier list Keyword: default, \ninscan, task \ndefault \n \n Directives \n do, for, loop, parallel, scope, sections, simd, taskloop, teams \n Semantics \n The reduction clause is a reduction scoping clause and a reduction participating clause, as \n described in Section 5.5.6 and Section 5.5.7.For each list item, a private copy is created for each \n implicit task or SIMD lane and is initialized with the initializer value of the reduction-identifier.\n After the end of the region, the original list item is updated with the values of the private copies \n using the combiner associated with the reduction-identifier."}
{"section_title": "5.5.8 reduction Clause", "chunk": "\n After the end of the region, the original list item is updated with the values of the private copies \n using the combiner associated with the reduction-identifier.\n If reduction-modifier is not present or the default reduction-modifier is present, the behavior is \n as follows.For parallel and worksharing constructs, one or more private copies of each list \n OpenMP API \u2013 Version 5.2 November 2021 \n item are created for each implicit task, as if the private clause had been used.For the simd \n construct, one or more private copies of each list item are created for each SIMD lane, as if the \n private clause had been used.For the taskloop construct, private copies are created \n according to the rules of the reduction scoping clauses.For the teams construct, one or more \n private copies of each list item are created for the initial task of each team in the league, as if the \n private clause had been used."}
{"section_title": "5.5.8 reduction Clause", "chunk": "For the teams construct, one or more \n private copies of each list item are created for the initial task of each team in the league, as if the \n private clause had been used.For the loop construct, private copies are created and used in the \n construct according to the description and restrictions in Section 5.3.At the end of a region that \n corresponds to a construct for which the reduction clause was specified, the original list item is \n updated by combining its original value with the final value of each of the private copies, using the \n combiner of the specified reduction-identifier.\n If the inscan reduction-modifier is present, a scan computation is performed over updates to the \n list item performed in each logical iteration of the loop associated with the worksharing-loop, \n worksharing-loop SIMD, or simd construct (see Section 5.6).The list items are privatized in the \n construct according to the description and restrictions in Section 5.3."}
{"section_title": "5.5.8 reduction Clause", "chunk": "The list items are privatized in the \n construct according to the description and restrictions in Section 5.3.At the end of the region, each \n original list item is assigned the value described in Section 5.6.\n If the task reduction-modifier is present for a parallel or worksharing construct, then each list \n item is privatized according to the description and restrictions in Section 5.3, and an unspecified \n number of additional private copies may be created to support task reductions.Any copies \n associated with the reduction are initialized before they are accessed by the tasks that participate in \n the reduction, which include all implicit tasks in the corresponding region and all participating \n explicit tasks that specify an in_reduction clause (see Section 5.5.10).After the end of the \n region, the original list item contains the result of the reduction."}
{"section_title": "5.5.8 reduction Clause", "chunk": "After the end of the \n region, the original list item contains the result of the reduction.\n Restrictions \n Restrictions to the reduction clause are as follows: \n \u2022 All restrictions common to all reduction clauses, as listed in Section 5.5.5, apply to this clause.\n \u2022 A list item that appears in a reduction clause on a worksharing construct must be shared in \n the parallel region to which a corresponding worksharing region binds.\n \u2022 If an array section or array element appears as a list item in a reduction clause on a \n worksharing construct, all threads of the team must specify the same storage location.\n \u2022 Each list item specified with the inscan reduction-modifier must appear as a list item in an \n inclusive or exclusive clause on a scan directive enclosed by the construct.\n \u2022 If the inscan reduction-modifier is specified, a reduction clause without the inscan \n reduction-modifier must not appear on the same construct."}
{"section_title": "5.5.8 reduction Clause", "chunk": "\n \u2022 If the inscan reduction-modifier is specified, a reduction clause without the inscan \n reduction-modifier must not appear on the same construct.\n \u2022 A reduction clause with the task reduction-modifier may only appear on a parallel \n construct, a worksharing construct or a combined or composite construct for which any of the \n aforementioned constructs is a constituent construct and neither simd nor loop are constituent \n constructs.\nCHAPTER 5.DATA ENVIRONMENT 135 \n \u2022 A reduction clause with the inscan reduction-modifier may only appear on a \n worksharing-loop construct, a simd construct or a combined or composite construct for which \n any of the aforementioned constructs is a constituent construct and distribute is not a \n constituent construct.\n \u2022 The inscan reduction-modifier must not be specified on a construct for which the ordered or \n schedule clause is specified."}
{"section_title": "5.5.8 reduction Clause", "chunk": "\n \u2022 The inscan reduction-modifier must not be specified on a construct for which the ordered or \n schedule clause is specified.\n \u2022 A list item that appears in a reduction clause of the innermost enclosing worksharing or \n parallel construct must not be accessed in an explicit task generated by a construct for which \n an in_reduction clause over the same list item does not appear.\n \u2022 The task reduction-modifier must not appear in a reduction clause if the nowait clause is \n specified on the same construct.\nC / C++ \n \u2022 If a list item in a reduction clause on a worksharing construct has a reference type then it \n must bind to the same object for all threads of the team.\n \u2022 If a list item in a reduction clause on a worksharing construct is an array section or an array \n element then the base pointer must point to the same variable for all threads of the team."}
{"section_title": "5.5.8 reduction Clause", "chunk": "\n \u2022 If a list item in a reduction clause on a worksharing construct is an array section or an array \n element then the base pointer must point to the same variable for all threads of the team.\n \u2022 A variable of class type (or array thereof) that appears in a reduction clause with the \n inscan reduction-modifier requires an accessible, unambiguous default constructor for the \n class type; the number of calls to it while performing the scan computation is unspecified.\n \u2022 A variable of class type (or array thereof) that appears in a reduction clause with the \n inscan reduction-modifier requires an accessible, unambiguous copy assignment operator for \n the class type; the number of calls to it while performing the scan computation is unspecified."}
{"section_title": "5.5.8 reduction Clause", "chunk": "\n \u2022 A variable of class type (or array thereof) that appears in a reduction clause with the \n inscan reduction-modifier requires an accessible, unambiguous copy assignment operator for \n the class type; the number of calls to it while performing the scan computation is unspecified.\nC / C++ \n Cross References \n \u2022 List Item Privatization, see Section 5.3 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 parallel directive, see Section 10.1 \n \u2022 private clause, see Section 5.4.3 \n \u2022 scan directive, see Section 5.6 \n \u2022 schedule clause, see Section 11.5.3 \n \u2022 scope directive, see Section 11.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 sections directive, see Section 11.3 \n \u2022 simd directive, see Section 10.4 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "5.5.9 task_reduction Clause", "chunk": "Name: task_reduction Properties: data-environment attribute, data\ufffesharing attribute, privatization, reduction \nscoping \n \n Arguments \nName Type Properties \nlist list of variable list item type default 8 \n Modifiers \nName Modifies Type Properties \nreduction\ufffeidentifier \nlist An OpenMP reduction iden\ufffetifier \n required, ultimate \n Directives \n taskgroup \n Semantics \n The task_reduction clause is a reduction scoping clause, as described in Section 5.5.6, that \n specifies a reduction among tasks.For each list item, the number of copies is unspecified.Any \n copies associated with the reduction are initialized before they are accessed by the tasks that \n participate in the reduction.After the end of the region, the original list item contains the result of \n the reduction.\n Restrictions \n Restrictions to the task_reduction clause are as follows: \n \u2022 All restrictions common to all reduction clauses, as listed in Section 5.5.5, apply to this clause."}
{"section_title": "5.5.9 task_reduction Clause", "chunk": "\n Restrictions \n Restrictions to the task_reduction clause are as follows: \n \u2022 All restrictions common to all reduction clauses, as listed in Section 5.5.5, apply to this clause.\n Cross References \n \u2022 taskgroup directive, see Section 15.4 \nCHAPTER 5.DATA ENVIRONMENT 137 \n"}
{"section_title": "5.5.10 in_reduction Clause", "chunk": "Name: in_reduction Properties: data-environment attribute, data\ufffesharing attribute, privatization, reduction par\ufffeticipating \n \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Modifiers \nName Modifies Type Properties \nreduction\ufffeidentifier \nlist An OpenMP reduction iden\ufffetifier \n required, ultimate \n Directives \n target, task, taskloop \n Semantics \n The in_reduction clause is a reduction participating clause, as described in Section 5.5.7, that \n specifies that a task participates in a reduction.For a given list item, the in_reduction clause \n defines a task to be a participant in a task reduction that is defined by an enclosing region for a \n matching list item that appears in a task_reduction clause or a reduction clause with \n task as the reduction-modifier, where either: \n 1.The matching list item has the same storage location as the list item in the in_reduction \n clause; or \n 2."}
{"section_title": "5.5.10 in_reduction Clause", "chunk": "The matching list item has the same storage location as the list item in the in_reduction \n clause; or \n 2.A private copy, derived from the matching list item, that is used to perform the task reduction \n has the same storage location as the list item in the in_reduction clause.\n For the task construct, the generated task becomes the participating task.For each list item, a \n private copy may be created as if the private clause had been used.\n For the target construct, the target task becomes the participating task.For each list item, a \n private copy may be created in the data environment of the target task as if the private clause \n had been used.This private copy will be implicitly mapped into the device data environment of the \n target device, if the target device is not the parent device.\n At the end of the task region, if a private copy was created its value is combined with a copy created \n by a reduction scoping clause or with the original list item."}
{"section_title": "5.5.10 in_reduction Clause", "chunk": "\n At the end of the task region, if a private copy was created its value is combined with a copy created \n by a reduction scoping clause or with the original list item.\n Restrictions \n Restrictions to the in_reduction clause are as follows: \n \u2022 All restrictions common to all reduction clauses, as listed in Section 5.5.5, apply to this clause.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 A list item that appears in a task_reduction clause or a reduction clause with task as \n the reduction-modifier that is specified on a construct that corresponds to a region in which the \n region of the participating task is closely nested must match each list item.The construct that \n corresponds to the innermost enclosing region that meets this condition must specify the same \n reduction-identifier for the matching list item as the in_reduction clause."}
{"section_title": "5.5.10 in_reduction Clause", "chunk": "The construct that \n corresponds to the innermost enclosing region that meets this condition must specify the same \n reduction-identifier for the matching list item as the in_reduction clause.\n Cross References \n \u2022 target directive, see Section 13.8 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "Name: declare reduction Association: none \nCategory: declarative Properties: pure \n \n Arguments \n declare reduction(reduction-specifier) \nName Type Properties \nreduction-specifier OpenMP reduction specifier default 14 \n Clauses \n initializer \n Semantics \n The declare reduction directive declares a reduction-identifier that can be used in a \n reduction clause as a user-defined reduction.The directive argument reduction-specifier uses the \n following syntax: \n reduction-identifier : typename-list : combiner \n where reduction-identifier is a reduction identifier, typename-list is a type-name list, and combiner \n is an OpenMP combiner expression.\n The reduction-identifier and the type identify the declare reduction directive.The \n reduction-identifier can later be used in a reduction clause that uses variables of the types specified \n in the declare reduction directive."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "The \n reduction-identifier can later be used in a reduction clause that uses variables of the types specified \n in the declare reduction directive.If the directive specifies several types then the behavior is \n as if a declare reduction directive was specified for each type.The visibility and \n accessibility of a user-defined reduction are the same as those of a variable declared at the same \n location in the program.\nC++ \n The declare reduction directive can also appear at the locations in a program where a static \n data member could be declared.In this case, the visibility and accessibility of the declaration are \n the same as those of a static data member declared at the same location in the program.\nC++ \nCHAPTER 5.DATA ENVIRONMENT 139 \n The enclosing context of the combiner and of the initializer-expr that is specified by the \n initializer clause is that of the declare reduction directive."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "DATA ENVIRONMENT 139 \n The enclosing context of the combiner and of the initializer-expr that is specified by the \n initializer clause is that of the declare reduction directive.The combiner and the \n initializer-expr must be correct in the base language as if they were the body of a function defined \n at the same location in the program.\nFortran \n If a type with deferred or assumed length type parameter is specified in a declare reduction \n directive, the reduction-identifier of that directive can be used in a reduction clause with any \n variable of the same type and the same kind parameter, regardless of the length type parameters \n with which the variable is declared."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "\nFortran \n If a type with deferred or assumed length type parameter is specified in a declare reduction \n directive, the reduction-identifier of that directive can be used in a reduction clause with any \n variable of the same type and the same kind parameter, regardless of the length type parameters \n with which the variable is declared.\n If the reduction-identifier is the same as the name of a user-defined operator or an extended \n operator, or the same as a generic name that is one of the allowed intrinsic procedures, and if the \n operator or procedure name appears in an accessibility statement in the same module, the \n accessibility of the corresponding declare reduction directive is determined by the \n accessibility attribute of the statement."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "\n If the reduction-identifier is the same as the name of a user-defined operator or an extended \n operator, or the same as a generic name that is one of the allowed intrinsic procedures, and if the \n operator or procedure name appears in an accessibility statement in the same module, the \n accessibility of the corresponding declare reduction directive is determined by the \n accessibility attribute of the statement.\n If the reduction-identifier is the same as a generic name that is one of the allowed intrinsic \n procedures and is accessible, and if it has the same name as a derived type in the same module, the \n accessibility of the corresponding declare reduction directive is determined by the \n accessibility of the generic name according to the base language."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "\n If the reduction-identifier is the same as a generic name that is one of the allowed intrinsic \n procedures and is accessible, and if it has the same name as a derived type in the same module, the \n accessibility of the corresponding declare reduction directive is determined by the \n accessibility of the generic name according to the base language.\nFortran \n Restrictions \n Restrictions to the declare reduction directive are as follows: \n \u2022 A reduction-identifier may not be re-declared in the current scope for the same type or for a type \n that is compatible according to the base language rules.\n \u2022 The typename-list must not declare new types.\nC / C++ \n \u2022 A type name in a declare reduction directive cannot be a function type, an array type, a \n reference type, or a type qualified with const, volatile or restrict.\nC / C++ \nFortran \n \u2022 If the length type parameter is specified for a type, it must be a constant, a colon (:) or an \n asterisk (*)."}
{"section_title": "5.5.11 declare reduction Directive", "chunk": "\nC / C++ \nFortran \n \u2022 If the length type parameter is specified for a type, it must be a constant, a colon (:) or an \n asterisk (*).\n \u2022 If a type with deferred or assumed length parameter is specified in a declare reduction \n directive, no other declare reduction directive with the same type, the same kind \n parameters and the same reduction-identifier is allowed in the same scope.\nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 OpenMP Combiner Expressions, see Section 5.5.2.1 \n \u2022 OpenMP Initializer Expressions, see Section 5.5.2.2 \n \u2022 OpenMP Reduction Identifiers, see Section 5.5.1 \n \u2022 initializer clause, see Section 5.5.4 \n"}
{"section_title": "5.6 scan Directive", "chunk": "Name: scan Association: separating \nCategory: subsidiary Properties: default 7 \n Separated directives \n do, for, simd \n Clauses \n exclusive, inclusive \n Clause set \n Properties: unique, required, exclusive Members: exclusive, inclusive \n Semantics \n The scan directive separates the final-loop-body of an enclosing simd construct or \n worksharing-loop construct (or a composite construct that combines them) into a structured block \n sequence that serves as an input phase and a structured block sequence that serves as a scan phase.\n The input phase contains all computations that update the list item in the iteration, and the scan \n phase ensures that any statement that reads the list item uses the result of the scan computation for \n that iteration.Thus, it specifies that a scan computation updates each list item on each logical \n iteration of the enclosing loop nest that is associated with the separated directive."}
{"section_title": "5.6 scan Directive", "chunk": "Thus, it specifies that a scan computation updates each list item on each logical \n iteration of the enclosing loop nest that is associated with the separated directive.\n If the inclusive clause is specified, the input phase includes the preceding structured block \n sequence and the scan phase includes the following structured block sequence and, thus, the \n directive specifies that an inclusive scan computation is performed for each list item of list.If the \n exclusive clause is specified, the input phase excludes the preceding structured block sequence \n and instead includes the following structured block sequence, while the scan phase includes the \n preceding structured block sequence and, thus, the directive specifies that an exclusive scan \n computation is performed for each list item of list."}
{"section_title": "5.6 scan Directive", "chunk": "If the \n exclusive clause is specified, the input phase excludes the preceding structured block sequence \n and instead includes the following structured block sequence, while the scan phase includes the \n preceding structured block sequence and, thus, the directive specifies that an exclusive scan \n computation is performed for each list item of list.\n The result of a scan computation for a given iteration is calculated according to the last generalized \n prefix sum (PRESUMlast) applied over the sequence of values given by the original value of the list \n item prior to the loop and all preceding updates to the list item in the logical iteration space of the \n loop.The operation PRESUMlast(op, a1, ..., aN ) is defined for a given binary operator op and a \n sequence of N values a1, ..., aN as follows: \nCHAPTER 5.DATA ENVIRONMENT 141 \n \u2022 if N = 1, a1 \n \u2022 if N > 1, op( PRESUMlast(op, a1, ..., aj), PRESUMlast(op, ak, ..., aN) ), 1 \u2264 j + 1 = k \u2264 N."}
{"section_title": "5.6 scan Directive", "chunk": ", aN) ), 1 \u2264 j + 1 = k \u2264 N.\n At the beginning of the input phase of each iteration, the list item is initialized with the value of the \n initializer expression of the reduction-identifier specified by the reduction clause on the \n separated construct.The update value of a list item is, for a given iteration, the value of the list item \n on completion of its input phase.\n Let orig-val be the value of the original list item on entry to the separated construct.Let combiner \n be the combiner expression for the reduction-identifier specified by the reduction clause on the \n construct.Let ui be the update value of a list item for iteration i.For list items that appear in an \n inclusive clause on the scan directive, at the beginning of the scan phase for iteration i the list \n item is assigned the result of the operation PRESUMlast( combiner, orig-val, u0, ..., ui)."}
{"section_title": "5.6 scan Directive", "chunk": ", ui).For list \n items that appear in an exclusive clause on the scan directive, at the beginning of the scan \n phase for iteration i = 0 the list item is assigned the value orig-val, and at the beginning of the scan \n phase for iteration i > 0 the list item is assigned the result of the operation PRESUMlast( combiner, \n orig-val, u0, ..., ui-1).\n For list items that appear in an inclusive clause, at the end of the separated construct, the \n original list item is assigned the private copy from the last logical iteration of the loops associated \n with the separated construct.For list items that appear in an exclusive clause, let k be the last \n logical iteration of the loops associated with the separated construct.At the end of the separated \n construct, the original list item is assigned the result of the operation PRESUMlast( combiner, \n orig-val, u0, ..., uk)."}
{"section_title": "5.6 scan Directive", "chunk": ", uk).\n Restrictions \n Restrictions to the scan directive are as follows: \n \u2022 A separated construct must have at most one scan directive as a separating directive.\n \u2022 The loops that are associated with the directive to which the scan directive is associated must \n all be perfectly nested.\n \u2022 Each list item that appears in the inclusive or exclusive clause must appear in a \n reduction clause with the inscan modifier on the separated construct.\n \u2022 Each list item that appears in a reduction clause with the inscan modifier on the separated \n construct must appear in a clause on the separating scan directive.\n \u2022 Cross-iteration dependences across different logical iterations must not exist, except for \n dependences for the list items specified in an inclusive or exclusive clause."}
{"section_title": "5.6 scan Directive", "chunk": "\n \u2022 Cross-iteration dependences across different logical iterations must not exist, except for \n dependences for the list items specified in an inclusive or exclusive clause.\n \u2022 Intra-iteration dependences from a statement in the structured block sequence that precede a \n scan directive to a statement in the structured block sequence that follows a scan directive \n must not exist, except for dependences for the list items specified in an inclusive or \n exclusive clause.\n \u2022 The private copy of list items that appear in the inclusive or exclusive clause must not be \n modified in the scan phase.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 do directive, see Section 11.5.2 \n \u2022 exclusive clause, see Section 5.6.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 inclusive clause, see Section 5.6.1 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 simd directive, see Section 10.4 \n"}
{"section_title": "5.6.1 inclusive Clause", "chunk": "9 Name: inclusive Properties: unique \n Arguments \nName Type Properties \nlist list of variable list item type default 11 \n Directives \n scan \n Semantics \n The inclusive clause is used on a separating directive that separates a structured block into two \n structured block sequences.The clause determines the association of the structured block sequence \n that precedes the directive on which the clause appears to a phase of that directive.\n The list items that appear in an inclusive clause may include array sections.\n Cross References \n \u2022 scan directive, see Section 5.6 \n"}
{"section_title": "5.6.2 exclusive Clause", "chunk": "22 Name: exclusive Properties: unique \n Arguments \nName Type Properties \nlist list of variable list item type default 24 \n Directives \n scan \nCHAPTER 5.DATA ENVIRONMENT 143 \n Semantics \n The exclusive clause is used on a separating directive that separates a structured block into two \n structured block sequences.The clause determines the association of the structured block sequence \n that precedes the directive on which the clause appears to a phase of that directive.\n The list items that appear in an exclusive clause may include array sections.\n Cross References \n \u2022 scan directive, see Section 5.6 \n"}
{"section_title": "5.7 Data Copying Clauses", "chunk": "9 This section describes the copyin clause and the copyprivate clause.These two clauses \n support copying data values from private or threadprivate variables of an implicit task or thread to \n the corresponding variables of other implicit tasks or threads in the team.\n"}
{"section_title": "5.7.1 copyin Clause", "chunk": "13 Name: copyin Properties: data copying \n Arguments \nName Type Properties \nlist list of variable list item type default 15 \n Directives \n parallel \n Semantics \n The copyin clause provides a mechanism to copy the value of a threadprivate variable of the \n primary thread to the threadprivate variable of each other member of the team that is executing the \n parallel region.\nC / C++ \n The copy is performed after the team is formed and prior to the execution of the associated \n structured block.For variables of non-array type, the copy is by copy assignment.For an array of \n elements of non-array type, each element is copied as if by assignment from an element of the array \n of the primary thread to the corresponding element of the array of all other threads.\nC / C++ \nC++ \n For class types, the copy assignment operator is invoked.The order in which copy assignment \n operators for different variables of the same class type are invoked is unspecified."}
{"section_title": "5.7.1 copyin Clause", "chunk": "The order in which copy assignment \n operators for different variables of the same class type are invoked is unspecified.\nC++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n The copy is performed, as if by assignment, after the team is formed and prior to the execution of \n the associated structured block.\n Named variables that appear in a threadprivate common block may be specified.The whole \n common block does not need to be specified.\n On entry to any parallel region, each thread\u2019s copy of a variable that is affected by a copyin \n clause for the parallel region will acquire the type parameters, allocation, association, and \n definition status of the copy of the primary thread, according to the following rules: \n \u2022 If the original list item has the POINTER attribute, each copy receives the same association \n status as that of the copy of the primary thread as if by pointer assignment."}
{"section_title": "5.7.1 copyin Clause", "chunk": "\n On entry to any parallel region, each thread\u2019s copy of a variable that is affected by a copyin \n clause for the parallel region will acquire the type parameters, allocation, association, and \n definition status of the copy of the primary thread, according to the following rules: \n \u2022 If the original list item has the POINTER attribute, each copy receives the same association \n status as that of the copy of the primary thread as if by pointer assignment.\n \u2022 If the original list item does not have the POINTER attribute, each copy becomes defined with \n the value of the copy of the primary thread as if by intrinsic assignment unless the list item has a \n type bound procedure as a defined assignment.If the original list item that does not have the \n POINTER attribute has the allocation status of unallocated, each copy will have the same status."}
{"section_title": "5.7.1 copyin Clause", "chunk": "If the original list item that does not have the \n POINTER attribute has the allocation status of unallocated, each copy will have the same status.\n \u2022 If the original list item is unallocated or unassociated, each copy inherits the declared type \n parameters and the default type parameter values from the original list item.\nFortran \n Restrictions \n Restrictions to the copyin clause are as follows: \n \u2022 A list item that appears in a copyin clause must be threadprivate.\nC++ \n \u2022 A variable of class type (or array thereof) that appears in a copyin clause requires an \n accessible, unambiguous copy assignment operator for the class type.\nC++ \nFortran \n \u2022 A common block name that appears in a copyin clause must be declared to be a common block \n in the same scoping unit in which the copyin clause appears.\n \u2022 A polymorphic variable with the ALLOCATABLE attribute must not be a list item."}
{"section_title": "5.7.1 copyin Clause", "chunk": "\n \u2022 A polymorphic variable with the ALLOCATABLE attribute must not be a list item.\nFortran \n Cross References \n \u2022 parallel directive, see Section 10.1 \n \u2022 threadprivate directive, see Section 5.2 \nCHAPTER 5.DATA ENVIRONMENT 145 \n"}
{"section_title": "5.7.2 copyprivate Clause", "chunk": "2 Name: copyprivate Properties: end-clause, data copying \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Directives \n single \n Semantics \n The copyprivate clause provides a mechanism to use a private variable to broadcast a value \n from the data environment of one implicit task to the data environments of the other implicit tasks \n that belong to the parallel region.The effect of the copyprivate clause on the specified list \n items occurs after the execution of the structured block associated with the associated construct, \n and before any of the threads in the team have left the barrier at the end of the construct.To avoid \n data races, concurrent reads or updates of the list item must be synchronized with the update of the \n list item that occurs as a result of the copyprivate clause if, for example, the nowait clause is \n used to remove the barrier."}
{"section_title": "5.7.2 copyprivate Clause", "chunk": "To avoid \n data races, concurrent reads or updates of the list item must be synchronized with the update of the \n list item that occurs as a result of the copyprivate clause if, for example, the nowait clause is \n used to remove the barrier.\nC / C++ \n In all other implicit tasks that belong to the parallel region, each specified list item becomes defined \n with the value of the corresponding list item in the implicit task associated with the thread that \n executed the structured block.For variables of non-array type, the definition occurs by copy \n assignment.For an array of elements of non-array type, each element is copied by copy assignment \n from an element of the array in the data environment of the implicit task that is associated with the \n thread that executed the structured block to the corresponding element of the array in the data \n environment of the other implicit tasks.\nC / C++ \nC++ \n For class types, a copy assignment operator is invoked."}
{"section_title": "5.7.2 copyprivate Clause", "chunk": "\nC / C++ \nC++ \n For class types, a copy assignment operator is invoked.The order in which copy assignment \n operators for different variables of class type are called is unspecified.\nC++ \nFortran \n If a list item does not have the POINTER attribute, then in all other implicit tasks that belong to the \n parallel region, the list item becomes defined as if by intrinsic assignment with the value of the \n corresponding list item in the implicit task that is associated with the thread that executed the \n structured block.If the list item has a type bound procedure as a defined assignment, the \n assignment is performed by the defined assignment."}
{"section_title": "5.7.2 copyprivate Clause", "chunk": "If the list item has a type bound procedure as a defined assignment, the \n assignment is performed by the defined assignment.\n OpenMP API \u2013 Version 5.2 November 2021 \n If the list item has the POINTER attribute then in all other implicit tasks that belong to the parallel \n region the list item receives, as if by pointer assignment, the same association status as the \n corresponding list item in the implicit task that is associated with the thread that executed the \n structured block.\n The order in which any final subroutines for different variables of a finalizable type are called is \n unspecified.\nFortran \n Restrictions \n Restrictions to the copyprivate clause are as follows: \n \u2022 All list items that appear in a copyprivate clause must be either threadprivate or private in \n the enclosing context.\nC++ \n \u2022 A variable of class type (or array thereof) that appears in a copyprivate clause requires an \n accessible unambiguous copy assignment operator for the class type."}
{"section_title": "5.7.2 copyprivate Clause", "chunk": "\nC++ \n \u2022 A variable of class type (or array thereof) that appears in a copyprivate clause requires an \n accessible unambiguous copy assignment operator for the class type.\nC++ \nFortran \n \u2022 A common block that appears in a copyprivate clause must be threadprivate.\n \u2022 Pointers with the INTENT(IN) attribute must not appear in a copyprivate clause.\n \u2022 Any list item with the ALLOCATABLE attribute must have the allocation status of allocated when \n the intrinsic assignment is performed.\n \u2022 If a list item is a polymorphic variable with the ALLOCATABLE attribute, the behavior is \n unspecified.\nFortran \n Cross References \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 private clause, see Section 5.4.3 \n \u2022 single directive, see Section 11.1 \n"}
{"section_title": "5.8 Data-Mapping Control", "chunk": "24 This section describes the available mechanisms for controlling how data are mapped to device data \n environments.It covers implicit data-mapping attribute rules for variables referenced in target \n constructs, explicit clauses for specifying how data should be mapped, and clauses for making \n available variables with static lifetimes and procedures on other devices.It also describes how \n mappers may be defined and referenced to control the mapping of data with user-defined types.\nCHAPTER 5.DATA ENVIRONMENT 147 \n"}
{"section_title": "5.8.1 Implicit Data-Mapping Attribute Rules", "chunk": "2 When specified, explicit data-environment attribute clauses on target directives determine the \n attributes for variables referenced in a target construct.Otherwise, the first matching rule from \n the following list determines the implicit data-mapping (or data-sharing) attribute for variables \n referenced in a target construct that do not have a predetermined data-sharing attribute \n according to Section 5.1.1.References to structure elements or array elements are treated as \n references to the structure or array, respectively, for the purposes of determining implicit \n data-mapping or data-sharing attributes of variables in a target construct.\n \u2022 If a variable appears in an enter or link clause on a declare target directive that does not have \n a device_type clause with the nohost device-type-description then it is treated as if it had \n appeared in a map clause with a map-type of tofrom."}
{"section_title": "5.8.1 Implicit Data-Mapping Attribute Rules", "chunk": "\n \u2022 If a variable appears in an enter or link clause on a declare target directive that does not have \n a device_type clause with the nohost device-type-description then it is treated as if it had \n appeared in a map clause with a map-type of tofrom.\n \u2022 If a variable is the base variable of a list item in a reduction, lastprivate or linear \n clause on a combined target construct then the list item is treated as if it had appeared in a map \n clause with a map-type of tofrom if Section 17.2 specifies this behavior.\n \u2022 If a variable is the base variable of a list item in an in_reduction clause on a target \n construct then it is treated as if the list item had appeared in a map clause with a map-type of \n tofrom and a map-type-modifier of always.\n \u2022 If a defaultmap clause is present for the category of the variable and specifies an implicit \n behavior other than default, the data-mapping or data-sharing attribute is determined by that \n clause."}
{"section_title": "5.8.1 Implicit Data-Mapping Attribute Rules", "chunk": "\n \u2022 If a defaultmap clause is present for the category of the variable and specifies an implicit \n behavior other than default, the data-mapping or data-sharing attribute is determined by that \n clause.\nC++ \n \u2022 If the target construct is within a class non-static member function, and a variable is an \n accessible data member of the object for which the non-static data member function is invoked, \n the variable is treated as if the this[:1] expression had appeared in a map clause with a \n map-type of tofrom.Additionally, if the variable is of type pointer or reference to pointer, it is \n also treated as if it had appeared in a map clause as a zero-length array section.\n \u2022 If the this keyword is referenced inside a target construct within a class non-static member \n function, it is treated as if the this[:1] expression had appeared in a map clause with a \n map-type of tofrom."}
{"section_title": "5.8.1 Implicit Data-Mapping Attribute Rules", "chunk": "\n \u2022 If the this keyword is referenced inside a target construct within a class non-static member \n function, it is treated as if the this[:1] expression had appeared in a map clause with a \n map-type of tofrom.\nC++ \nC / C++ \n \u2022 A variable that is of type pointer, but is neither a pointer to function nor (for C++) a pointer to a \n member function, is treated as if it is the base pointer of a zero-length array section that had \n appeared as a list item in a map clause.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n \u2022 A variable that is of type reference to pointer, but is neither a reference to point to function nor a \n reference to a pointer to a member function is treated as if it had appeared in a map clause as a \n zero-length array section.\nC++ \n \u2022 If a variable is not a scalar then it is treated as if it had appeared in a map clause with a map-type \n of tofrom."}
{"section_title": "5.8.1 Implicit Data-Mapping Attribute Rules", "chunk": "\nC++ \n \u2022 If a variable is not a scalar then it is treated as if it had appeared in a map clause with a map-type \n of tofrom.\nFortran \n \u2022 If a scalar variable has the TARGET, ALLOCATABLE or POINTER attribute then it is treated as \n if it had appeared in a map clause with a map-type of tofrom.\nFortran \n \u2022 If the above rules do not apply then a scalar variable is not mapped but instead has an implicit \n data-sharing attribute of firstprivate (see Section 5.1.1).\n"}
{"section_title": "5.8.2 Mapper Identifiers and mapper Modifiers", "chunk": "11 Modifiers \nName Modifies Type Properties \nmapper locator-list Complex, name: mapper \nArguments: \nmapper-identifier OpenMP \nidentifier (default) \nunique \n \n Clauses \n from, map, to \n Mapper identifiers can be used to uniquely identify the mapper used in a map or data-motion clause \n through a mapper modifier, which is a unique, complex modifier.A declare mapper directive \n defines a mapper identifier that can later be specified in a mapper modifier as its \n modifier-parameter-specification.Each mapper identifier is a base-language identifier or default \n where default is the default mapper for all types.\n A non-structure type T has a predefined default mapper that is defined as if by the following \n declare mapper directive: \nC / C++ \n #pragma omp declare mapper(T v) map(tofrom: v) \nC / C++ \nCHAPTER 5."}
{"section_title": "5.8.2 Mapper Identifiers and mapper Modifiers", "chunk": "\n A non-structure type T has a predefined default mapper that is defined as if by the following \n declare mapper directive: \nC / C++ \n #pragma omp declare mapper(T v) map(tofrom: v) \nC / C++ \nCHAPTER 5.DATA ENVIRONMENT 149 \nFortran \n !$omp declare mapper(T :: v) map(tofrom: v) \nFortran \n A structure type T has a predefined default mapper that is defined as if by a declare mapper \n directive that specifies v in a map clause with the alloc map-type and each structure element of v \n in a map clause with the tofrom map-type.\n A declare mapper directive that uses the default mapper identifier overrides the predefined \n default mapper for the given type, making it the default mapper for variables of that type.\n Cross References \n \u2022 from clause, see Section 5.9.2 \n \u2022 map clause, see Section 5.8.3 \n \u2022 to clause, see Section 5.9.1 \n"}
{"section_title": "5.8.3 map Clause", "chunk": "Name: map Properties: data-environment attribute, data\ufffemapping attribute 12 \n Arguments \nName Type Properties \nlocator-list list of locator list item type default 14 \n Modifiers \nName Modifies Type Properties \nmap-type-modifier locator-list Keyword: always, close, \npresent \ndefault \nmapper locator-list Complex, name: mapper \nArguments: \nmapper-identifier OpenMP \nidentifier (default) \nunique \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \nunique \nmap-type locator-list Keyword: alloc, delete, \nfrom, release, to, \ntofrom \nultimate \n \n OpenMP API \u2013 Version 5.2 November 2021 \n Directives \n declare mapper, target, target data, target enter data, target exit \n data \n Additional information \n The commas that separate modifiers in a map clause are optional.The specification of modifiers \n without comma separators for the map clause has been deprecated."}
{"section_title": "5.8.3 map Clause", "chunk": "The specification of modifiers \n without comma separators for the map clause has been deprecated.\n Semantics \n The map clause specifies how an original list item is mapped from the current task\u2019s data \n environment to a corresponding list item in the device data environment of the device identified by \n the construct.If a map-type is not specified, the map-type defaults to tofrom.The map clause is \n map-entering if the map-type is to, tofrom or alloc.The map clause is map-exiting if the \n map-type is from, tofrom, release or delete.\n The list items that appear in a map clause may include array sections and structure elements.A list \n item in a map clause may reference any iterator-identifier defined in its iterator modifier.A list \n item may appear more than once in the map clauses that are specified on the same directive.\n If a mapper modifier is not present, the behavior is as if a mapper modifier was specified with the \n default parameter."}
{"section_title": "5.8.3 map Clause", "chunk": "\n If a mapper modifier is not present, the behavior is as if a mapper modifier was specified with the \n default parameter.The map behavior of a list item in a map clause is modified by a visible \n user-defined mapper (see Section 5.8.8) if the mapper-identifier of the mapper modifier is defined \n for a base-language type that matches the type of the list item.Otherwise, the predefined default \n mapper for the type of the list item applies.The effect of the mapper is to remove the list item from \n the map clause, if the present modifier does not also appear, and to apply the clauses specified in \n the declared mapper to the construct on which the map clause appears.In the clauses applied by the \n mapper, references to var are replaced with references to the list item and the map-type is replaced \n with a final map type that is determined according to the rules of map-type decay (see \n Section 5.8.8)."}
{"section_title": "5.8.3 map Clause", "chunk": "In the clauses applied by the \n mapper, references to var are replaced with references to the list item and the map-type is replaced \n with a final map type that is determined according to the rules of map-type decay (see \n Section 5.8.8).\n A list item that is an array or array section of a type for which a user-defined mapper exists is \n mapped as if the map type decays to alloc, release, or delete, and then each array element \n is mapped with the original map type, as if by a separate construct, according to the mapper."}
{"section_title": "5.8.3 map Clause", "chunk": "\n A list item that is an array or array section of a type for which a user-defined mapper exists is \n mapped as if the map type decays to alloc, release, or delete, and then each array element \n is mapped with the original map type, as if by a separate construct, according to the mapper.\nFortran \n If a component of a derived type list item is a map clause list item that results from the predefined \n default mapper for that derived type, and if the derived type component is not an explicit list item or \n the base expression of an explicit list item in a map clause on the construct, then: \n \u2022 If it has the POINTER attribute, the map clause treats its association status as if it is undefined; \n and \n \u2022 If it has the ALLOCATABLE attribute and an allocated allocation status, and it is present in the \n device data environment when the construct is encountered, the map clause may treat its \n allocation status as if it is unallocated if the corresponding component does not have allocated \n storage."}
{"section_title": "5.8.3 map Clause", "chunk": "\nFortran \n If a component of a derived type list item is a map clause list item that results from the predefined \n default mapper for that derived type, and if the derived type component is not an explicit list item or \n the base expression of an explicit list item in a map clause on the construct, then: \n \u2022 If it has the POINTER attribute, the map clause treats its association status as if it is undefined; \n and \n \u2022 If it has the ALLOCATABLE attribute and an allocated allocation status, and it is present in the \n device data environment when the construct is encountered, the map clause may treat its \n allocation status as if it is unallocated if the corresponding component does not have allocated \n storage.\nCHAPTER 5."}
{"section_title": "5.8.3 map Clause", "chunk": "\nCHAPTER 5.DATA ENVIRONMENT 151 \n If a list item in a map clause is an associated pointer and the pointer is not the base pointer of \n another list item in a map clause on the same construct, then it is treated as if its pointer target is \n implicitly mapped in the same clause.For the purposes of the map clause, the mapped pointer \n target is treated as if its base pointer is the associated pointer.\nFortran \n For map clauses on map-entering constructs, if any list item has a base pointer for which a \n corresponding pointer exists in the data environment upon entry to the region and either a new list \n item or the corresponding pointer is created in the device data environment on entry to the region, \n then: \nC / C++ \n 1.The corresponding pointer variable is assigned an address such that the corresponding list item \n can be accessed through the pointer in a target region.\nC / C++ \nFortran \n 1."}
{"section_title": "5.8.3 map Clause", "chunk": "\nC / C++ \nFortran \n 1.The corresponding pointer variable is associated with a pointer target that has the same rank and \n bounds as the pointer target of the original pointer, such that the corresponding list item can be \n accessed through the pointer in a target region.\nFortran \n 2.The corresponding pointer variable becomes an attached pointer for the corresponding list item.\n 3.If the original base pointer and the corresponding attached pointer share storage, then the \n original list item and the corresponding list item must share storage.\nC++ \n If a lambda is mapped explicitly or implicitly, variables that are captured by the lambda behave as \n follows: \n \u2022 The variables that are of pointer type are treated as if they had appeared in a map clause as \n zero-length array sections; and \n \u2022 The variables that are of reference type are treated as if they had appeared in a map clause."}
{"section_title": "5.8.3 map Clause", "chunk": "\nC++ \n If a lambda is mapped explicitly or implicitly, variables that are captured by the lambda behave as \n follows: \n \u2022 The variables that are of pointer type are treated as if they had appeared in a map clause as \n zero-length array sections; and \n \u2022 The variables that are of reference type are treated as if they had appeared in a map clause.\n If a member variable is captured by a lambda in class scope, and the lambda is later mapped \n explicitly or implicitly with its full static type, the this pointer is treated as if it had appeared on a \n map clause.\nC++ \n If a map clause with a present map-type-modifier appears on a construct and on entry to the \n region the corresponding list item is not present in the device data environment, runtime error \n termination is performed.\n The map clauses on a construct collectively determine the set of mappable storage blocks for that \n construct."}
{"section_title": "5.8.3 map Clause", "chunk": "\n The map clauses on a construct collectively determine the set of mappable storage blocks for that \n construct.All map clause list items that have the same containing structure or share storage result \n in a single mappable storage block that contains the storage of the list items.The storage for each \n other map clause list item becomes a distinct mappable storage block.\n OpenMP API \u2013 Version 5.2 November 2021 \n For each mappable storage block that is determined by the map clauses on a map-entering \n construct, on entry to the region the following sequence of steps occurs as if they are performed as a \n single atomic operation: \n 1.If a corresponding storage block is not present in the device data environment then: \n a) A corresponding storage block, which share storage with the original storage block, is \n created in the device data environment of the device; \n b) The corresponding storage block receives a reference count that is initialized to zero."}
{"section_title": "5.8.3 map Clause", "chunk": "If a corresponding storage block is not present in the device data environment then: \n a) A corresponding storage block, which share storage with the original storage block, is \n created in the device data environment of the device; \n b) The corresponding storage block receives a reference count that is initialized to zero.This \n reference count also applies to any part of the corresponding storage block.\n 2.The reference count of the corresponding storage block is incremented by one.\n 3.For each map clause list item on the construct that is contained by the mappable storage block: \n a) If the reference count of the corresponding storage block is one, a new list item with \n language-specific attributes derived from the original list item is created in the \n corresponding storage block.The reference count of the new list item is always equal to the \n reference count of its storage."}
{"section_title": "5.8.3 map Clause", "chunk": "The reference count of the new list item is always equal to the \n reference count of its storage.\n b) If the reference count of the corresponding list item is one or if the always \n map-type-modifier is specified, and if the map-type is to or tofrom, the corresponding list \n item is updated as if the list item appeared in a to clause on a target update directive.\n \n Note \u2013 If the effect of the map clauses on a construct would assign the value of an original list \n item to a corresponding list item more than once, then an implementation is allowed to ignore \n additional assignments of the same value to the corresponding list item.\n \n In all cases on entry to the region, concurrent reads or updates of any part of the corresponding list \n item must be synchronized with any update of the corresponding list item that occurs as a result of \n the map clause to avoid data races."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \n In all cases on entry to the region, concurrent reads or updates of any part of the corresponding list \n item must be synchronized with any update of the corresponding list item that occurs as a result of \n the map clause to avoid data races.\n The original and corresponding list items may share storage such that writes to either item by one \n task followed by a read or write of the other item by another task without intervening \n synchronization can result in data races.They are guaranteed to share storage if the map clause \n appears on a target construct that corresponds to an inactive target region, or if it appears on \n a mapping-only construct that applies to the device data environment of the host device.\n If corresponding storage for a mappable storage block derived from map clauses on a map-exiting \n construct is not present in the device data environment on exit from the region, the mappable \n storage block is ignored."}
{"section_title": "5.8.3 map Clause", "chunk": "\n If corresponding storage for a mappable storage block derived from map clauses on a map-exiting \n construct is not present in the device data environment on exit from the region, the mappable \n storage block is ignored.For each mappable storage block that is determined by the map clauses on \n a map-exiting construct, on exit from the region the following sequence of steps occurs as if \n performed as a single atomic operation: \nCHAPTER 5.DATA ENVIRONMENT 153 \n 1.For each map clause list item that is contained by the mappable storage block: \n a) If the reference count of the corresponding list item is one or if the always \n map-type-modifier is specified, and if the map-type is from or tofrom, the original list \n item is updated as if the list item appeared in a from clause on a target update \n directive.\n 2.If the map-type is not delete and the reference count of the corresponding storage block is \n finite then the reference count is decremented by one.\n 3."}
{"section_title": "5.8.3 map Clause", "chunk": "\n 3.If the map-type is delete and the reference count of the corresponding storage block is finite \n then the reference count is set to zero.\n 4.If the reference count of the corresponding storage block is zero, all storage to which that \n reference count applies is removed from the device data environment.\n If the effect of the map clauses on a construct would assign the value of a corresponding list item to \n an original list item more than once, then an implementation is allowed to ignore additional \n assignments of the same value to the original list item.\n In all cases on exit from the region, concurrent reads or updates of any part of the original list item \n must be synchronized with any update of the original list item that occurs as a result of the map \n clause to avoid data races."}
{"section_title": "5.8.3 map Clause", "chunk": "\n In all cases on exit from the region, concurrent reads or updates of any part of the original list item \n must be synchronized with any update of the original list item that occurs as a result of the map \n clause to avoid data races.\n If a single contiguous part of the original storage of a list item with an implicit data-mapping \n attribute has corresponding storage in the device data environment prior to a task encountering the \n construct on which the map clause appears, only that part of the original storage will have \n corresponding storage in the device data environment as a result of the map clause."}
{"section_title": "5.8.3 map Clause", "chunk": "\n If a single contiguous part of the original storage of a list item with an implicit data-mapping \n attribute has corresponding storage in the device data environment prior to a task encountering the \n construct on which the map clause appears, only that part of the original storage will have \n corresponding storage in the device data environment as a result of the map clause.\n If a list item with an implicit data-mapping attribute does not have any corresponding storage in the \n device data environment prior to a task encountering the construct associated with the map clause, \n and one or more contiguous parts of the original storage are either list items or base pointers to list \n items that are explicitly mapped on the construct, only those parts of the original storage will have \n corresponding storage in the device data environment as a result of the map clauses on the \n construct."}
{"section_title": "5.8.3 map Clause", "chunk": "\n If a list item with an implicit data-mapping attribute does not have any corresponding storage in the \n device data environment prior to a task encountering the construct associated with the map clause, \n and one or more contiguous parts of the original storage are either list items or base pointers to list \n items that are explicitly mapped on the construct, only those parts of the original storage will have \n corresponding storage in the device data environment as a result of the map clauses on the \n construct.\nC / C++ \n If a new list item is created then the new list item will have the same static type as the original list \n item, and language-specific attributes of the new list item, including size and alignment, are \n determined by that type."}
{"section_title": "5.8.3 map Clause", "chunk": "\nC / C++ \n If a new list item is created then the new list item will have the same static type as the original list \n item, and language-specific attributes of the new list item, including size and alignment, are \n determined by that type.\nC / C++ \nC++ \n If corresponding storage that differs from the original mappable storage block is created in a device \n data environment, all new list items that are created in that corresponding storage are default \n initialized.Default initialization for new list items of class type, including their data members, is \n performed as if with an implicitly-declared default constructor and as if non-static data member \n initializers are ignored.\n OpenMP API \u2013 Version 5.2 November 2021 \n If the type of a new list item is a reference to a type T then it is initialized to refer to the object in \n the device data environment that corresponds to the object referenced by the original list item."}
{"section_title": "5.8.3 map Clause", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If the type of a new list item is a reference to a type T then it is initialized to refer to the object in \n the device data environment that corresponds to the object referenced by the original list item.The \n effect is as if the object were mapped through a pointer with an array section of length one and \n elements of type T.\nC++ \nFortran \n If a new list item is created then the new list item will have the same type, type parameter, and rank \n as the original list item.The new list item inherits all default values for the type parameters from \n the original list item.\n If the allocation status of an original list item that has the ALLOCATABLE attribute is changed \n while a corresponding list item is present in the device data environment, the allocation status of the \n corresponding list item is unspecified until the list item is again mapped with an always modifier \n on entry to a map-entering region."}
{"section_title": "5.8.3 map Clause", "chunk": "\n If the allocation status of an original list item that has the ALLOCATABLE attribute is changed \n while a corresponding list item is present in the device data environment, the allocation status of the \n corresponding list item is unspecified until the list item is again mapped with an always modifier \n on entry to a map-entering region.\nFortran \n The close map-type-modifier is a hint to the runtime to allocate memory close to the target device.\n Execution Model Events \n The target-map event occurs in a thread that executes the outermost region that corresponds to an \n encountered device construct with a map clause, after the target-task-begin event for the device \n construct and before any mapping operations are performed.\n The target-data-op-begin event occurs before a thread initiates a data operation on the target device \n that is associated with a map clause, in the outermost region that corresponds to the encountered \n construct."}
{"section_title": "5.8.3 map Clause", "chunk": "\n The target-data-op-begin event occurs before a thread initiates a data operation on the target device \n that is associated with a map clause, in the outermost region that corresponds to the encountered \n construct.\n The target-data-op-end event occurs after a thread initiates a data operation on the target device \n that is associated with a map clause, in the outermost region that corresponds to the encountered \n construct.\n Tool Callbacks \n A thread dispatches one or more registered ompt_callback_target_map or \n ompt_callback_target_map_emi callbacks for each occurrence of a target-map event in \n that thread.The callback occurs in the context of the target task and has type signature \n ompt_callback_target_map_t or ompt_callback_target_map_emi_t, \n respectively.\n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread."}
{"section_title": "5.8.3 map Clause", "chunk": "\n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\nCHAPTER 5.DATA ENVIRONMENT 155 \n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t."}
{"section_title": "5.8.3 map Clause", "chunk": "The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the map clause are as follows: \n \u2022 Two list items of the map clauses on the same construct must not share original storage unless \n they are the same list item or unless one is the containing structure of the other.\n \u2022 If the same list item appears more than once in map clauses on the same construct, the map \n clauses must specify the same mapper modifier.\n \u2022 If a list item is an array section, it must specify contiguous storage.\n \u2022 If an expression that is used to form a list item in a map clause contains an iterator identifier, the \n list item instances that would result from different values of the iterator must not have the same \n containing array and must not have base pointers that share original storage."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If an expression that is used to form a list item in a map clause contains an iterator identifier, the \n list item instances that would result from different values of the iterator must not have the same \n containing array and must not have base pointers that share original storage.\n \u2022 If multiple list items are explicitly mapped on the same construct and have the same containing \n array or have base pointers that share original storage, and if any of the list items do not have \n corresponding list items that are present in the device data environment prior to a task \n encountering the construct, then the list items must refer to the same array elements of either the \n containing array or the implicit array of the base pointers."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If multiple list items are explicitly mapped on the same construct and have the same containing \n array or have base pointers that share original storage, and if any of the list items do not have \n corresponding list items that are present in the device data environment prior to a task \n encountering the construct, then the list items must refer to the same array elements of either the \n containing array or the implicit array of the base pointers.\n \u2022 If any part of the original storage of a list item with an explicit data-mapping attribute has \n corresponding storage in the device data environment prior to a task encountering the construct \n associated with the map clause, all of the original storage must have corresponding storage in the \n device data environment prior to the task encountering the construct."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If any part of the original storage of a list item with an explicit data-mapping attribute has \n corresponding storage in the device data environment prior to a task encountering the construct \n associated with the map clause, all of the original storage must have corresponding storage in the \n device data environment prior to the task encountering the construct.\n \u2022 If an array appears as a list item in a map clause, multiple parts of the array have corresponding \n storage in the device data environment prior to a task encountering the construct associated with \n the map clause, and the corresponding storage for those parts was created by maps from more \n than one earlier construct, the behavior is unspecified."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If an array appears as a list item in a map clause, multiple parts of the array have corresponding \n storage in the device data environment prior to a task encountering the construct associated with \n the map clause, and the corresponding storage for those parts was created by maps from more \n than one earlier construct, the behavior is unspecified.\n \u2022 If a list item is an element of a structure, and a different element of the structure has a \n corresponding list item in the device data environment prior to a task encountering the construct \n associated with the map clause, then the list item must also have a corresponding list item in the \n device data environment prior to the task encountering the construct.\n \u2022 A list item must have a mappable type.\n \u2022 If a mapper modifier appears in a map clause, the type on which the specified mapper operates \n must match the type of the list items in the clause."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If a mapper modifier appears in a map clause, the type on which the specified mapper operates \n must match the type of the list items in the clause.\n \u2022 Memory spaces and memory allocators must not appear as a list item in a map clause.\n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n \u2022 If a list item has a polymorphic class type and its static type does not match its dynamic type, the \n behavior is unspecified if the map clause is specified on a map-entering construct and a \n corresponding list item is not present in the device data environment prior to a task encountering \n the construct.\n \u2022 No type mapped through a reference may contain a reference to its own type, or any references to \n types that could produce a cycle of references.\n \u2022 If a list item is a lambda, any pointers and references captured by the lambda must point or refer \n to storage that has corresponding storage in the device data environment prior to the task \n encountering the construct."}
{"section_title": "5.8.3 map Clause", "chunk": "\n \u2022 If a list item is a lambda, any pointers and references captured by the lambda must point or refer \n to storage that has corresponding storage in the device data environment prior to the task \n encountering the construct.\nC++ \nC / C++ \n \u2022 A list item cannot be a variable that is a member of a structure of a union type.\n \u2022 A bit-field cannot appear in a map clause.\n \u2022 A pointer that has a corresponding attached pointer must not be modified for the duration of the \n lifetime of the list item to which the corresponding pointer is attached in the device data \n environment.\nC / C++ \nFortran \n \u2022 If a list item of a map clause is an allocatable variable or is the subobject of an allocatable \n variable, the original allocatable variable may not be allocated, deallocated or reshaped while the \n corresponding allocatable variable has allocated storage."}
{"section_title": "5.8.3 map Clause", "chunk": "\nC / C++ \nFortran \n \u2022 If a list item of a map clause is an allocatable variable or is the subobject of an allocatable \n variable, the original allocatable variable may not be allocated, deallocated or reshaped while the \n corresponding allocatable variable has allocated storage.\n \u2022 A pointer that has a corresponding attached pointer and is associated with a given pointer target \n must not become associated with a different pointer target for the duration of the lifetime of the \n list item to which the corresponding pointer is attached in the device data environment.\n \u2022 If an array section is mapped and the size of the section is smaller than that of the whole array, \n the behavior of referencing the whole array in the target region is unspecified.\n \u2022 A list item must not be a whole array of an assumed-size array.\n \u2022 A list item must not be a complex part designator.\nFortran \nCHAPTER 5."}
{"section_title": "5.8.3 map Clause", "chunk": "\nFortran \nCHAPTER 5.DATA ENVIRONMENT 157 \n Cross References \n \u2022 Array Sections, see Section 3.2.5 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 ompt_callback_target_map_emi_t and ompt_callback_target_map_t, see \n Section 19.5.2.27 \n \u2022 declare mapper directive, see Section 5.8.8 \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 mapper modifier, see Section 5.8.2 \n \u2022 target data directive, see Section 13.5 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \n"}
{"section_title": "5.8.4 enter Clause", "chunk": "Name: enter Properties: data-environment attribute, data\ufffemapping attribute 16 \n Arguments \nName Type Properties \nlist list of extended list item type default 18 \n Directives \n declare target \n Additional information \n The clause-name to may be used as a synonym for the clause-name enter.This use has been \n deprecated.\n Semantics \n The enter clause is a data-mapping clause.\nC / C++ \n If a function appears in an enter clause in the same compilation unit in which the definition of the \n function occurs then a device-specific version of the function is created for all devices to which the \n directive of the clause applies.\n OpenMP API \u2013 Version 5.2 November 2021 \n If a variable appears in an enter clause in the same compilation unit in which the definition of the \n variable occurs then the original list item is allocated a corresponding list item in the device data \n environment of all devices to which the directive of the clause applies."}
{"section_title": "5.8.4 enter Clause", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If a variable appears in an enter clause in the same compilation unit in which the definition of the \n variable occurs then the original list item is allocated a corresponding list item in the device data \n environment of all devices to which the directive of the clause applies.\nC / C++ \nFortran \n If a procedure appears in an enter clause in the same compilation unit in which the definition of \n the procedure occurs then a device-specific version of the procedure is created for all devices to \n which the directive of the clause applies.\n If a variable that is host associated appears in an enter clause then the original list item is \n allocated a corresponding list item in the device data environment of all devices to which the \n directive of the clause applies."}
{"section_title": "5.8.4 enter Clause", "chunk": "\n If a variable that is host associated appears in an enter clause then the original list item is \n allocated a corresponding list item in the device data environment of all devices to which the \n directive of the clause applies.\nFortran \n If a variable appears in an enter clause then the corresponding list item in the device data \n environment of each device to which the directive of the clause applies is initialized once, in the \n manner specified by the program, but at an unspecified point in the program prior to the first \n reference to that list item.The list item is never removed from those device data environments as if \n its reference count was initialized to positive infinity.\n Cross References \n \u2022 declare target directive, see Section 7.8.1 \n"}
{"section_title": "5.8.5 link Clause", "chunk": "18 Name: link Properties: data-environment attribute \n Arguments \nName Type Properties \nlist list of variable list item type default 20 \n Directives \n declare target \n Semantics \n The link clause supports compilation of device routines that refer to variables with static storage \n duration that appear as list items in the clause.The declare target directive on which the \n clause appears does not map the list items.Instead, they are mapped according to the data-mapping \n rules described in Section 5.8.\n Cross References \n \u2022 Data-Mapping Control, see Section 5.8 \n \u2022 declare target directive, see Section 7.8.1 \nCHAPTER 5.DATA ENVIRONMENT 159 \nC / C++ \n"}
{"section_title": "5.8.6 Pointer Initialization for Device Data Environments", "chunk": "2 This section describes how a pointer that is predetermined firstprivate for a target construct may \n be assigned an initial value that is the address of an object that exists in a device data environment \n and corresponds to a matching mapped list item.\n All previously mapped list items that have corresponding storage in a given device data \n environment constitute the set of currently mapped list items.If a currently mapped list item has a \n base pointer, the base address of the currently mapped list item is the value of its base pointer.\n Otherwise, the base address is determined by the following steps: \n 1.Let X refer to the currently mapped list item.\n 2.If X refers to an array section or array element, let X refer to its base array.\n 3.If X refers to a structure element, let X refer to its containing structure and return to step 2.\n 4.The base address for the currently mapped list item is the address of X."}
{"section_title": "5.8.6 Pointer Initialization for Device Data Environments", "chunk": "The base address for the currently mapped list item is the address of X.\n Additionally, each currently mapped list item has a starting address and an ending address.The \n starting address is the address of the first storage location associated with the list item, and the \n ending address is the address of the storage location that immediately follows the last storage \n location associated with the list item.\n The mapped address range of the currently mapped list item is the range of addresses that starts \n from the starting address and ends with the ending address.The extended address range of the \n currently mapped list item is the range of addresses that starts from the minimum of the starting \n address and the base address and that ends with the maximum of the ending address and the base \n address."}
{"section_title": "5.8.6 Pointer Initialization for Device Data Environments", "chunk": "The extended address range of the \n currently mapped list item is the range of addresses that starts from the minimum of the starting \n address and the base address and that ends with the maximum of the ending address and the base \n address.\n If the value of a given pointer is in the mapped address range of a currently mapped list item then \n that currently mapped list item is a matching mapped list item.Otherwise, if the value of the \n pointer is in the extended address range of a currently mapped list item then that currently mapped \n list item is a matching mapped list item.\n If multiple matching mapped list items are found and they all appear as part of the same containing \n structure, the one that has the lowest starting address is treated as the sole matching mapped list \n item.Otherwise, if multiple matching mapped list items are found then the behavior is unspecified."}
{"section_title": "5.8.6 Pointer Initialization for Device Data Environments", "chunk": "Otherwise, if multiple matching mapped list items are found then the behavior is unspecified.\n If a matching mapped list item is found, the initial value that is assigned to the pointer is a device \n address such that the corresponding list item in the device data environment can be accessed \n through the pointer in a target region.\n If a matching mapped list item is not found, the pointer retains its original value as per the \n firstprivate semantics described in Section 5.4.4.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 map clause, see Section 5.8.3 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \nC / C++ \n"}
{"section_title": "5.8.7 defaultmap Clause", "chunk": "6 Name: defaultmap Properties: unique, post-modified \n Arguments \nName Type Properties \nimplicit-behavior Keyword: alloc, default, \nfirstprivate, from, none, \npresent, to, tofrom \ndefault 8 \n Modifiers \nName Modifies Type Properties \nvariable-category implicit-behavior Keyword: aggregate, \nall, allocatable, \npointer, scalar \ndefault 10 \n Directives \n target \n Semantics \n The defaultmap clause determines the implicit data-mapping or data-sharing attribute of certain \n variables that are referenced in a target construct, in accordance with the rules given in \n Section 5.8.1.The variable-category specifies the variables for which the attribute may be set, and \n the attribute is specified by implicit-behavior.If no variable-category is specified in the clause then \n the effect is as if all was specified for the variable-category.\nC / C++ \n The scalar variable-category specifies non-pointer variables of scalar type."}
{"section_title": "5.8.7 defaultmap Clause", "chunk": "\nC / C++ \n The scalar variable-category specifies non-pointer variables of scalar type.\nC / C++ \nFortran \n The scalar variable-category specifies non-pointer and non-allocatable variables of scalar type.\n The allocatable variable-category specifies variables with the ALLOCATABLE attribute.\nFortran \nCHAPTER 5.DATA ENVIRONMENT 161 \n The pointer variable-category specifies variables of pointer type.The aggregate \n variable-category specifies variables of aggregate type (arrays or structures).Finally, the all \n variable-category specifies all variables.\n If implicit-behavior is the name of a map type, the attribute is a data-mapping attribute determined \n by an implicit map clause with the specified map type.If implicit-behavior is firstprivate, \n the attribute is a data-sharing attribute of firstprivate."}
{"section_title": "5.8.7 defaultmap Clause", "chunk": "If implicit-behavior is firstprivate, \n the attribute is a data-sharing attribute of firstprivate.If implicit-behavior is present, the \n attribute is a data-mapping attribute determined by an implicit map clause with the map-type of \n alloc and map-type-modifier of present.If implicit-behavior is none then no implicit \n data-mapping or data-sharing attributes are defined for variables in variable-category, except for \n variables that appear in the enter or link clause of a declare target directive.If \n implicit-behavior is default then the clause has no effect.\n Restrictions \n Restrictions to the defaultmap clause are as follows: \n \u2022 A given variable-category may be specified in at most one defaultmap clause on a construct.\n \u2022 If a defaultmap clause specifies the all variable-category, no other defaultmap clause \n may appear on the construct."}
{"section_title": "5.8.7 defaultmap Clause", "chunk": "\n \u2022 If a defaultmap clause specifies the all variable-category, no other defaultmap clause \n may appear on the construct.\n \u2022 If implicit-behavior is none, each variable that is specified by variable-category and is \n referenced in the construct but does not have a predetermined data-sharing and does not appear \n in an enter or link clause on a declare target directive must be explicitly listed in a \n data-environment attribute clause on the construct.\nC / C++ \n \u2022 The specified variable-category must not be allocatable.\nC / C++ \n Cross References \n \u2022 Implicit Data-Mapping Attribute Rules, see Section 5.8.1 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "Name: declare mapper Association: none \nCategory: declarative Properties: default 26 \n Arguments \n declare mapper(mapper-specifier) \nName Type Properties \nmapper-specifier OpenMP mapper specifier default 29 \n Clauses \n map \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n User-defined mappers can be defined using the declare mapper directive.The mapper-specifier \n directive argument declares the mapper using the following syntax: \nC / C++ \n [ mapper-identifier : ] type var \nC / C++ \nFortran \n [ mapper-identifier : ] type :: var \nFortran \n where mapper-identifier is a mapper identifier, type is a type that is permitted in a type-name list, \n and var is a base-language identifier.\n The type and an optional mapper-identifier uniquely identify the mapper for use in a map clause or \n motion clause later in the program.The visibility and accessibility of this declaration are the same \n as those of a variable declared at the same location in the program."}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "The visibility and accessibility of this declaration are the same \n as those of a variable declared at the same location in the program.\n If mapper-identifier is not specified, the behavior is as if mapper-identifier is default.\n The variable declared by var is available for use in all map clauses on the directive, and no part of \n the variable to be mapped is mapped by default.\n The effect that a user-defined mapper has on either a map clause that maps a list item of the given \n base language type or a motion clause that invokes the mapper and updates a list item of the given \n base language type is to replace the map or update with a set of map clauses or updates derived \n from the map clauses specified by the mapper, as described in Section 5.8.3 and Section 5.9.\n The final map types that a mapper applies for a map clause that maps a list item of the given type \n are determined according to the rules of map-type decay, defined according to Table 5.3."}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "\n The final map types that a mapper applies for a map clause that maps a list item of the given type \n are determined according to the rules of map-type decay, defined according to Table 5.3.Table 5.3 \n shows the final map type that is determined by the combination of two map types, where the rows \n represent the map type specified by the mapper and the columns represent the map type specified \n by a map clause that invokes the mapper.For a target exit data construct that invokes a \n mapper with a map clause that has the from map type, if a map clause in the mapper specifies an \n alloc or to map type then the result is a release map type."}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "For a target exit data construct that invokes a \n mapper with a map clause that has the from map type, if a map clause in the mapper specifies an \n alloc or to map type then the result is a release map type.\nTABLE 5.3: Map-Type Decay of Map Type Combinations \nalloc to from tofrom release delete \nalloc alloc alloc alloc (release) alloc release delete \nto alloc to alloc (release) to release delete \nfrom alloc alloc from from release delete \ntofrom alloc to from tofrom release delete \n A list item in a map clause that appears on a declare mapper directive may include array \n sections.\nCHAPTER 5.DATA ENVIRONMENT 163 \n All map clauses that are introduced by a mapper are further subject to mappers that are in scope, \n except a map clause with list item var maps var without invoking a mapper.\nC++ \n The declare mapper directive can also appear at locations in the program at which a static data \n member could be declared."}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "\nC++ \n The declare mapper directive can also appear at locations in the program at which a static data \n member could be declared.In this case, the visibility and accessibility of the declaration are the \n same as those of a static data member declared at the same location in the program.\nC++ \n Restrictions \n Restrictions to the declare mapper directive are as follows: \n \u2022 No instance of type can be mapped as part of the mapper, either directly or indirectly through \n another base language type, except the instance var that is passed as the list item.If a set of \n declare mapper directives results in a cyclic definition then the behavior is unspecified.\n \u2022 The type must not declare a new base language type.\n \u2022 At least one map clause that maps var or at least one element of var is required."}
{"section_title": "5.8.8 declare mapper Directive", "chunk": "\n \u2022 At least one map clause that maps var or at least one element of var is required.\n \u2022 List items in map clauses on the declare mapper directive may only refer to the declared \n variable var and entities that could be referenced by a procedure defined at the same location.\n \u2022 Neither the release or delete map-type may be specified on any map clause.\n \u2022 If a mapper-modifier is specified for a map clause, its parameter must be default.\n \u2022 Multiple declare mapper directives that specify the same mapper-identifier for the same \n base language type or for compatible base language types, according to the base language rules, \n may not appear in the same scope.\nC \n \u2022 type must be a struct or union type.\nC \nC++ \n \u2022 type must be a struct, union, or class type.\nC++ \nFortran \n \u2022 type must not be an intrinsic type or an abstract type.\nFortran \n Cross References \n \u2022 map clause, see Section 5.8.3 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "2 Data-motion clauses specify data movement between a device set that is specified by the construct \n on which they appear.One member of that device set is always the encountering device, which is \n the device on which the encountering task for that construct executes.How the other devices, which \n are the targeted devices, are determined is defined by the construct specification.Each data-motion \n clause specifies the direction of the data movement relative to the targeted devices.\n A data-motion clause specifies an OpenMP locator list as its argument.A corresponding list item \n and an original list item exist for each list item.If the corresponding list item is not present in the \n device data environment then no assignment occurs between the corresponding and original list \n items.Otherwise, each corresponding list item in the device data environment has an original list \n item in the data environment of the encountering task."}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "Otherwise, each corresponding list item in the device data environment has an original list \n item in the data environment of the encountering task.Assignment is performed to either the \n original or corresponding list item as specified with the specific data-motion clauses.List items \n may reference any iterator-identifier defined in its iterator modifier.The list items may include \n array sections with stride expressions.\nC / C++ \n The list items may use shape-operators.\nC / C++ \n If a list item is an array or array section then it is treated as if it is replaced by each of its array \n elements in the clause.\n If the mapper modifier is not specified, the behavior is as if the modifier was specified with the \n default mapper-identifier.The effect of a data-motion clause on a list item is modified by a \n visible user-defined mapper if mapper-identifier is specified for a type that matches the type of the \n list item."}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "The effect of a data-motion clause on a list item is modified by a \n visible user-defined mapper if mapper-identifier is specified for a type that matches the type of the \n list item.Otherwise, the predefined default mapper for the type of the list item applies.Each list \n item is replaced with the list items that the given mapper specifies are to be mapped with a map \n type that is compatible with the data movement direction associated with the clause.\n If a present expectation is specified and the corresponding list item is not present in the device \n data environment then runtime error termination is performed.For a list item that is replaced with a \n set of list items as a result of a user-defined mapper, the expectation only applies to those mapper \n list items that share storage with the original list item."}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "For a list item that is replaced with a \n set of list items as a result of a user-defined mapper, the expectation only applies to those mapper \n list items that share storage with the original list item.\nFortran \n If a list item or a subobject of a list item has the ALLOCATABLE attribute, its assignment is \n performed only if its allocation status is allocated and only with respect to the allocated storage.If a \n list item has the POINTER attribute and its association status is associated, the effect is as if the \n assignment is performed with respect to the pointer target.\nCHAPTER 5."}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "\nCHAPTER 5.DATA ENVIRONMENT 165 \n On exit from the associated region, if the corresponding list item is an attached pointer, the original \n list item, if associated, will be associated with the same pointer target with which it was associated \n on entry to the region and the corresponding list item, if associated, will be associated with the \n same pointer target with which it was associated on entry to the region.\nFortran \nC / C++ \n On exit from the associated region, if the corresponding list item is an attached pointer, the original \n list item will have the value it had on entry to the region and the corresponding list item will have \n the value it had on entry to the region.\nC / C++ \n For each list item that is not an attached pointer, the value of the assigned list item is assigned the \n value of the other list item."}
{"section_title": "5.9 Data-Motion Clauses", "chunk": "\nC / C++ \n For each list item that is not an attached pointer, the value of the assigned list item is assigned the \n value of the other list item.To avoid data races, concurrent reads or updates of the assigned list \n item must be synchronized with the update of an assigned list item that occurs as a result of a \n data-motion clause.\n Restrictions \n Restrictions to data-motion clauses are as follows: \n \u2022 Each list item clause must have a mappable type.\n Cross References \n \u2022 Array Sections, see Section 3.2.5 \n \u2022 Array Shaping, see Section 3.2.4 \n \u2022 declare mapper directive, see Section 5.8.8 \n \u2022 device clause, see Section 13.2 \n \u2022 from clause, see Section 5.9.2 \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 target update directive, see Section 13.9 \n \u2022 to clause, see Section 5.9.1 \n"}
{"section_title": "5.9.1 to Clause", "chunk": "25 Name: to Properties: data-motion attribute \n Arguments \nName Type Properties \nlocator-list list of locator list item type default 27 \n OpenMP API \u2013 Version 5.2 November 2021 \n Modifiers \nName Modifies Type Properties \nexpectation Generic Keyword: present default \nmapper locator-list Complex, name: mapper \nArguments: \nmapper-identifier OpenMP \nidentifier (default) \nunique \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \nunique \n \n Directives \n target update \n Semantics \n The to clause is a data motion clause that specifies movement to the targeted devices from the \n encountering device so the corresponding list items are the assigned list items and the compatible \n map types are to and tofrom.\n Cross References \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 target update directive, see Section 13.9 \n"}
{"section_title": "5.9.2 from Clause", "chunk": "13 Name: from Properties: data-motion attribute \n Arguments \nName Type Properties \nlocator-list list of locator list item type default 15 \nCHAPTER 5.DATA ENVIRONMENT 167 \n Modifiers \nName Modifies Type Properties \nexpectation Generic Keyword: present default \nmapper locator-list Complex, name: mapper \nArguments: \nmapper-identifier OpenMP \nidentifier (default) \nunique \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \nunique \n \n Directives \n target update \n Semantics \n The from clause is a data motion clause that specifies movement from the targeted devices to the \n encountering device so the original list items are the assigned list items and the compatible map \n types are from and tofrom.\n Cross References \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 target update directive, see Section 13.9 \n"}
{"section_title": "5.10 uniform Clause", "chunk": "13 Name: uniform Properties: data-environment attribute \n Arguments \nName Type Properties \nparameter-list list of parameter list item type default 15 \n Directives \n declare simd \n Semantics \n The uniform clause declares one or more arguments to have an invariant value for all concurrent \n invocations of the function in the execution of a single SIMD loop.\n Cross References \n \u2022 declare simd directive, see Section 7.7 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "5.11 aligned Clause", "chunk": "Name: aligned Properties: data-environment attribute, post\ufffemodified 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Modifiers \nName Modifies Type Properties \nalignment list OpenMP integer expression positive, region \ninvariant, ultimate, \nunique \n \n Directives \n declare simd, simd \n Semantics \nC / C++ \n The aligned clause declares that the object to which each list item points is aligned to the \n number of bytes expressed in alignment.\nC / C++ \nFortran \n The aligned clause declares that the target of each list item is aligned to the number of bytes \n expressed in alignment.\nFortran \n The alignment modifier specifies the alignment that the program ensures related to the list items.If \n the alignment modifier is not specified, implementation-defined default alignments for SIMD \n instructions on the target platforms are assumed."}
{"section_title": "5.11 aligned Clause", "chunk": "If \n the alignment modifier is not specified, implementation-defined default alignments for SIMD \n instructions on the target platforms are assumed.\n Restrictions \n Restrictions to the aligned clause are as follows: \nC \n \u2022 The type of list items must be array or pointer.\nC \nC++ \n \u2022 The type of list items must be array, pointer, reference to array, or reference to pointer.\nC++ \nCHAPTER 5.DATA ENVIRONMENT 169 \nFortran \n \u2022 Each list item must have C_PTR or Cray pointer type or have the POINTER or ALLOCATABLE \n attribute.Cray pointer support has been deprecated.\n \u2022 If a list item has the ALLOCATABLE attribute, the allocation status must be allocated.\n \u2022 If a list item has the POINTER attribute, the association status must be associated.\n \u2022 If the type of a list item is either C_PTR or Cray pointer, it must be defined.Cray pointer support \n has been deprecated."}
{"section_title": "5.11 aligned Clause", "chunk": "Cray pointer support \n has been deprecated.\nFortran \n Cross References \n \u2022 declare simd directive, see Section 7.7 \n \u2022 simd directive, see Section 10.4 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "6 Memory Management", "chunk": "2 This chapter defines directives, clauses and related concepts for managing memory used by \n OpenMP programs.\n"}
{"section_title": "6.1 Memory Spaces", "chunk": "5 OpenMP memory spaces represent storage resources where variables can be stored and retrieved.\n Table 6.1 shows the list of predefined memory spaces.The selection of a given memory space \n expresses an intent to use storage with certain traits for the allocations.The actual storage resources \n that each memory space represents are implementation defined.\nTABLE 6.1: Predefined Memory Spaces \nMemory space name Storage selection intent \nomp_default_mem_space Represents the system default storage \nomp_large_cap_mem_space Represents storage with large capacity \nomp_const_mem_space Represents storage optimized for variables with con\ufffestant values \nomp_high_bw_mem_space Represents storage with high bandwidth \nomp_low_lat_mem_space Represents storage with low latency \n Variables allocated in the omp_const_mem_space memory space may be initialized through \n the firstprivate clause or with compile time constants for static and constant variables."}
{"section_title": "6.1 Memory Spaces", "chunk": "\nTABLE 6.1: Predefined Memory Spaces \nMemory space name Storage selection intent \nomp_default_mem_space Represents the system default storage \nomp_large_cap_mem_space Represents storage with large capacity \nomp_const_mem_space Represents storage optimized for variables with con\ufffestant values \nomp_high_bw_mem_space Represents storage with high bandwidth \nomp_low_lat_mem_space Represents storage with low latency \n Variables allocated in the omp_const_mem_space memory space may be initialized through \n the firstprivate clause or with compile time constants for static and constant variables.\n Implementation-defined mechanisms to provide the constant value of these variables may also be \n supported.\n Restrictions \n Restrictions to OpenMP memory spaces are as follows: \n \u2022 Variables in the omp_const_mem_space memory space may not be written.\n \n"}
{"section_title": "6.2 Memory Allocators", "chunk": "2 OpenMP memory allocators can be used by a program to make allocation requests.When a \n memory allocator receives a request to allocate storage of a certain size, an allocation of logically \n consecutive memory in the resources of its associated memory space of at least the size that was \n requested will be returned if possible.This allocation will not overlap with any other existing \n allocation from an OpenMP memory allocator.\n The behavior of the allocation process can be affected by the allocator traits that the user specifies.\n Table 6.2 shows the allowed allocator traits, their possible values and the default value of each trait."}
{"section_title": "6.2 Memory Allocators", "chunk": "\n Table 6.2 shows the allowed allocator traits, their possible values and the default value of each trait.\nTABLE 6.2: Allocator Traits \nAllocator trait Allowed values Default value \nsync_hint contended, uncontended, \nserialized, private \ncontended \nalignment Positive integer powers of 2 1 byte \naccess all, cgroup, pteam, thread all \npool_size Any positive integer Implementation de\ufffefined \nfallback default_mem_fb, null_fb, \nabort_fb, allocator_fb \ndefault_mem_fb \nfb_data an allocator handle (none) \npinned true, false false \npartition environment, nearest, blocked, \ninterleaved \nenvironment \n The sync_hint trait describes the expected manner in which multiple threads may use the \n allocator."}
{"section_title": "6.2 Memory Allocators", "chunk": "\nTABLE 6.2: Allocator Traits \nAllocator trait Allowed values Default value \nsync_hint contended, uncontended, \nserialized, private \ncontended \nalignment Positive integer powers of 2 1 byte \naccess all, cgroup, pteam, thread all \npool_size Any positive integer Implementation de\ufffefined \nfallback default_mem_fb, null_fb, \nabort_fb, allocator_fb \ndefault_mem_fb \nfb_data an allocator handle (none) \npinned true, false false \npartition environment, nearest, blocked, \ninterleaved \nenvironment \n The sync_hint trait describes the expected manner in which multiple threads may use the \n allocator.The values and their descriptions are: \n \u2022 contended: high contention is expected on the allocator; that is, many threads are expected to \n request allocations simultaneously; \n \u2022 uncontended: low contention is expected on the allocator; that is, few threads are expected to \n request allocations simultaneously; \n \u2022 serialized: one thread at a time will request allocations with the allocator."}
{"section_title": "6.2 Memory Allocators", "chunk": "The values and their descriptions are: \n \u2022 contended: high contention is expected on the allocator; that is, many threads are expected to \n request allocations simultaneously; \n \u2022 uncontended: low contention is expected on the allocator; that is, few threads are expected to \n request allocations simultaneously; \n \u2022 serialized: one thread at a time will request allocations with the allocator.Requesting two \n allocations simultaneously when specifying serialized results in unspecified behavior; and \n \u2022 private: the same thread will request allocations with the allocator every time.Requesting an \n allocation from different threads, simultaneously or not, when specifying private results in \n unspecified behavior.\n OpenMP API \u2013 Version 5.2 November 2021 \n Allocated memory will be byte aligned to at least the value specified for the alignment trait of \n the allocator."}
{"section_title": "6.2 Memory Allocators", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Allocated memory will be byte aligned to at least the value specified for the alignment trait of \n the allocator.Some directives and API routines can specify additional requirements on alignment \n beyond those described in this section.\n Memory allocated by allocators with the access trait defined to be all must be accessible by all \n threads in the device where the allocation was requested.Memory allocated by allocators with the \n access trait defined to be cgroup will be memory accessible by all threads in the same \n contention group as the thread that requested the allocation; attempts to access it by threads that are \n not part of the same contention group as the allocating thread result in unspecified behavior."}
{"section_title": "6.2 Memory Allocators", "chunk": "Memory allocated by allocators with the \n access trait defined to be cgroup will be memory accessible by all threads in the same \n contention group as the thread that requested the allocation; attempts to access it by threads that are \n not part of the same contention group as the allocating thread result in unspecified behavior.\n Memory allocated by allocators with the access trait defined to be pteam will be memory \n accessible by all threads that bind to the same parallel region of the thread that requested the \n allocation; attempts to access it by threads that do not bind to the same parallel region as the \n allocating thread result in unspecified behavior.Memory allocated by allocators with the access \n trait defined to be thread will be memory accessible by the thread that requested the allocation; \n attempts to access it by threads other than the allocating thread result in unspecified behavior."}
{"section_title": "6.2 Memory Allocators", "chunk": "Memory allocated by allocators with the access \n trait defined to be thread will be memory accessible by the thread that requested the allocation; \n attempts to access it by threads other than the allocating thread result in unspecified behavior.\n The total amount of storage in bytes that an allocator can use is limited by the pool_size trait.\n For allocators with the access trait defined to be all, this limit refers to allocations from all \n threads that access the allocator.For allocators with the access trait defined to be cgroup, this \n limit refers to allocations from threads that access the allocator from the same contention group.For \n allocators with the access trait defined to be pteam, this limit refers to allocations from threads \n that access the allocator from the same parallel team.For allocators with the access trait defined \n to be thread, this limit refers to allocations from each thread that accesses the allocator."}
{"section_title": "6.2 Memory Allocators", "chunk": "For allocators with the access trait defined \n to be thread, this limit refers to allocations from each thread that accesses the allocator.Requests \n that would result in using more storage than pool_size will not be fulfilled by the allocator.\n The fallback trait specifies how the allocator behaves when it cannot fulfill an allocation \n request.If the fallback trait is set to null_fb, the allocator returns the value zero if it fails to \n allocate the memory.If the fallback trait is set to abort_fb, the behavior is as if an error \n directive for which sev-level is fatal and action-time is execution is encountered if the \n allocation fails.If the fallback trait is set to allocator_fb then when an allocation fails the \n request will be delegated to the allocator specified in the fb_data trait."}
{"section_title": "6.2 Memory Allocators", "chunk": "If the fallback trait is set to allocator_fb then when an allocation fails the \n request will be delegated to the allocator specified in the fb_data trait.If the fallback trait is \n set to default_mem_fb then when an allocation fails another allocation will be tried in \n omp_default_mem_space, which assumes all allocator traits to be set to their default values \n except for fallback trait, which will be set to null_fb.\n Allocators with the pinned trait defined to be true ensure that their allocations remain in the \n same storage resource at the same location for their entire lifetime.\n The partition trait describes the partitioning of allocated memory over the storage resources \n represented by the memory space associated with the allocator.The partitioning will be done in \n parts with a minimum size that is implementation defined."}
{"section_title": "6.2 Memory Allocators", "chunk": "The partitioning will be done in \n parts with a minimum size that is implementation defined.The values are: \n \u2022 environment: the placement of allocated memory is determined by the execution \n environment; \n \u2022 nearest: allocated memory is placed in the storage resource that is nearest to the thread that \n requests the allocation; \nCHAPTER 6.MEMORY MANAGEMENT 173 \n \u2022 blocked: allocated memory is partitioned into parts of approximately the same size with at \n most one part per storage resource; and \n \u2022 interleaved: allocated memory parts are distributed in a round-robin fashion across the \n storage resources.\n Table 6.3 shows the list of predefined memory allocators and their associated memory spaces.The \n predefined memory allocators have default values for their allocator traits unless otherwise \n specified."}
{"section_title": "6.2 Memory Allocators", "chunk": "The \n predefined memory allocators have default values for their allocator traits unless otherwise \n specified.\nTABLE 6.3: Predefined Allocators \nAllocator name Associated memory space Non-default trait \nvalues \nomp_default_mem_alloc omp_default_mem_space fallback:null_fb \nomp_large_cap_mem_alloc omp_large_cap_mem_space (none) \nomp_const_mem_alloc omp_const_mem_space (none) \nomp_high_bw_mem_alloc omp_high_bw_mem_space (none) \nomp_low_lat_mem_alloc omp_low_lat_mem_space (none) \nomp_cgroup_mem_alloc Implementation defined access:cgroup \nomp_pteam_mem_alloc Implementation defined access:pteam \nomp_thread_mem_alloc Implementation defined access:thread \nFortran \n If any operation of the base language causes a reallocation of a variable that is allocated with a \n memory allocator then that memory allocator will be used to deallocate the current memory and to \n allocate the new memory."}
{"section_title": "6.2 Memory Allocators", "chunk": "\nTABLE 6.3: Predefined Allocators \nAllocator name Associated memory space Non-default trait \nvalues \nomp_default_mem_alloc omp_default_mem_space fallback:null_fb \nomp_large_cap_mem_alloc omp_large_cap_mem_space (none) \nomp_const_mem_alloc omp_const_mem_space (none) \nomp_high_bw_mem_alloc omp_high_bw_mem_space (none) \nomp_low_lat_mem_alloc omp_low_lat_mem_space (none) \nomp_cgroup_mem_alloc Implementation defined access:cgroup \nomp_pteam_mem_alloc Implementation defined access:pteam \nomp_thread_mem_alloc Implementation defined access:thread \nFortran \n If any operation of the base language causes a reallocation of a variable that is allocated with a \n memory allocator then that memory allocator will be used to deallocate the current memory and to \n allocate the new memory.For allocated allocatable components of such variables, the allocator that \n will be used for the deallocation and allocation is unspecified.\nFortran \n"}
{"section_title": "6.3 align Clause", "chunk": "13 Name: align Properties: unique \n Arguments \nName Type Properties \nalignment expression of integer type constant, positive 15 \n Directives \n allocate \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The align clause is used to specify the byte alignment to use for allocations associated with the \n construct on which the clause appears.Specifically, each allocation is byte aligned to at least the \n maximum of the value to which alignment evaluates, the alignment trait of the allocator being \n used for the allocation, and the alignment required by the base language for the type of the variable \n that is allocated.On constructs on which the clause may appear, if it is not specified then the effect \n is as if it was specified with the alignment trait of the allocator being used for the allocation.\n Restrictions \n Restrictions to the align clause are as follows: \n \u2022 alignment must evaluate to a power of two."}
{"section_title": "6.3 align Clause", "chunk": "\n Restrictions \n Restrictions to the align clause are as follows: \n \u2022 alignment must evaluate to a power of two.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 allocate directive, see Section 6.5 \n"}
{"section_title": "6.4 allocator Clause", "chunk": "15 Name: allocator Properties: unique \n Arguments \nName Type Properties \nallocator expression of allocator_handle type default 17 \n Directives \n allocate \n Semantics \n The allocator clause specifies the memory allocator to be used for allocations associated with \n the construct on which the clause appears.Specifically, the allocator to which allocator evaluates is \n used for the allocations.On constructs on which the clause may appear, if it is not specified then the \n effect is as if it was specified with the value of the def-allocator-var ICV.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 allocate directive, see Section 6.5 \n \u2022 def-allocator-var ICV, see Table 2.1 \nCHAPTER 6.MEMORY MANAGEMENT 175 \n"}
{"section_title": "6.5 allocate Directive", "chunk": "Name: allocate Association: none \nCategory: declarative Properties: default 2 \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Clauses \n align, allocator \n Semantics \n The storage for each list item that appears in the allocate directive is provided an allocation \n through the memory allocator as determined by the allocator clause with an alignment as \n determined by the align clause.The scope of this allocation is that of the list item in the base \n language.At the end of the scope for a given list item the memory allocator used to allocate that list \n item deallocates the storage.\n For allocations that arise from this directive the null_fb value of the fallback allocator trait \n behaves as if the abort_fb had been specified.\n Restrictions \n Restrictions to the allocate directive are as follows: \n \u2022 A variable that is part of another variable (as an array element or a structure element) cannot \n appear in a allocate directive."}
{"section_title": "6.5 allocate Directive", "chunk": "\n Restrictions \n Restrictions to the allocate directive are as follows: \n \u2022 A variable that is part of another variable (as an array element or a structure element) cannot \n appear in a allocate directive.\n \u2022 An allocate directive must appear in the same scope as the declarations of each of its list \n items and must follow all such declarations.\n \u2022 A declared variable may appear as a list item in at most one allocate directive in a given \n compilation unit.\n \u2022 allocate directives that appear in a target region must specify an allocator clause \n unless a requires directive with the dynamic_allocators clause is present in the same \n compilation unit.\nC / C++ \n \u2022 If a list item has static storage duration, the allocator clause must be specified and the \n allocator expression in the clause must be a constant expression that evaluates to one of the \n predefined memory allocator values."}
{"section_title": "6.5 allocate Directive", "chunk": "\nC / C++ \n \u2022 If a list item has static storage duration, the allocator clause must be specified and the \n allocator expression in the clause must be a constant expression that evaluates to one of the \n predefined memory allocator values.\n \u2022 A variable that is declared in a namespace or global scope may only appear as a list item in an \n allocate directive if an allocate directive that lists the variable follows a declaration that \n defines the variable and if all allocate directives that list it specify the same allocator.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC \n \u2022 After a list item has been allocated, the scope that contains the allocate directive must not \n end abnormally, such as through a call to the longjmp function.\nC \nC++ \n \u2022 After a list item has been allocated, the scope that contains the allocate directive must not end \n abnormally, such as through a call to the longjmp function, other than through C++ exceptions."}
{"section_title": "6.5 allocate Directive", "chunk": "\nC \nC++ \n \u2022 After a list item has been allocated, the scope that contains the allocate directive must not end \n abnormally, such as through a call to the longjmp function, other than through C++ exceptions.\n \u2022 A variable that has a reference type may not appear as a list item in an allocate directive.\nC++ \nFortran \n \u2022 A list item that is specified in an allocate directive must not have the ALLOCATABLE or \n POINTER attribute.\n \u2022 If a list item has the SAVE attribute, either explicitly or implicitly, or is a common block name \n then the allocator clause must be specified and only predefined memory allocator \n parameters can be used in the clause.\n \u2022 A variable that is part of a common block may not be specified as a list item in an allocate \n directive, except implicitly via the named common block.\n \u2022 A named common block may appear as a list item in at most one allocate directive in a given \n compilation unit."}
{"section_title": "6.5 allocate Directive", "chunk": "\n \u2022 A named common block may appear as a list item in at most one allocate directive in a given \n compilation unit.\n \u2022 If a named common block appears as a list item in an allocate directive, it must appear as a \n list item in an allocate directive that specifies the same allocator in every compilation unit in \n which the common block is used.\n \u2022 An associate name may not appear as a list item in an allocate directive.\nFortran \n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 align clause, see Section 6.3 \n \u2022 allocator clause, see Section 6.4 \nCHAPTER 6.MEMORY MANAGEMENT 177 \n"}
{"section_title": "6.6 allocate Clause", "chunk": "2 Name: allocate Properties: default \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Modifiers \nName Modifies Type Properties \nallocator-simple\ufffemodifier \nlist expression of OpenMP allo\ufffecator_handle type \nexclusive, unique \nallocator-complex\ufffemodifier \nlist Complex, name: \nallocator Arguments: \nallocator expression of allo\ufffecator_handle type (default) \nunique \nalign-modifier list Complex, name: align Ar\ufffeguments: \nalignment expression of in\ufffeteger type (constant, positive) \nunique \n \n Directives \n allocators, distribute, do, for, parallel, scope, sections, single, target, \n task, taskgroup, taskloop, teams \n Semantics \n The allocate clause specifies the memory allocator to be used to obtain storage for a list of \n variables."}
{"section_title": "6.6 allocate Clause", "chunk": "2 Name: allocate Properties: default \n Arguments \nName Type Properties \nlist list of variable list item type default 4 \n Modifiers \nName Modifies Type Properties \nallocator-simple\ufffemodifier \nlist expression of OpenMP allo\ufffecator_handle type \nexclusive, unique \nallocator-complex\ufffemodifier \nlist Complex, name: \nallocator Arguments: \nallocator expression of allo\ufffecator_handle type (default) \nunique \nalign-modifier list Complex, name: align Ar\ufffeguments: \nalignment expression of in\ufffeteger type (constant, positive) \nunique \n \n Directives \n allocators, distribute, do, for, parallel, scope, sections, single, target, \n task, taskgroup, taskloop, teams \n Semantics \n The allocate clause specifies the memory allocator to be used to obtain storage for a list of \n variables.If a list item in the clause also appears in a data-sharing attribute clause on the same \n directive that privatizes the list item, allocations that arise from that list item in the clause will be \n provided by the memory allocator."}
{"section_title": "6.6 allocate Clause", "chunk": "If a list item in the clause also appears in a data-sharing attribute clause on the same \n directive that privatizes the list item, allocations that arise from that list item in the clause will be \n provided by the memory allocator.If the allocator-simple-modifier is specified, the behavior is as if \n the allocator-complex-modifier is instead specified with allocator-simple-modifier as its allocator \n argument.The allocator-complex-modifier and align-modifier have the same syntax and semantics \n for the allocate clause as the allocator and align clauses have for the allocate \n directive.\n For allocations that arise from this clause the null_fb value of the fallback allocator trait behaves \n as if the abort_fb had been specified."}
{"section_title": "6.6 allocate Clause", "chunk": "\n For allocations that arise from this clause the null_fb value of the fallback allocator trait behaves \n as if the abort_fb had been specified.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the allocate clause are as follows: \n \u2022 For any list item that is specified in the allocate clause on a directive other than the \n allocators directive, a data-sharing attribute clause that may create a private copy of that list \n item must be specified on the same directive.\n \u2022 For task, taskloop or target directives, allocation requests to memory allocators with the \n trait access set to thread result in unspecified behavior.\n \u2022 allocate clauses that appear on a target construct or on constructs in a target region \n must specify an allocator-simple-modifier or allocator-complex-modifier unless a requires \n directive with the dynamic_allocators clause is present in the same compilation unit."}
{"section_title": "6.6 allocate Clause", "chunk": "\n \u2022 allocate clauses that appear on a target construct or on constructs in a target region \n must specify an allocator-simple-modifier or allocator-complex-modifier unless a requires \n directive with the dynamic_allocators clause is present in the same compilation unit.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 align clause, see Section 6.3 \n \u2022 allocator clause, see Section 6.4 \n \u2022 allocators directive, see Section 6.7 \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 scope directive, see Section 11.2 \n \u2022 sections directive, see Section 11.3 \n \u2022 single directive, see Section 11.1 \n \u2022 target directive, see Section 13.8 \n \u2022 task directive, see Section 12.5 \n \u2022 taskgroup directive, see Section 15.4 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \nCHAPTER 6.MEMORY MANAGEMENT 179 \nFortran \n"}
{"section_title": "6.7 allocators Construct", "chunk": "Name: allocators Association: block (allocator structured \nblock) \nCategory: executable Properties: default \n \n Clauses \n allocate \n Additional information \n The allocators construct may alternatively be expressed as one or more allocate directives \n that precede the allocator structured block.The syntax of these directives are as described in \n Section 6.5, except that the list directive argument is optional.If a list argument is not specified, the \n effect is as if there is an implicit list consisting of the names of each variable to be allocated in the \n associated allocate-stmt that is not explicitly listed in another allocate directive associated with \n the statement."}
{"section_title": "6.7 allocators Construct", "chunk": "If a list argument is not specified, the \n effect is as if there is an implicit list consisting of the names of each variable to be allocated in the \n associated allocate-stmt that is not explicitly listed in another allocate directive associated with \n the statement.allocate directives are semantically equivalent to an allocators directive that \n specifies OpenMP allocators and the variables to which they apply in one or more allocate \n clauses, and restricted uses of the allocators directive imply that equivalent uses of \n allocate directives are also restricted.If the allocate directive is used, an allocator will be \n used to allocate all variables even if they are not explicitly listed.This alternate syntax has been \n deprecated.\n Semantics \n The allocators construct specifies that OpenMP memory allocators are used for certain \n variables that are allocated by the associated allocate-stmt."}
{"section_title": "6.7 allocators Construct", "chunk": "\n Semantics \n The allocators construct specifies that OpenMP memory allocators are used for certain \n variables that are allocated by the associated allocate-stmt.If a variable that is to be allocated \n appears as a list item in an allocate clause on the directive, an OpenMP allocator is used to \n allocate storage for the variable according to the semantics of the allocate clause.If a variable \n that is to be allocated does not appear as a list item in an allocate clause, the allocation is \n performed according to the base language implementation.\n Restrictions \n Restrictions to the allocators construct are as follows: \n \u2022 A list item that appears in an allocate clause must appear as one of the variables that is \n allocated by the allocate-stmt in the associated allocator structured block."}
{"section_title": "6.7 allocators Construct", "chunk": "\n Restrictions \n Restrictions to the allocators construct are as follows: \n \u2022 A list item that appears in an allocate clause must appear as one of the variables that is \n allocated by the allocate-stmt in the associated allocator structured block.\n Additional restrictions to the (deprecated) allocate directive when it is associated with an \n allocator structured block are as follows: \n \u2022 If a list is specified, the directive must be preceded by an executable statement or OpenMP \n construct.\n \u2022 If multiple allocate directives are associated with an allocator structured block, at most one \n directive may specify no list items.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 OpenMP Allocator Structured Blocks, see Section 4.3.1.1 \n \u2022 allocate clause, see Section 6.6 \n \u2022 allocate directive, see Section 6.5 \nFortran \n"}
{"section_title": "6.8 uses_allocators Clause", "chunk": "Name: uses_allocators Properties: data-environment attribute, data\ufffesharing attribute 7 \n Arguments \nName Type Properties \nallocator expression of allocator_handle type default 9 \n Modifiers \nName Modifies Type Properties \nmem-space Generic Complex, name: memspace \nArguments: \nmemspace-handle \nexpression of \nmemspace_handle type (de\ufffefault) \ndefault \ntraits-array Generic Complex, name: traits \nArguments: \ntraits variable of alloctrait \narray type (default) \ndefault \n \n Directives \n target \n Additional information \n The comma-separated list syntax, in which each list item is a clause-argument-specification of the \n form allocator[(traits)] may also be used for the uses_allocators clause arguments.With \n this syntax, traits must be a constant array with constant values.This syntax has been deprecated.\nCHAPTER 6."}
{"section_title": "6.8 uses_allocators Clause", "chunk": "\nCHAPTER 6.MEMORY MANAGEMENT 181 \n Semantics \n The uses_allocators clause enables the use of the specified allocator in the region associated \n with the directive on which the clause appears.If allocator refers to a predefined allocator, that \n predefined allocator will be available for use in the region.If allocator does not refer to a \n predefined allocator, the effect is as if allocator is specified on a private clause.The resulting \n corresponding item is assigned the result of a call to omp_init_allocator at the beginning of \n the associated region with arguments memspace-handle, the number of traits in the traits array, and \n traits.If mem-space is not specified, the effect is as if memspace-handle is specified as \n omp_default_mem_space.If traits-array is not specified, the effect is as if traits is specified \n as an empty array.Further, at the end of the associated region, the effect is as if this allocator is \n destroyed as if by a call to omp_destroy_allocator."}
{"section_title": "6.8 uses_allocators Clause", "chunk": "Further, at the end of the associated region, the effect is as if this allocator is \n destroyed as if by a call to omp_destroy_allocator.\n Restrictions \n \u2022 The allocator expression must be a base language identifier.\n \u2022 If allocator is a predefined allocator, no modifiers may be specified.\n \u2022 If allocator is not a predefined allocator, it must be a variable.\n \u2022 The allocator argument must not appear in other data-sharing attribute clauses or data-mapping \n attribute clauses on the same construct.\n \u2022 The traits argument for the traits-array modifier must be a constant array, have constant values \n and be defined in the same scope as the construct on which the clause appears.\n \u2022 The memspace-handle argument for the mem-space modifier must be an identifier that matches \n one of the predefined memory space names."}
{"section_title": "6.8 uses_allocators Clause", "chunk": "\n \u2022 The memspace-handle argument for the mem-space modifier must be an identifier that matches \n one of the predefined memory space names.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 Memory Spaces, see Section 6.1 \n \u2022 omp_destroy_allocator, see Section 18.13.3 \n \u2022 omp_init_allocator, see Section 18.13.2 \n \u2022 target directive, see Section 13.8 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "7 Variant Directives", "chunk": "2 This chapter defines directives and related concepts to support the seamless adaption of programs \n to OpenMP contexts.\n"}
{"section_title": "7.1 OpenMP Contexts", "chunk": "5 At any point in a program, an OpenMP context exists that defines traits that describe the active \n OpenMP constructs, the execution devices, functionality supported by the implementation and \n available dynamic values.The traits are grouped into trait sets.The following trait sets exist: \n construct, device, target_device, implementation and dynamic.Traits are categorized as name-list \n traits, clause-list traits, non-property traits and extension traits.This categorization determines the \n syntax that is used to match the trait, as defined in Section 7.2.\n The construct set is composed of the directive names, each being a trait, of all enclosing constructs \n at that point in the program up to a target construct.Combined and composite constructs are \n added to the set as distinct constructs in the same nesting order specified by the original construct.\n Whether the dispatch construct is added to the construct set is implementation defined."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "\n Whether the dispatch construct is added to the construct set is implementation defined.If it is \n added, it will only be added for the target-call of the associated code.The set is ordered by nesting \n level in ascending order.Specifically, the ordering of the set of constructs is c1, ..., cN , where c1 is \n the construct at the outermost nesting level and cN is the construct at the innermost nesting level.In \n addition, if the point in the program is not enclosed by a target construct, the following rules are \n applied in order: \n 1.For procedures with a declare simd directive, the simd trait is added to the beginning of the \n set as c1 for any generated SIMD versions so the total size of the set is increased by one.\n 2.For procedures that are determined to be function variants by a declare variant directive, the \n selectors c1, ..., cM of the construct selector set are added in the same order to the \n beginning of the set as c1, ..."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "., cM so the total size of the set is increased by M.\n 3.For procedures that are determined to be target function variants by a declare target directive, the \n target trait is added to the beginning of the set as c1 so the total size of the set is increased by one.\n The simd trait is a clause-list trait that is defined with properties that match the clauses accepted by \n the declare simd directive with the same name and semantics.The simd trait defines at least the \n simdlen property and one of the inbranch or notinbranch properties.Traits in the construct set \n other than simd are non-property traits.\n \n The device set includes traits that define the characteristics of the device being targeted by the \n compiler at that point in the program.For each target device that the implementation supports, a \n target_device set exists that defines the characteristics of that device."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "For each target device that the implementation supports, a \n target_device set exists that defines the characteristics of that device.At least the following traits \n must be defined for the device and all target_device sets: \n \u2022 The kind(kind-name-list) trait specifies the general kind of the device.The following kind-name \n values are defined: \n \u2013 host, which specifies that the device is the host device; \n \u2013 nohost, which specifies that the device is not the host device; and \n \u2013 the values defined in the OpenMP Additional Definitions document.\n \u2022 The isa(isa-name-list) trait specifies the Instruction Set Architectures supported by the device.\n The accepted isa-name values are implementation defined.\n \u2022 The arch(arch-name-list) trait specifies the architectures supported by the device.The accepted \n arch-name values are implementation defined.\n The kind, isa and arch traits in the device and target_device sets are name-list traits."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "\n The kind, isa and arch traits in the device and target_device sets are name-list traits.\n Additionally, the target_device set defines the following trait: \n \u2022 The device_num trait specifies the device number of the device.\n The implementation set includes traits that describe the functionality supported by the OpenMP \n implementation at that point in the program.At least the following traits can be defined: \n \u2022 The vendor(vendor-name-list) trait, which specifies the vendor identifiers of the implementation.\n OpenMP defined values for vendor-name are defined in the OpenMP Additional Definitions \n document.\n \u2022 The extension(extension-name-list) trait, which specifies vendor specific extensions to the \n OpenMP specification.The accepted extension-name values are implementation defined.\n \u2022 A trait with a name that is identical to the name of any clause that was supplied to the requires \n directive prior to the program point."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "\n \u2022 A trait with a name that is identical to the name of any clause that was supplied to the requires \n directive prior to the program point.Such traits other than the atomic_default_mem_order trait \n are non-property traits.The presence of these traits has been deprecated.\n \u2022 A requires(requires-clause-list) trait, which is a clause-list trait for which the properties are the \n clauses that have been supplied to the requires directive prior to the program point as well as \n implementation-defined implicit requirements.\n The vendor and extension traits in the implementation set are name-list traits.\n Implementations can define additional traits in the device, target_device and implementation sets; \n these traits are extension traits.\n The dynamic trait set includes traits that define the dynamic properties of a program at a point in its \n execution."}
{"section_title": "7.1 OpenMP Contexts", "chunk": "\n The dynamic trait set includes traits that define the dynamic properties of a program at a point in its \n execution.The data state trait in the dynamic trait set refers to the complete data state of the \n program that may be accessed at runtime.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "7.2 Context Selectors", "chunk": "2 Context selectors are used to define the properties that can match an OpenMP context.OpenMP \n defines different sets of selectors, each containing different selectors."}
{"section_title": "7.2 Context Selectors", "chunk": "OpenMP \n defines different sets of selectors, each containing different selectors.\n The syntax for a context selector is context-selector-specification as described in the following \n grammar: \n context-selector-specification: \n trait-set-selector[,trait-set-selector[,...]] \n \n trait-set-selector: \n trait-set-selector-name={trait-selector[, trait-selector[, ...]]} \n \n trait-selector: \n trait-selector-name[([trait-score: ] trait-property[, trait-property[, ...]])] \n \n trait-property: \n trait-property-name \n trait-property-clause \n trait-property-expression \n trait-property-extension \n \n trait-property-clause: \n clause \n \n trait-property-name: \n identifier \n string-literal \n \n trait-property-expression \n scalar-expression (for C/C++) \n scalar-logical-expression (for Fortran) \n scalar-integer-expression (for Fortran) \n \n trait-score: \n score(score-expression) \n \n trait-property-extension: \n trait-property-name \n identifier(trait-property-extension[, trait-property-extension[, ...]]) \n constant integer expression \n For trait selectors that correspond to name-list traits, each trait-property should be \n trait-property-name and for any value that is a valid identifier both the identifier and the \nCHAPTER 7."}
{"section_title": "7.2 Context Selectors", "chunk": "\n The syntax for a context selector is context-selector-specification as described in the following \n grammar: \n context-selector-specification: \n trait-set-selector[,trait-set-selector[,...]] \n \n trait-set-selector: \n trait-set-selector-name={trait-selector[, trait-selector[, ...]]} \n \n trait-selector: \n trait-selector-name[([trait-score: ] trait-property[, trait-property[, ...]])] \n \n trait-property: \n trait-property-name \n trait-property-clause \n trait-property-expression \n trait-property-extension \n \n trait-property-clause: \n clause \n \n trait-property-name: \n identifier \n string-literal \n \n trait-property-expression \n scalar-expression (for C/C++) \n scalar-logical-expression (for Fortran) \n scalar-integer-expression (for Fortran) \n \n trait-score: \n score(score-expression) \n \n trait-property-extension: \n trait-property-name \n identifier(trait-property-extension[, trait-property-extension[, ...]]) \n constant integer expression \n For trait selectors that correspond to name-list traits, each trait-property should be \n trait-property-name and for any value that is a valid identifier both the identifier and the \nCHAPTER 7.VARIANT DIRECTIVES 185 \n corresponding string literal (for C/C++) and the corresponding char-literal-constant (for Fortran) \n representation are considered representations of the same value."}
{"section_title": "7.2 Context Selectors", "chunk": "VARIANT DIRECTIVES 185 \n corresponding string literal (for C/C++) and the corresponding char-literal-constant (for Fortran) \n representation are considered representations of the same value.\n For trait selectors that correspond to clause-list traits, each trait-property should be \n trait-property-clause.The syntax is the same as for the matching OpenMP clause.\n The construct selector set defines the construct traits that should be active in the OpenMP \n context.Each selector that can be defined in the construct set is the directive-name of a \n context-matching construct.Each trait-property of the simd selector is a trait-property-clause.\n The syntax is the same as for a valid clause of the declare simd directive and the restrictions on \n the clauses from that directive apply.The construct selector is an ordered list c1, ..., cN .\n The device and implementation selector sets define the traits that should be active in the \n corresponding trait set of the OpenMP context."}
{"section_title": "7.2 Context Selectors", "chunk": "\n The device and implementation selector sets define the traits that should be active in the \n corresponding trait set of the OpenMP context.The target_device selector set defines the \n traits that should be active in the target_device trait set for the device that the specified \n device_num selector identifies.The same traits that are defined in the corresponding traits sets \n can be used as selectors with the same properties.The kind selector of the device and \n target_device selector sets can also specify the value any, which is as if no kind selector \n was specified.If a device_num selector does not appear in the target_device selector set \n then a device_num selector that specifies the value of the default-device-var ICV is implied.For \n the device_num selector of the target_device selector set, a single \n trait-property-expression must be specified."}
{"section_title": "7.2 Context Selectors", "chunk": "For \n the device_num selector of the target_device selector set, a single \n trait-property-expression must be specified.For the atomic_default_mem_order selector of \n the implementation set, a single trait-property must be specified as an identifier equal to one \n of the valid arguments to the atomic_default_mem_order clause on the requires \n directive.For the requires selector of the implementation set, each trait-property is a \n trait-property-clause.The syntax is the same as for a valid clause of the requires directive and \n the restrictions on the clauses from that directive apply.\n The user selector set defines the condition selector that provides additional user-defined \n conditions.\n The condition selector contains a single trait-property-expression that must evaluate to true for \n the selector to be true."}
{"section_title": "7.2 Context Selectors", "chunk": "\n The condition selector contains a single trait-property-expression that must evaluate to true for \n the selector to be true.\n Any non-constant expression that is evaluated to determine the suitability of a variant is evaluated \n according to the data state trait in the dynamic trait set of the OpenMP context.\n The user selector set is dynamic if the condition selector is present and the expression in the \n condition selector is not a constant expression; otherwise, it is static.\n All parts of a context selector define the static part of the context selector except the following \n parts, which define the dynamic part of a context selector: \n \u2022 Its user selector set if it is dynamic; and \n \u2022 Its target_device selector set."}
{"section_title": "7.2 Context Selectors", "chunk": "\n All parts of a context selector define the static part of the context selector except the following \n parts, which define the dynamic part of a context selector: \n \u2022 Its user selector set if it is dynamic; and \n \u2022 Its target_device selector set.\n For the match clause of a declare variant directive, any argument of the base function that \n is referenced in an expression that appears in the context selector is treated as a reference to the \n OpenMP API \u2013 Version 5.2 November 2021 \n expression that is passed into that argument at the call to the base function.Otherwise, a variable or \n procedure reference in an expression that appears in a context selector is a reference to the variable \n or procedure of that name that is visible at the location of the directive on which the selector \n appears."}
{"section_title": "7.2 Context Selectors", "chunk": "Otherwise, a variable or \n procedure reference in an expression that appears in a context selector is a reference to the variable \n or procedure of that name that is visible at the location of the directive on which the selector \n appears.\nC++ \n Each occurrence of the this pointer in an expression in a context selector that appears in the \n match clause of a declare variant directive is treated as an expression that is the address of \n the object on which the associated base function is invoked.\nC++ \n Implementations can allow further selectors to be specified.Each specified trait-property for these \n implementation-defined selectors should be trait-property-extension.Implementations can ignore \n specified selectors that are not those described in this section.\n Restrictions \n Restrictions to context selectors are as follows: \n \u2022 Each trait-property can only be specified once in a trait-selector other than the construct \n selector set."}
{"section_title": "7.2 Context Selectors", "chunk": "\n Restrictions \n Restrictions to context selectors are as follows: \n \u2022 Each trait-property can only be specified once in a trait-selector other than the construct \n selector set.\n \u2022 Each trait-set-selector-name can only be specified once.\n \u2022 Each trait-selector-name can only be specified once.\n \u2022 A trait-score cannot be specified in traits from the construct, device or \n target_device trait-selector-sets.\n \u2022 A score-expression must be a non-negative constant integer expression.\n \u2022 The expression of a device_num trait must evaluate to a non-negative integer value that is less \n than or equal to the value of omp_get_num_devices().\n \u2022 A variable or procedure that is referenced in an expression that appears in a context selector must \n be visible at the location of the directive on which the selector appears unless the directive is a \n declare variant directive and the variable is an argument of the associated base function."}
{"section_title": "7.2 Context Selectors", "chunk": "\n \u2022 A variable or procedure that is referenced in an expression that appears in a context selector must \n be visible at the location of the directive on which the selector appears unless the directive is a \n declare variant directive and the variable is an argument of the associated base function.\n \u2022 If trait-property any is specified in the kind trait-selector of the device or \n target_device selector set, no other trait-property may be specified in the same selector.\n \u2022 For a trait-selector that corresponds to a name-list trait, at least one trait-property must be \n specified.\n \u2022 For a trait-selector that corresponds to a non-property trait, no trait-property may be specified.\n \u2022 For the requires selector of the implementation selector set, at least one trait-property \n must be specified.\nCHAPTER 7.VARIANT DIRECTIVES 187 \n"}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": ""}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": "2 A given context selector is compatible with a given OpenMP context if the following conditions are \n satisfied: \n \u2022 All selectors in the user set of the context selector are true; \n \u2022 All traits and trait properties that are defined by selectors in the target_device set of the \n context selector are active in the target_device trait set for the device that is identified by the \n device_num selector; \n \u2022 All traits and trait properties that are defined by selectors in the construct, device and \n implementation sets of the context selector are active in the corresponding trait sets of the \n OpenMP context; \n \u2022 For each selector in the context selector, its properties are a subset of the properties of the \n corresponding trait of the OpenMP context; \n \u2022 Selectors in the construct set of the context selector appear in the same relative order as their \n corresponding traits in the construct trait set of the OpenMP context; and \n \u2022 No specified implementation-defined selector is ignored by the implementation."}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": "2 A given context selector is compatible with a given OpenMP context if the following conditions are \n satisfied: \n \u2022 All selectors in the user set of the context selector are true; \n \u2022 All traits and trait properties that are defined by selectors in the target_device set of the \n context selector are active in the target_device trait set for the device that is identified by the \n device_num selector; \n \u2022 All traits and trait properties that are defined by selectors in the construct, device and \n implementation sets of the context selector are active in the corresponding trait sets of the \n OpenMP context; \n \u2022 For each selector in the context selector, its properties are a subset of the properties of the \n corresponding trait of the OpenMP context; \n \u2022 Selectors in the construct set of the context selector appear in the same relative order as their \n corresponding traits in the construct trait set of the OpenMP context; and \n \u2022 No specified implementation-defined selector is ignored by the implementation.\n Some properties of the simd selector have special rules to match the properties of the simd trait: \n \u2022 The simdlen(N) property of the selector matches the simdlen(M) trait of the OpenMP context \n if M is a multiple of N; and \n \u2022 The aligned(list:N) property of the selector matches the aligned(list:M) trait of the OpenMP \n context if N is a multiple of M."}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": "\n Some properties of the simd selector have special rules to match the properties of the simd trait: \n \u2022 The simdlen(N) property of the selector matches the simdlen(M) trait of the OpenMP context \n if M is a multiple of N; and \n \u2022 The aligned(list:N) property of the selector matches the aligned(list:M) trait of the OpenMP \n context if N is a multiple of M.\n Among compatible context selectors, a score is computed using the following algorithm: \n 1.Each trait selector for which the corresponding trait appears in the construct trait set in the \nOpenMP context is given the value 2 \np\u22121 23 where p is the position of the corresponding trait, cp, in \n the context construct trait set; if the traits that correspond to the construct selector set \n appear multiple times in the OpenMP context, the highest valued subset of context traits that \n contains all selectors in the same order are used; \n."}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": "Each trait selector for which the corresponding trait appears in the construct trait set in the \nOpenMP context is given the value 2 \np\u22121 23 where p is the position of the corresponding trait, cp, in \n the context construct trait set; if the traits that correspond to the construct selector set \n appear multiple times in the OpenMP context, the highest valued subset of context traits that \n contains all selectors in the same order are used; \n.The kind, arch, and isa selectors, if specified, are given the values 2 \nl \n, 2 \nl+1 and 2 \nl+2 27 , \n respectively, where l is the number of traits in the construct set; \n 3.Trait selectors for which a trait-score is specified are given the value specified by the trait-score \n score-expression; \n 4.The values given to any additional selectors allowed by the implementation are implementation \n defined; \n 5.Other selectors are given a value of zero; and \n OpenMP API \u2013 Version 5.2 November 2021 \n 6."}
{"section_title": "7.3 Matching and Scoring Context Selectors", "chunk": "Other selectors are given a value of zero; and \n OpenMP API \u2013 Version 5.2 November 2021 \n 6.A context selector that is a strict subset of another context selector has a score of zero.For other \n context selectors, the final score is the sum of the values of all specified selectors plus 1.\n"}
{"section_title": "7.4 Metadirectives", "chunk": "4 A metadirective is a directive that can specify multiple directive variants of which one may be \n conditionally selected to replace the metadirective based on the enclosing OpenMP context.A \n metadirective is replaced by a nothing directive or one of the directive variants specified by the \n when clauses or the otherwise clause.If no otherwise clause is specified the effect is as if \n one was specified without an associated directive variant.\n The OpenMP context for a given metadirective is defined according to Section 7.1.The order of \n clauses that appear on a metadirective is significant and otherwise must be the last clause \n specified on a metadirective.\n Replacement candidates are ordered according to the following rules in decreasing precedence: \n \u2022 A candidate is before another one if the score associated with the context selector of the \n corresponding when clause is higher."}
{"section_title": "7.4 Metadirectives", "chunk": "\n Replacement candidates are ordered according to the following rules in decreasing precedence: \n \u2022 A candidate is before another one if the score associated with the context selector of the \n corresponding when clause is higher.\n \u2022 A candidate that was explicitly specified is before one that was implicitly specified.\n \u2022 Candidates are ordered according to the order in which they lexically appear on the metadirective.\n The list of dynamic replacement candidates is the prefix of the sorted list of replacement candidates \n up to and including the first candidate for which the corresponding when clause has a static context \n selector.The first dynamic replacement candidate for which the corresponding when clause has a \n compatible context selector, according to the matching rules defined in Section 7.3, replaces the \n metadirective."}
{"section_title": "7.4 Metadirectives", "chunk": "The first dynamic replacement candidate for which the corresponding when clause has a \n compatible context selector, according to the matching rules defined in Section 7.3, replaces the \n metadirective.\n Restrictions \n Restrictions to metadirectives are as follows: \n \u2022 Replacement of the metadirective with the directive variant associated with any of the dynamic \n replacement candidates must result in a conforming OpenMP program.\n \u2022 Insertion of user code at the location of a metadirective must be allowed if the first dynamic \n replacement candidate does not have a static context selector.\n \u2022 All items must be executable directives if the first dynamic replacement candidate does not have \n a static context selector.\nFortran \n \u2022 A metadirective that appears in the specification part of a subprogram must follow all \n variant-generating declarative directives that appear in the same specification part."}
{"section_title": "7.4 Metadirectives", "chunk": "\nFortran \n \u2022 A metadirective that appears in the specification part of a subprogram must follow all \n variant-generating declarative directives that appear in the same specification part.\n \u2022 All directive variants of a metadirective must be pure otherwise the metadirective is not pure.\nFortran \nCHAPTER 7.VARIANT DIRECTIVES 189 \n"}
{"section_title": "7.4.1 when Clause", "chunk": "2 Name: when Properties: default \n Arguments \nName Type Properties \ndirective-variant directive-specification optional, unique 4 \n Modifiers \nName Modifies Type Properties \ncontext-selector directive-variant An OpenMP context\ufffeselector-specification \n required, unique \n Directives \n begin metadirective, metadirective \n Semantics \n The directive variant specified by a when clause is a candidate to replace the metadirective on \n which the clause is specified if the static part of the corresponding context selector is compatible \n with the OpenMP context according to the matching rules defined in Section 7.3.If a when clause \n does not explicitly specify a directive variant it implicitly specifies a nothing directive as the \n directive variant."}
{"section_title": "7.4.1 when Clause", "chunk": "If a when clause \n does not explicitly specify a directive variant it implicitly specifies a nothing directive as the \n directive variant.\n Expressions that appear in the context selector of a when clause are evaluated if no prior dynamic \n replacement candidate has a compatible context selector, and the number of times each expression \n is evaluated is implementation defined.All variables referenced by these expressions are \n considered to be referenced by the metadirective.\n A directive variant that is associated with a when clause can only affect the program if the directive \n variant is a dynamic replacement candidate.\n Restrictions \n Restrictions to the when clause are as follows: \n \u2022 directive-variant must not specify a metadirective.\n \u2022 context-selector must not specify any properties for the simd selector.\nC / C++ \n \u2022 directive-variant must not specify a begin declare variant directive."}
{"section_title": "7.4.1 when Clause", "chunk": "\nC / C++ \n \u2022 directive-variant must not specify a begin declare variant directive.\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Context Selectors, see Section 7.2 \n \u2022 begin metadirective directive, see Section 7.4.4 \n \u2022 metadirective directive, see Section 7.4.3 \n \u2022 nothing directive, see Section 8.4 \n"}
{"section_title": "7.4.2 otherwise Clause", "chunk": "7 Name: otherwise Properties: unique, ultimate \n Arguments \nName Type Properties \ndirective-variant directive-specification optional, unique 9 \n Directives \n begin metadirective, metadirective \n Additional information \n The clause-name default may be used as a synonym for the clause-name otherwise.This use \n has been deprecated.\n Semantics \n The otherwise clause is treated as a when clause with the specified directive variant, if any, and \n an always compatible static context selector that has a score lower than the scores associated with \n any other clause.\n Restrictions \n Restrictions to the otherwise clause are as follows: \n \u2022 directive-variant must not specify a metadirective.\nC / C++ \n \u2022 directive-variant must not specify a begin declare variant directive.\nC / C++ \n Cross References \n \u2022 begin metadirective directive, see Section 7.4.4 \n \u2022 metadirective directive, see Section 7.4.3 \n \u2022 when clause, see Section 7.4.1 \nCHAPTER 7."}
{"section_title": "7.4.2 otherwise Clause", "chunk": "\nC / C++ \n Cross References \n \u2022 begin metadirective directive, see Section 7.4.4 \n \u2022 metadirective directive, see Section 7.4.3 \n \u2022 when clause, see Section 7.4.1 \nCHAPTER 7.VARIANT DIRECTIVES 191 \n"}
{"section_title": "7.4.3 metadirective", "chunk": "Name: metadirective Association: none \nCategory: meta Properties: pure \n \n Clauses \n otherwise, when \n Semantics \n The metadirective specifies metadirective semantics.\n Cross References \n \u2022 Metadirectives, see Section 7.4 \n \u2022 otherwise clause, see Section 7.4.2 \n \u2022 when clause, see Section 7.4.1 \n"}
{"section_title": "7.4.4 begin metadirective", "chunk": "Name: begin metadirective Association: delimited \nCategory: meta Properties: pure \n \n Clauses \n otherwise, when \n Semantics \n The begin metadirective is a metadirective for which the specified directive variants other \n than the nothing directive must accept a paired end directive.For any directive variant that is \n selected to replace the begin metadirective directive, the end metadirective directive \n is implicitly replaced by its paired end directive to demarcate the statements that are affected by or \n are associated with the directive variant.If the nothing directive is selected to replace the \n begin metadirective directive, the paired end metadirective is ignored.\n Restrictions \n The restrictions to begin metadirective are as follows: \n \u2022 Any directive-variant that is specified by a when or otherwise clause must be an OpenMP \n directive that has a paired end directive or must be the nothing directive."}
{"section_title": "7.4.4 begin metadirective", "chunk": "\n Restrictions \n The restrictions to begin metadirective are as follows: \n \u2022 Any directive-variant that is specified by a when or otherwise clause must be an OpenMP \n directive that has a paired end directive or must be the nothing directive.\n Cross References \n \u2022 Metadirectives, see Section 7.4 \n \u2022 nothing directive, see Section 8.4 \n \u2022 otherwise clause, see Section 7.4.2 \n \u2022 when clause, see Section 7.4.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "7.5 Declare Variant Directives", "chunk": "2 Declare variant directives declare base functions to have the specified function variant.The context \n selector in the match clause is associated with the variant.\n The OpenMP context for a direct call to a given base function is defined according to Section 7.1.If \n a declare variant directive for the base function is visible at the call site and the static part of the \n context selector that is associated with the declared function variant is compatible with the \n OpenMP context of the call according to the matching rules defined in Section 7.3 then the variant \n is a replacement candidate to be called instead of the base function.Replacement candidates are \n ordered in decreasing order of the score associated with the context selector.If two replacement \n candidates have the same score then their order is implementation defined."}
{"section_title": "7.5 Declare Variant Directives", "chunk": "If two replacement \n candidates have the same score then their order is implementation defined.\n The list of dynamic replacement candidates is the prefix of the sorted list of replacement candidates \n up to and including the first candidate for which the corresponding context selector is static.\n The first dynamic replacement candidate for which the corresponding context selector is \n compatible, according to the matching rules defined in Section 7.3, is called instead of the base \n function.If no compatible candidate exists then the base function is called.\n Expressions that appear in the context selector of a match clause are evaluated if no prior dynamic \n replacement candidate has a compatible context selector, and the number of times each expression \n is evaluated is implementation defined.All variables referenced by these expressions are \n considered to be referenced at the call site."}
{"section_title": "7.5 Declare Variant Directives", "chunk": "All variables referenced by these expressions are \n considered to be referenced at the call site.\nC++ \n For calls to constexpr base functions that are evaluated in constant expressions, whether any \n variant replacement occurs is implementation defined.\nC++ \n For indirect function calls that can be determined to call a particular base function, whether any \n variant replacement occurs is unspecified.\n Any differences that the specific OpenMP context requires in the prototype of the variant from the \n base function prototype are implementation defined.\n Different declare variant directives may be specified for different declarations of the same base \n function."}
{"section_title": "7.5 Declare Variant Directives", "chunk": "\n Different declare variant directives may be specified for different declarations of the same base \n function.\n Restrictions \n Restrictions to declare variant directives are as follows: \n \u2022 Calling functions that a declare variant directive determined to be a function variant directly in \n an OpenMP context that is different from the one that the construct selector set of the context \n selector specifies is non-conforming.\n \u2022 If a function is determined to be a function variant through more than one declare variant \n directive then the construct selector set of their context selectors must be the same.\nCHAPTER 7.VARIANT DIRECTIVES 193 \n \u2022 A function determined to be a function variant may not be specified as a base function in another \n declare variant directive.\n \u2022 An adjust_args clause or append_args clause can only be specified if the dispatch \n selector of the construct selector set appears in the match clause."}
{"section_title": "7.5 Declare Variant Directives", "chunk": "\n \u2022 An adjust_args clause or append_args clause can only be specified if the dispatch \n selector of the construct selector set appears in the match clause.\nC / C++ \n \u2022 The type of the function variant must be compatible with the type of the base function after the \n implementation-defined transformation for its OpenMP context.\nC / C++ \nC++ \n \u2022 Declare variant directives cannot be specified for virtual, defaulted or deleted functions.\n \u2022 Declare variant directives cannot be specified for constructors or destructors.\n \u2022 Declare variant directives cannot be specified for immediate functions.\n \u2022 The function that a declare variant directive determined to be a function variant may not be an \n immediate function.\nC++ \n Cross References \n \u2022 Context Selectors, see Section 7.2 \n \u2022 OpenMP Contexts, see Section 7.1 \n \u2022 begin declare variant directive, see Section 7.5.5 \n \u2022 declare variant directive, see Section 7.5.4 \n"}
{"section_title": "7.5.1 match Clause", "chunk": "18 Name: match Properties: unique, required \n Arguments \nName Type Properties \ncontext-selector An OpenMP context-selector\ufffespecification \n default \n Directives \n begin declare variant, declare variant \n Semantics \n The match clause specifies the context-selector to use to determine if a specified variant function \n is a replacement candidate for the specified base function in a given context.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the match clause are as follows: \n \u2022 All variables that are referenced in an expression that appears in the context selector of a match \n clause must be accessible at a call site to the base function according to the base language rules.\n Cross References \n \u2022 Context Selectors, see Section 7.2 \n \u2022 begin declare variant directive, see Section 7.5.5 \n \u2022 declare variant directive, see Section 7.5.4 \n"}
{"section_title": "7.5.2 adjust_args Clause", "chunk": "10 Name: adjust_args Properties: default \n Arguments \nName Type Properties \nparameter-list list of parameter list item type default 12 \n Modifiers \nName Modifies Type Properties \nadjust-op parameter-list Keyword: \nneed_device_ptr, \nnothing \nrequired 14 \n Directives \n declare variant \n Semantics \n The adjust_args clause specifies how to adjust the arguments of the base function when a \n specified variant function is selected for replacement.For each adjust_args clause that is \n present on the selected variant the adjustment operation specified by adjust-op is applied to each \n argument specified in the clause before being passed to the selected variant.If the adjust-op \n modifier is nothing, the argument is passed to the selected variant without being modified.\n If the adjust-op modifier is need_device_ptr, the arguments are converted to corresponding \n device pointers of the default device."}
{"section_title": "7.5.2 adjust_args Clause", "chunk": "\n If the adjust-op modifier is need_device_ptr, the arguments are converted to corresponding \n device pointers of the default device.If an argument has the is_device_ptr property in its \n interoperability requirement set then the argument is not adjusted.Otherwise, the argument is \n converted in the same manner that a use_device_ptr clause on a target data construct \n converts its pointer list items into device pointers.If the argument cannot be converted into a device \n pointer then NULL is passed as the argument.\nCHAPTER 7.VARIANT DIRECTIVES 195 \n Restrictions \nFortran \n \u2022 Each argument that appears in a need_device_ptr adjust-op must be of type C_PTR in the \n dummy argument declaration of the variant function.\nFortran \n Cross References \n \u2022 declare variant directive, see Section 7.5.4 \n"}
{"section_title": "7.5.3 append_args Clause", "chunk": "7 Name: append_args Properties: unique \n Arguments \nName Type Properties \nappend-op-list list of OpenMP operation list item type default 9 \n Directives \n declare variant \n Semantics \n The append_args clause specifies additional arguments to pass in the call when a specified \n variant function is selected for replacement.The arguments are constructed according to each \n specified list item in append-op-list and are passed in the same order in which they are specified in \n the list.\n The supported OpenMP operations in append-op-list are: \n interop \n The interop operation accepts a comma-separated list of operands, each of which is an \n interop-type that is supported by the init clause on the interop construct.\n Each interop operation constructs an argument of interop OpenMP type using the \n interoperability requirement set of the encountering task."}
{"section_title": "7.5.3 append_args Clause", "chunk": "\n Each interop operation constructs an argument of interop OpenMP type using the \n interoperability requirement set of the encountering task.The argument is constructed as if by an \n interop construct with an init clause that specifies each interop-type operand in the interop \n operation.If the interoperability requirement set contains one or more properties that could be used \n as clauses for an interop construct of interop-type, the behavior is as if the corresponding \n clauses would also be part of the interop construct and those properties are removed from the \n interoperability requirement set.\n This argument is destroyed after the call to the selected variant returns, as if an interop construct \n with a destroy clause was used with the same clauses that were used to initialize the argument."}
{"section_title": "7.5.3 append_args Clause", "chunk": "\n This argument is destroyed after the call to the selected variant returns, as if an interop construct \n with a destroy clause was used with the same clauses that were used to initialize the argument.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Interoperability Requirement Set, see Section 14.2 \n \u2022 OpenMP Operations, see Section 3.2.3 \n \u2022 declare variant directive, see Section 7.5.4 \n \u2022 interop directive, see Section 14.1 \n"}
{"section_title": "7.5.4 declare variant Directive", "chunk": "Name: declare variant Association: declaration \nCategory: declarative Properties: pure \n \n Arguments \n declare variant([base\u2013name:]variant-name) \nName Type Properties \nbase-name identifier of function type optional \nvariant-name identifier of function type default \n \n Clauses \n adjust_args, append_args, match \n Semantics \n The declare variant specifies declare variant semantics for a single replacement candidate.\n variant-name identifies the function variant while base-name identifies the base function.\nC \n Any expressions in the match clause are interpreted as if they appeared in the scope of arguments \n of the base function.\nC \nC++ \n variant-name and any expressions in the match clause are interpreted as if they appeared at the \n scope of the trailing return type of the base function."}
{"section_title": "7.5.4 declare variant Directive", "chunk": "\nC \nC++ \n variant-name and any expressions in the match clause are interpreted as if they appeared at the \n scope of the trailing return type of the base function.\n The function variant is determined by base language standard name lookup rules ([basic.lookup]) \n of variant-name using the argument types at the call site after implementation-defined changes have \n been made according to the OpenMP context.\nC++ \nFortran \n The procedure to which base-name refers is resolved at the location of the directive according to the \n establishment rules for procedure names in the base language.\nFortran \nCHAPTER 7.VARIANT DIRECTIVES 197 \n Restrictions \n \u2022 If base-name is specified, it must match the name used in the associated declaration, if any \n declaration is associated.\nFortran \n \u2022 base-name must not be a generic name, an entry name, the name of a procedure pointer, a \n dummy procedure or a statement function."}
{"section_title": "7.5.4 declare variant Directive", "chunk": "\nFortran \n \u2022 base-name must not be a generic name, an entry name, the name of a procedure pointer, a \n dummy procedure or a statement function.\n \u2022 If base-name is omitted then the declare variant directive must appear in an interface \n block or the specification part of a procedure.\n \u2022 Any declare variant directive must appear in the specification part of a subroutine \n subprogram, function subprogram, or interface body to which it applies.\n \u2022 If the directive is specified for a procedure that is declared via a procedure declaration statement, \n the base-name must be specified.\n \u2022 The procedure base-name must have an accessible explicit interface at the location of the \n directive.\nFortran \n Cross References \n \u2022 Declare Variant Directives, see Section 7.5 \n \u2022 adjust_args clause, see Section 7.5.2 \n \u2022 append_args clause, see Section 7.5.3 \n \u2022 match clause, see Section 7.5.1 \nC / C++ \n"}
{"section_title": "7.5.5 begin declare variant Directive", "chunk": "Name: begin declare variant Association: delimited (declaration\ufffedefinition-seq) \nCategory: declarative Properties: default \n \n Clauses \n match \n Semantics \n The begin declare variant directive associates the context selector in the match clause \n with each function definition in declaration-definition-seq.For the purpose of call resolution, each \n function definition that appears between a begin declare variant directive and its paired \n end directive is a function variant for an assumed base function, with the same name and a \n compatible prototype, that is declared elsewhere without an associated declare variant directive.\n OpenMP API \u2013 Version 5.2 November 2021 \n If a declare variant directive appears between a begin declare variant directive and its \n paired end directive, the effective context selectors of the outer directive are appended to the \n context selector of the inner directive to form the effective context selector of the inner directive."}
{"section_title": "7.5.5 begin declare variant Directive", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If a declare variant directive appears between a begin declare variant directive and its \n paired end directive, the effective context selectors of the outer directive are appended to the \n context selector of the inner directive to form the effective context selector of the inner directive.If \n a trait-set-selector is present on both directives, the trait-selector list of the outer directive is \n appended to the trait-selector list of the inner directive after equivalent trait-selectors have been \n removed from the outer list.Restrictions that apply to explicitly specified context selectors also \n apply to effective context selectors constructed through this process."}
{"section_title": "7.5.5 begin declare variant Directive", "chunk": "Restrictions that apply to explicitly specified context selectors also \n apply to effective context selectors constructed through this process.\n The symbol name of a function definition that appears between a begin declare variant \n directive and its paired end directive is determined through the base language rules after the name \n of the function has been augmented with a string that is determined according to the effective \n context selector of the begin declare variant directive.The symbol names of two definitions \n of a function are considered to be equal if and only if their effective context selectors are equivalent.\n If the context selector of a begin declare variant directive contains traits in the device or \n implementation set that are known never to be compatible with an OpenMP context during the \n current compilation, the preprocessed code that follows the begin declare variant directive \n up to its paired end directive is elided."}
{"section_title": "7.5.5 begin declare variant Directive", "chunk": "\n If the context selector of a begin declare variant directive contains traits in the device or \n implementation set that are known never to be compatible with an OpenMP context during the \n current compilation, the preprocessed code that follows the begin declare variant directive \n up to its paired end directive is elided.\n Any expressions in the match clause are interpreted at the location of the directive.\n Restrictions \n The restrictions to begin declare variant directive are as follows: \n \u2022 match clause must not contain a simd trait-selector-name.\n \u2022 Two begin declare variant directives and their paired end directives must either \n encompass disjoint source ranges or be perfectly nested.\n \u2022 match clause must not contain a dynamic context selector that references the this pointer.\n \u2022 If an expression in the context selector that appears in match clause references the this \n pointer, the base function must be a non-static member function."}
{"section_title": "7.5.5 begin declare variant Directive", "chunk": "\n \u2022 If an expression in the context selector that appears in match clause references the this \n pointer, the base function must be a non-static member function.\n Cross References \n \u2022 Declare Variant Directives, see Section 7.5 \n \u2022 match clause, see Section 7.5.1 \nC / C++ \nCHAPTER 7.VARIANT DIRECTIVES 199 \n"}
{"section_title": "7.6 dispatch Construct", "chunk": "Name: dispatch Association: block (function dispatch struc\ufffetured block) \nCategory: executable Properties: context-matching \n \n Clauses \n depend, device, is_device_ptr, nocontext, novariants, nowait \n Binding \n The binding task set for a dispatch region is the generating task.The dispatch region binds \n to the region of the generating task.\n Semantics \n The dispatch construct controls whether variant substitution occurs for target-call in the \n associated function dispatch structured block.\n Properties added to the interoperability requirement set can be removed by the effect of other \n directives (see Section 14.2) before the dispatch region is executed.If one or more depend \n clauses are present on the dispatch construct, they are added as depend properties of the \n interoperability requirement set.If a nowait clause is present on the dispatch construct the \n nowait property is added to the interoperability requirement set."}
{"section_title": "7.6 dispatch Construct", "chunk": "If a nowait clause is present on the dispatch construct the \n nowait property is added to the interoperability requirement set.For each list item specified in an \n is_device_ptr clause, an is_device_ptr property for that list item is added to the \n interoperability requirement set.\n If the interoperability requirement set contains one or more depend properties, the behavior is as if \n those properties were applied as depend clauses to a taskwait construct that is executed before \n the dispatch region is executed.\n The presence of the nowait property in the interoperability requirement set has no effect on the \n dispatch construct.\n If the device clause is present, the value of the default-device-var ICV is set to the value of the \n expression in the clause on entry to the dispatch region and is restored to its previous value at \n the end of the region."}
{"section_title": "7.6 dispatch Construct", "chunk": "\n If the device clause is present, the value of the default-device-var ICV is set to the value of the \n expression in the clause on entry to the dispatch region and is restored to its previous value at \n the end of the region.\n Cross References \n \u2022 Interoperability Requirement Set, see Section 14.2 \n \u2022 OpenMP Function Dispatch Structured Blocks, see Section 4.3.1.2 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 device clause, see Section 13.2 \n \u2022 is_device_ptr clause, see Section 5.4.7 \n \u2022 nocontext clause, see Section 7.6.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 novariants clause, see Section 7.6.1 \n \u2022 nowait clause, see Section 15.6 \n"}
{"section_title": "7.6.1 novariants Clause", "chunk": "4 Name: novariants Properties: unique \n Arguments \nName Type Properties \ndo-not-use-variant expression of logical type default 6 \n Directives \n dispatch \n Semantics \n If do-not-use-variant evaluates to true, no function variant is selected for the target-call of the \n dispatch region associated with the novariants clause even if one would be selected \n normally.The use of a variable in do-not-use-variant causes an implicit reference to the variable in \n all enclosing constructs.do-not-use-variant is evaluated in the enclosing context.\n Cross References \n \u2022 dispatch directive, see Section 7.6 \n"}
{"section_title": "7.6.2 nocontext Clause", "chunk": "17 Name: nocontext Properties: unique \n Arguments \nName Type Properties \ndo-not-update-context expression of logical type default 19 \n Directives \n dispatch \n Semantics \n If do-not-update-context evaluates to true, the construct on which the nocontext clause appears \n is not added to the construct set of the OpenMP context.The use of a variable in \n do-not-update-context causes an implicit reference to the variable in all enclosing constructs.\n do-not-update-context is evaluated in the enclosing context.\n Cross References \n \u2022 dispatch directive, see Section 7.6 \nCHAPTER 7.VARIANT DIRECTIVES 201 \n"}
{"section_title": "7.7 declare simd Directive", "chunk": "Name: declare simd Association: declaration \nCategory: declarative Properties: pure \n \n Arguments \n declare simd[(proc-name)] \nName Type Properties \nproc-name identifier of function type optional 5 \n Clause groups \n branch \n Clauses \n aligned, linear, simdlen, uniform \n Semantics \n The association of one or more declare simd directives with a function declaration or definition \n enables the creation of corresponding SIMD versions of the associated function that can be used to \n process multiple arguments from a single invocation in a SIMD loop concurrently.\n If a SIMD version is created and the simdlen clause is not specified, the number of concurrent \n arguments for the function is implementation defined.\n For purposes of the linear clause, any integer-typed parameter that is specified in a uniform \n clause on the directive is considered to be constant and so may be used in linear-step."}
{"section_title": "7.7 declare simd Directive", "chunk": "\n For purposes of the linear clause, any integer-typed parameter that is specified in a uniform \n clause on the directive is considered to be constant and so may be used in linear-step.\nC / C++ \n The expressions that appear in the clauses of each directive are evaluated in the scope of the \n arguments of the function declaration or definition.\nC / C++ \nC++ \n The special this pointer can be used as if it was one of the arguments to the function in any of the \n linear, aligned, or uniform clauses.\nC++ \n Restrictions \n Restrictions to the declare simd directive are as follows: \n \u2022 The function or subroutine body must be a structured block.\n \u2022 The execution of the function or subroutine, when called from a SIMD loop, cannot result in the \n execution of an OpenMP construct except for an ordered construct with the simd clause or an \n atomic construct."}
{"section_title": "7.7 declare simd Directive", "chunk": "\n \u2022 The execution of the function or subroutine, when called from a SIMD loop, cannot result in the \n execution of an OpenMP construct except for an ordered construct with the simd clause or an \n atomic construct.\n \u2022 The execution of the function or subroutine cannot have any side effects that would alter its \n execution for concurrent iterations of a SIMD chunk.\n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n \u2022 If the function has any declarations, then the declare simd directive for any declaration that \n has one must be equivalent to the one specified for the definition.\n \u2022 The function cannot contain calls to the longjmp or setjmp functions.\nC / C++ \nC++ \n \u2022 The function cannot contain throw statements.\nC++ \nFortran \n \u2022 proc-name must not be a generic name, procedure pointer, or entry name."}
{"section_title": "7.7 declare simd Directive", "chunk": "\nC++ \nFortran \n \u2022 proc-name must not be a generic name, procedure pointer, or entry name.\n \u2022 If proc-name is omitted, the declare simd directive must appear in the specification part of a \n subroutine subprogram or a function subprogram for which creation of the SIMD versions is \n enabled.\n \u2022 Any declare simd directive must appear in the specification part of a subroutine subprogram, \n function subprogram, or interface body to which it applies.\n \u2022 If a declare simd directive is specified in an interface block for a procedure, it must match a \n declare simd directive in the definition of the procedure.\n \u2022 If a procedure is declared via a procedure declaration statement, the procedure proc-name should \n appear in the same specification.\n \u2022 If a declare simd directive is specified for a procedure name with explicit interface and a \n declare simd directive is also specified for the definition of the procedure then the two \n declare simd directives must match."}
{"section_title": "7.7 declare simd Directive", "chunk": "\n \u2022 If a declare simd directive is specified for a procedure name with explicit interface and a \n declare simd directive is also specified for the definition of the procedure then the two \n declare simd directives must match.\n \u2022 Procedure pointers may not be used to access versions created by the declare simd directive.\nFortran \n Cross References \n \u2022 aligned clause, see Section 5.11 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 simdlen clause, see Section 10.4.3 \n \u2022 uniform clause, see Section 5.10 \nCHAPTER 7.VARIANT DIRECTIVES 203 \n"}
{"section_title": "7.7.1 branch Clauses", "chunk": "2 Clause groups \n Properties: unique, exclusive, inarguable Members: inbranch, notinbranch \n Directives \n declare simd \n Semantics \n The branch clause grouping defines a set of clauses that indicate if a function can be assumed to be \n or not to be encountered in a branch.The inbranch clause specifies that the function will always \n be called from inside a conditional statement of the calling context.The notinbranch clause \n specifies that the function will never be called from inside a conditional statement of the calling \n context.If neither clause is specified, then the function may or may not be called from inside a \n conditional statement of the calling context.\n Cross References \n \u2022 declare simd directive, see Section 7.7 \n"}
{"section_title": "7.8 Declare Target Directives", "chunk": "16 Declare target directives apply to procedures and/or variables to ensure that they can be executed or \n accessed on a device.Variables are mapped for all device executions, or for specific device \n executions through a link clause.An implementation may generate different versions of a \n procedure to be used for target regions that execute on different devices.Whether the same \n version is generated for different devices, or whether a version that is called in a target region \n differs from the version that is called outside a target region, is implementation defined.\n To facilitate device usage, OpenMP defines rules that implicitly specify declare target directives for \n procedures and variables.The remainder of this section defines those rules as well as restrictions \n that apply to all declare target directives."}
{"section_title": "7.8 Declare Target Directives", "chunk": "The remainder of this section defines those rules as well as restrictions \n that apply to all declare target directives.\n If a variable with static storage duration is declared in a device routine then the named variable is \n treated as if it had appeared in an enter clause on a declare target directive.\n In the following, a non-host declare target directive is one that does not specify a device_type \n clause with host.Further, a reverse-offload region is a region that is associated with a target \n construct that specifies a device clause with the ancestor device-modifier.\nC / C++ \n If a function is referenced outside of any reverse-offload region in a function that appears as a list \n item in an enter clause on a non-host declare target directive then the name of the referenced \n function is treated as if it had appeared in an enter clause on a declare target directive."}
{"section_title": "7.8 Declare Target Directives", "chunk": "\nC / C++ \n If a function is referenced outside of any reverse-offload region in a function that appears as a list \n item in an enter clause on a non-host declare target directive then the name of the referenced \n function is treated as if it had appeared in an enter clause on a declare target directive.\n If a variable with static storage duration or a function (except lambda for C++) is referenced in the \n initializer expression list of a variable with static storage duration that appears as a list item in an \n OpenMP API \u2013 Version 5.2 November 2021 \n enter clause on a declare target directive then the name of the referenced variable or function is \n treated as if it had appeared in an enter clause on a declare target directive."}
{"section_title": "7.8 Declare Target Directives", "chunk": "\n If a variable with static storage duration or a function (except lambda for C++) is referenced in the \n initializer expression list of a variable with static storage duration that appears as a list item in an \n OpenMP API \u2013 Version 5.2 November 2021 \n enter clause on a declare target directive then the name of the referenced variable or function is \n treated as if it had appeared in an enter clause on a declare target directive.\nC / C++ \nFortran \n If a procedure is referenced outside of any reverse-offload region in a procedure that appears as a \n list item in an enter clause on a non-host declare target directive then the name of the \n referenced procedure is treated as if it had appeared in an enter clause on a declare target \n directive.\n If a declare target directive has a device_type clause then any enclosed internal \n procedures cannot contain any declare target directives.The enclosing device_type \n clause implicitly applies to internal procedures."}
{"section_title": "7.8 Declare Target Directives", "chunk": "The enclosing device_type \n clause implicitly applies to internal procedures.\nFortran \n Execution Model Events \n The target-global-data-op event occurs when an original variable is associated with a \n corresponding variable on a device as a result of a declare target directive; the event occurs before \n the first access to the corresponding variable.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op callback, or a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_beginend as its \n endpoint argument for each occurrence of a target-global-data-op event in that thread.These \n callbacks have type signature ompt_callback_target_data_op_t or \n ompt_callback_target_data_op_emi_t, respectively.\n Restrictions \n Restrictions to any declare target directive are as follows: \n \u2022 A variable declared in the directive must have a mappable type.\n \u2022 A variable declared in the directive must have static storage duration."}
{"section_title": "7.8 Declare Target Directives", "chunk": "\n \u2022 A variable declared in the directive must have static storage duration.\n \u2022 The same list item must not explicitly appear in both a enter clause on one declare target \n directive and a link clause on another declare target directive.\n \u2022 If a variable appears in a enter clause on the declare target directive, its initializer must not \n refer to a variable that appears in a link clause on a declare target directive.\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 begin declare target directive, see Section 7.8.2 \n \u2022 declare target directive, see Section 7.8.1 \n \u2022 enter clause, see Section 5.8.4 \n \u2022 link clause, see Section 5.8.5 \n \u2022 target directive, see Section 13.8 \nCHAPTER 7.VARIANT DIRECTIVES 205 \n"}
{"section_title": "7.8.1 declare target Directive", "chunk": "Name: declare target Association: none \nCategory: declarative Properties: device, declare target, pure 2 \n Arguments \n declare target(extended-list) \nName Type Properties \nextended-list list of extended list item type optional 5 \n Clauses \n device_type, enter, indirect, link \n Semantics \n The declare target directive is a declare target directive.If the extended-list argument is \n specified, the effect is as if an enter clause was specified with the extended-list as its argument.\nFortran \n If a declare target directive does not have any clauses and does not have an extended-list then \n an implicit enter clause with one item is formed from the name of the enclosing subroutine \n subprogram, function subprogram or interface body to which it applies.\nFortran \n Restrictions \n Restrictions to the declare target directive are as follows: \n \u2022 If the extended-list argument is specified, no clauses may be specified."}
{"section_title": "7.8.1 declare target Directive", "chunk": "\nFortran \n Restrictions \n Restrictions to the declare target directive are as follows: \n \u2022 If the extended-list argument is specified, no clauses may be specified.\n \u2022 If the directive has a clause, it must contain at least one enter clause or at least one link \n clause.\n \u2022 A variable for which nohost is specified may not appear in a link clause.\nFortran \n \u2022 If a list item is a procedure name, it must not be a generic name, procedure pointer, entry name, \n or statement function name.\n \u2022 If no clauses are specified or if a device_type clause is specified, the directive must appear in \n a specification part of a subroutine subprogram, function subprogram or interface body.\n \u2022 If a list item is a procedure name, the directive must be in the specification part of that subroutine \n or function subprogram or in the specification part of that subroutine or function in an interface \n body."}
{"section_title": "7.8.1 declare target Directive", "chunk": "\n \u2022 If a list item is a procedure name, the directive must be in the specification part of that subroutine \n or function subprogram or in the specification part of that subroutine or function in an interface \n body.\n \u2022 If an extended list item is a variable name, the directive must appear in the specification part of a \n subroutine subprogram, function subprogram, program or module.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If the directive is specified in an interface block for a procedure, it must match a \n declare target directive in the definition of the procedure, including the device_type \n clause if present.\n \u2022 If an external procedure is a type-bound procedure of a derived type and the directive is specified \n in the definition of the external procedure, it must appear in the interface block that is accessible \n to the derived-type definition."}
{"section_title": "7.8.1 declare target Directive", "chunk": "\n \u2022 If an external procedure is a type-bound procedure of a derived type and the directive is specified \n in the definition of the external procedure, it must appear in the interface block that is accessible \n to the derived-type definition.\n \u2022 If any procedure is declared via a procedure declaration statement that is not in the type-bound \n procedure part of a derived-type definition, any declare target with the procedure name \n must appear in the same specification part.\n \u2022 The directive must appear in the declaration section of a scoping unit in which the common block \n or variable is declared.\n \u2022 If a declare target directive that specifies a common block name appears in one program \n unit, then such a directive must also appear in every other program unit that contains a COMMON \n statement that specifies the same name, after the last such COMMON statement in the program unit."}
{"section_title": "7.8.1 declare target Directive", "chunk": "\n \u2022 If a declare target directive that specifies a common block name appears in one program \n unit, then such a directive must also appear in every other program unit that contains a COMMON \n statement that specifies the same name, after the last such COMMON statement in the program unit.\n \u2022 If a list item is declared with the BIND attribute, the corresponding C entities must also be \n specified in a declare target directive in the C program.\n \u2022 A variable can only appear in a declare target directive in the scope in which it is declared.\n It must not be an element of a common block or appear in an EQUIVALENCE statement.\n \u2022 A variable that appears in a declare target directive must be declared in the Fortran scope \n of a module or have the SAVE attribute, either explicitly or implicitly."}
{"section_title": "7.8.1 declare target Directive", "chunk": "\n \u2022 A variable that appears in a declare target directive must be declared in the Fortran scope \n of a module or have the SAVE attribute, either explicitly or implicitly.\nFortran \n Cross References \n \u2022 Declare Target Directives, see Section 7.8 \n \u2022 device_type clause, see Section 13.1 \n \u2022 enter clause, see Section 5.8.4 \n \u2022 indirect clause, see Section 7.8.3 \n \u2022 link clause, see Section 5.8.5 \nC / C++ \n"}
{"section_title": "7.8.2 begin declare target Directive", "chunk": "Name: begin declare target Association: delimited (declaration\ufffedefinition-seq) \nCategory: declarative Properties: device, declare target \n \n Clauses \n device_type, indirect \nCHAPTER 7.VARIANT DIRECTIVES 207 \n Additional information \n The directive name declare target may be used as a synonym to begin declare target \n if no clauses are specified.This syntax has been deprecated.\n Semantics \n The begin declare target directive is a declare target directive.The directive and its paired \n end directive form a delimited code region that defines an implicit extended-list.The implicit \n extended-list consists of the variable names of any variable declarations at file or namespace scope \n that appear in the delimited code region and of the function names of any function declarations at \n file, namespace or class scope that appear in the delimited code region.The implicit extended-list is \n converted to an implicit enter clause."}
{"section_title": "7.8.2 begin declare target Directive", "chunk": "The implicit extended-list is \n converted to an implicit enter clause.\n The delimited code region may contain declare target directives.If a device_type clause is \n present on the contained declare target directive, then its argument determines which versions are \n made available.If a list item appears both in an implicit and explicit list, the explicit list determines \n which versions are made available.\n Restrictions \n Restrictions to the begin declare target directive are as follows: \nC++ \n \u2022 The function names of overloaded functions or template functions may only be specified within \n an implicit extended-list.\n \u2022 If a lambda declaration and definition appears between a begin declare target directive \n and the paired end directive, all variables that are captured by the lambda expression must also \n appear in an enter clause.\n \u2022 A module export or import statement cannot appear between a declare target directive and the \n paired end directive."}
{"section_title": "7.8.2 begin declare target Directive", "chunk": "\n \u2022 A module export or import statement cannot appear between a declare target directive and the \n paired end directive.\nC++ \n Cross References \n \u2022 Declare Target Directives, see Section 7.8 \n \u2022 device_type clause, see Section 13.1 \n \u2022 enter clause, see Section 5.8.4 \n \u2022 indirect clause, see Section 7.8.3 \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "7.8.3 indirect Clause", "chunk": "2 Name: indirect Properties: unique \n Arguments \nName Type Properties \ninvoked-by-fptr expression of logical type constant, optional 4 \n Directives \n begin declare target, declare target \n Semantics \n If invoked-by-fptr evaluates to true, any procedures that appear in an enter clause on the directive \n on which the indirect clause is specified may be called with an indirect device invocation.If the \n invoked-by-fptr does not evaluate to true, any procedures that appear in an enter clause on the \n directive may not be called with an indirect device invocation.Unless otherwise specified by an \n indirect clause, procedures may not be called with an indirect device invocation.If the \n indirect clause is specified and invoked-by-fptr is not specified, the effect of the clause is as if \n invoked-by-fptr evaluates to true."}
{"section_title": "7.8.3 indirect Clause", "chunk": "If the \n indirect clause is specified and invoked-by-fptr is not specified, the effect of the clause is as if \n invoked-by-fptr evaluates to true.\nC / C++ \n If a function appears in the implicit enter clause of a begin declare target directive and in \n the enter clause of a declare target directive that is contained in the delimited code region of the \n begin declare target directive, and if an indirect clause appears on both directives, then \n the indirect clause on the begin declare target directive has no effect for that function.\nC / C++ \n Restrictions \n Restrictions to the indirect clause are as follows: \n \u2022 If invoked-by-fptr evaluates to true, a device_type clause must not appear on the same \n directive unless it specifies any.for its device-type-description.\n Cross References \n \u2022 begin declare target directive, see Section 7.8.2 \n \u2022 declare target directive, see Section 7.8.1 \nCHAPTER 7.VARIANT DIRECTIVES 209 \n"}
{"section_title": "8 Informational and Utility Directives", "chunk": "2 An informational directive conveys information about code properties to the compiler while a \n utility directive facilitates interactions with the compiler or supports code readability.A utility \n directive is informational unless the at clause implies it to be executable.\n"}
{"section_title": "8.1 at Clause", "chunk": "6 Name: at Properties: unique \n Arguments \nName Type Properties \naction-time Keyword: compilation, \nexecution \n default \n Directives \n error \n Semantics \n The at clause determines when the implementation performs an action that is associated with a \n utility directive.If action-time is compilation, the action is performed during compilation if the \n directive appears in a declarative context or in an executable context that is reachable at runtime.If \n action-time is compilation and the directive appears in an executable context that is not \n reachable at runtime, the action may or may not be performed.If action-time is execution, the \n action is performed during program execution when a thread encounters the directive and the \n directive is considered to be an executable directive.If the at clause is not specified, the effect is as \n if action-time is compilation.\n Cross References \n \u2022 error directive, see Section 8.5 \n"}
{"section_title": "8.2 requires Directive", "chunk": "Name: requires Association: none \nCategory: informational Properties: default 23 \n \n Clause groups \n requirement \n Semantics \n The requires directive specifies features that an implementation must support for correct \n execution and requirements for the execution of all code in the current compilation unit.The \n behavior that a requirement clause specifies may override the normal behavior specified elsewhere \n in this document.Whether an implementation supports the feature that a given requirement clause \n specifies is implementation defined.\n The clauses of a requires directive are added to the requires trait in the OpenMP context for all \n program points that follow the directive.\n Restrictions \n The restrictions to the requires directive are as follows: \n \u2022 All requires directives in the same compilation unit that specify the \n atomic_default_mem_order requirement must specify the same argument."}
{"section_title": "8.2 requires Directive", "chunk": "\n Restrictions \n The restrictions to the requires directive are as follows: \n \u2022 All requires directives in the same compilation unit that specify the \n atomic_default_mem_order requirement must specify the same argument.\n \u2022 Any requires directive that specifies a reverse_offload, unified_address, or \n unified_shared_memory requirement must appear lexically before any device constructs \n or device routines.\n \u2022 A requires directive may not appear lexically after a context selector in which any clause of \n the requires directive is used.\n \u2022 Either all compilation units of a program that contain declare target directives, device constructs \n or device routines or none of them must specify a requires directive that specifies the \n reverse_offload, unified_address or unified_shared_memory requirement."}
{"section_title": "8.2 requires Directive", "chunk": "\n \u2022 Either all compilation units of a program that contain declare target directives, device constructs \n or device routines or none of them must specify a requires directive that specifies the \n reverse_offload, unified_address or unified_shared_memory requirement.\n \u2022 A requires directive that specifies the atomic_default_mem_order requirement must \n not appear lexically after any atomic construct on which memory-order-clause is not specified.\nC \n \u2022 The requires directive may only appear at file scope.\nC \nC++ \n \u2022 The requires directive may only appear at file or namespace scope.\nC++ \nFortran \n \u2022 The requires directive must appear in the specification part of a program unit, after any USE \n statement, any IMPORT statement, and any IMPLICIT statement, unless the directive appears \n by referencing a module and each clause already appeared with the same arguments in the \n specification part of the program unit.\nFortran \nCHAPTER 8."}
{"section_title": "8.2 requires Directive", "chunk": "\nFortran \nCHAPTER 8.INFORMATIONAL AND UTILITY DIRECTIVES 211 \n"}
{"section_title": "8.2.1 requirement Clauses", "chunk": "2 Clause groups \nProperties: unique Members: atomic_default_mem_order, \ndynamic_allocators, \nreverse_offload, unified_address, \nunified_shared_memory \n \n Directives \n requires \n Semantics \n The requirement clause grouping defines a set of clauses that indicate the requirement that a \n program requires the implementation to support.Other than atomic_default_mem_order, \n the members of the set are inarguable.\n If an implementation supports a given requirement clause then the use of that clause on a \n requires directive will cause the implementation to ensure the enforcement of a guarantee \n represented by the specific member of the clause grouping.If the implementation does not support \n the requirement then it must perform compile-time error termination."}
{"section_title": "8.2.1 requirement Clauses", "chunk": "If the implementation does not support \n the requirement then it must perform compile-time error termination.\n The reverse_offload clause requires an implementation to guarantee that if a target \n construct specifies a device clause in which the ancestor modifier appears, the target \n region can execute on the parent device of an enclosing target region.\n The unified_address clause requires an implementation to guarantees that all devices \n accessible through OpenMP API routines and directives use a unified address space.In this address \n space, a pointer will always refer to the same location in memory from all devices accessible \n through OpenMP.Any OpenMP mechanism that returns a device pointer is guaranteed to return a \n device address that supports pointer arithmetic, and the is_device_ptr clause is not necessary \n to obtain device addresses from device pointers for use inside target regions."}
{"section_title": "8.2.1 requirement Clauses", "chunk": "Any OpenMP mechanism that returns a device pointer is guaranteed to return a \n device address that supports pointer arithmetic, and the is_device_ptr clause is not necessary \n to obtain device addresses from device pointers for use inside target regions.Host pointers may \n be passed as device pointer arguments to device memory routines and device pointers may be \n passed as host pointer arguments to device memory routines.Non-host devices may still have \n discrete memories and dereferencing a device pointer on the host device or a host pointer on a \n non-host device remains unspecified behavior.Memory local to a specific execution context may be \n exempt from the unified_address requirement, following the restrictions of locality to a given \n execution context, thread or contention group.\n The unified_shared_memory clause implies the unified_address requirement, \n inheriting all of its behaviors."}
{"section_title": "8.2.1 requirement Clauses", "chunk": "\n The unified_shared_memory clause implies the unified_address requirement, \n inheriting all of its behaviors.The implementation must also guarantee that storage locations in \n memory are accessible to threads on all available devices that the implementation supports, except \n for memory that is local to a specific execution context as defined in the description of \n unified_address above.Every device address that refers to storage allocated through \n OpenMP device memory routines is a valid host pointer that may be dereferenced.\n The unified_shared_memory clause makes map clauses optional on target constructs and \n declare target directives optional for variables with static storage duration that are accessed inside \n OpenMP API \u2013 Version 5.2 November 2021 \n functions to which a declare target directive is applied.Scalar variables are still firstprivate by \n default when referenced inside target constructs."}
{"section_title": "8.2.1 requirement Clauses", "chunk": "Scalar variables are still firstprivate by \n default when referenced inside target constructs.Values stored into memory by one device may \n not be visible to another device until those two devices synchronize with each other or both devices \n synchronize with the host.\n The dynamic_allocators clause removes certain restrictions on the use of memory allocators \n in target regions.Specifically, allocators may be used in a target region without specifying \n the uses_allocators clause on the corresponding target construct.The implementation \n must support calls to the omp_init_allocator and omp_destroy_allocator API \n routines in target regions.Finally, default allocators may be used on allocate directives and \n allocate clauses, and in omp_alloc API routines in target regions.\n The atomic_default_mem_order clause specifies the default memory ordering behavior for \n atomic constructs that an implementation must provide."}
{"section_title": "8.2.1 requirement Clauses", "chunk": "\n The atomic_default_mem_order clause specifies the default memory ordering behavior for \n atomic constructs that an implementation must provide.The effect is as if its argument appears as \n a clause on any atomic construct that does not specify a memory order clause.\n Cross References \n \u2022 requires directive, see Section 8.2 \n"}
{"section_title": "8.3 Assumption Directives", "chunk": "17 Assumption directives provide invariants that specify additional information about the expected \n properties of the program that can optionally be used for optimization.An implementation may \n ignore this information without altering the behavior of the program.Different assumption \n directive formats facilitate definition of assumptions for a scope that is appropriate to each base \n language.The scope of a particular format is its assumption scope and is defined in the section that \n defines that format.If the invariants do not hold at runtime, the behavior is unspecified.\n"}
{"section_title": "8.3.1 assumption Clauses", "chunk": "24 Clause groups \nProperties: Members: absent, contains, holds, \nno_openmp, no_openmp_routines, \nno_parallelism \n \n Directives \n assume, assumes, begin assumes \n Semantics \n The assumption clause grouping defines a set of clauses that indicate the assumptions that a \n program ensures the implementation can exploit.Other than absent, contains and holds, \n the members of the set are inarguable and unique.\nCHAPTER 8.INFORMATIONAL AND UTILITY DIRECTIVES 213 \n The no_openmp clause guarantees that no OpenMP related code is executed in the assumption \n scope.The no_openmp_routines clause guarantees that no explicit OpenMP runtime library \n calls are executed in the assumption scope.The no_parallelism clause guarantees that no \n OpenMP tasks (explicit or implicit) will be generated and that no SIMD constructs will be executed \n in the assumption scope."}
{"section_title": "8.3.1 assumption Clauses", "chunk": "The no_parallelism clause guarantees that no \n OpenMP tasks (explicit or implicit) will be generated and that no SIMD constructs will be executed \n in the assumption scope.\nC++ \n The no_openmp clause also guarantees that no thread will throw an exception in the assumption \n scope if it is contained in a region that arises from an exception-aborting directive.\nC++ \n The absent and contains clauses accept a directive-name list that may match a construct that \n is encountered within the assumption scope.An encountered construct matches the directive name \n if it or (if it is a combined or composite construct) one of its leaf constructs has the same \n directive-name as one of the members of the list.The absent clause specifies that the program \n guarantees that no constructs that match a listed directive name are encountered in the assumption \n scope."}
{"section_title": "8.3.1 assumption Clauses", "chunk": "The absent clause specifies that the program \n guarantees that no constructs that match a listed directive name are encountered in the assumption \n scope.The contains clause specifies that constructs that match the listed directive names are \n likely to be encountered in the assumption scope.\n When the holds clause appears on an assumption directive, the program guarantees that the listed \n expression evaluates to true in the assumption scope.The effect of the clause does not include an \n observable evaluation of the expression.\n Restrictions \n The restrictions to assumption clauses are as follows: \n \u2022 A directive-name list member must not specify a combined or composite directive.\n \u2022 A directive-name list member must not specify a directive that is a declarative directive, an \n informational directive other than the error directive, or a metadirective."}
{"section_title": "8.3.1 assumption Clauses", "chunk": "\n \u2022 A directive-name list member must not specify a directive that is a declarative directive, an \n informational directive other than the error directive, or a metadirective.\n Cross References \n \u2022 assume directive, see Section 8.3.3 \n \u2022 assumes directive, see Section 8.3.2 \n \u2022 begin assumes directive, see Section 8.3.4 \n"}
{"section_title": "8.3.2 assumes Directive", "chunk": "Name: assumes Association: none \nCategory: informational Properties: pure \n \n Clause groups \n assumption \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The assumption scope of the assumes directive is the code executed and reached from the current \n compilation unit.\n Restrictions \n The restrictions to the assumes directive are as follows: \nC \n \u2022 The assumes directive may only appear at file scope.\nC \nC++ \n \u2022 The assumes directive may only appear at file or namespace scope.\nC++ \nFortran \n \u2022 The assumes directive may only appear in the specification part of a module or subprogram, \n after any USE statement, any IMPORT statement, and any IMPLICIT statement.\nFortran \n"}
{"section_title": "8.3.3 assume Directive", "chunk": "Name: assume Association: block \nCategory: informational Properties: pure \n \n Clause groups \n assumption \n Semantics \n The assumption scope of the assume directive is the code executed in the corresponding region or \n in any region that is nested in the corresponding region.\nC / C++ \n"}
{"section_title": "8.3.4 begin assumes Directive", "chunk": "Name: begin assumes Association: delimited (declaration\ufffedefinition-seq) \nCategory: informational Properties: default \n \n Clause groups \n assumption \nCHAPTER 8.INFORMATIONAL AND UTILITY DIRECTIVES 215 \n Semantics \n The assumption scope of the begin assumes directive is the code that is executed and reached \n from any of the declared functions in the delimited code region.\nC / C++ \n"}
{"section_title": "8.4 nothing Directive", "chunk": "Name: nothing Association: none \nCategory: utility Properties: pure \n \n Semantics \n The nothing directive has no effect on the execution of the OpenMP program.\n Cross References \n \u2022 Metadirectives, see Section 7.4 \n"}
{"section_title": "8.5 error Directive", "chunk": "Name: error Association: none \nCategory: utility Properties: pure \n \n Clauses \n at, message, severity \n Semantics \n The error directive instructs the compiler or runtime to perform an error action.The error action \n displays an implementation-defined message.The severity clause determines whether the error \n action is abortive following the display of the message.If sev-level is fatal and action-time is \n compilation, the message is displayed and compilation of the current compilation unit is \n aborted.If sev-level is fatal and action-time is execution, the message is displayed and \n program execution is aborted.\n Execution Model Events \n The runtime-error event occurs when a thread encounters an error directive for which the at \n clause specifies execution.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_error callback for each occurrence of a \n runtime-error event in the context of the encountering task."}
{"section_title": "8.5 error Directive", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_error callback for each occurrence of a \n runtime-error event in the context of the encountering task.This callback has the type signature \n ompt_callback_error_t.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the error directive are as follows: \n \u2022 The directive is pure only if action-time is compilation.\n Cross References \n \u2022 ompt_callback_error_t, see Section 19.5.2.30 \n \u2022 at clause, see Section 8.1 \n \u2022 message clause, see Section 8.5.2 \n \u2022 severity clause, see Section 8.5.1 \n"}
{"section_title": "8.5.1 severity Clause", "chunk": "10 Name: severity Properties: unique \n Arguments \nName Type Properties \nsev-level Keyword: fatal, warning default 12 \n Directives \n error \n Semantics \n The severity clause determines the action that the implementation performs.If sev-level is \n warning, the implementation takes no action besides displaying the message that is associated \n with the directive.if sev-level is fatal, the implementation performs the abortive action \n associated with the directive on which the clause appears.If no severity clause is specified then \n the effect is as if sev-level is fatal.\n Cross References \n \u2022 error directive, see Section 8.5 \n"}
{"section_title": "8.5.2 message Clause", "chunk": "24 Name: message Properties: unique \n Arguments \nName Type Properties \nmsg-string expression of string type default 26 \n Directives \n error \nCHAPTER 8.INFORMATIONAL AND UTILITY DIRECTIVES 217 \n Semantics \n The message clause specifies that msg-string is included in the implementation-defined message \n that is associated with the directive on which the clause appears.\n Restrictions \nC / C++ \n \u2022 If the action-time is compilation, msg-string must be a constant string literal.\nC / C++ \nFortran \n \u2022 If the action-time is compilation, msg-string must be a constant character expression.\nFortran \n Cross References \n \u2022 error directive, see Section 8.5 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "9 Loop Transformation Constructs", "chunk": "2 A loop transformation construct replaces itself, including its associated loop nest, with a structured \n block that may be another loop nest.If the loop transformation construct is nested inside another \n loop nest, its replacement becomes part of that loop nest and therefore its generated loops may \n become associated with another loop-associated directive that forms an enclosing construct.A loop \n transformation construct that is closely nested within another loop transformation construct applies \n before the enclosing loop transformation construct.\n The associated loop nest of a loop transformation construct must have canonical loop nest form (see \n Section 4.4.1).All generated loops have canonical loop nest form, unless otherwise specified.Loop \n iteration variables of generated loops are always private in the enclosing parallelism-generating \n construct.\n Cross References \n \u2022 Canonical Loop Nest Form, see Section 4.4.1 \n"}
{"section_title": "9.1 tile Construct", "chunk": "Name: tile Association: loop \nCategory: executable Properties: pure \n \n Clauses \n sizes \n Semantics \n The tile construct tiles the outer n loops of the associated loop nest, where n is the number of \n items in the sizes clause, which consists of items s1, ..., sn.Let `1, ..., `n be the associated \n loops, from outermost to innermost, which the construct replaces with a loop nest that consists of \n 2n perfectly nested loops.Let f1, ..., fn, t1, ..., tn be the generated loops, from outermost to \n innermost.The loops f1, ..., fn are the floor loops and the loops t1, ..., tn are the tile loops.The \n tile loops do not have canonical loop nest form.\nLet \u2126 be the logical iteration vector space of the associated loops.For any (\u03b11, ..., \u03b1n) \u2208 N \nn 25 , \n define the set of iterations {(i1, ..., in) \u2208 \u2126 | \u2200k \u2208 {1, ..., n} : sk\u03b1k \u2264 ik < sk\u03b1k + sk} to be \ntile T\u03b11,...,\u03b1n \nand F = {T\u03b11,...,\u03b1n \n| T\u03b11,...,\u03b1n 27 6= \u2205} to be the set of tiles with at least one iteration."}
{"section_title": "9.1 tile Construct", "chunk": ", n} : sk\u03b1k \u2264 ik < sk\u03b1k + sk} to be \ntile T\u03b11,...,\u03b1n \nand F = {T\u03b11,...,\u03b1n \n| T\u03b11,...,\u03b1n 27 6= \u2205} to be the set of tiles with at least one iteration.\nTiles that contain Qn \nk=1 28 sk iterations are complete tiles.Otherwise, they are partial tiles.\n \n The floor loops iterate over all tiles {T\u03b11,...,\u03b1n \u2208 F} in lexicographic order with respect to their \nindices (\u03b11, ..., \u03b1n) and the tile loops iterate over the iterations in T\u03b11,...,\u03b1n 2 in the lexicographic \n order of the corresponding iteration vectors.An implementation may reorder the sequential \n execution of two iterations if at least one is from a partial tile and if their respective logical iteration \n vectors in loop-nest do not have a product order relation.\n Restrictions \n Restrictions to the tile construct are as follows: \n \u2022 The depth of the associated loop nest must be greater than or equal to n.\n \u2022 All loops that are associated with the construct must be perfectly nested."}
{"section_title": "9.1 tile Construct", "chunk": "\n \u2022 All loops that are associated with the construct must be perfectly nested.\n \u2022 No loop that is associated with the construct may be a non-rectangular loop.\n Cross References \n \u2022 sizes clause, see Section 9.1.1 \n"}
{"section_title": "9.1.1 sizes Clause", "chunk": "14 Name: sizes Properties: unique, required \n Arguments \nName Type Properties \nsize-list list of expression of integer type constant, positive 16 \n Directives \n tile \n Semantics \n The sizes clause specifies a list of n compile-time constant, positive OpenMP integer expressions.\n Cross References \n \u2022 tile directive, see Section 9.1 \n"}
{"section_title": "9.2 unroll Construct", "chunk": "Name: unroll Association: loop \nCategory: executable Properties: pure \n \n Clauses \n full, partial \n Clause set \n Properties: exclusive Members: full, partial \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The unroll construct unrolls the outermost loop of the loop nest according to its specified clause.\n If no clauses are specified, if and how the loop is unrolled is implementation defined.The unroll \n construct results in a generated loop that has canonical loop nest form if and only if the partial \n clause is specified.\n Cross References \n \u2022 full clause, see Section 9.2.1 \n \u2022 partial clause, see Section 9.2.2 \n"}
{"section_title": "9.2.1 full Clause", "chunk": "10 Name: full Properties: unique \n Directives \n unroll \n Semantics \n The full clause specifies that the associated loop is fully unrolled.The construct is replaced by a \n structured block that only contains n instances of its loop body, one for each of the n logical \n iterations of the associated loop and in their logical iteration order.\n Restrictions \n Restrictions to the full clause are as follows: \n \u2022 The iteration count of the associated loop must be a compile-time constant.\n Cross References \n \u2022 unroll directive, see Section 9.2 \n"}
{"section_title": "9.2.2 partial Clause", "chunk": "23 Name: partial Properties: unique \n Arguments \nName Type Properties \nunroll-factor expression of integer type optional, constant, posi\ufffetive \n \n Directives \n unroll \nCHAPTER 9.LOOP TRANSFORMATION CONSTRUCTS 221 \n Semantics \n The partial clause specifies that the associated loop is first tiled with a tile size of unroll-factor.\n Then, the generated tile loop is fully unrolled.If the partial clause is used without an \n unroll-factor argument then the unroll factor is a positive integer that is implementation defined.\n Cross References \n \u2022 unroll directive, see Section 9.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "10 Parallelism Generation and Control", "chunk": "2 This chapter defines constructs for generating and controlling parallelism.\n"}
{"section_title": "10.1 parallel Construct", "chunk": "Name: parallel Association: block \nCategory: executable Properties: parallelism-generating, can\ufffecellable, thread-limiting, context-matching \n \n Clauses \n allocate, copyin, default, firstprivate, if, num_threads, private, \n proc_bind, reduction, shared \n Binding \n The binding thread set for a parallel region is the encountering thread.The encountering thread \n becomes the primary thread of the new team.\n Semantics \n When a thread encounters a parallel construct, a team of threads is created to execute the \n parallel region (see Section 10.1.1 for more information about how the number of threads in \n the team is determined, including the evaluation of the if and num_threads clauses).The \n thread that encountered the parallel construct becomes the primary thread of the new team, \n with a thread number of zero for the duration of the new parallel region.All threads in the new \n team, including the primary thread, execute the region."}
{"section_title": "10.1 parallel Construct", "chunk": "All threads in the new \n team, including the primary thread, execute the region.Once the team is created, the number of \n threads in the team remains constant for the duration of that parallel region.\n Within a parallel region, thread numbers uniquely identify each thread.Thread numbers are \n consecutive whole numbers ranging from zero for the primary thread up to one less than the \n number of threads in the team.A thread may obtain its own thread number by a call to the \n omp_get_thread_num library routine.\n A set of implicit tasks, equal in number to the number of threads in the team, is generated by the \n encountering thread.The structured block of the parallel construct determines the code that \n will be executed in each implicit task.Each task is assigned to a different thread in the team and \n becomes tied.The task region of the task that the encountering thread is executing is suspended and \n each thread in the team executes its implicit task."}
{"section_title": "10.1 parallel Construct", "chunk": "The task region of the task that the encountering thread is executing is suspended and \n each thread in the team executes its implicit task.Each thread can execute a path of statements that \n is different from that of the other threads.\n \n The implementation may cause any thread to suspend execution of its implicit task at a task \n scheduling point, and to switch to execution of any explicit task generated by any of the threads in \n the team, before eventually resuming execution of the implicit task (for more details see \n Chapter 12).\n An implicit barrier occurs at the end of a parallel region.After the end of a parallel region, \n only the primary thread of the team resumes execution of the enclosing task region.\n If a thread in a team that is executing a parallel region encounters another parallel \n directive, it creates a new team, according to the rules in Section 10.1.1, and it becomes the primary \n thread of that new team."}
{"section_title": "10.1 parallel Construct", "chunk": "\n If a thread in a team that is executing a parallel region encounters another parallel \n directive, it creates a new team, according to the rules in Section 10.1.1, and it becomes the primary \n thread of that new team.\n If execution of a thread terminates while inside a parallel region, execution of all threads in all \n teams terminates.The order of termination of threads is unspecified.All work done by a team prior \n to any barrier that the team has passed in the program is guaranteed to be complete.The amount of \n work done by each thread after the last barrier that it passed and before it terminates is unspecified.\n Execution Model Events \n The parallel-begin event occurs in a thread that encounters a parallel construct before any \n implicit task is created for the corresponding parallel region."}
{"section_title": "10.1 parallel Construct", "chunk": "\n Execution Model Events \n The parallel-begin event occurs in a thread that encounters a parallel construct before any \n implicit task is created for the corresponding parallel region.\n Upon creation of each implicit task, an implicit-task-begin event occurs in the thread that executes \n the implicit task after the implicit task is fully initialized but before the thread begins to execute the \n structured block of the parallel construct.\n If the parallel region creates a native thread, a native-thread-begin event occurs as the first \n event in the context of the new thread prior to the implicit-task-begin event.\n Events associated with implicit barriers occur at the end of a parallel region.Section 15.3.2 \n describes events associated with implicit barriers.\n When a thread finishes an implicit task, an implicit-task-end event occurs in the thread after events \n associated with implicit barrier synchronization in the implicit task."}
{"section_title": "10.1 parallel Construct", "chunk": "\n When a thread finishes an implicit task, an implicit-task-end event occurs in the thread after events \n associated with implicit barrier synchronization in the implicit task.\n The parallel-end event occurs in the thread that encounters the parallel construct after the \n thread executes its implicit-task-end event but before the thread resumes execution of the \n encountering task.\n If a native thread is destroyed at the end of a parallel region, a native-thread-end event occurs \n in the thread as the last event prior to destruction of the thread.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_parallel_begin callback for each \n occurrence of a parallel-begin event in that thread.The callback occurs in the task that encounters \n the parallel construct.This callback has the type signature \n ompt_callback_parallel_begin_t.In the dispatched callback, \n (flags & ompt_parallel_team) evaluates to true."}
{"section_title": "10.1 parallel Construct", "chunk": "In the dispatched callback, \n (flags & ompt_parallel_team) evaluates to true.\n OpenMP API \u2013 Version 5.2 November 2021 \n A thread dispatches a registered ompt_callback_implicit_task callback with \n ompt_scope_begin as its endpoint argument for each occurrence of an implicit-task-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_implicit_task callback with ompt_scope_end as its endpoint \n argument for each occurrence of an implicit-task-end event in that thread.The callbacks occur in \n the context of the implicit task and have type signature ompt_callback_implicit_task_t.\n In the dispatched callback, (flags & ompt_task_implicit) evaluates to true.\n A thread dispatches a registered ompt_callback_parallel_end callback for each \n occurrence of a parallel-end event in that thread.The callback occurs in the task that encounters \n the parallel construct.This callback has the type signature \n ompt_callback_parallel_end_t."}
{"section_title": "10.1 parallel Construct", "chunk": "This callback has the type signature \n ompt_callback_parallel_end_t.\n A thread dispatches a registered ompt_callback_thread_begin callback for the \n native-thread-begin event in that thread.The callback occurs in the context of the thread.The \n callback has type signature ompt_callback_thread_begin_t.\n A thread dispatches a registered ompt_callback_thread_end callback for the \n native-thread-end event in that thread.The callback occurs in the context of the thread.The \n callback has type signature ompt_callback_thread_end_t."}
{"section_title": "10.1 parallel Construct", "chunk": "The \n callback has type signature ompt_callback_thread_end_t.\n Cross References \n \u2022 Determining the Number of Threads for a parallel Region, see Section 10.1.1 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 ompt_callback_implicit_task_t, see Section 19.5.2.11 \n \u2022 ompt_callback_parallel_begin_t, see Section 19.5.2.3 \n \u2022 ompt_callback_parallel_end_t, see Section 19.5.2.4 \n \u2022 ompt_callback_thread_begin_t, see Section 19.5.2.1 \n \u2022 ompt_callback_thread_end_t, see Section 19.5.2.2 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 allocate clause, see Section 6.6 \n \u2022 copyin clause, see Section 5.7.1 \n \u2022 default clause, see Section 5.4.1 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 if clause, see Section 3.4 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 private clause, see Section 5.4.3 \n \u2022 proc_bind clause, see Section 10.1.4 \nCHAPTER 10."}
{"section_title": "10.1 parallel Construct", "chunk": "\n Cross References \n \u2022 Determining the Number of Threads for a parallel Region, see Section 10.1.1 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 ompt_callback_implicit_task_t, see Section 19.5.2.11 \n \u2022 ompt_callback_parallel_begin_t, see Section 19.5.2.3 \n \u2022 ompt_callback_parallel_end_t, see Section 19.5.2.4 \n \u2022 ompt_callback_thread_begin_t, see Section 19.5.2.1 \n \u2022 ompt_callback_thread_end_t, see Section 19.5.2.2 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 allocate clause, see Section 6.6 \n \u2022 copyin clause, see Section 5.7.1 \n \u2022 default clause, see Section 5.4.1 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 if clause, see Section 3.4 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 private clause, see Section 5.4.3 \n \u2022 proc_bind clause, see Section 10.1.4 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 225 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 shared clause, see Section 5.4.2 \n"}
{"section_title": "10.1.1 Determining the Number of Threads for a parallel Region", "chunk": "4 Region \n When execution encounters a parallel directive, the value of the if clause or num_threads \n clause (if any) on the directive, the current parallel context, and the values of the nthreads-var, \n dyn-var, thread-limit-var, and max-active-levels-var ICVs are used to determine the number of \n threads to use in the region.\n Using a variable in an if or num_threads clause expression of a parallel construct causes \n an implicit reference to the variable in all enclosing constructs.The if clause expression and the \n num_threads clause expression are evaluated in the context outside of the parallel construct, \n and no ordering of those evaluations is specified.In what order or how many times any side effects \n of the evaluation of the num_threads or if clause expressions occur is also unspecified.\n When a thread encounters a parallel construct, the number of threads is determined according \n to Algorithm 2.1."}
{"section_title": "10.1.1 Determining the Number of Threads for a parallel Region", "chunk": "\n When a thread encounters a parallel construct, the number of threads is determined according \n to Algorithm 2.1.\n \n Algorithm 2.1 18 \n let ThreadsBusy be the number of OpenMP threads currently executing in this contention group; \n if an if clause exists \n then let IfClauseValue be the value of the if clause expression; \n else let IfClauseValue = true; \n if a num_threads clause exists \n then let ThreadsRequested be the value of the num_threads clause expression; \n else let ThreadsRequested = value of the first element of nthreads-var; \n let ThreadsAvailable = (thread-limit-var - ThreadsBusy + 1); \n if (IfClauseValue = false) \n then number of threads = 1; \n else if (active-levels-var \u2265 max-active-levels-var) \n then number of threads = 1; \n else if (dyn-var = true) and (ThreadsRequested \u2264 ThreadsAvailable) \n then 1 \u2264 number of threads \u2264 ThreadsRequested; \n OpenMP API \u2013 Version 5.2 November 2021 \n else if (dyn-var = true) and (ThreadsRequested > ThreadsAvailable) \n then 1 \u2264 number of threads \u2264 ThreadsAvailable; \n else if (dyn-var = false) and (ThreadsRequested \u2264 ThreadsAvailable) \n then number of threads = ThreadsRequested; \n else if (dyn-var = false) and (ThreadsRequested > ThreadsAvailable) \n then behavior is implementation defined; \n \n Cross References \n \u2022 dyn-var ICV, see Table 2.1 \n \u2022 if clause, see Section 3.4 \n \u2022 max-active-levels-var ICV, see Table 2.1 \n \u2022 nthreads-var ICV, see Table 2.1 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 parallel directive, see Section 10.1 \n \u2022 thread-limit-var ICV, see Table 2.1 \n"}
{"section_title": "10.1.2 num_threads Clause", "chunk": "17 Name: num_threads Properties: unique \n Arguments \nName Type Properties \nnthreads expression of integer type positive 19 \n Directives \n parallel \n Semantics \n The num_threads clause specifies the desired number of threads to execute a parallel region.\n Cross References \n \u2022 parallel directive, see Section 10.1 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 227 \n"}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "2 When a thread encounters a parallel directive without a proc_bind clause, the bind-var ICV \n is used to determine the policy for assigning OpenMP threads to places within the current place \n partition, that is, within the places listed in the place-partition-var ICV for the implicit task of the \n encountering thread.If the parallel directive has a proc_bind clause then the binding policy \n specified by the proc_bind clause overrides the policy specified by the first element of the \n bind-var ICV.Once a thread in the team is assigned to a place, the OpenMP implementation should \n not move it to another place.\n The primary thread affinity policy instructs the execution environment to assign every thread in \n the team to the same place as the primary thread.The place partition is not changed by this policy, \n and each implicit task inherits the place-partition-var ICV of the parent implicit task."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "The place partition is not changed by this policy, \n and each implicit task inherits the place-partition-var ICV of the parent implicit task.The master \n thread-affinity policy, which has been deprecated, has identical semantics to the primary thread \n affinity policy.\n The close thread affinity policy instructs the execution environment to assign the threads in the \n team to places close to the place of the parent thread.The place partition is not changed by this \n policy, and each implicit task inherits the place-partition-var ICV of the parent implicit task.If T \n is the number of threads in the team, and P is the number of places in the parent\u2019s place partition, \n then the assignment of threads in the team to places is as follows: \n \u2022 T \u2264 P: The primary thread executes on the place of the parent thread."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "If T \n is the number of threads in the team, and P is the number of places in the parent\u2019s place partition, \n then the assignment of threads in the team to places is as follows: \n \u2022 T \u2264 P: The primary thread executes on the place of the parent thread.The thread with the next \n smallest thread number executes on the next place in the place partition, and so on, with wrap \n around with respect to the place partition of the primary thread.\n \u2022 T > P: Each place p will contain Sp threads with consecutive thread numbers where \n bT /Pc \u2264 Sp \u2264 dT /Pe.The first S0 threads (including the primary thread) are assigned to the \n place of the parent thread.The next S1 threads are assigned to the next place in the place \n partition, and so on, with wrap around with respect to the place partition of the primary thread.\n When P does not divide T evenly, the exact number of threads in a particular place is \n implementation defined."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "\n When P does not divide T evenly, the exact number of threads in a particular place is \n implementation defined.\n The purpose of the spread thread affinity policy is to create a sparse distribution for a team of T \n threads among the P places of the parent\u2019s place partition.A sparse distribution is achieved by first \n subdividing the parent partition into T subpartitions if T \u2264 P, or P subpartitions if T > P.Then \n one thread (T \u2264 P) or a set of threads (T > P) is assigned to each subpartition.The \n place-partition-var ICV of each implicit task is set to its subpartition.The subpartitioning is not \n only a mechanism for achieving a sparse distribution, it also defines a subset of places for a thread \n to use when creating a nested parallel region.The assignment of threads to places is as follows: \n \u2022 T \u2264 P: The parent thread\u2019s place partition is split into T subpartitions, where each subpartition \n contains bP/Tc or dP/Te consecutive places."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "The assignment of threads to places is as follows: \n \u2022 T \u2264 P: The parent thread\u2019s place partition is split into T subpartitions, where each subpartition \n contains bP/Tc or dP/Te consecutive places.A single thread is assigned to each subpartition.\n The primary thread executes on the place of the parent thread and is assigned to the subpartition \n that includes that place.The thread with the next smallest thread number is assigned to the first \n place in the next subpartition, and so on, with wrap around with respect to the original place \n partition of the primary thread.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 T > P: The parent thread\u2019s place partition is split into P subpartitions, each consisting of a \n single place.Each subpartition is assigned Sp threads with consecutive thread numbers, where \n bT /Pc \u2264 Sp \u2264 dT /Pe.The first S0 threads (including the primary thread) are assigned to the \n subpartition that contains the place of the parent thread."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "The first S0 threads (including the primary thread) are assigned to the \n subpartition that contains the place of the parent thread.The next S1 threads are assigned to the \n next subpartition, and so on, with wrap around with respect to the original place partition of the \n primary thread.When P does not divide T evenly, the exact number of threads in a particular \n subpartition is implementation defined.\n The determination of whether the affinity request can be fulfilled is implementation defined.If the \n affinity request cannot be fulfilled, then the affinity of threads in the team is implementation defined.\n \n Note \u2013 Wrap around is needed if the end of a place partition is reached before all thread \n assignments are done.For example, wrap around may be needed in the case of close and T \u2264 P, \n if the primary thread is assigned to a place other than the first place in the place partition."}
{"section_title": "10.1.3 Controlling OpenMP Thread Affinity", "chunk": "For example, wrap around may be needed in the case of close and T \u2264 P, \n if the primary thread is assigned to a place other than the first place in the place partition.In this \n case, thread 1 is assigned to the place after the place of the primary thread, thread 2 is assigned to \n the place after that, and so on.The end of the place partition may be reached before all threads are \n assigned.In this case, assignment of threads is resumed with the first place in the place partition.\n \n Cross References \n \u2022 bind-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 place-partition-var ICV, see Table 2.1 \n \u2022 proc_bind clause, see Section 10.1.4 \n"}
{"section_title": "10.1.4 proc_bind Clause", "chunk": "24 Name: proc_bind Properties: unique \n Arguments \nName Type Properties \naffinity-policy Keyword: close, master (depre\ufffecated), primary, spread \n default \n Directives \n parallel \n Semantics \n The proc_bind clause specifies the mapping of OpenMP threads to places within the current \n place partition, that is, within the places listed in the place-partition-var ICV for the implicit task of \n the encountering thread.The effect of the possible values for affinity-policy are described in \n Section 10.1.3 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 229 \n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "10.2 teams Construct", "chunk": "Name: teams Association: block \nCategory: executable Properties: parallelism-generating, thread\ufffelimiting, context-matching \n \n Clauses \n allocate, default, firstprivate, num_teams, private, reduction, shared, \n thread_limit \n Binding \n The binding thread set for a teams region is the encountering thread.\n Semantics \n When a thread encounters a teams construct, a league of teams is created.Each team is an initial \n team, and the initial thread in each team executes the teams region.The number of teams created \n is determined by evaluating the if and num_teams clauses.Once the teams are created, the \n number of initial teams remains constant for the duration of the teams region.Within a teams \n region, initial team numbers uniquely identify each initial team.Initial team numbers are \n consecutive whole numbers ranging from zero to one less than the number of initial teams."}
{"section_title": "10.2 teams Construct", "chunk": "Initial team numbers are \n consecutive whole numbers ranging from zero to one less than the number of initial teams.\n When an if clause is present on a teams construct and the if clause expression evaluates to \n false, the number of created teams is one.The use of a variable in an if clause expression of a \n teams construct causes an implicit reference to the variable in all enclosing constructs.The if \n clause expression is evaluated in the context outside of the teams construct.\n If a thread_limit clause is not present on the teams construct, but the construct is closely \n nested inside a target construct on which the thread_limit clause is specified, the behavior \n is as if that thread_limit clause is also specified for the teams construct.\n On a combined or composite construct that includes target and teams constructs, the \n expressions in num_teams and thread_limit clauses are evaluated on the host device on \n entry to the target construct."}
{"section_title": "10.2 teams Construct", "chunk": "\n On a combined or composite construct that includes target and teams constructs, the \n expressions in num_teams and thread_limit clauses are evaluated on the host device on \n entry to the target construct.\n The place list, given by the place-partition-var ICV of the encountering thread, is split into \n subpartitions in an implementation-defined manner, and each team is assigned to a subpartition by \n setting the place-partition-var of its initial thread to the subpartition.\n The teams construct sets the default-device-var ICV for each initial thread to an \n implementation-defined value.\n After the teams have completed execution of the teams region, the encountering task resumes \n execution of the enclosing task region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n The teams-begin event occurs in a thread that encounters a teams construct before any initial task \n is created for the corresponding teams region."}
{"section_title": "10.2 teams Construct", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n The teams-begin event occurs in a thread that encounters a teams construct before any initial task \n is created for the corresponding teams region.\n Upon creation of each initial task, an initial-task-begin event occurs in the thread that executes the \n initial task after the initial task is fully initialized but before the thread begins to execute the \n structured block of the teams construct.\n If the teams region creates a native thread, a native-thread-begin event occurs as the first event in \n the context of the new thread prior to the initial-task-begin event.\n When a thread finishes an initial task, an initial-task-end event occurs in the thread.\n The teams-end event occurs in the thread that encounters the teams construct after the thread \n executes its initial-task-end event but before it resumes execution of the encountering task."}
{"section_title": "10.2 teams Construct", "chunk": "\n The teams-end event occurs in the thread that encounters the teams construct after the thread \n executes its initial-task-end event but before it resumes execution of the encountering task.\n If a native thread is destroyed at the end of a teams region, a native-thread-end event occurs in the \n thread as the last event prior to destruction of the thread.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_parallel_begin callback for each \n occurrence of a teams-begin event in that thread.The callback occurs in the task that encounters the \n teams construct.This callback has the type signature \n ompt_callback_parallel_begin_t.In the dispatched callback, \n (flags & ompt_parallel_league) evaluates to true.\n A thread dispatches a registered ompt_callback_implicit_task callback with \n ompt_scope_begin as its endpoint argument for each occurrence of an initial-task-begin in \n that thread."}
{"section_title": "10.2 teams Construct", "chunk": "\n A thread dispatches a registered ompt_callback_implicit_task callback with \n ompt_scope_begin as its endpoint argument for each occurrence of an initial-task-begin in \n that thread.Similarly, a thread dispatches a registered ompt_callback_implicit_task \n callback with ompt_scope_end as its endpoint argument for each occurrence of an \n initial-task-end event in that thread.The callbacks occur in the context of the initial task and have \n type signature ompt_callback_implicit_task_t.In the dispatched callback, \n (flags & ompt_task_initial) evaluates to true.\n A thread dispatches a registered ompt_callback_parallel_end callback for each \n occurrence of a teams-end event in that thread.The callback occurs in the task that encounters the \n teams construct.This callback has the type signature ompt_callback_parallel_end_t.\n A thread dispatches a registered ompt_callback_thread_begin callback for the \n native-thread-begin event in that thread."}
{"section_title": "10.2 teams Construct", "chunk": "\n A thread dispatches a registered ompt_callback_thread_begin callback for the \n native-thread-begin event in that thread.The callback occurs in the context of the thread.The \n callback has type signature ompt_callback_thread_begin_t.\n A thread dispatches a registered ompt_callback_thread_end callback for the \n native-thread-end event in that thread.The callback occurs in the context of the thread.The \n callback has type signature ompt_callback_thread_end_t.\nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 231 \n Restrictions \n Restrictions to the teams construct are as follows: \n \u2022 If a reduction-modifier is specified in a reduction clause that appears on the directive then the \n reduction modifier must be default.\n \u2022 A teams region must be strictly nested within the implicit parallel region that surrounds the \n whole OpenMP program or a target region."}
{"section_title": "10.2 teams Construct", "chunk": "\n \u2022 A teams region must be strictly nested within the implicit parallel region that surrounds the \n whole OpenMP program or a target region.If a teams region is nested inside a target \n region, the corresponding target construct must not contain any statements, declarations or \n directives outside of the corresponding teams construct.\n \u2022 distribute regions, including any distribute regions arising from composite constructs, \n parallel regions, including any parallel regions arising from combined constructs, loop \n regions, omp_get_num_teams() regions, and omp_get_team_num() regions are the \n only OpenMP regions that may be strictly nested inside the teams region."}
{"section_title": "10.2 teams Construct", "chunk": "\n \u2022 distribute regions, including any distribute regions arising from composite constructs, \n parallel regions, including any parallel regions arising from combined constructs, loop \n regions, omp_get_num_teams() regions, and omp_get_team_num() regions are the \n only OpenMP regions that may be strictly nested inside the teams region.\n Cross References \n \u2022 omp_get_num_teams, see Section 18.4.1 \n \u2022 omp_get_team_num, see Section 18.4.2 \n \u2022 ompt_callback_implicit_task_t, see Section 19.5.2.11 \n \u2022 ompt_callback_parallel_begin_t, see Section 19.5.2.3 \n \u2022 ompt_callback_parallel_end_t, see Section 19.5.2.4 \n \u2022 ompt_callback_thread_begin_t, see Section 19.5.2.1 \n \u2022 ompt_callback_thread_end_t, see Section 19.5.2.2 \n \u2022 allocate clause, see Section 6.6 \n \u2022 default clause, see Section 5.4.1 \n \u2022 distribute directive, see Section 11.6 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 num_teams clause, see Section 10.2.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 shared clause, see Section 5.4.2 \n \u2022 target directive, see Section 13.8 \n \u2022 thread_limit clause, see Section 13.3 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "10.2.1 num_teams Clause", "chunk": "2 Name: num_teams Properties: unique \n Arguments \nName Type Properties \nupper-bound expression of integer type positive 4 \n Modifiers \nName Modifies Type Properties \nlower-bound Generic OpenMP integer expression positive, ultimate, \nunique \n \n Directives \n teams \n Semantics \n The num_teams clause specifies the bounds on the number of teams created by the construct on \n which it appears.lower-bound specifies the lower bound and upper-bound specifies the upper \n bound on the number of teams requested.If lower-bound is not specified, the effect is as if \n lower-bound is specified as equal to upper-bound.The number of teams created is implementation \n defined, but it will be greater than or equal to the lower bound and less than or equal to the upper \n bound.\n If the num_teams clause is not specified on a construct then the effect is as if upper-bound was \n specified as follows."}
{"section_title": "10.2.1 num_teams Clause", "chunk": "\n If the num_teams clause is not specified on a construct then the effect is as if upper-bound was \n specified as follows.If the value of the nteams-var ICV is greater than zero, the effect is as if \n upper-bound was specified to an implementation-defined value greater than zero but less than or \n equal to the value of the nteams-var ICV.Otherwise, the effect is as if upper-bound was specified as \n an implementation defined value greater than or equal to one.\n Restrictions \n \u2022 lower-bound must be less than or equal to upper-bound.\n Cross References \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "10.3 order Clause", "chunk": "26 Name: order Properties: unique \n Arguments \nName Type Properties \nordering Keyword: concurrent default 28 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 233 \n Modifiers \nName Modifies Type Properties \norder-modifier ordering Keyword: reproducible, \nunconstrained \n default \n Directives \n distribute, do, for, loop, simd \n Semantics \n The order clause specifies an ordering of execution for the iterations of the associated loops of a \n loop-associated directive.If ordering is concurrent, the logical iterations of the associated \n loops may execute in any order, including concurrently.\n The order-modifier on the order clause affects the schedule specification for the purpose of \n determining its consistency with other schedules (see Section 4.4.5).If order-modifier is \n reproducible, the loop schedule for the construct on which the clause appears is reproducible, \n whereas if order-modifier is unconstrained, the loop schedule is not reproducible."}
{"section_title": "10.3 order Clause", "chunk": "If order-modifier is \n reproducible, the loop schedule for the construct on which the clause appears is reproducible, \n whereas if order-modifier is unconstrained, the loop schedule is not reproducible.\n Restrictions \n Restrictions to the order clause are as follows: \n \u2022 The only constructs that may be encountered inside a region that corresponds to a construct with \n an order clause that specifies concurrent are the loop construct, the parallel \n construct, the simd construct, and combined constructs for which the first construct is a \n parallel construct.\n \u2022 A region that corresponds to a construct with an order clause that specifies concurrent may \n not contain calls to procedures that contain OpenMP directives.\n \u2022 A region that corresponds to a construct with an order clause that specifies concurrent may \n not contain OpenMP runtime API calls."}
{"section_title": "10.3 order Clause", "chunk": "\n \u2022 A region that corresponds to a construct with an order clause that specifies concurrent may \n not contain OpenMP runtime API calls.\n \u2022 If a threadprivate variable is referenced inside a region that corresponds to a construct with an \n order clause that specifies concurrent, the behavior is unspecified.\n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 simd directive, see Section 10.4 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "10.4 simd Construct", "chunk": "Name: simd Association: loop \nCategory: executable Properties: parallelism-generating, context\ufffematching, simdizable, pure \n \n Separating directives \n scan \n Clauses \n aligned, collapse, if, lastprivate, linear, nontemporal, order, private, \n reduction, safelen, simdlen \n Binding \n A simd region binds to the current task region.The binding thread set of the simd region is the \n current team.\n Semantics \n The simd construct enables the execution of multiple iterations of the associated loops \n concurrently by using SIMD instructions.At the beginning of each logical iteration, the loop \n iteration variable or the variable declared by range-decl of each associated loop has the value that it \n would have if the set of the associated loops was executed sequentially.The number of iterations \n that are executed concurrently at any given time is implementation defined.Each concurrent \n iteration will be executed by a different SIMD lane."}
{"section_title": "10.4 simd Construct", "chunk": "Each concurrent \n iteration will be executed by a different SIMD lane.Each set of concurrent iterations is a SIMD \n chunk.Lexical forward dependences in the iterations of the original loop must be preserved within \n each SIMD chunk, unless an order clause that specifies concurrent is present.\n When an if clause is present and evaluates to false, the preferred number of iterations to be \n executed concurrently is one, regardless of whether a simdlen clause is specified.\n Restrictions \n Restrictions to the simd construct are as follows: \n \u2022 If both simdlen and safelen clauses are specified, the value of the simdlen length must \n be less than or equal to the value of the safelen length.\n \u2022 Only simdizable constructs can be encountered during execution of a simd region.\n \u2022 If an order clause that specifies concurrent appears on a simd directive, the safelen \n clause may not also appear."}
{"section_title": "10.4 simd Construct", "chunk": "\n \u2022 If an order clause that specifies concurrent appears on a simd directive, the safelen \n clause may not also appear.\nC / C++ \n \u2022 The simd region cannot contain calls to the longjmp or setjmp functions.\nC / C++ \nC++ \n \u2022 No exception can be raised in the simd region.\n \u2022 The only random access iterator types that are allowed for the associated loops are pointer types.\nC++ \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 235 \n Cross References \n \u2022 aligned clause, see Section 5.11 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 if clause, see Section 3.4 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 nontemporal clause, see Section 10.4.1 \n \u2022 order clause, see Section 10.3 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 safelen clause, see Section 10.4.2 \n \u2022 scan directive, see Section 5.6 \n \u2022 simdlen clause, see Section 10.4.3 \n"}
{"section_title": "10.4.1 nontemporal Clause", "chunk": "15 Name: nontemporal Properties: default \n Arguments \nName Type Properties \nlist list of variable list item type default 17 \n Directives \n simd \n Semantics \n The nontemporal clause specifies that accesses to the storage locations to which the list items \n refer have low temporal locality across the iterations in which those storage locations are accessed.\n The list items of the nontemporal clause may also appear as list items of data-environment \n attribute clauses.\n Cross References \n \u2022 simd directive, see Section 10.4 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "10.4.2 safelen Clause", "chunk": "2 Name: safelen Properties: unique \n Arguments \nName Type Properties \nlength expression of integer type positive, constant 4 \n Directives \n simd \n Semantics \n The safelen clause specifies that no two concurrent iterations within a SIMD chunk can have a \n distance in the logical iteration space that is greater than or equal to the value given in the clause.\n Cross References \n \u2022 simd directive, see Section 10.4 \n"}
{"section_title": "10.4.3 simdlen Clause", "chunk": "13 Name: simdlen Properties: unique \n Arguments \nName Type Properties \nlength expression of integer type positive, constant 15 \n Directives \n declare simd, simd \n Semantics \n When the simdlen clause appears on a simd construct, length is treated as a hint that specifies \n the preferred number of iterations to be executed concurrently.When the simdlen clause appears \n on a declare simd construct, if a SIMD version of the associated function is created, length \n corresponds to the number of concurrent arguments of the function.\n Cross References \n \u2022 declare simd directive, see Section 7.7 \n \u2022 simd directive, see Section 10.4 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 237 \n"}
{"section_title": "10.5 masked Construct", "chunk": "Name: masked Association: block \nCategory: executable Properties: thread-limiting 2 \n Clauses \n filter \n Additional information \n The directive-name master may be used as a synonym to masked if no clauses are specified.\n This syntax has been deprecated.\n Binding \n The binding thread set for a masked region is the current team.A masked region binds to the \n innermost enclosing parallel region.\n Semantics \n The masked construct specifies a structured block that is executed by a subset of the threads of the \n current team.The filter clause selects a subset of the threads of the team that executes the \n binding parallel region to execute the structured block of the masked region.Other threads in the \n team do not execute the associated structured block.No implied barrier occurs either on entry to or \n exit from the masked construct.The result of evaluating the thread_num parameter of the \n filter clause may vary across threads."}
{"section_title": "10.5 masked Construct", "chunk": "The result of evaluating the thread_num parameter of the \n filter clause may vary across threads.\n If more than one thread in the team executes the structured block of a masked region, the \n structured block must include any synchronization required to ensure that data races do not occur.\n Execution Model Events \n The masked-begin event occurs in any thread of a team that executes the masked region on entry \n to the region.\n The masked-end event occurs in any thread of a team that executes the masked region on exit from \n the region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_masked callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a masked-begin event in \n that thread.Similarly, a thread dispatches a registered ompt_callback_masked callback with \n ompt_scope_end as its endpoint argument for each occurrence of a masked-end event in that \n thread."}
{"section_title": "10.5 masked Construct", "chunk": "Similarly, a thread dispatches a registered ompt_callback_masked callback with \n ompt_scope_end as its endpoint argument for each occurrence of a masked-end event in that \n thread.These callbacks occur in the context of the task executed by the current thread and have the \n type signature ompt_callback_masked_t.\n Cross References \n \u2022 ompt_callback_masked_t, see Section 19.5.2.12 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 filter clause, see Section 10.5.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "10.5.1 filter Clause", "chunk": "2 Name: filter Properties: unique \n Arguments \nName Type Properties \nthread_num expression of integer type default 4 \n Directives \n masked \n Semantics \n If thread_num specifies the thread number of the current thread in the current team then the \n filter clause selects the current thread.If the filter clause is not specified, the effect is as if \n the clause is specified with thread_num equal to zero, so that the filter clause selects the \n primary thread.The use of a variable in a thread_num clause expression causes an implicit \n reference to the variable in all enclosing constructs.\n Cross References \n \u2022 masked directive, see Section 10.5 \nCHAPTER 10.PARALLELISM GENERATION AND CONTROL 239 \n"}
{"section_title": "11 Work-Distribution Constructs", "chunk": "2 A work-distribution construct distributes the execution of the corresponding region among the \n threads in its binding thread set.Threads execute portions of the region in the context of the \n implicit tasks that each one is executing.\n A work-distribution construct is worksharing if the binding thread set is a thread team.A \n worksharing region has no barrier on entry; however, an implied barrier exists at the end of the \n worksharing region, unless a nowait clause is specified.If a nowait clause is present, an \n implementation may omit the barrier at the end of the worksharing region.In this case, threads that \n finish early may proceed straight to the instructions that follow the worksharing region without \n waiting for the other members of the team to finish the worksharing region, and without performing \n a flush operation."}
{"section_title": "11 Work-Distribution Constructs", "chunk": "In this case, threads that \n finish early may proceed straight to the instructions that follow the worksharing region without \n waiting for the other members of the team to finish the worksharing region, and without performing \n a flush operation.\n Restrictions \n The following restrictions apply to work-distribution constructs: \n \u2022 Each work-distribution region must be encountered by all threads in the binding thread set or by \n none at all unless cancellation has been requested for the innermost enclosing parallel region.\n \u2022 The sequence of encountered work-distribution regions that have the same binding thread set \n must be the same for every thread in the binding thread set.\n \u2022 The sequence of encountered worksharing regions and barrier regions that bind to the same \n thread team must be the same for every thread in the team.\n"}
{"section_title": "11.1 single Construct", "chunk": "Name: single Association: block \nCategory: executable Properties: work-distribution, worksharing, \nthread-limiting \n \n Clauses \n allocate, copyprivate, firstprivate, nowait, private \n Binding \n The binding thread set for a single region is the current team.A single region binds to the \n innermost enclosing parallel region.Only the threads of the team that executes the binding \n parallel region participate in the execution of the structured block and the implied barrier of the \n single region if the barrier is not eliminated by a nowait clause.\n \n Semantics \n The single construct specifies that the associated structured block is executed by only one of the \n threads in the team (not necessarily the primary thread), in the context of its implicit task.The \n method of choosing a thread to execute the structured block each time the team encounters the \n construct is implementation defined."}
{"section_title": "11.1 single Construct", "chunk": "The \n method of choosing a thread to execute the structured block each time the team encounters the \n construct is implementation defined.An implicit barrier occurs at the end of a single region if \n the nowait clause is not specified.\n Execution Model Events \n The single-begin event occurs after an implicit task encounters a single construct but before the \n task starts to execute the structured block of the single region.\n The single-end event occurs after an implicit task finishes execution of a single region but before \n it resumes execution of the enclosing region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument for each occurrence of a single-begin event in that thread.Similarly, a \n thread dispatches a registered ompt_callback_work callback with ompt_scope_end as its \n endpoint argument for each occurrence of a single-end event in that thread."}
{"section_title": "11.1 single Construct", "chunk": "Similarly, a \n thread dispatches a registered ompt_callback_work callback with ompt_scope_end as its \n endpoint argument for each occurrence of a single-end event in that thread.For each of these \n callbacks, the wstype argument is ompt_work_single_executor if the thread executes the \n structured block associated with the single region; otherwise, the wstype argument is \n ompt_work_single_other.The callback has type signature ompt_callback_work_t.\n Restrictions \n Restrictions to the single construct are as follows: \n \u2022 The copyprivate clause must not be used with the nowait clause.\n Cross References \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 copyprivate clause, see Section 5.7.2 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 nowait clause, see Section 15.6 \n \u2022 private clause, see Section 5.4.3 \nCHAPTER 11."}
{"section_title": "11.1 single Construct", "chunk": "\n Cross References \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 copyprivate clause, see Section 5.7.2 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 nowait clause, see Section 15.6 \n \u2022 private clause, see Section 5.4.3 \nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 241 \n"}
{"section_title": "11.2 scope Construct", "chunk": "Name: scope Association: block \nCategory: executable Properties: work-distribution, worksharing, \nthread-limiting \n \n Clauses \n allocate, firstprivate, nowait, private, reduction \n Binding \n The binding thread set for a scope region is the current team.A scope region binds to the \n innermost enclosing parallel region.Only the threads of the team that executes the binding parallel \n region participate in the execution of the structured block and the implied barrier of the scope \n region if the barrier is not eliminated by a nowait clause.\n Semantics \n The scope construct specifies that all threads in a team execute the associated structured block and \n any additionally specified OpenMP operations.An implicit barrier occurs at the end of a scope \n region if the nowait clause is not specified."}
{"section_title": "11.2 scope Construct", "chunk": "An implicit barrier occurs at the end of a scope \n region if the nowait clause is not specified.\n Execution Model Events \n The scope-begin event occurs after an implicit task encounters a scope construct but before the \n task starts to execute the structured block of the scope region.\n The scope-end event occurs after an implicit task finishes execution of a scope region but before it \n resumes execution of the enclosing region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument and ompt_work_scope as its work_type argument for each occurrence \n of a scope-begin event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_work callback with ompt_scope_end as its endpoint argument and \n ompt_work_scope as its work_type argument for each occurrence of a scope-end event in that \n thread.The callbacks occur in the context of the implicit task."}
{"section_title": "11.2 scope Construct", "chunk": "The callbacks occur in the context of the implicit task.The callbacks have type signature \n ompt_callback_work_t.\n Cross References \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 nowait clause, see Section 15.6 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n"}
{"section_title": "11.3 sections Construct", "chunk": "Name: sections Association: block \nCategory: executable Properties: work-distribution, worksharing, \nthread-limiting, cancellable \n \n Separating directives \n section \n Clauses \n allocate, firstprivate, lastprivate, nowait, private, reduction \n Binding \n The binding thread set for a sections region is the current team.A sections region binds to \n the innermost enclosing parallel region.Only the threads of the team that executes the binding \n parallel region participate in the execution of the structured block sequences and the implied \n barrier of the sections region if the barrier is not eliminated by a nowait clause.\n Semantics \n The sections construct is a non-iterative worksharing construct that contains a structured block \n that consists of a set of structured block sequences that are to be distributed among and executed by \n the threads in a team."}
{"section_title": "11.3 sections Construct", "chunk": "\n Semantics \n The sections construct is a non-iterative worksharing construct that contains a structured block \n that consists of a set of structured block sequences that are to be distributed among and executed by \n the threads in a team.Each structured block sequence is executed by one of the threads in the team \n in the context of its implicit task.An implicit barrier occurs at the end of a sections region if \n the nowait clause is not specified.\n Each structured block sequence in the sections construct is preceded by a section directive \n except possibly the first sequence, for which a preceding section directive is optional.The \n method of scheduling the structured block sequences among the threads in the team is \n implementation defined.\n Execution Model Events \n The sections-begin event occurs after an implicit task encounters a sections construct but before \n the task executes any structured block sequences of the sections region."}
{"section_title": "11.3 sections Construct", "chunk": "\n Execution Model Events \n The sections-begin event occurs after an implicit task encounters a sections construct but before \n the task executes any structured block sequences of the sections region.\n The sections-end event occurs after an implicit task finishes execution of a sections region but \n before it resumes execution of the enclosing context.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument and ompt_work_sections as its work_type argument for each \n occurrence of a sections-begin event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_work callback with ompt_scope_end as its endpoint argument and \n ompt_work_sections as its work_type argument for each occurrence of a sections-end event \n in that thread.The callbacks occur in the context of the implicit task.The callbacks have type \n signature ompt_callback_work_t.\nCHAPTER 11."}
{"section_title": "11.3 sections Construct", "chunk": "\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 243 \n Cross References \n \u2022 ompt_callback_dispatch_t, see Section 19.5.2.6 \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 nowait clause, see Section 15.6 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 section directive, see Section 11.3.1 \n"}
{"section_title": "11.3.1 section Directive", "chunk": "Name: section Association: separating \nCategory: subsidiary Properties: default 14 \n Separated directives \n sections \n Semantics \n The section directive may be used to separate the structured block that is associated with a \n sections construct into multiple sections, each of which is a structured block sequence.\n Execution Model Events \n The section-begin event occurs before an implicit task starts to execute a structured block sequence \n in the sections construct for each of those structured block sequences that the task executes.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a \n section-begin event in that thread.The callback occurs in the context of the implicit task.The \n callback has type signature ompt_callback_dispatch_t.\n Cross References \n \u2022 sections directive, see Section 11.3 \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n"}
{"section_title": "11.4 workshare Construct", "chunk": "Name: workshare Association: block \nCategory: executable Properties: work-distribution, worksharing 2 \n Clauses \n nowait \n Binding \n The binding thread set for a workshare region is the current team.A workshare region binds \n to the innermost enclosing parallel region.Only the threads of the team that executes the \n binding parallel region participate in the execution of the units of work and the implied barrier \n of the workshare region if the barrier is not eliminated by a nowait clause.\n Semantics \n The workshare construct divides the execution of the associated structured block into separate \n units of work and causes the threads of the team to share the work such that each unit is executed \n only once by one thread, in the context of its implicit task.An implicit barrier occurs at the end of a \n workshare region if a nowait clause is not specified."}
{"section_title": "11.4 workshare Construct", "chunk": "An implicit barrier occurs at the end of a \n workshare region if a nowait clause is not specified.\n An implementation of the workshare construct must insert any synchronization that is required \n to maintain standard Fortran semantics.For example, the effects of one statement within the \n structured block must appear to occur before the execution of succeeding statements, and the \n evaluation of the right hand side of an assignment must appear to complete prior to the effects of \n assigning to the left hand side.\n The statements in the workshare construct are divided into units of work as follows: \n \u2022 For array expressions within each statement, including transformational array intrinsic functions \n that compute scalar values from arrays: \n \u2013 Evaluation of each element of the array expression, including any references to elemental \n functions, is a unit of work."}
{"section_title": "11.4 workshare Construct", "chunk": "\n The statements in the workshare construct are divided into units of work as follows: \n \u2022 For array expressions within each statement, including transformational array intrinsic functions \n that compute scalar values from arrays: \n \u2013 Evaluation of each element of the array expression, including any references to elemental \n functions, is a unit of work.\n \u2013 Evaluation of transformational array intrinsic functions may be freely subdivided into any \n number of units of work.\n \u2022 For array assignment statements, assignment of each element is a unit of work.\n \u2022 For scalar assignment statements, each assignment operation is a unit of work.\n \u2022 For WHERE statements or constructs, evaluation of the mask expression and the masked \n assignments are each a unit of work.\n \u2022 For FORALL statements or constructs, evaluation of the mask expression, expressions occurring \n in the specification of the iteration space, and the masked assignments are each a unit of work."}
{"section_title": "11.4 workshare Construct", "chunk": "\n \u2022 For FORALL statements or constructs, evaluation of the mask expression, expressions occurring \n in the specification of the iteration space, and the masked assignments are each a unit of work.\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 245 \nFortran (cont.) \n \u2022 For atomic constructs, critical constructs, and parallel constructs, the construct is a \n unit of work.A new thread team executes the statements contained in a parallel construct.\n \u2022 If none of the rules above apply to a portion of a statement in the structured block, then that \n portion is a unit of work.\n The transformational array intrinsic functions are MATMUL, DOT_PRODUCT, SUM, PRODUCT, \n MAXVAL, MINVAL, COUNT, ANY, ALL, SPREAD, PACK, UNPACK, RESHAPE, TRANSPOSE, \n EOSHIFT, CSHIFT, MINLOC, and MAXLOC.\n How units of work are assigned to the threads that execute a workshare region is unspecified."}
{"section_title": "11.4 workshare Construct", "chunk": "\n How units of work are assigned to the threads that execute a workshare region is unspecified.\n If an array expression in the block references the value, association status, or allocation status of \n private variables, the value of the expression is undefined, unless the same value would be \n computed by every thread.\n If an array assignment, a scalar assignment, a masked array assignment, or a FORALL assignment \n assigns to a private variable in the block, the result is unspecified.\n The workshare directive causes the sharing of work to occur only in the workshare construct, \n and not in the remainder of the workshare region.\n Execution Model Events \n The workshare-begin event occurs after an implicit task encounters a workshare construct but \n before the task starts to execute the structured block of the workshare region."}
{"section_title": "11.4 workshare Construct", "chunk": "\n Execution Model Events \n The workshare-begin event occurs after an implicit task encounters a workshare construct but \n before the task starts to execute the structured block of the workshare region.\n The workshare-end event occurs after an implicit task finishes execution of a workshare region \n but before it resumes execution of the enclosing context.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument and ompt_work_workshare as its work_type argument for each \n occurrence of a workshare-begin event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_work callback with ompt_scope_end as its endpoint argument and \n ompt_work_workshare as its work_type argument for each occurrence of a workshare-end \n event in that thread.The callbacks occur in the context of the implicit task.The callbacks have type \n signature ompt_callback_work_t."}
{"section_title": "11.4 workshare Construct", "chunk": "The callbacks have type \n signature ompt_callback_work_t.\n Restrictions \n Restrictions to the workshare construct are as follows: \n \u2022 The only OpenMP constructs that may be closely nested inside a workshare construct are the \n atomic, critical, and parallel constructs.\n \u2022 Base language statements that are encountered inside a workshare construct but that are not \n enclosed within a parallel or atomic construct that is nested inside the workshare \n construct must consist of only the following: \n \u2013 array assignments; \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2013 scalar assignments; \n \u2013 FORALL statements; \n \u2013 FORALL constructs; \n \u2013 WHERE statements; \n \u2013 WHERE constructs; and \n \u2013 BLOCK constructs that are strictly structured blocks associated with OpenMP directives."}
{"section_title": "11.4 workshare Construct", "chunk": "\n \u2022 Base language statements that are encountered inside a workshare construct but that are not \n enclosed within a parallel or atomic construct that is nested inside the workshare \n construct must consist of only the following: \n \u2013 array assignments; \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2013 scalar assignments; \n \u2013 FORALL statements; \n \u2013 FORALL constructs; \n \u2013 WHERE statements; \n \u2013 WHERE constructs; and \n \u2013 BLOCK constructs that are strictly structured blocks associated with OpenMP directives.\n \u2022 All array assignments, scalar assignments, and masked array assignments that are encountered \n inside a workshare construct but are not nested inside a parallel construct that is nested \n inside the workshare construct must be intrinsic assignments."}
{"section_title": "11.4 workshare Construct", "chunk": "\n \u2022 All array assignments, scalar assignments, and masked array assignments that are encountered \n inside a workshare construct but are not nested inside a parallel construct that is nested \n inside the workshare construct must be intrinsic assignments.\n \u2022 The construct must not contain any user-defined function calls unless either the function is pure \n and elemental or the function call is contained inside a parallel construct that is nested inside \n the workshare construct.\n Cross References \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 critical directive, see Section 15.2 \n \u2022 nowait clause, see Section 15.6 \n \u2022 parallel directive, see Section 10.1 \nFortran \n"}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "22 Binding \n The binding thread set for a worksharing-loop region is the current team.A worksharing-loop \n region binds to the innermost enclosing parallel region.Only those threads participate in \n execution of the loop iterations and the implied barrier of the worksharing-loop region when that \n barrier is not eliminated by a nowait clause.\n Semantics \n The worksharing-loop construct is a worksharing construct that specifies that the iterations of one \n or more associated loops will be executed in parallel by threads in the team in the context of their \n implicit tasks.The iterations are distributed across threads that already exist in the team that is \n executing the parallel region to which the worksharing-loop region binds.Each thread executes \n its assigned chunks in the context of its implicit task.The iterations of a given chunk are executed \n in sequential order.\nCHAPTER 11."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 247 \n If specified, the schedule clause determines the schedule of the logical iterations associated with \n the construct.That is, it determines the division of iterations into chunks and how those chunks are \n assigned to the threads.If the schedule clause is not specified then the schedule is \n implementation defined.\n At the beginning of each logical iteration, the loop iteration variable or the variable declared by \n range-decl of each associated loop has the value that it would have if the set of the associated loops \n was executed sequentially.\n The schedule is reproducible if one of the following conditions is true: \n \u2022 The order clause is specified with the reproducible order-modifier; or \n \u2022 The schedule clause is specified with static as the kind argument but not the simd \n ordering-modifier and the order clause is not specified with the unconstrained \n order-modifier."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "\n The schedule is reproducible if one of the following conditions is true: \n \u2022 The order clause is specified with the reproducible order-modifier; or \n \u2022 The schedule clause is specified with static as the kind argument but not the simd \n ordering-modifier and the order clause is not specified with the unconstrained \n order-modifier.\n Programs can only depend on which thread executes a particular iteration if the schedule is \n reproducible.Schedule reproducibility also determines the consistency with the execution of \n constructs with the same schedule.\n Execution Model Events \n The ws-loop-begin event occurs after an implicit task encounters a worksharing-loop construct but \n before the task starts execution of the structured block of the worksharing-loop region.\n The ws-loop-end event occurs after a worksharing-loop region finishes execution but before \n resuming execution of the encountering task."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "\n The ws-loop-end event occurs after a worksharing-loop region finishes execution but before \n resuming execution of the encountering task.\n The ws-loop-iteration-begin event occurs at the beginning of each iteration of a worksharing-loop \n region.The ws-loop-chunk-begin event occurs for each scheduled chunk of a worksharing-loop \n region before the implicit task executes any of the associated iterations.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument for each occurrence of a ws-loop-begin event in that thread.Similarly, a \n thread dispatches a registered ompt_callback_work callback with ompt_scope_end as its \n endpoint argument for each occurrence of a ws-loop-end event in that thread.The callbacks occur \n in the context of the implicit task.The callbacks have type signature ompt_callback_work_t \n and the work_type argument indicates the schedule as shown in Table 11.1."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "The callbacks have type signature ompt_callback_work_t \n and the work_type argument indicates the schedule as shown in Table 11.1.\n A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a \n ws-loop-iteration-begin or ws-loop-chunk-begin event in that thread.The callback occurs in the \n context of the implicit task.The callback has type signature ompt_callback_dispatch_t.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 11.1: ompt_callback_work Callback Work Types for Worksharing-Loop \nValue of work_type If determined schedule is \nompt_work_loop unknown at runtime \nompt_work_loop_static static \nompt_work_loop_dynamic dynamic \nompt_work_loop_guided guided \nompt_work_loop_other implementation specific \n Restrictions \n Restrictions to the worksharing-loop construct are as follows: \n \u2022 The logical iteration space of the loops associated with the worksharing-loop construct must be \n the same for all threads in the team."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 11.1: ompt_callback_work Callback Work Types for Worksharing-Loop \nValue of work_type If determined schedule is \nompt_work_loop unknown at runtime \nompt_work_loop_static static \nompt_work_loop_dynamic dynamic \nompt_work_loop_guided guided \nompt_work_loop_other implementation specific \n Restrictions \n Restrictions to the worksharing-loop construct are as follows: \n \u2022 The logical iteration space of the loops associated with the worksharing-loop construct must be \n the same for all threads in the team.\n \u2022 The value of the run-sched-var ICV must be the same for all threads in the team."}
{"section_title": "11.5 Worksharing-Loop Constructs", "chunk": "\n \u2022 The value of the run-sched-var ICV must be the same for all threads in the team.\n Cross References \n \u2022 Consistent Loop Schedules, see Section 4.4.5 \n \u2022 OMP_SCHEDULE, see Section 21.2.1 \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 nowait clause, see Section 15.6 \n \u2022 order clause, see Section 10.3 \n \u2022 schedule clause, see Section 11.5.3 \nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 249 \nC / C++ \n"}
{"section_title": "11.5.1 for Construct", "chunk": "Name: for Association: loop-associated \nCategory: executable Properties: work-distribution, workshar\ufffeing, worksharing-loop, cancellable, context\ufffematching \n \n Separating directives \n scan \n Clauses \n allocate, collapse, firstprivate, lastprivate, linear, nowait, order, \n ordered, private, reduction, schedule \n Semantics \n The for construct is a worksharing-loop construct."}
{"section_title": "11.5.1 for Construct", "chunk": "Name: for Association: loop-associated \nCategory: executable Properties: work-distribution, workshar\ufffeing, worksharing-loop, cancellable, context\ufffematching \n \n Separating directives \n scan \n Clauses \n allocate, collapse, firstprivate, lastprivate, linear, nowait, order, \n ordered, private, reduction, schedule \n Semantics \n The for construct is a worksharing-loop construct.\n Cross References \n \u2022 Worksharing-Loop Constructs, see Section 11.5 \n \u2022 allocate clause, see Section 6.6 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 nowait clause, see Section 15.6 \n \u2022 order clause, see Section 10.3 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 scan directive, see Section 5.6 \n \u2022 schedule clause, see Section 11.5.3 \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n"}
{"section_title": "11.5.2 do Construct", "chunk": "Name: do Association: loop \nCategory: executable Properties: work-distribution, workshar\ufffeing, worksharing-loop, cancellable, context\ufffematching \n \n Separating directives \n scan \n Clauses \n allocate, collapse, firstprivate, lastprivate, linear, nowait, order, \n ordered, private, reduction, schedule \n Semantics \n The do construct is a worksharing-loop construct.\n Cross References \n \u2022 Worksharing-Loop Constructs, see Section 11.5 \n \u2022 allocate clause, see Section 6.6 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 nowait clause, see Section 15.6 \n \u2022 order clause, see Section 10.3 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 scan directive, see Section 5.6 \n \u2022 schedule clause, see Section 11.5.3 \nFortran \nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 251 \n"}
{"section_title": "11.5.3 schedule Clause", "chunk": "2 Name: schedule Properties: unique \n Arguments \nName Type Properties \nkind Keyword: auto, dynamic, guided, \nruntime, static \ndefault \nchunk_size expression of integer type ultimate, optional, posi\ufffetive, region-invariant \n \n Modifiers \nName Modifies Type Properties \nordering-modifier kind Keyword: monotonic, \nnonmonotonic \nunique \nchunk-modifier kind Keyword: simd unique \n \n Directives \n do, for \n Semantics \n The schedule clause specifies how iterations of associated loops of a worksharing-loop construct \n are divided into contiguous non-empty subsets, called chunks, and how these chunks are distributed \n among threads of the team.The chunk_size expression is evaluated using the original list items of \n any variables that are made private in the worksharing-loop construct.Whether, in what order, or \n how many times, any side effects of the evaluation of this expression occur is unspecified."}
{"section_title": "11.5.3 schedule Clause", "chunk": "Whether, in what order, or \n how many times, any side effects of the evaluation of this expression occur is unspecified.The use \n of a variable in a schedule clause expression of a worksharing-loop construct causes an implicit \n reference to the variable in all enclosing constructs.\n If the kind argument is static, iterations are divided into chunks of size chunk_size, and the \n chunks are assigned to the threads in the team in a round-robin fashion in the order of the thread \n number.Each chunk contains chunk_size iterations, except for the chunk that contains the \n sequentially last iteration, which may have fewer iterations.If chunk_size is not specified, the \n logical iteration space is divided into chunks that are approximately equal in size, and at most one \n chunk is distributed to each thread.\n If the kind argument is dynamic, each thread executes a chunk, then requests another chunk, until \n no chunks remain to be assigned."}
{"section_title": "11.5.3 schedule Clause", "chunk": "\n If the kind argument is dynamic, each thread executes a chunk, then requests another chunk, until \n no chunks remain to be assigned.Each chunk contains chunk_size iterations, except for the chunk \n that contains the sequentially last iteration, which may have fewer iterations.If chunk_size is not \n specified, it defaults to 1.\n If the kind argument is guided, each thread executes a chunk, then requests another chunk, until \n no chunks remain to be assigned.For a chunk_size of 1, the size of each chunk is proportional to \n the number of unassigned iterations divided by the number of threads in the team, decreasing to 1.\n For a chunk_size with value k > 1, the size of each chunk is determined in the same way, with the \n OpenMP API \u2013 Version 5.2 November 2021 \n restriction that the chunks do not contain fewer than k iterations (except for the chunk that contains \n the sequentially last iteration, which may have fewer than k iterations)."}
{"section_title": "11.5.3 schedule Clause", "chunk": "\n For a chunk_size with value k > 1, the size of each chunk is determined in the same way, with the \n OpenMP API \u2013 Version 5.2 November 2021 \n restriction that the chunks do not contain fewer than k iterations (except for the chunk that contains \n the sequentially last iteration, which may have fewer than k iterations).If chunk_size is not \n specified, it defaults to 1.\n If the kind argument is auto, the decision regarding scheduling is implementation defined.\n If the kind argument is runtime, the decision regarding scheduling is deferred until runtime, and \n the behavior is as if the clause specifies kind, chunk-size and ordering-modifier as set in the \n run-sched-var ICV.If the schedule clause explicitly specifies any modifiers then they override \n any corresponding modifiers that are specified in the run-sched-var ICV."}
{"section_title": "11.5.3 schedule Clause", "chunk": "If the schedule clause explicitly specifies any modifiers then they override \n any corresponding modifiers that are specified in the run-sched-var ICV.\n If the simd chunk-modifier is specified and the loop is associated with a SIMD construct, \n new_chunk_size = dchunk_size/simd_widthe \u2217 simd_width is the chunk_size for all chunks \n except the first and last chunks, where simd_width is an implementation-defined value.The first \n chunk will have at least new_chunk_size iterations except if it is also the last chunk.The last chunk \n may have fewer iterations than new_chunk_size.If the simd modifier is specified and the loop is \n not associated with a SIMD construct, the modifier is ignored.\n \n Note \u2013 For a team of p threads and a loop of n iterations, let dn/pe be the integer q that satisfies \n n = p \u2217 q \u2212 r, with 0 <= r < p."}
{"section_title": "11.5.3 schedule Clause", "chunk": "\n \n Note \u2013 For a team of p threads and a loop of n iterations, let dn/pe be the integer q that satisfies \n n = p \u2217 q \u2212 r, with 0 <= r < p.One compliant implementation of the static schedule (with no \n specified chunk_size) would behave as though chunk_size had been specified with value q.Another \n compliant implementation would assign q iterations to the first p \u2212 r threads, and q \u2212 1 iterations to \n the remaining r threads.This illustrates why a conforming program must not rely on the details of a \n particular implementation.\n A compliant implementation of the guided schedule with a chunk_size value of k would assign \n q = dn/pe iterations to the first available thread and set n to the larger of n \u2212 q and p \u2217 k.It would \n then repeat this process until q is greater than or equal to the number of remaining iterations, at \n which time the remaining iterations form the final chunk."}
{"section_title": "11.5.3 schedule Clause", "chunk": "It would \n then repeat this process until q is greater than or equal to the number of remaining iterations, at \n which time the remaining iterations form the final chunk.Another compliant implementation could \n use the same method, except with q = dn/(2p)e, and set n to the larger of n \u2212 q and 2 \u2217 p \u2217 k.\n \n If the monotonic ordering-modifier is specified then each thread executes the chunks that it is \n assigned in increasing logical iteration order.When the nonmonotonic ordering-modifier is \n specified then chunks may be assigned to threads in any order and the behavior of an application \n that depends on any execution order of the chunks is unspecified.If an ordering-modifier is not \n specified, the effect is as if the monotonic modifier is specified if the kind argument is static \n or an ordered clause is specified on the construct; otherwise, the effect is as if the \n nonmonotonic modifier is specified."}
{"section_title": "11.5.3 schedule Clause", "chunk": "If an ordering-modifier is not \n specified, the effect is as if the monotonic modifier is specified if the kind argument is static \n or an ordered clause is specified on the construct; otherwise, the effect is as if the \n nonmonotonic modifier is specified.\n Restrictions \n Restrictions to the schedule clause are as follows: \n \u2022 The schedule clause cannot be specified if any of the associated loops are non-rectangular.\n \u2022 The value of the chunk_size expression must be the same for all threads in the team.\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 253 \n \u2022 If runtime or auto is specified for kind, chunk_size must not be specified.\n \u2022 The nonmonotonic ordering-modifier cannot be specified if an ordered clause is specified \n on the same construct.\n Cross References \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 run-sched-var ICV, see Table 2.1 \n"}
{"section_title": "11.6 distribute Construct", "chunk": "Name: distribute Association: loop \nCategory: executable Properties: work-distribution 10 \n Clauses \n allocate, collapse, dist_schedule, firstprivate, lastprivate, order, \n private \n Binding \n The binding thread set for a distribute region is the set of initial threads executing an \n enclosing teams region.A distribute region binds to this teams region.\n Semantics \n The distribute construct specifies that the iterations of one or more loops will be executed by \n the initial teams in the context of their implicit tasks.The iterations are distributed across the initial \n threads of all initial teams that execute the teams region to which the distribute region binds.\n No implicit barrier occurs at the end of a distribute region.To avoid data races the original list \n items that are modified due to lastprivate clauses should not be accessed between the end of \n the distribute construct and the end of the teams region to which the distribute binds."}
{"section_title": "11.6 distribute Construct", "chunk": "To avoid data races the original list \n items that are modified due to lastprivate clauses should not be accessed between the end of \n the distribute construct and the end of the teams region to which the distribute binds.\n If the dist_schedule clause is not specified, the schedule is implementation defined.\n At the beginning of each logical iteration, the loop iteration variable or the variable declared by \n range-decl of each associated loop has the value that it would have if the set of the associated loops \n was executed sequentially.\n The schedule is reproducible if one of the following conditions is true: \n \u2022 The order clause is specified with the reproducible modifier; or \n \u2022 The dist_schedule clause is specified with static as the kind parameter and the order \n clause is not specified with the unconstrained order-modifier."}
{"section_title": "11.6 distribute Construct", "chunk": "\n The schedule is reproducible if one of the following conditions is true: \n \u2022 The order clause is specified with the reproducible modifier; or \n \u2022 The dist_schedule clause is specified with static as the kind parameter and the order \n clause is not specified with the unconstrained order-modifier.\n OpenMP API \u2013 Version 5.2 November 2021 \n Programs can only depend on which team executes a particular iteration if the schedule is \n reproducible.Schedule reproducibility also determines the consistency with the execution of \n constructs with the same schedule.\n Execution Model Events \n The distribute-begin event occurs after an initial task encounters a distribute construct but \n before the task starts to execute the structured block of the distribute region.\n The distribute-end event occurs after an initial task finishes execution of a distribute region \n but before it resumes execution of the enclosing context."}
{"section_title": "11.6 distribute Construct", "chunk": "\n The distribute-end event occurs after an initial task finishes execution of a distribute region \n but before it resumes execution of the enclosing context.\n The distribute-chunk-begin event occurs for each scheduled chunk of a distribute region \n before execution of any associated iteration.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback with ompt_scope_begin \n as its endpoint argument and ompt_work_distribute as its work_type argument for each \n occurrence of a distribute-begin event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_work callback with ompt_scope_end as its endpoint argument and \n ompt_work_distribute as its work_type argument for each occurrence of a distribute-end \n event in that thread.The callbacks occur in the context of the implicit task.The callbacks have type \n signature ompt_callback_work_t."}
{"section_title": "11.6 distribute Construct", "chunk": "The callbacks have type \n signature ompt_callback_work_t.\n A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a \n distribute-chunk-begin event in that thread.The callback occurs in the context of the initial task.\n The callback has type signature ompt_callback_dispatch_t.\n Restrictions \n Restrictions to the distribute construct are as follows: \n \u2022 The logical iteration space of the loops associated with the distribute construct must be the \n same for all teams in the league.\n \u2022 The region that corresponds to the distribute construct must be strictly nested inside a \n teams region.\n \u2022 A list item may appear in a firstprivate or lastprivate clause, but not in both.\n \u2022 The conditional lastprivate-modifier must not be specified."}
{"section_title": "11.6 distribute Construct", "chunk": "\n \u2022 The conditional lastprivate-modifier must not be specified.\n Cross References \n \u2022 Consistent Loop Schedules, see Section 4.4.5 \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 dist_schedule clause, see Section 11.6.1 \nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 255 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 order clause, see Section 10.3 \n \u2022 private clause, see Section 5.4.3 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "11.6.1 dist_schedule Clause", "chunk": "7 Name: dist_schedule Properties: unique \n Arguments \nName Type Properties \nkind Keyword: static default \nchunk_size expression of integer type ultimate, optional, posi\ufffetive, region-invariant \n \n Directives \n distribute \n Semantics \n The dist_schedule clause specifies how iterations of associated loops of a distribute \n construct are divided into contiguous non-empty subsets, called chunks, and how these chunks are \n distributed among the teams of the league.if chunk_size is not specified, the iteration space is \n divided into chunks that are approximately equal in size, and at most one chunk is distributed to \n each initial team of the league.\n If the chunk_size argument is specified, iterations are divided into chunks of size chunk_size.The \n chunk_size expression is evaluated using the original list items of any variables that are made \n private in the distribute construct."}
{"section_title": "11.6.1 dist_schedule Clause", "chunk": "The \n chunk_size expression is evaluated using the original list items of any variables that are made \n private in the distribute construct.Whether, in what order, or how many times, any side \n effects of the evaluation of this expression occur is unspecified.The use of a variable in a \n dist_schedule clause expression of a distribute construct causes an implicit reference to \n the variable in all enclosing constructs.These chunks are assigned to the initial teams of the league \n in a round-robin fashion in the order of the initial team number.\n Restrictions \n Restrictions to the dist_schedule clause are as follows: \n \u2022 The value of the chunk_size expression must be the same for all teams in the league.\n \u2022 The dist_schedule clause cannot be specified if any of the associated loops are \n non-rectangular.\n Cross References \n \u2022 distribute directive, see Section 11.6 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "11.7 loop Construct", "chunk": "Name: loop Association: loop-associated \nCategory: executable Properties: work-distribution, worksharing, \nsimdizable \n \n Clauses \n bind, collapse, lastprivate, order, private, reduction \n Binding \n The bind clause determines the binding region, which determines the binding thread set.\n Semantics \n A loop construct specifies that the logical iterations of the associated loops may execute \n concurrently and permits the encountering threads to execute the loop accordingly.A loop \n construct is a worksharing construct if its binding region is the innermost enclosing parallel region.\n Otherwise it is not a worksharing region.The directive asserts that the iterations of the associated \n loops may execute in any order, including concurrently.Each logical iteration is executed once per \n instance of the loop region that is encountered by exactly one thread that is a member of the \n binding thread set."}
{"section_title": "11.7 loop Construct", "chunk": "Each logical iteration is executed once per \n instance of the loop region that is encountered by exactly one thread that is a member of the \n binding thread set.\n At the beginning of each logical iteration, the loop iteration variable or the variable declared by \n range-decl of each associated loop has the value that it would have if the set of the associated loops \n was executed sequentially.\n If the order clause is not present, the behavior is as if an order clause that specifies \n concurrent appeared on the construct.The loop schedule for a loop construct is reproducible \n unless the order clause is present with the unconstrained order-modifier.\n If the loop region binds to a teams region, the threads in the binding thread set may continue \n execution after the loop region without waiting for all logical iterations of the associated loops to \n complete.The iterations are guaranteed to complete before the end of the teams region."}
{"section_title": "11.7 loop Construct", "chunk": "The iterations are guaranteed to complete before the end of the teams region.If the \n loop region does not bind to a teams region, all logical iterations of the associated loops must \n complete before the encountering threads continue execution after the loop region.\n For the purpose of determining its consistency with other schedules, the schedule is defined by the \n implicit order clause.The schedule is reproducible if the schedule specified through the implicit \n order clause is reproducible.\n Restrictions \n Restrictions to the loop construct are as follows: \n \u2022 A list item may not appear in a lastprivate clause unless it is the loop iteration variable of a \n loop that is associated with the construct.\n \u2022 If a reduction-modifier is specified in a reduction clause that appears on the directive then the \n reduction modifier must be default.\nCHAPTER 11."}
{"section_title": "11.7 loop Construct", "chunk": "\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 257 \n \u2022 If a loop construct is not nested inside another OpenMP construct then the bind clause must \n be present.\n \u2022 If a loop region binds to a teams or parallel region, it must be encountered by all threads in \n the binding thread set or by none of them.\n Cross References \n \u2022 Consistent Loop Schedules, see Section 4.4.5 \n \u2022 bind clause, see Section 11.7.1 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 order clause, see Section 10.3 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "11.7.1 bind Clause", "chunk": "15 Name: bind Properties: unique \n Arguments \nName Type Properties \nbinding Keyword: parallel, teams, \nthread \n default \n Directives \n loop \n Semantics \n The bind clause specifies the binding region of the construct on which it appears.Specifically, if \n binding is teams and an innermost enclosing teams region exists then the binding region is that \n teams region; if binding is parallel then the binding region is the innermost enclosing parallel \n region, which may be an implicit parallel region; and if binding is thread then the binding region \n is not defined.If the bind clause is not specified on a construct for which it may be specified and \n the construct is closely nested inside a teams or parallel construct, the effect is as if binding is \n teams or parallel.If none of those conditions hold, the binding region is not defined.\n The specified binding region determines the binding thread set."}
{"section_title": "11.7.1 bind Clause", "chunk": "\n The specified binding region determines the binding thread set.Specifically, if the binding region is \n a teams region, then the binding thread set is the set of initial threads that are executing that \n region while if the binding region is a parallel region, then the binding thread set is the team of \n threads that are executing that region.If the binding region is not defined, then the binding thread \n set is the encountering thread.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the bind clause are as follows: \n \u2022 If teams is specified as binding then the corresponding loop region must be strictly nested \n inside a teams region.\n \u2022 If teams is specified as binding and the corresponding loop region executes on a non-host \n device then the behavior of a reduction clause that appears on the corresponding loop \n construct is unspecified if the construct is not nested inside a teams construct."}
{"section_title": "11.7.1 bind Clause", "chunk": "\n \u2022 If teams is specified as binding and the corresponding loop region executes on a non-host \n device then the behavior of a reduction clause that appears on the corresponding loop \n construct is unspecified if the construct is not nested inside a teams construct.\n \u2022 If parallel is specified as binding, the behavior is unspecified if the corresponding loop \n region is closely nested inside a simd region.\n Cross References \n \u2022 loop directive, see Section 11.7 \n \u2022 parallel construct, see Section 10.1 \n \u2022 teams construct, see Section 10.2.\nCHAPTER 11.WORK-DISTRIBUTION CONSTRUCTS 259 \n"}
{"section_title": "12 Tasking Constructs", "chunk": "2 This chapter defines directives and concepts related to explicit tasks.\n"}
{"section_title": "12.1 untied Clause", "chunk": "4 Name: untied Properties: unique, inarguable \n Directives \n task, taskloop \n Semantics \n The untied clause specifies that tasks generated by the construct on which it appears are untied, \n which means that any thread in the team can resume the task region after a suspension.If the \n untied clause is not specified on a construct on which it may appear, generated tasks are tied; if a \n tied task is suspended, its task region can only be resumed by the thread that started its execution.\n If a generated task is a final or an included task, the untied clause is ignored and the task is tied.\n Cross References \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "12.2 mergeable Clause", "chunk": "17 Name: mergeable Properties: unique, inarguable \n Directives \n task, taskloop \n Semantics \n The mergeable clause specifies that tasks generated by the construct on which it appears are \n mergeable tasks.\n Cross References \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n \n"}
{"section_title": "12.3 final Clause", "chunk": "2 Name: final Properties: unique \n Arguments \nName Type Properties \nfinalize expression of logical type default 4 \n Directives \n task, taskloop \n Semantics \n The final clause specifies that tasks generated by the construct on which it appears are final tasks \n if the finalize expression evaluates to true.All task constructs that are encountered during \n execution of a final task generate final and included tasks.The use of a variable in a finalize \n expression causes an implicit reference to the variable in all enclosing constructs.The finalize \n expression is evaluated in the context outside of the construct on which the clause appears, \n Cross References \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "12.4 priority Clause", "chunk": "17 Name: priority Properties: unique \n Arguments \nName Type Properties \npriority-value expression of integer type constant, non-negative 19 \n Directives \n task, taskloop \n Semantics \n The priority clause specifies a hint for the task execution order of tasks generated by the \n construct on which it appears in the priority-value argument.Among all tasks ready to be executed, \n higher priority tasks (those with a higher numerical priority-value) are recommended to execute \n before lower priority ones.The default priority-value when no priority clause is specified is \n zero (the lowest priority).If a specified priority-value is higher than the max-task-priority-var ICV \n then the implementation will use the value of that ICV.A program that relies on the task execution \n order being determined by the priority-value may have unspecified behavior.\nCHAPTER 12."}
{"section_title": "12.4 priority Clause", "chunk": "\nCHAPTER 12.TASKING CONSTRUCTS 261 \n Cross References \n \u2022 max-task-priority-var ICV, see Table 2.1 \n \u2022 task directive, see Section 12.5 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "12.5 task Construct", "chunk": "Name: task Association: block \nCategory: executable Properties: parallelism-generating, thread\ufffelimiting, task-generating \n \n Clauses \n affinity, allocate, default, depend, detach, final, firstprivate, if, \n in_reduction, mergeable, priority, private, shared, untied \n Clause set \n Properties: exclusive Members: detach, mergeable \n Binding \n The binding thread set of the task region is the current team.A task region binds to the \n innermost enclosing parallel region.\n Semantics \n When a thread encounters a task construct, an explicit task is generated from the code for the \n associated structured block.The data environment of the task is created according to the \n data-sharing attribute clauses on the task construct, per-data environment ICVs, and any defaults \n that apply.The data environment of the task is destroyed when the execution code of the associated \n structured block is completed."}
{"section_title": "12.5 task Construct", "chunk": "The data environment of the task is destroyed when the execution code of the associated \n structured block is completed.\n The encountering thread may immediately execute the task, or defer its execution.In the latter case, \n any thread in the team may be assigned the task.Completion of the task can be guaranteed using \n task synchronization constructs and clauses.If a task construct is encountered during execution \n of an outer task, the generated task region that corresponds to this construct is not a part of the \n outer task region unless the generated task is an included task.\n A detachable task is completed when the execution of its associated structured block is completed \n and the allow-completion event is fulfilled.If no detach clause is present on a task construct, \n the generated task is completed when the execution of its associated structured block is completed."}
{"section_title": "12.5 task Construct", "chunk": "If no detach clause is present on a task construct, \n the generated task is completed when the execution of its associated structured block is completed.\n A thread that encounters a task scheduling point within the task region may temporarily suspend \n the task region.\n The task construct includes a task scheduling point in the task region of its generating task, \n immediately following the generation of the explicit task.Each explicit task region includes a \n task scheduling point at the end of its associated structured block.\n OpenMP API \u2013 Version 5.2 November 2021 \n \n Note \u2013 When storage is shared by an explicit task region, the programmer must ensure, by \n adding proper synchronization, that the storage does not reach the end of its lifetime before the \n explicit task region completes its execution."}
{"section_title": "12.5 task Construct", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n \n Note \u2013 When storage is shared by an explicit task region, the programmer must ensure, by \n adding proper synchronization, that the storage does not reach the end of its lifetime before the \n explicit task region completes its execution.\n \n When an if clause is present on a task construct and the if clause expression evaluates to false, \n an undeferred task is generated, and the encountering thread must suspend the current task region, \n for which execution cannot be resumed until execution of the structured block that is associated \n with the generated task is completed.The use of a variable in an if clause expression of a task \n construct causes an implicit reference to the variable in all enclosing constructs.The if clause \n expression is evaluated in the context outside of the task construct."}
{"section_title": "12.5 task Construct", "chunk": "The if clause \n expression is evaluated in the context outside of the task construct.\n Execution Model Events \n The task-create event occurs when a thread encounters a construct that causes a new task to be \n created.The event occurs after the task is initialized but before it begins execution or is deferred.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_task_create callback for each occurrence \n of a task-create event in the context of the encountering task.This callback has the type signature \n ompt_callback_task_create_t and the flags argument indicates the task types shown in \n Table 12.1."}
{"section_title": "12.5 task Construct", "chunk": "This callback has the type signature \n ompt_callback_task_create_t and the flags argument indicates the task types shown in \n Table 12.1.\nTABLE 12.1: ompt_callback_task_create Callback Flags Evaluation \nOperation Evaluates to true \n(flags & ompt_task_explicit) Always in the dispatched callback \n(flags & ompt_task_undeferred) If the task is an undeferred task \n(flags & ompt_task_final) If the task is a final task \n(flags & ompt_task_untied) If the task is an untied task \n(flags & ompt_task_mergeable) If the task is a mergeable task \n(flags & ompt_task_merged) If the task is a merged task \n Cross References \n \u2022 Task Scheduling, see Section 12.9 \n \u2022 omp_fulfill_event, see Section 18.11.1 \n \u2022 ompt_callback_task_create_t, see Section 19.5.2.7 \n \u2022 affinity clause, see Section 12.5.1 \n \u2022 allocate clause, see Section 6.6 \nCHAPTER 12."}
{"section_title": "12.5 task Construct", "chunk": "\nTABLE 12.1: ompt_callback_task_create Callback Flags Evaluation \nOperation Evaluates to true \n(flags & ompt_task_explicit) Always in the dispatched callback \n(flags & ompt_task_undeferred) If the task is an undeferred task \n(flags & ompt_task_final) If the task is a final task \n(flags & ompt_task_untied) If the task is an untied task \n(flags & ompt_task_mergeable) If the task is a mergeable task \n(flags & ompt_task_merged) If the task is a merged task \n Cross References \n \u2022 Task Scheduling, see Section 12.9 \n \u2022 omp_fulfill_event, see Section 18.11.1 \n \u2022 ompt_callback_task_create_t, see Section 19.5.2.7 \n \u2022 affinity clause, see Section 12.5.1 \n \u2022 allocate clause, see Section 6.6 \nCHAPTER 12.TASKING CONSTRUCTS 263 \n \u2022 default clause, see Section 5.4.1 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 detach clause, see Section 12.5.2 \n \u2022 final clause, see Section 12.3 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 if clause, see Section 3.4 \n \u2022 in_reduction clause, see Section 5.5.10 \n \u2022 mergeable clause, see Section 12.2 \n \u2022 priority clause, see Section 12.4 \n \u2022 private clause, see Section 5.4.3 \n \u2022 shared clause, see Section 5.4.2 \n \u2022 untied clause, see Section 12.1 \n"}
{"section_title": "12.5.1 affinity Clause", "chunk": "14 Name: affinity Properties: unique \n Arguments \nName Type Properties \nlocator-list list of locator list item type default 16 \n Modifiers \nName Modifies Type Properties \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \nunique \n \n Directives \n task \n Semantics \n The affinity clause specifies a hint to indicate data affinity of tasks generated by the construct \n on which it appears.The hint recommends to execute generated tasks close to the location of the \n original list items.A program that relies on the task execution location being determined by this list \n may have unspecified behavior.\n OpenMP API \u2013 Version 5.2 November 2021 \n The list items that appear in the affinity clause may also appear in data-environment clauses.\n The list items may reference any iterators-identifier that is defined in the same clause and may \n include array sections."}
{"section_title": "12.5.1 affinity Clause", "chunk": "\n The list items may reference any iterators-identifier that is defined in the same clause and may \n include array sections.\nC / C++ \n The list items that appear in the affinity clause may use shape-operators.\nC / C++ \n Cross References \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "12.5.2 detach Clause", "chunk": "9 Name: detach Properties: unique \n Arguments \nName Type Properties \nevent-handle variable of event_handle type default 11 \n Directives \n task \n Semantics \n The detach clause specifies that the task generated by the construct on which it appears is a \n detachable task.A new allow-completion event is created and connected to the completion of the \n associated task region.The original event-handle is updated to represent that allow-completion \n event before the task data environment is created.The event-handle is considered as if it was \n specified on a firstprivate clause.The use of a variable in a detach clause expression of a \n task construct causes an implicit reference to the variable in all enclosing constructs.\n Restrictions \n Restrictions to the detach clause are as follows: \n \u2022 If a detach clause appears on a directive, then the encountering task must not be a final task."}
{"section_title": "12.5.2 detach Clause", "chunk": "\n Restrictions \n Restrictions to the detach clause are as follows: \n \u2022 If a detach clause appears on a directive, then the encountering task must not be a final task.\n \u2022 A variable that appears in a detach clause cannot appear as a list item on a data-environment \n attribute clause on the same construct.\n \u2022 A variable that is part of another variable (as an array element or a structure element) cannot \n appear in a detach clause.\nCHAPTER 12.TASKING CONSTRUCTS 265 \nFortran \n \u2022 event-handle must not have the POINTER attribute.\n \u2022 If event-handle has the ALLOCATABLE attribute, the allocation status must be allocated when \n the task construct is encountered, and the allocation status must not be changed, either \n explicitly or implicitly, in the task region.\nFortran \n Cross References \n \u2022 firstprivate clause, see Section 5.4.4.\n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "12.6 taskloop Construct", "chunk": "Name: taskloop Association: loop \nCategory: executable Properties: parallelism-generating, task\ufffegenerating \n \n Clauses \n allocate, collapse, default, final, firstprivate, grainsize, if, \n in_reduction, lastprivate, mergeable, nogroup, num_tasks, priority, \n private, reduction, shared, untied \n Clause set synchronization-clause \n Properties: exclusive Members: nogroup, reduction \n Clause set granularity-clause \n Properties: exclusive Members: grainsize, num_tasks \n Binding \n The binding thread set of the taskloop region is the current team.A taskloop region binds to \n the innermost enclosing parallel region.\n Semantics \n When a thread encounters a taskloop construct, the construct partitions the iterations of the \n associated loops into chunks, each of which is assigned to an explicit task for parallel execution.\n The iteration count for each associated loop is computed before entry to the outermost loop."}
{"section_title": "12.6 taskloop Construct", "chunk": "\n The iteration count for each associated loop is computed before entry to the outermost loop.The \n data environment of each generated task is created according to the data-sharing attribute clauses \n on the taskloop construct, per-data environment ICVs, and any defaults that apply.The order of \n the creation of the loop tasks is unspecified.Programs that rely on any execution order of the \n logical iterations are non-conforming.\n OpenMP API \u2013 Version 5.2 November 2021 \n If the nogroup clause is not present, the taskloop construct executes as if it was enclosed in a \n taskgroup construct with no statements or directives outside of the taskloop construct.Thus, \n the taskloop construct creates an implicit taskgroup region.If the nogroup clause is \n present, no implicit taskgroup region is created."}
{"section_title": "12.6 taskloop Construct", "chunk": "If the nogroup clause is \n present, no implicit taskgroup region is created.\n If a reduction clause is present, the behavior is as if a task_reduction clause with the \n same reduction operator and list items was applied to the implicit taskgroup construct that \n encloses the taskloop construct.The taskloop construct executes as if each generated task \n was defined by a task construct on which an in_reduction clause with the same reduction \n operator and list items is present.Thus, the generated tasks are participants of the reduction defined \n by the task_reduction clause that was applied to the implicit taskgroup construct.\n If an in_reduction clause is present, the behavior is as if each generated task was defined by a \n task construct on which an in_reduction clause with the same reduction operator and list \n items is present.Thus, the generated tasks are participants of a reduction previously defined by a \n reduction scoping clause."}
{"section_title": "12.6 taskloop Construct", "chunk": "Thus, the generated tasks are participants of a reduction previously defined by a \n reduction scoping clause.\n If no clause from the granularity-clause set is present, the number of loop tasks generated and the \n number of logical iterations assigned to these tasks is implementation defined.\n At the beginning of each logical iteration, the loop iteration variable or the variable declared by \n range-decl of each associated loop has the value that it would have if the set of the associated loops \n was executed sequentially.\n When an if clause is present and the if clause expression evaluates to false, undeferred tasks are \n generated.The use of a variable in an if clause expression causes an implicit reference to the \n variable in all enclosing constructs.\nC++ \n For firstprivate variables of class type, the number of invocations of copy constructors that \n perform the initialization is implementation defined."}
{"section_title": "12.6 taskloop Construct", "chunk": "\nC++ \n For firstprivate variables of class type, the number of invocations of copy constructors that \n perform the initialization is implementation defined.\nC++ \n \n Note \u2013 When storage is shared by a taskloop region, the programmer must ensure, by adding \n proper synchronization, that the storage does not reach the end of its lifetime before the taskloop \n region and its descendent tasks complete their execution.\n \n Execution Model Events \n The taskloop-begin event occurs upon entering the taskloop region.A taskloop-begin will \n precede any task-create events for the generated tasks.The taskloop-end event occurs upon \n completion of the taskloop region.\n Events for an implicit taskgroup region that surrounds the taskloop region are the same as for \n the taskgroup construct.\nCHAPTER 12.TASKING CONSTRUCTS 267 \n The taskloop-iteration-begin event occurs at the beginning of each iteration of a taskloop region \n before an explicit task executes the iteration."}
{"section_title": "12.6 taskloop Construct", "chunk": "TASKING CONSTRUCTS 267 \n The taskloop-iteration-begin event occurs at the beginning of each iteration of a taskloop region \n before an explicit task executes the iteration.The taskloop-chunk-begin event occurs before an \n explicit task executes any of its associated iterations in a taskloop region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_work callback for each occurrence of a \n taskloop-begin and taskloop-end event in that thread.The callback occurs in the context of the \n encountering task.The callback has type signature ompt_callback_work_t.The callback \n receives ompt_scope_begin or ompt_scope_end as its endpoint argument, as appropriate, \n and ompt_work_taskloop as its work_type argument.\n A thread dispatches a registered ompt_callback_dispatch callback for each occurrence of a \n taskloop-iteration-begin or taskloop-chunk-begin event in that thread.\n The callback binds to the explicit task executing the iterations."}
{"section_title": "12.6 taskloop Construct", "chunk": "\n The callback binds to the explicit task executing the iterations.The callback has type signature \n ompt_callback_dispatch_t.\n Restrictions \n Restrictions to the taskloop construct are as follows: \n \u2022 The reduction-modifier must be default.\n \u2022 The conditional lastprivate-modifier must not be specified."}
{"section_title": "12.6 taskloop Construct", "chunk": "\n \u2022 The conditional lastprivate-modifier must not be specified.\n Cross References \n \u2022 Canonical Loop Nest Form, see Section 4.4.1 \n \u2022 ompt_callback_dispatch_t, see Section 19.5.2.6 \n \u2022 ompt_callback_work_t, see Section 19.5.2.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 allocate clause, see Section 6.6 \n \u2022 collapse clause, see Section 4.4.3 \n \u2022 default clause, see Section 5.4.1 \n \u2022 final clause, see Section 12.3 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 grainsize clause, see Section 12.6.1 \n \u2022 if clause, see Section 3.4 \n \u2022 in_reduction clause, see Section 5.5.10 \n \u2022 lastprivate clause, see Section 5.4.5 \n \u2022 mergeable clause, see Section 12.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 nogroup clause, see Section 15.7 \n \u2022 num_tasks clause, see Section 12.6.2 \n \u2022 priority clause, see Section 12.4 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 shared clause, see Section 5.4.2 \n \u2022 task directive, see Section 12.5 \n \u2022 taskgroup directive, see Section 15.4 \n \u2022 untied clause, see Section 12.1 \n"}
{"section_title": "12.6.1 grainsize Clause", "chunk": "11 Name: grainsize Properties: unique \n Arguments \nName Type Properties \ngrain-size expression of integer type positive 13 \n Modifiers \nName Modifies Type Properties \nprescriptiveness grain-size Keyword: strict unique 15 \n Directives \n taskloop \n Semantics \n The grainsize clause specifies the number of logical iterations, Lt, that are assigned to each \n generated task t.If prescriptiveness is not specified as strict, other than possibly for the \n generated task that contains the sequentially last iteration, Lt is greater than or equal to the \n minimum of the value of the grain-size expression and the number of logical iterations, but less \n than two times the value of the grain-size expression.If prescriptiveness is specified as strict, \n other than possibly for the generated task that contains the sequentially last iteration, Lt is equal to \n the value of the grain-size expression."}
{"section_title": "12.6.1 grainsize Clause", "chunk": "If prescriptiveness is specified as strict, \n other than possibly for the generated task that contains the sequentially last iteration, Lt is equal to \n the value of the grain-size expression.In both cases, the generated task that contains the \n sequentially last iteration may have fewer iterations than the value of the grain-size expression.\n Restrictions \n Restrictions to the grainsize clause are as follows: \n \u2022 None of the associated loops may be non-rectangular loops.\n Cross References \n \u2022 taskloop directive, see Section 12.6 \nCHAPTER 12.TASKING CONSTRUCTS 269 \n"}
{"section_title": "12.6.2 num_tasks Clause", "chunk": "2 Name: num_tasks Properties: unique \n Arguments \nName Type Properties \nnum-tasks expression of integer type positive 4 \n Modifiers \nName Modifies Type Properties \nprescriptiveness num-tasks Keyword: strict unique 6 \n Directives \n taskloop \n Semantics \n The num_tasks clause specifies that the taskloop construct create as many tasks as the \n minimum of the num-tasks expression and the number of logical iterations.Each task must have at \n least one logical iteration.If prescriptiveness is specified as strict for a task loop with N logical \n iterations, the logical iterations are partitioned in a balanced manner and each partition is assigned, \n in order, to a generated task.The partition size is dN/num-taskse until the number of remaining \n iterations divides the number of remaining tasks evenly, at which point the partition size becomes \n bN/num-tasksc."}
{"section_title": "12.6.2 num_tasks Clause", "chunk": "The partition size is dN/num-taskse until the number of remaining \n iterations divides the number of remaining tasks evenly, at which point the partition size becomes \n bN/num-tasksc.\n Restrictions \n Restrictions to the num_tasks clause are as follows: \n \u2022 None of the associated loops may be non-rectangular loops.\n Cross References \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "12.7 taskyield Construct", "chunk": "Name: taskyield Association: none \nCategory: executable Properties: default 23 \n Binding \n A taskyield region binds to the current task region.The binding thread set of the taskyield \n region is the current team.\n Semantics \n The taskyield region includes an explicit task scheduling point in the current task region.\n Cross References \n \u2022 Task Scheduling, see Section 12.9 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "12.8 Initial Task", "chunk": "2 Execution Model Events \n No events are associated with the implicit parallel region in each initial thread.\n The initial-thread-begin event occurs in an initial thread after the OpenMP runtime invokes the tool \n initializer but before the initial thread begins to execute the first OpenMP region in the initial task.\n The initial-task-begin event occurs after an initial-thread-begin event but before the first OpenMP \n region in the initial task begins to execute.\n The initial-task-end event occurs before an initial-thread-end event but after the last OpenMP \n region in the initial task finishes execution.\n The initial-thread-end event occurs as the final event in an initial thread at the end of an initial task \n immediately prior to invocation of the tool finalizer.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_thread_begin callback for the \n initial-thread-begin event in an initial thread.The callback occurs in the context of the initial \n thread."}
{"section_title": "12.8 Initial Task", "chunk": "The callback occurs in the context of the initial \n thread.The callback has type signature ompt_callback_thread_begin_t.The callback \n receives ompt_thread_initial as its thread_type argument.\n A thread dispatches a registered ompt_callback_implicit_task callback with \n ompt_scope_begin as its endpoint argument for each occurrence of an initial-task-begin event \n in that thread.Similarly, a thread dispatches a registered ompt_callback_implicit_task \n callback with ompt_scope_end as its endpoint argument for each occurrence of an \n initial-task-end event in that thread.The callbacks occur in the context of the initial task and have \n type signature ompt_callback_implicit_task_t.In the dispatched callback, \n (flag & ompt_task_initial) always evaluates to true.\n A thread dispatches a registered ompt_callback_thread_end callback for the \n initial-thread-end event in that thread.The callback occurs in the context of the thread."}
{"section_title": "12.8 Initial Task", "chunk": "The callback occurs in the context of the thread.The \n callback has type signature ompt_callback_thread_end_t.The implicit parallel region \n does not dispatch a ompt_callback_parallel_end callback; however, the implicit parallel \n region can be finalized within this ompt_callback_thread_end callback.\n Cross References \n \u2022 ompt_callback_implicit_task_t, see Section 19.5.2.11 \n \u2022 ompt_callback_parallel_begin_t, see Section 19.5.2.3 \n \u2022 ompt_callback_parallel_end_t, see Section 19.5.2.4 \n \u2022 ompt_callback_thread_begin_t, see Section 19.5.2.1 \n \u2022 ompt_callback_thread_end_t, see Section 19.5.2.2 \n \u2022 ompt_task_flag_t, see Section 19.4.4.19 \n \u2022 ompt_thread_t, see Section 19.4.4.10 \nCHAPTER 12.TASKING CONSTRUCTS 271 \n"}
{"section_title": "12.9 Task Scheduling", "chunk": "2 Whenever a thread reaches a task scheduling point, the implementation may cause it to perform a \n task switch, beginning or resuming execution of a different task bound to the current team."}
{"section_title": "12.9 Task Scheduling", "chunk": "2 Whenever a thread reaches a task scheduling point, the implementation may cause it to perform a \n task switch, beginning or resuming execution of a different task bound to the current team.Task \n scheduling points are implied at the following locations: \n \u2022 during the generation of an explicit task; \n \u2022 the point immediately following the generation of an explicit task; \n \u2022 after the point of completion of the structured block associated with a task; \n \u2022 in a taskyield region; \n \u2022 in a taskwait region; \n \u2022 at the end of a taskgroup region; \n \u2022 in an implicit barrier region; \n \u2022 in an explicit barrier region; \n \u2022 during the generation of a target region; \n \u2022 the point immediately following the generation of a target region; \n \u2022 at the beginning and end of a target data region; \n \u2022 in a target update region; \n \u2022 in a target enter data region; \n \u2022 in a target exit data region; \n \u2022 in the omp_target_memcpy routine; \n \u2022 in the omp_target_memcpy_async routine; \n \u2022 in the omp_target_memcpy_rect routine; and \n \u2022 in the omp_target_memcpy_rect_async routine."}
{"section_title": "12.9 Task Scheduling", "chunk": "Task \n scheduling points are implied at the following locations: \n \u2022 during the generation of an explicit task; \n \u2022 the point immediately following the generation of an explicit task; \n \u2022 after the point of completion of the structured block associated with a task; \n \u2022 in a taskyield region; \n \u2022 in a taskwait region; \n \u2022 at the end of a taskgroup region; \n \u2022 in an implicit barrier region; \n \u2022 in an explicit barrier region; \n \u2022 during the generation of a target region; \n \u2022 the point immediately following the generation of a target region; \n \u2022 at the beginning and end of a target data region; \n \u2022 in a target update region; \n \u2022 in a target enter data region; \n \u2022 in a target exit data region; \n \u2022 in the omp_target_memcpy routine; \n \u2022 in the omp_target_memcpy_async routine; \n \u2022 in the omp_target_memcpy_rect routine; and \n \u2022 in the omp_target_memcpy_rect_async routine.\n When a thread encounters a task scheduling point it may do one of the following, subject to the \n Task Scheduling Constraints (below): \n \u2022 begin execution of a tied task bound to the current team; \n \u2022 resume any suspended task region, bound to the current team, to which it is tied; \n \u2022 begin execution of an untied task bound to the current team; or \n \u2022 resume any suspended untied task region bound to the current team."}
{"section_title": "12.9 Task Scheduling", "chunk": "\n When a thread encounters a task scheduling point it may do one of the following, subject to the \n Task Scheduling Constraints (below): \n \u2022 begin execution of a tied task bound to the current team; \n \u2022 resume any suspended task region, bound to the current team, to which it is tied; \n \u2022 begin execution of an untied task bound to the current team; or \n \u2022 resume any suspended untied task region bound to the current team.\n If more than one of the above choices is available, which one is chosen is unspecified.\n OpenMP API \u2013 Version 5.2 November 2021 \n Task Scheduling Constraints are as follows: \n 1.Scheduling of new tied tasks is constrained by the set of task regions that are currently tied to the \n thread and that are not suspended in a barrier region.If this set is empty, any new tied task may \n be scheduled.Otherwise, a new tied task may be scheduled only if it is a descendent task of \n every task in the set.\n 2."}
{"section_title": "12.9 Task Scheduling", "chunk": "\n 2.A dependent task shall not start its execution until its task dependences are fulfilled.\n 3.A task shall not be scheduled while any task with which it is mutually exclusive has been \n scheduled but has not yet completed.\n 4.When an explicit task is generated by a construct that contains an if clause for which the \n expression evaluated to false, and the previous constraints are already met, the task is executed \n immediately after generation of the task.\n A program that relies on any other assumption about task scheduling is non-conforming.\n \n Note \u2013 Task scheduling points dynamically divide task regions into parts.Each part is executed \n uninterrupted from start to end.Different parts of the same task region are executed in the order in \n which they are encountered.In the absence of task synchronization constructs, the order in which a \n thread executes parts of different schedulable tasks is unspecified."}
{"section_title": "12.9 Task Scheduling", "chunk": "In the absence of task synchronization constructs, the order in which a \n thread executes parts of different schedulable tasks is unspecified.\n A program must behave correctly and consistently with all conceivable scheduling sequences that \n are compatible with the rules above.\n For example, if threadprivate storage is accessed (explicitly in the source code or implicitly \n in calls to library routines) in one part of a task region, its value cannot be assumed to be preserved \n into the next part of the same task region if another schedulable task exists that modifies it.\n As another example, if a lock acquire and release happen in different parts of a task region, no \n attempt should be made to acquire the same lock in any part of another task that the executing \n thread may schedule.Otherwise, a deadlock is possible."}
{"section_title": "12.9 Task Scheduling", "chunk": "Otherwise, a deadlock is possible.A similar situation can occur when a \n critical region spans multiple parts of a task and another schedulable task contains a \n critical region with the same name.\n The use of threadprivate variables and the use of locks or critical sections in an explicit task with an \n if clause must take into account that when the if clause evaluates to false, the task is executed \n immediately, without regard to Task Scheduling Constraint 2.\n \n Execution Model Events \n The task-schedule event occurs in a thread when the thread switches tasks at a task scheduling \n point; no event occurs when switching to or from a merged task.\nCHAPTER 12.TASKING CONSTRUCTS 273 \n Tool Callbacks \n A thread dispatches a registered ompt_callback_task_schedule callback for each \n occurrence of a task-schedule event in the context of the task that begins or resumes.This callback \n has the type signature ompt_callback_task_schedule_t."}
{"section_title": "12.9 Task Scheduling", "chunk": "This callback \n has the type signature ompt_callback_task_schedule_t.The argument prior_task_status \n is used to indicate the cause for suspending the prior task.This cause may be the completion of the \n prior task region, the encountering of a taskyield construct, or the encountering of an active \n cancellation point.\n Cross References \n \u2022 ompt_callback_task_schedule_t, see Section 19.5.2.10 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "13 Device Directives and Clauses", "chunk": "2 This chapter defines constructs and concepts related to device execution.\n"}
{"section_title": "13.1 device_type Clause", "chunk": "4 Name: device_type Properties: unique \n Arguments \nName Type Properties \ndevice-type-description Keyword: any, host, nohost default 6 \n Directives \n begin declare target, declare target \n Semantics \n The device_type clause specifies if a version of the procedure or variable should be made \n available on the host device, non-host devices or both the host device and non-host devices.If \n host is specified then only a host device version of the procedure or variable is made available.If \n any is specified then both host device and non-host device versions of the procedure or variable are \n made available.If nohost is specified for a procedure then only non-host device versions of the \n procedure are made available.If nohost is specified for a variable then that variable is not \n available on the host device.If the device_type clause is not specified, the behavior is as if the \n device_type clause appears with any specified."}
{"section_title": "13.1 device_type Clause", "chunk": "If the device_type clause is not specified, the behavior is as if the \n device_type clause appears with any specified.\n Cross References \n \u2022 begin declare target directive, see Section 7.8.2 \n \u2022 declare target directive, see Section 7.8.1 \n \n"}
{"section_title": "13.2 device Clause", "chunk": "2 Name: device Properties: unique \n Arguments \nName Type Properties \ndevice-description expression of integer type default 4 \n Modifiers \nName Modifies Type Properties \ndevice-modifier device-description Keyword: ancestor, \ndevice_num \n default \n Directives \n dispatch, interop, target, target data, target enter data, target exit \n data, target update \n Semantics \n The device clause identifies the target device that is associated with a device construct.\n If device_num is specified as the device-modifier, the device-description specifies the device \n number of the target device.If device-modifier does not appear in the clause, the behavior of the \n clause is as if device-modifier is device_num.If the device-description evaluates to \n omp_invalid_device, runtime error termination is performed.\n If ancestor is specified as the device-modifier, the device-description specifies the number of \n target nesting level of the target device."}
{"section_title": "13.2 device Clause", "chunk": "\n If ancestor is specified as the device-modifier, the device-description specifies the number of \n target nesting level of the target device.Specifically, if the device-description evaluates to 1, the \n target device is the parent device of the enclosing target region.If the construct on which the \n device clause appears is not encountered in a target region, the current device is treated as the \n parent device.\n Unless otherwise specified, for directives that accept the device clause, if no device clause is \n present, the behavior is as if the device clause appears without a device-modifier and with a \n device-description that evaluates to the value of the default-device-var ICV.\n Restrictions \n \u2022 The ancestor device-modifier must not appear on the device clause on any directive other \n than the target construct."}
{"section_title": "13.2 device Clause", "chunk": "\n Restrictions \n \u2022 The ancestor device-modifier must not appear on the device clause on any directive other \n than the target construct.\n \u2022 If the ancestor device-modifier is specified, the device-description must evaluate to 1 \n and a requires directive with the reverse_offload clause must be specified; \n \u2022 If the device_num device-modifier is specified and target-offload-var is not mandatory, \n device-description must evaluate to a conforming device number.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 dispatch directive, see Section 7.6 \n \u2022 interop directive, see Section 14.1 \n \u2022 target data directive, see Section 13.5 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \n \u2022 target-offload-var ICV, see Table 2.1 \n"}
{"section_title": "13.3 thread_limit Clause", "chunk": "11 Name: thread_limit Properties: unique \n Arguments \nName Type Properties \nthreadlim expression of integer type positive 13 \n Directives \n target, teams \n Semantics \n As described in Section 2.4, some constructs limit the number of threads that may participate in a \n contention group initiated by each team by setting the value of the thread-limit-var ICV for the \n initial task to an implementation-defined value greater than zero.If the thread_limit clause is \n specified, the number of threads will be less than or equal to threadlim.Otherwise, if the \n teams-thread-limit-var ICV is greater than zero, the effect is as if the thread_limit clause was \n specified with a threadlim that evaluates to an implementation defined value less than or equal to \n the teams-thread-limit-var ICV.\n Cross References \n \u2022 target directive, see Section 13.8 \n \u2022 teams directive, see Section 10.2 \nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 277 \n"}
{"section_title": "13.4 Device Initialization", "chunk": "2 Execution Model Events \n The device-initialize event occurs in a thread that begins initialization of OpenMP on the device, \n after the device\u2019s OpenMP initialization, which may include device-side tool initialization, \n completes.\n The device-load event for a code block for a target device occurs in some thread before any thread \n executes code from that code block on that target device.\n The device-unload event for a target device occurs in some thread whenever a code block is \n unloaded from the device.\n The device-finalize event for a target device that has been initialized occurs in some thread before \n an OpenMP implementation shuts down.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_device_initialize callback for each \n occurrence of a device-initialize event in that thread.This callback has type signature \n ompt_callback_device_initialize_t."}
{"section_title": "13.4 Device Initialization", "chunk": "This callback has type signature \n ompt_callback_device_initialize_t.\n A thread dispatches a registered ompt_callback_device_load callback for each occurrence \n of a device-load event in that thread.This callback has type signature \n ompt_callback_device_load_t.\n A thread dispatches a registered ompt_callback_device_unload callback for each \n occurrence of a device-unload event in that thread.This callback has type signature \n ompt_callback_device_unload_t.\n A thread dispatches a registered ompt_callback_device_finalize callback for each \n occurrence of a device-finalize event in that thread.This callback has type signature \n ompt_callback_device_finalize_t.\n Restrictions \n Restrictions to OpenMP device initialization are as follows: \n \u2022 No thread may offload execution of an OpenMP construct to a device until a dispatched \n ompt_callback_device_initialize callback completes."}
{"section_title": "13.4 Device Initialization", "chunk": "\n Restrictions \n Restrictions to OpenMP device initialization are as follows: \n \u2022 No thread may offload execution of an OpenMP construct to a device until a dispatched \n ompt_callback_device_initialize callback completes.\n \u2022 No thread may offload execution of an OpenMP construct to a device after a dispatched \n ompt_callback_device_finalize callback occurs.\n Cross References \n \u2022 ompt_callback_device_finalize_t, see Section 19.5.2.20 \n \u2022 ompt_callback_device_initialize_t, see Section 19.5.2.19 \n \u2022 ompt_callback_device_load_t, see Section 19.5.2.21 \n \u2022 ompt_callback_device_unload_t, see Section 19.5.2.22 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "13.5 target data Construct", "chunk": "Name: target data Association: block \nCategory: executable Properties: device, device-affecting, data\ufffemapping, map-entering, map-exiting, \nmapping-only \n \n Clauses \n device, if, map, use_device_addr, use_device_ptr \n Clause set data-environment-clause \nProperties: required Members: map, use_device_addr, \nuse_device_ptr 6 \n Binding \n The binding task set for a target data region is the generating task.The target data region \n binds to the region of the generating task.\n Semantics \n The target data construct maps variables to a device data environment.When a \n target data construct is encountered, the encountering task executes the region.When an if \n clause is present and the if clause expression evaluates to false, the target device is the host.\n Variables are mapped for the extent of the region, according to any data-mapping attribute clauses, \n from the data environment of the encountering task to the device data environment."}
{"section_title": "13.5 target data Construct", "chunk": "\n Variables are mapped for the extent of the region, according to any data-mapping attribute clauses, \n from the data environment of the encountering task to the device data environment.\n A list item that appears in a map clause may also appear in a use_device_ptr clause or a \n use_device_addr clause.If one or more map clauses are present, the list item conversions that \n are performed for any use_device_ptr or use_device_addr clause occur after all \n variables are mapped on entry to the region according to those map clauses.\n Execution Model Events \n The events associated with entering a target data region are the same events as associated with \n a target enter data construct, as described in Section 13.6.\n The events associated with exiting a target data region are the same events as associated with a \n target exit data construct, as described in Section 13.7."}
{"section_title": "13.5 target data Construct", "chunk": "\n The events associated with exiting a target data region are the same events as associated with a \n target exit data construct, as described in Section 13.7.\n Tool Callbacks \n The tool callbacks dispatched when entering a target data region are the same as the tool \n callbacks dispatched when encountering a target enter data construct, as described in \n Section 13.6.\n The tool callbacks dispatched when exiting a target data region are the same as the tool \n callbacks dispatched when encountering a target exit data construct, as described in \n Section 13.7.\nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 279 \n Restrictions \n Restrictions to the target data construct are as follows: \n \u2022 A map-type in a map clause must be to, from, tofrom or alloc.\n Cross References \n \u2022 device clause, see Section 13.2 \n \u2022 if clause, see Section 3.4 \n \u2022 map clause, see Section 5.8.3 \n \u2022 use_device_addr clause, see Section 5.4.10 \n \u2022 use_device_ptr clause, see Section 5.4.8 \n"}
{"section_title": "13.6 target enter data Construct", "chunk": "Name: target enter data Association: none \nCategory: executable Properties: parallelism-generating, task\ufffegenerating, device, device-affecting, data\ufffemapping, map-entering, mapping-only \n \n Clauses \n depend, device, if, map, nowait \n Binding \n The binding task set for a target enter data region is the generating task, which is the target \n task generated by the target enter data construct.The target enter data region binds \n to the corresponding target task region.\n Semantics \n When a target enter data construct is encountered, the list items are mapped to the device \n data environment according to the map clause semantics.The target enter data construct \n generates a target task.The generated task region encloses the target enter data region.If a \n depend clause is present, it is associated with the target task.If the nowait clause is present, \n execution of the target task may be deferred."}
{"section_title": "13.6 target enter data Construct", "chunk": "If the nowait clause is present, \n execution of the target task may be deferred.If the nowait clause is not present, the target task is \n an included task.\n All clauses are evaluated when the target enter data construct is encountered.The data \n environment of the target task is created according to the data-mapping attribute clauses on the \n target enter data construct, per-data environment ICVs, and any default data-sharing \n attribute rules that apply to the target enter data construct.If a variable or part of a variable \n is mapped by the target enter data construct, the variable has a default data-sharing attribute \n of shared in the data environment of the target task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Assignment operations associated with mapping a variable (see Section 5.8.3) occur when the \n target task executes.\n When an if clause is present and the if clause expression evaluates to false, the target device is \n the host."}
{"section_title": "13.6 target enter data Construct", "chunk": "\n When an if clause is present and the if clause expression evaluates to false, the target device is \n the host.\n Execution Model Events \n Events associated with a target task are the same as for the task construct defined in Section 12.5.\n The target-enter-data-begin event occurs after creation of the target task and completion of all \n predecessor tasks that are not target tasks for the same device.The target-enter-data-begin event is \n a target-task-begin event.\n The target-enter-data-end event occurs after all other events associated with the \n target enter data construct.\n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback."}
{"section_title": "13.6 target enter data Construct", "chunk": "\n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback.\n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target_enter_data or ompt_target_enter_data_nowait if \n the nowait clause is present as its kind argument for each occurrence of a target-enter-data-begin \n event in that thread in the context of the target task on the host."}
{"section_title": "13.6 target enter data Construct", "chunk": "\n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target_enter_data or ompt_target_enter_data_nowait if \n the nowait clause is present as its kind argument for each occurrence of a target-enter-data-begin \n event in that thread in the context of the target task on the host.Similarly, a thread dispatches a \n registered ompt_callback_target or ompt_callback_target_emi callback with \n ompt_scope_end as its endpoint argument and ompt_target_enter_data or \n ompt_target_enter_data_nowait if the nowait clause is present as its kind argument \n for each occurrence of a target-enter-data-end event in that thread in the context of the target task \n on the host.These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively."}
{"section_title": "13.6 target enter data Construct", "chunk": "These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively.\n Restrictions \n Restrictions to the target enter data construct are as follows: \n \u2022 At least one map clause must appear on the directive.\n \u2022 All map clauses must be map-entering.\n Cross References \n \u2022 ompt_callback_target_emi_t and ompt_callback_target_t, see \n Section 19.5.2.26 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 device clause, see Section 13.2 \n \u2022 if clause, see Section 3.4 \nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 281 \n \u2022 map clause, see Section 5.8.3 \n \u2022 nowait clause, see Section 15.6 \n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "13.7 target exit data Construct", "chunk": "Name: target exit data Association: none \nCategory: executable Properties: parallelism-generating, task\ufffegenerating, device, device-affecting, data\ufffemapping, map-exiting, mapping-only \n \n Clauses \n depend, device, if, map, nowait \n Binding \n The binding task set for a target exit data region is the generating task, which is the target \n task generated by the target exit data construct.The target exit data region binds to \n the corresponding target task region.\n Semantics \n When a target exit data construct is encountered, the list items in the map clauses are \n unmapped from the device data environment according to the map clause semantics.The \n target exit data construct generates a target task.The generated task region encloses the \n target exit data region.If a depend clause is present, it is associated with the target task.If \n the nowait clause is present, execution of the target task may be deferred."}
{"section_title": "13.7 target exit data Construct", "chunk": "If \n the nowait clause is present, execution of the target task may be deferred.If the nowait clause \n is not present, the target task is an included task.\n All clauses are evaluated when the target exit data construct is encountered.The data \n environment of the target task is created according to the data-mapping attribute clauses on the \n target exit data construct, per-data environment ICVs, and any default data-sharing attribute \n rules that apply to the target exit data construct.If a variable or part of a variable is mapped \n by the target exit data construct, the variable has a default data-sharing attribute of shared in \n the data environment of the target task.\n Assignment operations associated with mapping a variable (see Section 5.8.3) occur when the \n target task executes.\n When an if clause is present and the if clause expression evaluates to false, the target device is \n the host."}
{"section_title": "13.7 target exit data Construct", "chunk": "\n When an if clause is present and the if clause expression evaluates to false, the target device is \n the host.\n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n Events associated with a target task are the same as for the task construct defined in Section 12.5.\n The target-exit-data-begin event occurs after creation of the target task and completion of all \n predecessor tasks that are not target tasks for the same device.The target-exit-data-begin event is a \n target-task-begin event.\n The target-exit-data-end event occurs after all other events associated with the \n target exit data construct.\n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback."}
{"section_title": "13.7 target exit data Construct", "chunk": "\n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback.\n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target_exit_data or ompt_target_exit_data_nowait if the \n nowait clause is present as its kind argument for each occurrence of a target-exit-data-begin \n event in that thread in the context of the target task on the host.Similarly, a thread dispatches a \n registered ompt_callback_target or ompt_callback_target_emi callback with \n ompt_scope_end as its endpoint argument and ompt_target_exit_data or \n ompt_target_exit_data_nowait if the nowait clause is present as its kind argument for \n each occurrence of a target-exit-data-end event in that thread in the context of the target task on the \n host."}
{"section_title": "13.7 target exit data Construct", "chunk": "Similarly, a thread dispatches a \n registered ompt_callback_target or ompt_callback_target_emi callback with \n ompt_scope_end as its endpoint argument and ompt_target_exit_data or \n ompt_target_exit_data_nowait if the nowait clause is present as its kind argument for \n each occurrence of a target-exit-data-end event in that thread in the context of the target task on the \n host.These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively.\n Restrictions \n Restrictions to the target exit data construct are as follows: \n \u2022 At least one map clause must appear on the directive.\n \u2022 All map clauses must be a map-exiting."}
{"section_title": "13.7 target exit data Construct", "chunk": "\n \u2022 All map clauses must be a map-exiting.\n Cross References \n \u2022 ompt_callback_target_emi_t and ompt_callback_target_t, see \n Section 19.5.2.26 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 device clause, see Section 13.2 \n \u2022 if clause, see Section 3.4 \n \u2022 map clause, see Section 5.8.3 \n \u2022 nowait clause, see Section 15.6 \n \u2022 task directive, see Section 12.5 \nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 283 \n"}
{"section_title": "13.8 target Construct", "chunk": "Name: target Association: block \nCategory: executable Properties: parallelism-generating, thread\ufffelimiting, exception-aborting, task-generating, \ndevice, device-affecting, data-mapping, map\ufffeentering, map-exiting, context-matching \n \n Clauses \n allocate, defaultmap, depend, device, firstprivate, has_device_addr, if, \n in_reduction, is_device_ptr, map, nowait, private, thread_limit, \n uses_allocators \n Binding \n The binding task set for a target region is the generating task, which is the target task generated \n by the target construct.The target region binds to the corresponding target task region.\n Semantics \n The target construct provides a superset of the functionality provided by the target data \n directive, except for the use_device_ptr and use_device_addr clauses.The functionality \n added to the target directive is the inclusion of an executable region to be executed on a device.\n The target construct generates a target task."}
{"section_title": "13.8 target Construct", "chunk": "\n The target construct generates a target task.The generated task region encloses the target \n region.If a depend clause is present, it is associated with the target task.The device clause \n determines the device on which the target region executes.If the nowait clause is present, \n execution of the target task may be deferred.If the nowait clause is not present, the target task is \n an included task.\n All clauses are evaluated when the target construct is encountered.The data environment of the \n target task is created according to the data-sharing and data-mapping attribute clauses on the \n target construct, per-data environment ICVs, and any default data-sharing attribute rules that \n apply to the target construct."}
{"section_title": "13.8 target Construct", "chunk": "The data environment of the \n target task is created according to the data-sharing and data-mapping attribute clauses on the \n target construct, per-data environment ICVs, and any default data-sharing attribute rules that \n apply to the target construct.If a variable or part of a variable is mapped by the target \n construct and does not appear as a list item in an in_reduction clause on the construct, the \n variable has a default data-sharing attribute of shared in the data environment of the target task.\n Assignment operations associated with mapping a variable (see Section 5.8.3) occur when the \n target task executes.\n If the device clause is specified with the ancestor device-modifier, the encountering thread \n waits for completion of the target region on the parent device before resuming."}
{"section_title": "13.8 target Construct", "chunk": "\n If the device clause is specified with the ancestor device-modifier, the encountering thread \n waits for completion of the target region on the parent device before resuming.For any list item \n that appears in a map clause on the same construct, if the corresponding list item exists in the device \n data environment of the parent device, it is treated as if it has a reference count of positive infinity.\n When an if clause is present and the if clause expression evaluates to false, the effect is as if a \n device clause that specifies omp_initial_device as the device number is present, \n regardless of any other device clause on the directive.\n OpenMP API \u2013 Version 5.2 November 2021 \n If a procedure is explicitly or implicitly referenced in a target construct that does not specify a \n device clause in which the ancestor device-modifier appears then that procedure is treated as \n if its name had appeared in an enter clause on a declare target directive."}
{"section_title": "13.8 target Construct", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If a procedure is explicitly or implicitly referenced in a target construct that does not specify a \n device clause in which the ancestor device-modifier appears then that procedure is treated as \n if its name had appeared in an enter clause on a declare target directive.\n If a variable with static storage duration is declared in a target construct that does not specify a \n device clause in which the ancestor device-modifier appears then the named variable is \n treated as if it had appeared in a enter clause on a declare target directive."}
{"section_title": "13.8 target Construct", "chunk": "\n If a variable with static storage duration is declared in a target construct that does not specify a \n device clause in which the ancestor device-modifier appears then the named variable is \n treated as if it had appeared in a enter clause on a declare target directive.\nC / C++ \n If a list item in a map clause has a base pointer and it is a scalar variable with a predetermined \n data-sharing attribute of firstprivate (see Section 5.1.1), then on entry to the target region: \n \u2022 If the list item is not a zero-length array section, the corresponding private variable is initialized \n such that the corresponding list item in the device data environment can be accessed through the \n pointer in the target region.\n \u2022 If the list item is a zero-length array section , the corresponding private variable is initialized \n according to Section 5.8.6."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 If the list item is a zero-length array section , the corresponding private variable is initialized \n according to Section 5.8.6.\nC / C++ \nFortran \n When an internal procedure is called in a target region, any references to variables that are host \n associated in the procedure have unspecified behavior.\nFortran \n Execution Model Events \n Events associated with a target task are the same as for the task construct defined in Section 12.5.\n Events associated with the initial task that executes the target region are defined in Section 12.8.\n The target-submit-begin event occurs prior to initiating creation of an initial task on a target device \n for a target region.\n The target-submit-end event occurs after initiating creation of an initial task on a target device for a \n target region.\n The target-begin event occurs after creation of the target task and completion of all predecessor \n tasks that are not target tasks for the same device."}
{"section_title": "13.8 target Construct", "chunk": "\n The target-begin event occurs after creation of the target task and completion of all predecessor \n tasks that are not target tasks for the same device.The target-begin event is a target-task-begin \n event.\n The target-end event occurs after all other events associated with the target construct.\n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback.\nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 285 \n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target or ompt_target_nowait if the nowait clause is present as its \n kind argument for each occurrence of a target-begin event in that thread in the context of the target \n task on the host."}
{"section_title": "13.8 target Construct", "chunk": "DEVICE DIRECTIVES AND CLAUSES 285 \n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target or ompt_target_nowait if the nowait clause is present as its \n kind argument for each occurrence of a target-begin event in that thread in the context of the target \n task on the host.Similarly, a thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_end as its endpoint argument \n and ompt_target or ompt_target_nowait if the nowait clause is present as its kind \n argument for each occurrence of a target-end event in that thread in the context of the target task on \n the host.These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively."}
{"section_title": "13.8 target Construct", "chunk": "These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively.\n A thread dispatches a registered ompt_callback_target_submit_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-submit-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_submit_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-submit-end event in that thread.These callbacks have type \n signature ompt_callback_target_submit_emi_t.\n A thread dispatches a registered ompt_callback_target_submit callback for each \n occurrence of a target-submit-begin event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_submit_t."}
{"section_title": "13.8 target Construct", "chunk": "The callback occurs in the context of the \n target task and has type signature ompt_callback_target_submit_t.\n Restrictions \n Restrictions to the target construct are as follows: \n \u2022 Device-affecting constructs, other than target constructs for which the ancestor \n device-modifier is specified, must not be encountered during execution of a target region.\n \u2022 The result of an omp_set_default_device, omp_get_default_device, or \n omp_get_num_devices routine called within a target region is unspecified.\n \u2022 The effect of an access to a threadprivate variable in a target region is unspecified.\n \u2022 If a list item in a map clause is a structure element, any other element of that structure that is \n referenced in the target construct must also appear as a list item in a map clause.\n \u2022 A list item in a data-sharing attribute clause that is specified on a target construct must not \n have the same base variable as a list item in a map clause on the construct."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 A list item in a data-sharing attribute clause that is specified on a target construct must not \n have the same base variable as a list item in a map clause on the construct.\n \u2022 A variable referenced in a target region but not the target construct that is not declared in \n the target region must appear in a declare target directive.\n \u2022 A map-type in a map clause must be to, from, tofrom or alloc.\n \u2022 If a device clause is specified with the ancestor device-modifier, only the device, \n firstprivate, private, defaultmap, and map clauses may appear on the construct and \n no OpenMP constructs or calls to OpenMP API runtime routines are allowed inside the \n corresponding target region.\n \u2022 Memory allocators that do not appear in a uses_allocators clause cannot appear as an \n allocator in an allocate clause or be used in the target region unless a requires \n directive with the dynamic_allocators clause is present in the same compilation unit."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 Memory allocators that do not appear in a uses_allocators clause cannot appear as an \n allocator in an allocate clause or be used in the target region unless a requires \n directive with the dynamic_allocators clause is present in the same compilation unit.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 Any IEEE floating-point exception status flag, halting mode, or rounding mode set prior to a \n target region is unspecified in the region.\n \u2022 Any IEEE floating-point exception status flag, halting mode, or rounding mode set in a target \n region is unspecified upon exiting the region.\n \u2022 A program must not rely on the value of a function address in a target region except for \n assignments, comparisons to zero and indirect calls.\nC / C++ \n \u2022 An attached pointer must not be modified in a target region.\nC / C++ \nC++ \n \u2022 The run-time type information (RTTI) of an object can only be accessed from the device on \n which it was constructed."}
{"section_title": "13.8 target Construct", "chunk": "\nC / C++ \nC++ \n \u2022 The run-time type information (RTTI) of an object can only be accessed from the device on \n which it was constructed.\n \u2022 Invoking a virtual member function of an object on a device other than the device on which the \n object was constructed results in unspecified behavior, unless the object is accessible and was \n constructed on the host device.\n \u2022 If an object of polymorphic class type is destructed, virtual member functions of any previously \n existing corresponding objects in other device data environments must not be invoked.\nC++ \nFortran \n \u2022 An attached pointer that is associated with a given pointer target must not become associated \n with a different pointer target in a target region.\n \u2022 If a list item in a map clause is an array section, and the array section is derived from a variable \n with a POINTER or ALLOCATABLE attribute then the behavior is unspecified if the \n corresponding list item\u2019s variable is modified in the region."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 If a list item in a map clause is an array section, and the array section is derived from a variable \n with a POINTER or ALLOCATABLE attribute then the behavior is unspecified if the \n corresponding list item\u2019s variable is modified in the region.\n \u2022 A reference to a coarray that is encountered on a non-host device must not be coindexed or appear \n as an actual argument to a procedure where the corresponding dummy argument is a coarray.\n \u2022 If the allocation status of a mapped variable that has the ALLOCATABLE attribute is unallocated \n on entry to a target region, the allocation status of the corresponding variable in the device \n data environment must be unallocated upon exiting the region."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 If the allocation status of a mapped variable that has the ALLOCATABLE attribute is unallocated \n on entry to a target region, the allocation status of the corresponding variable in the device \n data environment must be unallocated upon exiting the region.\n \u2022 If the allocation status of a mapped variable that has the ALLOCATABLE attribute is allocated on \n entry to a target region, the allocation status and shape of the corresponding variable in the \n device data environment may not be changed, either explicitly or implicitly, in the region after \n entry to it.\n \u2022 If the association status of a list item with the POINTER attribute that appears in a map clause \n on the construct is associated upon entry to the target region, the list item must be associated \n with the same pointer target upon exit from the region.\nCHAPTER 13."}
{"section_title": "13.8 target Construct", "chunk": "\nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 287 \n \u2022 If the association status of a list item with the POINTER attribute that appears in a map clause \n on the construct is disassociated upon entry to the target region, the list item must be \n disassociated upon exit from the region.\n \u2022 If the association status of a list item with the POINTER attribute that appears in a map clause \n on the construct is undefined on entry to the target region, the association status of the list \n item must not be associated upon exit from the region.\n \u2022 A program must not rely on the association status of a procedure pointer in a target region \n except for calls to the ASSOCIATED inquiry function without the optional proc-target argument, \n pointer assignments and indirect calls."}
{"section_title": "13.8 target Construct", "chunk": "\n \u2022 A program must not rely on the association status of a procedure pointer in a target region \n except for calls to the ASSOCIATED inquiry function without the optional proc-target argument, \n pointer assignments and indirect calls.\nFortran \n Cross References \n \u2022 ompt_callback_target_emi_t and ompt_callback_target_t, see \n Section 19.5.2.26 \n \u2022 ompt_callback_target_submit_emi_t and \n ompt_callback_target_submit_t, see Section 19.5.2.28 \n \u2022 allocate clause, see Section 6.6 \n \u2022 defaultmap clause, see Section 5.8.7 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 device clause, see Section 13.2 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 has_device_addr clause, see Section 5.4.9 \n \u2022 if clause, see Section 3.4 \n \u2022 in_reduction clause, see Section 5.5.10 \n \u2022 is_device_ptr clause, see Section 5.4.7 \n \u2022 map clause, see Section 5.8.3 \n \u2022 nowait clause, see Section 15.6 \n \u2022 private clause, see Section 5.4.3 \n \u2022 target data directive, see Section 13.5 \n \u2022 task directive, see Section 12.5 \n \u2022 thread_limit clause, see Section 13.3 \n \u2022 uses_allocators clause, see Section 6.8 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "13.9 target update Construct", "chunk": "Name: target update Association: none \nCategory: executable Properties: parallelism-generating, task\ufffegenerating, device, device-affecting \n \n Clauses \n depend, device, from, if, nowait, to \n Clause set \n Properties: required Members: from, to \n Binding \n The binding task set for a target update region is the generating task, which is the target task \n generated by the target update construct.The target update region binds to the \n corresponding target task region.\n Semantics \n The target update directive makes the corresponding list items in the device data environment \n consistent with their original list items, according to the specified data-motion-clauses.The \n target update construct generates a target task.The generated task region encloses the \n target update region.If a depend clause is present, it is associated with the target task.If the \n nowait clause is present, execution of the target task may be deferred."}
{"section_title": "13.9 target update Construct", "chunk": "If the \n nowait clause is present, execution of the target task may be deferred.If the nowait clause is \n not present, the target task is an included task.\n All clauses are evaluated when the target update construct is encountered.The data \n environment of the target task is created according to data-motion-clauses on the \n target update construct, per-data environment ICVs, and any default data-sharing attribute \n rules that apply to the target update construct.If a variable or part of a variable is a list item in \n a data-motion-clause on the target update construct, the variable has a default data-sharing \n attribute of shared in the data environment of the target task.\n Assignment operations associated with any motion clauses occur when the target task executes.\n When an if clause is present and the if clause expression evaluates to false, no assignments occur."}
{"section_title": "13.9 target update Construct", "chunk": "\n When an if clause is present and the if clause expression evaluates to false, no assignments occur.\n Execution Model Events \n Events associated with a target task are the same as for the task construct defined in Section 12.5.\n The target-update-begin event occurs after creation of the target task and completion of all \n predecessor tasks that are not target tasks for the same device.\n The target-update-end event occurs after all other events associated with the target update \n construct.\n The target-data-op-begin event occurs in the target update region before a thread initiates a \n data operation on the target device.\n The target-data-op-end event occurs in the target update region after a thread initiates a data \n operation on the target device.\nCHAPTER 13."}
{"section_title": "13.9 target update Construct", "chunk": "\nCHAPTER 13.DEVICE DIRECTIVES AND CLAUSES 289 \n Tool Callbacks \n Callbacks associated with events for target tasks are the same as for the task construct defined in \n Section 12.5; (flags & ompt_task_target) always evaluates to true in the dispatched callback.\n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target_update or ompt_target_update_nowait if the nowait \n clause is present as its kind argument for each occurrence of a target-update-begin event in that \n thread in the context of the target task on the host."}
{"section_title": "13.9 target update Construct", "chunk": "\n A thread dispatches a registered ompt_callback_target or \n ompt_callback_target_emi callback with ompt_scope_begin as its endpoint \n argument and ompt_target_update or ompt_target_update_nowait if the nowait \n clause is present as its kind argument for each occurrence of a target-update-begin event in that \n thread in the context of the target task on the host.Similarly, a thread dispatches a registered \n ompt_callback_target or ompt_callback_target_emi callback with \n ompt_scope_end as its endpoint argument and ompt_target_update or \n ompt_target_update_nowait if the nowait clause is present as its kind argument for each \n occurrence of a target-update-end event in that thread in the context of the target task on the host.\n These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively."}
{"section_title": "13.9 target update Construct", "chunk": "\n These callbacks have type signature ompt_callback_target_t or \n ompt_callback_target_emi_t, respectively.\n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t."}
{"section_title": "13.9 target update Construct", "chunk": "The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Cross References \n \u2022 ompt_callback_target_emi_t and ompt_callback_target_t, see \n Section 19.5.2.26 \n \u2022 ompt_callback_task_create_t, see Section 19.5.2.7 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 device clause, see Section 13.2 \n \u2022 from clause, see Section 5.9.2 \n \u2022 if clause, see Section 3.4 \n \u2022 nowait clause, see Section 15.6 \n \u2022 task directive, see Section 12.5 \n \u2022 to clause, see Section 5.9.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "14 Interoperability", "chunk": "2 An OpenMP implementation may interoperate with one or more foreign runtime environments \n through the use of the interop construct that is described in this chapter, the interop operation \n for a declared variant function and the interoperability routines that are available through the \n OpenMP Runtime API.\nC / C++ \n The implementation must provide foreign-runtime-id values that are enumerators of type \n omp_interop_fr_t and that correspond to the supported foreign runtime environments.\nC / C++ \nFortran \n The implementation must provide foreign-runtime-id values that are named integer constants with \n kind omp_interop_fr_kind and that correspond to the supported foreign runtime \n environments.\nFortran \n Each foreign-runtime-id value provided by an implementation will be available as \n omp_ifr_name, where name is the name of the foreign runtime environment."}
{"section_title": "14 Interoperability", "chunk": "\nFortran \n Each foreign-runtime-id value provided by an implementation will be available as \n omp_ifr_name, where name is the name of the foreign runtime environment.Available names \n include those that are listed in the OpenMP Additional Definitions document; \n implementation-defined names may also be supported.The value of omp_ifr_last is defined as \n one greater than the value of the highest supported foreign-runtime-id value that is listed in the \n aforementioned document.\n Cross References \n \u2022 Interoperability Routines, see Section 18.12 \n"}
{"section_title": "14.1 interop Construct", "chunk": "Name: interop Association: none \nCategory: executable Properties: device 20 \n Clauses \n depend, destroy, device, init, nowait, use \n Clause set action-clause \n Properties: required Members: destroy, init, use \nCHAPTER 14.INTEROPERABILITY 291 \n Binding \n The binding task set for an interop region is the generating task.The interop region binds to \n the region of the generating task.\n Semantics \n The interop construct retrieves interoperability properties from the OpenMP implementation to \n enable interoperability with foreign execution contexts.When an interop construct is \n encountered, the encountering task executes the region.\n For each action-clause, the interop-type set is the set of interop-type modifiers specified for the \n clause if the clause is init or for the init clause that initialized the interop-var that is specified for \n the clause if the clause is not init.\n If the interop-type set includes targetsync, an empty mergeable task is generated."}
{"section_title": "14.1 interop Construct", "chunk": "\n If the interop-type set includes targetsync, an empty mergeable task is generated.If the \n nowait clause is not present on the construct then the task is also an included task.Any depend \n clauses that are present on the construct apply to the generated task.\n The interop construct ensures an ordered execution of the generated task relative to foreign tasks \n executed in the foreign execution context through the foreign synchronization object that is \n accessible through the targetsync property.When the creation of the foreign task precedes the \n encountering of an interop construct in happens before order (see Section 1.4.5), the foreign \n task must complete execution before the generated task begins execution.Similarly, when the \n creation of a foreign task follows the encountering of an interop construct in happens before \n order, the foreign task must not begin execution until the generated task completes execution."}
{"section_title": "14.1 interop Construct", "chunk": "Similarly, when the \n creation of a foreign task follows the encountering of an interop construct in happens before \n order, the foreign task must not begin execution until the generated task completes execution.No \n ordering is imposed between the encountering thread and either foreign tasks or OpenMP tasks by \n the interop construct.\n If the interop-type set does not include targetsync, the nowait clause has no effect.\n Restrictions \n Restrictions to the interop construct are as follows: \n \u2022 A depend clause can only appear on the directive if the interop-type includes targetsync.\n \u2022 Each interop-var may be specified for at most one action-clause of each interop construct."}
{"section_title": "14.1 interop Construct", "chunk": "\n \u2022 Each interop-var may be specified for at most one action-clause of each interop construct.\n Cross References \n \u2022 Interoperability Routines, see Section 18.12 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 destroy clause, see Section 3.5 \n \u2022 device clause, see Section 13.2 \n \u2022 init clause, see Section 14.1.2 \n \u2022 nowait clause, see Section 15.6 \n \u2022 use clause, see Section 14.1.3 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "14.1.1 OpenMP Foreign Runtime Identifiers", "chunk": "2 An OpenMP foreign runtime identifier, foreign-runtime-id, is a base language string literal or a \n compile-time constant OpenMP integer expression.Allowed values for foreign-runtime-id include \n the names (as string literals) and integer values that the OpenMP Additional Definitions document \n specifies and the corresponding omp_ifr_name constants of OpenMP interop_fr type.\n Implementation-defined values for foreign-runtime-id may also be supported.\n"}
{"section_title": "14.1.2 init Clause", "chunk": "8 Name: init Properties: default \n Arguments \nName Type Properties \ninterop-var variable of omp_interop_t type default 10 \n Modifiers \nName Modifies Type Properties \ninterop-preference Generic Complex, name: \nprefer_type Arguments: \npreference_list OpenMP \nforeign runtime preference \nlist (default) \ncomplex, unique \ninterop-type Generic Keyword: target, \ntargetsync \nrepeatable, re\ufffequired \n \n Directives \n interop \n Semantics \n The init clause specifies that interop-var is initialized to refer to the list of properties associated \n with any interop-type.For any interop-type, the properties type, type_name, vendor, \n vendor_name and device_num will be available.If the implementation cannot initialize \n interop-var, it is initialized to the value of omp_interop_none, which is defined to be zero."}
{"section_title": "14.1.2 init Clause", "chunk": "If the implementation cannot initialize \n interop-var, it is initialized to the value of omp_interop_none, which is defined to be zero.\n The targetsync interop-type will additionally provide the targetsync property, which is the \n handle to a foreign synchronization object for enabling synchronization between OpenMP tasks and \n foreign tasks that execute in the foreign execution context.\n The target interop-type will additionally provide the following properties: \n \u2022 device, which will be a foreign device handle; \n \u2022 device_context, which will be a foreign device context handle; and \n \u2022 platform, which will be a handle to a foreign platform of the device.\nCHAPTER 14.INTEROPERABILITY 293 \n If the prefer_type interop-modifier clause is specified, the first supported foreign-runtime-id in \n preference-list in left-to-right order is used."}
{"section_title": "14.1.2 init Clause", "chunk": "INTEROPERABILITY 293 \n If the prefer_type interop-modifier clause is specified, the first supported foreign-runtime-id in \n preference-list in left-to-right order is used.The foreign-runtime-id that is used if the \n implementation does not support any of the items in preference-list is implementation defined.\n Restrictions \n Restrictions to the init clause are as follows: \n \u2022 Each interop-type may be specified at most once.\n \u2022 interop-var must be non-const.\n Cross References \n \u2022 OpenMP Foreign Runtime Identifiers, see Section 14.1.1 \n \u2022 interop directive, see Section 14.1 \n"}
{"section_title": "14.1.3 use Clause", "chunk": "12 Name: use Properties: default \n Arguments \nName Type Properties \ninterop-var variable of omp_interop_t type default 14 \n Directives \n interop \n Semantics \n The use clause specifies the interop-var that is used for the effects of the directive on which the \n clause appears.However, interop-var is not initialized, destroyed or otherwise modified.The \n interop-type is inferred based on the interop-type used to initialize interop-var.\n Cross References \n \u2022 interop directive, see Section 14.1 \n"}
{"section_title": "14.2 Interoperability Requirement Set", "chunk": "24 The interoperability requirement set of each task is a logical set of properties that can be added or \n removed by different directives.These properties can be queried by other constructs that have \n interoperability semantics.\n A construct can add the following properties to the set: \n \u2022 depend, which specifies that the construct requires enforcement of the synchronization \n relationship expressed by the depend clause; \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 nowait, which specifies that the construct is asynchronous; and \n \u2022 is_device_ptr(list-item), which specifies that the list-item is a device pointer in the construct.\n The following directives may add properties to the set: \n \u2022 dispatch.\n The following directives may remove properties from the set: \n \u2022 declare variant.\n Cross References \n \u2022 Declare Variant Directives, see Section 7.5 \n \u2022 dispatch directive, see Section 7.6 \nCHAPTER 14.INTEROPERABILITY 295 \n"}
{"section_title": "15 Synchronization Constructs and Clauses", "chunk": "2 Clauses \n A synchronization construct orders the completion of code executed by different threads.This \n ordering is imposed by synchronizing flush operations that are executed as part of the region that \n corresponds to the construct.\n Synchronization through the use of synchronizing flush operations and atomic operations is \n described in Section 1.4.4 and Section 1.4.6.Section 15.8.6 defines the behavior of synchronizing \n flush operations that are implied at various other locations in an OpenMP program.\n"}
{"section_title": "15.1 Synchronization Hints", "chunk": "10 The programmer can provide hints about the expected dynamic behavior or suggested \n implementation of a lock by using omp_init_lock_with_hint or \n omp_init_nest_lock_with_hint to initialize it.Synchronization hints may also be \n provided for atomic and critical directives by using the hint clause.The effect of a hint \n does not change the semantics of the associated construct; if ignoring the hint changes the program \n semantics, the result is unspecified.\n Cross References \n \u2022 hint clause, see Section 15.1.2 \n \u2022 omp_init_lock_with_hint and omp_init_nest_lock_with_hint, see \n Section 18.9.2 \n"}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "21 Synchronization hints are specified with an OpenMP sync_hint type.The C/C++ header file \n (omp.h) and the Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) define \n the valid hint constants."}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "The C/C++ header file \n (omp.h) and the Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) define \n the valid hint constants.The valid constants must include the following, which can be extended \n with implementation-defined values: \nC / C++ \n typedef enum omp_sync_hint_t { \n omp_sync_hint_none = 0x0, \n omp_lock_hint_none = omp_sync_hint_none, \n omp_sync_hint_uncontended = 0x1, \n omp_lock_hint_uncontended = omp_sync_hint_uncontended, \n OpenMP API \u2013 Version 5.2 November 2021 \n omp_sync_hint_contended = 0x2, \n omp_lock_hint_contended = omp_sync_hint_contended, \n omp_sync_hint_nonspeculative = 0x4, \n omp_lock_hint_nonspeculative = omp_sync_hint_nonspeculative, \n omp_sync_hint_speculative = 0x8, \n omp_lock_hint_speculative = omp_sync_hint_speculative \n } omp_sync_hint_t; \n \n typedef omp_sync_hint_t omp_lock_hint_t; \nC / C++ \nFortran \n integer, parameter :: omp_lock_hint_kind = omp_sync_hint_kind \n \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_none = & \n int(Z\u20190\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_none = omp_sync_hint_none \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_uncontended = & \n int(Z\u20191\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_uncontended = & \n omp_sync_hint_uncontended \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_contended = & \n int(Z\u20192\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_contended = & \n omp_sync_hint_contended \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_nonspeculative = & \n int(Z\u20194\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_nonspeculative = & \n omp_sync_hint_nonspeculative \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_speculative = & \n int(Z\u20198\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_speculative = & \n omp_sync_hint_speculative \nFortran \nCHAPTER 15."}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "The valid constants must include the following, which can be extended \n with implementation-defined values: \nC / C++ \n typedef enum omp_sync_hint_t { \n omp_sync_hint_none = 0x0, \n omp_lock_hint_none = omp_sync_hint_none, \n omp_sync_hint_uncontended = 0x1, \n omp_lock_hint_uncontended = omp_sync_hint_uncontended, \n OpenMP API \u2013 Version 5.2 November 2021 \n omp_sync_hint_contended = 0x2, \n omp_lock_hint_contended = omp_sync_hint_contended, \n omp_sync_hint_nonspeculative = 0x4, \n omp_lock_hint_nonspeculative = omp_sync_hint_nonspeculative, \n omp_sync_hint_speculative = 0x8, \n omp_lock_hint_speculative = omp_sync_hint_speculative \n } omp_sync_hint_t; \n \n typedef omp_sync_hint_t omp_lock_hint_t; \nC / C++ \nFortran \n integer, parameter :: omp_lock_hint_kind = omp_sync_hint_kind \n \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_none = & \n int(Z\u20190\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_none = omp_sync_hint_none \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_uncontended = & \n int(Z\u20191\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_uncontended = & \n omp_sync_hint_uncontended \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_contended = & \n int(Z\u20192\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_contended = & \n omp_sync_hint_contended \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_nonspeculative = & \n int(Z\u20194\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_nonspeculative = & \n omp_sync_hint_nonspeculative \n integer (kind=omp_sync_hint_kind), & \n parameter :: omp_sync_hint_speculative = & \n int(Z\u20198\u2019, kind=omp_sync_hint_kind) \n integer (kind=omp_lock_hint_kind), & \n parameter :: omp_lock_hint_speculative = & \n omp_sync_hint_speculative \nFortran \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 297 \n The hints can be combined by using the + or | operators in C/C++ or the + operator in Fortran."}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "SYNCHRONIZATION CONSTRUCTS AND CLAUSES 297 \n The hints can be combined by using the + or | operators in C/C++ or the + operator in Fortran.\n Combining omp_sync_hint_none with any other hint is equivalent to specifying the other hint."}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "\n Combining omp_sync_hint_none with any other hint is equivalent to specifying the other hint.\n The intended meaning of each hint is: \n \u2022 omp_sync_hint_uncontended: low contention is expected in this operation, that is, few \n threads are expected to perform the operation simultaneously in a manner that requires \n synchronization; \n \u2022 omp_sync_hint_contended: high contention is expected in this operation, that is, many \n threads are expected to perform the operation simultaneously in a manner that requires \n synchronization; \n \u2022 omp_sync_hint_speculative: the programmer suggests that the operation should be \n implemented using speculative techniques such as transactional memory; and \n \u2022 omp_sync_hint_nonspeculative: the programmer suggests that the operation should \n not be implemented using speculative techniques such as transactional memory.\n \n Note \u2013 Future OpenMP specifications may add additional hints to the sync_hint type."}
{"section_title": "15.1.1 Synchronization Hint Type", "chunk": "\n \n Note \u2013 Future OpenMP specifications may add additional hints to the sync_hint type.\n Implementers are advised to add implementation-defined hints starting from the most significant bit \n of the type and to include the name of the implementation in the name of the added hint to avoid \n name conflicts with other OpenMP implementations.\n \n The OpenMP sync_hint and lock_hint types are synonyms for each other.The OpenMP \n lock_hint type has been deprecated.\n Restrictions \n Restrictions to the synchronization hints are as follows: \n \u2022 The hints omp_sync_hint_uncontended and omp_sync_hint_contended cannot \n be combined.\n \u2022 The hints omp_sync_hint_nonspeculative and omp_sync_hint_speculative \n cannot be combined.\n The restrictions for combining multiple values of the OpenMP sync_hint type apply equally to \n the corresponding values of the OpenMP lock_hint type, and expressions that mix the two \n types.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "15.1.2 hint Clause", "chunk": "2 Name: hint Properties: unique \n Arguments \nName Type Properties \nhint-expr expression of sync_hint type default 4 \n Directives \n atomic, critical \n Semantics \n The hint clause gives the implementation additional information about the expected runtime \n properties of the region that corresponds to the construct on which it appears and that can \n optionally be used to optimize the implementation.The presence of a hint clause does not affect \n the semantics of the construct.If no hint clause is specified for a construct that accepts it, the \n effect is as if hint(omp_sync_hint_none) had been specified.\n Restrictions \n \u2022 hint-expr must evaluate to a valid synchronization hint.\n Cross References \n \u2022 Synchronization Hint Type, see Section 15.1.1 \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 critical directive, see Section 15.2 \n"}
{"section_title": "15.2 critical Construct", "chunk": "Name: critical Association: block \nCategory: executable Properties: thread-limiting 20 \n Arguments \n critical(name) \nName Type Properties \nname base language identifier optional 23 \n Clauses \n hint \n Binding \n The binding thread set for a critical region is all threads in the contention group.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 299 \n Semantics \n The name argument is used to identify the critical construct.For any critical construct for \n which name is not specified, the effect is as if an identical (unspecified) name was specified.The \n region that corresponds to a critical construct of a given name is executed as if only a single \n thread at a time among all threads in the contention group executes the region, without regard to the \n teams to which the threads belong."}
{"section_title": "15.2 critical Construct", "chunk": "The \n region that corresponds to a critical construct of a given name is executed as if only a single \n thread at a time among all threads in the contention group executes the region, without regard to the \n teams to which the threads belong.\nC / C++ \n Identifiers used to identify a critical construct have external linkage and are in a name space \n that is separate from the name spaces used by labels, tags, members, and ordinary identifiers.\nC / C++ \nFortran \n The names of critical constructs are global entities of the program.If a name conflicts with \n any other entity, the behavior of the program is unspecified.\nFortran \n Execution Model Events \n The critical-acquiring event occurs in a thread that encounters the critical construct on entry \n to the critical region before initiating synchronization for the region."}
{"section_title": "15.2 critical Construct", "chunk": "\nFortran \n Execution Model Events \n The critical-acquiring event occurs in a thread that encounters the critical construct on entry \n to the critical region before initiating synchronization for the region.\n The critical-acquired event occurs in a thread that encounters the critical construct after it \n enters the region, but before it executes the structured block of the critical region.\n The critical-released event occurs in a thread that encounters the critical construct after it \n completes any synchronization on exit from the critical region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of a critical-acquiring event in that thread.This callback has the type signature \n ompt_callback_mutex_acquire_t.\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of a critical-acquired event in that thread."}
{"section_title": "15.2 critical Construct", "chunk": "\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of a critical-acquired event in that thread.This callback has the type signature \n ompt_callback_mutex_t.\n A thread dispatches a registered ompt_callback_mutex_released callback for each \n occurrence of a critical-released event in that thread.This callback has the type signature \n ompt_callback_mutex_t.\n The callbacks occur in the task that encounters the critical construct.The callbacks should receive \n ompt_mutex_critical as their kind argument if practical, but a less specific kind is \n acceptable.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the critical construct are as follows: \n \u2022 Unless omp_sync_hint_none is specified, the critical construct must specify a name.\n \u2022 The hint-expr that is applied to each of the critical constructs with the same name must \n evaluate to the same value."}
{"section_title": "15.2 critical Construct", "chunk": "\n \u2022 The hint-expr that is applied to each of the critical constructs with the same name must \n evaluate to the same value.\nFortran \n \u2022 If a name is specified on a critical directive, the same name must also be specified on the \n end critical directive.\n \u2022 If no name appears on the critical directive, no name can appear on the end critical \n directive.\nFortran \n Cross References \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n \u2022 ompt_mutex_t, see Section 19.4.4.17 \n \u2022 hint clause, see Section 15.1.2 \n"}
{"section_title": "15.3 Barriers", "chunk": ""}
{"section_title": "15.3.1 barrier Construct", "chunk": "Name: barrier Association: none \nCategory: executable Properties: default 17 \n Binding \n The binding thread set for a barrier region is the current team.A barrier region binds to the \n innermost enclosing parallel region.\n Semantics \n The barrier construct specifies an explicit barrier at the point at which the construct appears.\n Unless the binding region is canceled, all threads of the team that executes that binding region must \n enter the barrier region and complete execution of all explicit tasks bound to that binding region \n before any of the threads continue execution beyond the barrier.\n The barrier region includes an implicit task scheduling point in the current task region.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 301 \n Execution Model Events \n The explicit-barrier-begin event occurs in each thread that encounters the barrier construct on \n entry to the barrier region."}
{"section_title": "15.3.1 barrier Construct", "chunk": "SYNCHRONIZATION CONSTRUCTS AND CLAUSES 301 \n Execution Model Events \n The explicit-barrier-begin event occurs in each thread that encounters the barrier construct on \n entry to the barrier region.\n The explicit-barrier-wait-begin event occurs when a task begins an interval of active or passive \n waiting in a barrier region.\n The explicit-barrier-wait-end event occurs when a task ends an interval of active or passive waiting \n and resumes execution in a barrier region.\n The explicit-barrier-end event occurs in each thread that encounters the barrier construct after \n the barrier synchronization on exit from the barrier region.\n A cancellation event occurs if cancellation is activated at an implicit cancellation point in a \n barrier region."}
{"section_title": "15.3.1 barrier Construct", "chunk": "\n A cancellation event occurs if cancellation is activated at an implicit cancellation point in a \n barrier region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_barrier_explicit as its kind argument and ompt_scope_begin \n as its endpoint argument for each occurrence of an explicit-barrier-begin event.Similarly, a thread \n dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_barrier_explicit as its kind argument and ompt_scope_end as \n its endpoint argument for each occurrence of an explicit-barrier-end event.These callbacks occur \n in the context of the task that encountered the barrier construct and have type signature \n ompt_callback_sync_region_t."}
{"section_title": "15.3.1 barrier Construct", "chunk": "These callbacks occur \n in the context of the task that encountered the barrier construct and have type signature \n ompt_callback_sync_region_t.\n A thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_barrier_explicit as its kind argument and ompt_scope_begin \n as its endpoint argument for each occurrence of an explicit-barrier-wait-begin event.Similarly, a \n thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_barrier_explicit as its kind argument and ompt_scope_end as \n its endpoint argument for each occurrence of an explicit-barrier-wait-end event.These callbacks \n occur in the context of the task that encountered the barrier construct and have type signature \n ompt_callback_sync_region_t.\n A thread dispatches a registered ompt_callback_cancel callback with \n ompt_cancel_detected as its flags argument for each occurrence of a cancellation event in \n that thread."}
{"section_title": "15.3.1 barrier Construct", "chunk": "\n A thread dispatches a registered ompt_callback_cancel callback with \n ompt_cancel_detected as its flags argument for each occurrence of a cancellation event in \n that thread.The callback occurs in the context of the encountering task.The callback has type \n signature ompt_callback_cancel_t.\n Restrictions \n Restrictions to the barrier construct are as follows: \n \u2022 Each barrier region must be encountered by all threads in a team or by none at all, unless \n cancellation has been requested for the innermost enclosing parallel region.\n \u2022 The sequence of worksharing regions and barrier regions encountered must be the same for \n every thread in a team.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 ompt_callback_cancel_t, see Section 19.5.2.18 \n \u2022 ompt_callback_sync_region_t, see Section 19.5.2.13 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n"}
{"section_title": "15.3.2 Implicit Barriers", "chunk": "7 This section describes the OMPT events and tool callbacks associated with implicit barriers, which \n occur at the end of various regions as defined in the description of the constructs to which they \n correspond.Implicit barriers are task scheduling points.For a description of task scheduling \n points, associated events, and tool callbacks, see Section 12.9.\n Execution Model Events \n The implicit-barrier-begin event occurs in each implicit task at the beginning of an implicit barrier \n region.\n The implicit-barrier-wait-begin event occurs when a task begins an interval of active or passive \n waiting in an implicit barrier region.\n The implicit-barrier-wait-end event occurs when a task ends an interval of active or waiting and \n resumes execution of an implicit barrier region.\n The implicit-barrier-end event occurs in each implicit task after the barrier synchronization on exit \n from an implicit barrier region."}
{"section_title": "15.3.2 Implicit Barriers", "chunk": "\n The implicit-barrier-end event occurs in each implicit task after the barrier synchronization on exit \n from an implicit barrier region.\n A cancellation event occurs if cancellation is activated at an implicit cancellation point in an \n implicit barrier region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback for each implicit \n barrier begin and end event.Similarly, a thread dispatches a registered \n ompt_callback_sync_region_wait callback for each implicit barrier wait-begin and \n wait-end event.All callbacks for implicit barrier events execute in the context of the encountering \n task and have type signature ompt_callback_sync_region_t.\n For the implicit barrier at the end of a worksharing construct, the kind argument is \n ompt_sync_region_barrier_implicit_workshare.For the implicit barrier at the end \n of a parallel region, the kind argument is \n ompt_sync_region_barrier_implicit_parallel."}
{"section_title": "15.3.2 Implicit Barriers", "chunk": "For the implicit barrier at the end \n of a parallel region, the kind argument is \n ompt_sync_region_barrier_implicit_parallel.For an extra barrier added by an \n OpenMP implementation, the kind argument is \n ompt_sync_region_barrier_implementation.For a barrier at the end of a teams \n region, the kind argument is ompt_sync_region_barrier_teams.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 303 \n A thread dispatches a registered ompt_callback_cancel callback with \n ompt_cancel_detected as its flags argument for each occurrence of a cancellation event in \n that thread.The callback occurs in the context of the encountering task.The callback has type \n signature ompt_callback_cancel_t."}
{"section_title": "15.3.2 Implicit Barriers", "chunk": "The callback has type \n signature ompt_callback_cancel_t.\n Restrictions \n Restrictions to implicit barriers are as follows: \n \u2022 If a thread is in the state ompt_state_wait_barrier_implicit_parallel, a call to \n ompt_get_parallel_info may return a pointer to a copy of the data object associated \n with the parallel region rather than a pointer to the associated data object itself.Writing to the \n data object returned by omp_get_parallel_info when a thread is in the \n ompt_state_wait_barrier_implicit_parallel results in unspecified behavior.\n Cross References \n \u2022 ompt_callback_cancel_t, see Section 19.5.2.18 \n \u2022 ompt_callback_sync_region_t, see Section 19.5.2.13 \n \u2022 ompt_cancel_flag_t, see Section 19.4.4.26 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n"}
{"section_title": "15.3.3 Implementation-Specific Barriers", "chunk": "19 An OpenMP implementation can execute implementation-specific barriers that the OpenMP \n specification does not imply; therefore, no execution model events are bound to them.The \n implementation can handle these barriers like implicit barriers and dispatch all events as for \n implicit barriers.These callbacks use ompt_sync_region_barrier_implementation \n \u2014 or ompt_sync_region_barrier, if the implementation cannot make a distinction \u2014 as \n the kind argument when they are dispatched.\n"}
{"section_title": "15.4 taskgroup Construct", "chunk": "Name: taskgroup Association: block \nCategory: executable Properties: cancellable 26 \n Clauses \n allocate, task_reduction \n Binding \n The binding task set of a taskgroup region is all tasks of the current team that are generated in \n the region.A taskgroup region binds to the innermost enclosing parallel region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The taskgroup construct specifies a wait on completion of the taskgroup set associated with the \n taskgroup region.When a thread encounters a taskgroup construct, it starts executing the \n region.\n An implicit task scheduling point occurs at the end of the taskgroup region.The current task is \n suspended at the task scheduling point until all tasks in the taskgroup set complete execution.\n Execution Model Events \n The taskgroup-begin event occurs in each thread that encounters the taskgroup construct on \n entry to the taskgroup region."}
{"section_title": "15.4 taskgroup Construct", "chunk": "\n Execution Model Events \n The taskgroup-begin event occurs in each thread that encounters the taskgroup construct on \n entry to the taskgroup region.\n The taskgroup-wait-begin event occurs when a task begins an interval of active or passive waiting \n in a taskgroup region.\n The taskgroup-wait-end event occurs when a task ends an interval of active or passive waiting and \n resumes execution in a taskgroup region.\n The taskgroup-end event occurs in each thread that encounters the taskgroup construct after the \n taskgroup synchronization on exit from the taskgroup region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_taskgroup as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskgroup-begin event in the task that encounters the \n taskgroup construct."}
{"section_title": "15.4 taskgroup Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_taskgroup as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskgroup-begin event in the task that encounters the \n taskgroup construct.Similarly, a thread dispatches a registered \n ompt_callback_sync_region callback with ompt_sync_region_taskgroup as its \n kind argument and ompt_scope_end as its endpoint argument for each occurrence of a \n taskgroup-end event in the task that encounters the taskgroup construct.These callbacks occur \n in the task that encounters the taskgroup construct and have the type signature \n ompt_callback_sync_region_t.\n A thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskgroup as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskgroup-wait-begin event."}
{"section_title": "15.4 taskgroup Construct", "chunk": "\n A thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskgroup as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskgroup-wait-begin event.Similarly, a thread \n dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskgroup as its kind argument and ompt_scope_end as its \n endpoint argument for each occurrence of a taskgroup-wait-end event.These callbacks occur in the \n context of the task that encounters the taskgroup construct and have type signature \n ompt_callback_sync_region_t.\n Cross References \n \u2022 Task Scheduling, see Section 12.9 \n \u2022 ompt_callback_sync_region_t, see Section 19.5.2.13 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 305 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n \u2022 allocate clause, see Section 6.6 \n \u2022 task_reduction clause, see Section 5.5.9 \n"}
{"section_title": "15.5 taskwait Construct", "chunk": "Name: taskwait Association: none \nCategory: executable Properties: default 5 \n Clauses \n depend, nowait \n Binding \n The taskwait region binds to the current task region.The binding thread set of the taskwait \n region is the current team.\n Semantics \n The taskwait construct specifies a wait on the completion of child tasks of the current task.\n If no depend clause is present on the taskwait construct, the current task region is suspended \n at an implicit task scheduling point associated with the construct.The current task region remains \n suspended until all child tasks that it generated before the taskwait region complete execution.\n If one or more depend clauses are present on the taskwait construct and the nowait clause is \n not also present, the behavior is as if these clauses were applied to a task construct with an empty \n associated structured block that generates a mergeable and included task."}
{"section_title": "15.5 taskwait Construct", "chunk": "\n If one or more depend clauses are present on the taskwait construct and the nowait clause is \n not also present, the behavior is as if these clauses were applied to a task construct with an empty \n associated structured block that generates a mergeable and included task.Thus, the current task \n region is suspended until the predecessor tasks of this task complete execution.\n If one or more depend clauses are present on the taskwait construct and the nowait clause is \n also present, the behavior is as if these clauses were applied to a task construct with an empty \n associated structured block that generates a task for which execution may be deferred.Thus, all \n predecessor tasks of this task must complete execution before any subsequently generated task that \n depends on this task starts its execution."}
{"section_title": "15.5 taskwait Construct", "chunk": "Thus, all \n predecessor tasks of this task must complete execution before any subsequently generated task that \n depends on this task starts its execution.\n Execution Model Events \n The taskwait-begin event occurs in a thread when it encounters a taskwait construct with no \n depend clause on entry to the taskwait region.\n The taskwait-wait-begin event occurs when a task begins an interval of active or passive waiting in \n a region corresponding to a taskwait construct with no depend clause.\n The taskwait-wait-end event occurs when a task ends an interval of active or passive waiting and \n resumes execution from a region corresponding to a taskwait construct with no depend clause.\n The taskwait-end event occurs in a thread when it encounters a taskwait construct with no \n depend clause after the taskwait synchronization on exit from the taskwait region."}
{"section_title": "15.5 taskwait Construct", "chunk": "\n The taskwait-end event occurs in a thread when it encounters a taskwait construct with no \n depend clause after the taskwait synchronization on exit from the taskwait region.\n OpenMP API \u2013 Version 5.2 November 2021 \n The taskwait-init event occurs in a thread when it encounters a taskwait construct with one or \n more depend clauses on entry to the taskwait region.\n The taskwait-complete event occurs on completion of the dependent task that results from a \n taskwait construct with one or more depend clauses, in the context of the thread that executes \n the dependent task and before any subsequently generated task that depends on the dependent task \n starts its execution.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_taskwait as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskwait-begin event in the task that encounters the \n taskwait construct."}
{"section_title": "15.5 taskwait Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_sync_region callback with \n ompt_sync_region_taskwait as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskwait-begin event in the task that encounters the \n taskwait construct.Similarly, a thread dispatches a registered \n ompt_callback_sync_region callback with ompt_sync_region_taskwait as its \n kind argument and ompt_scope_end as its endpoint argument for each occurrence of a \n taskwait-end event in the task that encounters the taskwait construct.These callbacks occur in \n the task that encounters the taskwait construct and have the type signature \n ompt_callback_sync_region_t.\n A thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskwait as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskwait-wait-begin event."}
{"section_title": "15.5 taskwait Construct", "chunk": "\n A thread dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskwait as its kind argument and ompt_scope_begin as its \n endpoint argument for each occurrence of a taskwait-wait-begin event.Similarly, a thread \n dispatches a registered ompt_callback_sync_region_wait callback with \n ompt_sync_region_taskwait as its kind argument and ompt_scope_end as its endpoint \n argument for each occurrence of a taskwait-wait-end event.These callbacks occur in the context of \n the task that encounters the taskwait construct and have type signature \n ompt_callback_sync_region_t.\n A thread dispatches a registered ompt_callback_task_create callback for each occurrence \n of a taskwait-init event in the context of the encountering task.This callback has the type signature \n ompt_callback_task_create_t.In the dispatched callback, (flags & \n ompt_task_taskwait) always evaluates to true."}
{"section_title": "15.5 taskwait Construct", "chunk": "In the dispatched callback, (flags & \n ompt_task_taskwait) always evaluates to true.If the nowait clause is not present, \n (flags & ompt_task_undeferred) also evaluates to true.\n A thread dispatches a registered ompt_callback_task_schedule callback for each \n occurrence of a taskwait-complete event.This callback has the type signature \n ompt_callback_task_schedule_t with ompt_taskwait_complete as its \n prior_task_status argument.\n Restrictions \n Restrictions to the taskwait construct are as follows: \n \u2022 The mutexinoutset dependence-type may not appear in a depend clause on a taskwait \n construct.\n \u2022 If the dependence-type of a depend clause is depobj then the dependence objects cannot \n represent dependences of the mutexinoutset dependence type.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 307 \n \u2022 The nowait clause may only appear on a taskwait directive if the depend clause is present."}
{"section_title": "15.5 taskwait Construct", "chunk": "SYNCHRONIZATION CONSTRUCTS AND CLAUSES 307 \n \u2022 The nowait clause may only appear on a taskwait directive if the depend clause is present.\n Cross References \n \u2022 ompt_callback_sync_region_t, see Section 19.5.2.13 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 nowait clause, see Section 15.6 \n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "15.6 nowait Clause", "chunk": "10 Name: nowait Properties: unique, end-clause \n Directives \n dispatch, do, for, interop, scope, sections, single, target, target enter \n data, target exit data, target update, taskwait, workshare \n Semantics \n The nowait clause overrides any synchronization that would otherwise occur at the end of a \n construct.It can also specify that an interoperability requirement set includes the nowait property.\n If the construct includes an implicit barrier, the nowait clause specifies that the barrier will not \n occur.For constructs that generate a task, the nowait clause specifies that the generated task may \n be deferred.If the nowait clause is not present on the directive then the generated task is an \n included task (so it executes synchronously in the context of the encountering task).For constructs \n that generate an interoperability requirement set, the nowait clause adds the nowait property to \n the set."}
{"section_title": "15.6 nowait Clause", "chunk": "For constructs \n that generate an interoperability requirement set, the nowait clause adds the nowait property to \n the set.\n Cross References \n \u2022 dispatch directive, see Section 7.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 interop directive, see Section 14.1 \n \u2022 scope directive, see Section 11.2 \n \u2022 sections directive, see Section 11.3 \n \u2022 single directive, see Section 11.1 \n \u2022 target directive, see Section 13.8 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \n \u2022 taskwait directive, see Section 15.5 \n \u2022 workshare directive, see Section 11.4 \n"}
{"section_title": "15.7 nogroup Clause", "chunk": "7 Name: nogroup Properties: unique \n Directives \n taskloop \n Semantics \n The nogroup clause overrides any implicit taskgroup that would otherwise enclose the \n construct.\n Cross References \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "15.8 OpenMP Memory Ordering", "chunk": "16 This sections describes constructs and clauses in OpenMP that support ordering of memory \n operations.\n"}
{"section_title": "15.8.1 memory-order Clauses", "chunk": "19 Clause groups \nProperties: unique, exclusive, inarguable Members: acq_rel, acquire, relaxed, \nrelease, seq_cst 20 \n Directives \n atomic, flush \n Semantics \n The memory-order clause grouping defines a set of clauses that indicate the memory ordering \n requirements for the visibility of the effects of the constructs on which they may be specified.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 309 \n Cross References \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 flush directive, see Section 15.8.5 \n"}
{"section_title": "15.8.2 atomic Clauses", "chunk": "5 Clause groups \n Properties: unique, exclusive, inarguable Members: read, update, write \n Directives \n atomic \n Semantics \n The atomic clause grouping defines a set of clauses that defines the semantics for which a directive \n enforces atomicity.If a construct accepts the atomic clause grouping and no member of the \n grouping is specified, the effect is as if the update clause is specified.\n Cross References \n \u2022 atomic directive, see Section 15.8.4 \n"}
{"section_title": "15.8.3 extended-atomic Clauses", "chunk": "16 Clause groups \n Properties: unique Members: capture, compare, fail, weak \n Directives \n atomic \n Semantics \n The extended-atomic clause grouping defines a set of clauses that extend the atomicity semantics \n specified by members of the atomic clause grouping.Other than the fail clause, they are \n inarguable; the fail clause takes a member of the memory-order clause grouping as an argument.\n The capture clause extends the semantics to capture the value of the variable being updated \n atomically.The compare clause extends the semantics to perform the atomic update conditionally.\n The fail clause extends the semantics to specify the memory ordering requirements for any \n comparison performed by any atomic conditional update that fails.Its argument overrides any other \n specified memory ordering."}
{"section_title": "15.8.3 extended-atomic Clauses", "chunk": "Its argument overrides any other \n specified memory ordering.If the fail clause is not specified on an atomic conditional update the \n effect is as if the fail clause is specified with a default argument that depends on the effective \n memory ordering.If the effective memory ordering is acq_rel, the default argument is \n acquire.If the effective memory ordering is release, the default argument is relaxed.For \n any other effective memory ordering, the default argument is equal to that effective memory \n ordering.The weak clause specifies that the comparison performed by a conditional atomic update \n may spuriously fail, evaluating to not equal even when the values are equal.\n OpenMP API \u2013 Version 5.2 November 2021 \n \n Note \u2013 Allowing for spurious failure by specifying a weak clause can result in performance gains \n on some systems when using compare-and-swap in a loop."}
{"section_title": "15.8.3 extended-atomic Clauses", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n \n Note \u2013 Allowing for spurious failure by specifying a weak clause can result in performance gains \n on some systems when using compare-and-swap in a loop.For cases where a single \n compare-and-swap would otherwise be sufficient, using a loop over a weak compare-and-swap is \n unlikely to improve performance.\n \n Restrictions \n Restrictions to the atomic construct are as follows: \n \u2022 acq_rel and release cannot be specified as arguments to the fail clause.\n Cross References \n \u2022 atomic Clauses, see Section 15.8.2 \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 memory-order Clauses, see Section 15.8.1 \n"}
{"section_title": "15.8.4 atomic Construct", "chunk": "Name: atomic Association: block (atomic structured block) \nCategory: executable Properties: simdizable 15 \n Clause groups \n atomic, extended-atomic, memory-order \n Clauses \n hint \n This section uses the terminology and symbols defined for OpenMP Atomic Structured Blocks (see \n Section 4.3.1.3).\n Binding \n If the size of x is 8, 16, 32, or 64 bits and x is aligned to a multiple of its size, the binding thread set \n for the atomic region is all threads on the device.Otherwise, the binding thread set for the \n atomic region is all threads in the contention group.atomic regions enforce exclusive access \n with respect to other atomic regions that access the same storage location x among all threads in \n the binding thread set without regard to the teams to which the threads belong."}
{"section_title": "15.8.4 atomic Construct", "chunk": "atomic regions enforce exclusive access \n with respect to other atomic regions that access the same storage location x among all threads in \n the binding thread set without regard to the teams to which the threads belong.\n Semantics \n The atomic construct ensures that a specific storage location is accessed atomically so that \n possible simultaneous reads and writes by multiple threads do not result in indeterminate values.\n The atomic construct with the read clause results in an atomic read of the location designated \n by x.The atomic construct with the write clause results in an atomic write of the location \n designated by x.The atomic construct with the update clause results in an atomic update of the \n location designated by x using the designated operator or intrinsic.Only the read and write of the \n location designated by x are performed mutually atomically."}
{"section_title": "15.8.4 atomic Construct", "chunk": "Only the read and write of the \n location designated by x are performed mutually atomically.The evaluation of expr or expr-list \n need not be atomic with respect to the read or write of the location designated by x.No task \n scheduling points are allowed between the read and the write of the location designated by x.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 311 \n If the capture clause is present, the atomic update is an atomic captured update \u2014 an atomic \n update to the location designated by x using the designated operator or intrinsic while also \n capturing the original or final value of the location designated by x with respect to the atomic \n update.The original or final value of the location designated by x is written in the location \n designated by v based on the base language semantics of structured block or statements of the \n atomic construct.Only the read and write of the location designated by x are performed mutually \n atomically."}
{"section_title": "15.8.4 atomic Construct", "chunk": "Only the read and write of the location designated by x are performed mutually \n atomically.Neither the evaluation of expr or expr-list, nor the write to the location designated by v, \n need be atomic with respect to the read or write of the location designated by x.\n If the compare clause is present, the atomic update is an atomic conditional update.For forms \n that use an equality comparison, the operation is an atomic compare-and-swap.It atomically \n compares the value of x to e and writes the value of d into the location designated by x if they are \n equal.Based on the base language semantics of the associated structured block, the original or final \n value of the location designated by x is written to the location designated by v, which is allowed to \n be the same location as designated by e, or the result of the comparison is written to the location \n designated by r.Only the read and write of the location designated by x are performed mutually \n atomically."}
{"section_title": "15.8.4 atomic Construct", "chunk": "Only the read and write of the location designated by x are performed mutually \n atomically.Neither the evaluation of either e or d nor writes to the locations designated by v and r \n need be atomic with respect to the read or write of the location designated by x.\nC / C++ \n If the compare clause is present, forms that use ordop are logically an atomic maximum or \n minimum, but they may be implemented with a compare-and-swap loop with short-circuiting.For \n forms where statement is cond-expr-stmt, if the result of the condition implies that the value of x \n does not change then the update may not occur.\nC / C++ \n If a memory-order clause is present, or implicitly provided by a requires directive, it specifies \n the effective memory ordering.Otherwise the effect is as if the relaxed memory ordering clause \n is specified.\n The atomic construct may be used to enforce memory consistency between threads, based on the \n guarantees provided by Section 1.4.6."}
{"section_title": "15.8.4 atomic Construct", "chunk": "\n The atomic construct may be used to enforce memory consistency between threads, based on the \n guarantees provided by Section 1.4.6.A strong flush on the location designated by x is performed \n on entry to and exit from the atomic operation, ensuring that the set of all atomic operations applied \n to the same location in a race-free program has a total completion order.If the write or update \n clause is specified, the atomic operation is not an atomic conditional update for which the \n comparison fails, and the effective memory ordering is release, acq_rel, or seq_cst, the \n strong flush on entry to the atomic operation is also a release flush.If the read or update clause \n is specified and the effective memory ordering is acquire, acq_rel, or seq_cst then the \n strong flush on exit from the atomic operation is also an acquire flush."}
{"section_title": "15.8.4 atomic Construct", "chunk": "If the read or update clause \n is specified and the effective memory ordering is acquire, acq_rel, or seq_cst then the \n strong flush on exit from the atomic operation is also an acquire flush.Therefore, if the effective \n memory ordering is not relaxed, release and/or acquire flush operations are implied and permit \n synchronization between the threads without the use of explicit flush directives.\n For all forms of the atomic construct, any combination of two or more of these atomic \n constructs enforces mutually exclusive access to the locations designated by x among threads in the \n binding thread set.To avoid data races, all accesses of the locations designated by x that could \n potentially occur in parallel must be protected with an atomic construct."}
{"section_title": "15.8.4 atomic Construct", "chunk": "To avoid data races, all accesses of the locations designated by x that could \n potentially occur in parallel must be protected with an atomic construct.\n OpenMP API \u2013 Version 5.2 November 2021 \n atomic regions do not guarantee exclusive access with respect to any accesses outside of \n atomic regions to the same storage location x even if those accesses occur during a critical \n or ordered region, while an OpenMP lock is owned by the executing task, or during the \n execution of a reduction clause.\n However, other OpenMP synchronization can ensure the desired exclusive access.For example, a \n barrier that follows a series of atomic updates to x guarantees that subsequent accesses do not form \n a race with the atomic accesses.\n A compliant implementation may enforce exclusive access between atomic regions that update \n different storage locations.The circumstances under which this occurs are implementation defined."}
{"section_title": "15.8.4 atomic Construct", "chunk": "The circumstances under which this occurs are implementation defined.\n If the storage location designated by x is not size-aligned (that is, if the byte alignment of x is not a \n multiple of the size of x), then the behavior of the atomic region is implementation defined.\n Execution Model Events \n The atomic-acquiring event occurs in the thread that encounters the atomic construct on entry to \n the atomic region before initiating synchronization for the region.\n The atomic-acquired event occurs in the thread that encounters the atomic construct after it \n enters the region, but before it executes the structured block of the atomic region.\n The atomic-released event occurs in the thread that encounters the atomic construct after it \n completes any synchronization on exit from the atomic region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of an atomic-acquiring event in that thread."}
{"section_title": "15.8.4 atomic Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of an atomic-acquiring event in that thread.This callback has the type signature \n ompt_callback_mutex_acquire_t.\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of an atomic-acquired event in that thread.This callback has the type signature \n ompt_callback_mutex_t.\n A thread dispatches a registered ompt_callback_mutex_released callback with \n ompt_mutex_atomic as the kind argument if practical, although a less specific kind may be \n used, for each occurrence of an atomic-released event in that thread.This callback has the type \n signature ompt_callback_mutex_t and occurs in the task that encounters the atomic \n construct.\n Restrictions \n Restrictions to the atomic construct are as follows: \n \u2022 OpenMP constructs may not be encountered during execution of an atomic region."}
{"section_title": "15.8.4 atomic Construct", "chunk": "\n Restrictions \n Restrictions to the atomic construct are as follows: \n \u2022 OpenMP constructs may not be encountered during execution of an atomic region.\n \u2022 If a capture or compare clause is specified, the atomic clause must be update.\n \u2022 If a capture clause is specified but the compare clause is not specified, an \n update-capture-atomic structured block must be associated with the construct.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 313 \n \u2022 If both capture and compare clauses are specified, a conditional-update-capture-atomic \n structured block must be associated with the construct.\n \u2022 If a compare clause is specified but the capture clause is not specified, a \n conditional-update-atomic structured block must be associated with the construct.\n \u2022 If a write clause is specified, a write-atomic structured block must be associated with the \n construct.\n \u2022 If a read clause is specified, a read-atomic structured block must be associated with the \n construct."}
{"section_title": "15.8.4 atomic Construct", "chunk": "\n \u2022 If a read clause is specified, a read-atomic structured block must be associated with the \n construct.\n \u2022 If the atomic clause is read then the memory-order clause must not be release.\n \u2022 If the atomic clause is write then the memory-order clause must not be acquire.\n \u2022 The weak clause may only appear if the resulting atomic operation is an atomic conditional \n update for which the comparison tests for equality.\nC / C++ \n \u2022 All atomic accesses to the storage locations designated by x throughout the program are required \n to have a compatible type.\n \u2022 The fail clause may only appear if the resulting atomic operation is an atomic conditional \n update.\nC / C++ \nFortran \n \u2022 All atomic accesses to the storage locations designated by x throughout the program are required \n to have the same type and type parameters."}
{"section_title": "15.8.4 atomic Construct", "chunk": "\nC / C++ \nFortran \n \u2022 All atomic accesses to the storage locations designated by x throughout the program are required \n to have the same type and type parameters.\n \u2022 The fail clause may only appear if the resulting atomic operation is an atomic conditional \n update or an atomic update where intrinsic-procedure-name is either MAX or MIN.\nFortran \n Cross References \n \u2022 Lock Routines, see Section 18.9 \n \u2022 OpenMP Atomic Structured Blocks, see Section 4.3.1.3 \n \u2022 Synchronization Hints, see Section 15.1 \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n \u2022 ompt_mutex_t, see Section 19.4.4.17 \n \u2022 ordered Construct, see Section 15.10 \n \u2022 barrier directive, see Section 15.3.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 critical directive, see Section 15.2 \n \u2022 flush directive, see Section 15.8.5 \n \u2022 hint clause, see Section 15.1.2 \n \u2022 requires directive, see Section 8.2 \n"}
{"section_title": "15.8.5 flush Construct", "chunk": "Name: flush Association: none \nCategory: executable Properties: default 6 \n Arguments \n flush(list) \nName Type Properties \nlist list of variable list item type optional 9 \n Clause groups \n memory-order \n Binding \n The binding thread set for a flush region is all threads in the device-set of its flush operation.\n Semantics \n The flush construct executes the OpenMP flush operation.This operation makes a thread\u2019s \n temporary view of memory consistent with memory and enforces an order on the memory \n operations of the variables explicitly specified or implied.Execution of a flush region affects the \n memory and it affects the temporary view of memory of the encountering thread.It does not affect \n the temporary view of other threads.Other threads on devices in the device-set must themselves \n execute a flush operation in order to be guaranteed to observe the effects of the flush operation of \n the encountering thread."}
{"section_title": "15.8.5 flush Construct", "chunk": "Other threads on devices in the device-set must themselves \n execute a flush operation in order to be guaranteed to observe the effects of the flush operation of \n the encountering thread.See the memory model description in Section 1.4 for more details.\n If neither a memory-order clause nor a list argument appears on a flush construct then the \n behavior is as if the memory-order clause is seq_cst.\n A flush construct with the seq_cst clause, executed on a given thread, operates as if all data \n storage blocks that are accessible to the thread are flushed by a strong flush operation.A flush \n construct with a list applies a strong flush operation to the items in the list, and the flush operation \n does not complete until the operation is complete for all specified list items.An implementation \n may implement a flush construct with a list by ignoring the list and treating it the same as a \n flush construct with the seq_cst clause."}
{"section_title": "15.8.5 flush Construct", "chunk": "An implementation \n may implement a flush construct with a list by ignoring the list and treating it the same as a \n flush construct with the seq_cst clause.\n If no list items are specified, the flush operation has the release and/or acquire flush properties: \n \u2022 If the memory-order clause is seq_cst or acq_rel, the flush operation is both a release flush \n and an acquire flush.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 315 \n \u2022 If the memory-order clause is release, the flush operation is a release flush.\n \u2022 If the memory-order clause is acquire, the flush operation is an acquire flush.\nC / C++ \n If a pointer is present in the list, the pointer itself is flushed, not the memory block to which the \n pointer refers.\n A flush construct without a list corresponds to a call to atomic_thread_fence, where the \n argument is given by the identifier that results from prefixing memory_order_ to the \n memory-order clause name."}
{"section_title": "15.8.5 flush Construct", "chunk": "\n A flush construct without a list corresponds to a call to atomic_thread_fence, where the \n argument is given by the identifier that results from prefixing memory_order_ to the \n memory-order clause name.\n For a flush construct without a list, the generated flush region implicitly performs the \n corresponding call to atomic_thread_fence.The behavior of an explicit call to \n atomic_thread_fence that occurs in the program and does not have the argument \n memory_order_consume is as if the call is replaced by its corresponding flush construct.\nC / C++ \nFortran \n If the list item or a subobject of the list item has the POINTER attribute, the allocation or \n association status of the POINTER item is flushed, but the pointer target is not.If the list item is a \n Cray pointer, the pointer is flushed, but the object to which it points is not.Cray pointer support has \n been deprecated."}
{"section_title": "15.8.5 flush Construct", "chunk": "Cray pointer support has \n been deprecated.If the list item is of type C_PTR, the variable is flushed, but the storage that \n corresponds to that address is not flushed.If the list item or the subobject of the list item has the \n ALLOCATABLE attribute and has an allocation status of allocated, the allocated variable is flushed; \n otherwise the allocation status is flushed.\nFortran \n Execution Model Events \n The flush event occurs in a thread that encounters the flush construct.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_flush callback for each occurrence of a \n flush event in that thread.This callback has the type signature ompt_callback_flush_t.\n Restrictions \n Restrictions to the flush construct are as follows: \n \u2022 If a memory-order clause is specified, the list argument must not be specified.\n \u2022 The memory-order clause must not be relaxed."}
{"section_title": "15.8.5 flush Construct", "chunk": "\n \u2022 The memory-order clause must not be relaxed.\n Cross References \n \u2022 ompt_callback_flush_t, see Section 19.5.2.17 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "2 Flush operations implied when executing an atomic region are described in Section 15.8.4.\n A flush region that corresponds to a flush directive with the release clause present is \n implied at the following locations: \n \u2022 During a barrier region; \n \u2022 At entry to a parallel region; \n \u2022 At entry to a teams region; \n \u2022 At exit from a critical region; \n \u2022 During an omp_unset_lock region; \n \u2022 During an omp_unset_nest_lock region; \n \u2022 During an omp_fulfill_event region; \n \u2022 Immediately before every task scheduling point; \n \u2022 At exit from the task region of each implicit task; \n \u2022 At exit from an ordered region, if a threads clause or a doacross clause with a source \n dependence type is present, or if no clauses are present; and \n \u2022 During a cancel region, if the cancel-var ICV is true."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n A flush region that corresponds to a flush directive with the release clause present is \n implied at the following locations: \n \u2022 During a barrier region; \n \u2022 At entry to a parallel region; \n \u2022 At entry to a teams region; \n \u2022 At exit from a critical region; \n \u2022 During an omp_unset_lock region; \n \u2022 During an omp_unset_nest_lock region; \n \u2022 During an omp_fulfill_event region; \n \u2022 Immediately before every task scheduling point; \n \u2022 At exit from the task region of each implicit task; \n \u2022 At exit from an ordered region, if a threads clause or a doacross clause with a source \n dependence type is present, or if no clauses are present; and \n \u2022 During a cancel region, if the cancel-var ICV is true.\n For a target construct, the device-set of an implicit release flush that is performed in a target task \n during the generation of the target region and that is performed on exit from the initial task \n region that implicitly encloses the target region consists of the devices that execute the target \n task and the target region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n For a target construct, the device-set of an implicit release flush that is performed in a target task \n during the generation of the target region and that is performed on exit from the initial task \n region that implicitly encloses the target region consists of the devices that execute the target \n task and the target region.\n A flush region that corresponds to a flush directive with the acquire clause present is \n implied at the following locations: \n \u2022 During a barrier region; \n \u2022 At exit from a teams region; \n \u2022 At entry to a critical region; \n \u2022 If the region causes the lock to be set, during: \n \u2013 an omp_set_lock region; \n \u2013 an omp_test_lock region; \n \u2013 an omp_set_nest_lock region; and \n \u2013 an omp_test_nest_lock region; \n \u2022 Immediately after every task scheduling point; \nCHAPTER 15."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n A flush region that corresponds to a flush directive with the acquire clause present is \n implied at the following locations: \n \u2022 During a barrier region; \n \u2022 At exit from a teams region; \n \u2022 At entry to a critical region; \n \u2022 If the region causes the lock to be set, during: \n \u2013 an omp_set_lock region; \n \u2013 an omp_test_lock region; \n \u2013 an omp_set_nest_lock region; and \n \u2013 an omp_test_nest_lock region; \n \u2022 Immediately after every task scheduling point; \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 317 \n \u2022 At entry to the task region of each implicit task; \n \u2022 At entry to an ordered region, if a threads clause or a doacross clause with a sink \n dependence type is present, or if no clauses are present; and \n \u2022 Immediately before a cancellation point, if the cancel-var ICV is true and cancellation has been \n activated."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "SYNCHRONIZATION CONSTRUCTS AND CLAUSES 317 \n \u2022 At entry to the task region of each implicit task; \n \u2022 At entry to an ordered region, if a threads clause or a doacross clause with a sink \n dependence type is present, or if no clauses are present; and \n \u2022 Immediately before a cancellation point, if the cancel-var ICV is true and cancellation has been \n activated.\n For a target construct, the device-set of an implicit acquire flush that is performed in a target \n task following the generation of the target region or that is performed on entry to the initial task \n region that implicitly encloses the target region consists of the devices that execute the target \n task and the target region.\n \n Note \u2013 A flush region is not implied at the following locations: \n \u2022 At entry to worksharing regions; and \n \u2022 At entry to or exit from masked regions."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \n Note \u2013 A flush region is not implied at the following locations: \n \u2022 At entry to worksharing regions; and \n \u2022 At entry to or exit from masked regions.\n \n The synchronization behavior of implicit flushes is as follows: \n \u2022 When a thread executes an atomic region for which the corresponding construct has the \n release, acq_rel, or seq_cst clause and specifies an atomic operation that starts a given \n release sequence, the release flush that is performed on entry to the atomic operation \n synchronizes with an acquire flush that is performed by a different thread and has an associated \n atomic operation that reads a value written by a modification in the release sequence."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \n The synchronization behavior of implicit flushes is as follows: \n \u2022 When a thread executes an atomic region for which the corresponding construct has the \n release, acq_rel, or seq_cst clause and specifies an atomic operation that starts a given \n release sequence, the release flush that is performed on entry to the atomic operation \n synchronizes with an acquire flush that is performed by a different thread and has an associated \n atomic operation that reads a value written by a modification in the release sequence.\n \u2022 When a thread executes an atomic region for which the corresponding construct has the \n acquire, acq_rel, or seq_cst clause and specifies an atomic operation that reads a value \n written by a given modification, a release flush that is performed by a different thread and has an \n associated release sequence that contains that modification synchronizes with the acquire flush \n that is performed on exit from the atomic operation."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes an atomic region for which the corresponding construct has the \n acquire, acq_rel, or seq_cst clause and specifies an atomic operation that reads a value \n written by a given modification, a release flush that is performed by a different thread and has an \n associated release sequence that contains that modification synchronizes with the acquire flush \n that is performed on exit from the atomic operation.\n \u2022 When a thread executes a critical region that has a given name, the behavior is as if the \n release flush performed on exit from the region synchronizes with the acquire flush performed on \n entry to the next critical region with the same name that is performed by a different thread, \n if it exists."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes a critical region that has a given name, the behavior is as if the \n release flush performed on exit from the region synchronizes with the acquire flush performed on \n entry to the next critical region with the same name that is performed by a different thread, \n if it exists.\n \u2022 When a thread team executes a barrier region, the behavior is as if the release flush performed \n by each thread within the region, and the release flush performed by any other thread upon \n fulfilling the allow-completion event for a detachable task bound to the binding parallel region of \n the region, synchronizes with the acquire flush performed by all other threads within the region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread team executes a barrier region, the behavior is as if the release flush performed \n by each thread within the region, and the release flush performed by any other thread upon \n fulfilling the allow-completion event for a detachable task bound to the binding parallel region of \n the region, synchronizes with the acquire flush performed by all other threads within the region.\n \u2022 When a thread executes a taskwait region that does not result in the creation of a dependent \n task and the task that encounters the corresponding taskwait construct has at least one child \n task, the behavior is as if each thread that executes a child task that is generated before the \n OpenMP API \u2013 Version 5.2 November 2021 \n taskwait region performs a release flush upon completion of the associated structured block \n of the child task that synchronizes with an acquire flush performed in the taskwait region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes a taskwait region that does not result in the creation of a dependent \n task and the task that encounters the corresponding taskwait construct has at least one child \n task, the behavior is as if each thread that executes a child task that is generated before the \n OpenMP API \u2013 Version 5.2 November 2021 \n taskwait region performs a release flush upon completion of the associated structured block \n of the child task that synchronizes with an acquire flush performed in the taskwait region.If \n the child task is detachable, the thread that fulfills its allow-completion event performs a release \n flush upon fulfilling the event that synchronizes with the acquire flush performed in the \n taskwait region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "If \n the child task is detachable, the thread that fulfills its allow-completion event performs a release \n flush upon fulfilling the event that synchronizes with the acquire flush performed in the \n taskwait region.\n \u2022 When a thread executes a taskgroup region, the behavior is as if each thread that executes a \n remaining descendent task performs a release flush upon completion of the associated structured \n block of the descendent task that synchronizes with an acquire flush performed on exit from the \n taskgroup region.If the descendent task is detachable, the thread that fulfills its \n allow-completion event performs a release flush upon fulfilling the event that synchronizes with \n the acquire flush performed in the taskgroup region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "If the descendent task is detachable, the thread that fulfills its \n allow-completion event performs a release flush upon fulfilling the event that synchronizes with \n the acquire flush performed in the taskgroup region.\n \u2022 When a thread executes an ordered region that does not arise from a stand-alone ordered \n directive, the behavior is as if the release flush performed on exit from the region synchronizes \n with the acquire flush performed on entry to an ordered region encountered in the next logical \n iteration to be executed by a different thread, if it exists.\n \u2022 When a thread executes an ordered region that arises from a stand-alone ordered directive, \n the behavior is as if the release flush performed in the ordered region from a given source \n iteration synchronizes with the acquire flush performed in all ordered regions executed by a \n different thread that are waiting for dependences on that iteration to be satisfied."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes an ordered region that arises from a stand-alone ordered directive, \n the behavior is as if the release flush performed in the ordered region from a given source \n iteration synchronizes with the acquire flush performed in all ordered regions executed by a \n different thread that are waiting for dependences on that iteration to be satisfied.\n \u2022 When a thread team begins execution of a parallel region, the behavior is as if the release \n flush performed by the primary thread on entry to the parallel region synchronizes with the \n acquire flush performed on entry to each implicit task that is assigned to a different thread."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread team begins execution of a parallel region, the behavior is as if the release \n flush performed by the primary thread on entry to the parallel region synchronizes with the \n acquire flush performed on entry to each implicit task that is assigned to a different thread.\n \u2022 When an initial thread begins execution of a target region that is generated by a different \n thread from a target task, the behavior is as if the release flush performed by the generating \n thread in the target task synchronizes with the acquire flush performed by the initial thread on \n entry to its initial task region.\n \u2022 When an initial thread completes execution of a target region that is generated by a different \n thread from a target task, the behavior is as if the release flush performed by the initial thread on \n exit from its initial task region synchronizes with the acquire flush performed by the generating \n thread in the target task."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When an initial thread completes execution of a target region that is generated by a different \n thread from a target task, the behavior is as if the release flush performed by the initial thread on \n exit from its initial task region synchronizes with the acquire flush performed by the generating \n thread in the target task.\n \u2022 When a thread encounters a teams construct, the behavior is as if the release flush performed by \n the thread on entry to the teams region synchronizes with the acquire flush performed on entry \n to each initial task that is executed by a different initial thread that participates in the execution of \n the teams region.\n \u2022 When a thread that encounters a teams construct reaches the end of the teams region, the \n behavior is as if the release flush performed by each different participating initial thread at exit \n from its initial task synchronizes with the acquire flush performed by the thread at exit from the \n teams region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread that encounters a teams construct reaches the end of the teams region, the \n behavior is as if the release flush performed by each different participating initial thread at exit \n from its initial task synchronizes with the acquire flush performed by the thread at exit from the \n teams region.\n \u2022 When a task generates an explicit task that begins execution on a different thread, the behavior is \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 319 \n as if the thread that is executing the generating task performs a release flush that synchronizes \n with the acquire flush performed by the thread that begins to execute the explicit task."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "SYNCHRONIZATION CONSTRUCTS AND CLAUSES 319 \n as if the thread that is executing the generating task performs a release flush that synchronizes \n with the acquire flush performed by the thread that begins to execute the explicit task.\n \u2022 When an undeferred task completes execution on a given thread that is different from the thread \n on which its generating task is suspended, the behavior is as if a release flush performed by the \n thread that completes execution of the associated structured block of the undeferred task \n synchronizes with an acquire flush performed by the thread that resumes execution of the \n generating task.\n \u2022 When a dependent task with one or more predecessor tasks begins execution on a given thread, \n the behavior is as if each release flush performed by a different thread on completion of the \n associated structured block of a predecessor task synchronizes with the acquire flush performed \n by the thread that begins to execute the dependent task."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a dependent task with one or more predecessor tasks begins execution on a given thread, \n the behavior is as if each release flush performed by a different thread on completion of the \n associated structured block of a predecessor task synchronizes with the acquire flush performed \n by the thread that begins to execute the dependent task.If the predecessor task is detachable, the \n thread that fulfills its allow-completion event performs a release flush upon fulfilling the event \n that synchronizes with the acquire flush performed when the dependent task begins to execute.\n \u2022 When a task begins execution on a given thread and it is mutually exclusive with respect to \n another sibling task that is executed by a different thread, the behavior is as if each release flush \n performed on completion of the sibling task synchronizes with the acquire flush performed by \n the thread that begins to execute the task."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a task begins execution on a given thread and it is mutually exclusive with respect to \n another sibling task that is executed by a different thread, the behavior is as if each release flush \n performed on completion of the sibling task synchronizes with the acquire flush performed by \n the thread that begins to execute the task.\n \u2022 When a thread executes a cancel region, the cancel-var ICV is true, and cancellation is not \n already activated for the specified region, the behavior is as if the release flush performed during \n the cancel region synchronizes with the acquire flush performed by a different thread \n immediately before a cancellation point in which that thread observes cancellation was activated \n for the region."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes a cancel region, the cancel-var ICV is true, and cancellation is not \n already activated for the specified region, the behavior is as if the release flush performed during \n the cancel region synchronizes with the acquire flush performed by a different thread \n immediately before a cancellation point in which that thread observes cancellation was activated \n for the region.\n \u2022 When a thread executes an omp_unset_lock region that causes the specified lock to be unset, \n the behavior is as if a release flush is performed during the omp_unset_lock region that \n synchronizes with an acquire flush that is performed during the next omp_set_lock or \n omp_test_lock region to be executed by a different thread that causes the specified lock to be \n set."}
{"section_title": "15.8.6 Implicit Flushes", "chunk": "\n \u2022 When a thread executes an omp_unset_lock region that causes the specified lock to be unset, \n the behavior is as if a release flush is performed during the omp_unset_lock region that \n synchronizes with an acquire flush that is performed during the next omp_set_lock or \n omp_test_lock region to be executed by a different thread that causes the specified lock to be \n set.\n \u2022 When a thread executes an omp_unset_nest_lock region that causes the specified nested \n lock to be unset, the behavior is as if a release flush is performed during the \n omp_unset_nest_lock region that synchronizes with an acquire flush that is performed \n during the next omp_set_nest_lock or omp_test_nest_lock region to be executed by \n a different thread that causes the specified nested lock to be set.\n"}
{"section_title": "15.9 OpenMP Dependences", "chunk": "34 This section describes constructs and clauses in OpenMP that support the specification and \n enforcement of dependences.OpenMP supports two kinds of dependences: task dependences, \n which enforce orderings between tasks; and cross-iteration dependences, which enforce orderings \n between loop iterations.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "15.9.1 task-dependence-type Modifier", "chunk": "2 Modifiers \nName Modifies Type Properties \ntask-dependence\ufffetype \nlocator-list Keyword: depobj, in, \ninout, inoutset, \nmutexinoutset, out \nrequired, ultimate 3 \n Clauses \n depend, update \n Semantics \n OpenMP clauses that are related to task dependences use the task-dependence-type modifier to \n identify the type of dependence relevant to that clause.The effect of the type of dependence is \n associated with locator list items as described with the depend clause, see Section 15.9.5.\n Cross References \n \u2022 depend clause, see Section 15.9.5 \n \u2022 update clause, see Section 15.9.3 \n"}
{"section_title": "15.9.2 Depend Objects", "chunk": "14 OpenMP depend objects can be used to supply user-computed dependences to depend clauses.\n OpenMP depend objects must be accessed only through the depobj construct or through the \n depend clause; programs that otherwise access OpenMP depend objects are non-conforming.\n An OpenMP depend object can be in one of the following states: uninitialized or initialized.\n Initially, OpenMP depend objects are in the uninitialized state.\n"}
{"section_title": "15.9.3 update Clause", "chunk": "20 Name: update Properties: unique \n Arguments \nName Type Properties \ntask-dependence-type Keyword: depobj, in, inout, \ninoutset, mutexinoutset, out \n default \n Directives \n depobj \n Semantics \n The update clause sets the dependence type of an OpenMP depend object to \n task-dependence-type.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 321 \n Restrictions \n Restrictions to the update clause are as follows: \n \u2022 task-dependence-type must not be depobj.\n Cross References \n \u2022 depobj directive, see Section 15.9.4 \n \u2022 task-dependence-type modifier, see Section 15.9.1 \n"}
{"section_title": "15.9.4 depobj Construct", "chunk": "Name: depobj Association: none \nCategory: executable Properties: default 8 \n Arguments \n depobj(depend-object) \nName Type Properties \ndepend-object variable of depend type default 11 \n Clauses \n depend, destroy, update \n Clause set \n Properties: unique, required, exclusive Members: depend, destroy, update \n Binding \n The binding thread set for a depobj region is the encountering thread.\n Semantics \n The depobj construct initializes, updates or destroys an OpenMP depend object.If a depend \n clause is specified, the state of depend-object is set to initialized and depend-object is set to \n represent the dependence that the depend clause specifies.If an update clause is specified, \n depend-object is updated to represent the new dependence type.If a destroy clause is specified, \n the state of depend-object is set to uninitialized."}
{"section_title": "15.9.4 depobj Construct", "chunk": "If a destroy clause is specified, \n the state of depend-object is set to uninitialized.\n Restrictions \n Restrictions to the depobj construct are as follows: \n \u2022 A depend clause on a depobj construct must only specify one locator.\n \u2022 The state of depend-object must be uninitialized if a depend clause is specified.\n \u2022 The state of depend-object must be initialized if a destroy clause or update clause is \n specified.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 depend clause, see Section 15.9.5 \n \u2022 destroy clause, see Section 3.5 \n \u2022 task-dependence-type modifier, see Section 15.9.1 \n \u2022 update clause, see Section 15.9.3 \n"}
{"section_title": "15.9.5 depend Clause", "chunk": "7 Name: depend Properties: default \n Arguments \nName Type Properties \nlocator-list list of locator list item type default 9 \n Modifiers \nName Modifies Type Properties \ntask-dependence\ufffetype \nlocator-list Keyword: depobj, in, \ninout, inoutset, \nmutexinoutset, out \nrequired, ultimate \niterator locator-list Complex, name: iterator \nArguments: \niterator-specifier OpenMP \nexpression (repeatable) \n unique \n Directives \n depobj, interop, target, target enter data, target exit data, target \n update, task, taskwait \n Semantics \n The depend clause enforces additional constraints on the scheduling of tasks.These constraints \n establish dependences only between sibling tasks.Task dependences are derived from the \n task-dependence-type and the list items.\n The storage location of a list item matches the storage location of another list item if they have the \n same storage location, or if any of the list items is omp_all_memory."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n The storage location of a list item matches the storage location of another list item if they have the \n same storage location, or if any of the list items is omp_all_memory.\n For the in task-dependence-type, if the storage location of at least one of the list items matches the \n storage location of a list item appearing in a depend clause with an out, inout, \n mutexinoutset, or inoutset task-dependence-type on a construct from which a sibling task \n was previously generated, then the generated task will be a dependent task of that sibling task.\nCHAPTER 15."}
{"section_title": "15.9.5 depend Clause", "chunk": "\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 323 \n For the out and inout task-dependence-types, if the storage location of at least one of the list \n items matches the storage location of a list item appearing in a depend clause with an in, out, \n inout, mutexinoutset, or inoutset task-dependence-type on a construct from which a \n sibling task was previously generated, then the generated task will be a dependent task of that \n sibling task.\n For the mutexinoutset task-dependence-type, if the storage location of at least one of the list \n items matches the storage location of a list item appearing in a depend clause with an in, out, \n inout, or inoutset task-dependence-type on a construct from which a sibling task was \n previously generated, then the generated task will be a dependent task of that sibling task."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n For the mutexinoutset task-dependence-type, if the storage location of at least one of the list \n items matches the storage location of a list item appearing in a depend clause with an in, out, \n inout, or inoutset task-dependence-type on a construct from which a sibling task was \n previously generated, then the generated task will be a dependent task of that sibling task.\n If a list item appearing in a depend clause with a mutexinoutset task-dependence-type on a \n task generating construct matches a list item appearing in a depend clause with a \n mutexinoutset task-dependence-type on a different task generating construct, and both \n constructs generate sibling tasks, the sibling tasks will be mutually exclusive tasks."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n If a list item appearing in a depend clause with a mutexinoutset task-dependence-type on a \n task generating construct matches a list item appearing in a depend clause with a \n mutexinoutset task-dependence-type on a different task generating construct, and both \n constructs generate sibling tasks, the sibling tasks will be mutually exclusive tasks.\n For the inoutset task-dependence-type, if the storage location of at least one of the list items \n matches the storage location of a list item appearing in a depend clause with an in, out, inout, \n or mutexinoutset task-dependence-type on a construct from which a sibling task was \n previously generated, then the generated task will be a dependent task of that sibling task."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n For the inoutset task-dependence-type, if the storage location of at least one of the list items \n matches the storage location of a list item appearing in a depend clause with an in, out, inout, \n or mutexinoutset task-dependence-type on a construct from which a sibling task was \n previously generated, then the generated task will be a dependent task of that sibling task.\n When the task-dependence-type is depobj, the task dependences are derived from the \n dependences represented by the depend objects specified in the depend clause as if the depend \n clauses of the depobj constructs were specified in the current construct.\n The list items that appear in the depend clause may reference any iterators-identifier defined in its \n iterator modifier.\n The list items that appear in the depend clause may include array sections or the \n omp_all_memory reserved locator."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n The list items that appear in the depend clause may include array sections or the \n omp_all_memory reserved locator.\nFortran \n If a list item has the ALLOCATABLE attribute and its allocation status is unallocated, the behavior \n is unspecified.If a list item has the POINTER attribute and its association status is disassociated or \n undefined, the behavior is unspecified.\nFortran \nC / C++ \n The list items that appear in a depend clause may use shape-operators.\nC / C++ \n \n Note \u2013 The enforced task dependence establishes a synchronization of memory accesses \n performed by a dependent task with respect to accesses performed by the predecessor tasks.\n However, the programmer must properly synchronize with respect to other concurrent accesses that \n occur outside of those tasks."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n However, the programmer must properly synchronize with respect to other concurrent accesses that \n occur outside of those tasks.\n \n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n The task-dependences event occurs in a thread that encounters a task generating construct or a \n taskwait construct with a depend clause immediately after the task-create event for the new \n task or the taskwait-init event.\n The task-dependence event indicates an unfulfilled dependence for the generated task.This event \n occurs in a thread that observes the unfulfilled dependence before it is satisfied.\n Tool Callbacks \n A thread dispatches the ompt_callback_dependences callback for each occurrence of the \n task-dependences event to announce its dependences with respect to the list items in the depend \n clause.This callback has type signature ompt_callback_dependences_t."}
{"section_title": "15.9.5 depend Clause", "chunk": "This callback has type signature ompt_callback_dependences_t.\n A thread dispatches the ompt_callback_task_dependence callback for a task-dependence \n event to report a dependence between a predecessor task (src_task_data) and a dependent task \n (sink_task_data).This callback has type signature ompt_callback_task_dependence_t.\n Restrictions \n Restrictions to the depend clause are as follows: \n \u2022 List items, other than reserved locators, used in depend clauses of the same task or sibling tasks \n must indicate identical storage locations or disjoint storage locations.\n \u2022 List items used in depend clauses cannot be zero-length array sections.\n \u2022 The omp_all_memory reserved locator can only be used in a depend clause with an out or \n inout task-dependence-type.\n \u2022 Array sections cannot be specified in depend clauses with the depobj task-dependence-type."}
{"section_title": "15.9.5 depend Clause", "chunk": "\n \u2022 Array sections cannot be specified in depend clauses with the depobj task-dependence-type.\n \u2022 List items used in depend clauses with the depobj task-dependence-type must be expressions \n of the OpenMP depend type that correspond to depend objects in the initialized state.\n \u2022 List items that are expressions of the OpenMP depend type can only be used in depend \n clauses with the depobj task-dependence-type.\nFortran \n \u2022 A common block name cannot appear in a depend clause.\nFortran \nC / C++ \n \u2022 A bit-field cannot appear in a depend clause.\nC / C++ \nCHAPTER 15."}
{"section_title": "15.9.5 depend Clause", "chunk": "\nC / C++ \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 325 \n Cross References \n \u2022 Array Sections, see Section 3.2.5 \n \u2022 Array Shaping, see Section 3.2.4 \n \u2022 ompt_callback_dependences_t, see Section 19.5.2.8 \n \u2022 ompt_callback_task_dependence_t, see Section 19.5.2.9 \n \u2022 depobj directive, see Section 15.9.4 \n \u2022 interop directive, see Section 14.1 \n \u2022 iterator modifier, see Section 3.2.6 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \n \u2022 task directive, see Section 12.5 \n \u2022 task-dependence-type modifier, see Section 15.9.1 \n \u2022 taskwait directive, see Section 15.5 \n"}
{"section_title": "15.9.6 doacross Clause", "chunk": "17 Name: doacross Properties: required \n Arguments \nName Type Properties \nvector loop-iteration vector default 19 \n Modifiers \nName Modifies Type Properties \ndependence-type vector Keyword: sink, source required 21 \n Directives \n ordered \n Additional information \n The clause-name depend may be used as a synonym for the clause-name doacross.This use \n has been deprecated.\n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The doacross clause identifies cross-iteration dependences that imply additional constraints on \n the scheduling of loop iterations.These constraints establish dependences only between loop \n iterations.\n The source dependence-type specifies the satisfaction of cross-iteration dependences that arise \n from the current iteration.If the source dependence-type is specified then the vector argument is \n optional; if vector is omitted, it is assumed to be omp_cur_iteration."}
{"section_title": "15.9.6 doacross Clause", "chunk": "If the source dependence-type is specified then the vector argument is \n optional; if vector is omitted, it is assumed to be omp_cur_iteration.\n The sink dependence-type specifies a cross-iteration dependence, where vector indicates the \n iteration that satisfies the dependence.If vector does not occur in the iteration space, the \n doacross clause is ignored.If all doacross clauses on an ordered construct are ignored \n then the construct is ignored.\n \n Note \u2013 If the sink dependence-type is specified for a vector that does not indicate an earlier \n iteration of the logical iteration space, deadlock may occur.\n \n Restrictions \n Restrictions to the doacross clause are as follows: \n \u2022 If vector is specified without the omp_cur_iteration keyword and it has n dimensions, the \n innermost loop-associated construct that encloses the construct on which the clause appears must \n specify an ordered clause for which the parameter value equals n."}
{"section_title": "15.9.6 doacross Clause", "chunk": "\n \n Restrictions \n Restrictions to the doacross clause are as follows: \n \u2022 If vector is specified without the omp_cur_iteration keyword and it has n dimensions, the \n innermost loop-associated construct that encloses the construct on which the clause appears must \n specify an ordered clause for which the parameter value equals n.\n \u2022 If vector is specified with the omp_cur_iteration keyword and with sink as the \n dependence-type then it must be omp_cur_iteration - 1.\n \u2022 If vector is specified with source as the dependence-type then it must be \n omp_cur_iteration.\n \u2022 For each element of vector for which the sink dependence-type is specified, if the loop iteration \nvariable vari has an integral or pointer type, the i \nth 26 expression of vector must be computable \nwithout overflow in that type for any value of vari 27 that can encounter the construct on which the \n doacross clause appears."}
{"section_title": "15.9.6 doacross Clause", "chunk": "\n \u2022 For each element of vector for which the sink dependence-type is specified, if the loop iteration \nvariable vari has an integral or pointer type, the i \nth 26 expression of vector must be computable \nwithout overflow in that type for any value of vari 27 that can encounter the construct on which the \n doacross clause appears.\nC++ \n \u2022 For each element of vector for which the sink dependence-type is specified, if the loop iteration \nvariable vari \nis of a random access iterator type other than pointer type, the i \nth 30 expression of \n vector must be computable without overflow in the type that would be used by \nstd::distance applied to variables of the type of vari for any value of vari 32 that can \n encounter the construct on which the doacross clause appears.\nC++ \nCHAPTER 15."}
{"section_title": "15.9.6 doacross Clause", "chunk": "\nC++ \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 327 \n Cross References \n \u2022 OpenMP Loop-Iteration Spaces and Vectors, see Section 4.4.2 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 ordered directive, see Section 15.10.1 \n"}
{"section_title": "15.10 ordered Construct", "chunk": "6 This section describes two forms for the ordered construct, the stand-alone ordered construct \n and the block-associated ordered construct.Both forms include the execution model events, tool \n callbacks, and restrictions listed in this section.\n Execution Model Events \n The ordered-acquiring event occurs in the task that encounters the ordered construct on entry to \n the ordered region before it initiates synchronization for the region.\n The ordered-acquired event occurs in the task that encounters the ordered construct after it \n enters the region, but before it executes the structured block of the ordered region.\n The ordered-released event occurs in the task that encounters the ordered construct after it \n completes any synchronization on exit from the ordered region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of an ordered-acquiring event in that thread."}
{"section_title": "15.10 ordered Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of an ordered-acquiring event in that thread.This callback has the type signature \n ompt_callback_mutex_acquire_t.\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of an ordered-acquired event in that thread.This callback has the type signature \n ompt_callback_mutex_t.\n A thread dispatches a registered ompt_callback_mutex_released callback with \n ompt_mutex_ordered as the kind argument if practical, although a less specific kind may be \n used, for each occurrence of an ordered-released event in that thread.This callback has the type \n signature ompt_callback_mutex_t and occurs in the task that encounters the construct.\n Restrictions \n \u2022 The construct that corresponds to the binding region of an ordered region must specify an \n ordered clause."}
{"section_title": "15.10 ordered Construct", "chunk": "\n Restrictions \n \u2022 The construct that corresponds to the binding region of an ordered region must specify an \n ordered clause.\n \u2022 The construct that corresponds to the binding region of an ordered region must not specify a \n reduction clause with the inscan modifier.\n \u2022 The regions of a stand-alone ordered construct and a block-associated ordered construct \n must not have the same binding region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n"}
{"section_title": "15.10.1 Stand-alone ordered Construct", "chunk": "Name: ordered Association: none \nCategory: executable Properties: default 5 \n Clauses \n doacross \n Binding \n The binding thread set for a stand-alone ordered region is the current team.A stand-alone \n ordered region binds to the innermost enclosing worksharing-loop region.\n Semantics \n The stand-alone ordered construct specifies that execution must not violate cross-iteration \n dependences as specified in the doacross clauses that appear on the construct.When a thread \n that is executing an iteration encounters a ordered construct with one or more doacross \n clauses for which the sink dependence-type is specified, the thread waits until its dependences on \n all valid iterations specified by the doacross clauses are satisfied before it continues execution.A \n specific dependence is satisfied when a thread that is executing the corresponding iteration \n encounters an ordered construct with a doacross clause for which the source \n dependence-type is specified."}
{"section_title": "15.10.1 Stand-alone ordered Construct", "chunk": "A \n specific dependence is satisfied when a thread that is executing the corresponding iteration \n encounters an ordered construct with a doacross clause for which the source \n dependence-type is specified.\n Execution Model Events \n The doacross-sink event occurs in the task that encounters an ordered construct for each \n doacross clause for which the sink dependence-type is specified after the dependence is \n fulfilled.\n The doacross-source event occurs in the task that encounters an ordered construct with a \n doacross clause for which the source dependence-type is specified before signaling that the \n dependence has been fulfilled.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_dependences callback with all vector \n entries listed as ompt_dependence_type_sink in the deps argument for each occurrence of a \n doacross-sink event in that thread."}
{"section_title": "15.10.1 Stand-alone ordered Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_dependences callback with all vector \n entries listed as ompt_dependence_type_sink in the deps argument for each occurrence of a \n doacross-sink event in that thread.A thread dispatches a registered \n ompt_callback_dependences callback with all vector entries listed as \n ompt_dependence_type_source in the deps argument for each occurrence of a \n doacross-source event in that thread.These callbacks have the type signature \n ompt_callback_dependences_t.\nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 329 \n Restrictions \n Additional restrictions to the stand-alone ordered construct are as follows: \n \u2022 At most one doacross clause may appear on the construct with source as the \n dependence-type.\n \u2022 All doacross clauses that appear on the construct must specify the same dependence-type.\n \u2022 The construct must not be an orphaned construct."}
{"section_title": "15.10.1 Stand-alone ordered Construct", "chunk": "\n \u2022 The construct must not be an orphaned construct.\n Cross References \n \u2022 Worksharing-Loop Constructs, see Section 11.5 \n \u2022 ompt_callback_dependences_t, see Section 19.5.2.8 \n \u2022 doacross clause, see Section 15.9.6 \n"}
{"section_title": "15.10.2 Block-associated ordered Construct", "chunk": "Name: ordered Association: block \nCategory: executable Properties: simdizable, thread-limiting 12 \n Clause groups \n parallelization-level \n Binding \n The binding thread set for a block-associated ordered region is the current team.A \n block-associated ordered region binds to the innermost enclosing worksharing-loop, simd or \n worksharing-loop SIMD region.\n Semantics \n If no clauses are specified, the effect is as if the threads parallelization-level clause was \n specified.If the threads clause is specified, the threads in the team that is executing the \n worksharing-loop region execute ordered regions sequentially in the order of the loop iterations.\n If the simd parallelization-level clause is specified, the ordered regions encountered by any \n thread will execute one at a time in the order of the loop iterations."}
{"section_title": "15.10.2 Block-associated ordered Construct", "chunk": "\n If the simd parallelization-level clause is specified, the ordered regions encountered by any \n thread will execute one at a time in the order of the loop iterations.With either \n parallelization-level, execution of code outside the region for different iterations can run in parallel; \n execution of that code within the same iteration must observe any constraints imposed by the \n base-language semantics.\n When the thread that is executing the first iteration of the loop encounters an ordered construct, \n it can enter the ordered region without waiting.When a thread that is executing any subsequent \n iteration encounters a block-associated ordered construct, it waits at the beginning of the \n ordered region until execution of all ordered regions that belong to all previous iterations has \n completed.ordered regions that bind to different regions execute independently of each other."}
{"section_title": "15.10.2 Block-associated ordered Construct", "chunk": "ordered regions that bind to different regions execute independently of each other.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Additional restrictions to the block-associated ordered construct are as follows: \n \u2022 The construct is simdizable only if the simd parallelization-level is specified.\n \u2022 If the simd parallelization-level is specified, the binding region must be a simd region or one \n that corresponds to a combined or composite construct for which the simd construct is a leaf \n construct.\n \u2022 If the threads parallelization-level is specified, the binding region must be a \n worksharing-loop region or one that corresponds to a combined or composite construct for which \n the worksharing-loop is a leaf construct.\n \u2022 If the threads parallelization-level is specified and the binding region corresponds to a \n combined or composite construct then simd construct must not be a leaf construct unless the \n simd parallelization-level is also specified."}
{"section_title": "15.10.2 Block-associated ordered Construct", "chunk": "\n \u2022 If the threads parallelization-level is specified and the binding region corresponds to a \n combined or composite construct then simd construct must not be a leaf construct unless the \n simd parallelization-level is also specified.\n \u2022 During execution of the logical iteration of a loop-associated construct, a thread must not execute \n more than one block-associated ordered region that binds to the corresponding region of the \n loop-associated construct.\n \u2022 An ordered clause with a parameter value equal to one must appear on the construct that \n corresponds to the binding region.\n Cross References \n \u2022 Worksharing-Loop Constructs, see Section 11.5 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 parallelization-level Clauses, see Section 15.10.3 \n \u2022 simd directive, see Section 10.4 \n"}
{"section_title": "15.10.3 parallelization-level Clauses", "chunk": "24 Clause groups \n Properties: unique, inarguable Members: simd, threads \n Directives \n ordered \n Semantics \n The parallelization-level clause grouping defines a set of clauses that indicate the level of \n parallelization with which to associate a construct.\n Cross References \n \u2022 ordered directive, see Section 15.10.2 \nCHAPTER 15.SYNCHRONIZATION CONSTRUCTS AND CLAUSES 331 \n"}
{"section_title": "16 Cancellation Constructs", "chunk": "2 This chapter defines constructs related to cancellation of OpenMP regions.\n"}
{"section_title": "16.1 cancel Construct", "chunk": "Name: cancel Association: none \nCategory: executable Properties: default 4 \n Clauses \n if, do, for, parallel, sections, taskgroup \n Additional information \n The cancel-directive-name clause set consists of the directive-name of each directive that has the \n cancellable property (i.e., directive-name for the worksharing-loop construct, parallel, \n sections and taskgroup).This clause set has the required, unique and exclusive properties.\n Binding \n The binding thread set of the cancel region is the current team.The binding region of the \n cancel region is the innermost enclosing region of the type that corresponds to \n cancel-directive-name.\n Semantics \n The cancel construct activates cancellation of the innermost enclosing region of the type \n specified by cancel-directive-name, which must be the directive-name of a cancellable construct."}
{"section_title": "16.1 cancel Construct", "chunk": "\n Semantics \n The cancel construct activates cancellation of the innermost enclosing region of the type \n specified by cancel-directive-name, which must be the directive-name of a cancellable construct.\n Cancellation of the binding region is activated only if the cancel-var ICV is true, in which case the \n cancel construct causes the encountering task to continue execution at the end of the binding \n region if cancel-directive-name is not taskgroup.If the cancel-var ICV is true and \n cancel-directive-name is taskgroup, the encountering task continues execution at the end of the \n current task region.If the cancel-var ICV is false, the cancel construct is ignored."}
{"section_title": "16.1 cancel Construct", "chunk": "If the cancel-var ICV is false, the cancel construct is ignored.\n Threads check for active cancellation only at cancellation points that are implied at the following \n locations: \n \u2022 cancel regions; \n \u2022 cancellation point regions; \n \u2022 barrier regions; \n \n \u2022 at the end of a worksharing-loop construct with a nowait clause and for which the same list \n item appears in both firstprivate and lastprivate clauses; and \n \u2022 implicit barrier regions.\n When a thread reaches one of the above cancellation points and if the cancel-var ICV is true, then: \n \u2022 If the thread is at a cancel or cancellation point region and cancel-directive-name is \n not taskgroup, the thread continues execution at the end of the canceled region if cancellation \n has been activated for the innermost enclosing region of the type specified."}
{"section_title": "16.1 cancel Construct", "chunk": "\n When a thread reaches one of the above cancellation points and if the cancel-var ICV is true, then: \n \u2022 If the thread is at a cancel or cancellation point region and cancel-directive-name is \n not taskgroup, the thread continues execution at the end of the canceled region if cancellation \n has been activated for the innermost enclosing region of the type specified.\n \u2022 If the thread is at a cancel or cancellation point region and cancel-directive-name is \n taskgroup, the encountering task checks for active cancellation of all of the taskgroup sets to \n which the encountering task belongs, and continues execution at the end of the current task \n region if cancellation has been activated for any of the taskgroup sets."}
{"section_title": "16.1 cancel Construct", "chunk": "\n \u2022 If the thread is at a cancel or cancellation point region and cancel-directive-name is \n taskgroup, the encountering task checks for active cancellation of all of the taskgroup sets to \n which the encountering task belongs, and continues execution at the end of the current task \n region if cancellation has been activated for any of the taskgroup sets.\n \u2022 If the encountering task is at a barrier region or at the end of a worksharing-loop construct with a \n nowait clause and for which the same list item appears in both firstprivate and \n lastprivate clauses, the encountering task checks for active cancellation of the innermost \n enclosing parallel region.If cancellation has been activated, then the encountering task \n continues execution at the end of the canceled region."}
{"section_title": "16.1 cancel Construct", "chunk": "If cancellation has been activated, then the encountering task \n continues execution at the end of the canceled region.\n When cancellation of tasks is activated through a cancel construct with taskgroup for \n cancel-directive-name, the tasks that belong to the taskgroup set of the innermost enclosing \n taskgroup region will be canceled.The task that encountered that construct continues execution \n at the end of its task region, which implies completion of that task.Any task that belongs to the \n innermost enclosing taskgroup and has already begun execution must run to completion or until \n a cancellation point is reached.Upon reaching a cancellation point and if cancellation is active, the \n task continues execution at the end of its task region, which implies the completion of the task.Any \n task that belongs to the innermost enclosing taskgroup and that has not begun execution may be \n discarded, which implies its completion."}
{"section_title": "16.1 cancel Construct", "chunk": "Any \n task that belongs to the innermost enclosing taskgroup and that has not begun execution may be \n discarded, which implies its completion.\n When cancellation of tasks is activated through a cancel construct with cancel-directive-name \n other than taskgroup, each thread of the binding thread set resumes execution at the end of the \n canceled region if a cancellation point is encountered.If the canceled region is a parallel region, \n any tasks that have been created by a task or a taskloop construct and their descendent tasks \n are canceled according to the above taskgroup cancellation semantics.If the canceled region is \n not a parallel region, no task cancellation occurs.\nC++ \n The usual C++ rules for object destruction are followed when cancellation is performed.\nC++ \nFortran \n All private objects or subobjects with ALLOCATABLE attribute that are allocated inside the \n canceled construct are deallocated.\nFortran \nCHAPTER 16."}
{"section_title": "16.1 cancel Construct", "chunk": "\nFortran \nCHAPTER 16.CANCELLATION CONSTRUCTS 333 \n If the canceled construct contains a reduction-scoping or lastprivate clause, the final values of \n the list items that appeared in those clauses are undefined.\n When an if clause is present on a cancel construct and the if expression evaluates to false, the \n cancel construct does not activate cancellation.The cancellation point associated with the \n cancel construct is always encountered regardless of the value of the if expression.\n \n Note \u2013 The programmer is responsible for releasing locks and other synchronization data \n structures that might cause a deadlock when a cancel construct is encountered and blocked \n threads cannot be canceled.The programmer is also responsible for ensuring proper \n synchronizations to avoid deadlocks that might arise from cancellation of OpenMP regions that \n contain OpenMP synchronization constructs."}
{"section_title": "16.1 cancel Construct", "chunk": "The programmer is also responsible for ensuring proper \n synchronizations to avoid deadlocks that might arise from cancellation of OpenMP regions that \n contain OpenMP synchronization constructs.\n \n Execution Model Events \n If a task encounters a cancel construct that will activate cancellation then a cancel event occurs.\n A discarded-task event occurs for any discarded tasks.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a \n cancel event in the context of the encountering task."}
{"section_title": "16.1 cancel Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a \n cancel event in the context of the encountering task.This callback has type signature \n ompt_callback_cancel_t; (flags & ompt_cancel_activated) always evaluates to \n true in the dispatched callback; (flags & ompt_cancel_parallel) evaluates to true in the \n dispatched callback if cancel-directive-name is parallel; \n (flags & ompt_cancel_sections) evaluates to true in the dispatched callback if \n cancel-directive-name is sections; (flags & ompt_cancel_loop) evaluates to true in the \n dispatched callback if cancel-directive-name is for or do; and \n (flags & ompt_cancel_taskgroup) evaluates to true in the dispatched callback if \n cancel-directive-name is taskgroup."}
{"section_title": "16.1 cancel Construct", "chunk": "This callback has type signature \n ompt_callback_cancel_t; (flags & ompt_cancel_activated) always evaluates to \n true in the dispatched callback; (flags & ompt_cancel_parallel) evaluates to true in the \n dispatched callback if cancel-directive-name is parallel; \n (flags & ompt_cancel_sections) evaluates to true in the dispatched callback if \n cancel-directive-name is sections; (flags & ompt_cancel_loop) evaluates to true in the \n dispatched callback if cancel-directive-name is for or do; and \n (flags & ompt_cancel_taskgroup) evaluates to true in the dispatched callback if \n cancel-directive-name is taskgroup.\n A thread dispatches a registered ompt_callback_cancel callback with the ompt_data_t \n associated with the discarded task as its task_data argument and \n ompt_cancel_discarded_task as its flags argument for each occurrence of a \n discarded-task event."}
{"section_title": "16.1 cancel Construct", "chunk": "\n A thread dispatches a registered ompt_callback_cancel callback with the ompt_data_t \n associated with the discarded task as its task_data argument and \n ompt_cancel_discarded_task as its flags argument for each occurrence of a \n discarded-task event.The callback occurs in the context of the task that discards the task and has \n type signature ompt_callback_cancel_t.\n Restrictions \n Restrictions to the cancel construct are as follows: \n \u2022 The behavior for concurrent cancellation of a region and a region nested within it is unspecified.\n \u2022 If cancel-directive-name is taskgroup, the cancel construct must be closely nested inside a \n task or a taskloop construct and the cancel region must be closely nested inside a \n taskgroup region.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If cancel-directive-name is not taskgroup, the cancel construct must be closely nested \n inside an OpenMP construct that matches cancel-directive-name."}
{"section_title": "16.1 cancel Construct", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 If cancel-directive-name is not taskgroup, the cancel construct must be closely nested \n inside an OpenMP construct that matches cancel-directive-name.\n \u2022 A worksharing construct that is canceled must not have a nowait clause or a reduction \n clause with a user-defined reduction that uses omp_orig in the initializer-expr of the \n corresponding declare reduction directive.\n \u2022 A worksharing-loop construct that is canceled must not have an ordered clause or a \n reduction clause with the inscan modifier.\n \u2022 When cancellation is active for a parallel region, a thread in the team that binds to that \n region may not be executing or encounter a worksharing construct with an ordered clause, a \n reduction clause with the inscan modifier or a reduction clause with a user-defined \n reduction that uses omp_orig in the initializer-expr of the corresponding \n declare reduction directive."}
{"section_title": "16.1 cancel Construct", "chunk": "\n \u2022 When cancellation is active for a parallel region, a thread in the team that binds to that \n region may not be executing or encounter a worksharing construct with an ordered clause, a \n reduction clause with the inscan modifier or a reduction clause with a user-defined \n reduction that uses omp_orig in the initializer-expr of the corresponding \n declare reduction directive.\n \u2022 When cancellation is active for a parallel region, a thread in the team that binds to that \n region may not be executing or encounter a scope construct with a reduction clause with a \n user-defined reduction that uses omp_orig in the initializer-expr of the corresponding \n declare reduction directive.\n \u2022 During execution of a construct that may be subject to cancellation, a thread must not encounter \n an orphaned cancellation point.That is, a cancellation point must only be encountered within \n that construct and must not be encountered elsewhere in its region."}
{"section_title": "16.1 cancel Construct", "chunk": "That is, a cancellation point must only be encountered within \n that construct and must not be encountered elsewhere in its region.\n Cross References \n \u2022 omp_get_cancellation, see Section 18.2.8 \n \u2022 ompt_callback_cancel_t, see Section 19.5.2.18 \n \u2022 ompt_cancel_flag_t, see Section 19.4.4.26 \n \u2022 barrier directive, see Section 15.3.1 \n \u2022 cancel-var ICV, see Table 2.1 \n \u2022 cancellation point directive, see Section 16.2 \n \u2022 declare reduction directive, see Section 5.5.11 \n \u2022 do directive, see Section 11.5.2 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 for directive, see Section 11.5.1 \n \u2022 if clause, see Section 3.4 \n \u2022 nowait clause, see Section 15.6 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 parallel directive, see Section 10.1 \nCHAPTER 16."}
{"section_title": "16.1 cancel Construct", "chunk": "\n Cross References \n \u2022 omp_get_cancellation, see Section 18.2.8 \n \u2022 ompt_callback_cancel_t, see Section 19.5.2.18 \n \u2022 ompt_cancel_flag_t, see Section 19.4.4.26 \n \u2022 barrier directive, see Section 15.3.1 \n \u2022 cancel-var ICV, see Table 2.1 \n \u2022 cancellation point directive, see Section 16.2 \n \u2022 declare reduction directive, see Section 5.5.11 \n \u2022 do directive, see Section 11.5.2 \n \u2022 firstprivate clause, see Section 5.4.4 \n \u2022 for directive, see Section 11.5.1 \n \u2022 if clause, see Section 3.4 \n \u2022 nowait clause, see Section 15.6 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 parallel directive, see Section 10.1 \nCHAPTER 16.CANCELLATION CONSTRUCTS 335 \n \u2022 private clause, see Section 5.4.3 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 sections directive, see Section 11.3 \n \u2022 task directive, see Section 12.5 \n \u2022 taskgroup directive, see Section 15.4 \n"}
{"section_title": "16.2 cancellation point Construct", "chunk": "Name: cancellation point Association: none \nCategory: executable Properties: default 7 \n Clauses \n do, for, parallel, sections, taskgroup \n Additional information \n The cancel-directive-name clause set consists of the directive-name of each directive that has the \n cancellable property (i.e., directive-name for the worksharing-loop construct, parallel, \n sections and taskgroup).This clause set has the required, unique and exclusive properties.\n Binding \n The binding thread set of the cancellation point construct is the current team.The binding \n region of the cancellation point region is the innermost enclosing region of the type that \n corresponds to cancel-directive-name."}
{"section_title": "16.2 cancellation point Construct", "chunk": "The binding \n region of the cancellation point region is the innermost enclosing region of the type that \n corresponds to cancel-directive-name.\n Semantics \n The cancellation point construct introduces a user-defined cancellation point at which an \n implicit or explicit task must check if cancellation of the innermost enclosing region of the type \n specified by cancel-directive-name, which must be the directive-name of a cancellable construct, \n has been activated.This construct does not implement any synchronization between threads or \n tasks.When an implicit or explicit task reaches a user-defined cancellation point and if the \n cancel-var ICV is true, then: \n \u2022 If the cancel-directive-name of the encountered cancellation point construct is not \n taskgroup, the thread continues execution at the end of the canceled region if cancellation has \n been activated for the innermost enclosing region of the type specified."}
{"section_title": "16.2 cancellation point Construct", "chunk": "When an implicit or explicit task reaches a user-defined cancellation point and if the \n cancel-var ICV is true, then: \n \u2022 If the cancel-directive-name of the encountered cancellation point construct is not \n taskgroup, the thread continues execution at the end of the canceled region if cancellation has \n been activated for the innermost enclosing region of the type specified.\n \u2022 If the cancel-directive-name of the encountered cancellation point construct is \n taskgroup, the encountering task checks for active cancellation of all taskgroup sets to which \n the encountering task belongs and continues execution at the end of the current task region if \n cancellation has been activated for any of them.\n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n The cancellation event occurs if a task encounters a cancellation point and detects the activation of \n cancellation."}
{"section_title": "16.2 cancellation point Construct", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Execution Model Events \n The cancellation event occurs if a task encounters a cancellation point and detects the activation of \n cancellation.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a \n cancel event in the context of the encountering task."}
{"section_title": "16.2 cancellation point Construct", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_cancel callback for each occurrence of a \n cancel event in the context of the encountering task.This callback has type signature \n ompt_callback_cancel_t; (flags & ompt_cancel_detected) always evaluates to true \n in the dispatched callback; (flags & ompt_cancel_parallel) evaluates to true in the \n dispatched callback if cancel-directive-name of the encountered cancellation point \n construct is parallel; (flags & ompt_cancel_sections) evaluates to true in the \n dispatched callback if cancel-directive-name of the encountered cancellation point \n construct is sections; (flags & ompt_cancel_loop) evaluates to true in the dispatched \n callback if cancel-directive-name of the encountered cancellation point construct is for \n or do; and (flags & ompt_cancel_taskgroup) evaluates to true in the dispatched callback if \n cancel-directive-name of the encountered cancellation point construct is taskgroup."}
{"section_title": "16.2 cancellation point Construct", "chunk": "This callback has type signature \n ompt_callback_cancel_t; (flags & ompt_cancel_detected) always evaluates to true \n in the dispatched callback; (flags & ompt_cancel_parallel) evaluates to true in the \n dispatched callback if cancel-directive-name of the encountered cancellation point \n construct is parallel; (flags & ompt_cancel_sections) evaluates to true in the \n dispatched callback if cancel-directive-name of the encountered cancellation point \n construct is sections; (flags & ompt_cancel_loop) evaluates to true in the dispatched \n callback if cancel-directive-name of the encountered cancellation point construct is for \n or do; and (flags & ompt_cancel_taskgroup) evaluates to true in the dispatched callback if \n cancel-directive-name of the encountered cancellation point construct is taskgroup.\n Restrictions \n Restrictions to the cancellation point construct are as follows: \n \u2022 A cancellation point construct for which cancel-directive-name is taskgroup must be \n closely nested inside a task or taskloop construct, and the cancellation point region \n must be closely nested inside a taskgroup region."}
{"section_title": "16.2 cancellation point Construct", "chunk": "\n Restrictions \n Restrictions to the cancellation point construct are as follows: \n \u2022 A cancellation point construct for which cancel-directive-name is taskgroup must be \n closely nested inside a task or taskloop construct, and the cancellation point region \n must be closely nested inside a taskgroup region.\n \u2022 A cancellation point construct for which cancel-directive-name is not taskgroup must \n be closely nested inside an OpenMP construct that matches cancel-directive-name.\n Cross References \n \u2022 omp_get_cancellation, see Section 18.2.8 \n \u2022 ompt_callback_cancel_t, see Section 19.5.2.18 \n \u2022 cancel-var ICV, see Table 2.1 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 sections directive, see Section 11.3 \n \u2022 taskgroup directive, see Section 15.4 \nCHAPTER 16.CANCELLATION CONSTRUCTS 337 \n"}
{"section_title": "17 Composition of Constructs", "chunk": "2 This chapter defines rules and mechanisms for nesting regions and for combining constructs.\n"}
{"section_title": "17.1 Nesting of Regions", "chunk": "4 This section describes a set of restrictions on the nesting of regions.The restrictions on nesting are \n as follows: \n \u2022 A worksharing region may not be closely nested inside a worksharing, task, taskloop, \n critical, ordered, atomic, or masked region.\n \u2022 A barrier region may not be closely nested inside a worksharing, task, taskloop, \n critical, ordered, atomic, or masked region.\n \u2022 A masked region may not be closely nested inside a worksharing, atomic, task, or \n taskloop region.\n \u2022 An ordered region that corresponds to an ordered construct without any clause or with the \n threads or depend clause may not be closely nested inside a critical, ordered, loop, \n atomic, task, or taskloop region.\n \u2022 An ordered region that corresponds to an ordered construct without the simd clause \n specified must be closely nested inside a worksharing-loop region."}
{"section_title": "17.1 Nesting of Regions", "chunk": "\n \u2022 An ordered region that corresponds to an ordered construct without the simd clause \n specified must be closely nested inside a worksharing-loop region.\n \u2022 An ordered region that corresponds to an ordered construct with the simd clause specified \n must be closely nested inside a simd or worksharing-loop SIMD region.\n \u2022 An ordered region that corresponds to an ordered construct with both the simd and \n threads clauses must be closely nested inside a worksharing-loop SIMD region or closely \n nested inside a worksharing-loop and simd region.\n \u2022 A critical region may not be nested (closely or otherwise) inside a critical region with \n the same name.This restriction is not sufficient to prevent deadlock.\n \u2022 OpenMP constructs may not be encountered during execution of an atomic region."}
{"section_title": "17.1 Nesting of Regions", "chunk": "\n \u2022 OpenMP constructs may not be encountered during execution of an atomic region.\n \u2022 The only OpenMP constructs that can be encountered during execution of a simd (or \n worksharing-loop SIMD) region are the atomic construct, the loop construct without a \n defined binding region, the simd construct and the ordered construct with the simd clause.\n \u2022 If a target update, target data, target enter data, or target exit data \n construct is encountered during execution of a target region, the behavior is unspecified.\n \n \u2022 If a target construct is encountered during execution of a target region and a device \n clause in which the ancestor device-modifier appears is not present on the construct, the \n behavior is unspecified.\n \u2022 A teams region must be strictly nested either within the implicit parallel region that surrounds \n the whole OpenMP program or within a target region."}
{"section_title": "17.1 Nesting of Regions", "chunk": "\n \u2022 A teams region must be strictly nested either within the implicit parallel region that surrounds \n the whole OpenMP program or within a target region.If a teams construct is nested within \n a target construct, that target construct must contain no statements, declarations or \n directives outside of the teams construct.\n \u2022 distribute regions, including any distribute regions arising from composite constructs, \n parallel regions, including any parallel regions arising from combined constructs, loop \n regions, omp_get_num_teams() regions, and omp_get_team_num() regions are the \n only OpenMP regions that may be strictly nested inside the teams region.\n \u2022 A loop region that binds to a teams region must be strictly nested inside a teams region.\n \u2022 A distribute region must be strictly nested inside a teams region."}
{"section_title": "17.1 Nesting of Regions", "chunk": "\n \u2022 A distribute region must be strictly nested inside a teams region.\n \u2022 If cancel-directive-name is taskgroup, the cancel construct must be closely nested inside a \n task construct and the cancel region must be closely nested inside a taskgroup region.\n Otherwise, the cancel construct must be closely nested inside an OpenMP construct for which \n directive-name is cancel-directive-name.\n \u2022 A cancellation point construct for which cancel-directive-name is taskgroup must be \n closely nested inside a task construct, and the cancellation point region must be closely \n nested inside a taskgroup region.Otherwise, a cancellation point construct must be \n closely nested inside an OpenMP construct for which directive-name is cancel-directive-name."}
{"section_title": "17.1 Nesting of Regions", "chunk": "Otherwise, a cancellation point construct must be \n closely nested inside an OpenMP construct for which directive-name is cancel-directive-name.\n \u2022 The only constructs that may be encountered inside a region that corresponds to a construct with \n an order clause that specifies concurrent are the loop, parallel and simd constructs, \n and combined constructs for which directive-name-A is parallel.\n \u2022 A region that corresponds to a construct with an order clause that specifies concurrent may \n not contain calls to the OpenMP Runtime API or to procedures that contain OpenMP directives.\n"}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "28 Constructs \n This section specifies the handling of clauses on combined or composite constructs and the \n handling of implicit clauses from variables with predetermined data sharing if they are not \n predetermined only on a particular construct.Some clauses are permitted only on a single leaf \n construct of the combined or composite construct, in which case the effect is as if the clause is \n applied to that specific construct.Other clauses that are permitted on more than one leaf construct \n have the effect as if they are applied to a subset of those constructs, as detailed in this section.\n The collapse clause is applied once to the combined or composite construct.\nCHAPTER 17.COMPOSITION OF CONSTRUCTS 339 \n The effect of the private clause is as if it is applied only to the innermost leaf construct that \n permits it."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "COMPOSITION OF CONSTRUCTS 339 \n The effect of the private clause is as if it is applied only to the innermost leaf construct that \n permits it.\n The effect of the firstprivate clause is as if it is applied to one or more leaf constructs as \n follows: \n \u2022 To the distribute construct if it is among the constituent constructs; \n \u2022 To the teams construct if it is among the constituent constructs and the distribute \n construct is not; \n \u2022 To a worksharing construct that accepts the clause if one is among the constituent constructs; \n \u2022 To the taskloop construct if it is among the constituent constructs; \n \u2022 To the parallel construct if it is among the constituent constructs and neither a taskloop \n construct nor a worksharing construct that accepts the clause is among them; \n \u2022 To the target construct if it is among the constituent constructs and the same list item neither \n appears in a lastprivate clause nor is the base variable or base pointer of a list item that \n appears in a map clause."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n The effect of the firstprivate clause is as if it is applied to one or more leaf constructs as \n follows: \n \u2022 To the distribute construct if it is among the constituent constructs; \n \u2022 To the teams construct if it is among the constituent constructs and the distribute \n construct is not; \n \u2022 To a worksharing construct that accepts the clause if one is among the constituent constructs; \n \u2022 To the taskloop construct if it is among the constituent constructs; \n \u2022 To the parallel construct if it is among the constituent constructs and neither a taskloop \n construct nor a worksharing construct that accepts the clause is among them; \n \u2022 To the target construct if it is among the constituent constructs and the same list item neither \n appears in a lastprivate clause nor is the base variable or base pointer of a list item that \n appears in a map clause.\n If the parallel construct is among the constituent constructs and the effect is not as if the \n firstprivate clause is applied to it by the above rules, then the effect is as if the shared \n clause with the same list item is applied to the parallel construct."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n If the parallel construct is among the constituent constructs and the effect is not as if the \n firstprivate clause is applied to it by the above rules, then the effect is as if the shared \n clause with the same list item is applied to the parallel construct.If the teams construct is \n among the constituent constructs and the effect is not as if the firstprivate clause is applied to \n it by the above rules, then the effect is as if the shared clause with the same list item is applied to \n the teams construct.\n The effect of the lastprivate clause is as if it is applied to all leaf constructs that permit the \n clause.If the parallel construct is among the constituent constructs and the list item is not also \n specified in the firstprivate clause, then the effect of the lastprivate clause is as if the \n shared clause with the same list item is applied to the parallel construct."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "If the parallel construct is among the constituent constructs and the list item is not also \n specified in the firstprivate clause, then the effect of the lastprivate clause is as if the \n shared clause with the same list item is applied to the parallel construct.If the teams \n construct is among the constituent constructs and the list item is not also specified in the \n firstprivate clause, then the effect of the lastprivate clause is as if the shared clause \n with the same list item is applied to the teams construct.If the target construct is among the \n constituent constructs and the list item is not the base variable or base pointer of a list item that \n appears in a map clause, the effect of the lastprivate clause is as if the same list item appears \n in a map clause with a map-type of tofrom.\n The effect of the shared, default, thread_limit, or order clause is as if it is applied to \n all leaf constructs that permit the clause."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n The effect of the shared, default, thread_limit, or order clause is as if it is applied to \n all leaf constructs that permit the clause.\n The effect of the allocate clause is as if it is applied to all leaf constructs that permit the clause \n and to which a data-sharing attribute clause that may create a private copy of the same list item is \n applied.\n The effect of the reduction clause is as if it is applied to all leaf constructs that permit the \n clause, except for the following constructs: \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 The parallel construct, when combined with the sections, worksharing-loop, loop, or \n taskloop construct; and \n \u2022 The teams construct, when combined with the loop construct.\n For the parallel and teams constructs above, the effect of the reduction clause instead is as \n if each list item or, for any list item that is an array item, its corresponding base array or base \n pointer appears in a shared clause for the construct."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n For the parallel and teams constructs above, the effect of the reduction clause instead is as \n if each list item or, for any list item that is an array item, its corresponding base array or base \n pointer appears in a shared clause for the construct.If the task reduction-modifier is specified, \n the effect is as if it only modifies the behavior of the reduction clause on the innermost leaf \n construct that accepts the modifier (see Section 5.5.8).If the inscan reduction-modifier is \n specified, the effect is as if it modifies the behavior of the reduction clause on all constructs of \n the combined construct to which the clause is applied and that accept the modifier.If a list item in a \n reduction clause on a combined target construct does not have the same base variable or base \n pointer as a list item in a map clause on the construct, then the effect is as if the list item in the \n reduction clause appears as a list item in a map clause with a map-type of tofrom."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "If a list item in a \n reduction clause on a combined target construct does not have the same base variable or base \n pointer as a list item in a map clause on the construct, then the effect is as if the list item in the \n reduction clause appears as a list item in a map clause with a map-type of tofrom.\n The effect of the if clause is described in Section 3.4.\n The effect of the linear clause is as if it is applied to the innermost leaf construct.Additionally, \n if the list item is not the iteration variable of a simd or worksharing-loop SIMD construct, the \n effect on the outer leaf constructs is as if the list item was specified in firstprivate and \n lastprivate clauses on the combined or composite construct, with the rules specified above \n applied."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "Additionally, \n if the list item is not the iteration variable of a simd or worksharing-loop SIMD construct, the \n effect on the outer leaf constructs is as if the list item was specified in firstprivate and \n lastprivate clauses on the combined or composite construct, with the rules specified above \n applied.If a list item of the linear clause is the iteration variable of a simd or worksharing-loop \n SIMD construct and it is not declared in the construct, the effect on the outer leaf constructs is as if \n the list item was specified in a lastprivate clause on the combined or composite construct with \n the rules specified above applied.\n The effect of the nowait clause is as if it is applied to the outermost leaf construct that permits it."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n The effect of the nowait clause is as if it is applied to the outermost leaf construct that permits it.\n If the clauses have expressions on them, such as for various clauses where the argument of the \n clause is an expression, or lower-bound, length, or stride expressions inside array sections (or \n subscript and stride expressions in subscript-triplet for Fortran), or linear-step or alignment \n expressions, the expressions are evaluated immediately before the construct to which the clause has \n been split or duplicated per the above rules (therefore inside of the outer leaf constructs).However, \n the expressions inside the num_teams and thread_limit clauses are always evaluated before \n the outermost leaf construct.\n The restriction that a list item may not appear in more than one data sharing clause with the \n exception of specifying a variable in both firstprivate and lastprivate clauses applies \n after the clauses are split or duplicated per the above rules."}
{"section_title": "17.2 Clauses on Combined and Composite Constructs", "chunk": "\n The restriction that a list item may not appear in more than one data sharing clause with the \n exception of specifying a variable in both firstprivate and lastprivate clauses applies \n after the clauses are split or duplicated per the above rules.\n Restrictions \n Restrictions to clauses on combined and composite constructs are as follows: \n \u2022 A clause that appears on a combined or composite construct must apply to at least one of the leaf \n constructs per the rules defined in this section.\nCHAPTER 17.COMPOSITION OF CONSTRUCTS 341 \n"}
{"section_title": "17.3 Combined and Composite Directive Names", "chunk": "2 Combined constructs are shortcuts for specifying one construct immediately nested inside another \n construct.Composite constructs are also shortcuts for specifying the effect of one construct \n immediately following the effect of another construct.However, composite constructs define \n semantics to combine constructs that cannot otherwise be immediately nested.\n For all combined and composite constructs, directive-name concatenates directive-name-A, the \n directive name of the enclosing construct, with an intervening space followed by directive-name-B, \n the directive name of the nested construct.If directive-name-A and directive-name-B both \n correspond to loop-associated constructs then directive-name is a composite construct.Otherwise \n directive-name is a combined construct.\n If directive-name-A is taskloop, for or do then directive-name-B may be simd."}
{"section_title": "17.3 Combined and Composite Directive Names", "chunk": "\n If directive-name-A is taskloop, for or do then directive-name-B may be simd.\n If directive-name-A is masked then directive-name-B may be taskloop or the directive name of \n a combined or composite construct for which directive-name-A is taskloop.\n If directive-name-A is parallel then directive-name-B may be loop, sections, \n workshare, masked, for, do or the directive name of a combined or composite construct for \n which directive-name-A is masked, for or do.\n If directive-name-A is distribute then directive-name-B may be simd or the directive name of \n a combined or composite construct for which directive-name-A is parallel and for or do is a \n leaf construct.\n If directive-name-A is teams then directive-name-B may be loop, distribute or the directive \n name of a combined or composite construct for which directive-name-A is distribute."}
{"section_title": "17.3 Combined and Composite Directive Names", "chunk": "\n If directive-name-A is teams then directive-name-B may be loop, distribute or the directive \n name of a combined or composite construct for which directive-name-A is distribute.\n If directive-name-A is target then directive-name-B may be simd, parallel, teams, the \n directive name of a combined or composite construct for which directive-name-A is teams or the \n directive name of a combined or composite construct for which directive-name-A is parallel \n and loop, for or do is a leaf construct.\n For all combined or composite constructs for which the masked construct is a leaf construct, the \n directive name master may be substituted for the directive name masked.The use of the \n directive name master has been deprecated."}
{"section_title": "17.3 Combined and Composite Directive Names", "chunk": "The use of the \n directive name master has been deprecated.\n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 do directive, see Section 11.5.2 \n \u2022 for directive, see Section 11.5.1 \n \u2022 loop directive, see Section 11.7 \n \u2022 masked directive, see Section 10.5 \n \u2022 parallel directive, see Section 10.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 sections directive, see Section 11.3 \n \u2022 target directive, see Section 13.8 \n \u2022 taskloop directive, see Section 12.6 \n \u2022 teams directive, see Section 10.2 \n \u2022 workshare directive, see Section 11.4 \n"}
{"section_title": "17.4 Combined Construct Semantics", "chunk": "7 The semantics of the combined constructs are identical to that of explicitly specifying the first \n construct containing one instance of the second construct and no other statements.All combined \n and composite directives for which a loop-associated construct is a leaf construct are themselves \n loop-associated constructs.For combined constructs, tool callbacks are invoked as if the constructs \n were explicitly nested.\n Restrictions \n Restrictions to combined constructs are as follows: \n \u2022 The restrictions of directive-name-A and directive-name-B apply.\n \u2022 If directive-name-A is parallel, the nowait and in_reduction clauses must not be \n specified.\n \u2022 If directive-name-A is target, the copyin clause must not be specified.\n Cross References \n \u2022 copyin clause, see Section 5.7.1 \n \u2022 in_reduction clause, see Section 5.5.10 \n \u2022 nowait clause, see Section 15.6 \n \u2022 parallel directive, see Section 10.1 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "17.5 Composite Construct Semantics", "chunk": "25 Composite constructs combine constructs that otherwise cannot be immediately nested.\n Specifically, composite constructs apply multiple loop-associated constructs to the same canonical \n loop nest.The semantics of each composite construct first apply the semantics of the enclosing \n construct as specified by directive-name-A and any clauses that apply to it.For each task (possibly \n implicit, possibly initial) as appropriate for the semantics of directive-name-A, the application of its \n semantics yields a nested loop of depth two in which the outer loop iterates over the chunks \nCHAPTER 17.COMPOSITION OF CONSTRUCTS 343 \n assigned to that task and the inner loop iterates over the logical iterations of each chunk.The \n semantics of directive-name-B and any clauses that apply to it are then applied to that inner loop.\n For composite constructs, tool callbacks are invoked as if the constructs were explicitly nested."}
{"section_title": "17.5 Composite Construct Semantics", "chunk": "\n For composite constructs, tool callbacks are invoked as if the constructs were explicitly nested.\n If directive-name-A is taskloop and directive-name-B is simd then for the application of the \n simd construct, the effect of any in_reduction clause is as if a reduction clause with the \n same reduction operator and list items is present.\n Restrictions \n Restrictions to composite constructs are as follows: \n \u2022 The restrictions of directive-name-A and directive-name-B apply.\n \u2022 If directive-name-A is distribute, the linear clause may only be specified for loop \n iteration variables of loops that are associated with the construct.\n \u2022 If directive-name-A is distribute, the ordered clause must not be specified."}
{"section_title": "17.5 Composite Construct Semantics", "chunk": "\n \u2022 If directive-name-A is distribute, the ordered clause must not be specified.\n Cross References \n \u2022 distribute directive, see Section 11.6 \n \u2022 in_reduction clause, see Section 5.5.10 \n \u2022 linear clause, see Section 5.4.6 \n \u2022 ordered clause, see Section 4.4.4 \n \u2022 reduction clause, see Section 5.5.8 \n \u2022 simd directive, see Section 10.4 \n \u2022 taskloop directive, see Section 12.6 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18 Runtime Library Routines", "chunk": "2 This chapter describes the OpenMP API runtime library routines and queryable runtime states.All \n OpenMP Runtime API names have an omp_ prefix.Names that begin with the ompx_ prefix are \n reserved for implementation-defined extensions to the OpenMP Runtime API.In this chapter, true \n and false are used as generic terms to simplify the description of the routines.\nC / C++ \n true means a non-zero integer value and false means an integer value of zero.\nC / C++ \nFortran \n true means a logical value of .TRUE.and false means a logical value of .FALSE..\nFortran \nFortran \n Restrictions \n The following restrictions apply to all OpenMP runtime library routines: \n \u2022 OpenMP runtime library routines may not be called from PURE or ELEMENTAL procedures.\n \u2022 OpenMP runtime library routines may not be called in DO CONCURRENT constructs.\nFortran \n"}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "13 For each base language, a compliant implementation must supply a set of definitions for the \n OpenMP API runtime library routines and the special data types of their parameters.The set of \n definitions must contain a declaration for each OpenMP API runtime library routine and variable \n and a definition of each required data type listed below.In addition, each set of definitions may \n specify other implementation specific values.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 345 \nC / C++ \n The library routines are external functions with \u201cC\u201d linkage.\n Prototypes for the C/C++ runtime library routines described in this chapter shall be provided in a \n header file named omp.h."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "\n Prototypes for the C/C++ runtime library routines described in this chapter shall be provided in a \n header file named omp.h.This file also defines the following: \n \u2022 The type omp_allocator_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type with at least the omp_null_allocator enumerator with the \n value zero and an enumerator for each predefined memory allocator in Table 6.3; \n \u2022 omp_atv_default, which is an instance of a type compatible with omp_uintptr_t with \n the value -1; \n \u2022 The type omp_control_tool_result_t; \n \u2022 The type omp_control_tool_t; \n \u2022 The type omp_depend_t; \n \u2022 The type omp_event_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type; \n \u2022 The enumerator omp_initial_device with value -1; \n \u2022 The type omp_interop_t, which must be an implementation-defined integral or pointer type; \n \u2022 The type omp_interop_fr_t, which must be an implementation-defined enum type with \n enumerators named omp_ifr_name where name is a foreign runtime name that is defined in \n the OpenMP Additional Definitions document; \n \u2022 The type omp_intptr_t, which is a signed integer type that is at least the size of a pointer on \n any device; \n \u2022 The enumerator omp_invalid_device with an implementation-defined value less than -1; \n \u2022 The type omp_lock_hint_t (deprecated); \n \u2022 The type omp_lock_t; \n \u2022 The type omp_memspace_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type with an enumerator for at least each predefined memory space in \n Table 6.1; \n \u2022 The type omp_nest_lock_t; \n \u2022 The type omp_pause_resource_t; \n \u2022 The type omp_proc_bind_t; \n \u2022 The type omp_sched_t; \n \u2022 The type omp_sync_hint_t; and \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 The type omp_uintptr_t, which is an unsigned integer type capable of holding a pointer on \n any device."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "This file also defines the following: \n \u2022 The type omp_allocator_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type with at least the omp_null_allocator enumerator with the \n value zero and an enumerator for each predefined memory allocator in Table 6.3; \n \u2022 omp_atv_default, which is an instance of a type compatible with omp_uintptr_t with \n the value -1; \n \u2022 The type omp_control_tool_result_t; \n \u2022 The type omp_control_tool_t; \n \u2022 The type omp_depend_t; \n \u2022 The type omp_event_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type; \n \u2022 The enumerator omp_initial_device with value -1; \n \u2022 The type omp_interop_t, which must be an implementation-defined integral or pointer type; \n \u2022 The type omp_interop_fr_t, which must be an implementation-defined enum type with \n enumerators named omp_ifr_name where name is a foreign runtime name that is defined in \n the OpenMP Additional Definitions document; \n \u2022 The type omp_intptr_t, which is a signed integer type that is at least the size of a pointer on \n any device; \n \u2022 The enumerator omp_invalid_device with an implementation-defined value less than -1; \n \u2022 The type omp_lock_hint_t (deprecated); \n \u2022 The type omp_lock_t; \n \u2022 The type omp_memspace_handle_t, which must be an implementation-defined (for C++ \n possibly scoped) enum type with an enumerator for at least each predefined memory space in \n Table 6.1; \n \u2022 The type omp_nest_lock_t; \n \u2022 The type omp_pause_resource_t; \n \u2022 The type omp_proc_bind_t; \n \u2022 The type omp_sched_t; \n \u2022 The type omp_sync_hint_t; and \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 The type omp_uintptr_t, which is an unsigned integer type capable of holding a pointer on \n any device.\nC / C++ \nC++ \n The OpenMP enumeration types provided in the omp.h header file shall not be scoped \n enumeration types unless explicitly allowed."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "\nC / C++ \nC++ \n The OpenMP enumeration types provided in the omp.h header file shall not be scoped \n enumeration types unless explicitly allowed.\n The omp.h header file also defines a class template that models the Allocator concept in the \n omp::allocator namespace for each predefined memory allocator in Table 6.3 for which the \n name includes neither the omp_ prefix nor the _alloc suffix.\nC++ \nFortran \n The OpenMP Fortran API runtime library routines are external procedures.The return values of \n these routines are of default kind, unless otherwise specified.\n Interface declarations for the OpenMP Fortran runtime library routines described in this chapter \n shall be provided in the form of a Fortran module named omp_lib or a Fortran include file \n named omp_lib.h.Whether the omp_lib.h file provides derived-type definitions or those \n routines that require an explicit interface is implementation defined."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "Whether the omp_lib.h file provides derived-type definitions or those \n routines that require an explicit interface is implementation defined.Whether the include file or \n the module file (or both) is provided is also implementation defined."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "Whether the include file or \n the module file (or both) is provided is also implementation defined.\n These files also define the following: \n \u2022 The default integer named constant omp_allocator_handle_kind; \n \u2022 An integer named constant of kind omp_allocator_handle_kind for each predefined \n memory allocator in Table 6.3; \n \u2022 The default integer named constant omp_alloctrait_key_kind; \n \u2022 The default integer named constant omp_alloctrait_val_kind; \n \u2022 The default integer named constant omp_control_tool_kind; \n \u2022 The default integer named constant omp_control_tool_result_kind; \n \u2022 The default integer named constant omp_depend_kind; \n \u2022 The default integer named constant omp_event_handle_kind; \n \u2022 The default integer named constant omp_initial_device with value -1; \n \u2022 The default integer named constant omp_interop_kind; \n \u2022 The default integer named constant omp_interop_fr_kind; \n \u2022 An integer named constant omp_ifr_name of kind omp_interop_fr_kind for each name \n that is a foreign runtime name that is defined in the OpenMP Additional Definitions document; \nCHAPTER 18."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "\n These files also define the following: \n \u2022 The default integer named constant omp_allocator_handle_kind; \n \u2022 An integer named constant of kind omp_allocator_handle_kind for each predefined \n memory allocator in Table 6.3; \n \u2022 The default integer named constant omp_alloctrait_key_kind; \n \u2022 The default integer named constant omp_alloctrait_val_kind; \n \u2022 The default integer named constant omp_control_tool_kind; \n \u2022 The default integer named constant omp_control_tool_result_kind; \n \u2022 The default integer named constant omp_depend_kind; \n \u2022 The default integer named constant omp_event_handle_kind; \n \u2022 The default integer named constant omp_initial_device with value -1; \n \u2022 The default integer named constant omp_interop_kind; \n \u2022 The default integer named constant omp_interop_fr_kind; \n \u2022 An integer named constant omp_ifr_name of kind omp_interop_fr_kind for each name \n that is a foreign runtime name that is defined in the OpenMP Additional Definitions document; \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 347 \n \u2022 The default integer named constant omp_invalid_device with an implementation-defined \n value less than -1; \n \u2022 The default integer named constant omp_lock_hint_kind (deprecated); \n \u2022 The default integer named constant omp_lock_kind; \n \u2022 The default integer named constant omp_memspace_handle_kind; \n \u2022 An integer named constant of kind omp_memspace_handle_kind for each predefined \n memory space in Table 6.1; \n \u2022 The default integer named constant omp_nest_lock_kind; \n \u2022 The default integer named constant omp_pause_resource_kind; \n \u2022 The default integer named constant omp_proc_bind_kind; \n \u2022 The default integer named constant omp_sched_kind; \n \u2022 The default integer named constant omp_sync_hint_kind; and \n \u2022 The default integer named constant openmp_version with a value yyyymm where yyyy and \n mm are the year and month designations of the version of the OpenMP Fortran API that the \n implementation supports; this value matches that of the C preprocessor macro _OPENMP, when \n a macro preprocessor is supported (see Section 3.3)."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "RUNTIME LIBRARY ROUTINES 347 \n \u2022 The default integer named constant omp_invalid_device with an implementation-defined \n value less than -1; \n \u2022 The default integer named constant omp_lock_hint_kind (deprecated); \n \u2022 The default integer named constant omp_lock_kind; \n \u2022 The default integer named constant omp_memspace_handle_kind; \n \u2022 An integer named constant of kind omp_memspace_handle_kind for each predefined \n memory space in Table 6.1; \n \u2022 The default integer named constant omp_nest_lock_kind; \n \u2022 The default integer named constant omp_pause_resource_kind; \n \u2022 The default integer named constant omp_proc_bind_kind; \n \u2022 The default integer named constant omp_sched_kind; \n \u2022 The default integer named constant omp_sync_hint_kind; and \n \u2022 The default integer named constant openmp_version with a value yyyymm where yyyy and \n mm are the year and month designations of the version of the OpenMP Fortran API that the \n implementation supports; this value matches that of the C preprocessor macro _OPENMP, when \n a macro preprocessor is supported (see Section 3.3).\n Whether any of the OpenMP runtime library routines that take an argument are extended with a \n generic interface so arguments of different KIND type can be accommodated is implementation \n defined."}
{"section_title": "18.1 Runtime Library Definitions", "chunk": "\n Whether any of the OpenMP runtime library routines that take an argument are extended with a \n generic interface so arguments of different KIND type can be accommodated is implementation \n defined.\nFortran \n"}
{"section_title": "18.2 Thread Team Routines", "chunk": "21 This section describes routines that affect and monitor thread teams in the current contention group.\n"}
{"section_title": "18.2.1 omp_set_num_threads", "chunk": "23 Summary \n The omp_set_num_threads routine affects the number of threads to be used for subsequent \n parallel regions that do not specify a num_threads clause, by setting the value of the first \n element of the nthreads-var ICV of the current task.\n Format \nC / C++ \n void omp_set_num_threads(int num_threads); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n subroutine omp_set_num_threads(num_threads) \n integer num_threads \nFortran \n Constraints on Arguments \n The value of the argument passed to this routine must evaluate to a positive integer, or else the \n behavior of this routine is implementation defined.\n Binding \n The binding task set for an omp_set_num_threads region is the generating task.\n Effect \n The effect of this routine is to set the value of the first element of the nthreads-var ICV of the \n current task to the value specified in the argument."}
{"section_title": "18.2.1 omp_set_num_threads", "chunk": "\n Effect \n The effect of this routine is to set the value of the first element of the nthreads-var ICV of the \n current task to the value specified in the argument.\n Cross References \n \u2022 Determining the Number of Threads for a parallel Region, see Section 10.1.1 \n \u2022 nthreads-var ICV, see Table 2.1 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.2.2 omp_get_num_threads", "chunk": "17 Summary \n The omp_get_num_threads routine returns the number of threads in the current team.\n Format \nC / C++ \n int omp_get_num_threads(void); \nC / C++ \nFortran \n integer function omp_get_num_threads() \nFortran \n Binding \n The binding region for an omp_get_num_threads region is the innermost enclosing parallel \n region.\n Effect \n The omp_get_num_threads routine returns the number of threads in the team that is executing \n the parallel region to which the routine region binds.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 349 \n"}
{"section_title": "18.2.3 omp_get_max_threads", "chunk": "2 Summary \n The omp_get_max_threads routine returns an upper bound on the number of threads that \n could be used to form a new team if a parallel construct without a num_threads clause is \n encountered after execution returns from this routine.\n Format \nC / C++ \n int omp_get_max_threads(void); \nC / C++ \nFortran \n integer function omp_get_max_threads() \nFortran \n Binding \n The binding task set for an omp_get_max_threads region is the generating task.\n Effect \n The value returned by omp_get_max_threads is the value of the first element of the \n nthreads-var ICV of the current task.This value is also an upper bound on the number of threads \n that could be used to form a new team if a parallel region without a num_threads clause is \n encountered after execution returns from this routine."}
{"section_title": "18.2.3 omp_get_max_threads", "chunk": "This value is also an upper bound on the number of threads \n that could be used to form a new team if a parallel region without a num_threads clause is \n encountered after execution returns from this routine.\n Cross References \n \u2022 Determining the Number of Threads for a parallel Region, see Section 10.1.1 \n \u2022 nthreads-var ICV, see Table 2.1 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.2.4 omp_get_thread_num", "chunk": "22 Summary \n The omp_get_thread_num routine returns the thread number, within the current team, of the \n calling thread.\n Format \nC / C++ \n int omp_get_thread_num(void); \nC / C++ \nFortran \n integer function omp_get_thread_num() \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n The binding thread set for an omp_get_thread_num region is the current team.The binding \n region for an omp_get_thread_num region is the innermost enclosing parallel region.\n Effect \n The omp_get_thread_num routine returns the thread number of the calling thread, within the \n team that is executing the parallel region to which the routine region binds.The thread number is \n an integer between 0 and one less than the value returned by omp_get_num_threads, \n inclusive.The thread number of the primary thread of the team is 0.\n Cross References \n \u2022 omp_get_num_threads, see Section 18.2.2 \n"}
{"section_title": "18.2.5 omp_in_parallel", "chunk": "12 Summary \n The omp_in_parallel routine returns true if the active-levels-var ICV is greater than zero; \n otherwise, it returns false.\n Format \nC / C++ \n int omp_in_parallel(void); \nC / C++ \nFortran \n logical function omp_in_parallel() \nFortran \n Binding \n The binding task set for an omp_in_parallel region is the generating task.\n Effect \n The effect of the omp_in_parallel routine is to return true if the current task is enclosed by an \n active parallel region, and the parallel region is enclosed by the outermost initial task \n region on the device; otherwise it returns false.\n Cross References \n \u2022 active-levels-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 351 \n"}
{"section_title": "18.2.6 omp_set_dynamic", "chunk": "2 Summary \n The omp_set_dynamic routine enables or disables dynamic adjustment of the number of \n threads available for the execution of subsequent parallel regions by setting the value of the \n dyn-var ICV.\n Format \nC / C++ \n void omp_set_dynamic(int dynamic_threads); \nC / C++ \nFortran \n subroutine omp_set_dynamic(dynamic_threads) \n logical dynamic_threads \nFortran \n Binding \n The binding task set for an omp_set_dynamic region is the generating task.\n Effect \n For implementations that support dynamic adjustment of the number of threads, if the argument to \n omp_set_dynamic evaluates to true, dynamic adjustment is enabled for the current task; \n otherwise, dynamic adjustment is disabled for the current task.For implementations that do not \n support dynamic adjustment of the number of threads, this routine has no effect: the value of \n dyn-var remains false.\n Cross References \n \u2022 dyn-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.7 omp_get_dynamic", "chunk": "21 Summary \n The omp_get_dynamic routine returns the value of the dyn-var ICV, which determines whether \n dynamic adjustment of the number of threads is enabled or disabled.\n Format \nC / C++ \n int omp_get_dynamic(void); \nC / C++ \nFortran \n logical function omp_get_dynamic() \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n The binding task set for an omp_get_dynamic region is the generating task.\n Effect \n This routine returns true if dynamic adjustment of the number of threads is enabled for the current \n task; otherwise, it returns false.If an implementation does not support dynamic adjustment of the \n number of threads, then this routine always returns false.\n Cross References \n \u2022 dyn-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.8 omp_get_cancellation", "chunk": "10 Summary \n The omp_get_cancellation routine returns the value of the cancel-var ICV, which \n determines if cancellation is enabled or disabled.\n Format \nC / C++ \n int omp_get_cancellation(void); \nC / C++ \nFortran \n logical function omp_get_cancellation() \nFortran \n Binding \n The binding task set for an omp_get_cancellation region is the whole program.\n Effect \n This routine returns true if cancellation is enabled.It returns false otherwise.\n Cross References \n \u2022 cancel-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.9 omp_set_nested (Deprecated)", "chunk": "23 Summary \n The deprecated omp_set_nested routine enables or disables nested parallelism by setting the \n max-active-levels-var ICV.\n Format \nC / C++ \n void omp_set_nested(int nested); \nC / C++ \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 353 \nFortran \n subroutine omp_set_nested(nested) \n logical nested \nFortran \n Binding \n The binding task set for an omp_set_nested region is the generating task.\n Effect \n If the argument to omp_set_nested evaluates to true, the value of the max-active-levels-var \n ICV is set to the number of active levels of parallelism that the implementation supports; otherwise, \n if the value of max-active-levels-var is greater than 1 then it is set to 1.This routine has been \n deprecated.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.10 omp_get_nested (Deprecated)", "chunk": "13 Summary \n The deprecated omp_get_nested routine returns whether nested parallelism is enabled or \n disabled, according to the value of the max-active-levels-var ICV.\n Format \nC / C++ \n int omp_get_nested(void); \nC / C++ \nFortran \n logical function omp_get_nested() \nFortran \n Binding \n The binding task set for an omp_get_nested region is the generating task.\n Effect \n This routine returns true if max-active-levels-var is greater than 1 and greater than active-levels-var \n for the current task; it returns false otherwise.If an implementation does not support nested \n parallelism, this routine always returns false.This routine has been deprecated.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.2.11 omp_set_schedule", "chunk": "2 Summary \n The omp_set_schedule routine affects the schedule that is applied when runtime is used as \n schedule kind, by setting the value of the run-sched-var ICV.\n Format \nC / C++ \n void omp_set_schedule(omp_sched_t kind, int chunk_size); \nC / C++ \nFortran \n subroutine omp_set_schedule(kind, chunk_size) \n integer (kind=omp_sched_kind) kind \n integer chunk_size \nFortran \n Constraints on Arguments \n The first argument passed to this routine can be one of the valid OpenMP schedule kinds (except for \n runtime) or any implementation-specific schedule.The C/C++ header file (omp.h) and the \n Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) define the valid \n constants."}
{"section_title": "18.2.11 omp_set_schedule", "chunk": "The C/C++ header file (omp.h) and the \n Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) define the valid \n constants.The valid constants must include the following, which can be extended with \n implementation-specific values: \nC / C++ \n typedef enum omp_sched_t { \n // schedule kinds \n omp_sched_static = 0x1, \n omp_sched_dynamic = 0x2, \n omp_sched_guided = 0x3, \n omp_sched_auto = 0x4, \n \n // schedule modifier \n omp_sched_monotonic = 0x80000000u \n } omp_sched_t; \nC / C++ \nFortran \n ! schedule kinds \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_static = & \n int(Z\u20191\u2019, kind=omp_sched_kind) \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_dynamic = & \n int(Z\u20192\u2019, kind=omp_sched_kind) \nCHAPTER 18."}
{"section_title": "18.2.11 omp_set_schedule", "chunk": "The valid constants must include the following, which can be extended with \n implementation-specific values: \nC / C++ \n typedef enum omp_sched_t { \n // schedule kinds \n omp_sched_static = 0x1, \n omp_sched_dynamic = 0x2, \n omp_sched_guided = 0x3, \n omp_sched_auto = 0x4, \n \n // schedule modifier \n omp_sched_monotonic = 0x80000000u \n } omp_sched_t; \nC / C++ \nFortran \n ! schedule kinds \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_static = & \n int(Z\u20191\u2019, kind=omp_sched_kind) \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_dynamic = & \n int(Z\u20192\u2019, kind=omp_sched_kind) \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 355 \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_guided = & \n int(Z\u20193\u2019, kind=omp_sched_kind) \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_auto = & \n int(Z\u20194\u2019, kind=omp_sched_kind) \n \n ! schedule modifier \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_monotonic = & \n int(Z\u201980000000\u2019, kind=omp_sched_kind) \nFortran \n Binding \n The binding task set for an omp_set_schedule region is the generating task."}
{"section_title": "18.2.11 omp_set_schedule", "chunk": "RUNTIME LIBRARY ROUTINES 355 \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_guided = & \n int(Z\u20193\u2019, kind=omp_sched_kind) \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_auto = & \n int(Z\u20194\u2019, kind=omp_sched_kind) \n \n ! schedule modifier \n integer(kind=omp_sched_kind), & \n parameter :: omp_sched_monotonic = & \n int(Z\u201980000000\u2019, kind=omp_sched_kind) \nFortran \n Binding \n The binding task set for an omp_set_schedule region is the generating task.\n Effect \n The effect of this routine is to set the value of the run-sched-var ICV of the current task to the \n values specified in the two arguments.The schedule is set to the schedule kind that is specified by \n the first argument kind.It can be any of the standard schedule kinds or any other \n implementation-specific one."}
{"section_title": "18.2.11 omp_set_schedule", "chunk": "It can be any of the standard schedule kinds or any other \n implementation-specific one.For the schedule kinds static, dynamic, and guided, the \n chunk_size is set to the value of the second argument, or to the default chunk_size if the value of the \n second argument is less than 1; for the schedule kind auto, the second argument has no meaning; \n for implementation-specific schedule kinds, the values and associated meanings of the second \n argument are implementation defined.\n Each of the schedule kinds can be combined with the omp_sched_monotonic modifier by \n using the + or | operators in C/C++ or the + operator in Fortran.If the schedule kind is combined \n with the omp_sched_monotonic modifier, the schedule is modified as if the monotonic \n schedule modifier was specified.Otherwise, the schedule modifier is nonmonotonic.\n Cross References \n \u2022 run-sched-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.12 omp_get_schedule", "chunk": "30 Summary \n The omp_get_schedule routine returns the schedule that is applied when the runtime schedule \n is used.\n Format \nC / C++ \n void omp_get_schedule(omp_sched_t *kind, int *chunk_size); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n subroutine omp_get_schedule(kind, chunk_size) \n integer (kind=omp_sched_kind) kind \n integer chunk_size \nFortran \n Binding \n The binding task set for an omp_get_schedule region is the generating task.\n Effect \n This routine returns the run-sched-var ICV in the task to which the routine binds.The first \n argument kind returns the schedule to be used.It can be any of the standard schedule kinds as \n defined in Section 18.2.11, or any implementation-specific schedule kind.If the returned schedule \n kind is static, dynamic, or guided, the second argument chunk_size returns the chunk size to \n be used, or a value less than 1 if the default chunk size is to be used."}
{"section_title": "18.2.12 omp_get_schedule", "chunk": "If the returned schedule \n kind is static, dynamic, or guided, the second argument chunk_size returns the chunk size to \n be used, or a value less than 1 if the default chunk size is to be used.The value returned by the \n second argument is implementation defined for any other schedule kinds.\n Cross References \n \u2022 run-sched-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.13 omp_get_thread_limit", "chunk": "16 Summary \n The omp_get_thread_limit routine returns the maximum number of OpenMP threads \n available to participate in the current contention group.\n Format \nC / C++ \n int omp_get_thread_limit(void); \nC / C++ \nFortran \n integer function omp_get_thread_limit() \nFortran \n Binding \n The binding task set for an omp_get_thread_limit region is the generating task.\n Effect \n The omp_get_thread_limit routine returns the value of the thread-limit-var ICV.\n Cross References \n \u2022 thread-limit-var ICV, see Table 2.1 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 357 \n"}
{"section_title": "18.2.14 omp_get_supported_active_levels", "chunk": "2 Summary \n The omp_get_supported_active_levels routine returns the number of active levels of \n parallelism supported by the implementation.\n Format \nC / C++ \n int omp_get_supported_active_levels(void); \nC / C++ \nFortran \n integer function omp_get_supported_active_levels() \nFortran \n Binding \n The binding task set for an omp_get_supported_active_levels region is the generating \n task.\n Effect \n The omp_get_supported_active_levels routine returns the number of active levels of \n parallelism supported by the implementation.The max-active-levels-var ICV cannot have a value \n that is greater than this number.The value that the omp_get_supported_active_levels \n routine returns is implementation defined, but it must be greater than 0.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.15 omp_set_max_active_levels", "chunk": "19 Summary \n The omp_set_max_active_levels routine limits the number of nested active parallel \n regions when a new nested parallel region is generated by the current task by setting the \n max-active-levels-var ICV.\n Format \nC / C++ \n void omp_set_max_active_levels(int max_levels); \nC / C++ \nFortran \n subroutine omp_set_max_active_levels(max_levels) \n integer max_levels \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Constraints on Arguments \n The value of the argument passed to this routine must evaluate to a non-negative integer, otherwise \n the behavior of this routine is implementation defined.\n Binding \n The binding task set for an omp_set_max_active_levels region is the generating task.\n Effect \n The effect of this routine is to set the value of the max-active-levels-var ICV to the value specified \n in the argument."}
{"section_title": "18.2.15 omp_set_max_active_levels", "chunk": "\n Effect \n The effect of this routine is to set the value of the max-active-levels-var ICV to the value specified \n in the argument.\n If the number of active levels requested exceeds the number of active levels of parallelism supported \n by the implementation, the value of the max-active-levels-var ICV will be set to the number of \n active levels supported by the implementation.If the number of active levels requested is less than \n the value of the active-levels-var ICV, the value of the max-active-levels-var ICV will be set to an \n implementation-defined value between the requested number and active-levels-var, inclusive.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \n"}
{"section_title": "18.2.16 omp_get_max_active_levels", "chunk": "17 Summary \n The omp_get_max_active_levels routine returns the value of the max-active-levels-var \n ICV, which determines the maximum number of nested active parallel regions when the innermost \n parallel region is generated by the current task.\n Format \nC / C++ \n int omp_get_max_active_levels(void); \nC / C++ \nFortran \n integer function omp_get_max_active_levels() \nFortran \n Binding \n The binding task set for an omp_get_max_active_levels region is the generating task.\n Effect \n The omp_get_max_active_levels routine returns the value of the max-active-levels-var \n ICV.The current task may only generate an active parallel region if the returned value is greater \n than the value of the active-levels-var ICV.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 359 \n"}
{"section_title": "18.2.17 omp_get_level", "chunk": "2 Summary \n The omp_get_level routine returns the value of the levels-var ICV.\n Format \nC / C++ \n int omp_get_level(void); \nC / C++ \nFortran \n integer function omp_get_level() \nFortran \n Binding \n The binding task set for an omp_get_level region is the generating task.\n Effect \n The effect of the omp_get_level routine is to return the number of nested parallel regions \n (whether active or inactive) that enclose the current task such that all of the parallel regions are \n enclosed by the outermost initial task region on the current device.\n Cross References \n \u2022 levels-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.2.18 omp_get_ancestor_thread_num", "chunk": "17 Summary \n The omp_get_ancestor_thread_num routine returns, for a given nested level of the current \n thread, the thread number of the ancestor of the current thread.\n Format \nC / C++ \n int omp_get_ancestor_thread_num(int level); \nC / C++ \nFortran \n integer function omp_get_ancestor_thread_num(level) \n integer level \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n The binding thread set for an omp_get_ancestor_thread_num region is the encountering \n thread.The binding region for an omp_get_ancestor_thread_num region is the innermost \n enclosing parallel region.\n Effect \n The omp_get_ancestor_thread_num routine returns the thread number of the ancestor at a \n given nest level of the current thread or the thread number of the current thread.If the requested \n nest level is outside the range of 0 and the nest level of the current thread, as returned by the \n omp_get_level routine, the routine returns -1."}
{"section_title": "18.2.18 omp_get_ancestor_thread_num", "chunk": "If the requested \n nest level is outside the range of 0 and the nest level of the current thread, as returned by the \n omp_get_level routine, the routine returns -1.\n \n Note \u2013 When the omp_get_ancestor_thread_num routine is called with a value of \n level=0, the routine always returns 0.If level=omp_get_level(), the routine has the \n same effect as the omp_get_thread_num routine.\n \n Cross References \n \u2022 omp_get_level, see Section 18.2.17 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.2.19 omp_get_team_size", "chunk": "20 Summary \n The omp_get_team_size routine returns, for a given nested level of the current thread, the size \n of the thread team to which the ancestor or the current thread belongs.\n Format \nC / C++ \n int omp_get_team_size(int level); \nC / C++ \nFortran \n integer function omp_get_team_size(level) \n integer level \nFortran \n Binding \n The binding thread set for an omp_get_team_size region is the encountering thread.The \n binding region for an omp_get_team_size region is the innermost enclosing parallel \n region.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 361 \n Effect \n The omp_get_team_size routine returns the size of the thread team to which the ancestor or \n the current thread belongs.If the requested nested level is outside the range of 0 and the nested \n level of the current thread, as returned by the omp_get_level routine, the routine returns -1.\n Inactive parallel regions are regarded as active parallel regions executed with one thread."}
{"section_title": "18.2.19 omp_get_team_size", "chunk": "\n Inactive parallel regions are regarded as active parallel regions executed with one thread.\n \n Note \u2013 When the omp_get_team_size routine is called with a value of level=0, the routine \n always returns 1.If level=omp_get_level(), the routine has the same effect as the \n omp_get_num_threads routine.\n \n Cross References \n \u2022 omp_get_level, see Section 18.2.17 \n \u2022 omp_get_num_threads, see Section 18.2.2 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.2.20 omp_get_active_level", "chunk": "16 Summary \n The omp_get_active_level routine returns the value of the active-levels-var ICV.\n Format \nC / C++ \n int omp_get_active_level(void); \nC / C++ \nFortran \n integer function omp_get_active_level() \nFortran \n Binding \n The binding task set for the an omp_get_active_level region is the generating task.\n Effect \n The effect of the omp_get_active_level routine is to return the number of nested active \n parallel regions enclosing the current task such that all of the parallel regions are enclosed \n by the outermost initial task region on the current device.\n Cross References \n \u2022 active-levels-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.3 Thread Affinity Routines", "chunk": "2 This section describes routines that affect and access thread affinity policies that are in effect.\n"}
{"section_title": "18.3.1 omp_get_proc_bind", "chunk": "4 Summary \n The omp_get_proc_bind routine returns the thread affinity policy to be used for the \n subsequent nested parallel regions that do not specify a proc_bind clause.\n Format \nC / C++ \n omp_proc_bind_t omp_get_proc_bind(void); \nC / C++ \nFortran \n integer (kind=omp_proc_bind_kind) function omp_get_proc_bind() \nFortran \n Constraints on Arguments \n The value returned by this routine must be one of the valid affinity policy kinds.The C/C++ header \n file (omp.h) and the Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) \n define the valid constants."}
{"section_title": "18.3.1 omp_get_proc_bind", "chunk": "The C/C++ header \n file (omp.h) and the Fortran include file (omp_lib.h) and/or Fortran module file (omp_lib) \n define the valid constants.The valid constants must include the following: \nC / C++ \n typedef enum omp_proc_bind_t { \n omp_proc_bind_false = 0, \n omp_proc_bind_true = 1, \n omp_proc_bind_primary = 2, \n omp_proc_bind_master = omp_proc_bind_primary, // (deprecated) \n omp_proc_bind_close = 3, \n omp_proc_bind_spread = 4 \n } omp_proc_bind_t; \nC / C++ \nFortran \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_false = 0 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_true = 1 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_primary = 2 \nCHAPTER 18."}
{"section_title": "18.3.1 omp_get_proc_bind", "chunk": "The valid constants must include the following: \nC / C++ \n typedef enum omp_proc_bind_t { \n omp_proc_bind_false = 0, \n omp_proc_bind_true = 1, \n omp_proc_bind_primary = 2, \n omp_proc_bind_master = omp_proc_bind_primary, // (deprecated) \n omp_proc_bind_close = 3, \n omp_proc_bind_spread = 4 \n } omp_proc_bind_t; \nC / C++ \nFortran \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_false = 0 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_true = 1 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_primary = 2 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 363 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_master = & \n omp_proc_bind_primary ! (deprecated) \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_close = 3 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_spread = 4 \nFortran \n Binding \n The binding task set for an omp_get_proc_bind region is the generating task."}
{"section_title": "18.3.1 omp_get_proc_bind", "chunk": "RUNTIME LIBRARY ROUTINES 363 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_master = & \n omp_proc_bind_primary ! (deprecated) \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_close = 3 \n integer (kind=omp_proc_bind_kind), & \n parameter :: omp_proc_bind_spread = 4 \nFortran \n Binding \n The binding task set for an omp_get_proc_bind region is the generating task.\n Effect \n The effect of this routine is to return the value of the first element of the bind-var ICV of the current \n task.See Section 10.1.3 for the rules that govern the thread affinity policy.\n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 bind-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "18.3.2 omp_get_num_places", "chunk": "18 Summary \n The omp_get_num_places routine returns the number of places available to the execution \n environment in the place list.\n Format \nC / C++ \n int omp_get_num_places(void); \nC / C++ \nFortran \n integer function omp_get_num_places() \nFortran \n Binding \n The binding thread set for an omp_get_num_places region is all threads on a device.The \n effect of executing this routine is not related to any specific region corresponding to any construct \n or API routine.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n The omp_get_num_places routine returns the number of places in the place list.This value is \n equivalent to the number of places in the place-partition-var ICV in the execution environment of \n the initial task.\n Cross References \n \u2022 place-partition-var ICV, see Table 2.1 \n"}
{"section_title": "18.3.3 omp_get_place_num_procs", "chunk": "8 Summary \n The omp_get_place_num_procs routine returns the number of processors available to the \n execution environment in the specified place.\n Format \nC / C++ \n int omp_get_place_num_procs(int place_num); \nC / C++ \nFortran \n integer function omp_get_place_num_procs(place_num) \n integer place_num \nFortran \n Binding \n The binding thread set for an omp_get_place_num_procs region is all threads on a device.\n The effect of executing this routine is not related to any specific region corresponding to any \n construct or API routine.\n Effect \n The omp_get_place_num_procs routine returns the number of processors associated with \n the place numbered place_num.The routine returns zero when place_num is negative or is greater \n than or equal to the value returned by omp_get_num_places().\n Cross References \n \u2022 omp_get_num_places, see Section 18.3.2 \n"}
{"section_title": "18.3.4 omp_get_place_proc_ids", "chunk": "26 Summary \n The omp_get_place_proc_ids routine returns the numerical identifiers of the processors \n available to the execution environment in the specified place.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 365 \n Format \nC / C++ \n void omp_get_place_proc_ids(int place_num, int *ids); \nC / C++ \nFortran \n subroutine omp_get_place_proc_ids(place_num, ids) \n integer place_num \n integer ids(*) \nFortran \n Binding \n The binding thread set for an omp_get_place_proc_ids region is all threads on a device.\n The effect of executing this routine is not related to any specific region corresponding to any \n construct or API routine.\n Effect \n The omp_get_place_proc_ids routine returns the numerical identifiers of each processor \n associated with the place numbered place_num.The numerical identifiers are non-negative and \n their meaning is implementation defined.The numerical identifiers are returned in the array ids and \n their order in the array is implementation defined."}
{"section_title": "18.3.4 omp_get_place_proc_ids", "chunk": "The numerical identifiers are returned in the array ids and \n their order in the array is implementation defined.The array must be sufficiently large to contain \n omp_get_place_num_procs(place_num) integers; otherwise, the behavior is unspecified.\n The routine has no effect when place_num has a negative value or a value greater than or equal to \n omp_get_num_places().\n Cross References \n \u2022 OMP_PLACES, see Section 21.1.6 \n \u2022 omp_get_num_places, see Section 18.3.2 \n \u2022 omp_get_place_num_procs, see Section 18.3.3 \n"}
{"section_title": "18.3.5 omp_get_place_num", "chunk": "23 Summary \n The omp_get_place_num routine returns the place number of the place to which the \n encountering thread is bound.\n Format \nC / C++ \n int omp_get_place_num(void); \nC / C++ \nFortran \n integer function omp_get_place_num() \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n The binding thread set for an omp_get_place_num region is the encountering thread.\n Effect \n When the encountering thread is bound to a place, the omp_get_place_num routine returns the \n place number associated with the thread.The returned value is between 0 and one less than the \n value returned by omp_get_num_places(), inclusive.When the encountering thread is not \n bound to a place, the routine returns -1.\n Cross References \n \u2022 omp_get_num_places, see Section 18.3.2 \n"}
{"section_title": "18.3.6 omp_get_partition_num_places", "chunk": "11 Summary \n The omp_get_partition_num_places routine returns the number of places in the place \n partition of the innermost implicit task.\n Format \nC / C++ \n int omp_get_partition_num_places(void); \nC / C++ \nFortran \n integer function omp_get_partition_num_places() \nFortran \n Binding \n The binding task set for an omp_get_partition_num_places region is the encountering \n implicit task.\n Effect \n The omp_get_partition_num_places routine returns the number of places in the \n place-partition-var ICV.\n Cross References \n \u2022 place-partition-var ICV, see Table 2.1 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 367 \n"}
{"section_title": "18.3.7 omp_get_partition_place_nums", "chunk": "2 Summary \n The omp_get_partition_place_nums routine returns the list of place numbers \n corresponding to the places in the place-partition-var ICV of the innermost implicit task.\n Format \nC / C++ \n void omp_get_partition_place_nums(int *place_nums); \nC / C++ \nFortran \n subroutine omp_get_partition_place_nums(place_nums) \n integer place_nums(*) \nFortran \n Binding \n The binding task set for an omp_get_partition_place_nums region is the encountering \n implicit task.\n Effect \n The omp_get_partition_place_nums routine returns the list of place numbers that \n correspond to the places in the place-partition-var ICV of the innermost implicit task.The array \n must be sufficiently large to contain omp_get_partition_num_places() integers; \n otherwise, the behavior is unspecified.\n Cross References \n \u2022 omp_get_partition_num_places, see Section 18.3.6 \n \u2022 place-partition-var ICV, see Table 2.1 \n"}
{"section_title": "18.3.8 omp_set_affinity_format", "chunk": "21 Summary \n The omp_set_affinity_format routine sets the affinity format to be used on the device by \n setting the value of the affinity-format-var ICV.\n Format \nC / C++ \n void omp_set_affinity_format(const char *format); \nC / C++ \nFortran \n subroutine omp_set_affinity_format(format) \n character(len=*),intent(in) :: format \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n When called from a sequential part of the program, the binding thread set for an \n omp_set_affinity_format region is the encountering thread.When called from within any \n parallel or teams region, the binding thread set (and binding region, if required) for the \n omp_set_affinity_format region is implementation defined.\n Effect \n The effect of omp_set_affinity_format routine is to copy the character string specified by \n the format argument into the affinity-format-var ICV on the current device."}
{"section_title": "18.3.8 omp_set_affinity_format", "chunk": "\n Effect \n The effect of omp_set_affinity_format routine is to copy the character string specified by \n the format argument into the affinity-format-var ICV on the current device.\n This routine has the described effect only when called from a sequential part of the program.When \n called from within a parallel or teams region, the effect of this routine is implementation \n defined.\n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 OMP_AFFINITY_FORMAT, see Section 21.2.5 \n \u2022 OMP_DISPLAY_AFFINITY, see Section 21.2.4 \n \u2022 omp_capture_affinity, see Section 18.3.11 \n \u2022 omp_display_affinity, see Section 18.3.10 \n \u2022 omp_get_affinity_format, see Section 18.3.9 \n"}
{"section_title": "18.3.9 omp_get_affinity_format", "chunk": "20 Summary \n The omp_get_affinity_format routine returns the value of the affinity-format-var ICV on \n the device.\n Format \nC / C++ \n size_t omp_get_affinity_format(char *buffer, size_t size); \nC / C++ \nFortran \n integer function omp_get_affinity_format(buffer) \n character(len=*),intent(out) :: buffer \nFortran \n Binding \n When called from a sequential part of the program, the binding thread set for an \n omp_get_affinity_format region is the encountering thread.When called from within any \n parallel or teams region, the binding thread set (and binding region, if required) for the \n omp_get_affinity_format region is implementation defined.\nCHAPTER 18."}
{"section_title": "18.3.9 omp_get_affinity_format", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 369 \n Effect \nC / C++ \n The omp_get_affinity_format routine returns the number of characters in the \n affinity-format-var ICV on the current device, excluding the terminating null byte (\u2019\\0\u2019) and if \n size is non-zero, writes the value of the affinity-format-var ICV on the current device to buffer \n followed by a null byte.If the return value is larger or equal to size, the affinity format specification \n is truncated, with the terminating null byte stored to buffer[size-1].If size is zero, nothing is \n stored and buffer may be NULL.\nC / C++ \nFortran \n The omp_get_affinity_format routine returns the number of characters that are required to \n hold the affinity-format-var ICV on the current device and writes the value of the \n affinity-format-var ICV on the current device to buffer.If the return value is larger than \n len(buffer), the affinity format specification is truncated."}
{"section_title": "18.3.9 omp_get_affinity_format", "chunk": "If the return value is larger than \n len(buffer), the affinity format specification is truncated.\nFortran \n If the buffer argument does not conform to the specified format then the result is implementation \n defined.\n Cross References \n \u2022 affinity-format-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "18.3.10 omp_display_affinity", "chunk": "19 Summary \n The omp_display_affinity routine prints the OpenMP thread affinity information using the \n format specification provided.\n Format \nC / C++ \n void omp_display_affinity(const char *format); \nC / C++ \nFortran \n subroutine omp_display_affinity(format) \n character(len=*),intent(in) :: format \nFortran \n Binding \n The binding thread set for an omp_display_affinity region is the encountering thread.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n The omp_display_affinity routine prints the thread affinity information of the current \n thread in the format specified by the format argument, followed by a new-line.If the format is \n NULL (for C/C++) or a zero-length string (for Fortran and C/C++), the value of the \n affinity-format-var ICV is used.If the format argument does not conform to the specified format \n then the result is implementation defined.\n Cross References \n \u2022 affinity-format-var ICV, see Table 2.1 \n"}
{"section_title": "18.3.11 omp_capture_affinity", "chunk": "10 Summary \n The omp_capture_affinity routine prints the OpenMP thread affinity information into a \n buffer using the format specification provided.\n Format \nC / C++ \n size_t omp_capture_affinity( \n char *buffer, \n size_t size, \n const char *format \n ); \nC / C++ \nFortran \n integer function omp_capture_affinity(buffer,format) \n character(len=*),intent(out) :: buffer \n character(len=*),intent(in) :: format \nFortran \n Binding \n The binding thread set for an omp_capture_affinity region is the encountering thread.\n Effect \nC / C++ \n The omp_capture_affinity routine returns the number of characters in the entire thread \n affinity information string excluding the terminating null byte (\u2019\\0\u2019).If size is non-zero, it writes \n the thread affinity information of the current thread in the format specified by the format argument \n into the character string buffer followed by a null byte."}
{"section_title": "18.3.11 omp_capture_affinity", "chunk": "If size is non-zero, it writes \n the thread affinity information of the current thread in the format specified by the format argument \n into the character string buffer followed by a null byte.If the return value is larger or equal to \n size, the thread affinity information string is truncated, with the terminating null byte stored to \n buffer[size-1].If size is zero, nothing is stored and buffer may be NULL.If the format is NULL \n or a zero-length string, the value of the affinity-format-var ICV is used.\nC / C++ \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 371 \nFortran \n The omp_capture_affinity routine returns the number of characters required to hold the \n entire thread affinity information string and prints the thread affinity information of the current \n thread into the character string buffer with the size of len(buffer) in the format specified by \n the format argument.If the format is a zero-length string, the value of the affinity-format-var ICV \n is used."}
{"section_title": "18.3.11 omp_capture_affinity", "chunk": "If the format is a zero-length string, the value of the affinity-format-var ICV \n is used.If the return value is larger than len(buffer), the thread affinity information string is \n truncated.If the format is a zero-length string, the value of the affinity-format-var ICV is used.\nFortran \n If the format argument does not conform to the specified format then the result is implementation \n defined.\n Cross References \n \u2022 affinity-format-var ICV, see Table 2.1 \n"}
{"section_title": "18.4 Teams Region Routines", "chunk": "12 This section describes routines that affect and monitor the league of teams that may execute a \n teams region.\n"}
{"section_title": "18.4.1 omp_get_num_teams", "chunk": "15 Summary \n The omp_get_num_teams routine returns the number of initial teams in the current teams \n region.\n Format \nC / C++ \n int omp_get_num_teams(void); \nC / C++ \nFortran \n integer function omp_get_num_teams() \nFortran \n Binding \n The binding task set for an omp_get_num_teams region is the generating task \n Effect \n The effect of this routine is to return the number of initial teams in the current teams region.The \n routine returns 1 if it is called from outside of a teams region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "18.4.2 omp_get_team_num", "chunk": "4 Summary \n The omp_get_team_num routine returns the initial team number of the calling thread.\n Format \nC / C++ \n int omp_get_team_num(void); \nC / C++ \nFortran \n integer function omp_get_team_num() \nFortran \n Binding \n The binding task set for an omp_get_team_num region is the generating task.\n Effect \n The omp_get_team_num routine returns the initial team number of the calling thread.The \n initial team number is an integer between 0 and one less than the value returned by \n omp_get_num_teams(), inclusive.The routine returns 0 if it is called outside of a teams \n region.\n Cross References \n \u2022 omp_get_num_teams, see Section 18.4.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "18.4.3 omp_set_num_teams", "chunk": "20 Summary \n The omp_set_num_teams routine affects the number of threads to be used for subsequent \n teams regions that do not specify a num_teams clause, by setting the value of the nteams-var \n ICV of the current device.\n Format \nC / C++ \n void omp_set_num_teams(int num_teams); \nC / C++ \nFortran \n subroutine omp_set_num_teams(num_teams) \n integer num_teams \nFortran \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 373 \n Constraints on Arguments \n The value of the argument passed to this routine must evaluate to a positive integer, or else the \n behavior of this routine is implementation defined.\n Binding \n The binding task set for an omp_set_num_teams region is the generating task.\n Effect \n The effect of this routine is to set the value of the nteams-var ICV of the current device to the value \n specified in the argument."}
{"section_title": "18.4.3 omp_set_num_teams", "chunk": "\n Effect \n The effect of this routine is to set the value of the nteams-var ICV of the current device to the value \n specified in the argument.\n Restrictions \n Restrictions to the omp_set_num_teams routine are as follows: \n \u2022 The routine may not be called from within a parallel region that is not the implicit parallel region \n that surrounds the whole OpenMP program.\n Cross References \n \u2022 nteams-var ICV, see Table 2.1 \n \u2022 num_teams clause, see Section 10.2.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "18.4.4 omp_get_max_teams", "chunk": "18 Summary \n The omp_get_max_teams routine returns an upper bound on the number of teams that could be \n created by a teams construct without a num_teams clause that is encountered after execution \n returns from this routine.\n Format \nC / C++ \n int omp_get_max_teams(void); \nC / C++ \nFortran \n integer function omp_get_max_teams() \nFortran \n Binding \n The binding task set for an omp_get_max_teams region is the generating task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n The value returned by omp_get_max_teams is the value of the nteams-var ICV of the current \n device.This value is also an upper bound on the number of teams that can be created by a teams \n construct without a num_teams clause that is encountered after execution returns from this \n routine.\n Cross References \n \u2022 nteams-var ICV, see Table 2.1 \n \u2022 num_teams clause, see Section 10.2.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "18.4.5 omp_set_teams_thread_limit", "chunk": "11 Summary \n The omp_set_teams_thread_limit routine defines the maximum number of OpenMP \n threads that can participate in each contention group created by a teams construct.\n Format \nC / C++ \n void omp_set_teams_thread_limit(int thread_limit); \nC / C++ \nFortran \n subroutine omp_set_teams_thread_limit(thread_limit) \n integer thread_limit \nFortran \n Constraints on Arguments \n The value of the argument passed to this routine must evaluate to a positive integer, or else the \n behavior of this routine is implementation defined.\n Binding \n The binding task set for an omp_set_teams_thread_limit region is the generating task.\n Effect \n The omp_set_teams_thread_limit routine sets the value of the teams-thread-limit-var \n ICV to the value of the thread_limit argument."}
{"section_title": "18.4.5 omp_set_teams_thread_limit", "chunk": "\n Effect \n The omp_set_teams_thread_limit routine sets the value of the teams-thread-limit-var \n ICV to the value of the thread_limit argument.If the value of thread_limit exceeds the number of \n OpenMP threads that an implementation supports for each contention group created by a teams \n construct, the value of the teams-thread-limit-var ICV will be set to the number that is supported by \n the implementation.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 375 \n Restrictions \n Restrictions to the omp_set_teams_thread_limit routine are as follows: \n \u2022 The routine may not be called from within a parallel region other than the implicit parallel region \n that surrounds the whole OpenMP program.\n Cross References \n \u2022 teams directive, see Section 10.2 \n \u2022 teams-thread-limit-var ICV, see Table 2.1 \n \u2022 thread_limit clause, see Section 13.3 \n"}
{"section_title": "18.4.6 omp_get_teams_thread_limit", "chunk": "10 Summary \n The omp_get_teams_thread_limit routine returns the maximum number of OpenMP \n threads available to participate in each contention group created by a teams construct.\n Format \nC / C++ \n int omp_get_teams_thread_limit(void); \nC / C++ \nFortran \n integer function omp_get_teams_thread_limit() \nFortran \n Binding \n The binding task set for an omp_get_teams_thread_limit region is the generating task.\n Effect \n The omp_get_teams_thread_limit routine returns the value of the teams-thread-limit-var \n ICV.\n Cross References \n \u2022 teams directive, see Section 10.2 \n \u2022 teams-thread-limit-var ICV, see Table 2.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.5 Tasking Routines", "chunk": "2 This section describes routines that pertain to OpenMP explicit tasks.\n"}
{"section_title": "18.5.1 omp_get_max_task_priority", "chunk": "4 Summary \n The omp_get_max_task_priority routine returns the maximum value that can be specified \n in the priority clause.\n Format \nC / C++ \n int omp_get_max_task_priority(void); \nC / C++ \nFortran \n integer function omp_get_max_task_priority() \nFortran \n Binding \n The binding thread set for an omp_get_max_task_priority region is all threads on the \n device.The effect of executing this routine is not related to any specific region that corresponds to \n any construct or API routine.\n Effect \n The omp_get_max_task_priority routine returns the value of the max-task-priority-var \n ICV, which determines the maximum value that can be specified in the priority clause.\n Cross References \n \u2022 max-task-priority-var ICV, see Table 2.1 \n \u2022 priority clause, see Section 12.4 \n"}
{"section_title": "18.5.2 omp_in_explicit_task", "chunk": "21 Summary \n The omp_in_explicit_task routine returns the value of the explicit-task-var ICV.\n Format \nC / C++ \n int omp_in_explicit_task(void); \nC / C++ \nFortran \n logical function omp_in_explicit_task() \nFortran \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 377 \n Binding \n The binding task set for an omp_in_explicit_task region is the generating task.\n Effect \n The omp_in_explicit_task routine returns the value of the explicit-task-var ICV, which \n indicates whether the encountering region is an explicit task region.\n Cross References \n \u2022 explicit-task-var ICV, see Table 2.1 \n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "18.5.3 omp_in_final", "chunk": "10 Summary \n The omp_in_final routine returns true if the routine is executed in a final task region; \n otherwise, it returns false.\n Format \nC / C++ \n int omp_in_final(void); \nC / C++ \nFortran \n logical function omp_in_final() \nFortran \n Binding \n The binding task set for an omp_in_final region is the generating task.\n Effect \n omp_in_final returns true if the enclosing task region is final.Otherwise, it returns false.\n"}
{"section_title": "18.6 Resource Relinquishing Routines", "chunk": "21 This section describes routines that relinquish resources used by the OpenMP runtime.\n"}
{"section_title": "18.6.1 omp_pause_resource", "chunk": "23 Summary \n The omp_pause_resource routine allows the runtime to relinquish resources used by OpenMP \n on the specified device.\n Format \nC / C++ \n int omp_pause_resource(omp_pause_resource_t kind, int device_num); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n integer function omp_pause_resource(kind, device_num) \n integer (kind=omp_pause_resource_kind) kind \n integer device_num \nFortran \n Constraints on Arguments \n The first argument passed to this routine can be one of the valid OpenMP pause kind, or any \n implementation-specific pause kind.The C/C++ header file (omp.h) and the Fortran include file \n (omp_lib.h) and/or Fortran module file (omp_lib) define the valid constants."}
{"section_title": "18.6.1 omp_pause_resource", "chunk": "The C/C++ header file (omp.h) and the Fortran include file \n (omp_lib.h) and/or Fortran module file (omp_lib) define the valid constants.The valid \n constants must include the following, which can be extended with implementation-specific values: \nC / C++ \n typedef enum omp_pause_resource_t { \n omp_pause_soft = 1, \n omp_pause_hard = 2 \n } omp_pause_resource_t; \nC / C++ \nFortran \n integer (kind=omp_pause_resource_kind), parameter :: & \n omp_pause_soft = 1 \n integer (kind=omp_pause_resource_kind), parameter :: & \n omp_pause_hard = 2 \nFortran \n The second argument passed to this routine indicates the device that will be paused.The \n device_num parameter must be a conforming device number.If the device number has the value \n omp_invalid_device, runtime error termination is performed.\n Binding \n The binding task set for an omp_pause_resource region is the whole program."}
{"section_title": "18.6.1 omp_pause_resource", "chunk": "\n Binding \n The binding task set for an omp_pause_resource region is the whole program.\n Effect \n The omp_pause_resource routine allows the runtime to relinquish resources used by OpenMP \n on the specified device.\n If successful, the omp_pause_hard value results in a hard pause for which the OpenMP state is \n not guaranteed to persist across the omp_pause_resource call.A hard pause may relinquish \n any data allocated by OpenMP on a given device, including data allocated by memory routines for \n that device as well as data present on the device as a result of a declare target directive or \n target data construct.A hard pause may also relinquish any data associated with a \n threadprivate directive.When relinquished and when applicable, base language appropriate \n deallocation/finalization is performed.When relinquished and when applicable, mapped data on a \n device will not be copied back from the device to the host.\nCHAPTER 18."}
{"section_title": "18.6.1 omp_pause_resource", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 379 \n If successful, the omp_pause_soft value results in a soft pause for which the OpenMP state is \n guaranteed to persist across the call, with the exception of any data associated with a \n threadprivate directive, which may be relinquished across the call.When relinquished and \n when applicable, base language appropriate deallocation/finalization is performed.\n \n Note \u2013 A hard pause may relinquish more resources, but may resume processing OpenMP regions \n more slowly.A soft pause allows OpenMP regions to restart more quickly, but may relinquish fewer \n resources.An OpenMP implementation will reclaim resources as needed for OpenMP regions \n encountered after the omp_pause_resource region.Since a hard pause may unmap data on the \n specified device, appropriate data mapping is required before using data on the specified device \n after the omp_pause_region region."}
{"section_title": "18.6.1 omp_pause_resource", "chunk": "Since a hard pause may unmap data on the \n specified device, appropriate data mapping is required before using data on the specified device \n after the omp_pause_region region.\n \n The routine returns zero in case of success, and non-zero otherwise.\n Tool Callbacks \n If the tool is not allowed to interact with the specified device after encountering this call, then the \n runtime must call the tool finalizer for that device.\n Restrictions \n Restrictions to the omp_pause_resource routine are as follows: \n \u2022 The omp_pause_resource region may not be nested in any explicit OpenMP region.\n \u2022 The routine may only be called when all explicit tasks have finalized execution.\n Cross References \n \u2022 Declare Target Directives, see Section 7.8 \n \u2022 target data directive, see Section 13.5 \n \u2022 threadprivate directive, see Section 5.2 \n"}
{"section_title": "18.6.2 omp_pause_resource_all", "chunk": "26 Summary \n The omp_pause_resource_all routine allows the runtime to relinquish resources used by \n OpenMP on all devices.\n Format \nC / C++ \n int omp_pause_resource_all(omp_pause_resource_t kind); \nC / C++ \nFortran \n integer function omp_pause_resource_all(kind) \n integer (kind=omp_pause_resource_kind) kind \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Binding \n The binding task set for an omp_pause_resource_all region is the whole program.\n Effect \n The omp_pause_resource_all routine allows the runtime to relinquish resources used by \n OpenMP on all devices.It is equivalent to calling the omp_pause_resource routine once for \n each available device, including the host device.\n The argument kind passed to this routine can be one of the valid OpenMP pause kind as defined in \n Section 18.6.1, or any implementation-specific pause kind."}
{"section_title": "18.6.2 omp_pause_resource_all", "chunk": "\n The argument kind passed to this routine can be one of the valid OpenMP pause kind as defined in \n Section 18.6.1, or any implementation-specific pause kind.\n Tool Callbacks \n If the tool is not allowed to interact with a given device after encountering this call, then the \n runtime must call the tool finalizer for that device.\n Restrictions \n Restrictions to the omp_pause_resource_all routine are as follows: \n \u2022 The omp_pause_resource_all region may not be nested in any explicit OpenMP region.\n \u2022 The routine may only be called when all explicit tasks have finalized execution.\n Cross References \n \u2022 omp_pause_resource, see Section 18.6.1 \n"}
{"section_title": "18.7 Device Information Routines", "chunk": "19 This section describes routines that pertain to the set of devices that are accessible to an OpenMP \n program.\n"}
{"section_title": "18.7.1 omp_get_num_procs", "chunk": "22 Summary \n The omp_get_num_procs routine returns the number of processors available to the device.\n Format \nC / C++ \n int omp_get_num_procs(void); \nC / C++ \nFortran \n integer function omp_get_num_procs() \nFortran \n Binding \n The binding thread set for an omp_get_num_procs region is all threads on a device.The effect \n of executing this routine is not related to any specific region corresponding to any construct or API \n routine.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 381 \n Effect \n The omp_get_num_procs routine returns the number of processors that are available to the \n device at the time the routine is called.This value may change between the time that it is \n determined by the omp_get_num_procs routine and the time that it is read in the calling \n context due to system actions outside the control of the OpenMP implementation.\n"}
{"section_title": "18.7.2 omp_set_default_device", "chunk": "7 Summary \n The omp_set_default_device routine controls the default target device by assigning the \n value of the default-device-var ICV.\n Format \nC / C++ \n void omp_set_default_device(int device_num); \nC / C++ \nFortran \n subroutine omp_set_default_device(device_num) \n integer device_num \nFortran \n Binding \n The binding task set for an omp_set_default_device region is the generating task.\n Effect \n The effect of this routine is to set the value of the default-device-var ICV of the current task to the \n value specified in the argument.When called from within a target region the effect of this \n routine is unspecified.\n Cross References \n \u2022 default-device-var ICV, see Table 2.1 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.7.3 omp_get_default_device", "chunk": "24 Summary \n The omp_get_default_device routine returns the default target device.\n Format \nC / C++ \n int omp_get_default_device(void); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n integer function omp_get_default_device() \nFortran \n Binding \n The binding task set for an omp_get_default_device region is the generating task.\n Effect \n The omp_get_default_device routine returns the value of the default-device-var ICV of the \n current task.When called from within a target region the effect of this routine is unspecified.\n Cross References \n \u2022 default-device-var ICV, see Table 2.1 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.7.4 omp_get_num_devices", "chunk": "11 Summary \n The omp_get_num_devices routine returns the number of non-host devices available for \n offloading code or data.\n Format \nC / C++ \n int omp_get_num_devices(void); \nC / C++ \nFortran \n integer function omp_get_num_devices() \nFortran \n Binding \n The binding task set for an omp_get_num_devices region is the generating task.\n Effect \n The omp_get_num_devices routine returns the number of available non-host devices onto \n which code or data may be offloaded.When called from within a target region the effect of this \n routine is unspecified.\n Cross References \n \u2022 target directive, see Section 13.8 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 383 \n"}
{"section_title": "18.7.5 omp_get_device_num", "chunk": "2 Summary \n The omp_get_device_num routine returns the device number of the device on which the \n calling thread is executing.\n Format \nC / C++ \n int omp_get_device_num(void); \nC / C++ \nFortran \n integer function omp_get_device_num() \nFortran \n Binding \n The binding task set for an omp_get_device_num region is the generating task.\n Effect \n The omp_get_device_num routine returns the device number of the device on which the \n calling thread is executing.When called on the host device, it will return the same value as the \n omp_get_initial_device routine.\n"}
{"section_title": "18.7.6 omp_is_initial_device", "chunk": "15 Summary \n The omp_is_initial_device routine returns true if the current task is executing on the host \n device; otherwise, it returns false.\n Format \nC / C++ \n int omp_is_initial_device(void); \nC / C++ \nFortran \n logical function omp_is_initial_device() \nFortran \n Binding \n The binding task set for an omp_is_initial_device region is the generating task.\n Effect \n The effect of this routine is to return true if the current task is executing on the host device; \n otherwise, it returns false.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.7.7 omp_get_initial_device", "chunk": "2 Summary \n The omp_get_initial_device routine returns a device number that represents the host \n device.\n Format \nC / C++ \n int omp_get_initial_device(void); \nC / C++ \nFortran \n integer function omp_get_initial_device() \nFortran \n Binding \n The binding task set for an omp_get_initial_device region is the generating task.\n Effect \n The effect of this routine is to return the device number of the host device.The value of the device \n number is the value returned by the omp_get_num_devices routine.When called from within \n a target region the effect of this routine is unspecified.\n Cross References \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8 Device Memory Routines", "chunk": "17 This section describes routines that support allocation of memory and management of pointers in \n the data environments of target devices.\n If the device_num, src_device_num, or dst_device_num argument of a device memory routine has \n the value omp_invalid_device, runtime error termination is performed.\n"}
{"section_title": "18.8.1 omp_target_alloc", "chunk": "22 Summary \n The omp_target_alloc routine allocates memory in a device data environment and returns a \n device pointer to that memory.\n Format \nC / C++ \n void* omp_target_alloc(size_t size, int device_num); \nC / C++ \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 385 \nFortran \n type(c_ptr) function omp_target_alloc(size, device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t, c_int \n integer(c_size_t), value :: size \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n The device_num argument must be a conforming device number.\n Binding \n The binding task set for an omp_target_alloc region is the generating task, which is the target \n task generated by the call to the omp_target_alloc routine.\n Effect \n The omp_target_alloc routine returns a device pointer that references the device address of a \n storage location of size bytes."}
{"section_title": "18.8.1 omp_target_alloc", "chunk": "\n Effect \n The omp_target_alloc routine returns a device pointer that references the device address of a \n storage location of size bytes.The storage location is dynamically allocated in the device data \n environment of the device specified by device_num.The omp_target_alloc routine executes \n as if part of a target task that is generated by the call to the routine and that is an included task.The \n omp_target_alloc routine returns NULL if it cannot dynamically allocate the memory in the \n device data environment.The device pointer returned by omp_target_alloc can be used in an \n is_device_ptr clause (see Section 5.4.7).\nFortran \n The omp_target_alloc routine requires an explicit interface and so might not be provided in \n omp_lib.h.\nFortran \n Execution Model Events \n The target-data-allocation-begin event occurs before a thread initiates a data allocation on a target \n device."}
{"section_title": "18.8.1 omp_target_alloc", "chunk": "\nFortran \n Execution Model Events \n The target-data-allocation-begin event occurs before a thread initiates a data allocation on a target \n device.\n The target-data-allocation-end event occurs after a thread initiates a data allocation on a target \n device.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a \n target-data-allocation-begin event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-allocation-end event in that thread.These callbacks \n have type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-allocation-end event in that thread."}
{"section_title": "18.8.1 omp_target_alloc", "chunk": "\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-allocation-end event in that thread.The callback occurs in the context \n of the target task and has type signature ompt_callback_target_data_op_t.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n Restrictions to the omp_target_alloc routine are as follows.\n \u2022 Freeing the storage returned by omp_target_alloc with any routine other than \n omp_target_free results in unspecified behavior.\n \u2022 When called from within a target region the effect is unspecified.\nC / C++ \n \u2022 Unless the unified_address clause appears on a requires directive in the compilation \n unit, pointer arithmetic is not supported on the device pointer returned by \n omp_target_alloc."}
{"section_title": "18.8.1 omp_target_alloc", "chunk": "\nC / C++ \n \u2022 Unless the unified_address clause appears on a requires directive in the compilation \n unit, pointer arithmetic is not supported on the device pointer returned by \n omp_target_alloc.\nC / C++ \n Cross References \n \u2022 omp_target_free, see Section 18.8.2 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 is_device_ptr clause, see Section 5.4.7 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.2 omp_target_free", "chunk": "16 Summary \n The omp_target_free routine frees the device memory allocated by the \n omp_target_alloc routine.\n Format \nC / C++ \n void omp_target_free(void *device_ptr, int device_num); \nC / C++ \nFortran \n subroutine omp_target_free(device_ptr, device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int \n type(c_ptr), value :: device_ptr \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n A program that calls omp_target_free with a non-null pointer that does not have a value \n returned from omp_target_alloc is non-conforming.The device_num argument must be a \n conforming device number.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 387 \n Binding \n The binding task set for an omp_target_free region is the generating task, which is the target \n task generated by the call to the omp_target_free routine.\n Effect \n The omp_target_free routine frees the memory in the device data environment associated \n with device_ptr."}
{"section_title": "18.8.2 omp_target_free", "chunk": "\n Effect \n The omp_target_free routine frees the memory in the device data environment associated \n with device_ptr.If device_ptr is NULL, the operation is ignored.The omp_target_free \n routine executes as if part of a target task that is generated by the call to the routine and that is an \n included task.Synchronization must be inserted to ensure that all accesses to device_ptr are \n completed before the call to omp_target_free.\nFortran \n The omp_target_free routine requires an explicit interface and so might not be provided in \n omp_lib.h.\nFortran \n Execution Model Events \n The target-data-free-begin event occurs before a thread initiates a data free on a target device.\n The target-data-free-end event occurs after a thread initiates a data free on a target device."}
{"section_title": "18.8.2 omp_target_free", "chunk": "\n The target-data-free-end event occurs after a thread initiates a data free on a target device.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-free-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-free-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-free-begin event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the omp_target_free routine are as follows."}
{"section_title": "18.8.2 omp_target_free", "chunk": "\n Restrictions \n Restrictions to the omp_target_free routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 omp_target_alloc, see Section 18.8.1 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.8.3 omp_target_is_present", "chunk": "2 Summary \n The omp_target_is_present routine tests whether a host pointer refers to storage that is \n mapped to a given device.\n Format \nC / C++ \n int omp_target_is_present(const void *ptr, int device_num); \nC / C++ \nFortran \n integer(c_int) function omp_target_is_present(ptr, device_num) & \n bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int \n type(c_ptr), value :: ptr \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n The value of ptr must be a valid host pointer or NULL.The device_num argument must be a \n conforming device number.\n Binding \n The binding task set for an omp_target_is_present region is the encountering task.\n Effect \n The omp_target_is_present routine returns true if device_num refers to the host device or \n if ptr refers to storage that has corresponding storage in the device data environment of device \n device_num.Otherwise, the routine returns false."}
{"section_title": "18.8.3 omp_target_is_present", "chunk": "Otherwise, the routine returns false.\nFortran \n The omp_target_is_present routine requires an explicit interface and so might not be \n provided in omp_lib.h.\nFortran \n Restrictions \n Restrictions to the omp_target_is_present routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 target directive, see Section 13.8 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 389 \n"}
{"section_title": "18.8.4 omp_target_is_accessible", "chunk": "2 Summary \n The omp_target_is_accessible routine tests whether host memory is accessible from a \n given device.\n Format \nC / C++ \n int omp_target_is_accessible( const void *ptr, size_t size, \n int device_num); \nC / C++ \nFortran \n integer(c_int) function omp_target_is_accessible( & \n ptr, size, device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t, c_int \n type(c_ptr), value :: ptr \n integer(c_size_t), value :: size \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n The value of ptr must be a valid host pointer or NULL.The device_num argument must be a \n conforming device number.\n Binding \n The binding task set for an omp_target_is_accessible region is the encountering task.\n Effect \n This routine returns true if the storage of size bytes starting at the address given by ptr is accessible \n from device device_num.Otherwise, it returns false."}
{"section_title": "18.8.4 omp_target_is_accessible", "chunk": "Otherwise, it returns false.\nFortran \n The omp_target_is_accessible routine requires an explicit interface and so might not be \n provided in omp_lib.h.\nFortran \n Restrictions \n Restrictions to the omp_target_is_accessible routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 target directive, see Section 13.8 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.8.5 omp_target_memcpy", "chunk": "2 Summary \n The omp_target_memcpy routine copies memory between any combination of host and device \n pointers.\n Format \nC / C++ \n int omp_target_memcpy( \n void *dst, \n const void *src, \n size_t length, \n size_t dst_offset, \n size_t src_offset, \n int dst_device_num, \n int src_device_num \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy(dst, src, length, & \n dst_offset, src_offset, dst_device_num, src_device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: length, dst_offset, src_offset \n integer(c_int), value :: dst_device_num, src_device_num \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy.The \n dst_device_num and src_device_num arguments must be conforming device numbers."}
{"section_title": "18.8.5 omp_target_memcpy", "chunk": "The \n dst_device_num and src_device_num arguments must be conforming device numbers.\n Binding \n The binding task set for an omp_target_memcpy region is the generating task, which is the \n target task generated by the call to the omp_target_memcpy routine.\n Effect \n This routine copies length bytes of memory at offset src_offset from src in the device data \n environment of device src_device_num to dst starting at offset dst_offset in the device data \n environment of device dst_device_num.The omp_target_memcpy routine executes as if part of \n a target task that is generated by the call to the routine and that is an included task.The return value \n is zero on success and non-zero on failure.This routine contains a task scheduling point.\nFortran \n The omp_target_memcpy routine requires an explicit interface and so might not be provided in \n omp_lib.h.\nFortran \nCHAPTER 18."}
{"section_title": "18.8.5 omp_target_memcpy", "chunk": "\nFortran \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 391 \n Execution Model Events \n The target-data-op-begin event occurs before a thread initiates a data transfer in the \n omp_target_memcpy region.\n The target-data-op-end event occurs after a thread initiates a data transfer in the \n omp_target_memcpy region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread."}
{"section_title": "18.8.5 omp_target_memcpy", "chunk": "\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the omp_target_memcpy routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "24 Summary \n The omp_target_memcpy_rect routine copies a rectangular subvolume from a \n multi-dimensional array to another multi-dimensional array.The omp_target_memcpy_rect \n routine performs a copy between any combination of host and device pointers."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "The omp_target_memcpy_rect \n routine performs a copy between any combination of host and device pointers.\n Format \nC / C++ \n int omp_target_memcpy_rect( \n void *dst, \n const void *src, \n size_t element_size, \n int num_dims, \n const size_t *volume, \n const size_t *dst_offsets, \n OpenMP API \u2013 Version 5.2 November 2021 \n const size_t *src_offsets, \n const size_t *dst_dimensions, \n const size_t *src_dimensions, \n int dst_device_num, \n int src_device_num \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_rect(dst,src,element_size, & \n num_dims, volume, dst_offsets, src_offsets, dst_dimensions, src_dimensions, & \n dst_device_num, src_device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: element_size \n integer(c_int), value :: num_dims, dst_device_num, src_device_num \n integer(c_size_t), intent(in) :: volume(*), dst_offsets(*), & \n src_offsets(*), dst_dimensions(*), src_dimensions(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "\n Format \nC / C++ \n int omp_target_memcpy_rect( \n void *dst, \n const void *src, \n size_t element_size, \n int num_dims, \n const size_t *volume, \n const size_t *dst_offsets, \n OpenMP API \u2013 Version 5.2 November 2021 \n const size_t *src_offsets, \n const size_t *dst_dimensions, \n const size_t *src_dimensions, \n int dst_device_num, \n int src_device_num \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_rect(dst,src,element_size, & \n num_dims, volume, dst_offsets, src_offsets, dst_dimensions, src_dimensions, & \n dst_device_num, src_device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: element_size \n integer(c_int), value :: num_dims, dst_device_num, src_device_num \n integer(c_size_t), intent(in) :: volume(*), dst_offsets(*), & \n src_offsets(*), dst_dimensions(*), src_dimensions(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy.The \n dst_device_num and src_device_num arguments must be conforming device numbers."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "The \n dst_device_num and src_device_num arguments must be conforming device numbers.The length \n of the offset and dimension arrays must be at least the value of num_dims.The value of num_dims \n must be between 1 and the implementation-defined limit, which must be at least three.\nFortran \n Because the interface binds directly to a C language function the function assumes C memory \n ordering.\nFortran \n Binding \n The binding task set for an omp_target_memcpy_rect region is the generating task, which is \n the target task generated by the call to the omp_target_memcpy_rect routine.\n Effect \n This routine copies a rectangular subvolume of src, in the device data environment of device \n src_device_num, to dst, in the device data environment of device dst_device_num.The volume is \n specified in terms of the size of an element, number of dimensions, and constant arrays of length \n num_dims."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "The volume is \n specified in terms of the size of an element, number of dimensions, and constant arrays of length \n num_dims.The maximum number of dimensions supported is at least three; support for higher \n dimensionality is implementation defined.The volume array specifies the length, in number of \n elements, to copy in each dimension from src to dst.The dst_offsets (src_offsets) parameter \n specifies the number of elements from the origin of dst (src) in elements.The dst_dimensions \n (src_dimensions) parameter specifies the length of each dimension of dst (src).\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 393 \n The omp_target_memcpy_rect routine executes as if part of a target task that is generated by \n the call to the routine and that is an included task.The routine returns zero if successful.\n Otherwise, it returns a non-zero value.The routine contains a task scheduling point."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "The routine contains a task scheduling point.\n An application can determine the inclusive number of dimensions supported by an implementation \n by passing NULL for both dst and src.The routine returns the number of dimensions supported by \n the implementation for the specified device numbers.No copy operation is performed.\nFortran \n The omp_target_memcpy_rect routine requires an explicit interface and so might not be \n provided in omp_lib.h.\nFortran \n Execution Model Events \n The target-data-op-begin event occurs before a thread initiates a data transfer in the \n omp_target_memcpy_rect region.\n The target-data-op-end event occurs after a thread initiates a data transfer in the \n omp_target_memcpy_rect region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the omp_target_memcpy_rect routine are as follows.\n \u2022 When called from within a target region the effect is unspecified."}
{"section_title": "18.8.6 omp_target_memcpy_rect", "chunk": "\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "32 Summary \n The omp_target_memcpy_async routine asynchronously performs a copy between any \n combination of host and device pointers."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "32 Summary \n The omp_target_memcpy_async routine asynchronously performs a copy between any \n combination of host and device pointers.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n int omp_target_memcpy_async( \n void *dst, \n const void *src, \n size_t length, \n size_t dst_offset, \n size_t src_offset, \n int dst_device_num, \n int src_device_num, \n int depobj_count, \n omp_depend_t *depobj_list \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_async(dst, src, length, & \n dst_offset, src_offset, dst_device_num, src_device_num, & \n depobj_count, depobj_list) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: length, dst_offset, src_offset \n integer(c_int), value :: dst_device_num, src_device_num, depobj_count \n integer(omp_depend_kind), optional :: depobj_list(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n int omp_target_memcpy_async( \n void *dst, \n const void *src, \n size_t length, \n size_t dst_offset, \n size_t src_offset, \n int dst_device_num, \n int src_device_num, \n int depobj_count, \n omp_depend_t *depobj_list \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_async(dst, src, length, & \n dst_offset, src_offset, dst_device_num, src_device_num, & \n depobj_count, depobj_list) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: length, dst_offset, src_offset \n integer(c_int), value :: dst_device_num, src_device_num, depobj_count \n integer(omp_depend_kind), optional :: depobj_list(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy.The \n dst_device_num and src_device_num arguments must be conforming device numbers."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "The \n dst_device_num and src_device_num arguments must be conforming device numbers.\n Binding \n The binding task set for an omp_target_memcpy_async region is the generating task, which \n is the target task generated by the call to the omp_target_memcpy_async routine.\n Effect \n This routine performs an asynchronous memory copy where length bytes of memory at offset \n src_offset from src in the device data environment of device src_device_num are copied to dst \n starting at offset dst_offset in the device data environment of device dst_device_num.The \n omp_target_memcpy_async routine executes as if part of a target task that is generated by the \n call to the routine and for which execution may be deferred.Task dependences are expressed with \n zero or more OpenMP depend objects.The dependences are specified by passing the number of \n depend objects followed by an array of the objects."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "The dependences are specified by passing the number of \n depend objects followed by an array of the objects.The generated target task is not a dependent task \n if the program passes in a count of zero for depobj_count.depobj_list is ignored if the value of \n depobj_count is zero.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 395 \n The routine returns zero if successful.Otherwise, it returns a non-zero value.The routine contains \n a task scheduling point.\nFortran \n The omp_target_memcpy_async routine requires an explicit interface and so might not be \n provided in omp_lib.h.\nFortran \n Execution Model Events \n The target-data-op-begin event occurs before a thread initiates a data transfer in the \n omp_target_memcpy_async region.\n The target-data-op-end event occurs after a thread initiates a data transfer in the \n omp_target_memcpy_async region."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "\n The target-data-op-end event occurs after a thread initiates a data transfer in the \n omp_target_memcpy_async region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the omp_target_memcpy_async routine are as follows."}
{"section_title": "18.8.7 omp_target_memcpy_async", "chunk": "\n Restrictions \n Restrictions to the omp_target_memcpy_async routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 Depend Objects, see Section 15.9.2 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "29 Summary \n The omp_target_memcpy_rect_async routine asynchronously performs a copy between \n any combination of host and device pointers."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "29 Summary \n The omp_target_memcpy_rect_async routine asynchronously performs a copy between \n any combination of host and device pointers.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n int omp_target_memcpy_rect_async( \n void *dst, \n const void *src, \n size_t element_size, \n int num_dims, \n const size_t *volume, \n const size_t *dst_offsets, \n const size_t *src_offsets, \n const size_t *dst_dimensions, \n const size_t *src_dimensions, \n int dst_device_num, \n int src_device_num, \n int depobj_count, \n omp_depend_t *depobj_list \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_rect_async(dst, src, & \n element_size, num_dims, volume, dst_offsets, src_offsets, & \n dst_dimensions, src_dimensions, dst_device_num, src_device_num, & \n depobj_count, depobj_list) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: element_size \n integer(c_int), value :: num_dims, dst_device_num, src_device_num, & \n depobj_count \n integer(c_size_t), intent(in) :: volume(*), dst_offsets(*), & \n src_offsets(*), dst_dimensions(*), src_dimensions(*) \n integer(omp_depobj_kind), optional :: depobj_list(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n int omp_target_memcpy_rect_async( \n void *dst, \n const void *src, \n size_t element_size, \n int num_dims, \n const size_t *volume, \n const size_t *dst_offsets, \n const size_t *src_offsets, \n const size_t *dst_dimensions, \n const size_t *src_dimensions, \n int dst_device_num, \n int src_device_num, \n int depobj_count, \n omp_depend_t *depobj_list \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_memcpy_rect_async(dst, src, & \n element_size, num_dims, volume, dst_offsets, src_offsets, & \n dst_dimensions, src_dimensions, dst_device_num, src_device_num, & \n depobj_count, depobj_list) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int, c_size_t \n type(c_ptr), value :: dst, src \n integer(c_size_t), value :: element_size \n integer(c_int), value :: num_dims, dst_device_num, src_device_num, & \n depobj_count \n integer(c_size_t), intent(in) :: volume(*), dst_offsets(*), & \n src_offsets(*), dst_dimensions(*), src_dimensions(*) \n integer(omp_depobj_kind), optional :: depobj_list(*) \nFortran \n Constraints on Arguments \n Each device pointer specified must be valid for the device on the same side of the copy.The \n dst_device_num and src_device_num arguments must be conforming device numbers."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "The \n dst_device_num and src_device_num arguments must be conforming device numbers.The length \n of the offset and dimension arrays must be at least the value of num_dims.The value of num_dims \n must be between 1 and the implementation-defined limit, which must be at least three.\nFortran \n Because the interface binds directly to a C language function the function assumes C memory \n ordering.\nFortran \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 397 \n Binding \n The binding task set for an omp_target_memcpy_rect_async region is the generating task, \n which is the target task generated by the call to the omp_target_memcpy_rect_async \n routine.\n Effect \n This routine copies a rectangular subvolume of src, in the device data environment of device \n src_device_num, to dst, in the device data environment of device dst_device_num.The volume is \n specified in terms of the size of an element, number of dimensions, and constant arrays of length \n num_dims."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "The volume is \n specified in terms of the size of an element, number of dimensions, and constant arrays of length \n num_dims.The maximum number of dimensions supported is at least three; support for higher \n dimensionality is implementation defined.The volume array specifies the length, in number of \n elements, to copy in each dimension from src to dst.The dst_offsets (src_offsets) parameter \n specifies the number of elements from the origin of dst (src) in elements.The dst_dimensions \n (src_dimensions) parameter specifies the length of each dimension of dst (src).\n The omp_target_memcpy_rect_async routine executes as if part of a target task that is \n generated by the call to the routine and for which execution may be deferred.Task dependences are \n expressed with zero or more OpenMP depend objects.The dependences are specified by passing \n the number of depend objects followed by an array of the objects."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "The dependences are specified by passing \n the number of depend objects followed by an array of the objects.The generated target task is not a \n dependent task if the program passes in a count of zero for depobj_count.depobj_list is ignored if \n the value of depobj_count is zero.\n The routine returns zero if successful.Otherwise, it returns a non-zero value.The routine contains \n a task scheduling point.\n An application can determine the number of inclusive dimensions supported by an implementation \n by passing NULL for both dst and src.The routine returns the number of dimensions supported by \n the implementation for the specified device numbers.No copy operation is performed.\nFortran \n The omp_target_memcpy_rect_async routine requires an explicit interface and so might \n not be provided in omp_lib.h.\nFortran \n Execution Model Events \n The target-data-op-begin event occurs before a thread initiates a data transfer in the \n omp_target_memcpy_rect_async region."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "\nFortran \n Execution Model Events \n The target-data-op-begin event occurs before a thread initiates a data transfer in the \n omp_target_memcpy_rect_async region.\n The target-data-op-end event occurs after a thread initiates a data transfer in the \n omp_target_memcpy_rect_async region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op_emi callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a target-data-op-begin \n event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_end as its endpoint \n argument for each occurrence of a target-data-op-end event in that thread.These callbacks have \n type signature ompt_callback_target_data_op_emi_t.\n OpenMP API \u2013 Version 5.2 November 2021 \n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread."}
{"section_title": "18.8.8 omp_target_memcpy_rect_async", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n A thread dispatches a registered ompt_callback_target_data_op callback for each \n occurrence of a target-data-op-end event in that thread.The callback occurs in the context of the \n target task and has type signature ompt_callback_target_data_op_t.\n Restrictions \n Restrictions to the omp_target_memcpy_rect_async routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 Depend Objects, see Section 15.9.2 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.9 omp_target_associate_ptr", "chunk": "13 Summary \n The omp_target_associate_ptr routine maps a device pointer, which may be returned \n from omp_target_alloc or implementation-defined runtime routines, to a host pointer.\n Format \nC / C++ \n int omp_target_associate_ptr( \n const void *host_ptr, \n const void *device_ptr, \n size_t size, \n size_t device_offset, \n int device_num \n ); \nC / C++ \nFortran \n integer(c_int) function omp_target_associate_ptr(host_ptr, & \n device_ptr, size, device_offset, device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t, c_int \n type(c_ptr), value :: host_ptr, device_ptr \n integer(c_size_t), value :: size, device_offset \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n The value of device_ptr value must be a valid pointer to device memory for the device denoted by \n the value of device_num.The device_num argument must be a conforming device number.\nCHAPTER 18."}
{"section_title": "18.8.9 omp_target_associate_ptr", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 399 \n Binding \n The binding task set for an omp_target_associate_ptr region is the generating task, which \n is the target task generated by the call to the omp_target_associate_ptr routine.\n Effect \n The omp_target_associate_ptr routine associates a device pointer in the device data \n environment of device device_num with a host pointer such that when the host pointer appears in a \n subsequent map clause, the associated device pointer is used as the target for data motion \n associated with that host pointer.The device_offset parameter specifies the offset into device_ptr \n that is used as the base address for the device side of the mapping.The reference count of the \n resulting mapping will be infinite.After being successfully associated, the buffer to which the \n device pointer points is invalidated and accessing data directly through the device pointer results in \n unspecified behavior."}
{"section_title": "18.8.9 omp_target_associate_ptr", "chunk": "After being successfully associated, the buffer to which the \n device pointer points is invalidated and accessing data directly through the device pointer results in \n unspecified behavior.The pointer can be retrieved for other uses by using the \n omp_target_disassociate_ptr routine to disassociate it .\n The omp_target_associate_ptr routine executes as if part of a target task that is generated \n by the call to the routine and that is an included task.The routine returns zero if successful.\n Otherwise it returns a non-zero value.\n Only one device buffer can be associated with a given host pointer value and device number pair.\n Attempting to associate a second buffer will return non-zero.Associating the same pair of pointers \n on the same device with the same offset has no effect and returns zero.Associating pointers that \n share underlying storage will result in unspecified behavior."}
{"section_title": "18.8.9 omp_target_associate_ptr", "chunk": "Associating pointers that \n share underlying storage will result in unspecified behavior.The omp_target_is_present \n function can be used to test whether a given host pointer has a corresponding variable in the device \n data environment.\nFortran \n The omp_target_associate_ptr routine requires an explicit interface and so might not be \n provided in omp_lib.h.\nFortran \n Execution Model Events \n The target-data-associate event occurs before a thread initiates a device pointer association on a \n target device.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op callback, or a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_beginend as its \n endpoint argument for each occurrence of a target-data-associate event in that thread.These \n callbacks have type signature ompt_callback_target_data_op_t or \n ompt_callback_target_data_op_emi_t, respectively."}
{"section_title": "18.8.9 omp_target_associate_ptr", "chunk": "These \n callbacks have type signature ompt_callback_target_data_op_t or \n ompt_callback_target_data_op_emi_t, respectively.\n Restrictions \n Restrictions to the omp_target_associate_ptr routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 omp_target_alloc, see Section 18.8.1 \n \u2022 omp_target_disassociate_ptr, see Section 18.8.10 \n \u2022 omp_target_is_present, see Section 18.8.3 \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.10 omp_target_disassociate_ptr", "chunk": "9 Summary \n The omp_target_disassociate_ptr removes the associated pointer for a given device \n from a host pointer.\n Format \nC / C++ \n int omp_target_disassociate_ptr(const void *ptr, int device_num); \nC / C++ \nFortran \n integer(c_int) function omp_target_disassociate_ptr(ptr, & \n device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int \n type(c_ptr), value :: ptr \n integer(c_int), value :: device_num \nFortran \n Constraints on Arguments \n The device_num argument must be a conforming device number.\n Binding \n The binding task set for an omp_target_disassociate_ptr region is the generating task, \n which is the target task generated by the call to the omp_target_disassociate_ptr routine.\n Effect \n The omp_target_disassociate_ptr removes the associated device data on device \n device_num from the presence table for host pointer ptr."}
{"section_title": "18.8.10 omp_target_disassociate_ptr", "chunk": "\n Effect \n The omp_target_disassociate_ptr removes the associated device data on device \n device_num from the presence table for host pointer ptr.A call to this routine on a pointer that is \n not NULL and does not have associated data on the given device results in unspecified behavior.\n The reference count of the mapping is reduced to zero, regardless of its current value.The \n omp_target_disassociate_ptr routine executes as if part of a target task that is generated \n by the call to the routine and that is an included task.The routine returns zero if successful.\n Otherwise it returns a non-zero value.After a call to omp_target_disassociate_ptr, the \n contents of the device buffer are invalidated.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 401 \nFortran \n The omp_target_disassociate_ptr routine requires an explicit interface and so might not \n be provided in omp_lib.h."}
{"section_title": "18.8.10 omp_target_disassociate_ptr", "chunk": "RUNTIME LIBRARY ROUTINES 401 \nFortran \n The omp_target_disassociate_ptr routine requires an explicit interface and so might not \n be provided in omp_lib.h.\nFortran \n Execution Model Events \n The target-data-disassociate event occurs before a thread initiates a device pointer disassociation \n on a target device.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_target_data_op callback, or a registered \n ompt_callback_target_data_op_emi callback with ompt_scope_beginend as its \n endpoint argument for each occurrence of a target-data-disassociate event in that thread.These \n callbacks have type signature ompt_callback_target_data_op_t or \n ompt_callback_target_data_op_emi_t, respectively.\n Restrictions \n Restrictions to the omp_target_disassociate_ptr routine are as follows.\n \u2022 When called from within a target region the effect is unspecified."}
{"section_title": "18.8.10 omp_target_disassociate_ptr", "chunk": "\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.8.11 omp_get_mapped_ptr", "chunk": "20 Summary \n The omp_get_mapped_ptr routine returns the device pointer that is associated with a host \n pointer for a given device.\n Format \nC / C++ \n void * omp_get_mapped_ptr(const void *ptr, int device_num); \nC / C++ \nFortran \n type(c_ptr) function omp_get_mapped_ptr(ptr, & \n device_num) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_int \n type(c_ptr), value :: ptr \n integer(c_int), value :: device_num \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n Constraints on Arguments \n The device_num argument must be a conforming device number.\n Binding \n The binding task set for an omp_get_mapped_ptr region is the encountering task.\n Effect \n The omp_get_mapped_ptr routine returns the associated device pointer on device device_num.\n A call to this routine for a pointer that is not NULL and does not have an associated pointer on the \n given device will return NULL.The routine returns NULL if unsuccessful."}
{"section_title": "18.8.11 omp_get_mapped_ptr", "chunk": "The routine returns NULL if unsuccessful.Otherwise it returns the \n device pointer, which is ptr if device_num is the value returned by \n omp_get_initial_device().\nFortran \n The omp_get_mapped_ptr routine requires an explicit interface and so might not be provided \n in omp_lib.h.\nFortran \n Execution Model Events \n No events are associated with this routine.\n Restrictions \n Restrictions to the omp_get_mapped_ptr routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 omp_get_initial_device, see Section 18.7.7 \n"}
{"section_title": "18.9 Lock Routines", "chunk": "21 The OpenMP runtime library includes a set of general-purpose lock routines that can be used for \n synchronization.These general-purpose lock routines operate on OpenMP locks that are \n represented by OpenMP lock variables.OpenMP lock variables must be accessed only through the \n routines described in this section; programs that otherwise access OpenMP lock variables are \n non-conforming.\n An OpenMP lock can be in one of the following states: uninitialized; unlocked; or locked.If a lock \n is in the unlocked state, a task can set the lock, which changes its state to locked.The task that sets \n the lock is then said to own the lock.A task that owns a lock can unset that lock, returning it to the \n unlocked state.A program in which a task unsets a lock that is owned by another task is \n non-conforming.\n Two types of locks are supported: simple locks and nestable locks."}
{"section_title": "18.9 Lock Routines", "chunk": "\n Two types of locks are supported: simple locks and nestable locks.A nestable lock can be set \n multiple times by the same task before being unset; a simple lock cannot be set if it is already \n owned by the task trying to set it.Simple lock variables are associated with simple locks and can \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 403 \n only be passed to simple lock routines.Nestable lock variables are associated with nestable locks \n and can only be passed to nestable lock routines.\n Each type of lock can also have a synchronization hint that contains information about the intended \n usage of the lock by the application code.The effect of the hint is implementation defined.An \n OpenMP implementation can use this hint to select a usage-specific lock, but hints do not change \n the mutual exclusion semantics of locks.A conforming implementation can safely ignore the hint."}
{"section_title": "18.9 Lock Routines", "chunk": "A conforming implementation can safely ignore the hint.\n Constraints on the state and ownership of the lock accessed by each of the lock routines are \n described with the routine.If these constraints are not met, the behavior of the routine is \n unspecified.\n The OpenMP lock routines access a lock variable such that they always read and update the most \n current value of the lock variable.An OpenMP program does not need to include explicit flush \n directives to ensure that the lock variable\u2019s value is consistent among different tasks.\n Binding \n The binding thread set for all lock routine regions is all threads in the contention group.As a \n consequence, for each OpenMP lock, the lock routine effects relate to all tasks that call the routines, \n without regard to which teams in the contention group the threads that are executing the tasks \n belong.\n Simple Lock Routines \nC / C++ \n The type omp_lock_t represents a simple lock."}
{"section_title": "18.9 Lock Routines", "chunk": "\n Simple Lock Routines \nC / C++ \n The type omp_lock_t represents a simple lock.For the following routines, a simple lock variable \n must be of omp_lock_t type.All simple lock routines require an argument that is a pointer to a \n variable of type omp_lock_t.\nC / C++ \nFortran \n For the following routines, a simple lock variable must be an integer variable of \n kind=omp_lock_kind.\nFortran \n The simple lock routines are as follows: \n \u2022 The omp_init_lock routine initializes a simple lock; \n \u2022 The omp_init_lock_with_hint routine initializes a simple lock and attaches a hint to it; \n \u2022 The omp_destroy_lock routine uninitializes a simple lock; \n \u2022 The omp_set_lock routine waits until a simple lock is available and then sets it; \n \u2022 The omp_unset_lock routine unsets a simple lock; and \n \u2022 The omp_test_lock routine tests a simple lock and sets it if it is available."}
{"section_title": "18.9 Lock Routines", "chunk": "\nFortran \n The simple lock routines are as follows: \n \u2022 The omp_init_lock routine initializes a simple lock; \n \u2022 The omp_init_lock_with_hint routine initializes a simple lock and attaches a hint to it; \n \u2022 The omp_destroy_lock routine uninitializes a simple lock; \n \u2022 The omp_set_lock routine waits until a simple lock is available and then sets it; \n \u2022 The omp_unset_lock routine unsets a simple lock; and \n \u2022 The omp_test_lock routine tests a simple lock and sets it if it is available.\n OpenMP API \u2013 Version 5.2 November 2021 \n Nestable Lock Routines \nC / C++ \n The type omp_nest_lock_t represents a nestable lock.For the following routines, a nestable \n lock variable must be of omp_nest_lock_t type.All nestable lock routines require an \n argument that is a pointer to a variable of type omp_nest_lock_t.\nC / C++ \nFortran \n For the following routines, a nestable lock variable must be an integer variable of \n kind=omp_nest_lock_kind."}
{"section_title": "18.9 Lock Routines", "chunk": "\nC / C++ \nFortran \n For the following routines, a nestable lock variable must be an integer variable of \n kind=omp_nest_lock_kind.\nFortran \n The nestable lock routines are as follows: \n \u2022 The omp_init_nest_lock routine initializes a nestable lock; \n \u2022 The omp_init_nest_lock_with_hint routine initializes a nestable lock and attaches a \n hint to it; \n \u2022 The omp_destroy_nest_lock routine uninitializes a nestable lock; \n \u2022 The omp_set_nest_lock routine waits until a nestable lock is available and then sets it; \n \u2022 The omp_unset_nest_lock routine unsets a nestable lock; and \n \u2022 The omp_test_nest_lock routine tests a nestable lock and sets it if it is available.\n Restrictions \n Restrictions to OpenMP lock routines are as follows: \n \u2022 The use of the same OpenMP lock in different contention groups results in unspecified behavior.\n"}
{"section_title": "18.9.1 omp_init_lock and omp_init_nest_lock", "chunk": "19 Summary \n These routines initialize an OpenMP lock without a hint.\n Format \nC / C++ \n void omp_init_lock(omp_lock_t *lock); \n void omp_init_nest_lock(omp_nest_lock_t *lock); \nC / C++ \nFortran \n subroutine omp_init_lock(svar) \n integer (kind=omp_lock_kind) svar \n \n subroutine omp_init_nest_lock(nvar) \n integer (kind=omp_nest_lock_kind) nvar \nFortran \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 405 \n Constraints on Arguments \n A program that accesses a lock that is not in the uninitialized state through either routine is \n non-conforming.\n Effect \n The effect of these routines is to initialize the lock to the unlocked state; that is, no task owns the \n lock.In addition, the nesting count for a nestable lock is set to zero.\n Execution Model Events \n The lock-init event occurs in a thread that executes an omp_init_lock region after initialization \n of the lock, but before it finishes the region."}
{"section_title": "18.9.1 omp_init_lock and omp_init_nest_lock", "chunk": "\n Execution Model Events \n The lock-init event occurs in a thread that executes an omp_init_lock region after initialization \n of the lock, but before it finishes the region.The nest-lock-init event occurs in a thread that executes \n an omp_init_nest_lock region after initialization of the lock, but before it finishes the region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_lock_init callback with \n omp_sync_hint_none as the hint argument and ompt_mutex_lock as the kind argument \n for each occurrence of a lock-init event in that thread.Similarly, a thread dispatches a registered \n ompt_callback_lock_init callback with omp_sync_hint_none as the hint argument \n and ompt_mutex_nest_lock as the kind argument for each occurrence of a nest-lock-init \n event in that thread.These callbacks have the type signature \n ompt_callback_mutex_acquire_t and occur in the task that encounters the routine."}
{"section_title": "18.9.1 omp_init_lock and omp_init_nest_lock", "chunk": "These callbacks have the type signature \n ompt_callback_mutex_acquire_t and occur in the task that encounters the routine.\n Cross References \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n"}
{"section_title": "18.9.2 omp_init_lock_with_hint and omp_init_nest_lock_with_hint", "chunk": "22 omp_init_nest_lock_with_hint \n Summary \n These routines initialize an OpenMP lock with a hint.The effect of the hint is \n implementation-defined.The OpenMP implementation can ignore the hint without changing \n program semantics.\n Format \nC / C++ \n void omp_init_lock_with_hint( \n omp_lock_t *lock, \n omp_sync_hint_t hint \n ); \n void omp_init_nest_lock_with_hint( \n omp_nest_lock_t *lock, \n omp_sync_hint_t hint \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n subroutine omp_init_lock_with_hint(svar, hint) \n integer (kind=omp_lock_kind) svar \n integer (kind=omp_sync_hint_kind) hint \n \n subroutine omp_init_nest_lock_with_hint(nvar, hint) \n integer (kind=omp_nest_lock_kind) nvar \n integer (kind=omp_sync_hint_kind) hint \nFortran \n Constraints on Arguments \n A program that accesses a lock that is not in the uninitialized state through either routine is \n non-conforming."}
{"section_title": "18.9.2 omp_init_lock_with_hint and omp_init_nest_lock_with_hint", "chunk": "\n Format \nC / C++ \n void omp_init_lock_with_hint( \n omp_lock_t *lock, \n omp_sync_hint_t hint \n ); \n void omp_init_nest_lock_with_hint( \n omp_nest_lock_t *lock, \n omp_sync_hint_t hint \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n subroutine omp_init_lock_with_hint(svar, hint) \n integer (kind=omp_lock_kind) svar \n integer (kind=omp_sync_hint_kind) hint \n \n subroutine omp_init_nest_lock_with_hint(nvar, hint) \n integer (kind=omp_nest_lock_kind) nvar \n integer (kind=omp_sync_hint_kind) hint \nFortran \n Constraints on Arguments \n A program that accesses a lock that is not in the uninitialized state through either routine is \n non-conforming.The second argument passed to these routines (hint) is a hint as described in \n Section 15.1.\n Effect \n The effect of these routines is to initialize the lock to the unlocked state and, optionally, to choose a \n specific lock implementation based on the hint."}
{"section_title": "18.9.2 omp_init_lock_with_hint and omp_init_nest_lock_with_hint", "chunk": "\n Effect \n The effect of these routines is to initialize the lock to the unlocked state and, optionally, to choose a \n specific lock implementation based on the hint.After initialization no task owns the lock.In \n addition, the nesting count for a nestable lock is set to zero.\n Execution Model Events \n The lock-init-with-hint event occurs in a thread that executes an omp_init_lock_with_hint \n region after initialization of the lock, but before it finishes the region.The nest-lock-init-with-hint \n event occurs in a thread that executes an omp_init_nest_lock region after initialization of the \n lock, but before it finishes the region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_lock_init callback with the same value \n for its hint argument as the hint argument of the call to omp_init_lock_with_hint and \n ompt_mutex_lock as the kind argument for each occurrence of a lock-init-with-hint event in \n that thread."}
{"section_title": "18.9.2 omp_init_lock_with_hint and omp_init_nest_lock_with_hint", "chunk": "\n Tool Callbacks \n A thread dispatches a registered ompt_callback_lock_init callback with the same value \n for its hint argument as the hint argument of the call to omp_init_lock_with_hint and \n ompt_mutex_lock as the kind argument for each occurrence of a lock-init-with-hint event in \n that thread.Similarly, a thread dispatches a registered ompt_callback_lock_init callback \n with the same value for its hint argument as the hint argument of the call to \n omp_init_nest_lock_with_hint and ompt_mutex_nest_lock as the kind argument \n for each occurrence of a nest-lock-init-with-hint event in that thread.These callbacks have the type \n signature ompt_callback_mutex_acquire_t and occur in the task that encounters the \n routine.\n Cross References \n \u2022 Synchronization Hints, see Section 15.1 \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 407 \n"}
{"section_title": "18.9.3 omp_destroy_lock and omp_destroy_nest_lock", "chunk": "2 Summary \n These routines ensure that the OpenMP lock is uninitialized.\n Format \nC / C++ \n void omp_destroy_lock(omp_lock_t *lock); \n void omp_destroy_nest_lock(omp_nest_lock_t *lock); \nC / C++ \nFortran \n subroutine omp_destroy_lock(svar) \n integer (kind=omp_lock_kind) svar \n \n subroutine omp_destroy_nest_lock(nvar) \n integer (kind=omp_nest_lock_kind) nvar \nFortran \n Constraints on Arguments \n A program that accesses a lock that is not in the unlocked state through either routine is \n non-conforming.\n Effect \n The effect of these routines is to change the state of the lock to uninitialized.\n Execution Model Events \n The lock-destroy event occurs in a thread that executes an omp_destroy_lock region before it \n finishes the region.The nest-lock-destroy event occurs in a thread that executes an \n omp_destroy_nest_lock region before it finishes the region."}
{"section_title": "18.9.3 omp_destroy_lock and omp_destroy_nest_lock", "chunk": "The nest-lock-destroy event occurs in a thread that executes an \n omp_destroy_nest_lock region before it finishes the region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_lock_destroy callback with \n ompt_mutex_lock as the kind argument for each occurrence of a lock-destroy event in that \n thread.Similarly, a thread dispatches a registered ompt_callback_lock_destroy callback \n with ompt_mutex_nest_lock as the kind argument for each occurrence of a nest-lock-destroy \n event in that thread.These callbacks have the type signature ompt_callback_mutex_t and \n occur in the task that encounters the routine.\n Cross References \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.9.4 omp_set_lock and omp_set_nest_lock", "chunk": "2 Summary \n These routines provide a means of setting an OpenMP lock.The calling task region behaves as if it \n was suspended until the lock can be set by this task.\n Format \nC / C++ \n void omp_set_lock(omp_lock_t *lock); \n void omp_set_nest_lock(omp_nest_lock_t *lock); \nC / C++ \nFortran \n subroutine omp_set_lock(svar) \n integer (kind=omp_lock_kind) svar \n \n subroutine omp_set_nest_lock(nvar) \n integer (kind=omp_nest_lock_kind) nvar \nFortran \n Constraints on Arguments \n A program that accesses a lock that is in the uninitialized state through either routine is \n non-conforming.A simple lock accessed by omp_set_lock that is in the locked state must not \n be owned by the task that contains the call or deadlock will result.\n Effect \n Each of these routines has an effect equivalent to suspension of the task that is executing the routine \n until the specified lock is available."}
{"section_title": "18.9.4 omp_set_lock and omp_set_nest_lock", "chunk": "\n Effect \n Each of these routines has an effect equivalent to suspension of the task that is executing the routine \n until the specified lock is available.\n \n Note \u2013 The semantics of these routines is specified as if they serialize execution of the region \n guarded by the lock.However, implementations may implement them in other ways provided that \n the isolation properties are respected so that the actual execution delivers a result that could arise \n from some serialization.\n \n A simple lock is available if it is unlocked.Ownership of the lock is granted to the task that \n executes the routine.A nestable lock is available if it is unlocked or if it is already owned by the \n task that executes the routine.The task that executes the routine is granted, or retains, ownership of \n the lock, and the nesting count for the lock is incremented.\nCHAPTER 18."}
{"section_title": "18.9.4 omp_set_lock and omp_set_nest_lock", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 409 \n Execution Model Events \n The lock-acquire event occurs in a thread that executes an omp_set_lock region before the \n associated lock is requested.The nest-lock-acquire event occurs in a thread that executes an \n omp_set_nest_lock region before the associated lock is requested.\n The lock-acquired event occurs in a thread that executes an omp_set_lock region after it \n acquires the associated lock but before it finishes the region.The nest-lock-acquired event occurs in \n a thread that executes an omp_set_nest_lock region if the thread did not already own the \n lock, after it acquires the associated lock but before it finishes the region.\n The nest-lock-owned event occurs in a thread when it already owns the lock and executes an \n omp_set_nest_lock region.The event occurs after the nesting count is incremented but \n before the thread finishes the region."}
{"section_title": "18.9.4 omp_set_lock and omp_set_nest_lock", "chunk": "The event occurs after the nesting count is incremented but \n before the thread finishes the region.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of a lock-acquire or nest-lock-acquire event in that thread.This callback has the type \n signature ompt_callback_mutex_acquire_t.\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of a lock-acquired or nest-lock-acquired event in that thread.This callback has the type \n signature ompt_callback_mutex_t.\n A thread dispatches a registered ompt_callback_nest_lock callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a nest-lock-owned event in \n that thread.This callback has the type signature ompt_callback_nest_lock_t.\n The above callbacks occur in the task that encounters the lock function."}
{"section_title": "18.9.4 omp_set_lock and omp_set_nest_lock", "chunk": "\n The above callbacks occur in the task that encounters the lock function.The kind argument of these \n callbacks is ompt_mutex_lock when the events arise from an omp_set_lock region while it \n is ompt_mutex_nest_lock when the events arise from an omp_set_nest_lock region.\n Cross References \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n \u2022 ompt_callback_nest_lock_t, see Section 19.5.2.16 \n"}
{"section_title": "18.9.5 omp_unset_lock and omp_unset_nest_lock", "chunk": "30 Summary \n These routines provide the means of unsetting an OpenMP lock.\n Format \nC / C++ \n void omp_unset_lock(omp_lock_t *lock); \n void omp_unset_nest_lock(omp_nest_lock_t *lock); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n subroutine omp_unset_lock(svar) \n integer (kind=omp_lock_kind) svar \n \n subroutine omp_unset_nest_lock(nvar) \n integer (kind=omp_nest_lock_kind) nvar \nFortran \n Constraints on Arguments \n A program that accesses a lock that is not in the locked state or that is not owned by the task that \n contains the call through either routine is non-conforming.\n Effect \n For a simple lock, the omp_unset_lock routine causes the lock to become unlocked.For a \n nestable lock, the omp_unset_nest_lock routine decrements the nesting count, and causes the \n lock to become unlocked if the resulting nesting count is zero."}
{"section_title": "18.9.5 omp_unset_lock and omp_unset_nest_lock", "chunk": "For a \n nestable lock, the omp_unset_nest_lock routine decrements the nesting count, and causes the \n lock to become unlocked if the resulting nesting count is zero.For either routine, if the lock \n becomes unlocked, and if one or more task regions were effectively suspended because the lock was \n unavailable, the effect is that one task is chosen and given ownership of the lock.\n Execution Model Events \n The lock-release event occurs in a thread that executes an omp_unset_lock region after it \n releases the associated lock but before it finishes the region.The nest-lock-release event occurs in a \n thread that executes an omp_unset_nest_lock region after it releases the associated lock but \n before it finishes the region.\n The nest-lock-held event occurs in a thread that executes an omp_unset_nest_lock region \n before it finishes the region when the thread still owns the lock after the nesting count is \n decremented."}
{"section_title": "18.9.5 omp_unset_lock and omp_unset_nest_lock", "chunk": "\n The nest-lock-held event occurs in a thread that executes an omp_unset_nest_lock region \n before it finishes the region when the thread still owns the lock after the nesting count is \n decremented.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_released callback with \n ompt_mutex_lock as the kind argument for each occurrence of a lock-release event in that \n thread.Similarly, a thread dispatches a registered ompt_callback_mutex_released \n callback with ompt_mutex_nest_lock as the kind argument for each occurrence of a \n nest-lock-release event in that thread.These callbacks have the type signature \n ompt_callback_mutex_t and occur in the task that encounters the routine.\n A thread dispatches a registered ompt_callback_nest_lock callback with \n ompt_scope_end as its endpoint argument for each occurrence of a nest-lock-held event in that \n thread.This callback has the type signature ompt_callback_nest_lock_t."}
{"section_title": "18.9.5 omp_unset_lock and omp_unset_nest_lock", "chunk": "This callback has the type signature ompt_callback_nest_lock_t.\n Cross References \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n \u2022 ompt_callback_nest_lock_t, see Section 19.5.2.16 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 411 \n"}
{"section_title": "18.9.6 omp_test_lock and omp_test_nest_lock", "chunk": "2 Summary \n These routines attempt to set an OpenMP lock but do not suspend execution of the task that \n executes the routine.\n Format \nC / C++ \n int omp_test_lock(omp_lock_t *lock); \n int omp_test_nest_lock(omp_nest_lock_t *lock); \nC / C++ \nFortran \n logical function omp_test_lock(svar) \n integer (kind=omp_lock_kind) svar \n \n integer function omp_test_nest_lock(nvar) \n integer (kind=omp_nest_lock_kind) nvar \nFortran \n Constraints on Arguments \n A program that accesses a lock that is in the uninitialized state through either routine is \n non-conforming.The behavior is unspecified if a simple lock accessed by omp_test_lock is in \n the locked state and is owned by the task that contains the call.\n Effect \n These routines attempt to set a lock in the same manner as omp_set_lock and \n omp_set_nest_lock, except that they do not suspend execution of the task that executes the \n routine."}
{"section_title": "18.9.6 omp_test_lock and omp_test_nest_lock", "chunk": "\n Effect \n These routines attempt to set a lock in the same manner as omp_set_lock and \n omp_set_nest_lock, except that they do not suspend execution of the task that executes the \n routine.For a simple lock, the omp_test_lock routine returns true if the lock is successfully \n set; otherwise, it returns false.For a nestable lock, the omp_test_nest_lock routine returns \n the new nesting count if the lock is successfully set; otherwise, it returns zero.\n Execution Model Events \n The lock-test event occurs in a thread that executes an omp_test_lock region before the \n associated lock is tested.The nest-lock-test event occurs in a thread that executes an \n omp_test_nest_lock region before the associated lock is tested.\n The lock-test-acquired event occurs in a thread that executes an omp_test_lock region before it \n finishes the region if the associated lock was acquired."}
{"section_title": "18.9.6 omp_test_lock and omp_test_nest_lock", "chunk": "\n The lock-test-acquired event occurs in a thread that executes an omp_test_lock region before it \n finishes the region if the associated lock was acquired.The nest-lock-test-acquired event occurs in a \n thread that executes an omp_test_nest_lock region before it finishes the region if the \n associated lock was acquired and the thread did not already own the lock.\n The nest-lock-owned event occurs in a thread that executes an omp_test_nest_lock region \n before it finishes the region after the nesting count is incremented if the thread already owned the \n lock.\n OpenMP API \u2013 Version 5.2 November 2021 \n Tool Callbacks \n A thread dispatches a registered ompt_callback_mutex_acquire callback for each \n occurrence of a lock-test or nest-lock-test event in that thread.This callback has the type signature \n ompt_callback_mutex_acquire_t."}
{"section_title": "18.9.6 omp_test_lock and omp_test_nest_lock", "chunk": "This callback has the type signature \n ompt_callback_mutex_acquire_t.\n A thread dispatches a registered ompt_callback_mutex_acquired callback for each \n occurrence of a lock-test-acquired or nest-lock-test-acquired event in that thread.This callback has \n the type signature ompt_callback_mutex_t.\n A thread dispatches a registered ompt_callback_nest_lock callback with \n ompt_scope_begin as its endpoint argument for each occurrence of a nest-lock-owned event in \n that thread.This callback has the type signature ompt_callback_nest_lock_t.\n The above callbacks occur in the task that encounters the lock function.The kind argument of these \n callbacks is ompt_mutex_test_lock when the events arise from an omp_test_lock \n region while it is ompt_mutex_test_nest_lock when the events arise from an \n omp_test_nest_lock region."}
{"section_title": "18.9.6 omp_test_lock and omp_test_nest_lock", "chunk": "The kind argument of these \n callbacks is ompt_mutex_test_lock when the events arise from an omp_test_lock \n region while it is ompt_mutex_test_nest_lock when the events arise from an \n omp_test_nest_lock region.\n Cross References \n \u2022 ompt_callback_mutex_acquire_t, see Section 19.5.2.14 \n \u2022 ompt_callback_mutex_t, see Section 19.5.2.15 \n \u2022 ompt_callback_nest_lock_t, see Section 19.5.2.16 \n"}
{"section_title": "18.10 Timing Routines", "chunk": "20 This section describes routines that support a portable wall clock timer.\n"}
{"section_title": "18.10.1 omp_get_wtime", "chunk": "22 Summary \n The omp_get_wtime routine returns elapsed wall clock time in seconds.\n Format \nC / C++ \n double omp_get_wtime(void); \nC / C++ \nFortran \n double precision function omp_get_wtime() \nFortran \n Binding \n The binding thread set for an omp_get_wtime region is the encountering thread.The routine\u2019s \n return value is not guaranteed to be consistent across any set of threads.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 413 \n Effect \n The omp_get_wtime routine returns a value equal to the elapsed wall clock time in seconds \n since some time-in-the-past.The actual time-in-the-past is arbitrary, but it is guaranteed not to \n change during the execution of the application program.The time returned is a per-thread time, so \n it is not required to be globally consistent across all threads that participate in an application.\n"}
{"section_title": "18.10.2 omp_get_wtick", "chunk": "7 Summary \n The omp_get_wtick routine returns the precision of the timer used by omp_get_wtime.\n Format \nC / C++ \n double omp_get_wtick(void); \nC / C++ \nFortran \n double precision function omp_get_wtick() \nFortran \n Binding \n The binding thread set for an omp_get_wtick region is the encountering thread.The routine\u2019s \n return value is not guaranteed to be consistent across any set of threads.\n Effect \n The omp_get_wtick routine returns a value equal to the number of seconds between successive \n clock ticks of the timer used by omp_get_wtime.\n"}
{"section_title": "18.11 Event Routine", "chunk": "19 This section describes a routine that supports OpenMP event objects.\n Binding \n The binding thread set for all event routine regions is the encountering thread.\n"}
{"section_title": "18.11.1 omp_fulfill_event", "chunk": "23 Summary \n This routine fulfills and destroys an OpenMP event.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n void omp_fulfill_event(omp_event_handle_t event); \nC / C++ \nFortran \n subroutine omp_fulfill_event(event) \n integer (kind=omp_event_handle_kind) event \nFortran \n Constraints on Arguments \n A program that calls this routine on an event that was already fulfilled is non-conforming.A \n program that calls this routine with an event handle that was not created by the detach clause is \n non-conforming.\n Effect \n The effect of this routine is to fulfill the event associated with the event handle argument.The effect \n of fulfilling the event will depend on how the event was created.The event is destroyed and cannot \n be accessed after calling this routine, and the event handle becomes unassociated with any event."}
{"section_title": "18.11.1 omp_fulfill_event", "chunk": "The event is destroyed and cannot \n be accessed after calling this routine, and the event handle becomes unassociated with any event.\n Execution Model Events \n The task-fulfill event occurs in a thread that executes an omp_fulfill_event region before the \n event is fulfilled if the OpenMP event object was created by a detach clause on a task.\n Tool Callbacks \n A thread dispatches a registered ompt_callback_task_schedule callback with NULL as its \n next_task_data argument while the argument prior_task_data binds to the detachable task for each \n occurrence of a task-fulfill event.If the task-fulfill event occurs before the detachable task finished \n the execution of the associated structured-block, the callback has \n ompt_task_early_fulfill as its prior_task_status argument; otherwise the callback has \n ompt_task_late_fulfill as its prior_task_status argument.This callback has type \n signature ompt_callback_task_schedule_t."}
{"section_title": "18.11.1 omp_fulfill_event", "chunk": "This callback has type \n signature ompt_callback_task_schedule_t.\n Restrictions \n Restrictions to the omp_fulfill_event routine are as follows: \n \u2022 The event handler passed to the routine must have been created by a thread in the same device as \n the thread that invoked the routine.\n Cross References \n \u2022 ompt_callback_task_schedule_t, see Section 19.5.2.10 \n \u2022 detach clause, see Section 12.5.2 \nCHAPTER 18."}
{"section_title": "18.11.1 omp_fulfill_event", "chunk": "\n Cross References \n \u2022 ompt_callback_task_schedule_t, see Section 19.5.2.10 \n \u2022 detach clause, see Section 12.5.2 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 415 \nTABLE 18.1: Required Values of the omp_interop_property_t enum Type \nEnum Name Contexts Name Property \nomp_ipr_fr_id = -1 all fr_id An intptr_t value that rep\uffferesents the foreign runtime id of \ncontext \nomp_ipr_fr_name = -2 all fr_name C string value that represents the \nforeign runtime name of context \nomp_ipr_vendor = -3 all vendor An intptr_t that represents \nthe vendor of context \nomp_ipr_vendor_name = \n-4 \nall vendor_name C string value that represents the \nvendor of context \nomp_ipr_device_num = -5 all device_num The OpenMP device ID for \nthe device in the range 0 to \nomp_get_num_devices() \ninclusive \nomp_ipr_platform = -6 target platform A foreign platform handle usu\ufffeally spanning multiple devices \nomp_ipr_device = -7 target device A foreign device handle \nomp_ipr_device_context \n= -8 \ntarget device_context A handle to an instance of a \nforeign device context \nomp_ipr_targetsync = -9 targetsync targetsync A handle to a synchronization \nobject of a foreign execution \ncontext \nomp_ipr_first = -9 \nC / C++ \n"}
{"section_title": "18.12 Interoperability Routines", "chunk": "2 The interoperability routines provide mechanisms to inspect the properties associated with an \n omp_interop_t object.Such objects may be initialized, destroyed or otherwise used by an \n interop construct.Additionally, an omp_interop_t object can be initialized to \n omp_interop_none, which is defined to be zero.An omp_interop_t object may only be \n accessed or modified through OpenMP directives and API routines.\n An omp_interop_t object can be copied without affecting, or copying, the underlying state.\n Destruction of an omp_interop_t object destroys the state to which all copies of the object refer.\n OpenMP reserves all negative values for properties, as listed in Table 18.1; implementation-defined \n properties may use zero and positive values.The special property, omp_ipr_first, will always \n have the lowest property value, which may change in future versions of this specification."}
{"section_title": "18.12 Interoperability Routines", "chunk": "The special property, omp_ipr_first, will always \n have the lowest property value, which may change in future versions of this specification.Valid \n values and types for the properties that Table 18.1 lists are specified in the OpenMP Additional \n Definitions document or are implementation defined unless otherwise specified."}
{"section_title": "18.12 Interoperability Routines", "chunk": "Valid \n values and types for the properties that Table 18.1 lists are specified in the OpenMP Additional \n Definitions document or are implementation defined unless otherwise specified.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 18.2: Required Values for the omp_interop_rc_t enum Type \nEnum Name Description \nomp_irc_no_value = 1 Parameters valid, no meaningful value available \nomp_irc_success = 0 Successful, value is usable \nomp_irc_empty = -1 The object provided is equal to omp_interop_none \nomp_irc_out_of_range = -2 Property ID is out of range, see Table 18.1 \nomp_irc_type_int = -3 Property type is int; use omp_get_interop_int \nomp_irc_type_ptr = -4 Property type is pointer; use omp_get_interop_ptr \nomp_irc_type_str = -5 Property type is string; use omp_get_interop_str \nomp_irc_other = -6 Other error; use omp_get_interop_rc_desc \n Table 18.2 lists the return codes used by routines that take an int* ret_code argument."}
{"section_title": "18.12 Interoperability Routines", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 18.2: Required Values for the omp_interop_rc_t enum Type \nEnum Name Description \nomp_irc_no_value = 1 Parameters valid, no meaningful value available \nomp_irc_success = 0 Successful, value is usable \nomp_irc_empty = -1 The object provided is equal to omp_interop_none \nomp_irc_out_of_range = -2 Property ID is out of range, see Table 18.1 \nomp_irc_type_int = -3 Property type is int; use omp_get_interop_int \nomp_irc_type_ptr = -4 Property type is pointer; use omp_get_interop_ptr \nomp_irc_type_str = -5 Property type is string; use omp_get_interop_str \nomp_irc_other = -6 Other error; use omp_get_interop_rc_desc \n Table 18.2 lists the return codes used by routines that take an int* ret_code argument.\n Binding \n The binding task set for all interoperability routine regions is the generating task.\nC / C++ \nC / C++ \n"}
{"section_title": "18.12.1 omp_get_num_interop_properties", "chunk": "5 Summary \n The omp_get_num_interop_properties routine retrieves the number of \n implementation-defined properties available for an omp_interop_t object.\n Format \n int omp_get_num_interop_properties(const omp_interop_t interop); \n Effect \n The omp_get_num_interop_properties routine returns the number of \n implementation-defined properties available for interop.The total number of properties available \n for interop is the returned value minus omp_ipr_first.\nC / C++ \nC / C++ \n"}
{"section_title": "18.12.2 omp_get_interop_int", "chunk": "15 Summary \n The omp_get_interop_int routine retrieves an integer property from an omp_interop_t \n object.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 417 \n Format \n omp_intptr_t omp_get_interop_int(const omp_interop_t interop, \n omp_interop_property_t property_id, \n int *ret_code); \n Effect \n The omp_get_interop_int routine returns the requested integer property, if available, and \n zero if an error occurs or no value is available.If the interop is omp_interop_none, an empty \n error occurs.If the property_id is less than omp_ipr_first or greater than or equal to \n omp_get_num_interop_properties(interop), an out of range error occurs.If the \n requested property value is not convertible into an integer value, a type error occurs.\n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which ret_code points."}
{"section_title": "18.12.2 omp_get_interop_int", "chunk": "\n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which ret_code points.If an error occurred, the stored value \n will be negative and it will match the error as defined in Table 18.2.On success, zero will be stored.\n If no error occurred but no meaningful value can be returned, omp_irc_no_value, which is \n one, will be stored.\n Restrictions \n Restrictions to the omp_get_interop_int routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid omp_interop_t object is provided.\n Cross References \n \u2022 omp_get_num_interop_properties, see Section 18.12.1 \nC / C++ \nC / C++ \n"}
{"section_title": "18.12.3 omp_get_interop_ptr", "chunk": "22 Summary \n The omp_get_interop_ptr routine retrieves a pointer property from an omp_interop_t \n object.\n Format \n void* omp_get_interop_ptr(const omp_interop_t interop, \n omp_interop_property_t property_id, \n int *ret_code); \n Effect \n The omp_get_interop_ptr routine returns the requested pointer property, if available, and \n NULL if an error occurs or no value is available.If the interop is omp_interop_none, an empty \n error occurs.If the property_id is less than omp_ipr_first or greater than or equal to \n omp_get_num_interop_properties(interop), an out of range error occurs.If the \n requested property value is not convertible into a pointer value, a type error occurs.\n OpenMP API \u2013 Version 5.2 November 2021 \n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which the ret_code points."}
{"section_title": "18.12.3 omp_get_interop_ptr", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which the ret_code points.If an error occurred, the stored \n value will be negative and it will match the error as defined in Table 18.2.On success, zero will be \n stored.If no error occurred but no meaningful value can be returned, omp_irc_no_value, \n which is one, will be stored.\n Restrictions \n Restrictions to the omp_get_interop_ptr routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid omp_interop_t object is provided.\n \u2022 Memory referenced by the pointer returned by the omp_get_interop_ptr routine is \n managed by the OpenMP implementation and should not be freed or modified.\n Cross References \n \u2022 omp_get_num_interop_properties, see Section 18.12.1 \nC / C++ \nC / C++ \n"}
{"section_title": "18.12.4 omp_get_interop_str", "chunk": "14 Summary \n The omp_get_interop_str routine retrieves a string property from an omp_interop_t \n object.\n Format \n const char* omp_get_interop_str(const omp_interop_t interop, \n omp_interop_property_t property_id, \n int *ret_code); \n Effect \n The omp_get_interop_str routine returns the requested string property as a C string, if \n available, and NULL if an error occurs or no value is available.If the interop is \n omp_interop_none, an empty error occurs.If the property_id is less than omp_ipr_first \n or greater than or equal to omp_get_num_interop_properties(interop), an out of range \n error occurs.If the requested property value is not convertible into a string value, a type error \n occurs.\n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which the ret_code points."}
{"section_title": "18.12.4 omp_get_interop_str", "chunk": "\n If a non-null pointer is passed to ret_code, an omp_interop_rc_t value that indicates the \n return code is stored in the object to which the ret_code points.If an error occurred, the stored \n value will be negative and it will match the error as defined in Table 18.2.On success, zero will be \n stored.If no error occurred but no meaningful value can be returned, omp_irc_no_value, \n which is one, will be stored.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 419 \n Restrictions \n Restrictions to the omp_get_interop_str routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid omp_interop_t object is provided.\n \u2022 Memory referenced by the pointer returned by the omp_get_interop_str routine is \n managed by the OpenMP implementation and should not be freed or modified.\n Cross References \n \u2022 omp_get_num_interop_properties, see Section 18.12.1 \nC / C++ \nC / C++ \n"}
{"section_title": "18.12.5 omp_get_interop_name", "chunk": "9 Summary \n The omp_get_interop_name routine retrieves a property name from an omp_interop_t \n object.\n Format \n const char* omp_get_interop_name(const omp_interop_t interop, \n omp_interop_property_t property_id) \n ; \n Effect \n The omp_get_interop_name routine returns the name of the property identified by \n property_id as a C string.Property names for non-implementation defined properties are listed in \n Table 18.1.If the property_id is less than omp_ipr_first or greater than or equal to \n omp_get_num_interop_properties(interop), NULL is returned.\n Restrictions \n Restrictions to the omp_get_interop_name routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid object is provided.\n \u2022 Memory referenced by the pointer returned by the omp_get_interop_name routine is \n managed by the OpenMP implementation and should not be freed or modified."}
{"section_title": "18.12.5 omp_get_interop_name", "chunk": "\n \u2022 Memory referenced by the pointer returned by the omp_get_interop_name routine is \n managed by the OpenMP implementation and should not be freed or modified.\n Cross References \n \u2022 omp_get_num_interop_properties, see Section 18.12.1 \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC / C++ \n"}
{"section_title": "18.12.6 omp_get_interop_type_desc", "chunk": "2 Summary \n The omp_get_interop_type_desc routine retrieves a description of the type of a property \n associated with an omp_interop_t object.\n Format \n const char* omp_get_interop_type_desc(const omp_interop_t interop, \n omp_interop_property_t \n property_id); \n Effect \n The omp_get_interop_type_desc routine returns a C string that describes the type of the \n property identified by property_id in human-readable form.That may contain a valid C type \n declaration possibly followed by a description or name of the type.If interop has the value \n omp_interop_none, NULL is returned.If the property_id is less than omp_ipr_first or \n greater than or equal to omp_get_num_interop_properties(interop), NULL is returned.\n Restrictions \n Restrictions to the omp_get_interop_type_desc routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid object is provided."}
{"section_title": "18.12.6 omp_get_interop_type_desc", "chunk": "\n Restrictions \n Restrictions to the omp_get_interop_type_desc routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid object is provided.\n \u2022 Memory referenced by the pointer returned from the omp_get_interop_type_desc \n routine is managed by the OpenMP implementation and should not be freed or modified.\n Cross References \n \u2022 omp_get_num_interop_properties, see Section 18.12.1 \nC / C++ \nC / C++ \n"}
{"section_title": "18.12.7 omp_get_interop_rc_desc", "chunk": "23 Summary \n The omp_get_interop_rc_desc routine retrieves a description of the return code associated \n with an omp_interop_t object.\n Format \n const char* omp_get_interop_rc_desc(const omp_interop_t interop, \n omp_interop_rc_t ret_code); \n Effect \n The omp_get_interop_rc_desc routine returns a C string that describes the return code \n ret_code in human-readable form.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 421 \n Restrictions \n Restrictions to the omp_get_interop_rc_desc routine are as follows: \n \u2022 The behavior of the routine is unspecified if an invalid object is provided or if ret_code was not \n last written by an interoperability routine invoked with the omp_interop_t object interop.\n \u2022 Memory referenced by the pointer returned by the omp_get_interop_rc_desc routine is \n managed by the OpenMP implementation and should not be freed or modified.\nC / C++ \n"}
{"section_title": "18.13 Memory Management Routines", "chunk": "8 This section describes routines that support memory management on the current device.Instances \n of memory management types must be accessed only through the routines described in this section; \n programs that otherwise access instances of these types are non-conforming.\n"}
{"section_title": "18.13.1 Memory Management Types", "chunk": ""}
{"section_title": "18.13.1 Memory Management Types", "chunk": "12 The following type definitions are used by the memory management routines: \nC / C++ \n typedef enum omp_alloctrait_key_t { \n omp_atk_sync_hint = 1, \n omp_atk_alignment = 2, \n omp_atk_access = 3, \n omp_atk_pool_size = 4, \n omp_atk_fallback = 5, \n omp_atk_fb_data = 6, \n omp_atk_pinned = 7, \n omp_atk_partition = 8 \n } omp_alloctrait_key_t; \n \n typedef enum omp_alloctrait_value_t { \n omp_atv_false = 0, \n omp_atv_true = 1, \n omp_atv_contended = 3, \n omp_atv_uncontended = 4, \n omp_atv_serialized = 5, \n omp_atv_sequential = omp_atv_serialized, // (deprecated) \n omp_atv_private = 6, \n omp_atv_all = 7, \n omp_atv_thread = 8, \n omp_atv_pteam = 9, \n omp_atv_cgroup = 10, \n OpenMP API \u2013 Version 5.2 November 2021 \n omp_atv_default_mem_fb = 11, \n omp_atv_null_fb = 12, \n omp_atv_abort_fb = 13, \n omp_atv_allocator_fb = 14, \n omp_atv_environment = 15, \n omp_atv_nearest = 16, \n omp_atv_blocked = 17, \n omp_atv_interleaved = 18 \n } omp_alloctrait_value_t; \n \n typedef struct omp_alloctrait_t { \n omp_alloctrait_key_t key; \n omp_uintptr_t value; \n } omp_alloctrait_t; \nC / C++ \nFortran \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_sync_hint = 1 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_alignment = 2 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_access = 3 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_pool_size = 4 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_fallback = 5 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_fb_data = 6 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_pinned = 7 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_partition = 8 \n \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_default = -1 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_false = 0 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_true = 1 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_contended = 3 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_uncontended = 4 \nCHAPTER 18."}
{"section_title": "18.13.1 Memory Management Types", "chunk": "12 The following type definitions are used by the memory management routines: \nC / C++ \n typedef enum omp_alloctrait_key_t { \n omp_atk_sync_hint = 1, \n omp_atk_alignment = 2, \n omp_atk_access = 3, \n omp_atk_pool_size = 4, \n omp_atk_fallback = 5, \n omp_atk_fb_data = 6, \n omp_atk_pinned = 7, \n omp_atk_partition = 8 \n } omp_alloctrait_key_t; \n \n typedef enum omp_alloctrait_value_t { \n omp_atv_false = 0, \n omp_atv_true = 1, \n omp_atv_contended = 3, \n omp_atv_uncontended = 4, \n omp_atv_serialized = 5, \n omp_atv_sequential = omp_atv_serialized, // (deprecated) \n omp_atv_private = 6, \n omp_atv_all = 7, \n omp_atv_thread = 8, \n omp_atv_pteam = 9, \n omp_atv_cgroup = 10, \n OpenMP API \u2013 Version 5.2 November 2021 \n omp_atv_default_mem_fb = 11, \n omp_atv_null_fb = 12, \n omp_atv_abort_fb = 13, \n omp_atv_allocator_fb = 14, \n omp_atv_environment = 15, \n omp_atv_nearest = 16, \n omp_atv_blocked = 17, \n omp_atv_interleaved = 18 \n } omp_alloctrait_value_t; \n \n typedef struct omp_alloctrait_t { \n omp_alloctrait_key_t key; \n omp_uintptr_t value; \n } omp_alloctrait_t; \nC / C++ \nFortran \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_sync_hint = 1 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_alignment = 2 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_access = 3 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_pool_size = 4 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_fallback = 5 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_fb_data = 6 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_pinned = 7 \n integer(kind=omp_alloctrait_key_kind), & \n parameter :: omp_atk_partition = 8 \n \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_default = -1 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_false = 0 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_true = 1 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_contended = 3 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_uncontended = 4 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 423 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_serialized = 5 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_sequential = & \n omp_atv_serialized ! (deprecated) \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_private = 6 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_all = 7 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_thread = 8 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_pteam = 9 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_cgroup = 10 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_default_mem_fb = 11 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_null_fb = 12 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_abort_fb = 13 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_allocator_fb = 14 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_environment = 15 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_nearest = 16 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_blocked = 17 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_interleaved = 18 \n \n ! omp_alloctrait might not be provided in omp_lib.h."}
{"section_title": "18.13.1 Memory Management Types", "chunk": "RUNTIME LIBRARY ROUTINES 423 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_serialized = 5 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_sequential = & \n omp_atv_serialized ! (deprecated) \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_private = 6 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_all = 7 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_thread = 8 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_pteam = 9 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_cgroup = 10 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_default_mem_fb = 11 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_null_fb = 12 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_abort_fb = 13 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_allocator_fb = 14 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_environment = 15 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_nearest = 16 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_blocked = 17 \n integer(kind=omp_alloctrait_val_kind), & \n parameter :: omp_atv_interleaved = 18 \n \n ! omp_alloctrait might not be provided in omp_lib.h.\n type omp_alloctrait \n integer(kind=omp_alloctrait_key_kind) key \n integer(kind=omp_alloctrait_val_kind) value \n end type omp_alloctrait \n \n integer(kind=omp_allocator_handle_kind), & \n parameter :: omp_null_allocator = 0 \nFortran \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "18.13.2 omp_init_allocator", "chunk": "2 Summary \n The omp_init_allocator routine initializes an allocator and associates it with a memory \n space.\n Format \nC / C++ \n omp_allocator_handle_t omp_init_allocator ( \n omp_memspace_handle_t memspace, \n int ntraits, \n const omp_alloctrait_t traits[] \n ); \nC / C++ \nFortran \n integer(kind=omp_allocator_handle_kind) & \n function omp_init_allocator ( memspace, ntraits, traits ) \n integer(kind=omp_memspace_handle_kind),intent(in) :: memspace \n integer,intent(in) :: ntraits \n type(omp_alloctrait),intent(in) :: traits(*) \nFortran \n Constraints on Arguments \n The memspace argument must be one of the predefined memory spaces defined in Table 6.1.If the \n ntraits argument is greater than zero then the traits argument must specify at least that many traits.\n If it specifies fewer than ntraits traits the behavior is unspecified.\n Binding \n The binding thread set for an omp_init_allocator region is all threads on a device."}
{"section_title": "18.13.2 omp_init_allocator", "chunk": "\n Binding \n The binding thread set for an omp_init_allocator region is all threads on a device.The \n effect of executing this routine is not related to any specific region that corresponds to any construct \n or API routine.\n Effect \n The omp_init_allocator routine creates a new allocator that is associated with the \n memspace memory space and returns a handle to it.All allocations through the created allocator \n will behave according to the allocator traits specified in the traits argument.The number of traits in \n the traits argument is specified by the ntraits argument.Specifying the same allocator trait more \n than once results in unspecified behavior.The routine returns a handle for the created allocator.If \n the special omp_atv_default value is used for a given trait, then its value will be the default \n value specified in Table 6.2 for that given trait."}
{"section_title": "18.13.2 omp_init_allocator", "chunk": "If \n the special omp_atv_default value is used for a given trait, then its value will be the default \n value specified in Table 6.2 for that given trait.\n If memspace is omp_default_mem_space and the traits argument is an empty set this routine \n will always return a handle to an allocator.Otherwise if an allocator based on the requirements \n cannot be created then the special omp_null_allocator handle is returned.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 425 \n Restrictions \n The restrictions to the omp_init_allocator routine are as follows: \n \u2022 The use of an allocator returned by this routine on a device other than the one on which it was \n created results in unspecified behavior.\n \u2022 Unless a requires directive with the dynamic_allocators clause is present in the same \n compilation unit, using this routine in a target region results in unspecified behavior."}
{"section_title": "18.13.2 omp_init_allocator", "chunk": "\n \u2022 Unless a requires directive with the dynamic_allocators clause is present in the same \n compilation unit, using this routine in a target region results in unspecified behavior.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 Memory Spaces, see Section 6.1 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.13.3 omp_destroy_allocator", "chunk": "13 Summary \n The omp_destroy_allocator routine releases all resources used by the allocator handle.\n Format \nC / C++ \n void omp_destroy_allocator (omp_allocator_handle_t allocator); \nC / C++ \nFortran \n subroutine omp_destroy_allocator ( allocator ) \n integer(kind=omp_allocator_handle_kind),intent(in) :: allocator \nFortran \n Constraints on Arguments \n The allocator argument must not represent a predefined memory allocator.\n Binding \n The binding thread set for an omp_destroy_allocator region is all threads on a device.The \n effect of executing this routine is not related to any specific region that corresponds to any construct \n or API routine.\n Effect \n The omp_destroy_allocator routine releases all resources used to implement the allocator \n handle.If allocator is omp_null_allocator then this routine will have no effect."}
{"section_title": "18.13.3 omp_destroy_allocator", "chunk": "If allocator is omp_null_allocator then this routine will have no effect.\n OpenMP API \u2013 Version 5.2 November 2021 \n Restrictions \n The restrictions to the omp_destroy_allocator routine are as follows: \n \u2022 Accessing any memory allocated by the allocator after this call results in unspecified behavior.\n \u2022 Unless a requires directive with the dynamic_allocators clause is present in the same \n compilation unit, using this routine in a target region results in unspecified behavior.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.13.4 omp_set_default_allocator", "chunk": "11 Summary \n The omp_set_default_allocator routine sets the default memory allocator to be used by \n allocation calls, allocate clauses and allocate and allocators directives that do not \n specify an allocator.\n Format \nC / C++ \n void omp_set_default_allocator (omp_allocator_handle_t allocator); \nC / C++ \nFortran \n subroutine omp_set_default_allocator ( allocator ) \n integer(kind=omp_allocator_handle_kind),intent(in) :: allocator \nFortran \n Constraints on Arguments \n The allocator argument must be a valid memory allocator handle.\n Binding \n The binding task set for an omp_set_default_allocator region is the binding implicit task.\n Effect \n The effect of this routine is to set the value of the def-allocator-var ICV of the binding implicit task \n to the value specified in the allocator argument."}
{"section_title": "18.13.4 omp_set_default_allocator", "chunk": "\n Effect \n The effect of this routine is to set the value of the def-allocator-var ICV of the binding implicit task \n to the value specified in the allocator argument.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 allocate clause, see Section 6.6 \n \u2022 allocate directive, see Section 6.5 \n \u2022 allocators directive, see Section 6.7 \n \u2022 def-allocator-var ICV, see Table 2.1 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 427 \n"}
{"section_title": "18.13.5 omp_get_default_allocator", "chunk": "2 Summary \n The omp_get_default_allocator routine returns a handle to the memory allocator to be \n used by allocation calls, allocate clauses and allocate and allocators directives that do \n not specify an allocator.\n Format \nC / C++ \n omp_allocator_handle_t omp_get_default_allocator (void); \nC / C++ \nFortran \n integer(kind=omp_allocator_handle_kind)& \n function omp_get_default_allocator () \nFortran \n Binding \n The binding task set for an omp_get_default_allocator region is the binding implicit task.\n Effect \n The effect of this routine is to return the value of the def-allocator-var ICV of the binding implicit \n task.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 allocate clause, see Section 6.6 \n \u2022 allocate directive, see Section 6.5 \n \u2022 allocators directive, see Section 6.7 \n \u2022 def-allocator-var ICV, see Table 2.1 \n"}
{"section_title": "18.13.6 omp_alloc and omp_aligned_alloc", "chunk": "22 Summary \n The omp_alloc and omp_aligned_alloc routines request a memory allocation from a \n memory allocator."}
{"section_title": "18.13.6 omp_alloc and omp_aligned_alloc", "chunk": "22 Summary \n The omp_alloc and omp_aligned_alloc routines request a memory allocation from a \n memory allocator.\n Format \nC \n void *omp_alloc(size_t size, omp_allocator_handle_t allocator); \n void *omp_aligned_alloc( \n size_t alignment, \n size_t size, \n omp_allocator_handle_t allocator); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n void *omp_alloc( \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \n void *omp_aligned_alloc( \n size_t alignment, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) function omp_alloc(size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: size \n integer(omp_allocator_handle_kind), value :: allocator \n \n type(c_ptr) function omp_aligned_alloc(alignment, & \n size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: alignment, size \n integer(omp_allocator_handle_kind), value :: allocator \nFortran \n Constraints on Arguments \n Unless dynamic_allocators appears on a requires directive in the same compilation unit, \n omp_alloc and omp_aligned_alloc invocations that appear in target regions must not \n pass omp_null_allocator as the allocator argument, which must be a constant expression \n that evaluates to one of the predefined memory allocator values."}
{"section_title": "18.13.6 omp_alloc and omp_aligned_alloc", "chunk": "\n Format \nC \n void *omp_alloc(size_t size, omp_allocator_handle_t allocator); \n void *omp_aligned_alloc( \n size_t alignment, \n size_t size, \n omp_allocator_handle_t allocator); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n void *omp_alloc( \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \n void *omp_aligned_alloc( \n size_t alignment, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) function omp_alloc(size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: size \n integer(omp_allocator_handle_kind), value :: allocator \n \n type(c_ptr) function omp_aligned_alloc(alignment, & \n size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: alignment, size \n integer(omp_allocator_handle_kind), value :: allocator \nFortran \n Constraints on Arguments \n Unless dynamic_allocators appears on a requires directive in the same compilation unit, \n omp_alloc and omp_aligned_alloc invocations that appear in target regions must not \n pass omp_null_allocator as the allocator argument, which must be a constant expression \n that evaluates to one of the predefined memory allocator values.The alignment argument to \n omp_aligned_alloc must be a power of two and the size argument must be a multiple of \n alignment."}
{"section_title": "18.13.6 omp_alloc and omp_aligned_alloc", "chunk": "The alignment argument to \n omp_aligned_alloc must be a power of two and the size argument must be a multiple of \n alignment.\n Binding \n The binding task set for an omp_alloc or omp_aligned_alloc region is the generating task.\n Effect \n The omp_alloc and omp_aligned_alloc routines request a memory allocation of size bytes \n from the specified memory allocator.If the allocator argument is omp_null_allocator the \n memory allocator used by the routines will be the one specified by the def-allocator-var ICV of the \n binding implicit task.Upon success they return a pointer to the allocated memory.Otherwise, the \n behavior that the fallback trait of the allocator specifies will be followed.If size is 0, \n omp_alloc and omp_aligned_alloc will return NULL.\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 429 \n Memory allocated by omp_alloc will be byte-aligned to at least the maximum of the alignment \n required by malloc and the alignment trait of the allocator."}
{"section_title": "18.13.6 omp_alloc and omp_aligned_alloc", "chunk": "RUNTIME LIBRARY ROUTINES 429 \n Memory allocated by omp_alloc will be byte-aligned to at least the maximum of the alignment \n required by malloc and the alignment trait of the allocator.Memory allocated by \n omp_aligned_alloc will be byte-aligned to at least the maximum of the alignment required by \n malloc, the alignment trait of the allocator and the alignment argument value.\nFortran \n The omp_alloc and omp_aligned_alloc routines require an explicit interface and so might \n not be provided in omp_lib.h.\nFortran \n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 def-allocator-var ICV, see Table 2.1 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.13.7 omp_free", "chunk": "13 Summary \n The omp_free routine deallocates previously allocated memory.\n Format \nC \n void omp_free (void *ptr, omp_allocator_handle_t allocator); \nC \nC++ \n void omp_free( \n void *ptr, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \nC++ \nFortran \n subroutine omp_free(ptr, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr \n type(c_ptr), value :: ptr \n integer(omp_allocator_handle_kind), value :: allocator \nFortran \n Binding \n The binding task set for an omp_free region is the generating task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n The omp_free routine deallocates the memory to which ptr points.The ptr argument must have \n been returned by an OpenMP allocation routine.If the allocator argument is specified it must be \n the memory allocator to which the allocation request was made.If the allocator argument is \n omp_null_allocator the implementation will determine that value automatically."}
{"section_title": "18.13.7 omp_free", "chunk": "If the allocator argument is \n omp_null_allocator the implementation will determine that value automatically.If ptr is \n NULL, no operation is performed.\nFortran \n The omp_free routine requires an explicit interface and so might not be provided in \n omp_lib.h.\nFortran \n Restrictions \n The restrictions to the omp_free routine are as follows: \n \u2022 Using omp_free on memory that was already deallocated or that was allocated by an allocator \n that has already been destroyed with omp_destroy_allocator results in unspecified \n behavior.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 omp_destroy_allocator, see Section 18.13.3 \n"}
{"section_title": "18.13.8 omp_calloc and omp_aligned_calloc", "chunk": "18 Summary \n The omp_calloc and omp_aligned_calloc routines request a zero initialized memory \n allocation from a memory allocator.\n Format \nC \n void *omp_calloc( \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator \n ); \n void *omp_aligned_calloc( \n size_t alignment, \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator \n ); \nC \nCHAPTER 18."}
{"section_title": "18.13.8 omp_calloc and omp_aligned_calloc", "chunk": "\n Format \nC \n void *omp_calloc( \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator \n ); \n void *omp_aligned_calloc( \n size_t alignment, \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator \n ); \nC \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 431 \nC++ \n void *omp_calloc( \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \n void *omp_aligned_calloc( \n size_t alignment, \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) function omp_calloc(nmemb, size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: nmemb, size \n integer(omp_allocator_handle_kind), value :: allocator \n \n type(c_ptr) function omp_aligned_calloc(alignment, nmemb, size, & \n allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: alignment, nmemb, size \n integer(omp_allocator_handle_kind), value :: allocator \nFortran \n Constraints on Arguments \n Unless dynamic_allocators appears on a requires directive in the same compilation unit, \n omp_calloc and omp_aligned_calloc invocations that appear in target regions must \n not pass omp_null_allocator as the allocator argument, which must be a constant expression \n that evaluates to one of the predefined memory allocator values."}
{"section_title": "18.13.8 omp_calloc and omp_aligned_calloc", "chunk": "RUNTIME LIBRARY ROUTINES 431 \nC++ \n void *omp_calloc( \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \n void *omp_aligned_calloc( \n size_t alignment, \n size_t nmemb, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) function omp_calloc(nmemb, size, allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: nmemb, size \n integer(omp_allocator_handle_kind), value :: allocator \n \n type(c_ptr) function omp_aligned_calloc(alignment, nmemb, size, & \n allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n integer(c_size_t), value :: alignment, nmemb, size \n integer(omp_allocator_handle_kind), value :: allocator \nFortran \n Constraints on Arguments \n Unless dynamic_allocators appears on a requires directive in the same compilation unit, \n omp_calloc and omp_aligned_calloc invocations that appear in target regions must \n not pass omp_null_allocator as the allocator argument, which must be a constant expression \n that evaluates to one of the predefined memory allocator values.The alignment argument to \n omp_aligned_calloc must be a power of two and the size argument must be a multiple of \n alignment."}
{"section_title": "18.13.8 omp_calloc and omp_aligned_calloc", "chunk": "The alignment argument to \n omp_aligned_calloc must be a power of two and the size argument must be a multiple of \n alignment.\n Binding \n The binding task set for an omp_calloc or omp_aligned_calloc region is the generating \n task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n The omp_calloc and omp_aligned_calloc routines request a memory allocation from the \n specified memory allocator for an array of nmemb elements each of which has a size of size bytes.\n If the allocator argument is omp_null_allocator the memory allocator used by the routines \n will be the one specified by the def-allocator-var ICV of the binding implicit task.Upon success \n they return a pointer to the allocated memory.Otherwise, the behavior that the fallback trait of \n the allocator specifies will be followed.Any memory allocated by these routines will be set to zero \n before returning.If either nmemb or size is 0, omp_calloc will return NULL."}
{"section_title": "18.13.8 omp_calloc and omp_aligned_calloc", "chunk": "If either nmemb or size is 0, omp_calloc will return NULL.\n Memory allocated by omp_calloc will be byte-aligned to at least the maximum of the alignment \n required by malloc and the alignment trait of the allocator.Memory allocated by \n omp_aligned_calloc will be byte-aligned to at least the maximum of the alignment required \n by malloc, the alignment trait of the allocator and the alignment argument value.\nFortran \n The omp_calloc and omp_aligned_calloc routines require an explicit interface and so \n might not be provided in omp_lib.h.\nFortran \n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 def-allocator-var ICV, see Table 2.1 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.13.9 omp_realloc", "chunk": "21 Summary \n The omp_realloc routine deallocates previously allocated memory and requests a memory \n allocation from a memory allocator.\n Format \nC \n void *omp_realloc( \n void *ptr, \n size_t size, \n omp_allocator_handle_t allocator, \n omp_allocator_handle_t free_allocator \n ); \nC \nCHAPTER 18."}
{"section_title": "18.13.9 omp_realloc", "chunk": "\n Format \nC \n void *omp_realloc( \n void *ptr, \n size_t size, \n omp_allocator_handle_t allocator, \n omp_allocator_handle_t free_allocator \n ); \nC \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 433 \nC++ \n void *omp_realloc( \n void *ptr, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator, \n omp_allocator_handle_t free_allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) & \n function omp_realloc(ptr, size, allocator, free_allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n type(c_ptr), value :: ptr \n integer(c_size_t), value :: size \n integer(omp_allocator_handle_kind), value :: allocator, free_allocator \nFortran \n Constraints on Arguments \n Unless a dynamic_allocators clause appears on a requires directive in the same \n compilation unit, omp_realloc invocations that appear in target regions must not pass \n omp_null_allocator as the allocator or free_allocator argument, which must be constant \n expressions that evaluate to one of the predefined memory allocator values."}
{"section_title": "18.13.9 omp_realloc", "chunk": "RUNTIME LIBRARY ROUTINES 433 \nC++ \n void *omp_realloc( \n void *ptr, \n size_t size, \n omp_allocator_handle_t allocator=omp_null_allocator, \n omp_allocator_handle_t free_allocator=omp_null_allocator \n ); \nC++ \nFortran \n type(c_ptr) & \n function omp_realloc(ptr, size, allocator, free_allocator) bind(c) \n use, intrinsic :: iso_c_binding, only : c_ptr, c_size_t \n type(c_ptr), value :: ptr \n integer(c_size_t), value :: size \n integer(omp_allocator_handle_kind), value :: allocator, free_allocator \nFortran \n Constraints on Arguments \n Unless a dynamic_allocators clause appears on a requires directive in the same \n compilation unit, omp_realloc invocations that appear in target regions must not pass \n omp_null_allocator as the allocator or free_allocator argument, which must be constant \n expressions that evaluate to one of the predefined memory allocator values.\n Binding \n The binding task set for an omp_realloc region is the generating task."}
{"section_title": "18.13.9 omp_realloc", "chunk": "\n Binding \n The binding task set for an omp_realloc region is the generating task.\n Effect \n The omp_realloc routine deallocates the memory to which ptr points and requests a new \n memory allocation of size bytes from the specified memory allocator.If the free_allocator \n argument is specified, it must be the memory allocator to which the previous allocation request was \n made.If the free_allocator argument is omp_null_allocator the implementation will \n determine that value automatically.If the allocator argument is omp_null_allocator the \n behavior is as if the memory allocator that allocated the memory to which ptr argument points is \n passed to the allocator argument.Upon success it returns a (possibly moved) pointer to the \n allocated memory and the contents of the new object shall be the same as that of the old object \n prior to deallocation, up to the minimum size of old allocated size and size."}
{"section_title": "18.13.9 omp_realloc", "chunk": "Upon success it returns a (possibly moved) pointer to the \n allocated memory and the contents of the new object shall be the same as that of the old object \n prior to deallocation, up to the minimum size of old allocated size and size.Any bytes in the new \n object beyond the old allocated size will have unspecified values.If the allocation failed, the \n behavior that the fallback trait of the allocator specifies will be followed.If ptr is NULL, \n omp_realloc will behave the same as omp_alloc with the same size and allocator arguments.\n If size is 0, omp_realloc will return NULL and the old allocation will be deallocated.If size is \n not 0, the old allocation will be deallocated if and only if the function returns a non-null value.\n Memory allocated by omp_realloc will be byte-aligned to at least the maximum of the \n alignment required by malloc and the alignment trait of the allocator."}
{"section_title": "18.13.9 omp_realloc", "chunk": "\n Memory allocated by omp_realloc will be byte-aligned to at least the maximum of the \n alignment required by malloc and the alignment trait of the allocator.\n OpenMP API \u2013 Version 5.2 November 2021 \nFortran \n The omp_realloc routine requires an explicit interface and so might not be provided in \n omp_lib.h.\nFortran \n Restrictions \n The restrictions to the omp_realloc routine are as follows: \n \u2022 The ptr argument must have been returned by an OpenMP allocation routine.\n \u2022 Using omp_realloc on memory that was already deallocated or that was allocated by an \n allocator that has already been destroyed with omp_destroy_allocator results in \n unspecified behavior.\n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 omp_alloc and omp_aligned_alloc, see Section 18.13.6 \n \u2022 omp_destroy_allocator, see Section 18.13.3 \n \u2022 requires directive, see Section 8.2 \n \u2022 target directive, see Section 13.8 \n"}
{"section_title": "18.14 Tool Control Routine", "chunk": "16 Summary \n The omp_control_tool routine enables a program to pass commands to an active tool.\n Format \nC / C++ \n int omp_control_tool(int command, int modifier, void *arg); \nC / C++ \nFortran \n integer function omp_control_tool(command, modifier) \n integer (kind=omp_control_tool_kind) command \n integer modifier \nFortran \n Constraints on Arguments \n The following enumeration type defines four standard commands.Table 18.3 describes the actions \n that these commands request from a tool.\nCHAPTER 18."}
{"section_title": "18.14 Tool Control Routine", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 435 \nC / C++ \n typedef enum omp_control_tool_t { \n omp_control_tool_start = 1, \n omp_control_tool_pause = 2, \n omp_control_tool_flush = 3, \n omp_control_tool_end = 4 \n } omp_control_tool_t; \nC / C++ \nFortran \n integer (kind=omp_control_tool_kind), & \n parameter :: omp_control_tool_start = 1 \n integer (kind=omp_control_tool_kind), & \n parameter :: omp_control_tool_pause = 2 \n integer (kind=omp_control_tool_kind), & \n parameter :: omp_control_tool_flush = 3 \n integer (kind=omp_control_tool_kind), & \n parameter :: omp_control_tool_end = 4 \nFortran \n Tool-specific values for command must be greater or equal to 64.Tools must ignore command \n values that they are not explicitly designed to handle.Other values accepted by a tool for command, \n and any values for modifier and arg are tool-defined.\nTABLE 18.3: Standard Tool Control Commands \nCommand Action \nomp_control_tool_start Start or restart monitoring if it is off."}
{"section_title": "18.14 Tool Control Routine", "chunk": "\nTABLE 18.3: Standard Tool Control Commands \nCommand Action \nomp_control_tool_start Start or restart monitoring if it is off.If monitoring \nis already on, this command is idempotent.If moni\ufffetoring has already been turned off permanently, this \ncommand will have no effect.\nomp_control_tool_pause Temporarily turn monitoring off.If monitoring is \nalready off, it is idempotent.\nomp_control_tool_flush Flush any data buffered by a tool.This command may \nbe applied whether monitoring is on or off.\nomp_control_tool_end Turn monitoring off permanently; the tool finalizes \nitself and flushes all output.\n Binding \n The binding task set for an omp_control_tool region is the generating task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n An OpenMP program may use omp_control_tool to pass commands to a tool."}
{"section_title": "18.14 Tool Control Routine", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n An OpenMP program may use omp_control_tool to pass commands to a tool.An application \n can use omp_control_tool to request that a tool starts or restarts data collection when a code \n region of interest is encountered, that a tool pauses data collection when leaving the region of \n interest, that a tool flushes any data that it has collected so far, or that a tool ends data collection.\n Additionally, omp_control_tool can be used to pass tool-specific commands to a particular \n tool."}
{"section_title": "18.14 Tool Control Routine", "chunk": "\n Additionally, omp_control_tool can be used to pass tool-specific commands to a particular \n tool.The following types correspond to return values from omp_control_tool: \nC / C++ \n typedef enum omp_control_tool_result_t { \n omp_control_tool_notool = -2, \n omp_control_tool_nocallback = -1, \n omp_control_tool_success = 0, \n omp_control_tool_ignored = 1 \n } omp_control_tool_result_t; \nC / C++ \nFortran \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_notool = -2 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_nocallback = -1 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_success = 0 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_ignored = 1 \nFortran \n If the OMPT interface state is inactive, the OpenMP implementation returns \n omp_control_tool_notool."}
{"section_title": "18.14 Tool Control Routine", "chunk": "The following types correspond to return values from omp_control_tool: \nC / C++ \n typedef enum omp_control_tool_result_t { \n omp_control_tool_notool = -2, \n omp_control_tool_nocallback = -1, \n omp_control_tool_success = 0, \n omp_control_tool_ignored = 1 \n } omp_control_tool_result_t; \nC / C++ \nFortran \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_notool = -2 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_nocallback = -1 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_success = 0 \n integer (kind=omp_control_tool_result_kind), & \n parameter :: omp_control_tool_ignored = 1 \nFortran \n If the OMPT interface state is inactive, the OpenMP implementation returns \n omp_control_tool_notool.If the OMPT interface state is active, but no callback is \n registered for the tool-control event, the OpenMP implementation returns \n omp_control_tool_nocallback."}
{"section_title": "18.14 Tool Control Routine", "chunk": "If the OMPT interface state is active, but no callback is \n registered for the tool-control event, the OpenMP implementation returns \n omp_control_tool_nocallback.An OpenMP implementation may return other \n implementation-defined negative values strictly smaller than -64; an application may assume that \n any negative return value indicates that a tool has not received the command.A return value of \n omp_control_tool_success indicates that the tool has performed the specified command.A \n return value of omp_control_tool_ignored indicates that the tool has ignored the specified \n command.A tool may return other positive values strictly greater than 64 that are tool-defined.\n Execution Model Events \n The tool-control event occurs in the thread that encounters a call to omp_control_tool at a \n point inside its corresponding OpenMP region.\nCHAPTER 18."}
{"section_title": "18.14 Tool Control Routine", "chunk": "\nCHAPTER 18.RUNTIME LIBRARY ROUTINES 437 \n Tool Callbacks \n A thread dispatches a registered ompt_callback_control_tool callback for each \n occurrence of a tool-control event.The callback executes in the context of the call that occurs in the \n user program and has type signature ompt_callback_control_tool_t.The callback may \n return any non-negative value, which will be returned to the application by the OpenMP \n implementation as the return value of the omp_control_tool call that triggered the callback.\n Arguments passed to the callback are those passed by the user to omp_control_tool.If the \n call is made in Fortran, the tool will be passed NULL as the third argument to the callback.If any of \n the four standard commands is presented to a tool, the tool will ignore the modifier and arg \n argument values."}
{"section_title": "18.14 Tool Control Routine", "chunk": "If any of \n the four standard commands is presented to a tool, the tool will ignore the modifier and arg \n argument values.\n Restrictions \n Restrictions on access to the state of an OpenMP first-party tool are as follows: \n \u2022 An application may access the tool state modified by an OMPT callback only by using \n omp_control_tool.\n Cross References \n \u2022 OMPT Interface, see Chapter 19 \n \u2022 ompt_callback_control_tool_t, see Section 19.5.2.29 \n"}
{"section_title": "18.15 Environment Display Routine", "chunk": "19 Summary \n The omp_display_env routine displays the OpenMP version number and the initial values of \n ICVs associated with the environment variables described in Chapter 21.\n Format \nC / C++ \n void omp_display_env(int verbose); \nC / C++ \nFortran \n subroutine omp_display_env(verbose) \n logical,intent(in) :: verbose \nFortran \n Binding \n The binding thread set for an omp_display_env region is the encountering thread.\n OpenMP API \u2013 Version 5.2 November 2021 \n Effect \n Each time the omp_display_env routine is invoked, the runtime system prints the OpenMP \n version number and the initial values of the ICVs associated with the environment variables \n described in Chapter 21.The displayed values are the values of the ICVs after they have been \n modified according to the environment variable settings and before the execution of any OpenMP \n construct or API routine."}
{"section_title": "18.15 Environment Display Routine", "chunk": "The displayed values are the values of the ICVs after they have been \n modified according to the environment variable settings and before the execution of any OpenMP \n construct or API routine.\n The display begins with \"OPENMP DISPLAY ENVIRONMENT BEGIN\", followed by the \n _OPENMP version macro (or the openmp_version named constant for Fortran) and ICV values, \n in the format NAME \u2019=\u2019 VALUE.NAME corresponds to the macro or environment variable name, \n optionally prepended with a bracketed DEVICE.VALUE corresponds to the value of the macro or \n ICV associated with this environment variable.Values are enclosed in single quotes.DEVICE \n corresponds to the device on which the value of the ICV is applied.The display is terminated with \n \"OPENMP DISPLAY ENVIRONMENT END\".\n For the OMP_NESTED environment variable, the printed value is true if the max-active-levels-var \n ICV is initialized to a value greater than 1; otherwise the printed value is false."}
{"section_title": "18.15 Environment Display Routine", "chunk": "\n For the OMP_NESTED environment variable, the printed value is true if the max-active-levels-var \n ICV is initialized to a value greater than 1; otherwise the printed value is false.The OMP_NESTED \n environment variable has been deprecated.\n If the verbose argument evaluates to false, the runtime displays the OpenMP version number \n defined by the _OPENMP version macro (or the openmp_version named constant for Fortran) \n value and the initial ICV values for the environment variables listed in Chapter 21.If the verbose \n argument evaluates to true, the runtime may also display the values of vendor-specific ICVs that \n may be modified by vendor-specific environment variables.\n Example output: \n OPENMP DISPLAY ENVIRONMENT BEGIN \n _OPENMP=\u2019202111\u2019 \n [host] OMP_SCHEDULE=\u2019GUIDED,4\u2019 \n [host] OMP_NUM_THREADS=\u20194,3,2\u2019 \n [device] OMP_NUM_THREADS=\u20192\u2019 \n [host,device] OMP_DYNAMIC=\u2019TRUE\u2019 \n [host] OMP_PLACES=\u2019{0:4},{4:4},{8:4},{12:4}\u2019 \n ..."}
{"section_title": "18.15 Environment Display Routine", "chunk": "\n Example output: \n OPENMP DISPLAY ENVIRONMENT BEGIN \n _OPENMP=\u2019202111\u2019 \n [host] OMP_SCHEDULE=\u2019GUIDED,4\u2019 \n [host] OMP_NUM_THREADS=\u20194,3,2\u2019 \n [device] OMP_NUM_THREADS=\u20192\u2019 \n [host,device] OMP_DYNAMIC=\u2019TRUE\u2019 \n [host] OMP_PLACES=\u2019{0:4},{4:4},{8:4},{12:4}\u2019 \n ...\n OPENMP DISPLAY ENVIRONMENT END \n Restrictions \n Restrictions to the omp_display_env routine are as follows.\n \u2022 When called from within a target region the effect is unspecified.\n Cross References \n \u2022 OMP_DISPLAY_ENV, see Section 21.7 \nCHAPTER 18.RUNTIME LIBRARY ROUTINES 439 \n"}
{"section_title": "19 OMPT Interface", "chunk": "2 This chapter describes OMPT, which is an interface for first-party tools.First-party tools are linked \n or loaded directly into the OpenMP program.OMPT defines mechanisms to initialize a tool, to \n examine OpenMP state associated with an OpenMP thread, to interpret the call stack of an OpenMP \n thread, to receive notification about OpenMP events, to trace activity on OpenMP target devices, to \n assess implementation-dependent details of an OpenMP implementation (such as supported states \n and mutual exclusion implementations), and to control a tool from an OpenMP application.\n"}
{"section_title": "19.1 OMPT Interfaces Definitions", "chunk": "C / C++ \n A compliant implementation must supply a set of definitions for the OMPT runtime entry points, \n OMPT callback signatures, and the special data types of their parameters and return values.These \n definitions, which are listed throughout this chapter, and their associated declarations shall be \n provided in a header file named omp-tools.h.In addition, the set of definitions may specify \n other implementation-specific values.\n The ompt_start_tool function is an external function with C linkage.\nC / C++ \n"}
{"section_title": "19.2 Activating a First-Party Tool", "chunk": "16 To activate a tool, an OpenMP implementation first determines whether the tool should be \n initialized.If so, the OpenMP implementation invokes the initializer of the tool, which enables the \n tool to prepare to monitor execution on the host.The tool may then also arrange to monitor \n computation that executes on target devices.This section explains how the tool and an OpenMP \n implementation interact to accomplish these tasks.\n"}
{"section_title": "19.2.1 ompt_start_tool", "chunk": "22 Summary \n In order to use the OMPT interface provided by an OpenMP implementation, a tool must implement \n the ompt_start_tool function, through which the OpenMP implementation initializes the tool.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n ompt_start_tool_result_t *ompt_start_tool( \n unsigned int omp_version, \n const char *runtime_version \n ); \nC \n Semantics \n For a tool to use the OMPT interface that an OpenMP implementation provides, the tool must define \n a globally-visible implementation of the function ompt_start_tool.The tool indicates that it \n will use the OMPT interface that an OpenMP implementation provides by returning a non-null \n pointer to an ompt_start_tool_result_t structure from the ompt_start_tool \n implementation that it provides."}
{"section_title": "19.2.1 ompt_start_tool", "chunk": "The tool indicates that it \n will use the OMPT interface that an OpenMP implementation provides by returning a non-null \n pointer to an ompt_start_tool_result_t structure from the ompt_start_tool \n implementation that it provides.The ompt_start_tool_result_t structure contains \n pointers to tool initialization and finalization callbacks as well as a tool data word that an OpenMP \n implementation must pass by reference to these callbacks.A tool may return NULL from \n ompt_start_tool to indicate that it will not use the OMPT interface in a particular execution.\n A tool may use the omp_version argument to determine if it is compatible with the OMPT interface \n that the OpenMP implementation provides.\n Description of Arguments \n The argument omp_version is the value of the _OPENMP version macro associated with the \n OpenMP API implementation."}
{"section_title": "19.2.1 ompt_start_tool", "chunk": "\n Description of Arguments \n The argument omp_version is the value of the _OPENMP version macro associated with the \n OpenMP API implementation.This value identifies the OpenMP API version that an OpenMP \n implementation supports, which specifies the version of the OMPT interface that it supports.\n The argument runtime_version is a version string that unambiguously identifies the OpenMP \n implementation.\n Constraints on Arguments \n The argument runtime_version must be an immutable string that is defined for the lifetime of a \n program execution."}
{"section_title": "19.2.1 ompt_start_tool", "chunk": "\n Constraints on Arguments \n The argument runtime_version must be an immutable string that is defined for the lifetime of a \n program execution.\n Effect \n If a tool returns a non-null pointer to an ompt_start_tool_result_t structure, an OpenMP \n implementation will call the tool initializer specified by the initialize field in this structure before \n beginning execution of any OpenMP construct or completing execution of any environment routine \n invocation; the OpenMP implementation will call the tool finalizer specified by the finalize field in \n this structure when the OpenMP implementation shuts down.\n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \nCHAPTER 19."}
{"section_title": "19.2.1 ompt_start_tool", "chunk": "\n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \nCHAPTER 19.OMPT INTERFACE 441 \nInactive \nRuntime \n(re)start tool-var Pending \nFind next tool \nReturn \nvalue r \nActive \nCall \nompt_start_tool \nInactive Found? \nRuntime shutdown \nor pause \nCall \nr->initialize \nReturn \nvalue \nenabled \ndisabled \nr=non-null \nr=NULL yes \nno \n \n \nFIGURE 19.1: First-Party Tool Activation Flow Chart \n"}
{"section_title": "19.2.2 Determining Whether a First-Party Tool Should be Initialized", "chunk": "2 Initialized \n An OpenMP implementation examines the tool-var ICV as one of its first initialization steps.If the \n value of tool-var is disabled, the initialization continues without a check for the presence of a tool \n and the functionality of the OMPT interface will be unavailable as the program executes.In this \n case, the OMPT interface state remains inactive.\n Otherwise, the OMPT interface state changes to pending and the OpenMP implementation activates \n any first-party tool that it finds."}
{"section_title": "19.2.2 Determining Whether a First-Party Tool Should be Initialized", "chunk": "\n Otherwise, the OMPT interface state changes to pending and the OpenMP implementation activates \n any first-party tool that it finds.A tool can provide a definition of ompt_start_tool to an \n OpenMP implementation in three ways: \n \u2022 By statically-linking its definition of ompt_start_tool into an OpenMP application; \n \u2022 By introducing a dynamically-linked library that includes its definition of ompt_start_tool \n into the application\u2019s address space; or \n \u2022 By providing, in the tool-libraries-var ICV, the name of a dynamically-linked library that is \n appropriate for the architecture and operating system used by the application and that includes a \n OpenMP API \u2013 Version 5.2 November 2021 \n definition of ompt_start_tool.\n If the value of tool-var is enabled, the OpenMP implementation must check if a tool has provided \n an implementation of ompt_start_tool."}
{"section_title": "19.2.2 Determining Whether a First-Party Tool Should be Initialized", "chunk": "\n If the value of tool-var is enabled, the OpenMP implementation must check if a tool has provided \n an implementation of ompt_start_tool.The OpenMP implementation first checks if a \n tool-provided implementation of ompt_start_tool is available in the address space, either \n statically-linked into the application or in a dynamically-linked library loaded in the address space.\n If multiple implementations of ompt_start_tool are available, the OpenMP implementation \n will use the first tool-provided implementation of ompt_start_tool that it finds.\n If the implementation does not find a tool-provided implementation of ompt_start_tool in the \n address space, it consults the tool-libraries-var ICV, which contains a (possibly empty) list of \n dynamically-linked libraries.As described in detail in Section 21.3.2, the libraries in \n tool-libraries-var are then searched for the first usable implementation of ompt_start_tool \n that one of the libraries in the list provides."}
{"section_title": "19.2.2 Determining Whether a First-Party Tool Should be Initialized", "chunk": "As described in detail in Section 21.3.2, the libraries in \n tool-libraries-var are then searched for the first usable implementation of ompt_start_tool \n that one of the libraries in the list provides.\n If the implementation finds a tool-provided definition of ompt_start_tool, it invokes that \n method; if a NULL pointer is returned, the OMPT interface state remains pending and the \n implementation continues to look for implementations of ompt_start_tool; otherwise a \n non-null pointer to an ompt_start_tool_result_t structure is returned, the OMPT \n interface state changes to active and the OpenMP implementation makes the OMPT interface \n available as the program executes.In this case, as the OpenMP implementation completes its \n initialization, it initializes the OMPT interface.\n If no tool can be found, the OMPT interface state changes to inactive."}
{"section_title": "19.2.2 Determining Whether a First-Party Tool Should be Initialized", "chunk": "\n If no tool can be found, the OMPT interface state changes to inactive.\n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \n \u2022 ompt_start_tool, see Section 19.2.1 \n \u2022 tool-libraries-var ICV, see Table 2.1 \n \u2022 tool-var ICV, see Table 2.1 \n"}
{"section_title": "19.2.3 Initializing a First-Party Tool", "chunk": "27 To initialize the OMPT interface, the OpenMP implementation invokes the tool initializer that is \n specified in the ompt_start_tool_result_t structure that is indicated by the non-null \n pointer that ompt_start_tool returns.The initializer is invoked prior to the occurrence of any \n OpenMP event.\n A tool initializer, described in Section 19.5.1.1, uses the function specified in its lookup argument \n to look up pointers to OMPT interface runtime entry points that the OpenMP implementation \n provides; this process is described in Section 19.2.3.1.Typically, a tool initializer obtains a pointer \n to the ompt_set_callback runtime entry point with type signature \n ompt_set_callback_t and then uses this runtime entry point to register tool callbacks for \n OpenMP events, as described in Section 19.2.4.\nCHAPTER 19."}
{"section_title": "19.2.3 Initializing a First-Party Tool", "chunk": "\nCHAPTER 19.OMPT INTERFACE 443 \n A tool initializer may use the ompt_enumerate_states runtime entry point, which has type \n signature ompt_enumerate_states_t, to determine the thread states that an OpenMP \n implementation employs.Similarly, it may use the ompt_enumerate_mutex_impls runtime \n entry point, which has type signature ompt_enumerate_mutex_impls_t, to determine the \n mutual exclusion implementations that the OpenMP implementation employs.\n If a tool initializer returns a non-zero value, the OMPT interface state remains active for the \n execution; otherwise, the OMPT interface state changes to inactive.\n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \n \u2022 ompt_enumerate_mutex_impls_t, see Section 19.6.1.2 \n \u2022 ompt_enumerate_states_t, see Section 19.6.1.1 \n \u2022 ompt_set_callback_t, see Section 19.6.1.3 \n \u2022 ompt_start_tool, see Section 19.2.1 \n"}
{"section_title": "19.2.3.1 Binding Entry Points in the OMPT Callback Interface", "chunk": "15 Functions that an OpenMP implementation provides to support the OMPT interface are not defined \n as global function symbols.Instead, they are defined as runtime entry points that a tool can only \n identify through the lookup function that is provided as an argument with type signature \n ompt_function_lookup_t to the tool initializer.A tool can use this function to obtain a \n pointer to each of the runtime entry points that an OpenMP implementation provides to support the \n OMPT interface.Once a tool has obtained a lookup function, it may employ it at any point in the \n future.\n For each runtime entry point in the OMPT interface for the host device, Table 19.1 provides the \n string name by which it is known and its associated type signature.Implementations can provide \n additional implementation-specific names and corresponding entry points.Any names that begin \n with ompt_ are reserved names."}
{"section_title": "19.2.3.1 Binding Entry Points in the OMPT Callback Interface", "chunk": "Any names that begin \n with ompt_ are reserved names.\n During initialization, a tool should look up each runtime entry point in the OMPT interface by \n name and bind a pointer maintained by the tool that can later be used to invoke the entry point.The \n entry points described in Table 19.1 enable a tool to assess the thread states and mutual exclusion \n implementations that an OpenMP implementation supports to register tool callbacks, to inspect \n registered callbacks, to introspect OpenMP state associated with threads, and to use tracing to \n monitor computations that execute on target devices.\n Detailed information about each runtime entry point listed in Table 19.1 is included as part of the \n description of its type signature."}
{"section_title": "19.2.3.1 Binding Entry Points in the OMPT Callback Interface", "chunk": "\n Detailed information about each runtime entry point listed in Table 19.1 is included as part of the \n description of its type signature.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 19.1: OMPT Callback Interface Runtime Entry Point Names and Their Type Signatures \nEntry Point String Name Type signature \n\u201compt_enumerate_states\u201d ompt_enumerate_states_t \n\u201compt_enumerate_mutex_impls\u201d ompt_enumerate_mutex_impls_t \n\u201compt_set_callback\u201d ompt_set_callback_t \n\u201compt_get_callback\u201d ompt_get_callback_t \n\u201compt_get_thread_data\u201d ompt_get_thread_data_t \n\u201compt_get_num_places\u201d ompt_get_num_places_t \n\u201compt_get_place_proc_ids\u201d ompt_get_place_proc_ids_t \n\u201compt_get_place_num\u201d ompt_get_place_num_t \n\u201compt_get_partition_place_nums\u201d ompt_get_partition_place_nums_t \n\u201compt_get_proc_id\u201d ompt_get_proc_id_t \n\u201compt_get_state\u201d ompt_get_state_t \n\u201compt_get_parallel_info\u201d ompt_get_parallel_info_t \n\u201compt_get_task_info\u201d ompt_get_task_info_t \n\u201compt_get_task_memory\u201d ompt_get_task_memory_t \n\u201compt_get_num_devices\u201d ompt_get_num_devices_t \n\u201compt_get_num_procs\u201d ompt_get_num_procs_t \n\u201compt_get_target_info\u201d ompt_get_target_info_t \n\u201compt_get_unique_id\u201d ompt_get_unique_id_t \n\u201compt_finalize_tool\u201d ompt_finalize_tool_t \n Cross References \n \u2022 Lookup Entry Points: ompt_function_lookup_t, see Section 19.6.3 \n \u2022 ompt_enumerate_mutex_impls_t, see Section 19.6.1.2 \n \u2022 ompt_enumerate_states_t, see Section 19.6.1.1 \n \u2022 ompt_get_callback_t, see Section 19.6.1.4 \n \u2022 ompt_get_num_devices_t, see Section 19.6.1.17 \n \u2022 ompt_get_num_places_t, see Section 19.6.1.7 \n \u2022 ompt_get_num_procs_t, see Section 19.6.1.6 \n \u2022 ompt_get_parallel_info_t, see Section 19.6.1.13 \n \u2022 ompt_get_partition_place_nums_t, see Section 19.6.1.10 \n \u2022 ompt_get_place_num_t, see Section 19.6.1.9 \n \u2022 ompt_get_place_proc_ids_t, see Section 19.6.1.8 \n \u2022 ompt_get_proc_id_t, see Section 19.6.1.11 \n \u2022 ompt_get_state_t, see Section 19.6.1.12 \nCHAPTER 19."}
{"section_title": "19.2.3.1 Binding Entry Points in the OMPT Callback Interface", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 19.1: OMPT Callback Interface Runtime Entry Point Names and Their Type Signatures \nEntry Point String Name Type signature \n\u201compt_enumerate_states\u201d ompt_enumerate_states_t \n\u201compt_enumerate_mutex_impls\u201d ompt_enumerate_mutex_impls_t \n\u201compt_set_callback\u201d ompt_set_callback_t \n\u201compt_get_callback\u201d ompt_get_callback_t \n\u201compt_get_thread_data\u201d ompt_get_thread_data_t \n\u201compt_get_num_places\u201d ompt_get_num_places_t \n\u201compt_get_place_proc_ids\u201d ompt_get_place_proc_ids_t \n\u201compt_get_place_num\u201d ompt_get_place_num_t \n\u201compt_get_partition_place_nums\u201d ompt_get_partition_place_nums_t \n\u201compt_get_proc_id\u201d ompt_get_proc_id_t \n\u201compt_get_state\u201d ompt_get_state_t \n\u201compt_get_parallel_info\u201d ompt_get_parallel_info_t \n\u201compt_get_task_info\u201d ompt_get_task_info_t \n\u201compt_get_task_memory\u201d ompt_get_task_memory_t \n\u201compt_get_num_devices\u201d ompt_get_num_devices_t \n\u201compt_get_num_procs\u201d ompt_get_num_procs_t \n\u201compt_get_target_info\u201d ompt_get_target_info_t \n\u201compt_get_unique_id\u201d ompt_get_unique_id_t \n\u201compt_finalize_tool\u201d ompt_finalize_tool_t \n Cross References \n \u2022 Lookup Entry Points: ompt_function_lookup_t, see Section 19.6.3 \n \u2022 ompt_enumerate_mutex_impls_t, see Section 19.6.1.2 \n \u2022 ompt_enumerate_states_t, see Section 19.6.1.1 \n \u2022 ompt_get_callback_t, see Section 19.6.1.4 \n \u2022 ompt_get_num_devices_t, see Section 19.6.1.17 \n \u2022 ompt_get_num_places_t, see Section 19.6.1.7 \n \u2022 ompt_get_num_procs_t, see Section 19.6.1.6 \n \u2022 ompt_get_parallel_info_t, see Section 19.6.1.13 \n \u2022 ompt_get_partition_place_nums_t, see Section 19.6.1.10 \n \u2022 ompt_get_place_num_t, see Section 19.6.1.9 \n \u2022 ompt_get_place_proc_ids_t, see Section 19.6.1.8 \n \u2022 ompt_get_proc_id_t, see Section 19.6.1.11 \n \u2022 ompt_get_state_t, see Section 19.6.1.12 \nCHAPTER 19.OMPT INTERFACE 445 \n \u2022 ompt_get_target_info_t, see Section 19.6.1.16 \n \u2022 ompt_get_task_info_t, see Section 19.6.1.14 \n \u2022 ompt_get_task_memory_t, see Section 19.6.1.15 \n \u2022 ompt_get_thread_data_t, see Section 19.6.1.5 \n \u2022 ompt_get_unique_id_t, see Section 19.6.1.18 \n \u2022 ompt_set_callback_t, see Section 19.6.1.3 \n"}
{"section_title": "19.2.4 Monitoring Activity on the Host with OMPT", "chunk": "8 To monitor the execution of an OpenMP program on the host device, a tool initializer must register \n to receive notification of events that occur as an OpenMP program executes.A tool can use the \n ompt_set_callback runtime entry point to register callbacks for OpenMP events.The return \n codes for ompt_set_callback use the ompt_set_result_t enumeration type.If the \n ompt_set_callback runtime entry point is called outside a tool initializer, registration of \n supported callbacks may fail with a return value of ompt_set_error.\n All callbacks registered with ompt_set_callback or returned by ompt_get_callback use \n the dummy type signature ompt_callback_t.\n For callbacks listed in Table 19.2, ompt_set_always is the only registration return code that is \n allowed.An OpenMP implementation must guarantee that the callback will be invoked every time \n that a runtime event that is associated with it occurs."}
{"section_title": "19.2.4 Monitoring Activity on the Host with OMPT", "chunk": "An OpenMP implementation must guarantee that the callback will be invoked every time \n that a runtime event that is associated with it occurs.Support for such callbacks is required in a \n minimal implementation of the OMPT interface.\n For callbacks listed in Table 19.3, the ompt_set_callback runtime entry may return any \n non-error code.Whether an OpenMP implementation invokes a registered callback never, \n sometimes, or always is implementation defined.If registration for a callback allows a return code \n of ompt_set_never, support for invoking such a callback may not be present in a minimal \n implementation of the OMPT interface.The return code from registering a callback indicates the \n implementation-defined level of support for the callback.\n Two techniques reduce the size of the OMPT interface."}
{"section_title": "19.2.4 Monitoring Activity on the Host with OMPT", "chunk": "\n Two techniques reduce the size of the OMPT interface.First, in cases where events are naturally \n paired, for example, the beginning and end of a region, and the arguments needed by the callback at \n each endpoint are identical, a tool registers a single callback for the pair of events, with \n ompt_scope_begin or ompt_scope_end provided as an argument to identify for which \n endpoint the callback is invoked.Second, when a class of events is amenable to uniform treatment, \n OMPT provides a single callback for that class of events, for example, an \n ompt_callback_sync_region_wait callback is used for multiple kinds of synchronization \n regions, such as barrier, taskwait, and taskgroup regions.Some events, for example, \n ompt_callback_sync_region_wait, use both techniques."}
{"section_title": "19.2.4 Monitoring Activity on the Host with OMPT", "chunk": "Some events, for example, \n ompt_callback_sync_region_wait, use both techniques.\n Cross References \n \u2022 ompt_get_callback_t, see Section 19.6.1.4 \n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 19.2: Callbacks for which ompt_set_callback Must Return ompt_set_always \nCallback Name \nompt_callback_thread_begin \nompt_callback_thread_end \nompt_callback_parallel_begin \nompt_callback_parallel_end \nompt_callback_task_create \nompt_callback_task_schedule \nompt_callback_implicit_task \nompt_callback_target \nompt_callback_target_emi \nompt_callback_target_data_op \nompt_callback_target_data_op_emi \nompt_callback_target_submit \nompt_callback_target_submit_emi \nompt_callback_control_tool \nompt_callback_device_initialize \nompt_callback_device_finalize \nompt_callback_device_load \nompt_callback_device_unload \n \u2022 ompt_set_callback_t, see Section 19.6.1.3 \n \u2022 ompt_set_result_t, see Section 19.4.4.2 \n"}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "4 A target device may or may not initialize a full OpenMP runtime system.Unless it does, \n monitoring activity on a device using a tool interface based on callbacks may not be possible.To \n accommodate such cases, the OMPT interface defines a monitoring interface for tracing activity on \n target devices.Tracing activity on a target device involves the following steps: \n \u2022 To prepare to trace activity on a target device, a tool must register for an \n ompt_callback_device_initialize callback.A tool may also register for an \n ompt_callback_device_load callback to be notified when code is loaded onto a target \n device or an ompt_callback_device_unload callback to be notified when code is \n unloaded from a target device.A tool may also optionally register an \n ompt_callback_device_finalize callback.\n \u2022 When an OpenMP implementation initializes a target device, the OpenMP implementation \n dispatches the device initialization callback of the tool on the host device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n \u2022 When an OpenMP implementation initializes a target device, the OpenMP implementation \n dispatches the device initialization callback of the tool on the host device.If the OpenMP \n implementation or target device does not support tracing, the OpenMP implementation passes \nCHAPTER 19."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "If the OpenMP \n implementation or target device does not support tracing, the OpenMP implementation passes \nCHAPTER 19.OMPT INTERFACE 447 \nTABLE 19.3: Callbacks for which ompt_set_callback May Return Any Non-Error Code \nCallback Name \nompt_callback_sync_region_wait \nompt_callback_mutex_released \nompt_callback_dependences \nompt_callback_task_dependence \nompt_callback_work \nompt_callback_master // (deprecated) \nompt_callback_masked \nompt_callback_target_map \nompt_callback_target_map_emi \nompt_callback_sync_region \nompt_callback_reduction \nompt_callback_lock_init \nompt_callback_lock_destroy \nompt_callback_mutex_acquire \nompt_callback_mutex_acquired \nompt_callback_nest_lock \nompt_callback_flush \nompt_callback_cancel \nompt_callback_dispatch \n NULL to the device initializer of the tool for its lookup argument; otherwise, the OpenMP \n implementation passes a pointer to a device-specific runtime entry point with type signature \n ompt_function_lookup_t to the device initializer of the tool."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "OMPT INTERFACE 447 \nTABLE 19.3: Callbacks for which ompt_set_callback May Return Any Non-Error Code \nCallback Name \nompt_callback_sync_region_wait \nompt_callback_mutex_released \nompt_callback_dependences \nompt_callback_task_dependence \nompt_callback_work \nompt_callback_master // (deprecated) \nompt_callback_masked \nompt_callback_target_map \nompt_callback_target_map_emi \nompt_callback_sync_region \nompt_callback_reduction \nompt_callback_lock_init \nompt_callback_lock_destroy \nompt_callback_mutex_acquire \nompt_callback_mutex_acquired \nompt_callback_nest_lock \nompt_callback_flush \nompt_callback_cancel \nompt_callback_dispatch \n NULL to the device initializer of the tool for its lookup argument; otherwise, the OpenMP \n implementation passes a pointer to a device-specific runtime entry point with type signature \n ompt_function_lookup_t to the device initializer of the tool.\n \u2022 If a non-null lookup pointer is provided to the device initializer of the tool, the tool may use it to \n determine the runtime entry points in the tracing interface that are available for the device and \n may bind the returned function pointers to tool variables."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n \u2022 If a non-null lookup pointer is provided to the device initializer of the tool, the tool may use it to \n determine the runtime entry points in the tracing interface that are available for the device and \n may bind the returned function pointers to tool variables.Table 19.4 indicates the names of \n runtime entry points that may be available for a device; an implementation may provide \n additional implementation-defined names and corresponding entry points.The driver for the \n device provides the runtime entry points that enable a tool to control the trace collection interface \n of the device.The native trace format that the interface uses may be device specific and the \n available kinds of trace records are implementation defined.Some devices may allow a tool to \n collect traces of records in a standard format known as OMPT trace records.Each OMPT trace \n record serves as a substitute for an OMPT callback that cannot be made on the device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "Each OMPT trace \n record serves as a substitute for an OMPT callback that cannot be made on the device.The fields \n in each trace record type are defined in the description of the callback that the record represents.\n If this type of record is provided then the lookup function returns values for the runtime entry \n points ompt_set_trace_ompt and ompt_get_record_ompt, which support collecting \n and decoding OMPT traces.If the native tracing format for a device is the OMPT format then \n tracing can be controlled using the runtime entry points for native or OMPT tracing."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "If the native tracing format for a device is the OMPT format then \n tracing can be controlled using the runtime entry points for native or OMPT tracing.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 19.4: OMPT Tracing Interface Runtime Entry Point Names and Their Type Signatures \nEntry Point String Name Type Signature \n\u201compt_get_device_num_procs\u201d ompt_get_device_num_procs_t \n\u201compt_get_device_time\u201d ompt_get_device_time_t \n\u201compt_translate_time\u201d ompt_translate_time_t \n\u201compt_set_trace_ompt\u201d ompt_set_trace_ompt_t \n\u201compt_set_trace_native\u201d ompt_set_trace_native_t \n\u201compt_start_trace\u201d ompt_start_trace_t \n\u201compt_pause_trace\u201d ompt_pause_trace_t \n\u201compt_flush_trace\u201d ompt_flush_trace_t \n\u201compt_stop_trace\u201d ompt_stop_trace_t \n\u201compt_advance_buffer_cursor\u201d ompt_advance_buffer_cursor_t \n\u201compt_get_record_type\u201d ompt_get_record_type_t \n\u201compt_get_record_ompt\u201d ompt_get_record_ompt_t \n\u201compt_get_record_native\u201d ompt_get_record_native_t \n\u201compt_get_record_abstract\u201d ompt_get_record_abstract_t \n \u2022 The tool uses the ompt_set_trace_native and/or the ompt_set_trace_ompt \n runtime entry point to specify what types of events or activities to monitor on the device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 19.4: OMPT Tracing Interface Runtime Entry Point Names and Their Type Signatures \nEntry Point String Name Type Signature \n\u201compt_get_device_num_procs\u201d ompt_get_device_num_procs_t \n\u201compt_get_device_time\u201d ompt_get_device_time_t \n\u201compt_translate_time\u201d ompt_translate_time_t \n\u201compt_set_trace_ompt\u201d ompt_set_trace_ompt_t \n\u201compt_set_trace_native\u201d ompt_set_trace_native_t \n\u201compt_start_trace\u201d ompt_start_trace_t \n\u201compt_pause_trace\u201d ompt_pause_trace_t \n\u201compt_flush_trace\u201d ompt_flush_trace_t \n\u201compt_stop_trace\u201d ompt_stop_trace_t \n\u201compt_advance_buffer_cursor\u201d ompt_advance_buffer_cursor_t \n\u201compt_get_record_type\u201d ompt_get_record_type_t \n\u201compt_get_record_ompt\u201d ompt_get_record_ompt_t \n\u201compt_get_record_native\u201d ompt_get_record_native_t \n\u201compt_get_record_abstract\u201d ompt_get_record_abstract_t \n \u2022 The tool uses the ompt_set_trace_native and/or the ompt_set_trace_ompt \n runtime entry point to specify what types of events or activities to monitor on the device.The \n return codes for ompt_set_trace_ompt and ompt_set_trace_native use the \n ompt_set_result_t enumeration type."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "The \n return codes for ompt_set_trace_ompt and ompt_set_trace_native use the \n ompt_set_result_t enumeration type.If the ompt_set_trace_native or the \n ompt_set_trace_ompt runtime entry point is called outside a device initializer, registration \n of supported callbacks may fail with a return code of ompt_set_error.\n \u2022 The tool initiates tracing on the device by invoking ompt_start_trace.Arguments to \n ompt_start_trace include two tool callbacks through which the OpenMP implementation \n can manage traces associated with the device.One callback allocates a buffer in which the device \n can deposit trace events.The second callback processes a buffer of trace events from the device.\n \u2022 If the device requires a trace buffer, the OpenMP implementation invokes the tool-supplied \n callback function on the host device to request a new buffer."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n \u2022 If the device requires a trace buffer, the OpenMP implementation invokes the tool-supplied \n callback function on the host device to request a new buffer.\n \u2022 The OpenMP implementation monitors the execution of OpenMP constructs on the device and \n records a trace of events or activities into a trace buffer.If possible, device trace records are \n marked with a host_op_id\u2014an identifier that associates device activities with the target \n operation that the host initiated to cause these activities.To correlate activities on the host with \n activities on a device, a tool can register a ompt_callback_target_submit_emi \n callback.Before and after the host initiates creation of an initial task on a device associated with \n a structured block for a target construct, the OpenMP implementation dispatches the \n ompt_callback_target_submit_emi callback on the host in the thread that is executing \n the task that encounters the target construct."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "Before and after the host initiates creation of an initial task on a device associated with \n a structured block for a target construct, the OpenMP implementation dispatches the \n ompt_callback_target_submit_emi callback on the host in the thread that is executing \n the task that encounters the target construct.This callback provides the tool with a pair of \n identifiers: one that identifies the target region and a second that uniquely identifies the initial \n task associated with that region.These identifiers help the tool correlate activities on the target \n device with their target region.\nCHAPTER 19.OMPT INTERFACE 449 \n \u2022 When appropriate, for example, when a trace buffer fills or needs to be flushed, the OpenMP \n implementation invokes the tool-supplied buffer completion callback to process a non-empty \n sequence of records in a trace buffer that is associated with the device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "OMPT INTERFACE 449 \n \u2022 When appropriate, for example, when a trace buffer fills or needs to be flushed, the OpenMP \n implementation invokes the tool-supplied buffer completion callback to process a non-empty \n sequence of records in a trace buffer that is associated with the device.\n \u2022 The tool-supplied buffer completion callback may return immediately, ignoring records in the \n trace buffer, or it may iterate through them using the ompt_advance_buffer_cursor \n entry point to inspect each record.A tool may use the ompt_get_record_type runtime \n entry point to inspect the type of the record at the current cursor position.Three runtime entry \n points (ompt_get_record_ompt, ompt_get_record_native, and \n ompt_get_record_abstract) allow tools to inspect the contents of some or all records in \n a trace buffer.The ompt_get_record_native runtime entry point uses the native trace \n format of the device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "The ompt_get_record_native runtime entry point uses the native trace \n format of the device.The ompt_get_record_abstract runtime entry point decodes the \n contents of a native trace record and summarizes them as an ompt_record_abstract_t \n record.The ompt_get_record_ompt runtime entry point can only be used to retrieve \n records in OMPT format.\n \u2022 Once tracing has been started on a device, a tool may pause or resume tracing on the device at \n any time by invoking ompt_pause_trace with an appropriate flag value as an argument.\n \u2022 A tool may invoke the ompt_flush_trace runtime entry point for a device at any time \n between device initialization and finalization to cause the device to flush pending trace records.\n \u2022 At any time, a tool may use the ompt_start_trace runtime entry point to start tracing or the \n ompt_stop_trace runtime entry point to stop tracing on a device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n \u2022 At any time, a tool may use the ompt_start_trace runtime entry point to start tracing or the \n ompt_stop_trace runtime entry point to stop tracing on a device.When tracing is stopped \n on a device, the OpenMP implementation eventually gathers all trace records already collected \n on the device and presents them to the tool using the buffer completion callback.\n \u2022 An OpenMP implementation can be shut down while device tracing is in progress.\n \u2022 When an OpenMP implementation is shut down, it finalizes each device.Device finalization \n occurs in three steps.First, the OpenMP implementation halts any tracing in progress for the \n device.Second, the OpenMP implementation flushes all trace records collected for the device \n and uses the buffer completion callback associated with that device to present them to the tool.\n Finally, the OpenMP implementation dispatches any ompt_callback_device_finalize \n callback registered for the device."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n Finally, the OpenMP implementation dispatches any ompt_callback_device_finalize \n callback registered for the device.\n Restrictions \n Restrictions on tracing activity on devices are as follows: \n \u2022 Implementation-defined names must not start with the prefix ompt_, which is reserved for the \n OpenMP specification."}
{"section_title": "19.2.5 Tracing Activity on Target Devices with OMPT", "chunk": "\n Restrictions \n Restrictions on tracing activity on devices are as follows: \n \u2022 Implementation-defined names must not start with the prefix ompt_, which is reserved for the \n OpenMP specification.\n Cross References \n \u2022 ompt_advance_buffer_cursor_t, see Section 19.6.2.10 \n \u2022 ompt_callback_device_finalize_t, see Section 19.5.2.20 \n \u2022 ompt_callback_device_initialize_t, see Section 19.5.2.19 \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 ompt_flush_trace_t, see Section 19.6.2.8 \n \u2022 ompt_get_device_num_procs_t, see Section 19.6.2.1 \n \u2022 ompt_get_device_time_t, see Section 19.6.2.2 \n \u2022 ompt_get_record_abstract_t, see Section 19.6.2.14 \n \u2022 ompt_get_record_native_t, see Section 19.6.2.13 \n \u2022 ompt_get_record_ompt_t, see Section 19.6.2.12 \n \u2022 ompt_get_record_type_t, see Section 19.6.2.11 \n \u2022 ompt_pause_trace_t, see Section 19.6.2.7 \n \u2022 ompt_set_trace_native_t, see Section 19.6.2.5 \n \u2022 ompt_set_trace_ompt_t, see Section 19.6.2.4 \n \u2022 ompt_start_trace_t, see Section 19.6.2.6 \n \u2022 ompt_stop_trace_t, see Section 19.6.2.9 \n \u2022 ompt_translate_time_t, see Section 19.6.2.3 \n"}
{"section_title": "19.3 Finalizing a First-Party Tool", "chunk": "15 If the OMPT interface state is active, the tool finalizer, which has type signature \n ompt_finalize_t and is specified by the finalize field in the \n ompt_start_tool_result_t structure returned from the ompt_start_tool function, is \n called when the OpenMP implementation shuts down.\n Cross References \n \u2022 ompt_finalize_t, see Section 19.5.1.2 \n"}
{"section_title": "19.4 OMPT Data Types", "chunk": "22 The C/C++ header file (omp-tools.h) provides the definitions of the types that are specified \n throughout this subsection.\n"}
{"section_title": "19.4.1 Tool Initialization and Finalization", "chunk": "25 Summary \n A tool\u2019s implementation of ompt_start_tool returns a pointer to an \n ompt_start_tool_result_t structure, which contains pointers to the tool\u2019s initialization \n and finalization callbacks as well as an ompt_data_t object for use by the tool.\nCHAPTER 19.OMPT INTERFACE 451 \n Format \nC / C++ \n typedef struct ompt_start_tool_result_t { \n ompt_initialize_t initialize; \n ompt_finalize_t finalize; \n ompt_data_t tool_data; \n } ompt_start_tool_result_t; \nC / C++ \n Restrictions \n Restrictions to the ompt_start_tool_result_t type are as follows: \n \u2022 The initialize and finalize callback pointer values in an ompt_start_tool_result_t \n structure that ompt_start_tool returns must be non-null.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_finalize_t, see Section 19.5.1.2 \n \u2022 ompt_initialize_t, see Section 19.5.1.1 \n \u2022 ompt_start_tool, see Section 19.2.1 \n"}
{"section_title": "19.4.2 Callbacks", "chunk": "17 Summary \n The ompt_callbacks_t enumeration type indicates the integer codes used to identify OpenMP \n callbacks when registering or querying them."}
{"section_title": "19.4.2 Callbacks", "chunk": "17 Summary \n The ompt_callbacks_t enumeration type indicates the integer codes used to identify OpenMP \n callbacks when registering or querying them.\n Format \nC / C++ \n typedef enum ompt_callbacks_t { \n ompt_callback_thread_begin = 1, \n ompt_callback_thread_end = 2, \n ompt_callback_parallel_begin = 3, \n ompt_callback_parallel_end = 4, \n ompt_callback_task_create = 5, \n ompt_callback_task_schedule = 6, \n ompt_callback_implicit_task = 7, \n ompt_callback_target = 8, \n ompt_callback_target_data_op = 9, \n ompt_callback_target_submit = 10, \n ompt_callback_control_tool = 11, \n ompt_callback_device_initialize = 12, \n ompt_callback_device_finalize = 13, \n ompt_callback_device_load = 14, \n ompt_callback_device_unload = 15, \n OpenMP API \u2013 Version 5.2 November 2021 \n ompt_callback_sync_region_wait = 16, \n ompt_callback_mutex_released = 17, \n ompt_callback_dependences = 18, \n ompt_callback_task_dependence = 19, \n ompt_callback_work = 20, \n ompt_callback_masked = 21, \n ompt_callback_master /*(deprecated)*/ = ompt_callback_masked, \n ompt_callback_target_map = 22, \n ompt_callback_sync_region = 23, \n ompt_callback_lock_init = 24, \n ompt_callback_lock_destroy = 25, \n ompt_callback_mutex_acquire = 26, \n ompt_callback_mutex_acquired = 27, \n ompt_callback_nest_lock = 28, \n ompt_callback_flush = 29, \n ompt_callback_cancel = 30, \n ompt_callback_reduction = 31, \n ompt_callback_dispatch = 32, \n ompt_callback_target_emi = 33, \n ompt_callback_target_data_op_emi = 34, \n ompt_callback_target_submit_emi = 35, \n ompt_callback_target_map_emi = 36, \n ompt_callback_error = 37 \n } ompt_callbacks_t; \nC / C++ \n"}
{"section_title": "19.4.3 Tracing", "chunk": "26 OpenMP provides type definitions that support tracing with OMPT.\n"}
{"section_title": "19.4.3.1 Record Type", "chunk": "28 Summary \n The ompt_record_t enumeration type indicates the integer codes used to identify OpenMP \n trace record formats.\n Format \nC / C++ \n typedef enum ompt_record_t { \n ompt_record_ompt = 1, \n ompt_record_native = 2, \n ompt_record_invalid = 3 \n } ompt_record_t; \nC / C++ \nCHAPTER 19.OMPT INTERFACE 453 \n"}
{"section_title": "19.4.3.2 Native Record Kind", "chunk": "2 Summary \n The ompt_record_native_t enumeration type indicates the integer codes used to identify \n OpenMP native trace record contents.\n Format \nC / C++ \n typedef enum ompt_record_native_t { \n ompt_record_native_info = 1, \n ompt_record_native_event = 2 \n } ompt_record_native_t; \nC / C++ \n"}
{"section_title": "19.4.3.3 Native Record Abstract Type", "chunk": "11 Summary \n The ompt_record_abstract_t type provides an abstract trace record format that is used to \n summarize native device trace records.\n Format \nC / C++ \n typedef struct ompt_record_abstract_t { \n ompt_record_native_t rclass; \n const char *type; \n ompt_device_time_t start_time; \n ompt_device_time_t end_time; \n ompt_hwid_t hwid; \n } ompt_record_abstract_t; \nC / C++ \n Semantics \n An ompt_record_abstract_t record contains information that a tool can use to process a \n native record that it may not fully understand.The rclass field indicates that the record is \n informational or that it represents an event; this information can help a tool determine how to \n present the record.The record type field points to a statically-allocated, immutable character string \n that provides a meaningful name that a tool can use to describe the event to a user.The start_time \n and end_time fields are used to place an event in time."}
{"section_title": "19.4.3.3 Native Record Abstract Type", "chunk": "The start_time \n and end_time fields are used to place an event in time.The times are relative to the device clock.If \n an event does not have an associated start_time (end_time), the value of the start_time (end_time) \n field is ompt_time_none.The hardware identifier field, hwid, indicates the location on the \n device where the event occurred.A hwid may represent a hardware abstraction such as a core or a \n hardware thread identifier.The meaning of a hwid value for a device is implementation defined.If \n no hardware abstraction is associated with the record then the value of hwid is ompt_hwid_none.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.4.3.4 Standard Trace Record Type", "chunk": "2 Summary \n The ompt_record_ompt_t type provides a standard complete trace record format."}
{"section_title": "19.4.3.4 Standard Trace Record Type", "chunk": "2 Summary \n The ompt_record_ompt_t type provides a standard complete trace record format.\n Format \nC / C++ \n typedef struct ompt_record_ompt_t { \n ompt_callbacks_t type; \n ompt_device_time_t time; \n ompt_id_t thread_id; \n ompt_id_t target_id; \n union { \n ompt_record_thread_begin_t thread_begin; \n ompt_record_parallel_begin_t parallel_begin; \n ompt_record_parallel_end_t parallel_end; \n ompt_record_work_t work; \n ompt_record_dispatch_t dispatch; \n ompt_record_task_create_t task_create; \n ompt_record_dependences_t dependences; \n ompt_record_task_dependence_t task_dependence; \n ompt_record_task_schedule_t task_schedule; \n ompt_record_implicit_task_t implicit_task; \n ompt_record_masked_t masked; \n ompt_record_sync_region_t sync_region; \n ompt_record_mutex_acquire_t mutex_acquire; \n ompt_record_mutex_t mutex; \n ompt_record_nest_lock_t nest_lock; \n ompt_record_flush_t flush; \n ompt_record_cancel_t cancel; \n ompt_record_target_t target; \n ompt_record_target_data_op_t target_data_op; \n ompt_record_target_map_t target_map; \n ompt_record_target_kernel_t target_kernel; \n ompt_record_control_tool_t control_tool; \n ompt_record_error_t error; \n } record; \n } ompt_record_ompt_t; \nC / C++ \n Semantics \n The field type specifies the type of record provided by this structure."}
{"section_title": "19.4.3.4 Standard Trace Record Type", "chunk": "\n Format \nC / C++ \n typedef struct ompt_record_ompt_t { \n ompt_callbacks_t type; \n ompt_device_time_t time; \n ompt_id_t thread_id; \n ompt_id_t target_id; \n union { \n ompt_record_thread_begin_t thread_begin; \n ompt_record_parallel_begin_t parallel_begin; \n ompt_record_parallel_end_t parallel_end; \n ompt_record_work_t work; \n ompt_record_dispatch_t dispatch; \n ompt_record_task_create_t task_create; \n ompt_record_dependences_t dependences; \n ompt_record_task_dependence_t task_dependence; \n ompt_record_task_schedule_t task_schedule; \n ompt_record_implicit_task_t implicit_task; \n ompt_record_masked_t masked; \n ompt_record_sync_region_t sync_region; \n ompt_record_mutex_acquire_t mutex_acquire; \n ompt_record_mutex_t mutex; \n ompt_record_nest_lock_t nest_lock; \n ompt_record_flush_t flush; \n ompt_record_cancel_t cancel; \n ompt_record_target_t target; \n ompt_record_target_data_op_t target_data_op; \n ompt_record_target_map_t target_map; \n ompt_record_target_kernel_t target_kernel; \n ompt_record_control_tool_t control_tool; \n ompt_record_error_t error; \n } record; \n } ompt_record_ompt_t; \nC / C++ \n Semantics \n The field type specifies the type of record provided by this structure.According to the type, event \n specific information is stored in the matching record entry."}
{"section_title": "19.4.3.4 Standard Trace Record Type", "chunk": "According to the type, event \n specific information is stored in the matching record entry.\nCHAPTER 19.OMPT INTERFACE 455 \n Restrictions \n Restrictions to the ompt_record_ompt_t type are as follows: \n \u2022 If type is set to ompt_callback_thread_end_t then the value of record is undefined.\n"}
{"section_title": "19.4.4 Miscellaneous Type Definitions", "chunk": "5 This section describes miscellaneous types and enumerations used by the tool interface.\n"}
{"section_title": "19.4.4.1 ompt_callback_t", "chunk": "7 Summary \n Pointers to tool callback functions with different type signatures are passed to the \n ompt_set_callback runtime entry point and returned by the ompt_get_callback \n runtime entry point.For convenience, these runtime entry points expect all type signatures to be \n cast to a dummy type ompt_callback_t.\n Format \nC / C++ \n typedef void (*ompt_callback_t) (void); \nC / C++ \n"}
{"section_title": "19.4.4.2 ompt_set_result_t", "chunk": "15 Summary \n The ompt_set_result_t enumeration type corresponds to values that the \n ompt_set_callback, ompt_set_trace_ompt and ompt_set_trace_native \n runtime entry points return.\n Format \nC / C++ \n typedef enum ompt_set_result_t { \n ompt_set_error = 0, \n ompt_set_never = 1, \n ompt_set_impossible = 2, \n ompt_set_sometimes = 3, \n ompt_set_sometimes_paired = 4, \n ompt_set_always = 5 \n } ompt_set_result_t; \nC / C++ \n Semantics \n Values of ompt_set_result_t, may indicate several possible outcomes.The \n ompt_set_error value indicates that the associated call failed.Otherwise, the value indicates \n when an event may occur and, when appropriate, dispatching a callback event leads to the \n invocation of the callback.The ompt_set_never value indicates that the event will never occur \n or that the callback will never be invoked at runtime.The ompt_set_impossible value \n indicates that the event may occur but that tracing of it is not possible."}
{"section_title": "19.4.4.2 ompt_set_result_t", "chunk": "The ompt_set_impossible value \n indicates that the event may occur but that tracing of it is not possible.The \n ompt_set_sometimes value indicates that the event may occur and, for an \n OpenMP API \u2013 Version 5.2 November 2021 \n implementation-defined subset of associated event occurrences, will be traced or the callback will \n be invoked at runtime.The ompt_set_sometimes_paired value indicates the same result as \n ompt_set_sometimes and, in addition, that a callback with an endpoint value of \n ompt_scope_begin will be invoked if and only if the same callback with an endpoint value of \n ompt_scope_end will also be invoked sometime in the future.The ompt_set_always value \n indicates that, whenever an associated event occurs, it will be traced or the callback will be invoked.\n Cross References \n \u2022 ompt_set_callback_t, see Section 19.6.1.3 \n \u2022 ompt_set_trace_native_t, see Section 19.6.2.5 \n \u2022 ompt_set_trace_ompt_t, see Section 19.6.2.4 \n"}
{"section_title": "19.4.4.3 ompt_id_t", "chunk": "12 Summary \n The ompt_id_t type is used to provide various identifiers to tools.\n Format \nC / C++ \n typedef uint64_t ompt_id_t; \nC / C++ \n Semantics \n When tracing asynchronous activity on devices, identifiers enable tools to correlate target regions \n and operations that the host initiates with associated activities on a target device.In addition, \n OMPT provides identifiers to refer to parallel regions and tasks that execute on a device.These \n various identifiers are of type ompt_id_t.\n ompt_id_none is defined as an instance of type ompt_id_t with the value 0.\n Restrictions \n Restrictions to the ompt_id_t type are as follows: \n \u2022 Identifiers created on each device must be unique from the time an OpenMP implementation is \n initialized until it is shut down.Identifiers for each target region and target data operation \n instance that the host device initiates must be unique over time on the host."}
{"section_title": "19.4.4.3 ompt_id_t", "chunk": "Identifiers for each target region and target data operation \n instance that the host device initiates must be unique over time on the host.Identifiers for parallel \n and task region instances that execute on a device must be unique over time within that device.\n"}
{"section_title": "19.4.4.4 ompt_data_t", "chunk": "29 Summary \n The ompt_data_t type represents data associated with threads and with parallel and task regions.\nCHAPTER 19.OMPT INTERFACE 457 \n Format \nC / C++ \n typedef union ompt_data_t { \n uint64_t value; \n void *ptr; \n } ompt_data_t; \nC / C++ \n Semantics \n The ompt_data_t type represents data that is reserved for tool use and that is related to a thread \n or to a parallel or task region.When an OpenMP implementation creates a thread or an instance of \n a parallel, teams, task, or target region, it initializes the associated ompt_data_t object with \n the value ompt_data_none, which is an instance of the type with the data and pointer fields \n equal to 0.\n"}
{"section_title": "19.4.4.5 ompt_device_t", "chunk": "13 Summary \n The ompt_device_t opaque object type represents a device.\n Format \nC / C++ \n typedef void ompt_device_t; \nC / C++ \n"}
{"section_title": "19.4.4.6 ompt_device_time_t", "chunk": "18 Summary \n The ompt_device_time_t type represents raw device time values.\n Format \nC / C++ \n typedef uint64_t ompt_device_time_t; \nC / C++ \n Semantics \n The ompt_device_time_t opaque object type represents raw device time values.\n ompt_time_none refers to an unknown or unspecified time and is defined as an instance of type \n ompt_device_time_t with the value 0.\n"}
{"section_title": "19.4.4.7 ompt_buffer_t", "chunk": "27 Summary \n The ompt_buffer_t opaque object type is a handle for a target buffer.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef void ompt_buffer_t; \nC / C++ \n"}
{"section_title": "19.4.4.8 ompt_buffer_cursor_t", "chunk": "4 Summary \n The ompt_buffer_cursor_t opaque type is a handle for a position in a target buffer.\n Format \nC / C++ \n typedef uint64_t ompt_buffer_cursor_t; \nC / C++ \n"}
{"section_title": "19.4.4.9 ompt_dependence_t", "chunk": "9 Summary \n The ompt_dependence_t type represents a task dependence.\n Format \nC / C++ \n typedef struct ompt_dependence_t { \n ompt_data_t variable; \n ompt_dependence_type_t dependence_type; \n } ompt_dependence_t; \nC / C++ \n Semantics \n The ompt_dependence_t type is a structure that holds information about a depend clause.For \n task dependences, the variable field points to the storage location of the dependence.For doacross \n dependences, the variable field contains the value of a vector element that describes the \n dependence.The dependence_type field indicates the type of the dependence.\n Cross References \n \u2022 ompt_dependence_type_t, see Section 19.4.4.24 \n"}
{"section_title": "19.4.4.10 ompt_thread_t", "chunk": "24 Summary \n The ompt_thread_t enumeration type defines the valid thread type values.\nCHAPTER 19.OMPT INTERFACE 459 \n Format \nC / C++ \n typedef enum ompt_thread_t { \n ompt_thread_initial = 1, \n ompt_thread_worker = 2, \n ompt_thread_other = 3, \n ompt_thread_unknown = 4 \n } ompt_thread_t; \nC / C++ \n Semantics \n Any initial thread has thread type ompt_thread_initial.All OpenMP threads that are not \n initial threads have thread type ompt_thread_worker.A thread that an OpenMP \n implementation uses but that does not execute user code has thread type ompt_thread_other.\n Any thread that is created outside an OpenMP implementation and that is not an initial thread has \n thread type ompt_thread_unknown.\n"}
{"section_title": "19.4.4.11 ompt_scope_endpoint_t", "chunk": "15 Summary \n The ompt_scope_endpoint_t enumeration type defines valid scope endpoint values.\n Format \nC / C++ \n typedef enum ompt_scope_endpoint_t { \n ompt_scope_begin = 1, \n ompt_scope_end = 2, \n ompt_scope_beginend = 3 \n } ompt_scope_endpoint_t; \nC / C++ \n"}
{"section_title": "19.4.4.12 ompt_dispatch_t", "chunk": "24 Summary \n The ompt_dispatch_t enumeration type defines the valid dispatch kind values.\n Format \nC / C++ \n typedef enum ompt_dispatch_t { \n ompt_dispatch_iteration = 1, \n ompt_dispatch_section = 2, \n ompt_dispatch_ws_loop_chunk = 3, \n ompt_dispatch_taskloop_chunk = 4, \n ompt_dispatch_distribute_chunk = 5 \n } ompt_dispatch_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.4.4.13 ompt_dispatch_chunk_t", "chunk": "2 Summary \n The ompt_dispatch_chunk_t type represents a the chunk information for a dispatched chunk.\n Format \nC / C++ \n typedef struct ompt_dispatch_chunk_t { \n uint64_t start; \n uint64_t iterations; \n } ompt_dispatch_chunk_t; \nC / C++ \n Semantics \n The ompt_dispatch_chunk_t type is a structure that holds information about a chunk of \n logical iterations of a loop nest.The start field specifies the first logical iteration of the chunk and \n the iterations field specifies the number of iterations in the chunk.Whether the chunk of a taskloop \n is contiguous is implementation defined.\n"}
{"section_title": "19.4.4.14 ompt_sync_region_t", "chunk": "15 Summary \n The ompt_sync_region_t enumeration type defines the valid synchronization region kind \n values.\n Format \nC / C++ \n typedef enum ompt_sync_region_t { \n ompt_sync_region_barrier = 1, // deprecated \n ompt_sync_region_barrier_implicit = 2, // deprecated \n ompt_sync_region_barrier_explicit = 3, \n ompt_sync_region_barrier_implementation = 4, \n ompt_sync_region_taskwait = 5, \n ompt_sync_region_taskgroup = 6, \n ompt_sync_region_reduction = 7, \n ompt_sync_region_barrier_implicit_workshare = 8, \n ompt_sync_region_barrier_implicit_parallel = 9, \n ompt_sync_region_barrier_teams = 10 \n } ompt_sync_region_t; \nC / C++ \n"}
{"section_title": "19.4.4.15 ompt_target_data_op_t", "chunk": "32 Summary \n The ompt_target_data_op_t enumeration type defines the valid target data operation values.\nCHAPTER 19.OMPT INTERFACE 461 \n Format \nC / C++ \n typedef enum ompt_target_data_op_t { \n ompt_target_data_alloc = 1, \n ompt_target_data_transfer_to_device = 2, \n ompt_target_data_transfer_from_device = 3, \n ompt_target_data_delete = 4, \n ompt_target_data_associate = 5, \n ompt_target_data_disassociate = 6, \n ompt_target_data_alloc_async = 17, \n ompt_target_data_transfer_to_device_async = 18, \n ompt_target_data_transfer_from_device_async = 19, \n ompt_target_data_delete_async = 20 \n } ompt_target_data_op_t; \nC / C++ \n"}
{"section_title": "19.4.4.16 ompt_work_t", "chunk": "15 Summary \n The ompt_work_t enumeration type defines the valid work type values.\n Format \nC / C++ \n typedef enum ompt_work_t { \n ompt_work_loop = 1, \n ompt_work_sections = 2, \n ompt_work_single_executor = 3, \n ompt_work_single_other = 4, \n ompt_work_workshare = 5, \n ompt_work_distribute = 6, \n ompt_work_taskloop = 7, \n ompt_work_scope = 8, \n ompt_work_loop_static = 10, \n ompt_work_loop_dynamic = 11, \n ompt_work_loop_guided = 12, \n ompt_work_loop_other = 13 \n } ompt_work_t; \nC / C++ \n"}
{"section_title": "19.4.4.17 ompt_mutex_t", "chunk": "33 Summary \n The ompt_mutex_t enumeration type defines the valid mutex kind values.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef enum ompt_mutex_t { \n ompt_mutex_lock = 1, \n ompt_mutex_test_lock = 2, \n ompt_mutex_nest_lock = 3, \n ompt_mutex_test_nest_lock = 4, \n ompt_mutex_critical = 5, \n ompt_mutex_atomic = 6, \n ompt_mutex_ordered = 7 \n } ompt_mutex_t; \nC / C++ \n"}
{"section_title": "19.4.4.18 ompt_native_mon_flag_t", "chunk": "12 Summary \n The ompt_native_mon_flag_t enumeration type defines the valid native monitoring flag \n values.\n Format \nC / C++ \n typedef enum ompt_native_mon_flag_t { \n ompt_native_data_motion_explicit = 0x01, \n ompt_native_data_motion_implicit = 0x02, \n ompt_native_kernel_invocation = 0x04, \n ompt_native_kernel_execution = 0x08, \n ompt_native_driver = 0x10, \n ompt_native_runtime = 0x20, \n ompt_native_overhead = 0x40, \n ompt_native_idleness = 0x80 \n } ompt_native_mon_flag_t; \nC / C++ \n"}
{"section_title": "19.4.4.19 ompt_task_flag_t", "chunk": "27 Summary \n The ompt_task_flag_t enumeration type defines valid task types.\n Format \nC / C++ \n typedef enum ompt_task_flag_t { \n ompt_task_initial = 0x00000001, \n ompt_task_implicit = 0x00000002, \n ompt_task_explicit = 0x00000004, \n ompt_task_target = 0x00000008, \n ompt_task_taskwait = 0x00000010, \nCHAPTER 19.OMPT INTERFACE 463 \n ompt_task_undeferred = 0x08000000, \n ompt_task_untied = 0x10000000, \n ompt_task_final = 0x20000000, \n ompt_task_mergeable = 0x40000000, \n ompt_task_merged = 0x80000000 \n ompt_task_flag_t; \nC / C++ \n Semantics \n The ompt_task_flag_t enumeration type defines valid task type values.The least significant \n byte provides information about the general classification of the task.The other bits represent \n properties of the task.\n"}
{"section_title": "19.4.4.20 ompt_task_status_t", "chunk": "12 Summary \n The ompt_task_status_t enumeration type indicates the reason that a task was switched \n when it reached a task scheduling point.\n Format \nC / C++ \n typedef enum ompt_task_status_t { \n ompt_task_complete = 1, \n ompt_task_yield = 2, \n ompt_task_cancel = 3, \n ompt_task_detach = 4, \n ompt_task_early_fulfill = 5, \n ompt_task_late_fulfill = 6, \n ompt_task_switch = 7, \n ompt_taskwait_complete = 8 \n } ompt_task_status_t; \nC / C++ \n Semantics \n The value ompt_task_complete of the ompt_task_status_t type indicates that the task \n that encountered the task scheduling point completed execution of the associated structured block \n and an associated allow-completion event was fulfilled.The value ompt_task_yield indicates \n that the task encountered a taskyield construct.The value ompt_task_cancel indicates \n that the task was canceled when it encountered an active cancellation point."}
{"section_title": "19.4.4.20 ompt_task_status_t", "chunk": "The value ompt_task_cancel indicates \n that the task was canceled when it encountered an active cancellation point.The value \n ompt_task_detach indicates that a task for which the detach clause was specified completed \n execution of the associated structured block and is waiting for an allow-completion event to be \n OpenMP API \u2013 Version 5.2 November 2021 \n fulfilled.The value ompt_task_early_fulfill indicates that the allow-completion event of \n the task was fulfilled before the task completed execution of the associated structured block.The \n value ompt_task_late_fulfill indicates that the allow-completion event of the task was \n fulfilled after the task completed execution of the associated structured block.The value \n ompt_taskwait_complete indicates completion of the dependent task that results from a \n taskwait construct with one or more depend clauses.The value ompt_task_switch is \n used for all other cases that a task was switched.\n"}
{"section_title": "19.4.4.21 ompt_target_t", "chunk": "9 Summary \n The ompt_target_t enumeration type defines the valid target type values.\n Format \nC / C++ \n typedef enum ompt_target_t { \n ompt_target = 1, \n ompt_target_enter_data = 2, \n ompt_target_exit_data = 3, \n ompt_target_update = 4, \n ompt_target_nowait = 9, \n ompt_target_enter_data_nowait = 10, \n ompt_target_exit_data_nowait = 11, \n ompt_target_update_nowait = 12 \n ompt_target_t; \nC / C++ \n"}
{"section_title": "19.4.4.22 ompt_parallel_flag_t", "chunk": "23 Summary \n The ompt_parallel_flag_t enumeration type defines valid invoker values.\n Format \nC / C++ \n typedef enum ompt_parallel_flag_t { \n ompt_parallel_invoker_program = 0x00000001, \n ompt_parallel_invoker_runtime = 0x00000002, \n ompt_parallel_league = 0x40000000, \n ompt_parallel_team = 0x80000000 \n } ompt_parallel_flag_t; \nC / C++ \nCHAPTER 19.OMPT INTERFACE 465 \n Semantics \n The ompt_parallel_flag_t enumeration type defines valid invoker values, which indicate \n how an outlined function is invoked.The value ompt_parallel_invoker_program \n indicates that the outlined function associated with implicit tasks for the region is invoked directly \n by the application on the primary thread for a parallel region.The value \n ompt_parallel_invoker_runtime indicates that the outlined function associated with \n implicit tasks for the region is invoked by the runtime on the primary thread for a parallel region."}
{"section_title": "19.4.4.22 ompt_parallel_flag_t", "chunk": "The value \n ompt_parallel_invoker_runtime indicates that the outlined function associated with \n implicit tasks for the region is invoked by the runtime on the primary thread for a parallel region.\n The value ompt_parallel_league indicates that the callback is invoked due to the creation of \n a league of teams by a teams construct.The value ompt_parallel_team indicates that the \n callback is invoked due to the creation of a team of threads by a parallel construct.\n"}
{"section_title": "19.4.4.23 ompt_target_map_flag_t", "chunk": "12 Summary \n The ompt_target_map_flag_t enumeration type defines the valid target map flag values.\n Format \nC / C++ \n typedef enum ompt_target_map_flag_t { \n ompt_target_map_flag_to = 0x01, \n ompt_target_map_flag_from = 0x02, \n ompt_target_map_flag_alloc = 0x04, \n ompt_target_map_flag_release = 0x08, \n ompt_target_map_flag_delete = 0x10, \n ompt_target_map_flag_implicit = 0x20, \n ompt_target_map_flag_always = 0x40, \n ompt_target_map_flag_present = 0x80, \n ompt_target_map_flag_close = 0x100, \n ompt_target_map_flag_shared = 0x200 \n } ompt_target_map_flag_t; \nC / C++ \n Semantics \n The ompt_target_map_flag_ map-type flag is set if the mapping operations have that \n map-type.If the map-type for the mapping operations is tofrom, both the \n ompt_target_map_flag_to and ompt_target_map_flag_from flags are set.The \n ompt_target_map_implicit flag is set if the mapping operations result from implicit \n data-mapping rules."}
{"section_title": "19.4.4.23 ompt_target_map_flag_t", "chunk": "The \n ompt_target_map_implicit flag is set if the mapping operations result from implicit \n data-mapping rules.The ompt_target_map_flag_ map-type-modifier flag is set if the \n mapping operations are specified with that map-type-modifier.The \n ompt_target_map_flag_shared flag is set if the original and corresponding storage are \n shared in the mapping operation.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.4.4.24 ompt_dependence_type_t", "chunk": "2 Summary \n The ompt_dependence_type_t enumeration type defines the valid task dependence type \n values.\n Format \nC / C++ \n typedef enum ompt_dependence_type_t { \n ompt_dependence_type_in = 1, \n ompt_dependence_type_out = 2, \n ompt_dependence_type_inout = 3, \n ompt_dependence_type_mutexinoutset = 4, \n ompt_dependence_type_source = 5, \n ompt_dependence_type_sink = 6, \n ompt_dependence_type_inoutset = 7 \n } ompt_dependence_type_t; \nC / C++ \n"}
{"section_title": "19.4.4.25 ompt_severity_t", "chunk": "16 Summary \n The ompt_severity_t enumeration type defines the valid severity values.\n Format \nC / C++ \n typedef enum ompt_severity_t { \n ompt_warning = 1, \n ompt_fatal = 2 \n } ompt_severity_t; \nC / C++ \n"}
{"section_title": "19.4.4.26 ompt_cancel_flag_t", "chunk": "24 Summary \n The ompt_cancel_flag_t enumeration type defines the valid cancel flag values.\n Format \nC / C++ \n typedef enum ompt_cancel_flag_t { \n ompt_cancel_parallel = 0x01, \n ompt_cancel_sections = 0x02, \n ompt_cancel_loop = 0x04, \n ompt_cancel_taskgroup = 0x08, \nCHAPTER 19.OMPT INTERFACE 467 \n ompt_cancel_activated = 0x10, \n ompt_cancel_detected = 0x20, \n ompt_cancel_discarded_task = 0x40 \n ompt_cancel_flag_t; \nC / C++ \n"}
{"section_title": "19.4.4.27 ompt_hwid_t", "chunk": "6 Summary \n The ompt_hwid_t opaque type is a handle for a hardware identifier for a target device.\n Format \nC / C++ \n typedef uint64_t ompt_hwid_t; \nC / C++ \n Semantics \n The ompt_hwid_t opaque type is a handle for a hardware identifier for a target device.\n ompt_hwid_none is an instance of the type that refers to an unknown or unspecified hardware \n identifier and that has the value 0.If no hwid is associated with an \n ompt_record_abstract_t then the value of hwid is ompt_hwid_none.\n Cross References \n \u2022 Native Record Abstract Type, see Section 19.4.3.3 \n"}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "18 Summary \n If the OMPT interface is in the active state then an OpenMP implementation must maintain thread \n state information for each thread.The thread state maintained is an approximation of the \n instantaneous state of a thread.\n Format \nC / C++ \n A thread state must be one of the values of the enumeration type ompt_state_t or an \n implementation-defined state value of 512 or higher."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "\n Format \nC / C++ \n A thread state must be one of the values of the enumeration type ompt_state_t or an \n implementation-defined state value of 512 or higher.\n typedef enum ompt_state_t { \n ompt_state_work_serial = 0x000, \n ompt_state_work_parallel = 0x001, \n ompt_state_work_reduction = 0x002, \n \n ompt_state_wait_barrier = 0x010, // \n deprecated \n ompt_state_wait_barrier_implicit_parallel = 0x011, \n ompt_state_wait_barrier_implicit_workshare = 0x012, \n OpenMP API \u2013 Version 5.2 November 2021 \n ompt_state_wait_barrier_implicit = 0x013, // \n deprecated \n ompt_state_wait_barrier_explicit = 0x014, \n ompt_state_wait_barrier_implementation = 0x015, \n ompt_state_wait_barrier_teams = 0x016, \n \n ompt_state_wait_taskwait = 0x020, \n ompt_state_wait_taskgroup = 0x021, \n \n ompt_state_wait_mutex = 0x040, \n ompt_state_wait_lock = 0x041, \n ompt_state_wait_critical = 0x042, \n ompt_state_wait_atomic = 0x043, \n ompt_state_wait_ordered = 0x044, \n \n ompt_state_wait_target = 0x080, \n ompt_state_wait_target_map = 0x081, \n ompt_state_wait_target_update = 0x082, \n \n ompt_state_idle = 0x100, \n ompt_state_overhead = 0x101, \n ompt_state_undefined = 0x102 \n ompt_state_t; \nC / C++ \n Semantics \n A tool can query the OpenMP state of a thread at any time."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "\n typedef enum ompt_state_t { \n ompt_state_work_serial = 0x000, \n ompt_state_work_parallel = 0x001, \n ompt_state_work_reduction = 0x002, \n \n ompt_state_wait_barrier = 0x010, // \n deprecated \n ompt_state_wait_barrier_implicit_parallel = 0x011, \n ompt_state_wait_barrier_implicit_workshare = 0x012, \n OpenMP API \u2013 Version 5.2 November 2021 \n ompt_state_wait_barrier_implicit = 0x013, // \n deprecated \n ompt_state_wait_barrier_explicit = 0x014, \n ompt_state_wait_barrier_implementation = 0x015, \n ompt_state_wait_barrier_teams = 0x016, \n \n ompt_state_wait_taskwait = 0x020, \n ompt_state_wait_taskgroup = 0x021, \n \n ompt_state_wait_mutex = 0x040, \n ompt_state_wait_lock = 0x041, \n ompt_state_wait_critical = 0x042, \n ompt_state_wait_atomic = 0x043, \n ompt_state_wait_ordered = 0x044, \n \n ompt_state_wait_target = 0x080, \n ompt_state_wait_target_map = 0x081, \n ompt_state_wait_target_update = 0x082, \n \n ompt_state_idle = 0x100, \n ompt_state_overhead = 0x101, \n ompt_state_undefined = 0x102 \n ompt_state_t; \nC / C++ \n Semantics \n A tool can query the OpenMP state of a thread at any time.If a tool queries the state of a thread that \n is not associated with OpenMP then the implementation reports the state as \n ompt_state_undefined."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "If a tool queries the state of a thread that \n is not associated with OpenMP then the implementation reports the state as \n ompt_state_undefined.\n The value ompt_state_work_serial indicates that the thread is executing code outside all \n parallel regions.The value ompt_state_work_parallel indicates that the thread is \n executing code within the scope of a parallel region.The value \n ompt_state_work_reduction indicates that the thread is combining partial reduction \n results from threads in its team.An OpenMP implementation may never report a thread in this \n state; a thread that is combining partial reduction results may have its state reported as \n ompt_state_work_parallel or ompt_state_overhead.The value \n ompt_state_wait_barrier_implicit_parallel indicates that the thread is waiting at \n the implicit barrier at the end of a parallel region."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "The value \n ompt_state_wait_barrier_implicit_parallel indicates that the thread is waiting at \n the implicit barrier at the end of a parallel region.The value \n ompt_state_wait_barrier_implicit_workshare indicates that the thread is waiting \n at an implicit barrier at the end of a worksharing construct.The value \n ompt_state_wait_barrier_explicit indicates that the thread is waiting in an explicit \n barrier region.The value ompt_state_wait_barrier_implementation indicates \n that the thread is waiting in a barrier not required by the OpenMP standard but introduced by an \nCHAPTER 19.OMPT INTERFACE 469 \n OpenMP implementation.The value ompt_state_wait_barrier_teams indicates that the \n thread is waiting at a barrier at the end of a teams region.The value \n ompt_state_wait_taskwait indicates that the thread is waiting at a taskwait construct.\n The value ompt_state_wait_taskgroup indicates that the thread is waiting at the end of a \n taskgroup construct."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "\n The value ompt_state_wait_taskgroup indicates that the thread is waiting at the end of a \n taskgroup construct.The value ompt_state_wait_mutex indicates that the thread is \n waiting for a mutex of an unspecified type.The value ompt_state_wait_lock indicates that \n the thread is waiting for a lock or nestable lock.The value ompt_state_wait_critical \n indicates that the thread is waiting to enter a critical region.The value \n ompt_state_wait_atomic indicates that the thread is waiting to enter an atomic region.\n The value ompt_state_wait_ordered indicates that the thread is waiting to enter an \n ordered region.The value ompt_state_wait_target indicates that the thread is waiting \n for a target region to complete.The value ompt_state_wait_target_map indicates that \n the thread is waiting for a target data mapping operation to complete.An implementation may \n report ompt_state_wait_target for target data constructs."}
{"section_title": "19.4.4.28 ompt_state_t", "chunk": "An implementation may \n report ompt_state_wait_target for target data constructs.The value \n ompt_state_wait_target_update indicates that the thread is waiting for a \n target update operation to complete.An implementation may report \n ompt_state_wait_target for target update constructs.The value \n ompt_state_idle indicates that the thread is idle, that is, it is not part of an OpenMP team.\n The value ompt_state_overhead indicates that the thread is in the overhead state at any point \n while executing within the OpenMP runtime, except while waiting at a synchronization point.The \n value ompt_state_undefined indicates that the native thread is not created by the OpenMP \n implementation.\n"}
{"section_title": "19.4.4.29 ompt_frame_t", "chunk": "24 Summary \n The ompt_frame_t type describes procedure frame information for an OpenMP task.\n Format \nC / C++ \n typedef struct ompt_frame_t { \n ompt_data_t exit_frame; \n ompt_data_t enter_frame; \n int exit_frame_flags; \n int enter_frame_flags; \n } ompt_frame_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n Each ompt_frame_t object is associated with the task to which the procedure frames belong.\n Each non-merged initial, implicit, explicit, or target task with one or more frames on the stack of a \n native thread has an associated ompt_frame_t object.\n The exit_frame field of an ompt_frame_t object contains information to identify the first \n procedure frame executing the task region.The exit_frame for the ompt_frame_t object \n associated with the initial task that is not nested inside any OpenMP construct is \n ompt_data_none."}
{"section_title": "19.4.4.29 ompt_frame_t", "chunk": "The exit_frame for the ompt_frame_t object \n associated with the initial task that is not nested inside any OpenMP construct is \n ompt_data_none.\n The enter_frame field of an ompt_frame_t object contains information to identify the latest still \n active procedure frame executing the task region before entering the OpenMP runtime \n implementation or before executing a different task.If a task with frames on the stack is not \n executing implementation code in the OpenMP runtime, the value of enter_frame for the \n ompt_frame_t object associated with the task will be ompt_data_none.\n For exit_frame, the exit_frame_flags and, for enter_frame, the enter_frame_flags field indicates that \n the provided frame information points to a runtime or an application frame address.The same \n fields also specify the kind of information that is provided to identify the frame, These fields are a \n disjunction of values in the ompt_frame_flag_t enumeration type."}
{"section_title": "19.4.4.29 ompt_frame_t", "chunk": "The same \n fields also specify the kind of information that is provided to identify the frame, These fields are a \n disjunction of values in the ompt_frame_flag_t enumeration type.\n The lifetime of an ompt_frame_t object begins when a task is created and ends when the task is \n destroyed.Tools should not assume that a frame structure remains at a constant location in memory \n throughout the lifetime of the task.A pointer to an ompt_frame_t object is passed to some \n callbacks; a pointer to the ompt_frame_t object of a task can also be retrieved by a tool at any \n time, including in a signal handler, by invoking the ompt_get_task_info runtime entry point \n (described in Section 19.6.1.14).A pointer to an ompt_frame_t object that a tool retrieved is \n valid as long as the tool does not pass back control to the OpenMP implementation.\n \n Note \u2013 A monitoring tool that uses asynchronous sampling can observe values of exit_frame and \n enter_frame at inconvenient times."}
{"section_title": "19.4.4.29 ompt_frame_t", "chunk": "\n \n Note \u2013 A monitoring tool that uses asynchronous sampling can observe values of exit_frame and \n enter_frame at inconvenient times.Tools must be prepared to handle ompt_frame_t objects \n observed just prior to when their field values will be set or cleared.\n \n"}
{"section_title": "19.4.4.30 ompt_frame_flag_t", "chunk": "31 Summary \n The ompt_frame_flag_t enumeration type defines valid frame information flags.\nCHAPTER 19.OMPT INTERFACE 471 \n Format \nC / C++ \n typedef enum ompt_frame_flag_t { \n ompt_frame_runtime = 0x00, \n ompt_frame_application = 0x01, \n ompt_frame_cfa = 0x10, \n ompt_frame_framepointer = 0x20, \n ompt_frame_stackaddress = 0x30 \n } ompt_frame_flag_t; \nC / C++ \n Semantics \n The value ompt_frame_runtime of the ompt_frame_flag_t type indicates that a frame \n address is a procedure frame in the OpenMP runtime implementation.The value \n ompt_frame_application of the ompt_frame_flag_t type indicates that a frame \n address is a procedure frame in the OpenMP application.\n Higher order bits indicate the kind of provided information that is unique for the particular frame \n pointer.The value ompt_frame_cfa indicates that a frame address specifies a canonical frame \n address."}
{"section_title": "19.4.4.30 ompt_frame_flag_t", "chunk": "The value ompt_frame_cfa indicates that a frame address specifies a canonical frame \n address.The value ompt_frame_framepointer indicates that a frame address provides the \n value of the frame pointer register.The value ompt_frame_stackaddress indicates that a \n frame address specifies a pointer address that is contained in the current stack frame.\n"}
{"section_title": "19.4.4.31 ompt_wait_id_t", "chunk": "20 Summary \n The ompt_wait_id_t type describes wait identifiers for an OpenMP thread.\n Format \nC / C++ \n typedef uint64_t ompt_wait_id_t; \nC / C++ \n Semantics \n Each thread maintains a wait identifier of type ompt_wait_id_t.When a task that a thread \n executes is waiting for mutual exclusion, the wait identifier of the thread indicates the reason that \n the thread is waiting.A wait identifier may represent a critical section name, a lock, a program \n variable accessed in an atomic region, or a synchronization object that is internal to an OpenMP \n implementation.When a thread is not in a wait state then the value of the wait identifier of the \n thread is undefined.ompt_wait_id_none is defined as an instance of type \n ompt_wait_id_t with the value 0.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.5 OMPT Tool Callback Signatures and Trace Records", "chunk": "2 Records \n The C/C++ header file (omp-tools.h) provides the definitions of the types that are specified \n throughout this subsection.Restrictions to the OpenMP tool callbacks are as follows: \n Restrictions \n \u2022 Tool callbacks may not use OpenMP directives or call any runtime library routines described in \n Chapter 18.\n \u2022 Tool callbacks must exit by either returning to the caller or aborting.\n"}
{"section_title": "19.5.1 Initialization and Finalization Callback Signature", "chunk": ""}
{"section_title": "19.5.1.1 ompt_initialize_t", "chunk": "11 Summary \n A callback with type signature ompt_initialize_t initializes the use of the OMPT interface.\n Format \nC / C++ \n typedef int (*ompt_initialize_t) ( \n ompt_function_lookup_t lookup, \n int initial_device_num, \n ompt_data_t *tool_data \n ); \nC / C++ \n Semantics \n To use the OMPT interface, an implementation of ompt_start_tool must return a non-null \n pointer to an ompt_start_tool_result_t structure that contains a pointer to a tool \n initializer function with type signature ompt_initialize_t.An OpenMP implementation will \n call the initializer after fully initializing itself but before beginning execution of any OpenMP \n construct or runtime library routine.The initializer returns a non-zero value if it succeeds; \n otherwise, the OMPT interface state changes to inactive as described in Section 19.2.3."}
{"section_title": "19.5.1.1 ompt_initialize_t", "chunk": "The initializer returns a non-zero value if it succeeds; \n otherwise, the OMPT interface state changes to inactive as described in Section 19.2.3.\n Description of Arguments \n The lookup argument is a callback to an OpenMP runtime routine that must be used to obtain a \n pointer to each runtime entry point in the OMPT interface.The initial_device_num argument \n provides the value of omp_get_initial_device().The tool_data argument is a pointer to \n the tool_data field in the ompt_start_tool_result_t structure that ompt_start_tool \n returned.\nCHAPTER 19.OMPT INTERFACE 473 \n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \n \u2022 omp_get_initial_device, see Section 18.7.7 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_start_tool, see Section 19.2.1 \n"}
{"section_title": "19.5.1.2 ompt_finalize_t", "chunk": "7 Summary \n A tool implements a finalizer with the type signature ompt_finalize_t to finalize its use of the \n OMPT interface.\n Format \nC / C++ \n typedef void (*ompt_finalize_t) ( \n ompt_data_t *tool_data \n ); \nC / C++ \n Semantics \n To use the OMPT interface, an implementation of ompt_start_tool must return a non-null \n pointer to an ompt_start_tool_result_t structure that contains a non-null pointer to a tool \n finalizer with type signature ompt_finalize_t.An OpenMP implementation must call the tool \n finalizer after the last OMPT event as the OpenMP implementation shuts down.\n Description of Arguments \n The tool_data argument is a pointer to the tool_data field in the \n ompt_start_tool_result_t structure returned by ompt_start_tool.\n Cross References \n \u2022 Tool Initialization and Finalization, see Section 19.4.1 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_start_tool, see Section 19.2.1 \n"}
{"section_title": "19.5.2 Event Callback Signatures and Trace Records", "chunk": "27 This section describes the signatures of tool callback functions that an OMPT tool may register and \n that are called during the runtime of an OpenMP program.An implementation may also provide a \n trace of events per device.Along with the callbacks, the following defines standard trace records.\n For the trace records, tool data arguments are replaced by an ID, which must be initialized by the \n OpenMP implementation.Each of parallel_id, task_id, and thread_id must be unique per target \n region.Tool implementations of callbacks are not required to be async signal safe.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \n"}
{"section_title": "19.5.2.1 ompt_callback_thread_begin_t", "chunk": "5 Summary \n The ompt_callback_thread_begin_t type is used for callbacks that are dispatched when \n native threads are created.\n Format \nC / C++ \n typedef void (*ompt_callback_thread_begin_t) ( \n ompt_thread_t thread_type, \n ompt_data_t *thread_data \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_thread_begin_t { \n ompt_thread_t thread_type; \n } ompt_record_thread_begin_t; \nC / C++ \n Description of Arguments \n The thread_type argument indicates the type of the new thread: initial, worker, or other.The \n binding of the thread_data argument is the new thread.\n Cross References \n \u2022 Initial Task, see Section 12.8 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_thread_t, see Section 19.4.4.10 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \nCHAPTER 19.OMPT INTERFACE 475 \n"}
{"section_title": "19.5.2.2 ompt_callback_thread_end_t", "chunk": "2 Summary \n The ompt_callback_thread_end_t type is used for callbacks that are dispatched when \n native threads are destroyed.\n Format \nC / C++ \n typedef void (*ompt_callback_thread_end_t) ( \n ompt_data_t *thread_data \n ); \nC / C++ \n Description of Arguments \n The binding of the thread_data argument is the thread that will be destroyed.\n Cross References \n \u2022 Initial Task, see Section 12.8 \n \u2022 Standard Trace Record Type, see Section 19.4.3.4 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "19.5.2.3 ompt_callback_parallel_begin_t", "chunk": "18 Summary \n The ompt_callback_parallel_begin_t type is used for callbacks that are dispatched \n when a parallel or teams region starts.\n Format \nC / C++ \n typedef void (*ompt_callback_parallel_begin_t) ( \n ompt_data_t *encountering_task_data, \n const ompt_frame_t *encountering_task_frame, \n ompt_data_t *parallel_data, \n unsigned int requested_parallelism, \n int flags, \n const void *codeptr_ra \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Trace Record \nC / C++ \n typedef struct ompt_record_parallel_begin_t { \n ompt_id_t encountering_task_id; \n ompt_id_t parallel_id; \n unsigned int requested_parallelism; \n int flags; \n const void *codeptr_ra; \n } ompt_record_parallel_begin_t; \nC / C++ \n Description of Arguments \n The binding of the encountering_task_data argument is the encountering task.\n The encountering_task_frame argument points to the frame object that is associated with the \n encountering task."}
{"section_title": "19.5.2.3 ompt_callback_parallel_begin_t", "chunk": "\n The encountering_task_frame argument points to the frame object that is associated with the \n encountering task.The behavior for accessing the frame object after the callback returned is \n unspecified.\n The binding of the parallel_data argument is the parallel or teams region that is beginning.\n The requested_parallelism argument indicates the number of threads or teams that the user \n requested.\n The flags argument indicates whether the code for the region is inlined into the application or \n invoked by the runtime and also whether the region is a parallel or teams region.Valid values \n for flags are a disjunction of elements in the enum ompt_parallel_flag_t.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_parallel_begin_t then codeptr_ra contains the return address of the call \n to that runtime routine."}
{"section_title": "19.5.2.3 ompt_callback_parallel_begin_t", "chunk": "If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_parallel_begin_t then codeptr_ra contains the return address of the call \n to that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_frame_t, see Section 19.4.4.29 \n \u2022 ompt_parallel_flag_t, see Section 19.4.4.22 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "19.5.2.4 ompt_callback_parallel_end_t", "chunk": "33 Summary \n The ompt_callback_parallel_end_t type is used for callbacks that are dispatched when a \n parallel or teams region ends.\nCHAPTER 19.OMPT INTERFACE 477 \n Format \nC / C++ \n typedef void (*ompt_callback_parallel_end_t) ( \n ompt_data_t *parallel_data, \n ompt_data_t *encountering_task_data, \n int flags, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_parallel_end_t { \n ompt_id_t parallel_id; \n ompt_id_t encountering_task_id; \n int flags; \n const void *codeptr_ra; \n } ompt_record_parallel_end_t; \nC / C++ \n Description of Arguments \n The binding of the parallel_data argument is the parallel or teams region that is ending.\n The binding of the encountering_task_data argument is the encountering task.\n The flags argument indicates whether the execution of the region is inlined into the application or \n invoked by the runtime and also whether it is a parallel or teams region."}
{"section_title": "19.5.2.4 ompt_callback_parallel_end_t", "chunk": "\n The flags argument indicates whether the execution of the region is inlined into the application or \n invoked by the runtime and also whether it is a parallel or teams region.Values for flags are a \n disjunction of elements in the enum ompt_parallel_flag_t.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_parallel_end_t then codeptr_ra contains the return address of the call to \n that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL."}
{"section_title": "19.5.2.4 ompt_callback_parallel_end_t", "chunk": "If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_parallel_flag_t, see Section 19.4.4.22 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.5.2.5 ompt_callback_work_t", "chunk": "2 Summary \n The ompt_callback_work_t type is used for callbacks that are dispatched when worksharing \n regions and taskloop regions begin and end.\n Format \nC / C++ \n typedef void (*ompt_callback_work_t) ( \n ompt_work_t work_type, \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *parallel_data, \n ompt_data_t *task_data, \n uint64_t count, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_work_t { \n ompt_work_t work_type; \n ompt_scope_endpoint_t endpoint; \n ompt_id_t parallel_id; \n ompt_id_t task_id; \n uint64_t count; \n const void *codeptr_ra; \n } ompt_record_work_t; \nC / C++ \n Description of Arguments \n The work_type argument indicates the kind of region.\n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The binding of the parallel_data argument is the current parallel region.\n The binding of the task_data argument is the current task."}
{"section_title": "19.5.2.5 ompt_callback_work_t", "chunk": "\n The binding of the task_data argument is the current task.\n The count argument is a measure of the quantity of work involved in the construct.For a \n worksharing-loop or taskloop construct, count represents the number of iterations in the \n iteration space, which may be the result of collapsing several associated loops.For a sections \n construct, count represents the number of sections.For a workshare construct, count represents \n the units of work, as defined by the workshare construct.For a single or scope construct, \nCHAPTER 19.OMPT INTERFACE 479 \n count is always 1.When the endpoint argument signals the end of a scope, a count value of 0 \n indicates that the actual count value is not available.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code."}
{"section_title": "19.5.2.5 ompt_callback_work_t", "chunk": "\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_work_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 Work-Distribution Constructs, see Chapter 11 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_work_t, see Section 19.4.4.16 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "19.5.2.6 ompt_callback_dispatch_t", "chunk": "16 Summary \n The ompt_callback_dispatch_t type is used for callbacks that are dispatched when a \n thread begins to execute a section or loop iteration.\n Format \nC / C++ \n typedef void (*ompt_callback_dispatch_t) ( \n ompt_data_t *parallel_data, \n ompt_data_t *task_data, \n ompt_dispatch_t kind, \n ompt_data_t instance \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_dispatch_t { \n ompt_id_t parallel_id; \n ompt_id_t task_id; \n ompt_dispatch_t kind; \n ompt_data_t instance; \n } ompt_record_dispatch_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The binding of the parallel_data argument is the current parallel region.\n The binding of the task_data argument is the implicit task that executes the structured block of the \n parallel region.\n The kind argument indicates whether a loop iteration or a section is being dispatched."}
{"section_title": "19.5.2.6 ompt_callback_dispatch_t", "chunk": "\n The kind argument indicates whether a loop iteration or a section is being dispatched.\n If the kind argument is ompt_dispatch_iteration, the value field of the instance argument \n contains the logical iteration number.If the kind argument is ompt_dispatch_section, the \n ptr field of the instance argument contains a code address that identifies the structured block.In \n cases where a runtime routine implements the structured block associated with this callback, the ptr \n field of the instance argument contains the return address of the call to the runtime routine.In cases \n where the implementation of the structured block is inlined, the ptr field of the instance argument \n contains the return address of the invocation of this callback."}
{"section_title": "19.5.2.6 ompt_callback_dispatch_t", "chunk": "In cases \n where the implementation of the structured block is inlined, the ptr field of the instance argument \n contains the return address of the invocation of this callback.If the kind argument is \n ompt_dispatch_ws_loop_chunk, ompt_dispatch_taskloop_chunk or \n ompt_dispatch_distribute_chunk, the ptr field of the instance argument points to a \n structure of type ompt_dispatch_chunk_t that contains the information for the chunk.\n Cross References \n \u2022 Worksharing-Loop Constructs, see Section 11.5 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_dispatch_chunk_t, see Section 19.4.4.13 \n \u2022 ompt_dispatch_t, see Section 19.4.4.12 \n \u2022 sections directive, see Section 11.3 \n \u2022 taskloop directive, see Section 12.6 \n"}
{"section_title": "19.5.2.7 ompt_callback_task_create_t", "chunk": "24 Summary \n The ompt_callback_task_create_t type is used for callbacks that are dispatched when \n task regions are generated.\n Format \nC / C++ \n typedef void (*ompt_callback_task_create_t) ( \n ompt_data_t *encountering_task_data, \n const ompt_frame_t *encountering_task_frame, \n ompt_data_t *new_task_data, \n int flags, \n int has_dependences, \n const void *codeptr_ra \n ); \nC / C++ \nCHAPTER 19.OMPT INTERFACE 481 \n Trace Record \nC / C++ \n typedef struct ompt_record_task_create_t { \n ompt_id_t encountering_task_id; \n ompt_id_t new_task_id; \n int flags; \n int has_dependences; \n const void *codeptr_ra; \n } ompt_record_task_create_t; \nC / C++ \n Description of Arguments \n The binding of the encountering_task_data argument is the encountering task.\n The encountering_task_frame argument points to the frame object associated with the encountering \n task.The behavior for accessing the frame object after the callback returned is unspecified."}
{"section_title": "19.5.2.7 ompt_callback_task_create_t", "chunk": "The behavior for accessing the frame object after the callback returned is unspecified.\n The binding of the new_task_data argument is the generated task.\n The flags argument indicates the kind of task (explicit or target) that is generated.Values for flags \n are a disjunction of elements in the ompt_task_flag_t enumeration type.\n The has_dependences argument is true if the generated task has dependences and false otherwise.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_task_create_t then codeptr_ra contains the return address of the call to \n that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL."}
{"section_title": "19.5.2.7 ompt_callback_task_create_t", "chunk": "If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n Cross References \n \u2022 Initial Task, see Section 12.8 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_frame_t, see Section 19.4.4.29 \n \u2022 ompt_task_flag_t, see Section 19.4.4.19 \n \u2022 task directive, see Section 12.5 \n"}
{"section_title": "19.5.2.8 ompt_callback_dependences_t", "chunk": "30 Summary \n The ompt_callback_dependences_t type is used for callbacks that are related to \n dependences and that are dispatched when new tasks are generated and when ordered constructs \n are encountered.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef void (*ompt_callback_dependences_t) ( \n ompt_data_t *task_data, \n const ompt_dependence_t *deps, \n int ndeps \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_dependences_t { \n ompt_id_t task_id; \n ompt_dependence_t dep; \n int ndeps; \n } ompt_record_dependences_t; \nC / C++ \n Description of Arguments \n The binding of the task_data argument is the generated task for a depend clause on a task construct, \n the target task for a depend clause on a target construct respectively depend object in an \n asynchronous runtime routine, or the encountering implicit task for a depend clause of the ordered \n construct."}
{"section_title": "19.5.2.8 ompt_callback_dependences_t", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef void (*ompt_callback_dependences_t) ( \n ompt_data_t *task_data, \n const ompt_dependence_t *deps, \n int ndeps \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_dependences_t { \n ompt_id_t task_id; \n ompt_dependence_t dep; \n int ndeps; \n } ompt_record_dependences_t; \nC / C++ \n Description of Arguments \n The binding of the task_data argument is the generated task for a depend clause on a task construct, \n the target task for a depend clause on a target construct respectively depend object in an \n asynchronous runtime routine, or the encountering implicit task for a depend clause of the ordered \n construct.\n The deps argument lists dependences of the new task or the dependence vector of the ordered \n construct.Dependences denoted with depend objects are described in terms of their dependence \n semantics."}
{"section_title": "19.5.2.8 ompt_callback_dependences_t", "chunk": "Dependences denoted with depend objects are described in terms of their dependence \n semantics.\n The ndeps argument specifies the length of the list passed by the deps argument.The memory for \n deps is owned by the caller; the tool cannot rely on the data after the callback returns.\n The performance monitor interface for tracing activity on target devices provides one record per \n dependence.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_dependence_t, see Section 19.4.4.9 \n \u2022 depend clause, see Section 15.9.5 \n \u2022 ordered directive, see Section 15.10.1 \nCHAPTER 19.OMPT INTERFACE 483 \n"}
{"section_title": "19.5.2.9 ompt_callback_task_dependence_t", "chunk": "2 Summary \n The ompt_callback_task_dependence_t type is used for callbacks that are dispatched \n when unfulfilled task dependences are encountered.\n Format \nC / C++ \n typedef void (*ompt_callback_task_dependence_t) ( \n ompt_data_t *src_task_data, \n ompt_data_t *sink_task_data \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_task_dependence_t { \n ompt_id_t src_task_id; \n ompt_id_t sink_task_id; \n } ompt_record_task_dependence_t; \nC / C++ \n Description of Arguments \n The binding of the src_task_data argument is a running task with an outgoing dependence.\n The binding of the sink_task_data argument is a task with an unsatisfied incoming dependence.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 depend clause, see Section 15.9.5 \n"}
{"section_title": "19.5.2.10 ompt_callback_task_schedule_t", "chunk": "22 Summary \n The ompt_callback_task_schedule_t type is used for callbacks that are dispatched when \n task scheduling decisions are made.\n Format \nC / C++ \n typedef void (*ompt_callback_task_schedule_t) ( \n ompt_data_t *prior_task_data, \n ompt_task_status_t prior_task_status, \n ompt_data_t *next_task_data \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Trace Record \nC / C++ \n typedef struct ompt_record_task_schedule_t { \n ompt_id_t prior_task_id; \n ompt_task_status_t prior_task_status; \n ompt_id_t next_task_id; \n } ompt_record_task_schedule_t; \nC / C++ \n Description of Arguments \n The prior_task_status argument indicates the status of the task that arrived at a task scheduling \n point.\n The binding of the prior_task_data argument is the task that arrived at the scheduling point.\n The binding of the next_task_data argument is the task that is resumed at the scheduling point."}
{"section_title": "19.5.2.10 ompt_callback_task_schedule_t", "chunk": "\n The binding of the next_task_data argument is the task that is resumed at the scheduling point.\n This argument is NULL if the callback is dispatched for a task-fulfill event or if the callback signals \n completion of a taskwait construct.\n Cross References \n \u2022 Task Scheduling, see Section 12.9 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_task_status_t, see Section 19.4.4.20 \n"}
{"section_title": "19.5.2.11 ompt_callback_implicit_task_t", "chunk": "19 Summary \n The ompt_callback_implicit_task_t type is used for callbacks that are dispatched when \n initial tasks and implicit tasks are generated and completed.\n Format \nC / C++ \n typedef void (*ompt_callback_implicit_task_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *parallel_data, \n ompt_data_t *task_data, \n unsigned int actual_parallelism, \n unsigned int index, \n int flags \n ); \nC / C++ \nCHAPTER 19.OMPT INTERFACE 485 \n Trace Record \nC / C++ \n typedef struct ompt_record_implicit_task_t { \n ompt_scope_endpoint_t endpoint; \n ompt_id_t parallel_id; \n ompt_id_t task_id; \n unsigned int actual_parallelism; \n unsigned int index; \n int flags; \n } ompt_record_implicit_task_t; \nC / C++ \n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The binding of the parallel_data argument is the current parallel or teams region."}
{"section_title": "19.5.2.11 ompt_callback_implicit_task_t", "chunk": "\n The binding of the parallel_data argument is the current parallel or teams region.For the \n implicit-task-end and the initial-task-end events, this argument is NULL.\n The binding of the task_data argument is the implicit task that executes the structured block of the \n parallel or teams region.\n The actual_parallelism argument indicates the number of threads in the parallel region or the \n number of teams in the teams region.For initial tasks that are not closely nested in a teams \n construct, this argument is 1.For the implicit-task-end and the initial-task-end events, this \n argument is 0.\n The index argument indicates the thread number or team number of the calling thread, within the \n team or league that is executing the parallel or teams region to which the implicit task region \n binds.For initial tasks, that are not created by a teams construct, this argument is 1.\n The flags argument indicates the kind of task (initial or implicit)."}
{"section_title": "19.5.2.11 ompt_callback_implicit_task_t", "chunk": "\n The flags argument indicates the kind of task (initial or implicit).\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 parallel directive, see Section 10.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "19.5.2.12 ompt_callback_masked_t", "chunk": "31 Summary \n The ompt_callback_masked_t type is used for callbacks that are dispatched when masked \n regions start and end.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef void (*ompt_callback_masked_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *parallel_data, \n ompt_data_t *task_data, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_masked_t { \n ompt_scope_endpoint_t endpoint; \n ompt_id_t parallel_id; \n ompt_id_t task_id; \n const void *codeptr_ra; \n } ompt_record_masked_t; \nC / C++ \n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The binding of the parallel_data argument is the current parallel region.\n The binding of the task_data argument is the encountering task.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code."}
{"section_title": "19.5.2.12 ompt_callback_masked_t", "chunk": "\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_masked_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 masked directive, see Section 10.5 \n"}
{"section_title": "19.5.2.13 ompt_callback_sync_region_t", "chunk": "31 Summary \n The ompt_callback_sync_region_t type is used for callbacks that are dispatched when \n barrier regions, taskwait regions, and taskgroup regions begin and end and when waiting \n begins and ends for them as well as for when reductions are performed.\nCHAPTER 19.OMPT INTERFACE 487 \n Format C / C++ \n typedef void (*ompt_callback_sync_region_t) ( \n ompt_sync_region_t kind, \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *parallel_data, \n ompt_data_t *task_data, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_sync_region_t { \n ompt_sync_region_t kind; \n ompt_scope_endpoint_t endpoint; \n ompt_id_t parallel_id; \n ompt_id_t task_id; \n const void *codeptr_ra; \n } ompt_record_sync_region_t; \nC / C++ \n Description of Arguments \n The kind argument indicates the kind of synchronization.\n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope."}
{"section_title": "19.5.2.13 ompt_callback_sync_region_t", "chunk": "\n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The binding of the parallel_data argument is the current parallel region.For the \n implicit-barrier-end event at the end of a parallel region this argument is NULL.For the \n implicit-barrier-wait-begin and implicit-barrier-wait-end event at the end of a parallel region, \n whether this argument is NULL or points to the parallel data of the current parallel region is \n implementation defined.\n The binding of the task_data argument is the current task.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_sync_region_t then codeptr_ra contains the return address of the call to \n that runtime routine."}
{"section_title": "19.5.2.13 ompt_callback_sync_region_t", "chunk": "If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_sync_region_t then codeptr_ra contains the return address of the call to \n that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Implicit Barriers, see Section 15.3.2 \n \u2022 Properties Common to All Reduction Clauses, see Section 5.5.5 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_sync_region_t, see Section 19.4.4.14 \n \u2022 barrier directive, see Section 15.3.1 \n \u2022 taskgroup directive, see Section 15.4 \n \u2022 taskwait directive, see Section 15.5 \n"}
{"section_title": "19.5.2.14 ompt_callback_mutex_acquire_t", "chunk": "11 Summary \n The ompt_callback_mutex_acquire_t type is used for callbacks that are dispatched when \n locks are initialized, acquired and tested and when critical regions, atomic regions, and \n ordered regions are begun.\n Format \nC / C++ \n typedef void (*ompt_callback_mutex_acquire_t) ( \n ompt_mutex_t kind, \n unsigned int hint, \n unsigned int impl, \n ompt_wait_id_t wait_id, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_mutex_acquire_t { \n ompt_mutex_t kind; \n unsigned int hint; \n unsigned int impl; \n ompt_wait_id_t wait_id; \n const void *codeptr_ra; \n } ompt_record_mutex_acquire_t; \nC / C++ \nCHAPTER 19.OMPT INTERFACE 489 \n Description of Arguments \n The kind argument indicates the kind of mutual exclusion event.\n The hint argument indicates the hint that was provided when initializing an implementation of \n mutual exclusion."}
{"section_title": "19.5.2.14 ompt_callback_mutex_acquire_t", "chunk": "\n The hint argument indicates the hint that was provided when initializing an implementation of \n mutual exclusion.If no hint is available when a thread initiates acquisition of mutual exclusion, the \n runtime may supply omp_sync_hint_none as the value for hint.\n The impl argument indicates the mechanism chosen by the runtime to implement the mutual \n exclusion.\n The wait_id argument indicates the object being awaited.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_mutex_acquire_t then codeptr_ra contains the return address of the call \n to that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL."}
{"section_title": "19.5.2.14 ompt_callback_mutex_acquire_t", "chunk": "If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n Cross References \n \u2022 omp_init_lock and omp_init_nest_lock, see Section 18.9.1 \n \u2022 ompt_mutex_t, see Section 19.4.4.17 \n \u2022 ordered Construct, see Section 15.10 \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 critical directive, see Section 15.2 \n \u2022 ompt_wait_id_t, see Section 19.4.4.31 \n"}
{"section_title": "19.5.2.15 ompt_callback_mutex_t", "chunk": "23 Summary \n The ompt_callback_mutex_t type is used for callbacks that indicate important \n synchronization events.\n Format \nC / C++ \n typedef void (*ompt_callback_mutex_t) ( \n ompt_mutex_t kind, \n ompt_wait_id_t wait_id, \n const void *codeptr_ra \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Trace Record \nC / C++ \n typedef struct ompt_record_mutex_t { \n ompt_mutex_t kind; \n ompt_wait_id_t wait_id; \n const void *codeptr_ra; \n } ompt_record_mutex_t; \nC / C++ \n Description of Arguments \n The kind argument indicates the kind of mutual exclusion event.\n The wait_id argument indicates the object being awaited.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_mutex_t then codeptr_ra contains the return address of the call to that \n runtime routine."}
{"section_title": "19.5.2.15 ompt_callback_mutex_t", "chunk": "If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_mutex_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 omp_set_lock and omp_set_nest_lock, see Section 18.9.4 \n \u2022 omp_test_lock and omp_test_nest_lock, see Section 18.9.6 \n \u2022 omp_unset_lock and omp_unset_nest_lock, see Section 18.9.5 \n \u2022 ompt_mutex_t, see Section 19.4.4.17 \n \u2022 ordered Construct, see Section 15.10 \n \u2022 atomic directive, see Section 15.8.4 \n \u2022 critical directive, see Section 15.2 \n \u2022 omp_destroy_lock and omp_destroy_nest_lock, see Section 18.9.3 \n \u2022 ompt_wait_id_t, see Section 19.4.4.31 \n"}
{"section_title": "19.5.2.16 ompt_callback_nest_lock_t", "chunk": "27 Summary \n The ompt_callback_nest_lock_t type is used for callbacks that indicate that a thread that \n owns a nested lock has performed an action related to the lock but has not relinquished ownership.\nCHAPTER 19.OMPT INTERFACE 491 \n Format \nC / C++ \n typedef void (*ompt_callback_nest_lock_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_wait_id_t wait_id, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_nest_lock_t { \n ompt_scope_endpoint_t endpoint; \n ompt_wait_id_t wait_id; \n const void *codeptr_ra; \n } ompt_record_nest_lock_t; \nC / C++ \n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The wait_id argument indicates the object being awaited.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code."}
{"section_title": "19.5.2.16 ompt_callback_nest_lock_t", "chunk": "\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_nest_lock_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 omp_set_lock and omp_set_nest_lock, see Section 18.9.4 \n \u2022 omp_test_lock and omp_test_nest_lock, see Section 18.9.6 \n \u2022 omp_unset_lock and omp_unset_nest_lock, see Section 18.9.5 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_wait_id_t, see Section 19.4.4.31 \n"}
{"section_title": "19.5.2.17 ompt_callback_flush_t", "chunk": "30 Summary \n The ompt_callback_flush_t type is used for callbacks that are dispatched when flush \n constructs are encountered.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef void (*ompt_callback_flush_t) ( \n ompt_data_t *thread_data, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_flush_t { \n const void *codeptr_ra; \n } ompt_record_flush_t; \nC / C++ \n Description of Arguments \n The binding of the thread_data argument is the executing thread.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_flush_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation."}
{"section_title": "19.5.2.17 ompt_callback_flush_t", "chunk": "If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 flush directive, see Section 15.8.5 \n"}
{"section_title": "19.5.2.18 ompt_callback_cancel_t", "chunk": "22 Summary \n The ompt_callback_cancel_t type is used for callbacks that are dispatched for cancellation, \n cancel and discarded-task events.\n Format \nC / C++ \n typedef void (*ompt_callback_cancel_t) ( \n ompt_data_t *task_data, \n int flags, \n const void *codeptr_ra \n ); \nC / C++ \nCHAPTER 19.OMPT INTERFACE 493 \n Trace Record \nC / C++ \n typedef struct ompt_record_cancel_t { \n ompt_id_t task_id; \n int flags; \n const void *codeptr_ra; \n } ompt_record_cancel_t; \nC / C++ \n Description of Arguments \n The binding of the task_data argument is the task that encounters a cancel construct, a \n cancellation point construct, or a construct defined as having an implicit cancellation \n point.\n The flags argument, defined by the ompt_cancel_flag_t enumeration type, indicates whether \n cancellation is activated by the current task or detected as being activated by another task.The \n construct that is being canceled is also described in the flags argument."}
{"section_title": "19.5.2.18 ompt_callback_cancel_t", "chunk": "The \n construct that is being canceled is also described in the flags argument.When several constructs are \n detected as being concurrently canceled, each corresponding bit in the argument will be set.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_cancel_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_cancel_flag_t, see Section 19.4.4.26 \n"}
{"section_title": "19.5.2.19 ompt_callback_device_initialize_t", "chunk": "24 Summary \n The ompt_callback_device_initialize_t type is used for callbacks that initialize \n device tracing interfaces.\n Format \nC / C++ \n typedef void (*ompt_callback_device_initialize_t) ( \n int device_num, \n const char *type, \n ompt_device_t *device, \n ompt_function_lookup_t lookup, \n const char *documentation \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n Registration of a callback with type signature ompt_callback_device_initialize_t for \n the ompt_callback_device_initialize event enables asynchronous collection of a trace \n for a device.The OpenMP implementation invokes this callback after OpenMP is initialized for the \n device but before execution of any OpenMP construct is started on the device.\n Description of Arguments \n The device_num argument identifies the logical device that is being initialized.\n The type argument is a C string that indicates the type of the device."}
{"section_title": "19.5.2.19 ompt_callback_device_initialize_t", "chunk": "\n The type argument is a C string that indicates the type of the device.A device type string is a \n semicolon-separated character string that includes, at a minimum, the vendor and model name of \n the device.These names may be followed by a semicolon-separated sequence of properties that \n describe the hardware or software of the device.\n The device argument is a pointer to an opaque object that represents the target device instance.\n Functions in the device tracing interface use this pointer to identify the device that is being \n addressed.\n The lookup argument points to a runtime callback that a tool must use to obtain pointers to runtime \n entry points in the device\u2019s OMPT tracing interface.If a device does not support tracing then \n lookup is NULL.\n The documentation argument is a C string that describes how to use any device-specific runtime \n entry points that can be obtained through the lookup argument."}
{"section_title": "19.5.2.19 ompt_callback_device_initialize_t", "chunk": "\n The documentation argument is a C string that describes how to use any device-specific runtime \n entry points that can be obtained through the lookup argument.This documentation string may be a \n pointer to external documentation, or it may be inline descriptions that include names and type \n signatures for any device-specific interfaces that are available through the lookup argument along \n with descriptions of how to use these interface functions to control monitoring and analysis of \n device traces.\n Constraints on Arguments \n The type and documentation arguments must be immutable strings that are defined for the lifetime \n of program execution.\n Effect \n A device initializer must fulfill several duties.First, the type argument should be used to determine \n if any special knowledge about the hardware and/or software of a device is employed."}
{"section_title": "19.5.2.19 ompt_callback_device_initialize_t", "chunk": "First, the type argument should be used to determine \n if any special knowledge about the hardware and/or software of a device is employed.Second, the \n lookup argument should be used to look up pointers to runtime entry points in the OMPT tracing \n interface for the device.Finally, these runtime entry points should be used to set up tracing for the \n device.Initialization of tracing for a target device is described in Section 19.2.5.\n Cross References \n \u2022 Lookup Entry Points: ompt_function_lookup_t, see Section 19.6.3 \nCHAPTER 19.OMPT INTERFACE 495 \n"}
{"section_title": "19.5.2.20 ompt_callback_device_finalize_t", "chunk": "2 Summary \n The ompt_callback_device_initialize_t type is used for callbacks that finalize device \n tracing interfaces.\n Format \nC / C++ \n typedef void (*ompt_callback_device_finalize_t) ( \n int device_num \n ); \nC / C++ \n Description of Arguments \n The device_num argument identifies the logical device that is being finalized.\n Semantics \n A registered callback with type signature ompt_callback_device_finalize_t is \n dispatched for a device immediately prior to finalizing the device.Prior to dispatching a finalization \n callback for a device on which tracing is active, the OpenMP implementation stops tracing on the \n device and synchronously flushes all trace records for the device that have not yet been reported.\n These trace records are flushed through one or more buffer completion callbacks with type \n signature ompt_callback_buffer_complete_t as needed prior to the dispatch of the \n callback with type signature ompt_callback_device_finalize_t."}
{"section_title": "19.5.2.20 ompt_callback_device_finalize_t", "chunk": "\n These trace records are flushed through one or more buffer completion callbacks with type \n signature ompt_callback_buffer_complete_t as needed prior to the dispatch of the \n callback with type signature ompt_callback_device_finalize_t.\n Cross References \n \u2022 ompt_callback_buffer_complete_t, see Section 19.5.2.24 \n"}
{"section_title": "19.5.2.21 ompt_callback_device_load_t", "chunk": "22 Summary \n The ompt_callback_device_load_t type is used for callbacks that the OpenMP runtime \n invokes to indicate that it has just loaded code onto the specified device.\n Format \nC / C++ \n typedef void (*ompt_callback_device_load_t) ( \n int device_num, \n const char *filename, \n int64_t offset_in_file, \n void *vma_in_file, \n size_t bytes, \n void *host_addr, \n void *device_addr, \n uint64_t module_id \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The device_num argument specifies the device.\n The filename argument indicates the name of a file in which the device code can be found.A NULL \n filename indicates that the code is not available in a file in the file system.\n The offset_in_file argument indicates an offset into filename at which the code can be found.A \n value of -1 indicates that no offset is provided.\n ompt_addr_none is defined as a pointer with the value ~0."}
{"section_title": "19.5.2.21 ompt_callback_device_load_t", "chunk": "\n ompt_addr_none is defined as a pointer with the value ~0.\n The vma_in_file argument indicates a virtual address in filename at which the code can be found.A \n value of ompt_addr_none indicates that a virtual address in the file is not available.\n The bytes argument indicates the size of the device code object in bytes.\n The host_addr argument indicates the address at which a copy of the device code is available in \n host memory.A value of ompt_addr_none indicates that a host code address is not available.\n The device_addr argument indicates the address at which the device code has been loaded in device \n memory.A value of ompt_addr_none indicates that a device code address is not available.\n The module_id argument is an identifier that is associated with the device code object.\n Cross References \n \u2022 Device Directives and Clauses, see Chapter 13 \n"}
{"section_title": "19.5.2.22 ompt_callback_device_unload_t", "chunk": "19 Summary \n The ompt_callback_device_unload_t type is used for callbacks that the OpenMP \n runtime invokes to indicate that it is about to unload code from the specified device.\n Format \nC / C++ \n typedef void (*ompt_callback_device_unload_t) ( \n int device_num, \n uint64_t module_id \n ); \nC / C++ \n Description of Arguments \n The device_num argument specifies the device.\n The module_id argument is an identifier that is associated with the device code object.\n Cross References \n \u2022 Device Directives and Clauses, see Chapter 13 \nCHAPTER 19.OMPT INTERFACE 497 \n"}
{"section_title": "19.5.2.23 ompt_callback_buffer_request_t", "chunk": "2 Summary \n The ompt_callback_buffer_request_t type is used for callbacks that are dispatched \n when a buffer to store event records for a device is requested.\n Format \nC / C++ \n typedef void (*ompt_callback_buffer_request_t) ( \n int device_num, \n ompt_buffer_t **buffer, \n size_t *bytes \n ); \nC / C++ \n Semantics \n A callback with type signature ompt_callback_buffer_request_t requests a buffer to \n store trace records for the specified device.A buffer request callback may set *bytes to 0 if it does \n not provide a buffer.If a callback sets *bytes to 0, further recording of events for the device is \n disabled until the next invocation of ompt_start_trace.This action causes the device to drop \n future trace records until recording is restarted.\n Description of Arguments \n The device_num argument specifies the device.\n The *buffer argument points to a buffer where device events may be recorded.The *bytes argument \n indicates the length of that buffer."}
{"section_title": "19.5.2.23 ompt_callback_buffer_request_t", "chunk": "The *bytes argument \n indicates the length of that buffer.\n Cross References \n \u2022 ompt_buffer_t, see Section 19.4.4.7 \n"}
{"section_title": "19.5.2.24 ompt_callback_buffer_complete_t", "chunk": "24 Summary \n The ompt_callback_buffer_complete_t type is used for callbacks that are dispatched \n when devices will not record any more trace records in an event buffer and all records written to the \n buffer are valid.\n Format \nC / C++ \n typedef void (*ompt_callback_buffer_complete_t) ( \n int device_num, \n ompt_buffer_t *buffer, \n size_t bytes, \n ompt_buffer_cursor_t begin, \n int buffer_owned \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n A callback with type signature ompt_callback_buffer_complete_t provides a buffer that \n contains trace records for the specified device.Typically, a tool will iterate through the records in \n the buffer and process them.The OpenMP implementation makes these callbacks on a thread that \n is not an OpenMP primary or worker thread.The callee may not delete the buffer if the \n buffer_owned argument is 0.The buffer completion callback is not required to be async signal safe."}
{"section_title": "19.5.2.24 ompt_callback_buffer_complete_t", "chunk": "The buffer completion callback is not required to be async signal safe.\n Description of Arguments \n The device_num argument indicates the device for which the buffer contains events.\n The buffer argument is the address of a buffer that was previously allocated by a buffer request \n callback.\n The bytes argument indicates the full size of the buffer.\n The begin argument is an opaque cursor that indicates the position of the beginning of the first \n record in the buffer.\n The buffer_owned argument is 1 if the data to which the buffer points can be deleted by the callback \n and 0 otherwise.If multiple devices accumulate trace events into a single buffer, this callback may \n be invoked with a pointer to one or more trace records in a shared buffer with buffer_owned = 0.In \n this case, the callback may not delete the buffer.\n Cross References \n \u2022 ompt_buffer_cursor_t, see Section 19.4.4.8 \n \u2022 ompt_buffer_t, see Section 19.4.4.7 \n"}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "22 ompt_callback_target_data_op_t \n Summary \n The ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t types are used for callbacks that are dispatched when \n a thread maps data to a device.\n Format \nC / C++ \n typedef void (*ompt_callback_target_data_op_emi_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *target_task_data, \n ompt_data_t *target_data, \n ompt_id_t *host_op_id, \n ompt_target_data_op_t optype, \n void *src_addr, \n int src_device_num, \nCHAPTER 19."}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "\n Format \nC / C++ \n typedef void (*ompt_callback_target_data_op_emi_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *target_task_data, \n ompt_data_t *target_data, \n ompt_id_t *host_op_id, \n ompt_target_data_op_t optype, \n void *src_addr, \n int src_device_num, \nCHAPTER 19.OMPT INTERFACE 499 \n void *dest_addr, \n int dest_device_num, \n size_t bytes, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_data_op_t) ( \n ompt_id_t target_id, \n ompt_id_t host_op_id, \n ompt_target_data_op_t optype, \n void *src_addr, \n int src_device_num, \n void *dest_addr, \n int dest_device_num, \n size_t bytes, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_data_op_t { \n ompt_id_t host_op_id; \n ompt_target_data_op_t optype; \n void *src_addr; \n int src_device_num; \n void *dest_addr; \n int dest_device_num; \n size_t bytes; \n ompt_device_time_t end_time; \n const void *codeptr_ra; \n } ompt_record_target_data_op_t; \nC / C++ \n Semantics \n A thread dispatches a registered ompt_callback_target_data_op_emi or \n ompt_callback_target_data_op callback when device memory is allocated or freed, as \n well as when data is copied to or from a device."}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "OMPT INTERFACE 499 \n void *dest_addr, \n int dest_device_num, \n size_t bytes, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_data_op_t) ( \n ompt_id_t target_id, \n ompt_id_t host_op_id, \n ompt_target_data_op_t optype, \n void *src_addr, \n int src_device_num, \n void *dest_addr, \n int dest_device_num, \n size_t bytes, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_data_op_t { \n ompt_id_t host_op_id; \n ompt_target_data_op_t optype; \n void *src_addr; \n int src_device_num; \n void *dest_addr; \n int dest_device_num; \n size_t bytes; \n ompt_device_time_t end_time; \n const void *codeptr_ra; \n } ompt_record_target_data_op_t; \nC / C++ \n Semantics \n A thread dispatches a registered ompt_callback_target_data_op_emi or \n ompt_callback_target_data_op callback when device memory is allocated or freed, as \n well as when data is copied to or from a device.\n \n Note \u2013 An OpenMP implementation may aggregate program variables and data operations upon \n them."}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "\n \n Note \u2013 An OpenMP implementation may aggregate program variables and data operations upon \n them.For instance, an OpenMP implementation may synthesize a composite to represent multiple \n scalars and then allocate, free, or copy this composite as a whole rather than performing data \n operations on each scalar individually.Thus, callbacks may not be dispatched as separate data \n operations on each variable.\n \n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning or end of a scope.\n The binding of the target_task_data argument is the target task region.\n The binding of the target_data argument is the target region.\n The host_op_id argument points to a tool-controlled integer value, which identifies a data operation \n on a target device.\n The optype argument indicates the kind of data operation."}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "\n The optype argument indicates the kind of data operation.\n The src_addr argument indicates the data address before the operation, where applicable.\n The src_device_num argument indicates the source device number for the data operation, where \n applicable.\n The dest_addr argument indicates the data address after the operation.\n The dest_device_num argument indicates the destination device number for the data operation.\n Whether in some operations src_addr or dest_addr may point to an intermediate buffer is \n implementation defined.\n The bytes argument indicates the size of data.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_target_data_op_emi_t or ompt_callback_target_data_op_t \n then codeptr_ra contains the return address of the call to that runtime routine."}
{"section_title": "19.5.2.25 ompt_callback_target_data_op_emi_t and ompt_callback_target_data_op_t", "chunk": "If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_target_data_op_emi_t or ompt_callback_target_data_op_t \n then codeptr_ra contains the return address of the call to that runtime routine.If the \n implementation of the region is inlined then codeptr_ra contains the return address of the callback \n invocation.If attribution to source code is impossible or inappropriate, codeptr_ra may be NULL.\n Restrictions \n Restrictions to the ompt_callback_target_data_op_emi and \n ompt_callback_target_data_op callbacks are as follows: \n \u2022 These callbacks must not be registered at the same time.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_target_data_op_t, see Section 19.4.4.15 \n \u2022 map clause, see Section 5.8.3 \nCHAPTER 19.OMPT INTERFACE 501 \n"}
{"section_title": "19.5.2.26 ompt_callback_target_emi_t and ompt_callback_target_t", "chunk": "2 ompt_callback_target_t \n Summary \n The ompt_callback_target_emi_t and ompt_callback_target_t types are used \n for callbacks that are dispatched when a thread begins to execute a device construct."}
{"section_title": "19.5.2.26 ompt_callback_target_emi_t and ompt_callback_target_t", "chunk": "2 ompt_callback_target_t \n Summary \n The ompt_callback_target_emi_t and ompt_callback_target_t types are used \n for callbacks that are dispatched when a thread begins to execute a device construct.\n Format \nC / C++ \n typedef void (*ompt_callback_target_emi_t) ( \n ompt_target_t kind, \n ompt_scope_endpoint_t endpoint, \n int device_num, \n ompt_data_t *task_data, \n ompt_data_t *target_task_data, \n ompt_data_t *target_data, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_t) ( \n ompt_target_t kind, \n ompt_scope_endpoint_t endpoint, \n int device_num, \n ompt_data_t *task_data, \n ompt_id_t target_id, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_t { \n ompt_target_t kind; \n ompt_scope_endpoint_t endpoint; \n int device_num; \n ompt_id_t task_id; \n ompt_id_t target_id; \n const void *codeptr_ra; \n } ompt_record_target_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The kind argument indicates the kind of target region."}
{"section_title": "19.5.2.26 ompt_callback_target_emi_t and ompt_callback_target_t", "chunk": "\n Format \nC / C++ \n typedef void (*ompt_callback_target_emi_t) ( \n ompt_target_t kind, \n ompt_scope_endpoint_t endpoint, \n int device_num, \n ompt_data_t *task_data, \n ompt_data_t *target_task_data, \n ompt_data_t *target_data, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_t) ( \n ompt_target_t kind, \n ompt_scope_endpoint_t endpoint, \n int device_num, \n ompt_data_t *task_data, \n ompt_id_t target_id, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_t { \n ompt_target_t kind; \n ompt_scope_endpoint_t endpoint; \n int device_num; \n ompt_id_t task_id; \n ompt_id_t target_id; \n const void *codeptr_ra; \n } ompt_record_target_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The kind argument indicates the kind of target region.\n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope."}
{"section_title": "19.5.2.26 ompt_callback_target_emi_t and ompt_callback_target_t", "chunk": "\n The endpoint argument indicates that the callback signals the beginning of a scope or the end of a \n scope.\n The device_num argument indicates the device number of the device that will execute the target \n region.\n The binding of the task_data argument is the encountering task.\n The binding of the target_task_data argument is the target task region.If a target region has no \n target task or if the target task is merged, this argument is NULL.\n The binding of the target_data argument is the target region.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_target_emi_t or ompt_callback_target_t then codeptr_ra \n contains the return address of the call to that runtime routine.If the implementation of the region is \n inlined then codeptr_ra contains the return address of the callback invocation."}
{"section_title": "19.5.2.26 ompt_callback_target_emi_t and ompt_callback_target_t", "chunk": "If the implementation of the region is \n inlined then codeptr_ra contains the return address of the callback invocation.If attribution to \n source code is impossible or inappropriate, codeptr_ra may be NULL.\n Restrictions \n Restrictions to the ompt_callback_target_emi and ompt_callback_target callbacks \n are as follows: \n \u2022 These callbacks must not be registered at the same time.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 ompt_target_t, see Section 19.4.4.21 \n \u2022 target data directive, see Section 13.5 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n \u2022 target update directive, see Section 13.9 \nCHAPTER 19.OMPT INTERFACE 503 \n"}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "2 ompt_callback_target_map_t \n Summary \n The ompt_callback_target_map_emi_t and ompt_callback_target_map_t types \n are used for callbacks that are dispatched to indicate data mapping relationships."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "2 ompt_callback_target_map_t \n Summary \n The ompt_callback_target_map_emi_t and ompt_callback_target_map_t types \n are used for callbacks that are dispatched to indicate data mapping relationships.\n Format \nC / C++ \n typedef void (*ompt_callback_target_map_emi_t) ( \n ompt_data_t *target_data, \n unsigned int nitems, \n void **host_addr, \n void **device_addr, \n size_t *bytes, \n unsigned int *mapping_flags, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_map_t) ( \n ompt_id_t target_id, \n unsigned int nitems, \n void **host_addr, \n void **device_addr, \n size_t *bytes, \n unsigned int *mapping_flags, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_map_t { \n ompt_id_t target_id; \n unsigned int nitems; \n void **host_addr; \n void **device_addr; \n size_t *bytes; \n unsigned int *mapping_flags; \n const void *codeptr_ra; \n } ompt_record_target_map_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n An instance of a target, target data, target enter data, or target exit data \n construct may contain one or more map clauses."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "\n Format \nC / C++ \n typedef void (*ompt_callback_target_map_emi_t) ( \n ompt_data_t *target_data, \n unsigned int nitems, \n void **host_addr, \n void **device_addr, \n size_t *bytes, \n unsigned int *mapping_flags, \n const void *codeptr_ra \n ); \n typedef void (*ompt_callback_target_map_t) ( \n ompt_id_t target_id, \n unsigned int nitems, \n void **host_addr, \n void **device_addr, \n size_t *bytes, \n unsigned int *mapping_flags, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_map_t { \n ompt_id_t target_id; \n unsigned int nitems; \n void **host_addr; \n void **device_addr; \n size_t *bytes; \n unsigned int *mapping_flags; \n const void *codeptr_ra; \n } ompt_record_target_map_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n An instance of a target, target data, target enter data, or target exit data \n construct may contain one or more map clauses.An OpenMP implementation may report the set of \n mappings associated with map clauses for a construct with a single \n ompt_callback_target_map_emi or ompt_callback_target_map callback to report \n the effect of all mappings or multiple ompt_callback_target_map_emi or \n ompt_callback_target_map callbacks with each reporting a subset of the mappings."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "An OpenMP implementation may report the set of \n mappings associated with map clauses for a construct with a single \n ompt_callback_target_map_emi or ompt_callback_target_map callback to report \n the effect of all mappings or multiple ompt_callback_target_map_emi or \n ompt_callback_target_map callbacks with each reporting a subset of the mappings.\n Furthermore, an OpenMP implementation may omit mappings that it determines are unnecessary.\n If an OpenMP implementation issues multiple ompt_callback_target_map_emi or \n ompt_callback_target_map callbacks, these callbacks may be interleaved with \n ompt_callback_target_data_op_emi or ompt_callback_target_data_op \n callbacks used to report data operations associated with the mappings.\n Description of Arguments \n The binding of the target_data argument is the target region.\n The nitems argument indicates the number of data mappings that this callback reports."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "\n The nitems argument indicates the number of data mappings that this callback reports.\n The host_addr argument indicates an array of host data addresses.\n The device_addr argument indicates an array of device data addresses.\n The bytes argument indicates an array of sizes of data.\n The mapping_flags argument indicates the kind of mapping operations, which may result from \n explicit map clauses or the implicit data-mapping rules defined in Section 5.8.Flags for the \n mapping operations include one or more values specified by the ompt_target_map_flag_t \n type.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_target_map_t or ompt_callback_target_map_emi_t then \n codeptr_ra contains the return address of the call to that runtime routine."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_target_map_t or ompt_callback_target_map_emi_t then \n codeptr_ra contains the return address of the call to that runtime routine.If the implementation of \n the region is inlined then codeptr_ra contains the return address of the callback invocation.If \n attribution to source code is impossible or inappropriate, codeptr_ra may be NULL.\n Restrictions \n Restrictions to the ompt_callback_target_data_map_emi and \n ompt_callback_target_data_map callbacks are as follows: \n \u2022 These callbacks must not be registered at the same time.\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \nCHAPTER 19."}
{"section_title": "19.5.2.27 ompt_callback_target_map_emi_t and ompt_callback_target_map_t", "chunk": "\n Cross References \n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t, see Section 19.5.2.25 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \nCHAPTER 19.OMPT INTERFACE 505 \n \u2022 ompt_target_map_flag_t, see Section 19.4.4.23 \n \u2022 target data directive, see Section 13.5 \n \u2022 target directive, see Section 13.8 \n \u2022 target enter data directive, see Section 13.6 \n \u2022 target exit data directive, see Section 13.7 \n"}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "7 ompt_callback_target_submit_t \n Summary \n The ompt_callback_target_submit_emi_t and \n ompt_callback_target_submit_t types are used for callbacks that are dispatched before \n and after the host initiates creation of an initial task on a device."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "7 ompt_callback_target_submit_t \n Summary \n The ompt_callback_target_submit_emi_t and \n ompt_callback_target_submit_t types are used for callbacks that are dispatched before \n and after the host initiates creation of an initial task on a device.\n Format \nC / C++ \n typedef void (*ompt_callback_target_submit_emi_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *target_data, \n ompt_id_t *host_op_id, \n unsigned int requested_num_teams \n ); \n typedef void (*ompt_callback_target_submit_t) ( \n ompt_id_t target_id, \n ompt_id_t host_op_id, \n unsigned int requested_num_teams \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_kernel_t { \n ompt_id_t host_op_id; \n unsigned int requested_num_teams; \n unsigned int granted_num_teams; \n ompt_device_time_t end_time; \n } ompt_record_target_kernel_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n A thread dispatches a registered ompt_callback_target_submit_emi or \n ompt_callback_target_submit callback on the host before and after a target task initiates \n creation of an initial task on a device."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "\n Format \nC / C++ \n typedef void (*ompt_callback_target_submit_emi_t) ( \n ompt_scope_endpoint_t endpoint, \n ompt_data_t *target_data, \n ompt_id_t *host_op_id, \n unsigned int requested_num_teams \n ); \n typedef void (*ompt_callback_target_submit_t) ( \n ompt_id_t target_id, \n ompt_id_t host_op_id, \n unsigned int requested_num_teams \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_target_kernel_t { \n ompt_id_t host_op_id; \n unsigned int requested_num_teams; \n unsigned int granted_num_teams; \n ompt_device_time_t end_time; \n } ompt_record_target_kernel_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n A thread dispatches a registered ompt_callback_target_submit_emi or \n ompt_callback_target_submit callback on the host before and after a target task initiates \n creation of an initial task on a device.\n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning or end of a scope."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "\n Description of Arguments \n The endpoint argument indicates that the callback signals the beginning or end of a scope.\n The binding of the target_data argument is the target region.\n The host_op_id argument points to a tool-controlled integer value, which identifies an initial task \n on a target device.\n The requested_num_teams argument is the number of teams that the host requested to execute the \n kernel.The actual number of teams that execute the kernel may be smaller and generally will not be \n known until the kernel begins to execute on the device.\n If ompt_set_trace_ompt has configured the device to trace kernel execution then the device \n will log a ompt_record_target_kernel_t record in a trace."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "\n If ompt_set_trace_ompt has configured the device to trace kernel execution then the device \n will log a ompt_record_target_kernel_t record in a trace.The fields in the record are as \n follows: \n \u2022 The host_op_id field contains a tool-controlled identifier that can be used to correlate a \n ompt_record_target_kernel_t record with its associated \n ompt_callback_target_submit_emi or ompt_callback_target_submit \n callback on the host; \n \u2022 The requested_num_teams field contains the number of teams that the host requested to execute \n the kernel; \n \u2022 The granted_num_teams field contains the number of teams that the device actually used to \n execute the kernel; \n \u2022 The time when the initial task began execution on the device is recorded in the time field of an \n enclosing ompt_record_t structure; and \n \u2022 The time when the initial task completed execution on the device is recorded in the end_time \n field."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "The fields in the record are as \n follows: \n \u2022 The host_op_id field contains a tool-controlled identifier that can be used to correlate a \n ompt_record_target_kernel_t record with its associated \n ompt_callback_target_submit_emi or ompt_callback_target_submit \n callback on the host; \n \u2022 The requested_num_teams field contains the number of teams that the host requested to execute \n the kernel; \n \u2022 The granted_num_teams field contains the number of teams that the device actually used to \n execute the kernel; \n \u2022 The time when the initial task began execution on the device is recorded in the time field of an \n enclosing ompt_record_t structure; and \n \u2022 The time when the initial task completed execution on the device is recorded in the end_time \n field.\n Restrictions \n Restrictions to the ompt_callback_target_submit_emi and \n ompt_callback_target_submit callbacks are as follows: \n \u2022 These callbacks must not be registered at the same time."}
{"section_title": "19.5.2.28 ompt_callback_target_submit_emi_t and ompt_callback_target_submit_t", "chunk": "\n Restrictions \n Restrictions to the ompt_callback_target_submit_emi and \n ompt_callback_target_submit callbacks are as follows: \n \u2022 These callbacks must not be registered at the same time.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_id_t, see Section 19.4.4.3 \n \u2022 ompt_scope_endpoint_t, see Section 19.4.4.11 \n \u2022 target directive, see Section 13.8 \nCHAPTER 19.OMPT INTERFACE 507 \n"}
{"section_title": "19.5.2.29 ompt_callback_control_tool_t", "chunk": "2 Summary \n The ompt_callback_control_tool_t type is used for callbacks that dispatch tool-control \n events.\n Format \nC / C++ \n typedef int (*ompt_callback_control_tool_t) ( \n uint64_t command, \n uint64_t modifier, \n void *arg, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_control_tool_t { \n uint64_t command; \n uint64_t modifier; \n const void *codeptr_ra; \n } ompt_record_control_tool_t; \nC / C++ \n Semantics \n Callbacks with type signature ompt_callback_control_tool_t may return any \n non-negative value, which will be returned to the application as the return value of the \n omp_control_tool call that triggered the callback.\n Description of Arguments \n The command argument passes a command from an application to a tool.Standard values for \n command are defined by omp_control_tool_t in Section 18.14.\n The modifier argument passes a command modifier from an application to a tool."}
{"section_title": "19.5.2.29 ompt_callback_control_tool_t", "chunk": "\n The modifier argument passes a command modifier from an application to a tool.\n The command and modifier arguments may have tool-specific values.Tools must ignore command \n values that they are not designed to handle.\n The arg argument is a void pointer that enables a tool and an application to exchange arbitrary state.\n The arg argument may be NULL.\n OpenMP API \u2013 Version 5.2 November 2021 \n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_control_tool_t then codeptr_ra contains the return address of the call to \n that runtime routine.If the implementation of the region is inlined then codeptr_ra contains the \n return address of the callback invocation.If attribution to source code is impossible or \n inappropriate, codeptr_ra may be NULL.\n Constraints on Arguments \n Tool-specific values for command must be \u2265 64."}
{"section_title": "19.5.2.29 ompt_callback_control_tool_t", "chunk": "\n Constraints on Arguments \n Tool-specific values for command must be \u2265 64.\n Cross References \n \u2022 Tool Control Routine, see Section 18.14 \n"}
{"section_title": "19.5.2.30 ompt_callback_error_t", "chunk": "12 Summary \n The ompt_callback_error_t type is used for callbacks that dispatch runtime-error events.\n Format \nC / C++ \n typedef void (*ompt_callback_error_t) ( \n ompt_severity_t severity, \n const char *message, \n size_t length, \n const void *codeptr_ra \n ); \nC / C++ \n Trace Record \nC / C++ \n typedef struct ompt_record_error_t { \n ompt_severity_t severity; \n const char *message; \n size_t length; \n const void *codeptr_ra; \n } ompt_record_error_t; \nC / C++ \n Semantics \n A thread dispatches a registered ompt_callback_error_t callback when an error directive \n is encountered for which the at(execution) clause is specified.\nCHAPTER 19.OMPT INTERFACE 509 \n Description of Arguments \n The severity argument passes the specified severity level.\n The message argument passes the C string from the message clause.\n The length argument provides the length of the C string."}
{"section_title": "19.5.2.30 ompt_callback_error_t", "chunk": "\n The length argument provides the length of the C string.\n The codeptr_ra argument relates the implementation of an OpenMP region to its source code.If a \n runtime routine implements the region associated with a callback that has type signature \n ompt_callback_error_t then codeptr_ra contains the return address of the call to that \n runtime routine.If the implementation of the region is inlined then codeptr_ra contains the return \n address of the callback invocation.If attribution to source code is impossible or inappropriate, \n codeptr_ra may be NULL.\n Cross References \n \u2022 ompt_severity_t, see Section 19.4.4.25 \n \u2022 error directive, see Section 8.5 \n"}
{"section_title": "19.6 OMPT Runtime Entry Points for Tools", "chunk": "15 OMPT supports two principal sets of runtime entry points for tools.One set of runtime entry points \n enables a tool to register callbacks for OpenMP events and to inspect the state of an OpenMP thread \n while executing in a tool callback or a signal handler.The second set of runtime entry points \n enables a tool to trace activities on a device.When directed by the tracing interface, an OpenMP \n implementation will trace activities on a device, collect buffers of trace records, and invoke \n callbacks on the host to process these records.OMPT runtime entry points should not be global \n symbols since tools cannot rely on the visibility of such symbols.\n OMPT also supports runtime entry points for two classes of lookup routines.The first class of \n lookup routines contains a single member: a routine that returns runtime entry points in the OMPT \n callback interface."}
{"section_title": "19.6 OMPT Runtime Entry Points for Tools", "chunk": "The first class of \n lookup routines contains a single member: a routine that returns runtime entry points in the OMPT \n callback interface.The second class of lookup routines includes a unique lookup routine for each \n kind of device that can return runtime entry points in a device\u2019s OMPT tracing interface.\n The omp-tools.h C/C++ header file provides the definitions of the types that are specified \n throughout this subsection.\n Binding \n The binding thread set for each of the entry points in this section is the encountering thread unless \n otherwise specified.The binding task set is the task executing on the encountering thread.\n Restrictions \n Restrictions on OMPT runtime entry points are as follows: \n \u2022 OMPT runtime entry points must not be called from a signal handler on a native thread before a \n native-thread-begin or after a native-thread-end event.\n \u2022 OMPT device runtime entry points must not be called after a device-finalize event for that device."}
{"section_title": "19.6 OMPT Runtime Entry Points for Tools", "chunk": "\n \u2022 OMPT device runtime entry points must not be called after a device-finalize event for that device.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.6.1 Entry Points in the OMPT Callback Interface", "chunk": "2 Entry points in the OMPT callback interface enable a tool to register callbacks for OpenMP events \n and to inspect the state of an OpenMP thread while executing in a tool callback or a signal handler.\n Pointers to these runtime entry points are obtained through the lookup function that is provided \n through the OMPT initializer.\n"}
{"section_title": "19.6.1.1 ompt_enumerate_states_t", "chunk": "7 Summary \n The ompt_enumerate_states_t type is the type signature of the \n ompt_enumerate_states runtime entry point, which enumerates the thread states that an \n OpenMP implementation supports.\n Format \nC / C++ \n typedef int (*ompt_enumerate_states_t) ( \n int current_state, \n int *next_state, \n const char **next_state_name \n ); \nC / C++ \n Semantics \n An OpenMP implementation may support only a subset of the states that the ompt_state_t \n enumeration type defines.An OpenMP implementation may also support implementation-specific \n states.The ompt_enumerate_states runtime entry point, which has type signature \n ompt_enumerate_states_t, enables a tool to enumerate the supported thread states."}
{"section_title": "19.6.1.1 ompt_enumerate_states_t", "chunk": "The ompt_enumerate_states runtime entry point, which has type signature \n ompt_enumerate_states_t, enables a tool to enumerate the supported thread states.\n When a supported thread state is passed as current_state, the runtime entry point assigns the next \n thread state in the enumeration to the variable passed by reference in next_state and assigns the \n name associated with that state to the character pointer passed by reference in next_state_name.\n Whenever one or more states are left in the enumeration, the ompt_enumerate_states \n runtime entry point returns 1.When the last state in the enumeration is passed as current_state, \n ompt_enumerate_states returns 0, which indicates that the enumeration is complete.\n Description of Arguments \n The current_state argument must be a thread state that the OpenMP implementation supports.To \n begin enumerating the supported states, a tool should pass ompt_state_undefined as \n current_state."}
{"section_title": "19.6.1.1 ompt_enumerate_states_t", "chunk": "To \n begin enumerating the supported states, a tool should pass ompt_state_undefined as \n current_state.Subsequent invocations of ompt_enumerate_states should pass the value \n assigned to the variable that was passed by reference in next_state to the previous call.\n The value ompt_state_undefined is reserved to indicate an invalid thread state.\n ompt_state_undefined is defined as an integer with the value 0x102.\nCHAPTER 19.OMPT INTERFACE 511 \n The next_state argument is a pointer to an integer in which ompt_enumerate_states returns \n the value of the next state in the enumeration.\n The next_state_name argument is a pointer to a character string pointer through which \n ompt_enumerate_states returns a string that describes the next state.\n Constraints on Arguments \n Any string returned through the next_state_name argument must be immutable and defined for the \n lifetime of program execution.\n Cross References \n \u2022 ompt_state_t, see Section 19.4.4.28 \n"}
{"section_title": "19.6.1.2 ompt_enumerate_mutex_impls_t", "chunk": "11 Summary \n The ompt_enumerate_mutex_impls_t type is the type signature of the \n ompt_enumerate_mutex_impls runtime entry point, which enumerates the kinds of mutual \n exclusion implementations that an OpenMP implementation employs.\n Format \nC / C++ \n typedef int (*ompt_enumerate_mutex_impls_t) ( \n int current_impl, \n int *next_impl, \n const char **next_impl_name \n ); \nC / C++ \n Semantics \n Mutual exclusion for locks, critical sections, and atomic regions may be implemented in \n several ways.The ompt_enumerate_mutex_impls runtime entry point, which has type \n signature ompt_enumerate_mutex_impls_t, enables a tool to enumerate the supported \n mutual exclusion implementations."}
{"section_title": "19.6.1.2 ompt_enumerate_mutex_impls_t", "chunk": "The ompt_enumerate_mutex_impls runtime entry point, which has type \n signature ompt_enumerate_mutex_impls_t, enables a tool to enumerate the supported \n mutual exclusion implementations.\n When a supported mutex implementation is passed as current_impl, the runtime entry point assigns \n the next mutex implementation in the enumeration to the variable passed by reference in next_impl \n and assigns the name associated with that mutex implementation to the character pointer passed by \n reference in next_impl_name.\n Whenever one or more mutex implementations are left in the enumeration, the \n ompt_enumerate_mutex_impls runtime entry point returns 1.When the last mutex \n implementation in the enumeration is passed as current_impl, the runtime entry point returns 0, \n which indicates that the enumeration is complete."}
{"section_title": "19.6.1.2 ompt_enumerate_mutex_impls_t", "chunk": "When the last mutex \n implementation in the enumeration is passed as current_impl, the runtime entry point returns 0, \n which indicates that the enumeration is complete.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The current_impl argument must be a mutex implementation that an OpenMP implementation \n supports.To begin enumerating the supported mutex implementations, a tool should pass \n ompt_mutex_impl_none as current_impl.Subsequent invocations of \n ompt_enumerate_mutex_impls should pass the value assigned to the variable that was \n passed in next_impl to the previous call.\n The value ompt_mutex_impl_none is reserved to indicate an invalid mutex implementation.\n ompt_mutex_impl_none is defined as an integer with the value 0.\n The next_impl argument is a pointer to an integer in which ompt_enumerate_mutex_impls \n returns the value of the next mutex implementation in the enumeration."}
{"section_title": "19.6.1.2 ompt_enumerate_mutex_impls_t", "chunk": "\n The next_impl argument is a pointer to an integer in which ompt_enumerate_mutex_impls \n returns the value of the next mutex implementation in the enumeration.\n The next_impl_name argument is a pointer to a character string pointer in which \n ompt_enumerate_mutex_impls returns a string that describes the next mutex \n implementation.\n Constraints on Arguments \n Any string returned through the next_impl_name argument must be immutable and defined for the \n lifetime of a program execution.\n"}
{"section_title": "19.6.1.3 ompt_set_callback_t", "chunk": "18 Summary \n The ompt_set_callback_t type is the type signature of the ompt_set_callback runtime \n entry point, which registers a pointer to a tool callback that an OpenMP implementation invokes \n when a host OpenMP event occurs.\n Format \nC / C++ \n typedef ompt_set_result_t (*ompt_set_callback_t) ( \n ompt_callbacks_t event, \n ompt_callback_t callback \n ); \nC / C++ \n Semantics \n OpenMP implementations can use callbacks to indicate the occurrence of events during the \n execution of an OpenMP program.The ompt_set_callback runtime entry point, which has \n type signature ompt_set_callback_t, registers a callback for an OpenMP event on the \n current device, The return value of ompt_set_callback indicates the outcome of registering \n the callback.\nCHAPTER 19.OMPT INTERFACE 513 \n Description of Arguments \n The event argument indicates the event for which the callback is being registered.\n The callback argument is a tool callback function."}
{"section_title": "19.6.1.3 ompt_set_callback_t", "chunk": "\n The callback argument is a tool callback function.If callback is NULL then callbacks associated \n with event are disabled.If callbacks are successfully disabled then ompt_set_always is \n returned.\n Constraints on Arguments \n When a tool registers a callback for an event, the type signature for the callback must match the \n type signature appropriate for the event.\n Restrictions \n Restrictions on the ompt_set_callback runtime entry point are as follows: \n \u2022 The entry point must not return ompt_set_impossible.\n Cross References \n \u2022 Callbacks, see Section 19.4.2 \n \u2022 Monitoring Activity on the Host with OMPT, see Section 19.2.4 \n \u2022 ompt_callback_t, see Section 19.4.4.1 \n \u2022 ompt_get_callback_t, see Section 19.6.1.4 \n \u2022 ompt_set_result_t, see Section 19.4.4.2 \n"}
{"section_title": "19.6.1.4 ompt_get_callback_t", "chunk": "19 Summary \n The ompt_get_callback_t type is the type signature of the ompt_get_callback runtime \n entry point, which retrieves a pointer to a registered tool callback routine (if any) that an OpenMP \n implementation invokes when a host OpenMP event occurs.\n Format \nC / C++ \n typedef int (*ompt_get_callback_t) ( \n ompt_callbacks_t event, \n ompt_callback_t *callback \n ); \nC / C++ \n Semantics \n The ompt_get_callback runtime entry point, which has type signature \n ompt_get_callback_t, retrieves a pointer to the tool callback that an OpenMP \n implementation may invoke when a host OpenMP event occurs.If a non-null tool callback is \n registered for the specified event, the pointer to the tool callback is assigned to the variable passed \n by reference in callback and ompt_get_callback returns 1; otherwise, it returns 0.If \n ompt_get_callback returns 0, the value of the variable passed by reference as callback is \n undefined."}
{"section_title": "19.6.1.4 ompt_get_callback_t", "chunk": "If \n ompt_get_callback returns 0, the value of the variable passed by reference as callback is \n undefined.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The event argument indicates the event for which the callback would be invoked.\n The callback argument returns a pointer to the callback associated with event.\n Constraints on Arguments \n The callback argument cannot be NULL and must point to valid storage.\n Cross References \n \u2022 Callbacks, see Section 19.4.2 \n \u2022 ompt_callback_t, see Section 19.4.4.1 \n \u2022 ompt_set_callback_t, see Section 19.6.1.3 \n"}
{"section_title": "19.6.1.5 ompt_get_thread_data_t", "chunk": "11 Summary \n The ompt_get_thread_data_t type is the type signature of the \n ompt_get_thread_data runtime entry point, which returns the address of the thread data \n object for the current thread.\n Format \nC / C++ \n typedef ompt_data_t *(*ompt_get_thread_data_t) (void); \nC / C++ \n Semantics \n Each OpenMP thread can have an associated thread data object of type ompt_data_t.The \n ompt_get_thread_data runtime entry point, which has type signature \n ompt_get_thread_data_t, retrieves a pointer to the thread data object, if any, that is \n associated with the current thread.A tool may use a pointer to an OpenMP thread\u2019s data object that \n ompt_get_thread_data retrieves to inspect or to modify the value of the data object.When \n an OpenMP thread is created, its data object is initialized with value ompt_data_none.This \n runtime entry point is async signal safe.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n"}
{"section_title": "19.6.1.6 ompt_get_num_procs_t", "chunk": "28 Summary \n The ompt_get_num_procs_t type is the type signature of the ompt_get_num_procs \n runtime entry point, which returns the number of processors currently available to the execution \n environment on the host device.\nCHAPTER 19.OMPT INTERFACE 515 \n Format \nC / C++ \n typedef int (*ompt_get_num_procs_t) (void); \nC / C++ \n Binding \n The binding thread set is all threads on the host device.\n Semantics \n The ompt_get_num_procs runtime entry point, which has type signature \n ompt_get_num_procs_t, returns the number of processors that are available on the host \n device at the time the routine is called.This value may change between the time that it is \n determined and the time that it is read in the calling context due to system actions outside the \n control of the OpenMP implementation.This runtime entry point is async signal safe.\n"}
{"section_title": "19.6.1.7 ompt_get_num_places_t", "chunk": "12 Summary \n The ompt_get_num_places_t type is the type signature of the ompt_get_num_places \n runtime entry point, which returns the number of places currently available to the execution \n environment in the place list.\n Format \nC / C++ \n typedef int (*ompt_get_num_places_t) (void); \nC / C++ \n Binding \n The binding thread set is all threads on a device.\n Semantics \n The ompt_get_num_places runtime entry point, which has type signature \n ompt_get_num_places_t, returns the number of places in the place list.This value is \n equivalent to the number of places in the place-partition-var ICV in the execution environment of \n the initial task.This runtime entry point is async signal safe.\n Cross References \n \u2022 OMP_PLACES, see Section 21.1.6 \n \u2022 place-partition-var ICV, see Table 2.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.6.1.8 ompt_get_place_proc_ids_t", "chunk": "2 Summary \n The ompt_get_place_procs_ids_t type is the type signature of the \n ompt_get_num_place_procs_ids runtime entry point, which returns the numerical \n identifiers of the processors that are available to the execution environment in the specified place.\n Format \nC / C++ \n typedef int (*ompt_get_place_proc_ids_t) ( \n int place_num, \n int ids_size, \n int *ids \n ); \nC / C++ \n Binding \n The binding thread set is all threads on a device.\n Semantics \n The ompt_get_place_proc_ids runtime entry point, which has type signature \n ompt_get_place_proc_ids_t, returns the numerical identifiers of each processor that is \n associated with the specified place.These numerical identifiers are non-negative, and their meaning \n is implementation defined.\n Description of Arguments \n The place_num argument specifies the place that is being queried.\n The ids argument is an array in which the routine can return a vector of processor identifiers in the \n specified place."}
{"section_title": "19.6.1.8 ompt_get_place_proc_ids_t", "chunk": "\n The ids argument is an array in which the routine can return a vector of processor identifiers in the \n specified place.\n The ids_size argument indicates the size of the result array that is specified by ids.\n Effect \n If the ids array of size ids_size is large enough to contain all identifiers then they are returned in ids \n and their order in the array is implementation defined.Otherwise, if the ids array is too small, the \n values in ids when the function returns are unspecified.The routine always returns the number of \n numerical identifiers of the processors that are available to the execution environment in the \n specified place.\n"}
{"section_title": "19.6.1.9 ompt_get_place_num_t", "chunk": "31 Summary \n The ompt_get_place_num_t type is the type signature of the ompt_get_place_num \n runtime entry point, which returns the place number of the place to which the current thread is \n bound.\nCHAPTER 19.OMPT INTERFACE 517 \n Format \nC / C++ \n typedef int (*ompt_get_place_num_t) (void); \nC / C++ \n Semantics \n When the current thread is bound to a place, ompt_get_place_num returns the place number \n associated with the thread.The returned value is between 0 and one less than the value returned by \n ompt_get_num_places, inclusive.When the current thread is not bound to a place, the routine \n returns -1.This runtime entry point is async signal safe.\n"}
{"section_title": "19.6.1.10 ompt_get_partition_place_nums_t", "chunk": "9 Summary \n The ompt_get_partition_place_nums_t type is the type signature of the \n ompt_get_partition_place_nums runtime entry point, which returns a list of place \n numbers that correspond to the places in the place-partition-var ICV of the innermost implicit task.\n Format \nC / C++ \n typedef int (*ompt_get_partition_place_nums_t) ( \n int place_nums_size, \n int *place_nums \n ); \nC / C++ \n Semantics \n The ompt_get_partition_place_nums runtime entry point, which has type signature \n ompt_get_partition_place_nums_t, returns a list of place numbers that correspond to \n the places in the place-partition-var ICV of the innermost implicit task.This runtime entry point is \n async signal safe.\n Description of Arguments \n The place_nums argument is an array in which the routine can return a vector of place identifiers.\n The place_nums_size argument indicates the size of the result array that the place_nums argument \n specifies."}
{"section_title": "19.6.1.10 ompt_get_partition_place_nums_t", "chunk": "\n The place_nums_size argument indicates the size of the result array that the place_nums argument \n specifies.\n Effect \n If the place_nums array of size place_nums_size is large enough to contain all identifiers then they \n are returned in place_nums and their order in the array is implementation defined.Otherwise, if the \n place_nums array is too small, the values in place_nums when the function returns are unspecified.\n The routine always returns the number of places in the place-partition-var ICV of the innermost \n implicit task.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 OMP_PLACES, see Section 21.1.6 \n \u2022 place-partition-var ICV, see Table 2.1 \n"}
{"section_title": "19.6.1.11 ompt_get_proc_id_t", "chunk": "5 Summary \n The ompt_get_proc_id_t type is the type signature of the ompt_get_proc_id runtime \n entry point, which returns the numerical identifier of the processor of the current thread.\n Format \nC / C++ \n typedef int (*ompt_get_proc_id_t) (void); \nC / C++ \n Semantics \n The ompt_get_proc_id runtime entry point, which has type signature \n ompt_get_proc_id_t, returns the numerical identifier of the processor of the current thread.\n A defined numerical identifier is non-negative, and its meaning is implementation defined.A \n negative number indicates a failure to retrieve the numerical identifier.This runtime entry point is \n async signal safe.\n"}
{"section_title": "19.6.1.12 ompt_get_state_t", "chunk": "17 Summary \n The ompt_get_state_t type is the type signature of the ompt_get_state runtime entry \n point, which returns the state and the wait identifier of the current thread.\n Format \nC / C++ \n typedef int (*ompt_get_state_t) ( \n ompt_wait_id_t *wait_id \n ); \nC / C++ \n Semantics \n Each OpenMP thread has an associated state and a wait identifier.If a thread\u2019s state indicates that \n the thread is waiting for mutual exclusion then its wait identifier contains an opaque handle that \n indicates the data object upon which the thread is waiting.The ompt_get_state runtime entry \n point, which has type signature ompt_get_state_t, retrieves the state and wait identifier of the \n current thread.The returned value may be any one of the states predefined by ompt_state_t or \n a value that represents an implementation-specific state.The tool may obtain a string representation \nCHAPTER 19.OMPT INTERFACE 519 \n for each state with the ompt_enumerate_states function."}
{"section_title": "19.6.1.12 ompt_get_state_t", "chunk": "OMPT INTERFACE 519 \n for each state with the ompt_enumerate_states function.If the returned state indicates that \n the thread is waiting for a lock, nest lock, critical region, atomic region, or ordered region \n then the value of the thread\u2019s wait identifier is assigned to a non-null wait identifier passed as the \n wait_id argument.This runtime entry point is async signal safe.\n Description of Arguments \n The wait_id argument is a pointer to an opaque handle that is available to receive the value of the \n wait identifier of the thread.If wait_id is not NULL then the entry point assigns the value of the \n wait identifier of the thread to the object to which wait_id points.If the returned state is not one of \n the specified wait states then the value of the opaque object to which wait_id points is undefined \n after the call.\n Constraints on Arguments \n The argument passed to the entry point must be a reference to a variable of the specified type or \n NULL."}
{"section_title": "19.6.1.12 ompt_get_state_t", "chunk": "\n Constraints on Arguments \n The argument passed to the entry point must be a reference to a variable of the specified type or \n NULL.\n Cross References \n \u2022 ompt_enumerate_states_t, see Section 19.6.1.1 \n \u2022 ompt_state_t, see Section 19.4.4.28 \n \u2022 ompt_wait_id_t, see Section 19.4.4.31 \n"}
{"section_title": "19.6.1.13 ompt_get_parallel_info_t", "chunk": "19 Summary \n The ompt_get_parallel_info_t type is the type signature of the \n ompt_get_parallel_info runtime entry point, which returns information about the parallel \n region, if any, at the specified ancestor level for the current execution context.\n Format \nC / C++ \n typedef int (*ompt_get_parallel_info_t) ( \n int ancestor_level, \n ompt_data_t **parallel_data, \n int *team_size \n ); \nC / C++ \n Semantics \n During execution, an OpenMP program may employ nested parallel regions.The \n ompt_get_parallel_info runtime entry point, which has type signature \n ompt_get_parallel_info_t, retrieves information about the current parallel region and any \n enclosing parallel regions for the current execution context.The entry point returns 2 if a parallel \n region exists at the specified ancestor level and the information is available, 1 if a parallel region \n exists at the specified ancestor level but the information is currently unavailable, and 0 otherwise."}
{"section_title": "19.6.1.13 ompt_get_parallel_info_t", "chunk": "The entry point returns 2 if a parallel \n region exists at the specified ancestor level and the information is available, 1 if a parallel region \n exists at the specified ancestor level but the information is currently unavailable, and 0 otherwise.\n OpenMP API \u2013 Version 5.2 November 2021 \n A tool may use the pointer to the data object of a parallel region that it obtains from this runtime \n entry point to inspect or to modify the value of the data object.When a parallel region is created, its \n data object will be initialized with the value ompt_data_none.\n This runtime entry point is async signal safe.\n Between a parallel-begin event and an implicit-task-begin event, a call to \n ompt_get_parallel_info(0,...) may return information about the outer parallel team or \n the new parallel team."}
{"section_title": "19.6.1.13 ompt_get_parallel_info_t", "chunk": "\n Between a parallel-begin event and an implicit-task-begin event, a call to \n ompt_get_parallel_info(0,...) may return information about the outer parallel team or \n the new parallel team.\n If a thread is in the state ompt_state_wait_barrier_implicit_parallel then a call to \n ompt_get_parallel_info may return a pointer to a copy of the specified parallel region\u2019s \n parallel_data rather than a pointer to the data word for the region itself.This convention enables \n the primary thread for a parallel region to free storage for the region immediately after the region \n ends, yet avoid having some other thread in the team that is executing the region potentially \n reference the parallel_data object for the region after it has been freed.\n Description of Arguments \n The ancestor_level argument specifies the parallel region of interest by its ancestor level."}
{"section_title": "19.6.1.13 ompt_get_parallel_info_t", "chunk": "\n Description of Arguments \n The ancestor_level argument specifies the parallel region of interest by its ancestor level.Ancestor \n level 0 refers to the innermost parallel region; information about enclosing parallel regions may be \n obtained using larger values for ancestor_level.\n The parallel_data argument returns the parallel data if the argument is not NULL.\n The team_size argument returns the team size if the argument is not NULL.\n Effect \n If the runtime entry point returns 0 or 1, no argument is modified.Otherwise, \n ompt_get_parallel_info has the following effects: \n \u2022 If a non-null value was passed for parallel_data, the value returned in parallel_data is a pointer \n to a data word that is associated with the parallel region at the specified level; and \n \u2022 If a non-null value was passed for team_size, the value returned in the integer to which team_size \n point is the number of threads in the team that is associated with the parallel region."}
{"section_title": "19.6.1.13 ompt_get_parallel_info_t", "chunk": "Otherwise, \n ompt_get_parallel_info has the following effects: \n \u2022 If a non-null value was passed for parallel_data, the value returned in parallel_data is a pointer \n to a data word that is associated with the parallel region at the specified level; and \n \u2022 If a non-null value was passed for team_size, the value returned in the integer to which team_size \n point is the number of threads in the team that is associated with the parallel region.\n Constraints on Arguments \n While argument ancestor_level is passed by value, all other arguments to the entry point must be \n pointers to variables of the specified types or NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n"}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "33 Summary \n The ompt_get_task_info_t type is the type signature of the ompt_get_task_info \n runtime entry point, which returns information about the task, if any, at the specified ancestor level \n in the current execution context.\nCHAPTER 19.OMPT INTERFACE 521 \n Format \nC / C++ \n typedef int (*ompt_get_task_info_t) ( \n int ancestor_level, \n int *flags, \n ompt_data_t **task_data, \n ompt_frame_t **task_frame, \n ompt_data_t **parallel_data, \n int *thread_num \n ); \nC / C++ \n Semantics \n During execution, an OpenMP thread may be executing an OpenMP task.Additionally, the stack of \n the thread may contain procedure frames that are associated with suspended OpenMP tasks or \n OpenMP runtime system routines.To obtain information about any task on the stack of the current \n thread, a tool uses the ompt_get_task_info runtime entry point, which has type signature \n ompt_get_task_info_t."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "To obtain information about any task on the stack of the current \n thread, a tool uses the ompt_get_task_info runtime entry point, which has type signature \n ompt_get_task_info_t.\n Ancestor level 0 refers to the active task; information about other tasks with associated frames \n present on the stack in the current execution context may be queried at higher ancestor levels.\n The ompt_get_task_info runtime entry point returns 2 if a task region exists at the specified \n ancestor level and the information is available, 1 if a task region exists at the specified ancestor level \n but the information is currently unavailable, and 0 otherwise.\n If a task exists at the specified ancestor level and the information is available then information is \n returned in the variables passed by reference to the entry point."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "\n If a task exists at the specified ancestor level and the information is available then information is \n returned in the variables passed by reference to the entry point.If no task region exists at the \n specified ancestor level or the information is unavailable then the values of variables passed by \n reference to the entry point are undefined when ompt_get_task_info returns.\n A tool may use a pointer to a data object for a task or parallel region that it obtains from \n ompt_get_task_info to inspect or to modify the value of the data object.When either a \n parallel region or a task region is created, its data object will be initialized with the value \n ompt_data_none.\n This runtime entry point is async signal safe.\n Description of Arguments \n The ancestor_level argument specifies the task region of interest by its ancestor level."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "\n Description of Arguments \n The ancestor_level argument specifies the task region of interest by its ancestor level.Ancestor \n level 0 refers to the active task; information about ancestor tasks found in the current execution \n context may be queried at higher ancestor levels.\n The flags argument returns the task type if the argument is not NULL.\n The task_data argument returns the task data if the argument is not NULL.\n The task_frame argument returns the task frame pointer if the argument is not NULL.\n OpenMP API \u2013 Version 5.2 November 2021 \n The parallel_data argument returns the parallel data if the argument is not NULL.\n The thread_num argument returns the thread number if the argument is not NULL.\n Effect \n If the runtime entry point returns 0 or 1, no argument is modified."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "\n Effect \n If the runtime entry point returns 0 or 1, no argument is modified.Otherwise, \n ompt_get_task_info has the following effects: \n \u2022 If a non-null value was passed for flags then the value returned in the integer to which flags \n points represents the type of the task at the specified level; possible task types include initial, \n implicit, explicit, and target tasks; \n \u2022 If a non-null value was passed for task_data then the value that is returned in the object to which \n it points is a pointer to a data word that is associated with the task at the specified level; \n \u2022 If a non-null value was passed for task_frame then the value that is returned in the object to \n which task_frame points is a pointer to the ompt_frame_t structure that is associated with the \n task at the specified level; \n \u2022 If a non-null value was passed for parallel_data then the value that is returned in the object to \n which parallel_data points is a pointer to a data word that is associated with the parallel region \n that contains the task at the specified level or, if the task at the specified level is an initial task, \n NULL; and \n \u2022 If a non-null value was passed for thread_num, then the value that is returned in the object to \n which thread_num points indicates the number of the thread in the parallel region that is \n executing the task at the specified level."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "Otherwise, \n ompt_get_task_info has the following effects: \n \u2022 If a non-null value was passed for flags then the value returned in the integer to which flags \n points represents the type of the task at the specified level; possible task types include initial, \n implicit, explicit, and target tasks; \n \u2022 If a non-null value was passed for task_data then the value that is returned in the object to which \n it points is a pointer to a data word that is associated with the task at the specified level; \n \u2022 If a non-null value was passed for task_frame then the value that is returned in the object to \n which task_frame points is a pointer to the ompt_frame_t structure that is associated with the \n task at the specified level; \n \u2022 If a non-null value was passed for parallel_data then the value that is returned in the object to \n which parallel_data points is a pointer to a data word that is associated with the parallel region \n that contains the task at the specified level or, if the task at the specified level is an initial task, \n NULL; and \n \u2022 If a non-null value was passed for thread_num, then the value that is returned in the object to \n which thread_num points indicates the number of the thread in the parallel region that is \n executing the task at the specified level.\n Constraints on Arguments \n While argument ancestor_level is passed by value, all other arguments to \n ompt_get_task_info must be pointers to variables of the specified types or NULL."}
{"section_title": "19.6.1.14 ompt_get_task_info_t", "chunk": "\n Constraints on Arguments \n While argument ancestor_level is passed by value, all other arguments to \n ompt_get_task_info must be pointers to variables of the specified types or NULL.\n Cross References \n \u2022 ompt_data_t, see Section 19.4.4.4 \n \u2022 ompt_frame_t, see Section 19.4.4.29 \n \u2022 ompt_task_flag_t, see Section 19.4.4.19 \n"}
{"section_title": "19.6.1.15 ompt_get_task_memory_t", "chunk": "29 Summary \n The ompt_get_task_memory_t type is the type signature of the \n ompt_get_task_memory runtime entry point, which returns information about memory ranges \n that are associated with the task.\nCHAPTER 19.OMPT INTERFACE 523 \n Format \nC / C++ \n typedef int (*ompt_get_task_memory_t)( \n void **addr, \n size_t *size, \n int block \n ); \nC / C++ \n Semantics \n During execution, an OpenMP thread may be executing an OpenMP task.The OpenMP \n implementation must preserve the data environment from the creation of the task for the execution \n of the task.The ompt_get_task_memory runtime entry point, which has type signature \n ompt_get_task_memory_t, provides information about the memory ranges used to store the \n data environment for the current task.Multiple memory ranges may be used to store these data.\n The block argument supports iteration over these memory ranges."}
{"section_title": "19.6.1.15 ompt_get_task_memory_t", "chunk": "\n The block argument supports iteration over these memory ranges.The \n ompt_get_task_memory runtime entry point returns 1 if more memory ranges are available, \n and 0 otherwise.If no memory is used for a task, size is set to 0.In this case, addr is unspecified.\n This runtime entry point is async signal safe.\n Description of Arguments \n The addr argument is a pointer to a void pointer return value to provide the start address of a \n memory block.\n The size argument is a pointer to a size type return value to provide the size of the memory block.\n The block argument is an integer value to specify the memory block of interest.\n"}
{"section_title": "19.6.1.16 ompt_get_target_info_t", "chunk": "23 Summary \n The ompt_get_target_info_t type is the type signature of the \n ompt_get_target_info runtime entry point, which returns identifiers that specify a thread\u2019s \n current target region and target operation ID, if any.\n Format \nC / C++ \n typedef int (*ompt_get_target_info_t) ( \n uint64_t *device_num, \n ompt_id_t *target_id, \n ompt_id_t *host_op_id \n ); \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The ompt_get_target_info entry point, which has type signature \n ompt_get_target_info_t, returns 1 if the current thread is in a target region and 0 \n otherwise.If the entry point returns 0 then the values of the variables passed by reference as its \n arguments are undefined.If the current thread is in a target region then \n ompt_get_target_info returns information about the current device, active target region, \n and active host operation, if any.This runtime entry point is async signal safe."}
{"section_title": "19.6.1.16 ompt_get_target_info_t", "chunk": "This runtime entry point is async signal safe.\n Description of Arguments \n The device_num argument returns the device number if the current thread is in a target region.\n The target_id argument returns the target region identifier if the current thread is in a target \n region.\n If the current thread is in the process of initiating an operation on a target device (for example, \n copying data to or from an accelerator or launching a kernel), then host_op_id returns the identifier \n for the operation; otherwise, host_op_id returns ompt_id_none.\n Constraints on Arguments \n Arguments passed to the entry point must be valid references to variables of the specified types.\n Cross References \n \u2022 ompt_id_t, see Section 19.4.4.3 \n"}
{"section_title": "19.6.1.17 ompt_get_num_devices_t", "chunk": "20 Summary \n The ompt_get_num_devices_t type is the type signature of the \n ompt_get_num_devices runtime entry point, which returns the number of available devices.\n Format \nC / C++ \n typedef int (*ompt_get_num_devices_t) (void); \nC / C++ \n Semantics \n The ompt_get_num_devices runtime entry point, which has type signature \n ompt_get_num_devices_t, returns the number of devices available to an OpenMP program.\n This runtime entry point is async signal safe.\n"}
{"section_title": "19.6.1.18 ompt_get_unique_id_t", "chunk": "30 Summary \n The ompt_get_unique_id_t type is the type signature of the ompt_get_unique_id \n runtime entry point, which returns a unique number.\nCHAPTER 19.OMPT INTERFACE 525 \n Format \nC / C++ \n typedef uint64_t (*ompt_get_unique_id_t) (void); \nC / C++ \n Semantics \n The ompt_get_unique_id runtime entry point, which has type signature \n ompt_get_unique_id_t, returns a number that is unique for the duration of an OpenMP \n program.Successive invocations may not result in consecutive or even increasing numbers.This \n runtime entry point is async signal safe.\n"}
{"section_title": "19.6.1.19 ompt_finalize_tool_t", "chunk": "9 Summary \n The ompt_finalize_tool_t type is the type signature of the ompt_finalize_tool \n runtime entry point, which enables a tool to finalize itself.\n Format \nC / C++ \n typedef void (*ompt_finalize_tool_t) (void); \nC / C++ \n Semantics \n A tool may detect that the execution of an OpenMP program is ending before the OpenMP \n implementation does.To facilitate clean termination of the tool, the tool may invoke the \n ompt_finalize_tool runtime entry point, which has type signature \n ompt_finalize_tool_t.Upon completion of ompt_finalize_tool, no OMPT \n callbacks are dispatched.\n Effect \n The ompt_finalize_tool routine detaches the tool from the runtime, unregisters all callbacks \n and invalidates all OMPT entry points passed to the tool in the lookup-function.Upon completion \n of ompt_finalize_tool, no further callbacks will be issued on any thread."}
{"section_title": "19.6.1.19 ompt_finalize_tool_t", "chunk": "Upon completion \n of ompt_finalize_tool, no further callbacks will be issued on any thread.Before the \n callbacks are unregistered, the OpenMP runtime should attempt to dispatch all outstanding \n registered callbacks as well as the callbacks that would be encountered during shutdown of the \n runtime, if possible in the current execution context.\n"}
{"section_title": "19.6.2 Entry Points in the OMPT Device Tracing Interface", "chunk": "28 The runtime entry points with type signatures of the types that are specified in this section enable a \n tool to trace activities on a device.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.6.2.1 ompt_get_device_num_procs_t", "chunk": "2 Summary \n The ompt_get_device_num_procs_t type is the type signature of the \n ompt_get_device_num_procs runtime entry point, which returns the number of processors \n currently available to the execution environment on the specified device.\n Format \nC / C++ \n typedef int (*ompt_get_device_num_procs_t) ( \n ompt_device_t *device \n ); \nC / C++ \n Semantics \n The ompt_get_device_num_procs runtime entry point, which has type signature \n ompt_get_device_num_procs_t, returns the number of processors that are available on the \n device at the time the routine is called.This value may change between the time that it is \n determined and the time that it is read in the calling context due to system actions outside the \n control of the OpenMP implementation.\n Description of Arguments \n The device argument is a pointer to an opaque object that represents the target device instance."}
{"section_title": "19.6.2.1 ompt_get_device_num_procs_t", "chunk": "\n Description of Arguments \n The device argument is a pointer to an opaque object that represents the target device instance.The \n pointer to the device instance object is used by functions in the device tracing interface to identify \n the device being addressed.\n Cross References \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.2 ompt_get_device_time_t", "chunk": "23 Summary \n The ompt_get_device_time_t type is the type signature of the \n ompt_get_device_time runtime entry point, which returns the current time on the specified \n device.\n Format \nC / C++ \n typedef ompt_device_time_t (*ompt_get_device_time_t) ( \n ompt_device_t *device \n ); \nC / C++ \nCHAPTER 19.OMPT INTERFACE 527 \n Semantics \n Host and target devices are typically distinct and run independently.If host and target devices are \n different hardware components, they may use different clock generators.For this reason, a common \n time base for ordering host-side and device-side events may not be available.The \n ompt_get_device_time runtime entry point, which has type signature \n ompt_get_device_time_t, returns the current time on the specified device.A tool can use \n this information to align time stamps from different devices.\n Description of Arguments \n The device argument is a pointer to an opaque object that represents the target device instance."}
{"section_title": "19.6.2.2 ompt_get_device_time_t", "chunk": "\n Description of Arguments \n The device argument is a pointer to an opaque object that represents the target device instance.The \n pointer to the device instance object is used by functions in the device tracing interface to identify \n the device being addressed.\n Cross References \n \u2022 ompt_device_t, see Section 19.4.4.5 \n \u2022 ompt_device_time_t, see Section 19.4.4.6 \n"}
{"section_title": "19.6.2.3 ompt_translate_time_t", "chunk": "16 Summary \n The ompt_translate_time_t type is the type signature of the ompt_translate_time \n runtime entry point, which translates a time value that is obtained from the specified device to a \n corresponding time value on the host device.\n Format \nC / C++ \n typedef double (*ompt_translate_time_t) ( \n ompt_device_t *device, \n ompt_device_time_t time \n ); \nC / C++ \n Semantics \n The ompt_translate_time runtime entry point, which has type signature \n ompt_translate_time_t, translates a time value obtained from the specified device to a \n corresponding time value on the host device.The returned value for the host time has the same \n meaning as the value returned from omp_get_wtime.\n Description of Arguments \n The device argument is a pointer to an opaque object that represents the target device instance.The \n pointer to the device instance object is used by functions in the device tracing interface to identify \n the device being addressed."}
{"section_title": "19.6.2.3 ompt_translate_time_t", "chunk": "The \n pointer to the device instance object is used by functions in the device tracing interface to identify \n the device being addressed.\n The time argument is a time from the specified device.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 omp_get_wtime, see Section 18.10.1 \n \u2022 ompt_device_t, see Section 19.4.4.5 \n \u2022 ompt_device_time_t, see Section 19.4.4.6 \n"}
{"section_title": "19.6.2.4 ompt_set_trace_ompt_t", "chunk": "6 Summary \n The ompt_set_trace_ompt_t type is the type signature of the ompt_set_trace_ompt \n runtime entry point, which enables or disables the recording of trace records for one or more types \n of OMPT events.\n Format \nC / C++ \n typedef ompt_set_result_t (*ompt_set_trace_ompt_t) ( \n ompt_device_t *device, \n unsigned int enable, \n unsigned int etype \n ); \nC / C++ \n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n The etype argument indicates the events to which the invocation of ompt_set_trace_ompt \n applies.If the value of etype is 0 then the invocation applies to all events.If etype is positive then it \n applies to the event in ompt_callbacks_t that matches that value."}
{"section_title": "19.6.2.4 ompt_set_trace_ompt_t", "chunk": "If etype is positive then it \n applies to the event in ompt_callbacks_t that matches that value.\n The enable argument indicates whether tracing should be enabled or disabled for the event or events \n that the etype argument specifies.A positive value for enable indicates that recording should be \n enabled; a value of 0 for enable indicates that recording should be disabled.\n Restrictions \n Restrictions on the ompt_set_trace_ompt runtime entry point are as follows: \n \u2022 The entry point must not return ompt_set_sometimes_paired.\n Cross References \n \u2022 Callbacks, see Section 19.4.2 \n \u2022 Tracing Activity on Target Devices with OMPT, see Section 19.2.5 \n \u2022 ompt_device_t, see Section 19.4.4.5 \n \u2022 ompt_set_result_t, see Section 19.4.4.2 \nCHAPTER 19.OMPT INTERFACE 529 \n"}
{"section_title": "19.6.2.5 ompt_set_trace_native_t", "chunk": "2 Summary \n The ompt_set_trace_native_t type is the type signature of the \n ompt_set_trace_native runtime entry point, which enables or disables the recording of \n native trace records for a device.\n Format \nC / C++ \n typedef ompt_set_result_t (*ompt_set_trace_native_t) ( \n ompt_device_t *device, \n int enable, \n int flags \n ); \nC / C++ \n Semantics \n This interface is designed for use by a tool that cannot directly use native control functions for the \n device.If a tool can directly use the native control functions then it can invoke native control \n functions directly using pointers that the lookup function associated with the device provides and \n that are described in the documentation string that is provided to the device initializer callback.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance."}
{"section_title": "19.6.2.5 ompt_set_trace_native_t", "chunk": "\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n The enable argument indicates whether this invocation should enable or disable recording of events.\n The flags argument specifies the kinds of native device monitoring to enable or to disable.Each \n kind of monitoring is specified by a flag bit.Flags can be composed by using logical or to combine \n enumeration values from type ompt_native_mon_flag_t.\n Restrictions \n Restrictions on the ompt_set_trace_native runtime entry point are as follows: \n \u2022 The entry point must not return ompt_set_sometimes_paired."}
{"section_title": "19.6.2.5 ompt_set_trace_native_t", "chunk": "\n Restrictions \n Restrictions on the ompt_set_trace_native runtime entry point are as follows: \n \u2022 The entry point must not return ompt_set_sometimes_paired.\n Cross References \n \u2022 Tracing Activity on Target Devices with OMPT, see Section 19.2.5 \n \u2022 ompt_device_t, see Section 19.4.4.5 \n \u2022 ompt_native_mon_flag_t, see Section 19.4.4.18 \n \u2022 ompt_set_result_t, see Section 19.4.4.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "19.6.2.6 ompt_start_trace_t", "chunk": "2 Summary \n The ompt_start_trace_t type is the type signature of the ompt_start_trace runtime \n entry point, which starts tracing of activity on a specific device.\n Format \nC / C++ \n typedef int (*ompt_start_trace_t) ( \n ompt_device_t *device, \n ompt_callback_buffer_request_t request, \n ompt_callback_buffer_complete_t complete \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_start_trace runtime entry point, which has type signature \n ompt_start_trace_t, initiates tracing on the device.Under normal operating conditions, \n every event buffer provided to a device by a tool callback is returned to the tool before the OpenMP \n runtime shuts down.If an exceptional condition terminates execution of an OpenMP program, the \n OpenMP runtime may not return buffers provided to the device.An invocation of \n ompt_start_trace returns 1 if the command succeeds and 0 otherwise."}
{"section_title": "19.6.2.6 ompt_start_trace_t", "chunk": "An invocation of \n ompt_start_trace returns 1 if the command succeeds and 0 otherwise.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n The request argument specifies a tool callback that supplies a buffer in which a device can deposit \n events.\n The complete argument specifies a tool callback that is invoked by the OpenMP implementation to \n empty a buffer that contains event records.\n Cross References \n \u2022 ompt_callback_buffer_complete_t, see Section 19.5.2.24 \n \u2022 ompt_callback_buffer_request_t, see Section 19.5.2.23 \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.7 ompt_pause_trace_t", "chunk": "30 Summary \n The ompt_pause_trace_t type is the type signature of the ompt_pause_trace runtime \n entry point, which pauses or restarts activity tracing on a specific device.\nCHAPTER 19.OMPT INTERFACE 531 \n Format \nC / C++ \n typedef int (*ompt_pause_trace_t) ( \n ompt_device_t *device, \n int begin_pause \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_pause_trace runtime entry point, which has type signature \n ompt_pause_trace_t, pauses or resumes tracing on a device.An invocation of \n ompt_pause_trace returns 1 if the command succeeds and 0 otherwise.Redundant pause or \n resume commands are idempotent and will return the same value as the prior command.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n The begin_pause argument indicates whether to pause or to resume tracing."}
{"section_title": "19.6.2.7 ompt_pause_trace_t", "chunk": "\n The begin_pause argument indicates whether to pause or to resume tracing.To resume tracing, \n zero should be supplied for begin_pause; to pause tracing, any other value should be supplied.\n Cross References \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.8 ompt_flush_trace_t", "chunk": "19 Summary \n The ompt_flush_trace_t type is the type signature of the ompt_flush_trace runtime \n entry point, which causes all pending trace records for the specified device to be delivered.\n Format \nC / C++ \n typedef int (*ompt_flush_trace_t) ( \n ompt_device_t *device \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_flush_trace runtime entry point, which has type signature \n ompt_flush_trace_t, causes the OpenMP implementation to issue a sequence of zero or more \n buffer completion callbacks to deliver all trace records that have been collected prior to the flush.\n An invocation of ompt_flush_trace returns 1 if the command succeeds and 0 otherwise.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed."}
{"section_title": "19.6.2.8 ompt_flush_trace_t", "chunk": "Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.9 ompt_stop_trace_t", "chunk": "4 Summary \n The ompt_stop_trace_t type is the type signature of the ompt_stop_trace runtime entry \n point, which stops tracing for a device.\n Format \nC / C++ \n typedef int (*ompt_stop_trace_t) ( \n ompt_device_t *device \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_stop_trace runtime entry point, which has type signature \n ompt_stop_trace_t, halts tracing on the device and requests that any pending trace records be \n flushed.An invocation of ompt_stop_trace returns 1 if the command succeeds and 0 \n otherwise.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n Cross References \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.10 ompt_advance_buffer_cursor_t", "chunk": "22 Summary \n The ompt_advance_buffer_cursor_t type is the type signature of the \n ompt_advance_buffer_cursor runtime entry point, which advances a trace buffer cursor to \n the next record.\n Format \nC / C++ \n typedef int (*ompt_advance_buffer_cursor_t) ( \n ompt_device_t *device, \n ompt_buffer_t *buffer, \n size_t size, \n ompt_buffer_cursor_t current, \n ompt_buffer_cursor_t *next \n ); \nC / C++ \nCHAPTER 19.OMPT INTERFACE 533 \n Semantics \n A device\u2019s ompt_advance_buffer_cursor runtime entry point, which has type signature \n ompt_advance_buffer_cursor_t, advances a trace buffer pointer to the next trace record.\n An invocation of ompt_advance_buffer_cursor returns true if the advance is successful \n and the next position in the buffer is valid.\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance."}
{"section_title": "19.6.2.10 ompt_advance_buffer_cursor_t", "chunk": "\n Description of Arguments \n The device argument points to an opaque object that represents the target device instance.Functions \n in the device tracing interface use this pointer to identify the device that is being addressed.\n The buffer argument indicates a trace buffer that is associated with the cursors.\n The argument size indicates the size of buffer in bytes.\n The current argument is an opaque buffer cursor.\n The next argument returns the next value of an opaque buffer cursor.\n Cross References \n \u2022 ompt_buffer_cursor_t, see Section 19.4.4.8 \n \u2022 ompt_device_t, see Section 19.4.4.5 \n"}
{"section_title": "19.6.2.11 ompt_get_record_type_t", "chunk": "17 Summary \n The ompt_get_record_type_t type is the type signature of the \n ompt_get_record_type runtime entry point, which inspects the type of a trace record.\n Format \nC / C++ \n typedef ompt_record_t (*ompt_get_record_type_t) ( \n ompt_buffer_t *buffer, \n ompt_buffer_cursor_t current \n ); \nC / C++ \n Semantics \n Trace records for a device may be in one of two forms: native record format, which may be \n device-specific, or OMPT record format, in which each trace record corresponds to an OpenMP \n event and most fields in the record structure are the arguments that would be passed to the OMPT \n callback for the event.A device\u2019s ompt_get_record_type runtime entry point, which has \n type signature ompt_get_record_type_t, inspects the type of a trace record and indicates \n whether the record at the current position in the trace buffer is an OMPT record, a native record, or \n an invalid record.An invalid record type is returned if the cursor is out of bounds."}
{"section_title": "19.6.2.11 ompt_get_record_type_t", "chunk": "An invalid record type is returned if the cursor is out of bounds.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The buffer argument indicates a trace buffer.\n The current argument is an opaque buffer cursor.\n Cross References \n \u2022 Record Type, see Section 19.4.3.1 \n \u2022 ompt_buffer_cursor_t, see Section 19.4.4.8 \n \u2022 ompt_buffer_t, see Section 19.4.4.7 \n"}
{"section_title": "19.6.2.12 ompt_get_record_ompt_t", "chunk": "9 Summary \n The ompt_get_record_ompt_t type is the type signature of the \n ompt_get_record_ompt runtime entry point, which obtains a pointer to an OMPT trace \n record from a trace buffer associated with a device.\n Format \nC / C++ \n typedef ompt_record_ompt_t *(*ompt_get_record_ompt_t) ( \n ompt_buffer_t *buffer, \n ompt_buffer_cursor_t current \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_get_record_ompt runtime entry point, which has type signature \n ompt_get_record_ompt_t, returns a pointer that may point to a record in the trace buffer, or \n it may point to a record in thread-local storage in which the information extracted from a record was \n assembled.The information available for an event depends upon its type.The return value of the \n ompt_record_ompt_t type includes a field of a union type that can represent information for \n any OMPT event record type."}
{"section_title": "19.6.2.12 ompt_get_record_ompt_t", "chunk": "The return value of the \n ompt_record_ompt_t type includes a field of a union type that can represent information for \n any OMPT event record type.Another call to the runtime entry point may overwrite the contents of \n the fields in a record returned by a prior invocation.\n Description of Arguments \n The buffer argument indicates a trace buffer.\n The current argument is an opaque buffer cursor.\n Cross References \n \u2022 Standard Trace Record Type, see Section 19.4.3.4 \n \u2022 ompt_buffer_cursor_t, see Section 19.4.4.8 \n \u2022 ompt_device_t, see Section 19.4.4.5 \nCHAPTER 19.OMPT INTERFACE 535 \n"}
{"section_title": "19.6.2.13 ompt_get_record_native_t", "chunk": "2 Summary \n The ompt_get_record_native_t type is the type signature of the \n ompt_get_record_native runtime entry point, which obtains a pointer to a native trace \n record from a trace buffer associated with a device.\n Format \nC / C++ \n typedef void *(*ompt_get_record_native_t) ( \n ompt_buffer_t *buffer, \n ompt_buffer_cursor_t current, \n ompt_id_t *host_op_id \n ); \nC / C++ \n Semantics \n A device\u2019s ompt_get_record_native runtime entry point, which has type signature \n ompt_get_record_native_t, returns a pointer that may point into the specified trace buffer, \n or into thread-local storage in which the information extracted from a trace record was assembled.\n The information available for a native event depends upon its type.If the function returns a non-null \n result, it will also set the object to which host_op_id points to a host-side identifier for the \n operation that is associated with the record."}
{"section_title": "19.6.2.13 ompt_get_record_native_t", "chunk": "If the function returns a non-null \n result, it will also set the object to which host_op_id points to a host-side identifier for the \n operation that is associated with the record.A subsequent call to ompt_get_record_native \n may overwrite the contents of the fields in a record returned by a prior invocation.\n Description of Arguments \n The buffer argument indicates a trace buffer.\n The current argument is an opaque buffer cursor.\n The host_op_id argument is a pointer to an identifier that is returned by the function.The entry \n point sets the identifier to which host_op_id points to the value of a host-side identifier for an \n operation on a target device that was created when the operation was initiated by the host.\n Cross References \n \u2022 ompt_buffer_cursor_t, see Section 19.4.4.8 \n \u2022 ompt_buffer_t, see Section 19.4.4.7 \n \u2022 ompt_id_t, see Section 19.4.4.3 \n"}
{"section_title": "19.6.2.14 ompt_get_record_abstract_t", "chunk": "31 Summary \n The ompt_get_record_abstract_t type is the type signature of the \n ompt_get_record_abstract runtime entry point, which summarizes the context of a native \n (device-specific) trace record.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC / C++ \n typedef ompt_record_abstract_t *(*ompt_get_record_abstract_t) ( \n void *native_record \n ); \nC / C++ \n Semantics \n An OpenMP implementation may execute on a device that logs trace records in a native \n (device-specific) format that a tool cannot interpret directly.The \n ompt_get_record_abstract runtime entry point of a device, which has type signature \n ompt_get_record_abstract_t, translates a native trace record into a standard form.\n Description of Arguments \n The native_record argument is a pointer to a native trace record.\n Cross References \n \u2022 Native Record Abstract Type, see Section 19.4.3.3 \n"}
{"section_title": "19.6.3 Lookup Entry Points: ompt_function_lookup_t", "chunk": "15 Summary \n The ompt_function_lookup_t type is the type signature of the lookup runtime entry points \n that provide pointers to runtime entry points that are part of the OMPT interface.\n Format \nC / C++ \n typedef void (*ompt_interface_fn_t) (void); \n \n typedef ompt_interface_fn_t (*ompt_function_lookup_t) ( \n const char *interface_function_name \n ); \nC / C++ \n Semantics \n An OpenMP implementation provides pointers to lookup routines that provide pointers to OMPT \n runtime entry points.When the implementation invokes a tool initializer to configure the OMPT \n callback interface, it provides a lookup function that provides pointers to runtime entry points that \n implement routines that are part of the OMPT callback interface."}
{"section_title": "19.6.3 Lookup Entry Points: ompt_function_lookup_t", "chunk": "When the implementation invokes a tool initializer to configure the OMPT \n callback interface, it provides a lookup function that provides pointers to runtime entry points that \n implement routines that are part of the OMPT callback interface.Alternatively, when it invokes a \n tool initializer to configure the OMPT tracing interface for a device, it provides a lookup function \n that provides pointers to runtime entry points that implement tracing control routines appropriate \n for that device.\nCHAPTER 19.OMPT INTERFACE 537 \n If the provided function name is unknown to the OpenMP implementation, the function returns \n NULL.In a compliant implementation, the lookup function provided by the tool initializer for the \n OMPT callback interface returns a valid function pointer for any OMPT runtime entry point name \n listed in Table 19.1."}
{"section_title": "19.6.3 Lookup Entry Points: ompt_function_lookup_t", "chunk": "In a compliant implementation, the lookup function provided by the tool initializer for the \n OMPT callback interface returns a valid function pointer for any OMPT runtime entry point name \n listed in Table 19.1.\n A compliant implementation of a lookup function passed to a tool\u2019s \n ompt_device_initialize callback must provide non-NULL function pointers for all strings \n in Table 19.4, except for ompt_set_trace_ompt and ompt_get_record_ompt, as \n described in Section 19.2.5.\n Description of Arguments \n The interface_function_name argument is a C string that represents the name of a runtime entry \n point.\n Cross References \n \u2022 Entry Points in the OMPT Callback Interface, see Section 19.6.1 \n \u2022 Entry Points in the OMPT Device Tracing Interface, see Section 19.6.2 \n \u2022 Tracing Activity on Target Devices with OMPT, see Section 19.2.5 \n \u2022 ompt_initialize_t, see Section 19.5.1.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "20 OMPD Interface", "chunk": "2 This chapter describes OMPD, which is an interface for third-party tools.Third-party tools exist in \n separate processes from the OpenMP program.To provide OMPD support, an OpenMP \n implementation must provide an OMPD library that the third-party tool can load.An OpenMP \n implementation does not need to maintain any extra information to support OMPD inquiries from \n third-party tools unless it is explicitly instructed to do so.\n OMPD allows third-party tools such as debuggers to inspect the OpenMP state of a live program or \n core file in an implementation-agnostic manner.That is, a third-party tool that uses OMPD should \n work with any conforming OpenMP implementation.An OpenMP implementer provides a library \n for OMPD that a third-party tool can dynamically load.The third-party tool can use the interface \n exported by the OMPD library to inspect the OpenMP state of a program."}
{"section_title": "20 OMPD Interface", "chunk": "The third-party tool can use the interface \n exported by the OMPD library to inspect the OpenMP state of a program.In order to satisfy \n requests from the third-party tool, the OMPD library may need to read data from the OpenMP \n program, or to find the addresses of symbols in it.The OMPD library provides this functionality \n through a callback interface that the third-party tool must instantiate for the OMPD library.\n To use OMPD, the third-party tool loads the OMPD library.The OMPD library exports the API \n that is defined throughout this section, and the third-party tool uses the API to determine OpenMP \n information about the OpenMP program.The OMPD library must look up the symbols and read \n data out of the program.It does not perform these operations directly but instead directs the third\ufffe19 party tool to perform them by using the callback interface that the third-party tool exports."}
{"section_title": "20 OMPD Interface", "chunk": "It does not perform these operations directly but instead directs the third\ufffe19 party tool to perform them by using the callback interface that the third-party tool exports.\n The OMPD design insulates third-party tools from the internal structure of the OpenMP runtime, \n while the OMPD library is insulated from the details of how to access the OpenMP program.This \n decoupled design allows for flexibility in how the OpenMP program and third-party tool are \n deployed, so that, for example, the third-party tool and the OpenMP program are not required to \n execute on the same machine.\n Generally, the third-party tool does not interact directly with the OpenMP runtime but instead \n interacts with the runtime through the OMPD library.However, a few cases require the third-party \n tool to access the OpenMP runtime directly.These cases fall into two broad categories."}
{"section_title": "20 OMPD Interface", "chunk": "These cases fall into two broad categories.The first is \n during initialization where the third-party tool must look up symbols and read variables in the \n OpenMP runtime in order to identify the OMPD library that it should use, which is discussed in \n Section 20.2.2 and Section 20.2.3.The second category relates to arranging for the third-party tool \n to be notified when certain events occur during the execution of the OpenMP program.For this \n purpose, the OpenMP implementation must define certain symbols in the runtime code, as is \n discussed in Section 20.6.Each of these symbols corresponds to an event type.The OpenMP \n runtime must ensure that control passes through the appropriate named location when events occur.\n If the third-party tool requires notification of an event, it can plant a breakpoint at the matching \n \n location.The location can, but may not, be a function.It can, for example, simply be a label."}
{"section_title": "20 OMPD Interface", "chunk": "It can, for example, simply be a label.\n However, the names of the locations must have external C linkage.\n"}
{"section_title": "20.1 OMPD Interfaces Definitions", "chunk": "C / C++ \n A compliant implementation must supply a set of definitions for the OMPD runtime entry points, \n OMPD third-party tool callback signatures, third-party tool interface functions and the special data \n types of their parameters and return values.These definitions, which are listed throughout this \n chapter, and their associated declarations shall be provided in a header file named omp-tools.h.\n In addition, the set of definitions may specify other implementation-specific values.\n The ompd_dll_locations variable, all OMPD third-party tool interface functions, and all \n OMPD runtime entry points are external symbols with C linkage.\nC / C++ \n"}
{"section_title": "20.2 Activating a Third-Party Tool", "chunk": "12 The third-party tool and the OpenMP program exist as separate processes.Thus, coordination is \n required between the OpenMP runtime and the third-party tool for OMPD.\n"}
{"section_title": "20.2.1 Enabling Runtime Support for OMPD", "chunk": "15 In order to support third-party tools, the OpenMP runtime may need to collect and to store \n information that it may not otherwise maintain.The OpenMP runtime collects whatever \n information is necessary to support OMPD if the environment variable OMP_DEBUG is set to \n enabled.\n Cross References \n \u2022 OMP_DEBUG, see Section 21.4.1 \n"}
{"section_title": "20.2.2 ompd_dll_locations", "chunk": "22 Summary \n The ompd_dll_locations global variable points to the locations of OMPD libraries that are \n compatible with the OpenMP implementation.\n Format \nC \n extern const char **ompd_dll_locations; \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n An OpenMP runtime may have more than one OMPD library.The third-party tool must be able to \n locate the right library to use for the OpenMP program that it is examining.The OpenMP runtime \n system must provide a public variable ompd_dll_locations, which is an argv-style vector of \n pathname string pointers that provides the names of any compatible OMPD libraries.This variable \n must have C linkage.The third-party tool uses the name of the variable verbatim and, in particular, \n does not apply any name mangling before performing the look up."}
{"section_title": "20.2.2 ompd_dll_locations", "chunk": "The third-party tool uses the name of the variable verbatim and, in particular, \n does not apply any name mangling before performing the look up.\n The architecture on which the third-party tool and, thus, the OMPD library execute does not have to \n match the architecture on which the OpenMP program that is being examined executes.The \n third-party tool must interpret the contents of ompd_dll_locations to find a suitable OMPD \n library that matches its own architectural characteristics.On platforms that support different \n architectures (for example, 32-bit vs 64-bit), OpenMP implementations are encouraged to provide \n an OMPD library for each supported architecture that can handle OpenMP programs that run on \n any supported architecture.Thus, for example, a 32-bit debugger that uses OMPD should be able to \n debug a 64-bit OpenMP program by loading a 32-bit OMPD implementation that can manage a \n 64-bit OpenMP runtime."}
{"section_title": "20.2.2 ompd_dll_locations", "chunk": "Thus, for example, a 32-bit debugger that uses OMPD should be able to \n debug a 64-bit OpenMP program by loading a 32-bit OMPD implementation that can manage a \n 64-bit OpenMP runtime.\n The ompd_dll_locations variable points to a NULL-terminated vector of zero or more \n null-terminated pathname strings that do not have any filename conventions.This vector must be \n fully initialized before ompd_dll_locations is set to a non-null value.Thus, if a third-party \n tool, such as a debugger, stops execution of the OpenMP program at any point at which \n ompd_dll_locations is non-null, the vector of strings to which it points shall be valid and \n complete.\n Cross References \n \u2022 ompd_dll_locations_valid, see Section 20.2.3 \n"}
{"section_title": "20.2.3 ompd_dll_locations_valid", "chunk": "26 Summary \n The OpenMP runtime notifies third-party tools that ompd_dll_locations is valid by allowing \n execution to pass through a location that the symbol ompd_dll_locations_valid identifies.\n Format \nC \n void ompd_dll_locations_valid(void); \nC \n Semantics \n Since ompd_dll_locations may not be a static variable, it may require runtime initialization.\n The OpenMP runtime notifies third-party tools that ompd_dll_locations is valid by having \n execution pass through a location that the symbol ompd_dll_locations_valid identifies.If \n ompd_dll_locations is NULL, a third-party tool can place a breakpoint at \n ompd_dll_locations_valid to be notified that ompd_dll_locations is initialized.In \n practice, the symbol ompd_dll_locations_valid may not be a function; instead, it may be a \n labeled machine instruction through which execution passes once the vector is valid.\nCHAPTER 20.OMPD INTERFACE 541 \n"}
{"section_title": "20.3 OMPD Data Types", "chunk": "2 This section defines OMPD data types.\n"}
{"section_title": "20.3.1 Size Type", "chunk": "4 Summary \n The ompd_size_t type specifies the number of bytes in opaque data objects that are passed \n across the OMPD API.\n Format \nC / C++ \n typedef uint64_t ompd_size_t; \nC / C++ \n"}
{"section_title": "20.3.2 Wait ID Type", "chunk": "10 Summary \n A variable of ompd_wait_id_t type identifies the object on which a thread waits.\n Format \nC / C++ \n typedef uint64_t ompd_wait_id_t; \nC / C++ \n Semantics \n The values and meaning of ompd_wait_id_t are the same as those defined for the \n ompt_wait_id_t type.\n Cross References \n \u2022 ompt_wait_id_t, see Section 19.4.4.31 \n"}
{"section_title": "20.3.3 Basic Value Types", "chunk": "20 Summary \n These definitions represent word, address, and segment value types.\n Format \nC / C++ \n typedef uint64_t ompd_addr_t; \n typedef int64_t ompd_word_t; \n typedef uint64_t ompd_seg_t; \nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The ompd_addr_t type represents an address in an OpenMP process with an unsigned integer type.\n The ompd_word_t type represents a data word from the OpenMP runtime with a signed integer \n type.The ompd_seg_t type represents a segment value with an unsigned integer type.\n"}
{"section_title": "20.3.4 Address Type", "chunk": "6 Summary \n The ompd_address_t type is used to specify device addresses.\n Format \nC / C++ \n typedef struct ompd_address_t { \n ompd_seg_t segment; \n ompd_addr_t address; \n } ompd_address_t; \nC / C++ \n Semantics \n The ompd_address_t type is a structure that OMPD uses to specify device addresses, which \n may or may not be segmented.For non-segmented architectures, ompd_segment_none is used \n in the segment field of ompd_address_t; it is an instance of the ompd_seg_t type that has the \n value 0.\n Cross References \n \u2022 Basic Value Types, see Section 20.3.3 \n"}
{"section_title": "20.3.5 Frame Information Type", "chunk": "21 Summary \n The ompd_frame_info_t type is used to specify frame information.\n Format \nC / C++ \n typedef struct ompd_frame_info_t { \n ompd_address_t frame_address; \n ompd_word_t frame_flag; \n } ompd_frame_info_t; \nC / C++ \n Semantics \n The ompd_frame_info_t type is a structure that OMPD uses to specify frame information.\n The frame_address field of ompd_frame_info_t identifies a frame.The frame_flag field of \n ompd_frame_info_t indicates what type of information is provided in frame_address.The \n values and meaning is the same as defined for the ompt_frame_flag_t enumeration type.\nCHAPTER 20.OMPD INTERFACE 543 \n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 Basic Value Types, see Section 20.3.3 \n \u2022 ompt_frame_flag_t, see Section 19.4.4.30 \n"}
{"section_title": "20.3.6 System Device Identifiers", "chunk": "6 Summary \n The ompd_device_t type provides information about OpenMP devices.\n Format \nC / C++ \n typedef uint64_t ompd_device_t; \nC / C++ \n Semantics \n OpenMP runtimes may utilize different underlying devices, each represented by a device identifier.\n The device identifiers can vary in size and format and, thus, are not explicitly represented in the \n OMPD interface.Instead, a device identifier is passed across the interface via its \n ompd_device_t kind, its size in bytes and a pointer to where it is stored.The OMPD library and \n the third-party tool use the ompd_device_t kind to interpret the format of the device identifier \n that is referenced by the pointer argument.Each different device identifier kind is represented by a \n unique unsigned 64-bit integer value.Recommended values of ompd_device_t kinds are \n defined in the ompd-types.h header file, which is available on http://www.openmp.org/.\n"}
{"section_title": "20.3.7 Native Thread Identifiers", "chunk": "20 Summary \n The ompd_thread_id_t type provides information about native threads.\n Format \nC / C++ \n typedef uint64_t ompd_thread_id_t; \nC / C++ \n Semantics \n OpenMP runtimes may use different native thread implementations.Native thread identifiers for \n these implementations can vary in size and format and, thus, are not explicitly represented in the \n OMPD interface.Instead, a native thread identifier is passed across the interface via its \n ompd_thread_id_t kind, its size in bytes and a pointer to where it is stored.The OMPD \n library and the third-party tool use the ompd_thread_id_t kind to interpret the format of the \n native thread identifier that is referenced by the pointer argument.Each different native thread \n identifier kind is represented by a unique unsigned 64-bit integer value."}
{"section_title": "20.3.7 Native Thread Identifiers", "chunk": "Each different native thread \n identifier kind is represented by a unique unsigned 64-bit integer value.Recommended values of \n ompd_thread_id_t kinds, and formats for some corresponding native thread identifiers, are \n defined in the ompd-types.h header file, which is available on http://www.openmp.org/.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "20.3.8 OMPD Handle Types", "chunk": "2 Summary \n The OMPD library defines handles for referring to address spaces, threads, parallel regions and \n tasks that are managed by the OpenMP runtime.The internal structures that these handles represent \n are opaque to the third-party tool.\n Format \nC / C++ \n typedef struct _ompd_aspace_handle ompd_address_space_handle_t; \n typedef struct _ompd_thread_handle ompd_thread_handle_t; \n typedef struct _ompd_parallel_handle ompd_parallel_handle_t; \n typedef struct _ompd_task_handle ompd_task_handle_t; \nC / C++ \n Semantics \n OMPD uses handles for the following entities that are managed by the OpenMP runtime: address \n spaces (ompd_address_space_handle_t), threads (ompd_thread_handle_t), parallel \n regions (ompd_parallel_handle_t), and tasks (ompd_task_handle_t).Each operation \n of the OMPD interface that applies to a particular address space, thread, parallel region or task \n must explicitly specify a corresponding handle."}
{"section_title": "20.3.8 OMPD Handle Types", "chunk": "Each operation \n of the OMPD interface that applies to a particular address space, thread, parallel region or task \n must explicitly specify a corresponding handle.Handles are defined by the OMPD library and are \n opaque to the third-party tool.A handle remains constant and valid while the associated entity is \n managed by the OpenMP runtime or until it is released with the corresponding third-party tool \n interface routine for releasing handles of that type.If a tool receives notification of the end of the \n lifetime of a managed entity (see Section 20.6) or it releases the handle, the handle may no longer \n be referenced.\n Defining externally visible type names in this way introduces type safety to the interface, and helps \n to catch instances where incorrect handles are passed by the third-party tool to the OMPD library."}
{"section_title": "20.3.8 OMPD Handle Types", "chunk": "\n Defining externally visible type names in this way introduces type safety to the interface, and helps \n to catch instances where incorrect handles are passed by the third-party tool to the OMPD library.\n The structures do not need to be defined; instead, the OMPD library must cast incoming (pointers \n to) handles to the appropriate internal, private types.\n"}
{"section_title": "20.3.9 OMPD Scope Types", "chunk": "27 Summary \n The ompd_scope_t type identifies OMPD scopes.\n Format \nC / C++ \n typedef enum ompd_scope_t { \n ompd_scope_global = 1, \n ompd_scope_address_space = 2, \n ompd_scope_thread = 3, \n ompd_scope_parallel = 4, \n ompd_scope_implicit_task = 5, \n ompd_scope_task = 6 \n } ompd_scope_t; \nC / C++ \nCHAPTER 20.OMPD INTERFACE 545 \n Semantics \n The ompd_scope_t type identifies OpenMP scopes, including those related to parallel regions \n and tasks.When used in an OMPD interface function call, the scope type and the OMPD handle \n must match according to Table 20.1.\nTABLE 20.1: Mapping of Scope Type and OMPD Handles \nScope types Handles \nompd_scope_global Address space handle for the host device \nompd_scope_address_space Any address space handle \nompd_scope_thread Any thread handle \nompd_scope_parallel Any parallel region handle \nompd_scope_implicit_task Task handle for an implicit task \nompd_scope_task Any task handle \n"}
{"section_title": "20.3.10 ICV ID Type", "chunk": "6 Summary \n The ompd_icv_id_t type identifies an OpenMP implementation ICV.\n Format \nC / C++ \n typedef uint64_t ompd_icv_id_t; \nC / C++ \n Semantics \n The ompd_icv_id_t type identifies OpenMP implementation ICVs.ompd_icv_undefined \n is an instance of this type with the value 0.\n"}
{"section_title": "20.3.11 Tool Context Types", "chunk": "14 Summary \n A third-party tool defines contexts to identify abstractions uniquely.The internal structures that \n these contexts represent are opaque to the OMPD library.\n Format \nC / C++ \n typedef struct _ompd_aspace_cont ompd_address_space_context_t; \n typedef struct _ompd_thread_cont ompd_thread_context_t; \nC / C++ \n Semantics \n A third-party tool uniquely defines an address space context to identify the address space for the \n process that it is monitoring.Similarly, it uniquely defines a thread context to identify a native \n thread of the process that it is monitoring.These contexts are opaque to the OMPD library.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "20.3.12 Return Code Types", "chunk": "2 Summary \n The ompd_rc_t type is the return code type of an OMPD operation.\n Format \nC / C++ \n typedef enum ompd_rc_t { \n ompd_rc_ok = 0, \n ompd_rc_unavailable = 1, \n ompd_rc_stale_handle = 2, \n ompd_rc_bad_input = 3, \n ompd_rc_error = 4, \n ompd_rc_unsupported = 5, \n ompd_rc_needs_state_tracking = 6, \n ompd_rc_incompatible = 7, \n ompd_rc_device_read_error = 8, \n ompd_rc_device_write_error = 9, \n ompd_rc_nomem = 10, \n ompd_rc_incomplete = 11, \n ompd_rc_callback_error = 12 \n } ompd_rc_t; \nC / C++ \n Semantics \n The ompd_rc_t type is used for the return codes of OMPD operations."}
{"section_title": "20.3.12 Return Code Types", "chunk": "\n Format \nC / C++ \n typedef enum ompd_rc_t { \n ompd_rc_ok = 0, \n ompd_rc_unavailable = 1, \n ompd_rc_stale_handle = 2, \n ompd_rc_bad_input = 3, \n ompd_rc_error = 4, \n ompd_rc_unsupported = 5, \n ompd_rc_needs_state_tracking = 6, \n ompd_rc_incompatible = 7, \n ompd_rc_device_read_error = 8, \n ompd_rc_device_write_error = 9, \n ompd_rc_nomem = 10, \n ompd_rc_incomplete = 11, \n ompd_rc_callback_error = 12 \n } ompd_rc_t; \nC / C++ \n Semantics \n The ompd_rc_t type is used for the return codes of OMPD operations.The return code types and \n their semantics are defined as follows: \n \u2022 ompd_rc_ok is returned when the operation is successful; \n \u2022 ompd_rc_unavailable is returned when information is not available for the specified \n context; \n \u2022 ompd_rc_stale_handle is returned when the specified handle is no longer valid; \n \u2022 ompd_rc_bad_input is returned when the input parameters (other than handle) are invalid; \n \u2022 ompd_rc_error is returned when a fatal error occurred; \n \u2022 ompd_rc_unsupported is returned when the requested operation is not supported; \n \u2022 ompd_rc_needs_state_tracking is returned when the state tracking operation failed \n because state tracking is not currently enabled; \n \u2022 ompd_rc_device_read_error is returned when a read operation failed on the device; \n \u2022 ompd_rc_device_write_error is returned when a write operation failed on the device; \n \u2022 ompd_rc_incompatible is returned when this OMPD library is incompatible with the \n OpenMP program or is not capable of handling it; \nCHAPTER 20."}
{"section_title": "20.3.12 Return Code Types", "chunk": "The return code types and \n their semantics are defined as follows: \n \u2022 ompd_rc_ok is returned when the operation is successful; \n \u2022 ompd_rc_unavailable is returned when information is not available for the specified \n context; \n \u2022 ompd_rc_stale_handle is returned when the specified handle is no longer valid; \n \u2022 ompd_rc_bad_input is returned when the input parameters (other than handle) are invalid; \n \u2022 ompd_rc_error is returned when a fatal error occurred; \n \u2022 ompd_rc_unsupported is returned when the requested operation is not supported; \n \u2022 ompd_rc_needs_state_tracking is returned when the state tracking operation failed \n because state tracking is not currently enabled; \n \u2022 ompd_rc_device_read_error is returned when a read operation failed on the device; \n \u2022 ompd_rc_device_write_error is returned when a write operation failed on the device; \n \u2022 ompd_rc_incompatible is returned when this OMPD library is incompatible with the \n OpenMP program or is not capable of handling it; \nCHAPTER 20.OMPD INTERFACE 547 \n \u2022 ompd_rc_nomem is returned when a memory allocation fails; \n \u2022 ompd_rc_incomplete is returned when the information provided on return is incomplete, \n while the arguments are still set to valid values; and \n \u2022 ompd_rc_callback_error is returned when the callback interface or any one of the \n required callback routines provided by the third-party tool is invalid."}
{"section_title": "20.3.12 Return Code Types", "chunk": "OMPD INTERFACE 547 \n \u2022 ompd_rc_nomem is returned when a memory allocation fails; \n \u2022 ompd_rc_incomplete is returned when the information provided on return is incomplete, \n while the arguments are still set to valid values; and \n \u2022 ompd_rc_callback_error is returned when the callback interface or any one of the \n required callback routines provided by the third-party tool is invalid.\n"}
{"section_title": "20.3.13 Primitive Type Sizes", "chunk": "7 Summary \n The ompd_device_type_sizes_t type provides the size of primitive types in the OpenMP \n architecture address space.\n Format \nC / C++ \n typedef struct ompd_device_type_sizes_t { \n uint8_t sizeof_char; \n uint8_t sizeof_short; \n uint8_t sizeof_int; \n uint8_t sizeof_long; \n uint8_t sizeof_long_long; \n uint8_t sizeof_pointer; \n } ompd_device_type_sizes_t; \nC / C++ \n Semantics \n The ompd_device_type_sizes_t type is used in operations through which the OMPD \n library can interrogate the third-party tool about the size of primitive types for the target \n architecture of the OpenMP runtime, as returned by the sizeof operator.The fields of \n ompd_device_type_sizes_t give the sizes of the eponymous basic types used by the \n OpenMP runtime.As the third-party tool and the OMPD library, by definition, execute on the same \n architecture, the size of the fields can be given as uint8_t."}
{"section_title": "20.3.13 Primitive Type Sizes", "chunk": "As the third-party tool and the OMPD library, by definition, execute on the same \n architecture, the size of the fields can be given as uint8_t.\n Cross References \n \u2022 ompd_callback_sizeof_fn_t, see Section 20.4.2.2 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "20.4 OMPD Third-Party Tool Callback Interface", "chunk": "2 For the OMPD library to provide information about the internal state of the OpenMP runtime \n system in an OpenMP process or core file, it must have a means to extract information from the \n OpenMP process that the third-party tool is examining.The OpenMP process on which the \n third-party tool is operating may be either a \u201clive\u201d process or a core file, and a thread may be either \n a \u201clive\u201d thread in an OpenMP process or a thread in a core file.To enable the OMPD library to \n extract state information from an OpenMP process or core file, the third-party tool must supply the \n OMPD library with callback functions to inquire about the size of primitive types in the device of \n the OpenMP process, to look up the addresses of symbols, and to read and to write memory in the \n device.The OMPD library uses these callbacks to implement its interface operations."}
{"section_title": "20.4 OMPD Third-Party Tool Callback Interface", "chunk": "The OMPD library uses these callbacks to implement its interface operations.The OMPD \n library only invokes the callback functions in direct response to calls made by the third-party tool to \n the OMPD library.\n Description of Return Codes \n All of the OMPD callback functions must return the following return codes or function-specific \n return codes: \n \u2022 ompd_rc_ok on success; or \n \u2022 ompd_rc_stale_handle if an invalid context argument is provided.\n"}
{"section_title": "20.4.1 Memory Management of OMPD Library", "chunk": "19 ompd_callback_memory_alloc_fn_t (see Section 20.4.1.1) and \n ompd_callback_memory_free_fn_t (see Section 20.4.1.2) are provided by the third-party \n tool to obtain and to release heap memory.This mechanism ensures that the library does not \n interfere with any custom memory management scheme that the third-party tool may use.\n If the OMPD library is implemented in C++ then memory management operators, like new and \n delete and their variants, must all be overloaded and implemented in terms of the callbacks that \n the third-party tool provides.The OMPD library must be implemented in a manner such that any of \n its definitions of new or delete do not interfere with any that the third-party tool defines.\n In some cases, the OMPD library must allocate memory to return results to the third-party tool.\n The third-party tool then owns this memory and has the responsibility to release it.Thus, the \n OMPD library and the third-party tool must use the same memory manager."}
{"section_title": "20.4.1 Memory Management of OMPD Library", "chunk": "Thus, the \n OMPD library and the third-party tool must use the same memory manager.\n The OMPD library creates OMPD handles, which are opaque to the third-party tool and may have a \n complex internal structure.The third-party tool cannot determine if the handle pointers that the \n API returns correspond to discrete heap allocations.Thus, the third-party tool must not simply \n deallocate a handle by passing an address that it receives from the OMPD library to its own \n memory manager.Instead, the OMPD API includes functions that the third-party tool must use \n when it no longer needs a handle.\nCHAPTER 20.OMPD INTERFACE 549 \n A third-party tool creates contexts and passes them to the OMPD library.The OMPD library does \n not release contexts; instead the third-party tool releases them after it releases any handles that may \n reference the contexts.\n"}
{"section_title": "20.4.1.1 ompd_callback_memory_alloc_fn_t", "chunk": "5 Summary \n The ompd_callback_memory_alloc_fn_t type is the type signature of the callback routine \n that the third-party tool provides to the OMPD library to allocate memory.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_memory_alloc_fn_t) ( \n ompd_size_t nbytes, \n void **ptr \n ); \nC \n Semantics \n The ompd_callback_memory_alloc_fn_t type is the type signature of the memory \n allocation callback routine that the third-party tool provides.The OMPD library may call the \n ompd_callback_memory_alloc_fn_t callback function to allocate memory.\n Description of Arguments \n The nbytes argument is the size in bytes of the block of memory to allocate.\n The address of the newly allocated block of memory is returned in the location to which the ptr \n argument points.The newly allocated block is suitably aligned for any type of variable and is not \n guaranteed to be set to zero."}
{"section_title": "20.4.1.1 ompd_callback_memory_alloc_fn_t", "chunk": "The newly allocated block is suitably aligned for any type of variable and is not \n guaranteed to be set to zero.\n Description of Return Codes \n Routines that use the ompd_callback_memory_alloc_fn_t type may return the general \n return codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 The Callback Interface, see Section 20.4.6 \n"}
{"section_title": "20.4.1.2 ompd_callback_memory_free_fn_t", "chunk": "30 Summary \n The ompd_callback_memory_free_fn_t type is the type signature of the callback routine \n that the third-party tool provides to the OMPD library to deallocate memory.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n typedef ompd_rc_t (*ompd_callback_memory_free_fn_t) ( \n void *ptr \n ); \nC \n Semantics \n The ompd_callback_memory_free_fn_t type is the type signature of the memory \n deallocation callback routine that the third-party tool provides.The OMPD library may call the \n ompd_callback_memory_free_fn_t callback function to deallocate memory that was \n obtained from a prior call to the ompd_callback_memory_alloc_fn_t callback function.\n Description of Arguments \n The ptr argument is the address of the block to be deallocated.\n Description of Return Codes \n Routines that use the ompd_callback_memory_free_fn_t type may return the general \n return codes listed at the beginning of Section 20.4."}
{"section_title": "20.4.1.2 ompd_callback_memory_free_fn_t", "chunk": "\n Description of Return Codes \n Routines that use the ompd_callback_memory_free_fn_t type may return the general \n return codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 ompd_callback_memory_alloc_fn_t, see Section 20.4.1.1 \n"}
{"section_title": "20.4.2 Context Management and Navigation", "chunk": "20 Summary \n The third-party tool provides the OMPD library with callbacks to manage and to navigate context \n relationships.\n"}
{"section_title": "20.4.2.1 ompd_callback_get_thread_context_for_thread_id_fn_t", "chunk": "24 Summary \n The ompd_callback_get_thread_context_for_thread_id_fn_t is the type \n signature of the callback routine that the third-party tool provides to the OMPD library to map a \n native thread identifier to a third-party tool thread context.\nCHAPTER 20.OMPD INTERFACE 551 \n Format \nC \n typedef ompd_rc_t \n (*ompd_callback_get_thread_context_for_thread_id_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n ompd_thread_id_t kind, \n ompd_size_t sizeof_thread_id, \n const void *thread_id, \n ompd_thread_context_t **thread_context \n ); \nC \n Semantics \n The ompd_callback_get_thread_context_for_thread_id_fn_t is the type \n signature of the context mapping callback routine that the third-party tool provides.This callback \n maps a native thread identifier to a third-party tool thread context.The native thread identifier is \n within the address space that address_space_context identifies."}
{"section_title": "20.4.2.1 ompd_callback_get_thread_context_for_thread_id_fn_t", "chunk": "The native thread identifier is \n within the address space that address_space_context identifies.The OMPD library can use the \n thread context, for example, to access thread local storage.\n Description of Arguments \n The address_space_context argument is an opaque handle that the third-party tool provides to \n reference an address space.The kind, sizeof_thread_id, and thread_id arguments represent a native \n thread identifier.On return, the thread_context argument provides an opaque handle that maps a \n native thread identifier to a third-party tool thread context."}
{"section_title": "20.4.2.1 ompd_callback_get_thread_context_for_thread_id_fn_t", "chunk": "On return, the thread_context argument provides an opaque handle that maps a \n native thread identifier to a third-party tool thread context.\n Description of Return Codes \n In addition to the general return codes listed at the beginning of Section 20.4, routines that use the \n ompd_callback_get_thread_context_for_thread_id_fn_t type may also return \n the following return codes: \n \u2022 ompd_rc_bad_input if a different value in sizeof_thread_id is expected for the native thread \n identifier kind given by kind; or \n \u2022 ompd_rc_unsupported if the native thread identifier kind is not supported.\n Restrictions \n Restrictions on routines that use \n ompd_callback_get_thread_context_for_thread_id_fn_t are as follows: \n \u2022 The provided thread_context must be valid until the OMPD library returns from the OMPD \n third-party tool interface routine."}
{"section_title": "20.4.2.1 ompd_callback_get_thread_context_for_thread_id_fn_t", "chunk": "\n Restrictions \n Restrictions on routines that use \n ompd_callback_get_thread_context_for_thread_id_fn_t are as follows: \n \u2022 The provided thread_context must be valid until the OMPD library returns from the OMPD \n third-party tool interface routine.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Native Thread Identifiers, see Section 20.3.7 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.4.2.2 ompd_callback_sizeof_fn_t", "chunk": "8 Summary \n The ompd_callback_sizeof_fn_t type is the type signature of the callback routine that the \n third-party tool provides to the OMPD library to determine the sizes of the primitive types in an \n address space.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_sizeof_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n ompd_device_type_sizes_t *sizes \n ); \nC \n Semantics \n The ompd_callback_sizeof_fn_t is the type signature of the type-size query callback \n routine that the third-party tool provides.This callback provides the sizes of the basic primitive \n types for a given address space.\n Description of Arguments \n The callback returns the sizes of the basic primitive types used by the address space context that the \n address_space_context argument specifies in the location to which the sizes argument points."}
{"section_title": "20.4.2.2 ompd_callback_sizeof_fn_t", "chunk": "\n Description of Arguments \n The callback returns the sizes of the basic primitive types used by the address space context that the \n address_space_context argument specifies in the location to which the sizes argument points.\n Description of Return Codes \n Routines that use the ompd_callback_sizeof_fn_t type may return the general return \n codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Primitive Type Sizes, see Section 20.3.13 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \nCHAPTER 20.OMPD INTERFACE 553 \n"}
{"section_title": "20.4.3 Accessing Memory in the OpenMP Program or Runtime", "chunk": "2 Runtime \n The OMPD library cannot directly read from or write to memory of the OpenMP program.Instead \n the OMPD library must use callbacks that the third-party tool provides so that the third-party tool \n performs the operation.\n"}
{"section_title": "20.4.3.1 ompd_callback_symbol_addr_fn_t", "chunk": "7 Summary \n The ompd_callback_symbol_addr_fn_t type is the type signature of the callback that the \n third-party tool provides to look up the addresses of symbols in an OpenMP program.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_symbol_addr_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n ompd_thread_context_t *thread_context, \n const char *symbol_name, \n ompd_address_t *symbol_addr, \n const char *file_name \n ); \nC \n Semantics \n The ompd_callback_symbol_addr_fn_t is the type signature of the symbol-address query \n callback routine that the third-party tool provides.This callback looks up addresses of symbols \n within a specified address space.\n Description of Arguments \n This callback looks up the symbol provided in the symbol_name argument.\n The address_space_context argument is the third-party tool\u2019s representation of the address space of \n the process, core file, or device."}
{"section_title": "20.4.3.1 ompd_callback_symbol_addr_fn_t", "chunk": "\n The address_space_context argument is the third-party tool\u2019s representation of the address space of \n the process, core file, or device.\n The thread_context argument is NULL for global memory accesses.If thread_context is not NULL, \n thread_context gives the thread-specific context for the symbol lookup for the purpose of \n calculating thread local storage addresses.In this case, the thread to which thread_context refers \n must be associated with either the process or the device that corresponds to the \n address_space_context argument.\n The third-party tool uses the symbol_name argument that the OMPD library supplies verbatim.In \n particular, no name mangling, demangling or other transformations are performed prior to the \n lookup.The symbol_name parameter must correspond to a statically allocated symbol within the \n specified address space."}
{"section_title": "20.4.3.1 ompd_callback_symbol_addr_fn_t", "chunk": "The symbol_name parameter must correspond to a statically allocated symbol within the \n specified address space.The symbol can correspond to any type of object, such as a variable, \n thread local storage variable, function, or untyped label.The symbol can have local, global, or \n weak binding.\n OpenMP API \u2013 Version 5.2 November 2021 \n The file_name argument is an optional input parameter that indicates the name of the shared library \n in which the symbol is defined, and it is intended to help the third-party tool disambiguate symbols \n that are defined multiple times across the executable or shared library files.The shared library name \n may not be an exact match for the name seen by the third-party tool."}
{"section_title": "20.4.3.1 ompd_callback_symbol_addr_fn_t", "chunk": "The shared library name \n may not be an exact match for the name seen by the third-party tool.If file_name is NULL then the \n third-party tool first tries to find the symbol in the executable file, and, if the symbol is not found, \n the third-party tool tries to find the symbol in the shared libraries in the order in which the shared \n libraries are loaded into the address space.If file_name is non-null then the third-party tool first \n tries to find the symbol in the libraries that match the name in the file_name argument, and, if the \n symbol is not found, the third-party tool then uses the same procedure as when file_name is NULL.\n The callback does not support finding either symbols that are dynamically allocated on the call \n stack or statically allocated symbols that are defined within the scope of a function or subroutine.\n The callback returns the address of the symbol in the location to which symbol_addr points."}
{"section_title": "20.4.3.1 ompd_callback_symbol_addr_fn_t", "chunk": "\n The callback returns the address of the symbol in the location to which symbol_addr points.\n Description of Return Codes \n In addition to the general return codes listed at the beginning of Section 20.4, routines that use the \n ompd_callback_symbol_addr_fn_t type may also return the following return codes: \n \u2022 ompd_rc_error if the requested symbol is not found; or \n \u2022 ompd_rc_bad_input if no symbol name is provided.\n Restrictions \n Restrictions on routines that use the ompd_callback_symbol_addr_fn_t type are as \n follows: \n \u2022 The address_space_context argument must be non-null.\n \u2022 The symbol that the symbol_name argument specifies must be defined.\n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.4.3.2 ompd_callback_memory_read_fn_t", "chunk": "29 Summary \n The ompd_callback_memory_read_fn_t type is the type signature of the callback that the \n third-party tool provides to read data (read_memory) or a string (read_string) from an OpenMP \n program.\nCHAPTER 20.OMPD INTERFACE 555 \n Format \nC \n typedef ompd_rc_t (*ompd_callback_memory_read_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n ompd_thread_context_t *thread_context, \n const ompd_address_t *addr, \n ompd_size_t nbytes, \n void *buffer \n ); \nC \n Semantics \n The ompd_callback_memory_read_fn_t is the type signature of the read callback routines \n that the third-party tool provides.\n The read_memory callback copies a block of data from addr within the address space given by \n address_space_context to the third-party tool buffer.\n The read_string callback copies a string to which addr points, including the terminating null byte \n (\u2019\\0\u2019), to the third-party tool buffer.At most nbytes bytes are copied."}
{"section_title": "20.4.3.2 ompd_callback_memory_read_fn_t", "chunk": "At most nbytes bytes are copied.If a null byte is not among \n the first nbytes bytes, the string placed in buffer is not null-terminated.\n Description of Arguments \n The address from which the data are to be read in the OpenMP program that \n address_space_context specifies is given by addr.The nbytes argument is the number of bytes to \n be transferred.The thread_context argument for global memory accesses should be NULL.If it is \n non-null, thread_context identifies the thread-specific context for the memory access for the \n purpose of accessing thread local storage.\n The data are returned through buffer, which is allocated and owned by the OMPD library.The \n contents of the buffer are unstructured, raw bytes.The OMPD library must arrange for any \n transformations such as byte-swapping that may be necessary (see Section 20.4.4) to interpret the \n data."}
{"section_title": "20.4.3.2 ompd_callback_memory_read_fn_t", "chunk": "The OMPD library must arrange for any \n transformations such as byte-swapping that may be necessary (see Section 20.4.4) to interpret the \n data.\n Description of Return Codes \n In addition to the general return codes listed at the beginning of Section 20.4, routines that use the \n ompd_callback_memory_read_fn_t type may also return the following return codes: \n \u2022 ompd_rc_incomplete if no terminating null byte is found while reading nbytes using the \n read_string callback; or \n \u2022 ompd_rc_error if unallocated memory is reached while reading nbytes using either the \n read_memory or read_string callback.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 Data Format Conversion: ompd_callback_device_host_fn_t, see Section 20.4.4 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.4.3.3 ompd_callback_memory_write_fn_t", "chunk": "9 Summary \n The ompd_callback_memory_write_fn_t type is the type signature of the callback that \n the third-party tool provides to write data to an OpenMP program.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_memory_write_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n ompd_thread_context_t *thread_context, \n const ompd_address_t *addr, \n ompd_size_t nbytes, \n const void *buffer \n ); \nC \n Semantics \n The ompd_callback_memory_write_fn_t is the type signature of the write callback \n routine that the third-party tool provides.The OMPD library may call this callback to have the \n third-party tool write a block of data to a location within an address space from a provided buffer.\n Description of Arguments \n The address to which the data are to be written in the OpenMP program that address_space_context \n specifies is given by addr.The nbytes argument is the number of bytes to be transferred."}
{"section_title": "20.4.3.3 ompd_callback_memory_write_fn_t", "chunk": "The nbytes argument is the number of bytes to be transferred.The \n thread_context argument for global memory accesses should be NULL.If it is non-null, then \n thread_context identifies the thread-specific context for the memory access for the purpose of \n accessing thread local storage.\n The data to be written are passed through buffer, which is allocated and owned by the OMPD \n library.The contents of the buffer are unstructured, raw bytes.The OMPD library must arrange for \n any transformations such as byte-swapping that may be necessary (see Section 20.4.4) to render the \n data into a form that is compatible with the OpenMP runtime.\nCHAPTER 20.OMPD INTERFACE 557 \n Description of Return Codes \n Routines that use the ompd_callback_memory_write_fn_t type may return the general \n return codes listed at the beginning of Section 20.4."}
{"section_title": "20.4.3.3 ompd_callback_memory_write_fn_t", "chunk": "OMPD INTERFACE 557 \n Description of Return Codes \n Routines that use the ompd_callback_memory_write_fn_t type may return the general \n return codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 Data Format Conversion: ompd_callback_device_host_fn_t, see Section 20.4.4 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.4.4 Data Format Conversion: ompd_callback_device_host_fn_t", "chunk": "12 ompd_callback_device_host_fn_t \n Summary \n The ompd_callback_device_host_fn_t type is the type signature of the callback that the \n third-party tool provides to convert data between the formats that the third-party tool and the \n OMPD library use and that the OpenMP program uses.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_device_host_fn_t) ( \n ompd_address_space_context_t *address_space_context, \n const void *input, \n ompd_size_t unit_size, \n ompd_size_t count, \n void *output \n ); \nC \n Semantics \n The architecture on which the third-party tool and the OMPD library execute may be different from \n the architecture on which the OpenMP program that is being examined executes.Thus, the \n conventions for representing data may differ.The callback interface includes operations to convert \n between the conventions, such as the byte order (endianness), that the third-party tool and OMPD \n library use and the ones that the OpenMP program use."}
{"section_title": "20.4.4 Data Format Conversion: ompd_callback_device_host_fn_t", "chunk": "The callback interface includes operations to convert \n between the conventions, such as the byte order (endianness), that the third-party tool and OMPD \n library use and the ones that the OpenMP program use.The callback with the \n ompd_callback_device_host_fn_t type signature converts data between the formats.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The address_space_context argument specifies the OpenMP address space that is associated with \n the data.The input argument is the source buffer and the output argument is the destination buffer.\n The unit_size argument is the size of each of the elements to be converted.The count argument is \n the number of elements to be transformed.\n The OMPD library allocates and owns the input and output buffers.It must ensure that the buffers \n have the correct size and are eventually deallocated when they are no longer needed."}
{"section_title": "20.4.4 Data Format Conversion: ompd_callback_device_host_fn_t", "chunk": "It must ensure that the buffers \n have the correct size and are eventually deallocated when they are no longer needed.\n Description of Return Codes \n Routines that use the ompd_callback_device_host_fn_t type may return the general \n return codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.4.5 ompd_callback_print_string_fn_t", "chunk": "17 Summary \n The ompd_callback_print_string_fn_t type is the type signature of the callback that \n the third-party tool provides so that the OMPD library can emit output.\n Format \nC \n typedef ompd_rc_t (*ompd_callback_print_string_fn_t) ( \n const char *string, \n int category \n ); \nC \n Semantics \n The OMPD library may call the ompd_callback_print_string_fn_t callback function to \n emit output, such as logging or debug information.The third-party tool may set the \n ompd_callback_print_string_fn_t callback function to NULL to prevent the OMPD \n library from emitting output.The OMPD library may not write to file descriptors that it did not \n open.\n Description of Arguments \n The string argument is the null-terminated string to be printed.No conversion or formatting is \n performed on the string.\n The category argument is the implementation-defined category of the string to be printed.\nCHAPTER 20."}
{"section_title": "20.4.5 ompd_callback_print_string_fn_t", "chunk": "\nCHAPTER 20.OMPD INTERFACE 559 \n Description of Return Codes \n Routines that use the ompd_callback_print_string_fn_t type may return the general \n return codes listed at the beginning of Section 20.4.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 The Callback Interface, see Section 20.4.6 \n"}
{"section_title": "20.4.6 The Callback Interface", "chunk": "8 Summary \n All OMPD library interactions with the OpenMP program must be through a set of callbacks that \n the third-party tool provides.These callbacks must also be used for allocating or releasing \n resources, such as memory, that the OMPD library needs."}
{"section_title": "20.4.6 The Callback Interface", "chunk": "These callbacks must also be used for allocating or releasing \n resources, such as memory, that the OMPD library needs.\n Format \nC \n typedef struct ompd_callbacks_t { \n ompd_callback_memory_alloc_fn_t alloc_memory; \n ompd_callback_memory_free_fn_t free_memory; \n ompd_callback_print_string_fn_t print_string; \n ompd_callback_sizeof_fn_t sizeof_type; \n ompd_callback_symbol_addr_fn_t symbol_addr_lookup; \n ompd_callback_memory_read_fn_t read_memory; \n ompd_callback_memory_write_fn_t write_memory; \n ompd_callback_memory_read_fn_t read_string; \n ompd_callback_device_host_fn_t device_to_host; \n ompd_callback_device_host_fn_t host_to_device; \n ompd_callback_get_thread_context_for_thread_id_fn_t \n get_thread_context_for_thread_id; \n } ompd_callbacks_t; \nC \n Semantics \n The set of callbacks that the OMPD library must use is collected in the ompd_callbacks_t \n structure."}
{"section_title": "20.4.6 The Callback Interface", "chunk": "\n Format \nC \n typedef struct ompd_callbacks_t { \n ompd_callback_memory_alloc_fn_t alloc_memory; \n ompd_callback_memory_free_fn_t free_memory; \n ompd_callback_print_string_fn_t print_string; \n ompd_callback_sizeof_fn_t sizeof_type; \n ompd_callback_symbol_addr_fn_t symbol_addr_lookup; \n ompd_callback_memory_read_fn_t read_memory; \n ompd_callback_memory_write_fn_t write_memory; \n ompd_callback_memory_read_fn_t read_string; \n ompd_callback_device_host_fn_t device_to_host; \n ompd_callback_device_host_fn_t host_to_device; \n ompd_callback_get_thread_context_for_thread_id_fn_t \n get_thread_context_for_thread_id; \n } ompd_callbacks_t; \nC \n Semantics \n The set of callbacks that the OMPD library must use is collected in the ompd_callbacks_t \n structure.An instance of this type is passed to the OMPD library as a parameter to \n ompd_initialize (see Section 20.5.1.1)."}
{"section_title": "20.4.6 The Callback Interface", "chunk": "An instance of this type is passed to the OMPD library as a parameter to \n ompd_initialize (see Section 20.5.1.1).Each field points to a function that the OMPD library \n must use either to interact with the OpenMP program or for memory operations.\n The alloc_memory and free_memory fields are pointers to functions the OMPD library uses to \n allocate and to release dynamic memory.\n The print_string field points to a function that prints a string.\n The architecture on which the OMPD library and third-party tool execute may be different from the \n architecture on which the OpenMP program that is being examined executes.The sizeof_type field \n OpenMP API \u2013 Version 5.2 November 2021 \n points to a function that allows the OMPD library to determine the sizes of the basic integer and \n pointer types that the OpenMP program uses."}
{"section_title": "20.4.6 The Callback Interface", "chunk": "The sizeof_type field \n OpenMP API \u2013 Version 5.2 November 2021 \n points to a function that allows the OMPD library to determine the sizes of the basic integer and \n pointer types that the OpenMP program uses.Because of the potential differences in the targeted \n architectures, the conventions for representing data in the OMPD library and the OpenMP program \n may be different.The device_to_host field points to a function that translates data from the \n conventions that the OpenMP program uses to those that the third-party tool and OMPD library \n use.The reverse operation is performed by the function to which the host_to_device field points.\n The symbol_addr_lookup field points to a callback that the OMPD library can use to find the \n address of a global or thread local storage symbol.The read_memory, read_string and \n write_memory fields are pointers to functions for reading from and writing to global memory or \n thread local storage in the OpenMP program."}
{"section_title": "20.4.6 The Callback Interface", "chunk": "The read_memory, read_string and \n write_memory fields are pointers to functions for reading from and writing to global memory or \n thread local storage in the OpenMP program.\n The get_thread_context_for_thread_id field is a pointer to a function that the OMPD library can \n use to obtain a thread context that corresponds to a native thread identifier.\n Cross References \n \u2022 Data Format Conversion: ompd_callback_device_host_fn_t, see Section 20.4.4 \n \u2022 ompd_callback_get_thread_context_for_thread_id_fn_t, see \n Section 20.4.2.1 \n \u2022 ompd_callback_memory_alloc_fn_t, see Section 20.4.1.1 \n \u2022 ompd_callback_memory_free_fn_t, see Section 20.4.1.2 \n \u2022 ompd_callback_memory_read_fn_t, see Section 20.4.3.2 \n \u2022 ompd_callback_memory_write_fn_t, see Section 20.4.3.3 \n \u2022 ompd_callback_print_string_fn_t, see Section 20.4.5 \n \u2022 ompd_callback_sizeof_fn_t, see Section 20.4.2.2 \n \u2022 ompd_callback_symbol_addr_fn_t, see Section 20.4.3.1 \n"}
{"section_title": "20.5 OMPD Tool Interface Routines", "chunk": "25 This section defines the interface provided by the OMPD library to be used by the third-party tool.\n Some interface routines require one or more specified threads to be stopped for the returned values \n to be meaningful.In this context, a stopped thread is a thread that is not modifying the observable \n OpenMP runtime state.\n Description of Return Codes \n All of the OMPD Tool Interface Routines must return function-specific return codes or any of the \n following return codes: \n \u2022 ompd_rc_stale_handle if a provided handle is stale; \n \u2022 ompd_rc_bad_input if an invalid value is provided for any input argument; \nCHAPTER 20.OMPD INTERFACE 561 \n \u2022 ompd_rc_callback if a callback returned an unexpected error, which leads to a failure of the \n query; \n \u2022 ompd_rc_needs_state_tracking if the information cannot be provided while the \n debug-var is disabled; \n \u2022 ompd_rc_ok on success; or \n \u2022 ompd_rc_error for any other error.\n"}
{"section_title": "20.5.1 Per OMPD Library Initialization and Finalization", "chunk": "8 The OMPD library must be initialized exactly once after it is loaded, and finalized exactly once \n before it is unloaded.Per OpenMP process or core file initialization and finalization are also \n required.Once loaded, the tool can determine the version of the OMPD API that the library \n supports by calling ompd_get_api_version (see Section 20.5.1.2).If the tool supports the \n version that ompd_get_api_version returns, the tool starts the initialization by calling \n ompd_initialize (see Section 20.5.1.1) using the version of the OMPD API that the library \n supports.If the tool does not support the version that ompd_get_api_version returns, it may \n attempt to call ompd_initialize with a different version.\n"}
{"section_title": "20.5.1.1 ompd_initialize", "chunk": "17 Summary \n The ompd_initialize function initializes the OMPD library.\n Format \nC \n ompd_rc_t ompd_initialize( \n ompd_word_t api_version, \n const ompd_callbacks_t *callbacks \n ); \nC \n Semantics \n A tool that uses OMPD calls ompd_initialize to initialize each OMPD library that it loads.\n More than one library may be present in a third-party tool, such as a debugger, because the tool \n may control multiple devices, which may use different runtime systems that require different \n OMPD libraries.This initialization must be performed exactly once before the tool can begin to \n operate on an OpenMP process or core file.\n Description of Arguments \n The api_version argument is the OMPD API version that the tool requests to use.The tool may call \n ompd_get_api_version to obtain the latest OMPD API version that the OMPD library \n supports."}
{"section_title": "20.5.1.1 ompd_initialize", "chunk": "The tool may call \n ompd_get_api_version to obtain the latest OMPD API version that the OMPD library \n supports.\n OpenMP API \u2013 Version 5.2 November 2021 \n The tool provides the OMPD library with a set of callback functions in the callbacks input \n argument which enables the OMPD library to allocate and to deallocate memory in the tool\u2019s \n address space, to lookup the sizes of basic primitive types in the device, to lookup symbols in the \n device, and to read and to write memory in the device.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n any of the following return codes: \n \u2022 ompd_rc_bad_input if invalid callbacks are provided; or \n \u2022 ompd_rc_unsupported if the requested API version cannot be provided.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 The Callback Interface, see Section 20.4.6 \n \u2022 ompd_get_api_version, see Section 20.5.1.2 \n"}
{"section_title": "20.5.1.2 ompd_get_api_version", "chunk": "15 Summary \n The ompd_get_api_version function returns the OMPD API version.\n Format \nC \n ompd_rc_t ompd_get_api_version(ompd_word_t *version); \nC \n Semantics \n The tool may call the ompd_get_api_version function to obtain the latest OMPD API \n version number of the OMPD library.The OMPD API version number is equal to the value of the \n _OPENMP macro defined in the associated OpenMP implementation, if the C preprocessor is \n supported.If the associated OpenMP implementation compiles Fortran codes without the use of a \n C preprocessor, the OMPD API version number is equal to the value of the Fortran integer \n parameter openmp_version.\n Description of Arguments \n The latest version number is returned into the location to which the version argument points.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \nCHAPTER 20."}
{"section_title": "20.5.1.2 ompd_get_api_version", "chunk": "\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \nCHAPTER 20.OMPD INTERFACE 563 \n"}
{"section_title": "20.5.1.3 ompd_get_version_string", "chunk": "2 Summary \n The ompd_get_version_string function returns a descriptive string for the OMPD library \n version.\n Format \nC \n ompd_rc_t ompd_get_version_string(const char **string); \nC \n Semantics \n The tool may call this function to obtain a pointer to a descriptive version string of the OMPD \n library vendor, implementation, internal version, date, or any other information that may be useful \n to a tool user or vendor.An implementation should provide a different string for every change to its \n source code or build that could be visible to the interface user.\n Description of Arguments \n A pointer to a descriptive version string is placed into the location to which the string output \n argument points.The OMPD library owns the string that the OMPD library returns; the tool must \n not modify or release this string.The string remains valid for as long as the library is loaded."}
{"section_title": "20.5.1.3 ompd_get_version_string", "chunk": "The string remains valid for as long as the library is loaded.The \n ompd_get_version_string function may be called before ompd_initialize (see \n Section 20.5.1.1).Accordingly, the OMPD library must not use heap or stack memory for the string.\n The signatures of ompd_get_api_version (see Section 20.5.1.2) and \n ompd_get_version_string are guaranteed not to change in future versions of the API.In \n contrast, the type definitions and prototypes in the rest of the API do not carry the same guarantee.\n Therefore a tool that uses OMPD should check the version of the API of the loaded OMPD library \n before it calls any other function of the API.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.1.4 ompd_finalize", "chunk": "28 Summary \n When the tool is finished with the OMPD library it should call ompd_finalize before it \n unloads the library.\n Format \nC \n ompd_rc_t ompd_finalize(void); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The call to ompd_finalize must be the last OMPD call that the tool makes before it unloads the \n library.This call allows the OMPD library to free any resources that it may be holding.The OMPD \n library may implement a finalizer section, which executes as the library is unloaded and therefore \n after the call to ompd_finalize.During finalization, the OMPD library may use the callbacks \n that the tool provided earlier during the call to ompd_initialize.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unsupported if the OMPD library is not initialized.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.2 Per OpenMP Process Initialization and Finalization", "chunk": ""}
{"section_title": "20.5.2.1 ompd_process_initialize", "chunk": "15 Summary \n A tool calls ompd_process_initialize to obtain an address space handle for the host device \n when it initializes a session on a live process or core file.\n Format \nC \n ompd_rc_t ompd_process_initialize( \n ompd_address_space_context_t *context, \n ompd_address_space_handle_t **host_handle \n ); \nC \n Semantics \n A tool calls ompd_process_initialize to obtain an address space handle for the host device \n when it initializes a session on a live process or core file.On return from \n ompd_process_initialize, the tool owns the address space handle, which it must release \n with ompd_rel_address_space_handle.The initialization function must be called before \n any OMPD operations are performed on the OpenMP process or core file.This call allows the \n OMPD library to confirm that it can handle the OpenMP process or core file that context identifies."}
{"section_title": "20.5.2.1 ompd_process_initialize", "chunk": "This call allows the \n OMPD library to confirm that it can handle the OpenMP process or core file that context identifies.\n Description of Arguments \n The context argument is an opaque handle that the tool provides to address an address space from \n the host device.On return, the host_handle argument provides an opaque handle to the tool for this \n address space, which the tool must release when it is no longer needed.\nCHAPTER 20.OMPD INTERFACE 565 \n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_incompatible if the OMPD library is incompatible with the runtime library \n loaded in the process.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Tool Context Types, see Section 20.3.11 \n \u2022 ompd_rel_address_space_handle, see Section 20.5.2.3 \n"}
{"section_title": "20.5.2.2 ompd_device_initialize", "chunk": "12 Summary \n A tool calls ompd_device_initialize to obtain an address space handle for a non-host \n device that has at least one active target region.\n Format \nC \n ompd_rc_t ompd_device_initialize( \n ompd_address_space_handle_t *host_handle, \n ompd_address_space_context_t *device_context, \n ompd_device_t kind, \n ompd_size_t sizeof_id, \n void *id, \n ompd_address_space_handle_t **device_handle \n ); \nC \n Semantics \n A tool calls ompd_device_initialize to obtain an address space handle for a non-host \n device that has at least one active target region.On return from ompd_device_initialize, \n the tool owns the address space handle.\n Description of Arguments \n The host_handle argument is an opaque handle that the tool provides to reference the host device \n address space associated with an OpenMP process or core file.The device_context argument is an \n opaque handle that the tool provides to reference a non-host device address space."}
{"section_title": "20.5.2.2 ompd_device_initialize", "chunk": "The device_context argument is an \n opaque handle that the tool provides to reference a non-host device address space.The kind, \n sizeof_id, and id arguments represent a device identifier.On return the device_handle argument \n provides an opaque handle to the tool for this address space.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unsupported if the OMPD library has no support for the specific device.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n \u2022 System Device Identifiers, see Section 20.3.6 \n \u2022 Tool Context Types, see Section 20.3.11 \n"}
{"section_title": "20.5.2.3 ompd_rel_address_space_handle", "chunk": "12 Summary \n A tool calls ompd_rel_address_space_handle to release an address space handle.\n Format \nC \n ompd_rc_t ompd_rel_address_space_handle( \n ompd_address_space_handle_t *handle \n ); \nC \n Semantics \n When the tool is finished with the OpenMP process address space handle it should call \n ompd_rel_address_space_handle to release the handle, which allows the OMPD library \n to release any resources that it has related to the address space.\n Description of Arguments \n The handle argument is an opaque handle for the address space to be released.\n Restrictions \n Restrictions to the ompd_rel_address_space_handle routine are as follows: \n \u2022 An address space context must not be used after the corresponding address space handle is \n released.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\nCHAPTER 20."}
{"section_title": "20.5.2.3 ompd_rel_address_space_handle", "chunk": "\nCHAPTER 20.OMPD INTERFACE 567 \n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.2.4 ompd_get_device_thread_id_kinds", "chunk": "5 Summary \n The ompd_get_device_thread_id_kinds function returns a list of supported native \n thread identifier kinds and a corresponding list of their respective sizes.\n Format \nC \n ompd_rc_t ompd_get_device_thread_id_kinds( \n ompd_address_space_handle_t *device_handle, \n ompd_thread_id_t **kinds, \n ompd_size_t **thread_id_sizes, \n int *count \n ); \nC \n Semantics \n The ompd_get_device_thread_id_kinds function returns an array of supported native \n thread identifier kinds and a corresponding array of their respective sizes for a given device.The \n OMPD library allocates storage for the arrays with the memory allocation callback that the tool \n provides.Each supported native thread identifier kind is guaranteed to be recognizable by the \n OMPD library and may be mapped to and from any OpenMP thread that executes on the device."}
{"section_title": "20.5.2.4 ompd_get_device_thread_id_kinds", "chunk": "Each supported native thread identifier kind is guaranteed to be recognizable by the \n OMPD library and may be mapped to and from any OpenMP thread that executes on the device.\n The third-party tool owns the storage for the array of kinds and the array of sizes that is returned via \n the kinds and thread_id_sizes arguments, and it is responsible for freeing that storage.\n Description of Arguments \n The device_handle argument is a pointer to an opaque address space handle that represents a host \n device (returned by ompd_process_initialize) or a non-host device (returned by \n ompd_device_initialize).On return, the kinds argument is the address of a pointer to an \n array of native thread identifier kinds, the thread_id_sizes argument is the address of a pointer to an \n array of the corresponding native thread identifier sizes used by the OMPD library, and the count \n argument is the address of a variable that indicates the sizes of the returned arrays."}
{"section_title": "20.5.2.4 ompd_get_device_thread_id_kinds", "chunk": "On return, the kinds argument is the address of a pointer to an \n array of native thread identifier kinds, the thread_id_sizes argument is the address of a pointer to an \n array of the corresponding native thread identifier sizes used by the OMPD library, and the count \n argument is the address of a variable that indicates the sizes of the returned arrays.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Native Thread Identifiers, see Section 20.3.7 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n"}
{"section_title": "20.5.3 Thread and Signal Safety", "chunk": "7 The OMPD library does not need to be reentrant.The tool must ensure that only one thread enters \n the OMPD library at a time.The OMPD library must not install signal handlers or otherwise \n interfere with the tool\u2019s signal configuration.\n"}
{"section_title": "20.5.4 Address Space Information", "chunk": ""}
{"section_title": "20.5.4.1 ompd_get_omp_version", "chunk": "12 Summary \n The tool may call the ompd_get_omp_version function to obtain the version of the OpenMP \n API that is associated with an address space.\n Format \nC \n ompd_rc_t ompd_get_omp_version( \n ompd_address_space_handle_t *address_space, \n ompd_word_t *omp_version \n ); \nC \n Semantics \n The tool may call the ompd_get_omp_version function to obtain the version of the OpenMP \n API that is associated with the address space.\n Description of Arguments \n The address_space argument is an opaque handle that the tool provides to reference the address \n space of the OpenMP process or device.\n Upon return, the omp_version argument contains the version of the OpenMP runtime in the \n _OPENMP version macro format.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\nCHAPTER 20."}
{"section_title": "20.5.4.1 ompd_get_omp_version", "chunk": "\nCHAPTER 20.OMPD INTERFACE 569 \n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.4.2 ompd_get_omp_version_string", "chunk": "5 Summary \n The ompd_get_omp_version_string function returns a descriptive string for the OpenMP \n API version that is associated with an address space.\n Format \nC \n ompd_rc_t ompd_get_omp_version_string( \n ompd_address_space_handle_t *address_space, \n const char **string \n ); \nC \n Semantics \n After initialization, the tool may call the ompd_get_omp_version_string function to obtain \n the version of the OpenMP API that is associated with an address space.\n Description of Arguments \n The address_space argument is an opaque handle that the tool provides to reference the address \n space of the OpenMP process or device.A pointer to a descriptive version string is placed into the \n location to which the string output argument points.After returning from the call, the tool owns the \n string.The OMPD library must use the memory allocation callback that the tool provides to \n allocate the string storage.The tool is responsible for releasing the memory."}
{"section_title": "20.5.4.2 ompd_get_omp_version_string", "chunk": "The tool is responsible for releasing the memory.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.5 Thread Handles", "chunk": ""}
{"section_title": "20.5.5.1 ompd_get_thread_in_parallel", "chunk": "29 Summary \n The ompd_get_thread_in_parallel function enables a tool to obtain handles for OpenMP \n threads that are associated with a parallel region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n ompd_rc_t ompd_get_thread_in_parallel( \n ompd_parallel_handle_t *parallel_handle, \n int thread_num, \n ompd_thread_handle_t **thread_handle \n ); \nC \n Semantics \n A successful invocation of ompd_get_thread_in_parallel returns a pointer to a thread \n handle in the location to which thread_handle points.This call yields meaningful results only \n if all OpenMP threads in the team that is executing the parallel region are stopped.\n Description of Arguments \n The parallel_handle argument is an opaque handle for a parallel region and selects the parallel \n region on which to operate.The thread_num argument represents the OpenMP thread number and \n selects the thread, the handle for which is to be returned."}
{"section_title": "20.5.5.1 ompd_get_thread_in_parallel", "chunk": "The thread_num argument represents the OpenMP thread number and \n selects the thread, the handle for which is to be returned.On return, the thread_handle argument is \n an opaque handle for the selected thread.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if the thread_num argument is greater than or equal to the \n team-size-var ICV or negative.\n Restrictions \n Restrictions on the ompd_get_thread_in_parallel function are as follows: \n \u2022 The value of thread_num must be a non-negative integer smaller than the team size that was \n provided as the team-size-var ICV from ompd_get_icv_from_scope.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_get_icv_from_scope, see Section 20.5.10.2 \n"}
{"section_title": "20.5.5.2 ompd_get_thread_handle", "chunk": "30 Summary \n The ompd_get_thread_handle function maps a native thread to an OMPD thread handle.\nCHAPTER 20.OMPD INTERFACE 571 \n Format \nC \n ompd_rc_t ompd_get_thread_handle( \n ompd_address_space_handle_t *handle, \n ompd_thread_id_t kind, \n ompd_size_t sizeof_thread_id, \n const void *thread_id, \n ompd_thread_handle_t **thread_handle \n ); \nC \n Semantics \n The ompd_get_thread_handle function determines if the native thread identifier to which \n thread_id points represents an OpenMP thread.If so, the function returns ompd_rc_ok and the \n location to which thread_handle points is set to the thread handle for the OpenMP thread.\n Description of Arguments \n The handle argument is an opaque handle that the tool provides to reference an address space.The \n kind, sizeof_thread_id, and thread_id arguments represent a native thread identifier.On return, the \n thread_handle argument provides an opaque handle to the thread within the provided address space."}
{"section_title": "20.5.5.2 ompd_get_thread_handle", "chunk": "On return, the \n thread_handle argument provides an opaque handle to the thread within the provided address space.\n The native thread identifier to which thread_id points is guaranteed to be valid for the duration of \n the call.If the OMPD library must retain the native thread identifier, it must copy it.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n any of the following return codes: \n \u2022 ompd_rc_bad_input if a different value in sizeof_thread_id is expected for a thread kind of \n kind.\n \u2022 ompd_rc_unsupported if the kind of thread is not supported.\n \u2022 ompd_rc_unavailable if the thread is not an OpenMP thread.\n Cross References \n \u2022 Native Thread Identifiers, see Section 20.3.7 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n"}
{"section_title": "20.5.5.3 ompd_rel_thread_handle", "chunk": "32 Summary \n The ompd_rel_thread_handle function releases a thread handle.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n ompd_rc_t ompd_rel_thread_handle( \n ompd_thread_handle_t *thread_handle \n ); \nC \n Semantics \n Thread handles are opaque to tools, which therefore cannot release them directly.Instead, when the \n tool is finished with a thread handle it must pass it to ompd_rel_thread_handle for disposal.\n Description of Arguments \n The thread_handle argument is an opaque handle for a thread to be released.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.5.4 ompd_thread_handle_compare", "chunk": "16 Summary \n The ompd_thread_handle_compare function allows tools to compare two thread handles.\n Format \nC \n ompd_rc_t ompd_thread_handle_compare( \n ompd_thread_handle_t *thread_handle_1, \n ompd_thread_handle_t *thread_handle_2, \n int *cmp_value \n ); \nC \n Semantics \n The internal structure of thread handles is opaque to a tool.While the tool can easily compare \n pointers to thread handles, it cannot determine whether handles of two different addresses refer to \n the same underlying thread.The ompd_thread_handle_compare function compares thread \n handles.\n On success, ompd_thread_handle_compare returns in the location to which cmp_value \n points a signed integer value that indicates how the underlying threads compare: a value less than, \n equal to, or greater than 0 indicates that the thread corresponding to thread_handle_1 is, \n respectively, less than, equal to, or greater than that corresponding to thread_handle_2.\nCHAPTER 20."}
{"section_title": "20.5.5.4 ompd_thread_handle_compare", "chunk": "\nCHAPTER 20.OMPD INTERFACE 573 \n Description of Arguments \n The thread_handle_1 and thread_handle_2 arguments are opaque handles for threads.On return \n the cmp_value argument is set to a signed integer value.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.5.5 ompd_get_thread_id", "chunk": "10 Summary \n The ompd_get_thread_id function maps an OMPD thread handle to a native thread.\n Format \nC \n ompd_rc_t ompd_get_thread_id( \n ompd_thread_handle_t *thread_handle, \n ompd_thread_id_t kind, \n ompd_size_t sizeof_thread_id, \n void *thread_id \n ); \nC \n Semantics \n The ompd_get_thread_id function maps an OMPD thread handle to a native thread identifier.\n This call yields meaningful results only if the referenced OpenMP thread is stopped.\n Description of Arguments \n The thread_handle argument is an opaque thread handle.The kind argument represents the native \n thread identifier.The sizeof_thread_id argument represents the size of the native thread identifier.\n On return, the thread_id argument is a buffer that represents a native thread identifier."}
{"section_title": "20.5.5.5 ompd_get_thread_id", "chunk": "\n On return, the thread_id argument is a buffer that represents a native thread identifier.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n any of the following return codes: \n \u2022 ompd_rc_bad_input if a different value in sizeof_thread_id is expected for a thread kind of \n kind; or \n \u2022 ompd_rc_unsupported if the kind of thread is not supported.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 Native Thread Identifiers, see Section 20.3.7 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Size Type, see Section 20.3.1 \n"}
{"section_title": "20.5.5.6 ompd_get_device_from_thread", "chunk": "7 Summary \n The ompd_get_device_from_thread function obtains a pointer to the address space handle \n for a device on which an OpenMP thread is executing.\n Format \nC \n ompd_rc_t ompd_get_device_from_thread( \n ompd_thread_handle_t *thread_handle, \n ompd_address_space_handle_t **device \n ); \nC \n Semantics \n The ompd_get_device_from_thread function obtains a pointer to the address space handle \n for a device on which an OpenMP thread is executing.The returned pointer will be the same as the \n address space handle pointer that was previously returned by a call to \n ompd_process_initialize (for a host device) or a call to ompd_device_initialize \n (for a non-host device).This call yields meaningful results only if the referenced OpenMP thread is \n stopped.\n Description of Arguments \n The thread_handle argument is a pointer to an opaque thread handle that represents an OpenMP \n thread."}
{"section_title": "20.5.5.6 ompd_get_device_from_thread", "chunk": "\n Description of Arguments \n The thread_handle argument is a pointer to an opaque thread handle that represents an OpenMP \n thread.On return, the device argument is the address of a pointer to an OMPD address space \n handle.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \nCHAPTER 20.OMPD INTERFACE 575 \n"}
{"section_title": "20.5.6 Parallel Region Handles", "chunk": ""}
{"section_title": "20.5.6.1 ompd_get_curr_parallel_handle", "chunk": "3 Summary \n The ompd_get_curr_parallel_handle function obtains a pointer to the parallel handle for \n an OpenMP thread\u2019s current parallel region.\n Format \nC \n ompd_rc_t ompd_get_curr_parallel_handle( \n ompd_thread_handle_t *thread_handle, \n ompd_parallel_handle_t **parallel_handle \n ); \nC \n Semantics \n The ompd_get_curr_parallel_handle function enables the tool to obtain a pointer to the \n parallel handle for the current parallel region that is associated with an OpenMP thread.This call \n yields meaningful results only if the referenced OpenMP thread is stopped.The parallel handle is \n owned by the tool and it must be released by calling ompd_rel_parallel_handle.\n Description of Arguments \n The thread_handle argument is an opaque handle for a thread and selects the thread on which to \n operate.On return, the parallel_handle argument is set to a handle for the parallel region that the \n associated thread is currently executing, if any."}
{"section_title": "20.5.6.1 ompd_get_curr_parallel_handle", "chunk": "On return, the parallel_handle argument is set to a handle for the parallel region that the \n associated thread is currently executing, if any.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unavailable if the thread is not currently part of a team.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_parallel_handle, see Section 20.5.6.4 \n"}
{"section_title": "20.5.6.2 ompd_get_enclosing_parallel_handle", "chunk": "29 Summary \n The ompd_get_enclosing_parallel_handle function obtains a pointer to the parallel \n handle for an enclosing parallel region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n ompd_rc_t ompd_get_enclosing_parallel_handle( \n ompd_parallel_handle_t *parallel_handle, \n ompd_parallel_handle_t **enclosing_parallel_handle \n ); \nC \n Semantics \n The ompd_get_enclosing_parallel_handle function enables a tool to obtain a pointer \n to the parallel handle for the parallel region that encloses the parallel region that \n parallel_handle specifies.This call is meaningful only if at least one thread in the team that \n is executing the parallel region is stopped.A pointer to the parallel handle for the enclosing region \n is returned in the location to which enclosing_parallel_handle points.After the call, the tool owns \n the handle; the tool must release the handle with ompd_rel_parallel_handle when it is no \n longer required."}
{"section_title": "20.5.6.2 ompd_get_enclosing_parallel_handle", "chunk": "After the call, the tool owns \n the handle; the tool must release the handle with ompd_rel_parallel_handle when it is no \n longer required.\n Description of Arguments \n The parallel_handle argument is an opaque handle for a parallel region that selects the parallel \n region on which to operate.On return, the enclosing_parallel_handle argument is set to a handle \n for the parallel region that encloses the selected parallel region.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unavailable if no enclosing parallel region exists.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_parallel_handle, see Section 20.5.6.4 \n"}
{"section_title": "20.5.6.3 ompd_get_task_parallel_handle", "chunk": "27 Summary \n The ompd_get_task_parallel_handle function obtains a pointer to the parallel handle for \n the parallel region that encloses a task region.\n Format \nC \n ompd_rc_t ompd_get_task_parallel_handle( \n ompd_task_handle_t *task_handle, \n ompd_parallel_handle_t **task_parallel_handle \n ); \nC \nCHAPTER 20.OMPD INTERFACE 577 \n Semantics \n The ompd_get_task_parallel_handle function enables a tool to obtain a pointer to the \n parallel handle for the parallel region that encloses the task region that task_handle specifies.This \n call yields meaningful results only if at least one thread in the team that is executing the parallel \n region is stopped.A pointer to the parallel regions handle is returned in the location to which \n task_parallel_handle points.The tool owns that parallel handle, which it must release with \n ompd_rel_parallel_handle.\n Description of Arguments \n The task_handle argument is an opaque handle that selects the task on which to operate."}
{"section_title": "20.5.6.3 ompd_get_task_parallel_handle", "chunk": "\n Description of Arguments \n The task_handle argument is an opaque handle that selects the task on which to operate.On return, \n the parallel_handle argument is set to a handle for the parallel region that encloses the selected task.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_parallel_handle, see Section 20.5.6.4 \n"}
{"section_title": "20.5.6.4 ompd_rel_parallel_handle", "chunk": "18 Summary \n The ompd_rel_parallel_handle function releases a parallel region handle.\n Format \nC \n ompd_rc_t ompd_rel_parallel_handle( \n ompd_parallel_handle_t *parallel_handle \n ); \nC \n Semantics \n Parallel region handles are opaque so tools cannot release them directly.Instead, a tool must pass a \n parallel region handle to the ompd_rel_parallel_handle function for disposal when \n finished with it.\n Description of Arguments \n The parallel_handle argument is an opaque handle to be released.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n OpenMP API \u2013 Version 5.2 November 2021 \n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.6.5 ompd_parallel_handle_compare", "chunk": "5 Summary \n The ompd_parallel_handle_compare function compares two parallel region handles.\n Format \nC \n ompd_rc_t ompd_parallel_handle_compare( \n ompd_parallel_handle_t *parallel_handle_1, \n ompd_parallel_handle_t *parallel_handle_2, \n int *cmp_value \n ); \nC \n Semantics \n The internal structure of parallel region handles is opaque to tools.While tools can easily compare \n pointers to parallel region handles, they cannot determine whether handles at two different \n addresses refer to the same underlying parallel region and, instead must use the \n ompd_parallel_handle_compare function.\n On success, ompd_parallel_handle_compare returns a signed integer value in the location \n to which cmp_value points that indicates how the underlying parallel regions compare."}
{"section_title": "20.5.6.5 ompd_parallel_handle_compare", "chunk": "\n On success, ompd_parallel_handle_compare returns a signed integer value in the location \n to which cmp_value points that indicates how the underlying parallel regions compare.A value less \n than, equal to, or greater than 0 indicates that the region corresponding to parallel_handle_1 is, \n respectively, less than, equal to, or greater than that corresponding to parallel_handle_2.This \n function is provided since the means by which parallel region handles are ordered is \n implementation defined.\n Description of Arguments \n The parallel_handle_1 and parallel_handle_2 arguments are opaque handles that correspond to \n parallel regions.On return the cmp_value argument points to a signed integer value that indicates \n how the underlying parallel regions compare.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5."}
{"section_title": "20.5.6.5 ompd_parallel_handle_compare", "chunk": "\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \nCHAPTER 20.OMPD INTERFACE 579 \n"}
{"section_title": "20.5.7 Task Handles", "chunk": ""}
{"section_title": "20.5.7.1 ompd_get_curr_task_handle", "chunk": "3 Summary \n The ompd_get_curr_task_handle function obtains a pointer to the task handle for the \n current task region that is associated with an OpenMP thread.\n Format \nC \n ompd_rc_t ompd_get_curr_task_handle( \n ompd_thread_handle_t *thread_handle, \n ompd_task_handle_t **task_handle \n ); \nC \n Semantics \n The ompd_get_curr_task_handle function obtains a pointer to the task handle for the \n current task region that is associated with an OpenMP thread.This call yields meaningful results \n only if the thread for which the handle is provided is stopped.The task handle must be released \n with ompd_rel_task_handle.\n Description of Arguments \n The thread_handle argument is an opaque handle that selects the thread on which to operate.On \n return, the task_handle argument points to a location that points to a handle for the task that the \n thread is currently executing."}
{"section_title": "20.5.7.1 ompd_get_curr_task_handle", "chunk": "On \n return, the task_handle argument points to a location that points to a handle for the task that the \n thread is currently executing.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unavailable if the thread is currently not executing a task.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_task_handle, see Section 20.5.7.5 \n"}
{"section_title": "20.5.7.2 ompd_get_generating_task_handle", "chunk": "29 Summary \n The ompd_get_generating_task_handle function obtains a pointer to the task handle of \n the generating task region.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n ompd_rc_t ompd_get_generating_task_handle( \n ompd_task_handle_t *task_handle, \n ompd_task_handle_t **generating_task_handle \n ); \nC \n Semantics \n The ompd_get_generating_task_handle function obtains a pointer to the task handle for \n the task that encountered the OpenMP task construct that generated the task represented by \n task_handle.The generating task is the OpenMP task that was active when the task specified by \n task_handle was created.This call yields meaningful results only if the thread that is executing the \n task that task_handle specifies is stopped while executing the task.The generating task handle must \n be released with ompd_rel_task_handle.\n Description of Arguments \n The task_handle argument is an opaque handle that selects the task on which to operate."}
{"section_title": "20.5.7.2 ompd_get_generating_task_handle", "chunk": "\n Description of Arguments \n The task_handle argument is an opaque handle that selects the task on which to operate.On return, \n the generating_task_handle argument points to a location that points to a handle for the generating \n task.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unavailable if no generating task region exists.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_task_handle, see Section 20.5.7.5 \n"}
{"section_title": "20.5.7.3 ompd_get_scheduling_task_handle", "chunk": "26 Summary \n The ompd_get_scheduling_task_handle function obtains a task handle for the task that \n was active at a task scheduling point.\n Format \nC \n ompd_rc_t ompd_get_scheduling_task_handle( \n ompd_task_handle_t *task_handle, \n ompd_task_handle_t **scheduling_task_handle \n ); \nC \nCHAPTER 20.OMPD INTERFACE 581 \n Semantics \n The ompd_get_scheduling_task_handle function obtains a task handle for the task that \n was active when the task that task_handle represents was scheduled.An implicit task does not have \n a scheduling task.This call yields meaningful results only if the thread that is executing the task \n that task_handle specifies is stopped while executing the task.The scheduling task handle must be \n released with ompd_rel_task_handle.\n Description of Arguments \n The task_handle argument is an opaque handle for a task and selects the task on which to operate."}
{"section_title": "20.5.7.3 ompd_get_scheduling_task_handle", "chunk": "\n Description of Arguments \n The task_handle argument is an opaque handle for a task and selects the task on which to operate.\n On return, the scheduling_task_handle argument points to a location that points to a handle for the \n task that is still on the stack of execution on the same thread and was deferred in favor of executing \n the selected task.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unavailable if no scheduling task exists.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_rel_task_handle, see Section 20.5.7.5 \n"}
{"section_title": "20.5.7.4 ompd_get_task_in_parallel", "chunk": "21 Summary \n The ompd_get_task_in_parallel function obtains handles for the implicit tasks that are \n associated with a parallel region.\n Format \nC \n ompd_rc_t ompd_get_task_in_parallel( \n ompd_parallel_handle_t *parallel_handle, \n int thread_num, \n ompd_task_handle_t **task_handle \n ); \nC \n Semantics \n The ompd_get_task_in_parallel function obtains handles for the implicit tasks that are \n associated with a parallel region.A successful invocation of ompd_get_task_in_parallel \n returns a pointer to a task handle in the location to which task_handle points.This call yields \n meaningful results only if all OpenMP threads in the parallel region are stopped.\n OpenMP API \u2013 Version 5.2 November 2021 \n Description of Arguments \n The parallel_handle argument is an opaque handle that selects the parallel region on which to \n operate.The thread_num argument selects the implicit task of the team to be returned."}
{"section_title": "20.5.7.4 ompd_get_task_in_parallel", "chunk": "The thread_num argument selects the implicit task of the team to be returned.The \n thread_num argument is equal to the thread-num-var ICV value of the selected implicit task.On \n return, the task_handle argument points to a location that points to an opaque handle for the \n selected implicit task.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if the thread_num argument is greater than or equal to the \n team-size-var ICV or negative.\n Restrictions \n Restrictions on the ompd_get_task_in_parallel function are as follows: \n \u2022 The value of thread_num must be a non-negative integer that is smaller than the size of the team \n size that is the value of the team-size-var ICV that ompd_get_icv_from_scope returns."}
{"section_title": "20.5.7.4 ompd_get_task_in_parallel", "chunk": "\n Restrictions \n Restrictions on the ompd_get_task_in_parallel function are as follows: \n \u2022 The value of thread_num must be a non-negative integer that is smaller than the size of the team \n size that is the value of the team-size-var ICV that ompd_get_icv_from_scope returns.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_get_icv_from_scope, see Section 20.5.10.2 \n"}
{"section_title": "20.5.7.5 ompd_rel_task_handle", "chunk": "21 Summary \n This ompd_rel_task_handle function releases a task handle.\n Format \nC \n ompd_rc_t ompd_rel_task_handle( \n ompd_task_handle_t *task_handle \n ); \nC \n Semantics \n Task handles are opaque to tools; thus tools cannot release them directly.Instead, when a tool is \n finished with a task handle it must use the ompd_rel_task_handle function to release it.\n Description of Arguments \n The task_handle argument is an opaque task handle to be released.\nCHAPTER 20.OMPD INTERFACE 583 \n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.7.6 ompd_task_handle_compare", "chunk": "7 Summary \n The ompd_task_handle_compare function compares task handles.\n Format \nC \n ompd_rc_t ompd_task_handle_compare( \n ompd_task_handle_t *task_handle_1, \n ompd_task_handle_t *task_handle_2, \n int *cmp_value \n ); \nC \n Semantics \n The internal structure of task handles is opaque; so tools cannot directly determine if handles at two \n different addresses refer to the same underlying task.The ompd_task_handle_compare \n function compares task handles.After a successful call to ompd_task_handle_compare, the \n value of the location to which cmp_value points is a signed integer that indicates how the underlying \n tasks compare: a value less than, equal to, or greater than 0 indicates that the task that corresponds \n to task_handle_1 is, respectively, less than, equal to, or greater than the task that corresponds to \n task_handle_2.The means by which task handles are ordered is implementation defined."}
{"section_title": "20.5.7.6 ompd_task_handle_compare", "chunk": "The means by which task handles are ordered is implementation defined.\n Description of Arguments \n The task_handle_1 and task_handle_2 arguments are opaque handles that correspond to tasks.On \n return, the cmp_value argument points to a location in which a signed integer value indicates how \n the underlying tasks compare.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "20.5.7.7 ompd_get_task_function", "chunk": "2 Summary \n This ompd_get_task_function function returns the entry point of the code that corresponds \n to the body of a task.\n Format \nC \n ompd_rc_t ompd_get_task_function ( \n ompd_task_handle_t *task_handle, \n ompd_address_t *entry_point \n ); \nC \n Semantics \n The ompd_get_task_function function returns the entry point of the code that corresponds \n to the body of code that the task executes.This call is meaningful only if the thread that is \n executing the task that task_handle specifies is stopped while executing the task.\n Description of Arguments \n The task_handle argument is an opaque handle that selects the task on which to operate.On return, \n the entry_point argument is set to an address that describes the beginning of application code that \n executes the task region.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5."}
{"section_title": "20.5.7.7 ompd_get_task_function", "chunk": "\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.7.8 ompd_get_task_frame", "chunk": "25 Summary \n The ompd_get_task_frame function extracts the frame pointers of a task.\n Format \nC \n ompd_rc_t ompd_get_task_frame ( \n ompd_task_handle_t *task_handle, \n ompd_frame_info_t *exit_frame, \n ompd_frame_info_t *enter_frame \n ); \nC \nCHAPTER 20.OMPD INTERFACE 585 \n Semantics \n An OpenMP implementation maintains an ompt_frame_t object for every implicit or explicit \n task.The ompd_get_task_frame function extracts the enter_frame and exit_frame fields of \n the ompt_frame_t object of the task that task_handle identifies.This call yields meaningful \n results only if the thread that is executing the task that task_handle specifies is stopped while \n executing the task.\n Description of Arguments \n The task_handle argument specifies an OpenMP task."}
{"section_title": "20.5.7.8 ompd_get_task_frame", "chunk": "\n Description of Arguments \n The task_handle argument specifies an OpenMP task.On return, the exit_frame argument points to \n an ompd_frame_info_t object that has the frame information with the same semantics as the \n exit_frame field in the ompt_frame_t object that is associated with the specified task.On return, \n the enter_frame argument points to an ompd_frame_info_t object that has the frame \n information with the same semantics as the enter_frame field in the ompt_frame_t object that is \n associated with the specified task.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 Address Type, see Section 20.3.4 \n \u2022 Frame Information Type, see Section 20.3.5 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompt_frame_t, see Section 19.4.4.29 \n"}
{"section_title": "20.5.8 Querying Thread States", "chunk": ""}
{"section_title": "20.5.8.1 ompd_enumerate_states", "chunk": "24 Summary \n The ompd_enumerate_states function enumerates thread states that an OpenMP \n implementation supports.\n Format \nC \n ompd_rc_t ompd_enumerate_states ( \n ompd_address_space_handle_t *address_space_handle, \n ompd_word_t current_state, \n ompd_word_t *next_state, \n const char **next_state_name, \n ompd_word_t *more_enums \n ); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n An OpenMP implementation may support only a subset of the states that the ompt_state_t \n enumeration type defines.In addition, an OpenMP implementation may support \n implementation-specific states.The ompd_enumerate_states call enables a tool to \n enumerate the thread states that an OpenMP implementation supports.\n When the current_state argument is a thread state that an OpenMP implementation supports, the \n call assigns the value and string name of the next thread state in the enumeration to the locations to \n which the next_state and next_state_name arguments point."}
{"section_title": "20.5.8.1 ompd_enumerate_states", "chunk": "\n When the current_state argument is a thread state that an OpenMP implementation supports, the \n call assigns the value and string name of the next thread state in the enumeration to the locations to \n which the next_state and next_state_name arguments point.\n On return, the third-party tool owns the next_state_name string.The OMPD library allocates \n storage for the string with the memory allocation callback that the tool provides.The tool is \n responsible for releasing the memory.\n On return, the location to which the more_enums argument points has the value 1 whenever one or \n more states are left in the enumeration.On return, the location to which the more_enums argument \n points has the value 0 when current_state is the last state in the enumeration.\n Description of Arguments \n The address_space_handle argument identifies the address space.The current_state argument must \n be a thread state that the OpenMP implementation supports."}
{"section_title": "20.5.8.1 ompd_enumerate_states", "chunk": "The current_state argument must \n be a thread state that the OpenMP implementation supports.To begin enumerating the supported \n states, a tool should pass ompt_state_undefined as the value of current_state.Subsequent \n calls to ompd_enumerate_states by the tool should pass the value that the call returned in \n the next_state argument.On return, the next_state argument points to an integer with the value of \n the next state in the enumeration.On return, the next_state_name argument points to a character \n string that describes the next state.On return, the more_enums argument points to an integer with a \n value of 1 when more states are left to enumerate and a value of 0 when no more states are left.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if an unknown value is provided in current_state."}
{"section_title": "20.5.8.1 ompd_enumerate_states", "chunk": "\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if an unknown value is provided in current_state.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompt_state_t, see Section 19.4.4.28 \n"}
{"section_title": "20.5.8.2 ompd_get_state", "chunk": "33 Summary \n The ompd_get_state function obtains the state of a thread.\nCHAPTER 20.OMPD INTERFACE 587 \n Format \nC \n ompd_rc_t ompd_get_state ( \n ompd_thread_handle_t *thread_handle, \n ompd_word_t *state, \n ompd_wait_id_t *wait_id \n ); \nC \n Semantics \n The ompd_get_state function returns the state of an OpenMP thread.This call yields \n meaningful results only if the referenced OpenMP thread is stopped.\n Description of Arguments \n The thread_handle argument identifies the thread.The state argument represents the state of that \n thread as represented by a value that ompd_enumerate_states returns.On return, if the \n wait_id argument is non-null then it points to a handle that corresponds to the wait_id wait \n identifier of the thread.If the thread state is not one of the specified wait states, the value to which \n wait_id points is undefined."}
{"section_title": "20.5.8.2 ompd_get_state", "chunk": "If the thread state is not one of the specified wait states, the value to which \n wait_id points is undefined.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 Wait ID Type, see Section 20.3.2 \n \u2022 ompd_enumerate_states, see Section 20.5.8.1 \n"}
{"section_title": "20.5.9 Display Control Variables", "chunk": ""}
{"section_title": "20.5.9.1 ompd_get_display_control_vars", "chunk": "25 Summary \n The ompd_get_display_control_vars function returns a list of name/value pairs for \n OpenMP control variables.\n Format \nC \n ompd_rc_t ompd_get_display_control_vars ( \n ompd_address_space_handle_t *address_space_handle, \n const char * const **control_vars \n ); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The ompd_get_display_control_vars function returns a NULL-terminated vector of \n null-terminated strings of name/value pairs of control variables that have user controllable settings \n and are important to the operation or performance of an OpenMP runtime system.The control \n variables that this interface exposes include all OpenMP environment variables, settings that may \n come from vendor or platform-specific environment variables, and other settings that affect the \n operation or functioning of an OpenMP runtime.\n The format of the strings is \"icv-name=icv-value\".\n On return, the third-party tool owns the vector and the strings."}
{"section_title": "20.5.9.1 ompd_get_display_control_vars", "chunk": "\n On return, the third-party tool owns the vector and the strings.The OMPD library must satisfy the \n termination constraints; it may use static or dynamic memory for the vector and/or the strings and is \n unconstrained in how it arranges them in memory.If it uses dynamic memory then the OMPD \n library must use the allocate callback that the tool provides to ompd_initialize.The tool must \n use the ompd_rel_display_control_vars function to release the vector and the strings.\n Description of Arguments \n The address_space_handle argument identifies the address space.On return, the control_vars \n argument points to the vector of display control variables.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5."}
{"section_title": "20.5.9.1 ompd_get_display_control_vars", "chunk": "\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_initialize, see Section 20.5.1.1 \n \u2022 ompd_rel_display_control_vars, see Section 20.5.9.2 \n"}
{"section_title": "20.5.9.2 ompd_rel_display_control_vars", "chunk": "25 Summary \n The ompd_rel_display_control_vars releases a list of name/value pairs of OpenMP \n control variables previously acquired with ompd_get_display_control_vars.\n Format \nC \n ompd_rc_t ompd_rel_display_control_vars ( \n const char * const **control_vars \n ); \nC \nCHAPTER 20.OMPD INTERFACE 589 \n Semantics \n The third-party tool owns the vector and strings that ompd_get_display_control_vars \n returns.The tool must call ompd_rel_display_control_vars to release the vector and the \n strings.\n Description of Arguments \n The control_vars argument is the vector of display control variables to be released.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5.\n Cross References \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_get_display_control_vars, see Section 20.5.9.1 \n"}
{"section_title": "20.5.10 Accessing Scope-Specific Information", "chunk": ""}
{"section_title": "20.5.10.1 ompd_enumerate_icvs", "chunk": "14 Summary \n The ompd_enumerate_icvs function enumerates ICVs.\n Format \nC \n ompd_rc_t ompd_enumerate_icvs ( \n ompd_address_space_handle_t *handle, \n ompd_icv_id_t current, \n ompd_icv_id_t *next_id, \n const char **next_icv_name, \n ompd_scope_t *next_scope, \n int *more \n ); \nC \n Semantics \n An OpenMP implementation must support all ICVs listed in Section 2.1.An OpenMP \n implementation may support additional implementation-specific variables.An implementation may \n store ICVs in a different scope than Table 2.1 indicates.The ompd_enumerate_icvs function \n enables a tool to enumerate the ICVs that an OpenMP implementation supports and their related \n scopes.The ICVs num-procs-var, thread-num-var, final-task-var, explicit-task-var and \n team-size-var must also be available with an ompd- prefix; this requirement has been deprecated."}
{"section_title": "20.5.10.1 ompd_enumerate_icvs", "chunk": "The ICVs num-procs-var, thread-num-var, final-task-var, explicit-task-var and \n team-size-var must also be available with an ompd- prefix; this requirement has been deprecated.\n When the current argument is set to the identifier of a supported ICV, ompd_enumerate_icvs \n assigns the value, string name, and scope of the next ICV in the enumeration to the locations to \n which the next_id, next_icv_name, and next_scope arguments point.On return, the third-party tool \n owns the next_icv_name string.The OMPD library uses the memory allocation callback that the \n tool provides to allocate the string storage; the tool is responsible for releasing the memory.\n OpenMP API \u2013 Version 5.2 November 2021 \n On return, the location to which the more argument points has the value of 1 whenever one or more \n ICV are left in the enumeration.On return, that location has the value 0 when current is the last \n ICV in the enumeration."}
{"section_title": "20.5.10.1 ompd_enumerate_icvs", "chunk": "On return, that location has the value 0 when current is the last \n ICV in the enumeration.\n Description of Arguments \n The address_space_handle argument identifies the address space.The current argument must be \n an ICV that the OpenMP implementation supports.To begin enumerating the ICVs, a tool should \n pass ompd_icv_undefined as the value of current.Subsequent calls to \n ompd_enumerate_icvs should pass the value returned by the call in the next_id output \n argument.On return, the next_id argument points to an integer with the value of the ID of the next \n ICV in the enumeration.On return, the next_icv_name argument points to a character string with \n the name of the next ICV.On return, the next_scope argument points to the scope enum value of the \n scope of the next ICV.On return, the more_enums argument points to an integer with the value of 1 \n when more ICVs are left to enumerate and the value of 0 when no more ICVs are left."}
{"section_title": "20.5.10.1 ompd_enumerate_icvs", "chunk": "On return, the more_enums argument points to an integer with the value of 1 \n when more ICVs are left to enumerate and the value of 0 when no more ICVs are left.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if an unknown value is provided in current.\n Cross References \n \u2022 ICV ID Type, see Section 20.3.10 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 OMPD Scope Types, see Section 20.3.9 \n \u2022 Return Code Types, see Section 20.3.12 \n"}
{"section_title": "20.5.10.2 ompd_get_icv_from_scope", "chunk": "24 Summary \n The ompd_get_icv_from_scope function returns the value of an ICV.\n Format \nC \n ompd_rc_t ompd_get_icv_from_scope ( \n void *handle, \n ompd_scope_t scope, \n ompd_icv_id_t icv_id, \n ompd_word_t *icv_value \n ); \nC \nCHAPTER 20.OMPD INTERFACE 591 \n Semantics \n The ompd_get_icv_from_scope function provides access to the ICVs that \n ompd_enumerate_icvs identifies.\n Description of Arguments \n The handle argument provides an OpenMP scope handle.The scope argument specifies the kind of \n scope provided in handle.The icv_id argument specifies the ID of the requested ICV.On return, \n the icv_value argument points to a location with the value of the requested ICV.\n Constraints on Arguments \n The provided handle must match the scope as defined in Section 20.3.10.\n The provided scope must match the scope for icv_id as requested by ompd_enumerate_icvs."}
{"section_title": "20.5.10.2 ompd_get_icv_from_scope", "chunk": "\n The provided scope must match the scope for icv_id as requested by ompd_enumerate_icvs.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n any of the following return codes: \n \u2022 ompd_rc_incompatible if the ICV cannot be represented as an integer; \n \u2022 ompd_rc_incomplete if only the first item of the ICV is returned in the integer (e.g., if \n nthreads-var is a list); or \n \u2022 ompd_rc_bad_input if an unknown value is provided in icv_id.\n Cross References \n \u2022 ICV ID Type, see Section 20.3.10 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 OMPD Scope Types, see Section 20.3.9 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_enumerate_icvs, see Section 20.5.10.1 \n"}
{"section_title": "20.5.10.3 ompd_get_icv_string_from_scope", "chunk": "25 Summary \n The ompd_get_icv_string_from_scope function returns the value of an ICV.\n Format \nC \n ompd_rc_t ompd_get_icv_string_from_scope ( \n void *handle, \n ompd_scope_t scope, \n ompd_icv_id_t icv_id, \n const char **icv_string \n ); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The ompd_get_icv_string_from_scope function provides access to the ICVs that \n ompd_enumerate_icvs identifies.\n Description of Arguments \n The handle argument provides an OpenMP scope handle.The scope argument specifies the kind of \n scope provided in handle.The icv_id argument specifies the ID of the requested ICV.On return, \n the icv_string argument points to a string representation of the requested ICV.\n On return, the third-party tool owns the icv_string string.The OMPD library allocates the string \n storage with the memory allocation callback that the tool provides.The tool is responsible for \n releasing the memory."}
{"section_title": "20.5.10.3 ompd_get_icv_string_from_scope", "chunk": "The tool is responsible for \n releasing the memory.\n Constraints on Arguments \n The provided handle must match the scope as defined in Section 20.3.10.\n The provided scope must match the scope for icv_id as requested by ompd_enumerate_icvs.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_bad_input if an unknown value is provided in icv_id.\n Cross References \n \u2022 ICV ID Type, see Section 20.3.10 \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 OMPD Scope Types, see Section 20.3.9 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompd_enumerate_icvs, see Section 20.5.10.1 \n"}
{"section_title": "20.5.10.4 ompd_get_tool_data", "chunk": "25 Summary \n The ompd_get_tool_data function provides access to the OMPT data variable stored for each \n OpenMP scope.\n Format \nC \n ompd_rc_t ompd_get_tool_data( \n void* handle, \n ompd_scope_t scope, \n ompd_word_t *value, \n ompd_address_t *ptr \n ); \nC \nCHAPTER 20.OMPD INTERFACE 593 \n Semantics \n The ompd_get_tool_data function provides access to the OMPT tool data stored for each \n scope.If the runtime library does not support OMPT then the function returns \n ompd_rc_unsupported.\n Description of Arguments \n The handle argument provides an OpenMP scope handle.The scope argument specifies the kind of \n scope provided in handle.On return, the value argument points to the value field of the \n ompt_data_t union stored for the selected scope.On return, the ptr argument points to the ptr \n field of the ompt_data_t union stored for the selected scope."}
{"section_title": "20.5.10.4 ompd_get_tool_data", "chunk": "On return, the ptr argument points to the ptr \n field of the ompt_data_t union stored for the selected scope.\n Description of Return Codes \n This routine must return any of the general return codes listed at the beginning of Section 20.5 or \n the following return code: \n \u2022 ompd_rc_unsupported if the runtime library does not support OMPT.\n Cross References \n \u2022 OMPD Handle Types, see Section 20.3.8 \n \u2022 OMPD Scope Types, see Section 20.3.9 \n \u2022 Return Code Types, see Section 20.3.12 \n \u2022 ompt_data_t, see Section 19.4.4.4 \n"}
{"section_title": "20.6 Runtime Entry Points for OMPD", "chunk": "20 The OpenMP implementation must define several entry point symbols through which execution \n must pass when particular events occur and data collection for OMPD is enabled.A tool can enable \n notification of an event by setting a breakpoint at the address of the entry point symbol.\n Entry point symbols have external C linkage and do not require demangling or other \n transformations to look up their names to obtain the address in the OpenMP program.While each \n entry point symbol conceptually has a function type signature, it may not be a function.It may be a \n labeled location \n"}
{"section_title": "20.6.1 Beginning Parallel Regions", "chunk": "28 Summary \n Before starting the execution of an OpenMP parallel region, the implementation executes \n ompd_bp_parallel_begin.\n Format \nC \n void ompd_bp_parallel_begin(void); \nC \n OpenMP API \u2013 Version 5.2 November 2021 \n Semantics \n The OpenMP implementation must execute ompd_bp_parallel_begin at every \n parallel-begin event.At the point that the implementation reaches \n ompd_bp_parallel_begin, the binding for ompd_get_curr_parallel_handle is the \n parallel region that is beginning and the binding for ompd_get_curr_task_handle is the \n task that encountered the parallel construct.\n Cross References \n \u2022 ompd_get_curr_parallel_handle, see Section 20.5.6.1 \n \u2022 ompd_get_curr_task_handle, see Section 20.5.7.1 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "20.6.2 Ending Parallel Regions", "chunk": "12 Summary \n After finishing the execution of an OpenMP parallel region, the implementation executes \n ompd_bp_parallel_end.\n Format \nC \n void ompd_bp_parallel_end(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_parallel_end at every parallel-end \n event.At the point that the implementation reaches ompd_bp_parallel_end, the binding for \n ompd_get_curr_parallel_handle is the parallel region that is ending and the binding \n for ompd_get_curr_task_handle is the task that encountered the parallel construct.\n After execution of ompd_bp_parallel_end, any parallel_handle that was acquired for the \n parallel region is invalid and should be released.\n Cross References \n \u2022 ompd_get_curr_parallel_handle, see Section 20.5.6.1 \n \u2022 ompd_get_curr_task_handle, see Section 20.5.7.1 \n \u2022 ompd_rel_parallel_handle, see Section 20.5.6.4 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "20.6.3 Beginning Task Regions", "chunk": "30 Summary \n Before starting the execution of an OpenMP task region, the implementation executes \n ompd_bp_task_begin.\nCHAPTER 20.OMPD INTERFACE 595 \n Format \nC \n void ompd_bp_task_begin(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_task_begin immediately before starting \n execution of a structured-block that is associated with a non-merged task.At the point that the \n implementation reaches ompd_bp_task_begin, the binding for \n ompd_get_curr_task_handle is the task that is scheduled to execute.\n Cross References \n \u2022 ompd_get_curr_task_handle, see Section 20.5.7.1 \n"}
{"section_title": "20.6.4 Ending Task Regions", "chunk": "11 Summary \n After finishing the execution of an OpenMP task region, the implementation executes \n ompd_bp_task_end.\n Format \nC \n void ompd_bp_task_end(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_task_end immediately after completion \n of a structured-block that is associated with a non-merged task.At the point that the implementation \n reaches ompd_bp_task_end, the binding for ompd_get_curr_task_handle is the task \n that finished execution.After execution of ompd_bp_task_end, any task_handle that was \n acquired for the task region is invalid and should be released.\n Cross References \n \u2022 ompd_get_curr_task_handle, see Section 20.5.7.1 \n \u2022 ompd_rel_task_handle, see Section 20.5.7.5 \n"}
{"section_title": "20.6.5 Beginning OpenMP Threads", "chunk": "26 Summary \n When starting an OpenMP thread, the implementation executes ompd_bp_thread_begin.\n OpenMP API \u2013 Version 5.2 November 2021 \n Format \nC \n void ompd_bp_thread_begin(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_thread_begin at every \n native-thread-begin and initial-thread-begin event.This execution occurs before the thread starts \n the execution of any OpenMP region.\n Cross References \n \u2022 Initial Task, see Section 12.8 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "20.6.6 Ending OpenMP Threads", "chunk": "11 Summary \n When terminating an OpenMP thread, the implementation executes ompd_bp_thread_end.\n Format \nC \n void ompd_bp_thread_end(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_thread_end at every native-thread-end \n and initial-thread-end event.This execution occurs after the thread completes the execution of all \n OpenMP regions.After executing ompd_bp_thread_end, any thread_handle that was acquired \n for this thread is invalid and should be released.\n Cross References \n \u2022 Initial Task, see Section 12.8 \n \u2022 ompd_rel_thread_handle, see Section 20.5.5.3 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "20.6.7 Initializing OpenMP Devices", "chunk": "25 Summary \n The OpenMP implementation must execute ompd_bp_device_begin at every device-initialize \n event.\nCHAPTER 20.OMPD INTERFACE 597 \n Format \nC \n void ompd_bp_device_begin(void); \nC \n Semantics \n When initializing a device for execution of a target region, the implementation must execute \n ompd_bp_device_begin.This execution occurs before the work associated with any OpenMP \n region executes on the device.\n Cross References \n \u2022 Device Initialization, see Section 13.4 \n"}
{"section_title": "20.6.8 Finalizing OpenMP Devices", "chunk": "10 Summary \n When terminating an OpenMP thread, the implementation executes ompd_bp_device_end.\n Format \nC \n void ompd_bp_device_end(void); \nC \n Semantics \n The OpenMP implementation must execute ompd_bp_device_end at every device-finalize \n event.This execution occurs after the thread executes all OpenMP regions.After execution of \n ompd_bp_device_end, any address_space_handle that was acquired for this device is invalid \n and should be released.\n Cross References \n \u2022 Device Initialization, see Section 13.4 \n \u2022 ompd_rel_address_space_handle, see Section 20.5.2.3 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "21 Environment Variables", "chunk": "2 This chapter describes the OpenMP environment variables that specify the settings of the ICVs that \n affect the execution of OpenMP programs (see Chapter 2).The names of the environment variables \n must be upper case.Unless otherwise specified, the values assigned to the environment variables \n are case insensitive and may have leading and trailing white space.Modifications to the \n environment variables after the program has started, even if modified by the program itself, are \n ignored by the OpenMP implementation.However, the settings of some of the ICVs can be \n modified during the execution of the OpenMP program by the use of the appropriate directive \n clauses or OpenMP API routines."}
{"section_title": "21 Environment Variables", "chunk": "However, the settings of some of the ICVs can be \n modified during the execution of the OpenMP program by the use of the appropriate directive \n clauses or OpenMP API routines.\n The following examples demonstrate how the OpenMP environment variables can be set in \n different environments: \n \u2022 csh-like shells: \n setenv OMP_SCHEDULE \"dynamic\" \n \u2022 bash-like shells: \n export OMP_SCHEDULE=\"dynamic\" \n \u2022 Windows Command Line: \n set OMP_SCHEDULE=dynamic \n As defined following Table 2.2 in Section 2.2, device-specific environment variables extend many \n of the environment variables defined in this chapter.If the corresponding environment variable for \n a specific device number, including the host device, is set, then the setting for that environment \n variable is used to set the value of the associated ICV of the device with the corresponding device \n number."}
{"section_title": "21 Environment Variables", "chunk": "If the corresponding environment variable for \n a specific device number, including the host device, is set, then the setting for that environment \n variable is used to set the value of the associated ICV of the device with the corresponding device \n number.If the corresponding environment variable that includes the _DEV suffix but no device \n number is set, then the setting of that environment variable is used to set the value of the associated \n ICV of any non-host device for which the device-number-specific corresponding environment \n variable is not set.In all cases the setting of an environment variable for which a device number is \n specified takes precedence.\n Restrictions \n Restrictions to device-specific environment variables are as follows: \n \u2022 Device-specific environment variables must not correspond to environment variables that \n initialize ICVs with global scope.\n \n"}
{"section_title": "21.1 Parallel Region Environment Variables", "chunk": "2 This section defines environment variables that affect the operation of parallel regions.\n"}
{"section_title": "21.1.1 OMP_DYNAMIC", "chunk": "4 The OMP_DYNAMIC environment variable controls dynamic adjustment of the number of threads \n to use for executing parallel regions by setting the initial value of the dyn-var ICV.\n The value of this environment variable must be one of the following: \n true | false \n If the environment variable is set to true, the OpenMP implementation may adjust the number of \n threads to use for executing parallel regions in order to optimize the use of system resources.If \n the environment variable is set to false, the dynamic adjustment of the number of threads is \n disabled.The behavior of the program is implementation defined if the value of OMP_DYNAMIC is \n neither true nor false.\n Example: \n setenv OMP_DYNAMIC true \n Cross References \n \u2022 omp_get_dynamic, see Section 18.2.7 \n \u2022 omp_set_dynamic, see Section 18.2.6 \n \u2022 dyn-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "21.1.2 OMP_NUM_THREADS", "chunk": "21 The OMP_NUM_THREADS environment variable sets the number of threads to use for parallel \n regions by setting the initial value of the nthreads-var ICV.See Chapter 2 for a comprehensive set \n of rules about the interaction between the OMP_NUM_THREADS environment variable, the \n num_threads clause, the omp_set_num_threads library routine and dynamic adjustment of \n threads, and Section 10.1.1 for a complete algorithm that describes how the number of threads for a \n parallel region is determined.\n The value of this environment variable must be a list of positive integer values.The values of the \n list set the number of threads to use for parallel regions at the corresponding nested levels.\n The behavior of the program is implementation defined if any value of the list specified in the \n OMP_NUM_THREADS environment variable leads to a number of threads that is greater than an \n implementation can support, or if any value is not a positive integer."}
{"section_title": "21.1.2 OMP_NUM_THREADS", "chunk": "\n The behavior of the program is implementation defined if any value of the list specified in the \n OMP_NUM_THREADS environment variable leads to a number of threads that is greater than an \n implementation can support, or if any value is not a positive integer.\n OpenMP API \u2013 Version 5.2 November 2021 \n The OMP_NUM_THREADS environment variable sets the max-active-levels-var ICV to the number \n of active levels of parallelism that the implementation supports if the OMP_NUM_THREADS \n environment variable is set to a comma-separated list of more than one value.The value of the \n max-active-level-var ICV may be overridden by setting OMP_MAX_ACTIVE_LEVELS or \n OMP_NESTED.See Section 21.1.4 and Section 21.1.5 for details."}
{"section_title": "21.1.2 OMP_NUM_THREADS", "chunk": "See Section 21.1.4 and Section 21.1.5 for details.\n Example: \n setenv OMP_NUM_THREADS 4,3,2 \n Cross References \n \u2022 OMP_MAX_ACTIVE_LEVELS, see Section 21.1.4 \n \u2022 OMP_NESTED (Deprecated), see Section 21.1.5 \n \u2022 omp_set_num_threads, see Section 18.2.1 \n \u2022 nthreads-var ICV, see Table 2.1 \n \u2022 num_threads clause, see Section 10.1.2 \n \u2022 parallel directive, see Section 10.1 \n"}
{"section_title": "21.1.3 OMP_THREAD_LIMIT", "chunk": "16 The OMP_THREAD_LIMIT environment variable sets the maximum number of OpenMP threads \n to use in a contention group by setting the thread-limit-var ICV.The value of this environment \n variable must be a positive integer.The behavior of the program is implementation defined if the \n requested value of OMP_THREAD_LIMIT is greater than the number of threads an implementation \n can support, or if the value is not a positive integer.\n Cross References \n \u2022 thread-limit-var ICV, see Table 2.1 \n"}
{"section_title": "21.1.4 OMP_MAX_ACTIVE_LEVELS", "chunk": "24 The OMP_MAX_ACTIVE_LEVELS environment variable controls the maximum number of nested \n active parallel regions by setting the initial value of the max-active-levels-var ICV.The value \n of this environment variable must be a non-negative integer.The behavior of the program is \n implementation defined if the requested value of OMP_MAX_ACTIVE_LEVELS is greater than the \n maximum number of nested active parallel levels an implementation can support, or if the value is \n not a non-negative integer.\n Cross References \n \u2022 max-active-levels-var ICV, see Table 2.1 \nCHAPTER 21.ENVIRONMENT VARIABLES 601 \n"}
{"section_title": "21.1.5 OMP_NESTED (Deprecated)", "chunk": "2 The OMP_NESTED environment variable controls nested parallelism by setting the initial value of \n the max-active-levels-var ICV.If the environment variable is set to true, the initial value of \n max-active-levels-var is set to the number of active levels of parallelism supported by the \n implementation.If the environment variable is set to false, the initial value of \n max-active-levels-var is set to 1.The behavior of the program is implementation defined if the \n value of OMP_NESTED is neither true nor false.\n If both the OMP_NESTED and OMP_MAX_ACTIVE_LEVELS environment variables are set, the \n value of OMP_NESTED is false, and the value of OMP_MAX_ACTIVE_LEVELS is greater than \n 1, then the behavior is implementation defined.Otherwise, if both environment variables are set \n then the OMP_NESTED environment variable has no effect.\n The OMP_NESTED environment variable has been deprecated."}
{"section_title": "21.1.5 OMP_NESTED (Deprecated)", "chunk": "\n The OMP_NESTED environment variable has been deprecated.\n Example: \n setenv OMP_NESTED false \n Cross References \n \u2022 OMP_MAX_ACTIVE_LEVELS, see Section 21.1.4 \n \u2022 max-active-levels-var ICV, see Table 2.1 \n"}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "19 The OMP_PLACES environment variable sets the initial value of the place-partition-var ICV.A list \n of places can be specified in the OMP_PLACES environment variable.The value of OMP_PLACES \n can be one of two types of values: either an abstract name that describes a set of places or an \n explicit list of places described by non-negative numbers.\n The OMP_PLACES environment variable can be defined using an explicit ordered list of \n comma-separated places.A place is defined by an unordered set of comma-separated non-negative \n numbers enclosed by braces, or a non-negative number.The meaning of the numbers and how the \n numbering is done are implementation defined.Generally, the numbers represent the smallest unit \n of execution exposed by the execution environment, typically a hardware thread.\n Intervals may also be used to define places."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "\n Intervals may also be used to define places.Intervals can be specified using the <lower-bound> : \n <length> : <stride> notation to represent the following list of numbers: \u201c<lower-bound>, \n <lower-bound> + <stride>, ..., <lower-bound> + (<length> - 1)*<stride>.\u201d When <stride> is \n omitted, a unit stride is assumed.Intervals can specify numbers within a place as well as sequences \n of places.\n An exclusion operator \u201c!\u201d can also be used to exclude the number or place immediately following \n the operator.\n OpenMP API \u2013 Version 5.2 November 2021 \n Alternatively, the abstract names listed in Table 21.1 should be understood by the execution and \n runtime environment.The precise definitions of the abstract names are implementation defined.An \n implementation may also add abstract names as appropriate for the target platform."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "An \n implementation may also add abstract names as appropriate for the target platform.\n The abstract name may be appended by a positive number in parentheses to denote the length of the \n place list to be created, that is abstract_name(num-places).When requesting fewer places than \n available on the system, the determination of which resources of type abstract_name are to be \n included in the place list is implementation defined.When requesting more resources than \n available, the length of the place list is implementation defined.\nTABLE 21.1: Predefined Abstract Names for OMP_PLACES \nAbstract Name Meaning \nthreads Each place corresponds to a single hardware thread on the de\ufffevice.\ncores Each place corresponds to a single core (having one or more \nhardware threads) on the device.\nll_caches Each place corresponds to a set of cores that share the last \nlevel cache on the device."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "\nll_caches Each place corresponds to a set of cores that share the last \nlevel cache on the device.\nnuma_domains Each place corresponds to a set of cores for which their closest \nmemory on the device is: \n\u2022 the same memory; and \n\u2022 at a similar distance from the cores.\nsockets Each place corresponds to a single socket (consisting of one or \nmore cores) on the device.\n The behavior of the program is implementation defined when the execution environment cannot \n map a numerical value (either explicitly defined or implicitly derived from an interval) within the \n OMP_PLACES list to a processor on the target platform, or if it maps to an unavailable processor.\n The behavior is also implementation defined when the OMP_PLACES environment variable is \n defined using an abstract name.\n The following grammar describes the values accepted for the OMP_PLACES environment variable."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "\n The following grammar describes the values accepted for the OMP_PLACES environment variable.\nhlisti |= hp-listi | hanamei \nhp-listi |= hp-intervali | hp-listi,hp-intervali \nhp-intervali |= hplacei:hleni:hstridei | hplacei:hleni | hplacei | !hplacei \nhplacei |= {hres-listi} | hresi \nhres-listi |= hres-intervali | hres-listi,hres-intervali \nhres-intervali |= hresi:hnum-placesi:hstridei | hresi:hnum-placesi | hresi | !hresi \nCHAPTER 21."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "\nhlisti |= hp-listi | hanamei \nhp-listi |= hp-intervali | hp-listi,hp-intervali \nhp-intervali |= hplacei:hleni:hstridei | hplacei:hleni | hplacei | !hplacei \nhplacei |= {hres-listi} | hresi \nhres-listi |= hres-intervali | hres-listi,hres-intervali \nhres-intervali |= hresi:hnum-placesi:hstridei | hresi:hnum-placesi | hresi | !hresi \nCHAPTER 21.ENVIRONMENT VARIABLES 603 \nhanamei |= hwordi(hnum-placesi) | hwordi \nhwordi |= sockets | cores | ll_caches | numa_domains \n| threads | <implementation-defined abstract name> \nhresi |= non-negative integer \nhnum-placesi |= positive integer \nhstridei |= integer \nhleni |= positive integer \n Examples: \n setenv OMP_PLACES threads \n setenv OMP_PLACES \"threads(4)\" \n setenv OMP_PLACES \n \"{0,1,2,3},{4,5,6,7},{8,9,10,11},{12,13,14,15}\" \n setenv OMP_PLACES \"{0:4},{4:4},{8:4},{12:4}\" \n setenv OMP_PLACES \"{0:4}:4:4\" \n where each of the last three definitions corresponds to the same 4 places including the smallest \n units of execution exposed by the execution environment numbered, in turn, 0 to 3, 4 to 7, 8 to 11, \n and 12 to 15."}
{"section_title": "21.1.6 OMP_PLACES", "chunk": "ENVIRONMENT VARIABLES 603 \nhanamei |= hwordi(hnum-placesi) | hwordi \nhwordi |= sockets | cores | ll_caches | numa_domains \n| threads | <implementation-defined abstract name> \nhresi |= non-negative integer \nhnum-placesi |= positive integer \nhstridei |= integer \nhleni |= positive integer \n Examples: \n setenv OMP_PLACES threads \n setenv OMP_PLACES \"threads(4)\" \n setenv OMP_PLACES \n \"{0,1,2,3},{4,5,6,7},{8,9,10,11},{12,13,14,15}\" \n setenv OMP_PLACES \"{0:4},{4:4},{8:4},{12:4}\" \n setenv OMP_PLACES \"{0:4}:4:4\" \n where each of the last three definitions corresponds to the same 4 places including the smallest \n units of execution exposed by the execution environment numbered, in turn, 0 to 3, 4 to 7, 8 to 11, \n and 12 to 15.\n Cross References \n \u2022 place-partition-var ICV, see Table 2.1 \n"}
{"section_title": "21.1.7 OMP_PROC_BIND", "chunk": "14 The OMP_PROC_BIND environment variable sets the initial value of the bind-var ICV.The value \n of this environment variable is either true, false, or a comma separated list of primary, \n master (master has been deprecated), close, or spread.The values of the list set the thread \n affinity policy to be used for parallel regions at the corresponding nested level.\n If the environment variable is set to false, the execution environment may move OpenMP threads \n between OpenMP places, thread affinity is disabled, and proc_bind clauses on parallel \n constructs are ignored.\n Otherwise, the execution environment should not move OpenMP threads between OpenMP places, \n thread affinity is enabled, and the initial thread is bound to the first place in the place-partition-var \n ICV prior to the first active parallel region."}
{"section_title": "21.1.7 OMP_PROC_BIND", "chunk": "\n Otherwise, the execution environment should not move OpenMP threads between OpenMP places, \n thread affinity is enabled, and the initial thread is bound to the first place in the place-partition-var \n ICV prior to the first active parallel region.An initial thread that is created by a teams construct is \n bound to the first place in its place-partition-var ICV before it begins execution of the associated \n structured block.\n If the environment variable is set to true, the thread affinity policy is implementation defined but \n must conform to the previous paragraph.The behavior of the program is implementation defined if \n the value in the OMP_PROC_BIND environment variable is not true, false, or a comma \n OpenMP API \u2013 Version 5.2 November 2021 \n separated list of primary, master (master has been deprecated), close, or spread.The \n behavior is also implementation defined if an initial thread cannot be bound to the first place in the \n place-partition-var ICV."}
{"section_title": "21.1.7 OMP_PROC_BIND", "chunk": "The \n behavior is also implementation defined if an initial thread cannot be bound to the first place in the \n place-partition-var ICV.\n The OMP_PROC_BIND environment variable sets the max-active-levels-var ICV to the number of \n active levels of parallelism that the implementation supports if the OMP_PROC_BIND environment \n variable is set to a comma-separated list of more than one element.The value of the \n max-active-level-var ICV may be overridden by setting OMP_MAX_ACTIVE_LEVELS or \n OMP_NESTED.See Section 21.1.4 and Section 21.1.5 for details."}
{"section_title": "21.1.7 OMP_PROC_BIND", "chunk": "See Section 21.1.4 and Section 21.1.5 for details.\n Examples: \n setenv OMP_PROC_BIND false \n setenv OMP_PROC_BIND \"spread, spread, close\" \n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 OMP_MAX_ACTIVE_LEVELS, see Section 21.1.4 \n \u2022 OMP_NESTED (Deprecated), see Section 21.1.5 \n \u2022 omp_get_proc_bind, see Section 18.3.1 \n \u2022 bind-var ICV, see Table 2.1 \n \u2022 max-active-levels-var ICV, see Table 2.1 \n \u2022 parallel directive, see Section 10.1 \n \u2022 place-partition-var ICV, see Table 2.1 \n \u2022 proc_bind clause, see Section 10.1.4 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "21.2 Program Execution Environment Variables", "chunk": "24 This section defines environment variables that affect program execution.\n"}
{"section_title": "21.2.1 OMP_SCHEDULE", "chunk": "26 The OMP_SCHEDULE environment variable controls the schedule kind and chunk size of all \n worksharing-loop directives that have the schedule kind runtime, by setting the value of the \n run-sched-var ICV.The value of this environment variable takes the form [modifier:]kind[, chunk], \n where: \n \u2022 modifier is one of monotonic or nonmonotonic; \n \u2022 kind is one of static, dynamic, guided, or auto; \n \u2022 chunk is an optional positive integer that specifies the chunk size.\nCHAPTER 21.ENVIRONMENT VARIABLES 605 \n If the modifier is not present, the modifier is set to monotonic if kind is static; for any other \n kind it is set to nonmonotonic.\n If chunk is present, white space may be on either side of the \u201c,\u201d.See Section 11.5.3 for a detailed \n description of the schedule kinds.\n The behavior of the program is implementation defined if the value of OMP_SCHEDULE does not \n conform to the above format."}
{"section_title": "21.2.1 OMP_SCHEDULE", "chunk": "\n The behavior of the program is implementation defined if the value of OMP_SCHEDULE does not \n conform to the above format.\n Examples: \n setenv OMP_SCHEDULE \"guided,4\" \n setenv OMP_SCHEDULE \"dynamic\" \n setenv OMP_SCHEDULE \"nonmonotonic:dynamic,4\" \n Cross References \n \u2022 run-sched-var ICV, see Table 2.1 \n \u2022 schedule clause, see Section 11.5.3 \n"}
{"section_title": "21.2.2 OMP_STACKSIZE", "chunk": "15 The OMP_STACKSIZE environment variable controls the size of the stack for threads created by \n the OpenMP implementation, by setting the value of the stacksize-var ICV.The environment \n variable does not control the size of the stack for an initial thread.The value of this environment \n variable takes the form size[unit], where: \n \u2022 size is a positive integer that specifies the size of the stack for threads that are created by the \n OpenMP implementation.\n \u2022 unit is B, K, M, or G and specifies whether the given size is in Bytes, Kilobytes (1024 Bytes), \n Megabytes (1024 Kilobytes), or Gigabytes (1024 Megabytes), respectively.If unit is present, \n white space may occur between size and it, whereas if unit is not present then K is assumed.\n The behavior of the program is implementation defined if OMP_STACKSIZE does not conform to \n the above format, or if the implementation cannot provide a stack with the requested size."}
{"section_title": "21.2.2 OMP_STACKSIZE", "chunk": "\n The behavior of the program is implementation defined if OMP_STACKSIZE does not conform to \n the above format, or if the implementation cannot provide a stack with the requested size.\n Examples: \n setenv OMP_STACKSIZE 2000500B \n setenv OMP_STACKSIZE \"3000 k \" \n setenv OMP_STACKSIZE 10M \n setenv OMP_STACKSIZE \" 10 M \" \n setenv OMP_STACKSIZE \"20 m \" \n setenv OMP_STACKSIZE \" 1G\" \n setenv OMP_STACKSIZE 20000 \n Cross References \n \u2022 stacksize-var ICV, see Table 2.1 \n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "21.2.3 OMP_WAIT_POLICY", "chunk": "2 The OMP_WAIT_POLICY environment variable provides a hint to an OpenMP implementation \n about the desired behavior of waiting threads by setting the wait-policy-var ICV.A compliant \n OpenMP implementation may or may not abide by the setting of the environment variable.The \n value of this environment variable must be one of the following: \n active | passive \n The active value specifies that waiting threads should mostly be active, consuming processor \n cycles, while waiting.An OpenMP implementation may, for example, make waiting threads spin.\n The passive value specifies that waiting threads should mostly be passive, not consuming \n processor cycles, while waiting.For example, an OpenMP implementation may make waiting \n threads yield the processor to other threads or go to sleep.The details of the active and \n passive behaviors are implementation defined.The behavior of the program is implementation \n defined if the value of OMP_WAIT_POLICY is neither active nor passive."}
{"section_title": "21.2.3 OMP_WAIT_POLICY", "chunk": "The behavior of the program is implementation \n defined if the value of OMP_WAIT_POLICY is neither active nor passive.\n Examples: \n setenv OMP_WAIT_POLICY ACTIVE \n setenv OMP_WAIT_POLICY active \n setenv OMP_WAIT_POLICY PASSIVE \n setenv OMP_WAIT_POLICY passive \n Cross References \n \u2022 wait-policy-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.4 OMP_DISPLAY_AFFINITY", "chunk": "22 The OMP_DISPLAY_AFFINITY environment variable instructs the runtime to display formatted \n affinity information by setting the display-affinity-var ICV.Affinity information is printed for all \n OpenMP threads in the parallel region upon entering it and when any change occurs in the \n information accessible by the format specifiers listed in Table 21.2.If affinity of any thread in a \n parallel region changes then thread affinity information for all threads in that region is displayed.If \n the thread affinity for each respective parallel region at each nesting level has already been displayed \n and the thread affinity has not changed, then the information is not displayed again.Thread affinity \n information for threads in the same parallel region may be displayed in any order."}
{"section_title": "21.2.4 OMP_DISPLAY_AFFINITY", "chunk": "Thread affinity \n information for threads in the same parallel region may be displayed in any order.The value of the \n OMP_DISPLAY_AFFINITY environment variable may be set to one of these values: \n true | false \n The true value instructs the runtime to display the OpenMP thread affinity information, and uses \n the format setting defined in the affinity-format-var ICV.The runtime does not display the OpenMP \n thread affinity information when the value of the OMP_DISPLAY_AFFINITY environment \n variable is false or undefined.For all values of the environment variable other than true or \n false, the display action is implementation defined.\nCHAPTER 21.ENVIRONMENT VARIABLES 607 \n Example: \n setenv OMP_DISPLAY_AFFINITY TRUE \n For this example, an OpenMP implementation displays thread affinity information during program \n execution, in a format given by the affinity-format-var ICV."}
{"section_title": "21.2.4 OMP_DISPLAY_AFFINITY", "chunk": "ENVIRONMENT VARIABLES 607 \n Example: \n setenv OMP_DISPLAY_AFFINITY TRUE \n For this example, an OpenMP implementation displays thread affinity information during program \n execution, in a format given by the affinity-format-var ICV.The following is a sample output: \n nesting_level= 1, thread_num= 0, thread_affinity= 0,1 \n nesting_level= 1, thread_num= 1, thread_affinity= 2,3 \n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 OMP_AFFINITY_FORMAT, see Section 21.2.5 \n \u2022 affinity-format-var ICV, see Table 2.1 \n \u2022 display-affinity-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.5 OMP_AFFINITY_FORMAT", "chunk": "13 The OMP_AFFINITY_FORMAT environment variable sets the initial value of the \n affinity-format-var ICV which defines the format when displaying OpenMP thread affinity \n information.The value of this environment variable is case sensitive and leading and trailing \n whitespace is significant.Its value is a character string that may contain as substrings one or more \n field specifiers (as well as other characters).The format of each field specifier is \n %[[[0].] size ] type \n where each specifier must contain the percent symbol (%) and a type, that must be either a single \n character short name or its corresponding long name delimited with curly braces, such as %n or \n %{thread_num}.A literal percent is specified as %%.Field specifiers can be provided in any \n order.The behavior is implementation defined for field specifiers that do not conform to this format."}
{"section_title": "21.2.5 OMP_AFFINITY_FORMAT", "chunk": "The behavior is implementation defined for field specifiers that do not conform to this format.\n The 0 modifier indicates whether or not to add leading zeros to the output, following any indication \n of sign or base.The .modifier indicates the output should be right justified when size is specified.\n By default, output is left justified.The minimum field length is size, which is a decimal digit string \n with a non-zero first digit.If no size is specified, the actual length needed to print the field will be \n used.If the 0 modifier is used with type of A, {thread_affinity}, H, {host}, or a type that \n is not printed as a number, the result is unspecified.Any other characters in the format string that \n are not part of a field specifier will be included literally in the output.\n Implementations may define additional field types."}
{"section_title": "21.2.5 OMP_AFFINITY_FORMAT", "chunk": "\n Implementations may define additional field types.If an implementation does not have information \n for a field type or an unknown field type is part of a field specifier, \"undefined\" is printed for this \n field when displaying the OpenMP thread affinity information.\n OpenMP API \u2013 Version 5.2 November 2021 \nTABLE 21.2: Available Field Types for Formatting OpenMP Thread Affinity Information \nShort \nName \nLong Name Meaning \nt team_num The value returned by omp_get_team_num().\nT num_teams The value returned by omp_get_num_teams().\nL nesting_level The value returned by omp_get_level().\nn thread_num The value returned by omp_get_thread_num().\nN num_threads The value returned by omp_get_num_threads().\na ancestor_tnum The value returned by \nomp_get_ancestor_thread_num(level), \nwhere level is omp_get_level() minus 1.\nH host The name for the host device on which the OpenMP pro\ufffegram is running.\nP process_id The process identifier used by the implementation."}
{"section_title": "21.2.5 OMP_AFFINITY_FORMAT", "chunk": "\nP process_id The process identifier used by the implementation.\ni native_thread_id The native thread identifier used by the implementation.\nA thread_affinity The list of numerical identifiers, in the format of a comma\ufffeseparated list of integers or integer ranges, that represent \nprocessors on which a thread may execute, subject to \nOpenMP thread affinity control and/or other external affin\ufffeity mechanisms.\n Example: \n setenv OMP_AFFINITY_FORMAT \n \"Thread Affinity: %0.3L %.8n %.15{thread_affinity} %.12H\" \n The above example causes an OpenMP implementation to display OpenMP thread affinity \n information in the following form: \n Thread Affinity: 001 0 0-1,16-17 nid003 \n Thread Affinity: 001 1 2-3,18-19 nid003 \n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 omp_get_ancestor_thread_num, see Section 18.2.18 \n \u2022 omp_get_level, see Section 18.2.17 \n \u2022 omp_get_num_teams, see Section 18.4.1 \nCHAPTER 21."}
{"section_title": "21.2.5 OMP_AFFINITY_FORMAT", "chunk": "\n Example: \n setenv OMP_AFFINITY_FORMAT \n \"Thread Affinity: %0.3L %.8n %.15{thread_affinity} %.12H\" \n The above example causes an OpenMP implementation to display OpenMP thread affinity \n information in the following form: \n Thread Affinity: 001 0 0-1,16-17 nid003 \n Thread Affinity: 001 1 2-3,18-19 nid003 \n Cross References \n \u2022 Controlling OpenMP Thread Affinity, see Section 10.1.3 \n \u2022 omp_get_ancestor_thread_num, see Section 18.2.18 \n \u2022 omp_get_level, see Section 18.2.17 \n \u2022 omp_get_num_teams, see Section 18.4.1 \nCHAPTER 21.ENVIRONMENT VARIABLES 609 \n \u2022 omp_get_num_threads, see Section 18.2.2 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 omp_get_thread_num, see Section 18.2.4 \n \u2022 affinity-format-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.6 OMP_CANCELLATION", "chunk": "6 The OMP_CANCELLATION environment variable sets the initial value of the cancel-var ICV.The \n value of this environment variable must be one of the following: \n true|false \n If the environment variable is set to true, the effects of the cancel construct and of cancellation \n points are enabled (i.e., cancellation is enabled).If the environment variable is set to false, \n cancellation is disabled and the cancel construct and cancellation points are effectively ignored.\n The behavior of the program is implementation defined if OMP_CANCELLATION is set to neither \n true nor false.\n Cross References \n \u2022 cancel directive, see Section 16.1 \n \u2022 cancel-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.7 OMP_DEFAULT_DEVICE", "chunk": "18 The OMP_DEFAULT_DEVICE environment variable sets the device number to use in device \n constructs by setting the initial value of the default-device-var ICV.The value of this environment \n variable must be a non-negative integer value.\n Cross References \n \u2022 Device Directives and Clauses, see Chapter 13 \n \u2022 default-device-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.8 OMP_TARGET_OFFLOAD", "chunk": "25 The OMP_TARGET_OFFLOAD environment variable sets the initial value of the target-offload-var \n ICV.Its value must be one of the following: \n mandatory | disabled | default \n The mandatory value specifies that the effect of any device construct or device memory routine \n that uses a device that is unavailable or not supported by the implementation, or uses a \n non-conforming device number, is as if the omp_invalid_device device number was used.\n OpenMP API \u2013 Version 5.2 November 2021 \n Support for the disabled value is implementation defined.If an implementation supports it, the \n behavior is as if the only device is the host device.The default value specifies the default \n behavior as described in Section 1.3.\n Example: \n % setenv OMP_TARGET_OFFLOAD mandatory \n Cross References \n \u2022 Device Directives and Clauses, see Chapter 13 \n \u2022 Device Memory Routines, see Section 18.8 \n \u2022 target-offload-var ICV, see Table 2.1 \n"}
{"section_title": "21.2.9 OMP_MAX_TASK_PRIORITY", "chunk": "11 The OMP_MAX_TASK_PRIORITY environment variable controls the use of task priorities by \n setting the initial value of the max-task-priority-var ICV.The value of this environment variable \n must be a non-negative integer.\n Example: \n % setenv OMP_MAX_TASK_PRIORITY 20 \n Cross References \n \u2022 max-task-priority-var ICV, see Table 2.1 \n"}
{"section_title": "21.3 OMPT Environment Variables", "chunk": "19 This section defines environment variables that affect operation of the OMPT tool interface.\n"}
{"section_title": "21.3.1 OMP_TOOL", "chunk": "21 The OMP_TOOL environment variable sets the tool-var ICV, which controls whether an OpenMP \n runtime will try to register a first party tool.The value of this environment variable must be one of \n the following: \n enabled | disabled \n If OMP_TOOL is set to any value other than enabled or disabled, the behavior is unspecified.\n If OMP_TOOL is not defined, the default value for tool-var is enabled.\n Example: \n % setenv OMP_TOOL enabled \n Cross References \n \u2022 OMPT Interface, see Chapter 19 \n \u2022 tool-var ICV, see Table 2.1 \nCHAPTER 21.ENVIRONMENT VARIABLES 611 \n"}
{"section_title": "21.3.2 OMP_TOOL_LIBRARIES", "chunk": "2 The OMP_TOOL_LIBRARIES environment variable sets the tool-libraries-var ICV to a list of tool \n libraries that are considered for use on a device on which an OpenMP implementation is being \n initialized.The value of this environment variable must be a list of names of dynamically-loadable \n libraries, separated by an implementation specific, platform typical separator.Whether the value of \n this environment variable is case sensitive is implementation defined.\n If the tool-var ICV is not enabled, the value of tool-libraries-var is ignored.Otherwise, if \n ompt_start_tool is not visible in the address space on a device where OpenMP is being \n initialized or if ompt_start_tool returns NULL, an OpenMP implementation will consider \n libraries in the tool-libraries-var list in a left-to-right order."}
{"section_title": "21.3.2 OMP_TOOL_LIBRARIES", "chunk": "Otherwise, if \n ompt_start_tool is not visible in the address space on a device where OpenMP is being \n initialized or if ompt_start_tool returns NULL, an OpenMP implementation will consider \n libraries in the tool-libraries-var list in a left-to-right order.The OpenMP implementation will \n search the list for a library that meets two criteria: it can be dynamically loaded on the current \n device and it defines the symbol ompt_start_tool.If an OpenMP implementation finds a \n suitable library, no further libraries in the list will be considered.\n Example: \n % setenv OMP_TOOL_LIBRARIES libtoolXY64.so:/usr/local/lib/ \n libtoolXY32.so \n Cross References \n \u2022 OMPT Interface, see Chapter 19 \n \u2022 ompt_start_tool, see Section 19.2.1 \n \u2022 tool-libraries-var ICV, see Table 2.1 \n"}
{"section_title": "21.3.3 OMP_TOOL_VERBOSE_INIT", "chunk": "22 The OMP_TOOL_VERBOSE_INIT environment variable sets the tool-verbose-init-var ICV, which \n controls whether an OpenMP implementation will verbosely log the registration of a tool.The \n value of this environment variable must be one of the following: \n disabled | stdout | stderr | <filename> \n If OMP_TOOL_VERBOSE_INIT is set to any value other than case insensitive disabled, \n stdout, or stderr, the value is interpreted as a filename and the OpenMP runtime will try to \n log to a file with prefix filename.If the value is interpreted as a filename, whether it is case \n sensitive is implementation defined.If opening the logfile fails, the output will be redirected to \n stderr.If OMP_TOOL_VERBOSE_INIT is not defined, the default value for tool-verbose-init-var \n is disabled.Support for logging to stdout or stderr is implementation defined."}
{"section_title": "21.3.3 OMP_TOOL_VERBOSE_INIT", "chunk": "Support for logging to stdout or stderr is implementation defined.Unless \n tool-verbose-init-var is disabled, the OpenMP runtime will log the steps of the tool activation \n process defined in Section 19.2.2 to a file with a name that is constructed using the provided \n filename prefix.The format and detail of the log is implementation defined.At a minimum, the log \n will contain one of the following: \n \u2022 That the tool-var ICV is disabled; \n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 An indication that a tool was available in the address space at program launch; or \n \u2022 The path name of each tool in OMP_TOOL_LIBRARIES that is considered for dynamic loading, \n whether dynamic loading was successful, and whether the ompt_start_tool function is \n found in the loaded library.\n In addition, if an ompt_start_tool function is called the log will indicate whether or not the \n tool will use the OMPT interface."}
{"section_title": "21.3.3 OMP_TOOL_VERBOSE_INIT", "chunk": "\n In addition, if an ompt_start_tool function is called the log will indicate whether or not the \n tool will use the OMPT interface.\n Example: \n % setenv OMP_TOOL_VERBOSE_INIT disabled \n % setenv OMP_TOOL_VERBOSE_INIT STDERR \n % setenv OMP_TOOL_VERBOSE_INIT ompt_load.log \n Cross References \n \u2022 OMPT Interface, see Chapter 19 \n \u2022 tool-verbose-init-var ICV, see Table 2.1 \n"}
{"section_title": "21.4 OMPD Environment Variables", "chunk": "15 This section defines environment variables that affect operation of the OMPD tool interface.\n"}
{"section_title": "21.4.1 OMP_DEBUG", "chunk": "17 The OMP_DEBUG environment variable sets the debug-var ICV, which controls whether an \n OpenMP runtime collects information that an OMPD library may need to support a tool.The value \n of this environment variable must be one of the following: \n enabled | disabled \n If OMP_DEBUG is set to any value other than enabled or disabled then the behavior is \n implementation defined.\n Example: \n % setenv OMP_DEBUG enabled \n Cross References \n \u2022 Enabling Runtime Support for OMPD, see Section 20.2.1 \n \u2022 OMPD Interface, see Chapter 20 \n \u2022 debug-var ICV, see Table 2.1 \nCHAPTER 21.ENVIRONMENT VARIABLES 613 \n"}
{"section_title": "21.5 Memory Allocation Environment Variables", "chunk": "2 This section defines environment variables that affect memory allocations.\n"}
{"section_title": "21.5.1 OMP_ALLOCATOR", "chunk": "4 The OMP_ALLOCATOR environment variable sets the initial value of the def-allocator-var ICV \n that specifies the default allocator for allocation calls, directives and clauses that do not specify an \n allocator.The following grammar describes the values accepted for the OMP_ALLOCATOR \n environment variable.\nhallocatori |= hpredef-allocatori | hpredef-mem-spacei | hpredef-mem-spacei:htraitsi \nhtraitsi |= htraiti=hvaluei | htraiti=hvaluei,htraitsi \nhpredef-allocatori |= one of the predefined allocators from Table 6.3 \nhpredef-mem-spacei |= one of the predefined memory spaces from Table 6.1 \nhtraiti |= one of the allocator trait names from Table 6.2 \nhvaluei |= one of the allowed values from Table 6.2 | non-negative integer \n| hpredef-allocatori \n The value can be an integer only if the trait accepts a numerical value, for the fb_data trait the \n value can only be predef-allocator."}
{"section_title": "21.5.1 OMP_ALLOCATOR", "chunk": "\nhallocatori |= hpredef-allocatori | hpredef-mem-spacei | hpredef-mem-spacei:htraitsi \nhtraitsi |= htraiti=hvaluei | htraiti=hvaluei,htraitsi \nhpredef-allocatori |= one of the predefined allocators from Table 6.3 \nhpredef-mem-spacei |= one of the predefined memory spaces from Table 6.1 \nhtraiti |= one of the allocator trait names from Table 6.2 \nhvaluei |= one of the allowed values from Table 6.2 | non-negative integer \n| hpredef-allocatori \n The value can be an integer only if the trait accepts a numerical value, for the fb_data trait the \n value can only be predef-allocator.If the value of this environment variable is not a predefined \n allocator, then a new allocator with the given predefined memory space and optional traits is \n created and set as the def-allocator-var ICV.If the new allocator cannot be created, the \n def-allocator-var ICV will be set to omp_default_mem_alloc."}
{"section_title": "21.5.1 OMP_ALLOCATOR", "chunk": "If the new allocator cannot be created, the \n def-allocator-var ICV will be set to omp_default_mem_alloc.\n Example: \n setenv OMP_ALLOCATOR omp_high_bw_mem_alloc \n setenv OMP_ALLOCATOR omp_large_cap_mem_space:alignment=16,\\ \n pinned=true \n setenv OMP_ALLOCATOR omp_high_bw_mem_space:pool_size=1048576,\\ \n fallback=allocator_fb,fb_data=omp_low_lat_mem_alloc \n Cross References \n \u2022 Memory Allocators, see Section 6.2 \n \u2022 def-allocator-var ICV, see Table 2.1 \n"}
{"section_title": "21.6 Teams Environment Variables", "chunk": "23 This section defines environment variables that affect the operation of teams regions.\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "21.6.1 OMP_NUM_TEAMS", "chunk": "2 The OMP_NUM_TEAMS environment variable sets the maximum number of teams created by a \n teams construct by setting the nteams-var ICV.The value of this environment variable must be a \n positive integer.The behavior of the program is implementation defined if the requested value of \n OMP_NUM_TEAMS is greater than the number of teams that an implementation can support, or if \n the value is not a positive integer.\n Cross References \n \u2022 nteams-var ICV, see Table 2.1 \n \u2022 teams directive, see Section 10.2 \n"}
{"section_title": "21.6.2 OMP_TEAMS_THREAD_LIMIT", "chunk": "11 The OMP_TEAMS_THREAD_LIMIT environment variable sets the maximum number of OpenMP \n threads to use in each contention group created by a teams construct by setting the \n teams-thread-limit-var ICV.The value of this environment variable must be a positive integer.The \n behavior of the program is implementation defined if the requested value of \n OMP_TEAMS_THREAD_LIMIT is greater than the number of threads that an implementation can \n support, or if the value is not a positive integer.\n Cross References \n \u2022 teams directive, see Section 10.2 \n \u2022 teams-thread-limit-var ICV, see Table 2.1 \n"}
{"section_title": "21.7 OMP_DISPLAY_ENV", "chunk": "21 The OMP_DISPLAY_ENV environment variable instructs the runtime to display the information as \n described in the omp_display_env routine section (Section 18.15).The value of the \n OMP_DISPLAY_ENV environment variable may be set to one of these values: \n true | false | verbose \n If the environment variable is set to true, the effect is as if the omp_display_env routine is \n called with the verbose argument set to false at the beginning of the program.If the environment \n variable is set to verbose, the effect is as if the omp_display_env routine is called with the \n verbose argument set to true at the beginning of the program.If the environment variable is \n undefined or set to false, the runtime does not display any information.For all values of the \n environment variable other than true, false, and verbose, the displayed information is \n unspecified.\n Example: \n % setenv OMP_DISPLAY_ENV true \n For the output of the above example, see Section 18.15."}
{"section_title": "21.7 OMP_DISPLAY_ENV", "chunk": "\n Example: \n % setenv OMP_DISPLAY_ENV true \n For the output of the above example, see Section 18.15.\n Cross References \n \u2022 Environment Display Routine, see Section 18.15 \nCHAPTER 21.ENVIRONMENT VARIABLES 615 \n"}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "2 Behaviors \n This appendix summarizes the behaviors that are described as implementation defined in the \n OpenMP API.Each behavior is cross-referenced back to its description in the main specification.\n An implementation is required to define and to document its behavior in these cases.\n Chapter 1: \n \u2022 Processor: A hardware unit that is implementation defined (see Section 1.2.1).\n \u2022 Device: An implementation-defined logical execution engine (see Section 1.2.1).\n \u2022 Device pointer: An implementation-defined handle that refers to a device address (see \n Section 1.2.6).\n \u2022 Supported active levels of parallelism: The maximum number of active parallel regions that \n may enclose any region of code in the program is implementation defined (see Section 1.2.7).\n \u2022 Deprecated features: For any deprecated feature, whether any modifications provided by its \n replacement feature (if any) apply to the deprecated feature is implementation defined (see \n Section 1.2.7)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 Deprecated features: For any deprecated feature, whether any modifications provided by its \n replacement feature (if any) apply to the deprecated feature is implementation defined (see \n Section 1.2.7).\n \u2022 Memory model: The minimum size at which a memory update may also read and write back \n adjacent variables that are part of another variable (as array elements or structure elements) is \n implementation defined but is no larger than the base language requires.The manner in which a \n program can obtain the referenced device address from a device pointer, outside the mechanisms \n specified by OpenMP, is implementation defined (see Section 1.4.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "The manner in which a \n program can obtain the referenced device address from a device pointer, outside the mechanisms \n specified by OpenMP, is implementation defined (see Section 1.4.1).\n Chapter 2: \n \u2022 Internal control variables: The initial values of dyn-var, nthreads-var, run-sched-var, bind-var, \n stacksize-var, wait-policy-var, thread-limit-var, max-active-levels-var, place-partition-var, \n affinity-format-var, default-device-var, num-procs-var and def-allocator-var are implementation \n defined (see Section 2.2).\n Chapter 3: \nC / C++ \n \u2022 A pragma directive that uses ompx as the first processing token is implementation defined (see \n Section 3.1).\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n \u2022 The attribute namespace of an attribute specifier or the optional namespace qualifier within a \n sequence attribute that uses ompx is implementation defined (see Section 3.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\nC / C++ \n OpenMP API \u2013 Version 5.2 November 2021 \nC++ \n \u2022 The attribute namespace of an attribute specifier or the optional namespace qualifier within a \n sequence attribute that uses ompx is implementation defined (see Section 3.1).\n \u2022 Whether a throw executed inside a region that arises from an exception-aborting directive \n results in runtime error termination is implementation defined (see Section 3.1).\nC++ \nFortran \n \u2022 Any directive that uses omx or ompx in the sentinel is implementation defined (see Section 3.1).\nFortran \n Chapter 4: \n \u2022 Loop-iteration spaces and vectors: The particular integer type used to compute the iteration \n count for the collapsed loop is implementation defined (see Section 4.4.2)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\nFortran \n Chapter 4: \n \u2022 Loop-iteration spaces and vectors: The particular integer type used to compute the iteration \n count for the collapsed loop is implementation defined (see Section 4.4.2).\n Chapter 5: \nFortran \n \u2022 Data-sharing attributes: The data-sharing attributes of dummy arguments that do not have the \n VALUE attribute are implementation defined if the associated actual argument is shared unless \n the actual argument is a scalar variable, structure, an array that is not a pointer or assumed-shape \n array, or a simply contiguous array section (see Section 5.1.2).\n \u2022 threadprivate directive: If the conditions for values of data in the threadprivate objects of \n threads (other than an initial thread) to persist between two consecutive active parallel regions do \n not all hold, the allocation status of an allocatable variable in the second region is \n implementation defined (see Section 5.2)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 threadprivate directive: If the conditions for values of data in the threadprivate objects of \n threads (other than an initial thread) to persist between two consecutive active parallel regions do \n not all hold, the allocation status of an allocatable variable in the second region is \n implementation defined (see Section 5.2).\nFortran \n \u2022 is_device_ptr clause: Support for pointers created outside of the OpenMP device data \n management routines is implementation defined (see Section 5.4.7).\n Chapter 6: \n \u2022 Memory spaces: The actual storage resources that each memory space defined in Table 6.1 \n represents are implementation defined.The mechanism that provides the constant value of the \n variables allocated in the omp_const_mem_space memory space is implementation defined \n (see Section 6.1).\n \u2022 Memory allocators: The minimum size for partitioning allocated memory over storage \n resources is implementation defined."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 Memory allocators: The minimum size for partitioning allocated memory over storage \n resources is implementation defined.The default value for the pool_size allocator trait (see \n Table 6.2) is implementation defined.The memory spaces associated with the predefined \n omp_cgroup_mem_alloc, omp_pteam_mem_alloc and omp_thread_mem_alloc \n allocators (see Table 6.3) are implementation defined (see Section 6.2).\n \u2022 aligned clause: If the alignment modifier is not specified, the default alignments for SIMD \n instructions on the target platforms are implementation defined (see Section 5.11).\nAPPENDIX A.OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 617 \n Chapter 7: \n \u2022 OpenMP context: The accepted isa-name values for the isa trait, the accepted arch-name values \n for the arch trait, the accepted extension-name values for the extension trait and whether the \n dispatch construct is added to the construct set are implementation defined (see Section 7.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 617 \n Chapter 7: \n \u2022 OpenMP context: The accepted isa-name values for the isa trait, the accepted arch-name values \n for the arch trait, the accepted extension-name values for the extension trait and whether the \n dispatch construct is added to the construct set are implementation defined (see Section 7.1).\n \u2022 Metadirectives: The number of times that each expression of the context selector of a when \n clause is evaluated is implementation defined (see Section 7.4.1).\n \u2022 Declare variant directives: If two replacement candidates have the same score then their order \n is implementation defined.The number of times each expression of the context selector of a \n match clause is evaluated is implementation defined.For calls to constexpr base functions \n that are evaluated in constant expressions, whether any variant replacement occurs is \n implementation defined."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "For calls to constexpr base functions \n that are evaluated in constant expressions, whether any variant replacement occurs is \n implementation defined.Any differences that the specific OpenMP context requires in the \n prototype of the variant from the base function prototype are implementation defined (see \n Section 7.5).\n \u2022 declare simd directive: If a SIMD version is created and the simdlen clause is not \n specified, the number of concurrent arguments for the function is implementation defined (see \n Section 7.7).\n \u2022 Declare target directives: Whether the same version is generated for different devices, or \n whether a version that is called in a target region differs from the version that is called outside \n a target region, is implementation defined (see Section 7.8).\n Chapter 8: \n \u2022 requires directive: Support for any feature specified by a requirement clause on a \n requires directive is implementation defined (see Section 8.2)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n Chapter 8: \n \u2022 requires directive: Support for any feature specified by a requirement clause on a \n requires directive is implementation defined (see Section 8.2).\n Chapter 9: \n \u2022 unroll construct: If no clauses are specified, if and how the loop is unrolled is \n implementation defined.If the partial clause is specified without an unroll-factor argument \n then the unroll factor is a positive integer that is implementation defined (see Section 9.2).\n Chapter 10: \n \u2022 Dynamic adjustment of threads: Providing the ability to adjust the number of threads \n dynamically is implementation defined (see Section 10.1.1).\n \u2022 Thread affinity: For the close thread affinity policy, if T > P and P does not divide T evenly, \n the exact number of threads in a particular place is implementation defined.For the spread \n thread affinity, if T > P and P does not divide T evenly, the exact number of threads in a \n particular subpartition is implementation defined."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "For the spread \n thread affinity, if T > P and P does not divide T evenly, the exact number of threads in a \n particular subpartition is implementation defined.The determination of whether the affinity \n request can be fulfilled is implementation defined.If the affinity request cannot be fulfilled, then \n the affinity of threads in the team is implementation defined (see Section 10.1.3).\n \u2022 teams construct: The number of teams that are created is implementation defined, but it is \n greater than or equal to the lower bound and less than or equal to the upper bound values of the \n num_teams clause if specified.If the num_teams clause is not specified,r the number of \n OpenMP API \u2013 Version 5.2 November 2021 \n teams is less than or equal to the value of the nteams-var ICV if its value is greater than zero.\n Otherwise it is an implementation defined value greater than or equal to 1 (see Section 10.2)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n Otherwise it is an implementation defined value greater than or equal to 1 (see Section 10.2).\n \u2022 simd construct: The number of iterations that are executed concurrently at any given time is \n implementation defined (see Section 10.4).\n Chapter 11: \n \u2022 single construct: The method of choosing a thread to execute the structured block each time \n the team encounters the construct is implementation defined (see Section 11.1).\n \u2022 sections construct: The method of scheduling the structured block sequences among threads \n in the team is implementation defined (see Section 11.3).\n \u2022 Worksharing-loop directive: The schedule that is used is implementation defined if the \n schedule clause is not specified or if the specified schedule has the kind auto.The value of \n simd_width for the simd schedule modifier is implementation defined (see Section 11.5)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "The value of \n simd_width for the simd schedule modifier is implementation defined (see Section 11.5).\n \u2022 distribute construct: If no dist_schedule clause is specified then the schedule for the \n distribute construct is implementation defined (see Section 11.6).\n Chapter 12: \n \u2022 taskloop construct: The number of loop iterations assigned to a task created from a \n taskloop construct is implementation defined, unless the grainsize or num_tasks \n clause is specified (see Section 12.6).\nC++ \n \u2022 taskloop construct: For firstprivate variables of class type, the number of invocations \n of copy constructors to perform the initialization is implementation defined (see Section 12.6).\nC++ \n Chapter 13: \n \u2022 thread_limit clause: The maximum number of threads that participate in the contention \n group that each team initiates is implementation defined if no thread_limit clause is \n specified on the construct."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\nC++ \n Chapter 13: \n \u2022 thread_limit clause: The maximum number of threads that participate in the contention \n group that each team initiates is implementation defined if no thread_limit clause is \n specified on the construct.Otherwise, it has the implementation defined upper bound of the \n teams-thread-limit-var ICV, if the value of this ICV is greater than zero (see Section 13.3).\n Chapter 14: \n \u2022 interop Construct: The foreign-runtime-id values for the prefer_type clause that the \n implementation supports, including non-standard names compatible with this clause, and the \n default choice when the implementation supports multiple values are implementation defined \n (see Section 14.1).\n Chapter 15: \n \u2022 atomic construct: A compliant implementation may enforce exclusive access between \n atomic regions that update different storage locations.The circumstances under which this \n occurs are implementation defined."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "The circumstances under which this \n occurs are implementation defined.If the storage location designated by x is not size-aligned \n (that is, if the byte alignment of x is not a multiple of the size of x), then the behavior of the \n atomic region is implementation defined (see Section 15.8.4).\nAPPENDIX A.OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 619 \n Chapter 16: \n \u2022 None.\n Chapter 17: \n \u2022 None.\n Chapter 18: \n \u2022 Runtime Routine names that begin with the ompx_ prefix are implementation-defined extensions \n to the OpenMP Runtime API (see Chapter 18).\nC / C++ \n \u2022 Runtime library definitions: The enum types for omp_allocator_handle_t, \n omp_event_handle_t, omp_interop_fr_t and omp_memspace_handle_t are \n implementation defined.The integral or pointer type for omp_interop_t is implementation \n defined.The value of the omp_invalid_device enumerator is implementation defined (see \n Section 18.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "The value of the omp_invalid_device enumerator is implementation defined (see \n Section 18.1).\nC / C++ \nFortran \n \u2022 Runtime library definitions: Whether the include file omp_lib.h or the module omp_lib \n (or both) is provided is implementation defined.Whether the omp_lib.h file provides \n derived-type definitions or those routines that require an explicit interface is implementation \n defined.Whether any of the OpenMP runtime library routines that take an argument are \n extended with a generic interface so arguments of different KIND type can be accommodated is \n implementation defined.The value of the omp_invalid_device named constant is \n implementation defined (see Section 18.1).\nFortran \n \u2022 omp_set_num_threads routine: If the argument is not a positive integer, the behavior is \n implementation defined (see Section 18.2.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\nFortran \n \u2022 omp_set_num_threads routine: If the argument is not a positive integer, the behavior is \n implementation defined (see Section 18.2.1).\n \u2022 omp_set_schedule routine: For implementation-specific schedule kinds, the values and \n associated meanings of the second argument are implementation defined (see Section 18.2.11).\n \u2022 omp_get_schedule routine: The value returned by the second argument is implementation \n defined for any schedule kinds other than static, dynamic and guided (see \n Section 18.2.12).\n \u2022 omp_get_supported_active_levels routine: The number of active levels of \n parallelism supported by the implementation is implementation defined, but must be positive (see \n Section 18.2.14).\n \u2022 omp_set_max_active_levels routine: If the argument is a negative integer then the \n behavior is implementation defined."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 omp_set_max_active_levels routine: If the argument is a negative integer then the \n behavior is implementation defined.If the argument is less than the active-levels-var ICV, the \n max-active-levels-var ICV is set to an implementation-defined value between the value of the \n argument and the value of active-levels-var, inclusive (see Section 18.2.15).\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 omp_get_place_proc_ids routine: The meaning of the non-negative numerical identifiers \n returned by the omp_get_place_proc_ids routine is implementation defined.The order of \n the numerical identifiers returned in the array ids is implementation defined (see Section 18.3.4).\n \u2022 omp_set_affinity_format routine: When called from within any parallel or teams \n region, the binding thread set (and binding region, if required) for the \n omp_set_affinity_format region and the effect of this routine are implementation \n defined (see Section 18.3.8)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 omp_set_affinity_format routine: When called from within any parallel or teams \n region, the binding thread set (and binding region, if required) for the \n omp_set_affinity_format region and the effect of this routine are implementation \n defined (see Section 18.3.8).\n \u2022 omp_get_affinity_format routine: When called from within any parallel or teams \n region, the binding thread set (and binding region, if required) for the \n omp_get_affinity_format region is implementation defined (see Section 18.3.9).\n \u2022 omp_display_affinity routine: If the format argument does not conform to the specified \n format then the result is implementation defined (see Section 18.3.10).\n \u2022 omp_capture_affinity routine: If the format argument does not conform to the specified \n format then the result is implementation defined (see Section 18.3.11)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 omp_capture_affinity routine: If the format argument does not conform to the specified \n format then the result is implementation defined (see Section 18.3.11).\n \u2022 omp_set_num_teams routine: If the argument does not evaluate to a positive integer, the \n behavior of this routine is implementation defined (see Section 18.4.3).\n \u2022 omp_set_teams_thread_limit routine: If the argument is not a positive integer, the \n behavior is implementation defined (see Section 18.4.5).\n \u2022 omp_pause_resource_all routine: The behavior of this routine is implementation \n defined if the argument kind is not listed in Section 18.6.1 (see Section 18.6.2).\n \u2022 omp_target_memcpy_rect and omp_target_memcpy_rect_async routines: The \n maximum number of dimensions supported is implementation defined, but must be at least three \n (see Section 18.8.6 and Section 18.8.8)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 omp_target_memcpy_rect and omp_target_memcpy_rect_async routines: The \n maximum number of dimensions supported is implementation defined, but must be at least three \n (see Section 18.8.6 and Section 18.8.8).\n \u2022 Lock routines: If a lock contains a synchronization hint, the effect of the hint is implementation \n defined (see Section 18.9).\n \u2022 Interoperability routines: Implementation-defined properties may use zero and positive values \n for properties associated with an omp_interop_t object (see Section 18.12).\n Chapter 19: \n \u2022 Tool callbacks: If a tool attempts to register a callback listed in Table 19.3), whether the \n registered callback may never, sometimes or always invoke this callback for the associated events \n is implementation defined (see Section 19.2.4)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n Chapter 19: \n \u2022 Tool callbacks: If a tool attempts to register a callback listed in Table 19.3), whether the \n registered callback may never, sometimes or always invoke this callback for the associated events \n is implementation defined (see Section 19.2.4).\n \u2022 Device tracing: Whether a target device supports tracing or not is implementation defined; if a \n target device does not support tracing, a NULL may be supplied for the lookup function to the \n device initializer of a tool (see Section 19.2.5).\n \u2022 ompt_set_trace_ompt and ompt_get_record_ompt runtime entry points: Whether \n a device-specific tracing interface defines this runtime entry point, indicating that it can collect \nAPPENDIX A.OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 621 \n traces in OMPT format, is implementation defined.The kinds of trace records available for a \n device is implementation defined (see Section 19.2.5)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "The kinds of trace records available for a \n device is implementation defined (see Section 19.2.5).\n \u2022 Native record abstract type: The meaning of a hwid value for a device is implementation \n defined (see Section 19.4.3.3).\n \u2022 ompt_dispatch_chunk_t type: Whether the chunk of a taskloop is contiguous is \n implementation defined (see Section 19.4.4.13).\n \u2022 ompt_record_abstract_t type: The set of OMPT thread states supported is \n implementation defined (see Section 19.4.4.28).\n \u2022 ompt_callback_sync_region_t callback type: For the implicit-barrier-wait-begin and \n implicit-barrier-wait-end events at the end of a parallel region, whether the parallel_data \n argument is NULL or points to the parallel data of the current parallel region is implementation \n defined (see Section 19.5.2.13)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 ompt_callback_sync_region_t callback type: For the implicit-barrier-wait-begin and \n implicit-barrier-wait-end events at the end of a parallel region, whether the parallel_data \n argument is NULL or points to the parallel data of the current parallel region is implementation \n defined (see Section 19.5.2.13).\n \u2022 ompt_callback_target_data_op_emi_t and \n ompt_callback_target_data_op_t callback types: Whether in some operations \n src_addr or dest_addr might point to an intermediate buffer is implementation defined (see \n Section 19.5.2.25).\n \u2022 ompt_get_place_proc_ids_t entry point type: The meaning of the numerical \n identifiers returned is implementation defined.The order of ids returned in the array is \n implementation defined (see Section 19.6.1.8).\n \u2022 ompt_get_partition_place_nums_t entry point type: The order of the identifiers \n returned in the array place_nums is implementation defined (see Section 19.6.1.10)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 ompt_get_partition_place_nums_t entry point type: The order of the identifiers \n returned in the array place_nums is implementation defined (see Section 19.6.1.10).\n \u2022 ompt_get_proc_id_t entry point type: The meaning of the numerical identifier returned \n is implementation defined (see Section 19.6.1.11).\n Chapter 20: \n \u2022 ompd_callback_print_string_fn_t callback type: The value of category is \n implementation defined (see Section 20.4.5).\n \u2022 ompd_parallel_handle_compare operation: The means by which parallel region \n handles are ordered is implementation defined (see Section 20.5.6.5).\n \u2022 ompd_task_handle_compare operation: The means by which task handles are ordered is \n implementation defined (see Section 20.5.7.6).\n Chapter 21: \n \u2022 OMP_DYNAMIC environment variable: If the value is neither true nor false, the behavior \n of the program is implementation defined (see Section 21.1.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n Chapter 21: \n \u2022 OMP_DYNAMIC environment variable: If the value is neither true nor false, the behavior \n of the program is implementation defined (see Section 21.1.1).\n \u2022 OMP_NUM_THREADS environment variable: If any value of the list specified leads to a number \n of threads that is greater than the implementation can support, or if any value is not a positive \n integer, then the behavior of the program is implementation defined (see Section 21.1.2).\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 OMP_THREAD_LIMIT environment variable: If the requested value is greater than the number \n of threads an implementation can support, or if the value is not a positive integer, the behavior of \n the program is implementation defined (see Section 21.1.3)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 OMP_THREAD_LIMIT environment variable: If the requested value is greater than the number \n of threads an implementation can support, or if the value is not a positive integer, the behavior of \n the program is implementation defined (see Section 21.1.3).\n \u2022 OMP_MAX_ACTIVE_LEVELS environment variable: If the value is a negative integer or is \n greater than the maximum number of nested active parallel levels that an implementation can \n support then the behavior of the program is implementation defined (see Section 21.1.4).\n \u2022 OMP_NESTED environment variable (deprecated): If the value is neither true nor false, \n the behavior of the program is implementation defined (see Section 21.1.5)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 OMP_NESTED environment variable (deprecated): If the value is neither true nor false, \n the behavior of the program is implementation defined (see Section 21.1.5).\n \u2022 Conflicting OMP_NESTED (deprecated) and OMP_MAX_ACTIVE_LEVELS environment \n variables: If both environment variables are set, the value of OMP_NESTED is false, and the \n value of OMP_MAX_ACTIVE_LEVELS is greater than 1, then the behavior is implementation \n defined (see Section 21.1.5).\n \u2022 OMP_PLACES environment variable: The meaning of the numbers specified in the \n environment variable and how the numbering is done are implementation defined.The precise \n definitions of the abstract names are implementation defined.An implementation may add \n implementation-defined abstract names as appropriate for the target platform."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "An implementation may add \n implementation-defined abstract names as appropriate for the target platform.When creating a \n place list of n elements by appending the number n to an abstract name, the determination of \n which resources to include in the place list is implementation defined.When requesting more \n resources than available, the length of the place list is also implementation defined.The behavior \n of the program is implementation defined when the execution environment cannot map a \n numerical value (either explicitly defined or implicitly derived from an interval) within the \n OMP_PLACES list to a processor on the target platform, or if it maps to an unavailable processor.\n The behavior is also implementation defined when the OMP_PLACES environment variable is \n defined using an abstract name (see Section 21.1.6)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n The behavior is also implementation defined when the OMP_PLACES environment variable is \n defined using an abstract name (see Section 21.1.6).\n \u2022 OMP_PROC_BIND environment variable: If the value is not true, false, or a comma \n separated list of primary (master has been deprecated), close, or spread, the behavior is \n implementation defined.The behavior is also implementation defined if an initial thread cannot \n be bound to the first place in the OpenMP place list.The thread affinity policy is implementation \n defined if the value is true (see Section 21.1.7).\n \u2022 OMP_SCHEDULE environment variable: If the value does not conform to the specified format \n then the behavior of the program is implementation defined (see Section 21.2.1).\n \u2022 OMP_STACKSIZE environment variable: If the value does not conform to the specified format \n or the implementation cannot provide a stack of the specified size then the behavior is \n implementation defined (see Section 21.2.2)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 OMP_STACKSIZE environment variable: If the value does not conform to the specified format \n or the implementation cannot provide a stack of the specified size then the behavior is \n implementation defined (see Section 21.2.2).\n \u2022 OMP_WAIT_POLICY environment variable: The details of the active and passive \n behaviors are implementation defined (see Section 21.2.3).\n \u2022 OMP_DISPLAY_AFFINITY environment variable: For all values of the environment \n variables other than true or false, the display action is implementation defined (see \n Section 21.2.4).\nAPPENDIX A.OPENMP IMPLEMENTATION-DEFINED BEHAVIORS 623 \n \u2022 OMP_AFFINITY_FORMAT environment variable: Additional implementation-defined field \n types can be added (see Section 21.2.5).\n \u2022 OMP_CANCELLATION environment variable: If the value is set to neither true nor false, \n the behavior of the program is implementation defined (see Section 21.2.6)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 OMP_CANCELLATION environment variable: If the value is set to neither true nor false, \n the behavior of the program is implementation defined (see Section 21.2.6).\n \u2022 OMP_TARGET_OFFLOAD environment variable: The support of disabled is \n implementation defined (see Section 21.2.8).\n \u2022 OMP_TOOL_LIBRARIES environment variable: Whether the value of the environment \n variable is case sensitive is implementation defined (see Section 21.3.2).\n \u2022 OMP_TOOL_VERBOSE_INIT environment variable: Support for logging to stdout or \n stderr is implementation defined.Whether the value of the environment variable is case \n sensitive when it is treated as a filename is implementation defined.The format and detail of the \n log is implementation defined (see Section 21.3.3).\n \u2022 OMP_DEBUG environment variable: If the value is neither disabled nor enabled, the \n behavior is implementation defined (see Section 21.4.1)."}
{"section_title": "A OpenMP Implementation-Defined Behaviors", "chunk": "\n \u2022 OMP_DEBUG environment variable: If the value is neither disabled nor enabled, the \n behavior is implementation defined (see Section 21.4.1).\n \u2022 OMP_NUM_TEAMS environment variable: If the value is not a positive integer or is greater than \n the number of teams that an implementation can support, the behavior of the program is \n implementation defined (see Section 21.6.1).\n \u2022 OMP_TEAMS_THREAD_LIMIT environment variable: If the value is not a positive integer or \n is greater than the number of threads that an implementation can support, the behavior of the \n program is implementation defined (see Section 21.6.2).\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
{"section_title": "B Features History", "chunk": "2 This appendix summarizes the major changes between OpenMP API versions since version 2.5.\n"}
{"section_title": "B.1 Deprecated Features", "chunk": "4 The following features were deprecated in Version 5.2: \n \u2022 The syntax of the linear clause that specifies its argument and linear-modifier as \n linear-modifier(list) was deprecated.\n \u2022 The minus (-) operator for reductions was deprecated.\n \u2022 The syntax of modifiers without comma separators in the map clause was deprecated.\nFortran \n \u2022 The use of one or more allocate directives with an associated ALLOCATE statement was \n deprecated.\nFortran \n \u2022 The argument that specified the arguments of the uses_allocators clause as a \n comma-separated list in which each list item is a clause-argument-specification of the form \n allocator[(traits)] was deprecated.\n \u2022 The use of the default clause on metadirectives was deprecated.\nC / C++ \n \u2022 The delimited form of the declare target directive was deprecated.\nC / C++ \n \u2022 The use of the to clause on the declare target directive was deprecated."}
{"section_title": "B.1 Deprecated Features", "chunk": "\nC / C++ \n \u2022 The use of the to clause on the declare target directive was deprecated.\n \u2022 The syntax of the destroy clause on the depobj construct with no argument was deprecated.\n \u2022 The use of the keywords source and sink as task-dependence-type modifiers and the \n associated syntax for the depend clause was deprecated.\n \u2022 The init clause of interop construct now accepts an interop_type in any position of the \n modifier list.\n \u2022 The requirement that the ICVs num-procs-var, thread-num-var, final-task-var, implicit-task-var \n and team-size-var must also be available with an ompd- prefix was deprecated.\nAPPENDIX B.FEATURES HISTORY 625 \n The following features were deprecated in Version 5.1: \nFortran \n \u2022 Cray pointer support was deprecated.\n \u2022 Specifying list items that are not of type C_PTR in a use_device_ptr or is_device_ptr \n clause was deprecated.\nFortran \n \u2022 The use of clauses supplied to the requires directive as context traits was deprecated."}
{"section_title": "B.1 Deprecated Features", "chunk": "\nFortran \n \u2022 The use of clauses supplied to the requires directive as context traits was deprecated.\n \u2022 The master affinity policy was deprecated.\n \u2022 The master construct and all combined and composite constructs of which it is a constituent \n construct were deprecated.\n \u2022 The constant omp_atv_sequential was deprecated.\n \u2022 The ompt_sync_region_barrier and ompt_sync_region_barrier_implicit \n values of the ompt_sync_region_t enum were deprecated.\n \u2022 The ompt_state_wait_barrier and ompt_state_wait_barrier_implicit \n values of the ompt_state_t enum were deprecated.\n The following features were deprecated in Version 5.0: \n \u2022 The nest-var ICV, the OMP_NESTED environment variable, and the omp_set_nested and \n omp_get_nested routines were deprecated.\n \u2022 Lock hints were renamed to synchronization hints."}
{"section_title": "B.1 Deprecated Features", "chunk": "\n \u2022 Lock hints were renamed to synchronization hints.The following lock hint type and constants \n were deprecated: \n \u2013 the C/C++ type omp_lock_hint_t and the Fortran kind omp_lock_hint_kind; \n \u2013 the constants omp_lock_hint_none, omp_lock_hint_uncontended, \n omp_lock_hint_contended, omp_lock_hint_nonspeculative, and \n omp_lock_hint_speculative.\n"}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "24 \u2022 The explicit-task-var ICV has replaced the implicit-task-var ICV and has the opposite meaning \n and semantics (see Chapter 2).The omp_in_explicit_task routine was added to query if \n a code region is executed from an explicit task region (see Section 18.5.2).\n \u2022 Major reorganization and numerous changes were made to improve the quality of the \n specification of OpenMP syntax and to increase consistency of restrictions and their wording.\n These changes frequently result in the possible perception of differences to preceding versions of \n the OpenMP specification.However, those differences almost always resolve ambiguities, which \n may nonetheless have implications for existing implementations and programs."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "However, those differences almost always resolve ambiguities, which \n may nonetheless have implications for existing implementations and programs.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 For OpenMP directives, reserved the omp sentinel (see Section 3.1, Section 3.1.1 and \n Section 3.1.2) and, for implementation-defined directives that extend the OpenMP directives \n reserved the ompx sentinel for C/C++ and free source form Fortran (see Section 3.1 and \n Section 3.1.2) and the omx sentinel for fixed source form Fortran to accommodate character \n position requirements (see Section 3.1.1).Reserved clause names that begin with the ompx_ \n prefix for implementation-defined clauses on OpenMP directives (see Section 3.2).Reserved \n names in the base language that start with the omp_ and ompx_ prefix and reserved the omp and \n ompx namespaces (see Chapter 4) for the OpenMP runtime API and for implementation-defined \n extensions to that API (see Chapter 18)."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "Reserved \n names in the base language that start with the omp_ and ompx_ prefix and reserved the omp and \n ompx namespaces (see Chapter 4) for the OpenMP runtime API and for implementation-defined \n extensions to that API (see Chapter 18).\n \u2022 Allowed any clause that can be specified on a paired end directive to be specified on the \n directive (see Section 3.1), including the copyprivate clause (see Section 5.7.2) and the \n nowait clause in Fortran (see Section 15.6).\n \u2022 For consistency with the syntax of other definitions of the clause, the syntax of the destroy \n clause on the depobj construct with no argument was deprecated (see Section 3.5).\n \u2022 For consistency with the syntax of other clauses, the syntax of the linear clause that specifies \n its argument and linear-modifier as linear-modifier(list) was deprecated and the step modifier \n was added for specifying the linear step (see Section 5.4.6)."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "\n \u2022 For consistency with the syntax of other clauses, the syntax of the linear clause that specifies \n its argument and linear-modifier as linear-modifier(list) was deprecated and the step modifier \n was added for specifying the linear step (see Section 5.4.6).\n \u2022 The minus (-) operator for reductions was deprecated (see Section 5.5.5).\n \u2022 The syntax of modifiers without comma separators in the map clause was deprecated (see \n Section 5.8.3).\n \u2022 To support the complete range of user-defined mappers and to improve consistency of map \n clause usage, the declare mapper directive was extended to accept iterator-modifier and the \n present map-type-modifier (see Section 5.8.3 and Section 5.8.8).\n \u2022 If a matching mapped list item is not found in the data environment, the pointer retains its \n original value as per the firstprivate semantics (see Section 5.8.6)."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "\n \u2022 If a matching mapped list item is not found in the data environment, the pointer retains its \n original value as per the firstprivate semantics (see Section 5.8.6).\n \u2022 The enter clause was added as a synonym for the to clause on the declare target directive, and \n the corresponding to clause was deprecated to reduce parsing ambiguity (see Section 5.8.4 and \n Section 7.8).\nFortran \n \u2022 Metadirectives (see Section 7.4), assumption directives (see Section 8.3), nothing directives \n (see Section 8.4), error directives (see Section 8.5) and loop transformation constructs (see \n Chapter 9) were added to the list of directives that are allowed in a pure procedure (see \n Chapter 3).\n \u2022 The allocators construct was added to support the use of OpenMP allocators for variables \n that are allocated by a Fortran ALLOCATE statement, and the application of allocate \n directives to an ALLOCATE statement was deprecated (see Section 6.7).\nAPPENDIX B."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "\nAPPENDIX B.FEATURES HISTORY 627 \n \u2022 For consistency with other constructs with associated base language code, the dispatch \n construct was extended to allow an optional paired end directive to be specified (see \n Section 7.6).\nFortran \n \u2022 To support the full range of allocators and to improve consistency with the syntax of other \n clauses, the argument that specified the arguments of the uses_allocators as a \n comma-separated list in which each list item is a clause-argument-specification of the form \n allocator[(traits)] was deprecated (see Section 6.8).\n \u2022 To improve code clarity and to reduce ambiguity in this specification, the otherwise clause \n was added as a synonym for the default clause on metadirectives and the corresponding \n default clause syntax was deprecated (see Section 7.4.2).\nC / C++ \n \u2022 To improve overall syntax consistency and to reduce redundancy, the delimited form of the \n declare target directive was deprecated (see Section 7.8.2)."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "\nC / C++ \n \u2022 To improve overall syntax consistency and to reduce redundancy, the delimited form of the \n declare target directive was deprecated (see Section 7.8.2).\nC / C++ \n \u2022 The behavior of the order clause with the concurrent parameter was changed so that it only \n affects whether a loop schedule is reproducible if a modifier is explicitly specified (see \n Section 10.3).\n \u2022 Support for the allocate and firstprivate clauses on the scope directive was added \n (see Section 11.2).\n \u2022 The ompt_callback_work callback work types for worksharing loop were added (see \n Section 11.5).\n \u2022 To simplify usage, the map clause on a target enter data or target exit data \n construct now has a default map type that provides the same behavior as the to or from map \n types, respectively (see Section 13.6 and Section 13.7)."}
{"section_title": "B.2 Version 5.1 to 5.2 Differences", "chunk": "\n \u2022 To simplify usage, the map clause on a target enter data or target exit data \n construct now has a default map type that provides the same behavior as the to or from map \n types, respectively (see Section 13.6 and Section 13.7).\n \u2022 The doacross clause was added as a synonym for the depend clause with the keywords \n source and sink as dependence-type modifiers and the corresponding depend clause syntax \n was deprecated to improve code clarity and to reduce parsing ambiguity.Also, the \n omp_cur_iteration keyword was added to represent an iteration vector that refers to the \n current logical iteration (see Section 15.9.6).\n"}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "29 \u2022 Full support of C11, C++11, C++14, C++17, C++20 and Fortran 2008 was completed (see \n Section 1.7).\n \u2022 Various changes throughout the specification were made to provide initial support of Fortran \n 2018 (see Section 1.7).\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 To support device-specific ICV settings the environment variable syntax was extended to support \n device-specific variables (see Section 2.2 and Chapter 21).\n \u2022 The OpenMP directive syntax was extended to include C++ attribute specifiers (see Section 3.1).\n \u2022 The omp_all_memory reserved locator was added (see Section 3.1), and the depend clause \n was extended to allow its use (see Section 15.9.5).\n \u2022 Support for private and firstprivate as an argument to the default clause in C and \n C++ was added (see Section 5.4.1).\n \u2022 Support was added so that iterators may be defined and used in a map clause (see Section 5.8.3) \n or in data-motion clause on a target update directive (see Section 13.9)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 Support was added so that iterators may be defined and used in a map clause (see Section 5.8.3) \n or in data-motion clause on a target update directive (see Section 13.9).\n \u2022 The present argument was added to the defaultmap clause (see Section 5.8.7).\n \u2022 Support for the align clause on the allocate directive and allocator and align \n modifiers on the allocate clause was added (see Chapter 6).\n \u2022 The target_device trait set was added to the OpenMP context (see Section 7.1), and the \n target_device selector set was added to context selectors (see Section 7.2).\n \u2022 For C/C++, the declare variant directive was extended to support elision of preprocessed code \n and to allow enclosed function definitions to be interpreted as variant functions (see Section 7.5).\n \u2022 The declare variant directive was extended with new clauses (adjust_args and \n append_args) that support adjustment of the interface between the original function and its \n variants (see Section 7.5)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 The declare variant directive was extended with new clauses (adjust_args and \n append_args) that support adjustment of the interface between the original function and its \n variants (see Section 7.5).\n \u2022 The dispatch construct was added to allow users to control when variant substitution happens \n and to define additional information that can be passed as arguments to the function variants (see \n Section 7.6).\n \u2022 Support was added for indirect calls to the device version of a procedure or function in target \n regions (see Section 7.8).\n \u2022 Assumption directives were added to allow users to specify invariants (see Section 8.3).\n \u2022 To support clarity in metadirectives, the nothing directive was added (see Section 8.4).\n \u2022 To allow users to control the compilation process and runtime error actions, the error directive \n was added (see Section 8.5).\n \u2022 Loop transformation constructs were added (see Chapter 7)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 Loop transformation constructs were added (see Chapter 7).\n \u2022 The masked construct was added to support restricting execution to a specific thread (see \n Section 10.5).\n \u2022 The scope directive was added to support reductions without requiring a parallel or \n worksharing region (see Section 11.2).\nAPPENDIX B.FEATURES HISTORY 629 \n \u2022 The grainsize and num_tasks clauses for the taskloop construct were extended with a \n strict modifier to ensure a deterministic distribution of logical iterations to tasks (see \n Section 12.6).\n \u2022 The thread_limit clause was added to the target construct to control the upper bound on \n the number of threads in the created contention group (see Section 13.8).\n \u2022 The has_device_addr clause was added to the target construct to allow access to \n variables or array sections that already have a device address (see Section 13.8)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 The has_device_addr clause was added to the target construct to allow access to \n variables or array sections that already have a device address (see Section 13.8).\n \u2022 The interop directive was added to enable portable interoperability with foreign execution \n contexts used to implement OpenMP (see Section 14.1).Runtime routines that facilitate use of \n omp_interop_t objects were also added (see Section 18.12).\n \u2022 The nowait clause was added to the taskwait directive to support insertion of non-blocking \n join operations in a task dependence graph (see Section 15.5).\n \u2022 Support was added for compare-and-swap and (for C and C++) minimum and maximum atomic \n operations through the compare clause.Support was also added for the specification of the \n memory order to apply to a failed comparing atomic operation with the fail clause (see \n Section 15.8.4)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "Support was also added for the specification of the \n memory order to apply to a failed comparing atomic operation with the fail clause (see \n Section 15.8.4).\n \u2022 Specification of the seq_cst clause on a flush construct was allowed, with the same \n meaning as a flush construct without a list and without a clause (see Section 15.8.5).\n \u2022 To support inout sets, the inoutset argument was added to the depend clause (see \n Section 15.9.5).\n \u2022 The omp_set_num_teams and omp_set_teams_thread_limit runtime routines were \n added to control the number of teams and the size of those teams on the teams construct (see \n Section 18.4.3 and Section 18.4.5).Additionally, the omp_get_max_teams and \n omp_get_teams_thread_limit runtime routines were added to retrieve the values that \n will be used in the next teams construct (see Section 18.4.4 and Section 18.4.6)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "Additionally, the omp_get_max_teams and \n omp_get_teams_thread_limit runtime routines were added to retrieve the values that \n will be used in the next teams construct (see Section 18.4.4 and Section 18.4.6).\n \u2022 The omp_target_is_accessible runtime routine was added to test whether host memory \n is accessible from a given device (see Section 18.8.4).\n \u2022 To support asynchronous device memory management, omp_target_memcpy_async and \n omp_target_memcpy_rect_async runtime routines were added (see Section 18.8.7 and \n Section 18.8.8).\n \u2022 The omp_get_mapped_ptr runtime routine was added to support obtaining the device \n pointer that is associated with a host pointer for a given device (see Section 18.8.11).\n \u2022 The omp_calloc, omp_realloc, omp_aligned_alloc and omp_aligned_calloc \n API routines were added (see Section 18.13).\n \u2022 For the omp_alloctrait_key_t enum, the omp_atv_serialized value was added and \n the omp_atv_default value was changed (see Section 18.13.1)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 For the omp_alloctrait_key_t enum, the omp_atv_serialized value was added and \n the omp_atv_default value was changed (see Section 18.13.1).\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 The omp_display_env runtime routine was added to provide information about ICVs and \n settings of environment variables (see Section 18.15).\n \u2022 The ompt_scope_beginend value was added to the ompt_scope_endpoint_t enum \n to indicate the coincident beginning and end of a scope (see Section 19.4.4.11).\n \u2022 The ompt_sync_region_barrier_implicit_workshare, \n ompt_sync_region_barrier_implicit_parallel, and \n ompt_sync_region_barrier_teams values were added to the \n ompt_sync_region_t enum (see Section 19.4.4.14).\n \u2022 Values for asynchronous data transfers were added to the ompt_target_data_op_t enum \n (see Section 19.4.4.15).\n \u2022 The ompt_state_wait_barrier_implementation and \n ompt_state_wait_barrier_teams values were added to the ompt_state_t enum \n (see Section 19.4.4.28)."}
{"section_title": "B.3 Version 5.0 to 5.1 Differences", "chunk": "\n \u2022 The ompt_state_wait_barrier_implementation and \n ompt_state_wait_barrier_teams values were added to the ompt_state_t enum \n (see Section 19.4.4.28).\n \u2022 The ompt_callback_target_data_op_emi_t, ompt_callback_target_emi_t, \n ompt_callback_target_map_emi_t, and \n ompt_callback_target_submit_emi_t callbacks were added to support external \n monitoring interfaces (see Section 19.5.2.25, Section 19.5.2.26, Section 19.5.2.27 and \n Section 19.5.2.28).\n \u2022 The ompt_callback_error_t type was added (see Section 19.5.2.30).\n \u2022 The OMP_PLACES syntax was extended (see Section 21.1.6).\n \u2022 The OMP_NUM_TEAMS and OMP_TEAMS_THREAD_LIMIT environment variables were added \n to control the number and size of teams on the teams construct (see Section 21.6.1 and \n Section 21.6.2).\n"}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "25 \u2022 The memory model was extended to distinguish different types of flush operations according to \n specified flush properties (see Section 1.4.4) and to define a happens before order based on \n synchronizing flush operations (see Section 1.4.5).\n \u2022 Various changes throughout the specification were made to provide initial support of C11, \n C++11, C++14, C++17 and Fortran 2008 (see Section 1.7).\n \u2022 Full support of Fortran 2003 was completed (see Section 1.7).\n \u2022 The target-offload-var internal control variable (see Chapter 2) and the \n OMP_TARGET_OFFLOAD environment variable (see Section 21.2.8) were added to support \n runtime control of the execution of device constructs.\nAPPENDIX B."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\nAPPENDIX B.FEATURES HISTORY 631 \n \u2022 Control over whether nested parallelism is enabled or disabled was integrated into the \n max-active-levels-var internal control variable (see Section 2.2), the default value of which is \n now implementation defined, unless determined according to the values of the \n OMP_NUM_THREADS (see Section 21.1.2) or OMP_PROC_BIND (see Section 21.1.7) \n environment variables.\n \u2022 Support for array shaping (see Section 3.2.4) and for array sections with non-unit strides in C and \n C++ (see Section 3.2.5) was added to facilitate specification of discontiguous storage, and the \n target update construct (see Section 13.9) and the depend clause (see Section 15.9.5) \n were extended to allow the use of shape-operators (see Section 3.2.4).\n \u2022 Iterators (see Section 3.2.6) were added to support expressions in a list that expand to multiple \n expressions."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 Iterators (see Section 3.2.6) were added to support expressions in a list that expand to multiple \n expressions.\n \u2022 The canonical loop form was defined for Fortran and, for all base languages, extended to permit \n non-rectangular loop nests (see Section 4.4.1).\n \u2022 The relational-op in the canonical loop form for C/C++ was extended to include != (see \n Section 4.4.1).\n \u2022 To support conditional assignment to lastprivate variables, the conditional modifier was \n added to the lastprivate clause (see Section 5.4.5).\n \u2022 The inscan modifier for the reduction clause (see Section 5.5.8) and the scan directive \n (see Section 5.6) were added to support inclusive and exclusive scan computations."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The inscan modifier for the reduction clause (see Section 5.5.8) and the scan directive \n (see Section 5.6) were added to support inclusive and exclusive scan computations.\n \u2022 To support task reductions, the task modifier was added to the reduction clause (see \n Section 5.5.8), the task_reduction clause (see Section 5.5.9) was added to the \n taskgroup construct (see Section 15.4), and the in_reduction clause (see Section 5.5.10) \n was added to the task (see Section 12.5) and target (see Section 13.8) constructs.\n \u2022 To support taskloop reductions, the reduction (see Section 5.5.8) and in_reduction (see \n Section 5.5.10) clauses were added to the taskloop construct (see Section 12.6).\n \u2022 The description of the map clause was modified to clarify the mapping order when multiple \n map-types are specified for a variable or structure members of a variable on the same construct."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The description of the map clause was modified to clarify the mapping order when multiple \n map-types are specified for a variable or structure members of a variable on the same construct.\n The close map-type-modifier was added as a hint for the runtime to allocate memory close to \n the target device (see Section 5.8.3).\n \u2022 The capability to map C/C++ pointer variables and to assign the address of device memory that \n is mapped by an array section to them was added.Support for mapping of Fortran pointer and \n allocatable variables, including pointer and allocatable components of variables, was added (see \n Section 5.8.3).\n \u2022 The defaultmap clause (see Section 5.8.7) was extended to allow selecting the data-mapping \n or data-sharing attributes for any of the scalar, aggregate, pointer, or allocatable classes on a \n per-region basis."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The defaultmap clause (see Section 5.8.7) was extended to allow selecting the data-mapping \n or data-sharing attributes for any of the scalar, aggregate, pointer, or allocatable classes on a \n per-region basis.Additionally it accepts the none parameter to support the requirement that all \n variables referenced in the construct must be explicitly mapped or privatized.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 The declare mapper directive was added to support mapping of data types with direct and \n indirect members (see Section 5.8.8).\n \u2022 Predefined memory spaces (see Section 6.1), predefined memory allocators and allocator traits \n (see Section 6.2) and directives, clauses and API routines (see Chapter 6 and Section 18.13) to \n use them were added to support different kinds of memories."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 Predefined memory spaces (see Section 6.1), predefined memory allocators and allocator traits \n (see Section 6.2) and directives, clauses and API routines (see Chapter 6 and Section 18.13) to \n use them were added to support different kinds of memories.\n \u2022 Metadirectives (see Section 7.4) and declare variant directives (see Section 7.5) were added to \n support selection of directive variants and declared function variants at a call site, respectively, \n based on compile-time traits of the enclosing context.\n \u2022 Support for nested declare target directives was added (see Section 7.8).\n \u2022 The requires directive (see Section 8.2) was added to support applications that require \n implementation-specific features.\n \u2022 The teams construct (see Section 10.2) was extended to support execution on the host device \n without an enclosing target construct (see Section 13.8)."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The teams construct (see Section 10.2) was extended to support execution on the host device \n without an enclosing target construct (see Section 13.8).\n \u2022 The loop construct and the order(concurrent) clause were added to support compiler \n optimization and parallelization of loops for which iterations may execute in any order, including \n concurrently (see Section 10.3 and Section 11.7).\n \u2022 The collapse of associated loops that are imperfectly nested loops was defined for the simd (see \n Section 10.4), worksharing-loop (see Section 11.5), distribute (see Section 11.6) and \n taskloop (see Section 12.6) constructs.\n \u2022 The simd construct (see Section 10.4) was extended to accept the if, nontemporal, and \n order(concurrent) clauses and to allow the use of atomic constructs within it.\n \u2022 The default loop schedule modifier for worksharing-loop constructs without the static \n schedule and the ordered clause was changed to nonmonotonic (see Section 11.5)."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The default loop schedule modifier for worksharing-loop constructs without the static \n schedule and the ordered clause was changed to nonmonotonic (see Section 11.5).\n \u2022 The affinity clause was added to the task construct (see Section 12.5) to support hints that \n indicate data affinity of explicit tasks.\n \u2022 The detach clause for the task construct (see Section 12.5) and the omp_fulfill_event \n runtime routine (see Section 18.11.1) were added to support execution of detachable tasks.\n \u2022 The taskloop construct (see Section 12.6) was added to the list of constructs that can be \n canceled by the cancel construct (see Section 16.1)).\n \u2022 To support mutually exclusive inout sets, a mutexinoutset dependence-type was added to \n the depend clause (see Section 12.9 and Section 15.9.5)."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 To support mutually exclusive inout sets, a mutexinoutset dependence-type was added to \n the depend clause (see Section 12.9 and Section 15.9.5).\n \u2022 The semantics of the use_device_ptr clause for pointer variables was clarified and the \n use_device_addr clause for using the device address of non-pointer variables inside the \n target data construct was added (see Section 13.5).\n \u2022 To support reverse offload, the ancestor modifier was added to the device clause for the \n target construct (see Section 13.8).\nAPPENDIX B.FEATURES HISTORY 633 \n \u2022 To reduce programmer effort, implicit declare target directives for some functions (C, C++, \n Fortran) and subroutines (Fortran) were added (see Section 13.8 and Section 7.8).\n \u2022 The target update construct (see Section 13.9) was modified to allow array sections that \n specify discontiguous storage."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The target update construct (see Section 13.9) was modified to allow array sections that \n specify discontiguous storage.\n \u2022 The to and from clauses on the target update construct (see Section 13.9), the depend \n clause on task generating constructs (see Section 15.9.5), and the map clause (see Section 5.8.3) \n were extended to allow any lvalue expression as a list item for C/C++.\n \u2022 Lock hints were renamed to synchronization hints, and the old names were deprecated (see \n Section 15.1).\n \u2022 The depend clause was added to the taskwait construct (see Section 15.5).\n \u2022 To support acquire and release semantics with weak memory ordering, the acq_rel, \n acquire, and release clauses were added to the atomic construct (see Section 15.8.4) and \n flush construct (see Section 15.8.5), and the memory ordering semantics of implicit flushes on \n various constructs and runtime routines were clarified (see Section 15.8.6)."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 To support acquire and release semantics with weak memory ordering, the acq_rel, \n acquire, and release clauses were added to the atomic construct (see Section 15.8.4) and \n flush construct (see Section 15.8.5), and the memory ordering semantics of implicit flushes on \n various constructs and runtime routines were clarified (see Section 15.8.6).\n \u2022 The atomic construct was extended with the hint clause (see Section 15.8.4).\n \u2022 The depend clause (see Section 15.9.5) was extended to support iterators and to support depend \n objects that can be created with the new depobj construct.\n \u2022 New combined constructs master taskloop, parallel master, \n parallel master taskloop, master taskloop simd \n parallel master taskloop simd (see Section 17.3) were added.\n \u2022 The omp_set_nested (see Section 18.2.9) and omp_get_nested (see Section 18.2.10) \n routines and the OMP_NESTED environment variable (see Section 21.1.5) were deprecated."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The omp_set_nested (see Section 18.2.9) and omp_get_nested (see Section 18.2.10) \n routines and the OMP_NESTED environment variable (see Section 21.1.5) were deprecated.\n \u2022 The omp_get_supported_active_levels routine was added to query the number of \n active levels of parallelism supported by the implementation (see Section 18.2.14).\n \u2022 Runtime routines omp_set_affinity_format (see Section 18.3.8), \n omp_get_affinity_format (see Section 18.3.9), omp_set_affinity (see \n Section 18.3.10), and omp_capture_affinity (see Section 18.3.11) and environment \n variables OMP_DISPLAY_AFFINITY (see Section 21.2.4) and OMP_AFFINITY_FORMAT \n (see Section 21.2.5) were added to provide OpenMP runtime thread affinity information.\n \u2022 The omp_pause_resource and omp_pause_resource_all runtime routines were \n added to allow the runtime to relinquish resources used by OpenMP (see Section 18.6.1 and \n Section 18.6.2)."}
{"section_title": "B.4 Version 4.5 to 5.0 Differences", "chunk": "\n \u2022 The omp_pause_resource and omp_pause_resource_all runtime routines were \n added to allow the runtime to relinquish resources used by OpenMP (see Section 18.6.1 and \n Section 18.6.2).\n \u2022 The omp_get_device_num runtime routine (see Section 18.7.5) was added to support \n determination of the device on which a thread is executing.\n \u2022 Support for a first-party tool interface (see Chapter 19) was added.\n \u2022 Support for a third-party tool interface (see Chapter 20) was added.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 Support for controlling offloading behavior with the OMP_TARGET_OFFLOAD environment \n variable was added (see Section 21.2.8).\n \u2022 Stubs for Runtime Library Routines (previously Appendix A) were moved to a separate \n document.\n \u2022 Interface Declarations (previously Appendix B) were moved to a separate document.\n"}
{"section_title": "B.5 Version 4.0 to 4.5 Differences", "chunk": "7 \u2022 Support for several features of Fortran 2003 was added (see Section 1.7).\n \u2022 The if clause was extended to take a directive-name-modifier that allows it to apply to combined \n constructs (see Section 3.4).\n \u2022 The implicit data-sharing attribute for scalar variables in target regions was changed to \n firstprivate (see Section 5.1.1).\n \u2022 Use of some C++ reference types was allowed in some data sharing attribute clauses (see \n Section 5.4).\n \u2022 The ref, val, and uval modifiers were added to the linear clause (see Section 5.4.6).\n \u2022 Semantics for reductions on C/C++ array sections were added and restrictions on the use of \n arrays and pointers in reductions were removed (see Section 5.5.8).\n \u2022 Support was added to the map clauses to handle structure elements (see Section 5.8.3)."}
{"section_title": "B.5 Version 4.0 to 4.5 Differences", "chunk": "\n \u2022 Support was added to the map clauses to handle structure elements (see Section 5.8.3).\n \u2022 To support unstructured data mapping for devices, the map clause (see Section 5.8.3) was \n updated and the target enter data (see Section 13.6) and target exit data (see \n Section 13.7) constructs were added.\n \u2022 The declare target directive was extended to allow mapping of global variables to be \n deferred to specific device executions and to allow an extended-list to be specified in C/C++ (see \n Section 7.8).\n \u2022 The simdlen clause was added to the simd construct (see Section 10.4) to support \n specification of the exact number of iterations desired per SIMD chunk.\n \u2022 A parameter was added to the ordered clause of the worksharing-loop construct (see \n Section 11.5) and clauses were added to the ordered construct (see Section 15.10) to support \n doacross loop nests and use of the simd construct on loops with loop-carried backward \n dependences."}
{"section_title": "B.5 Version 4.0 to 4.5 Differences", "chunk": "\n \u2022 A parameter was added to the ordered clause of the worksharing-loop construct (see \n Section 11.5) and clauses were added to the ordered construct (see Section 15.10) to support \n doacross loop nests and use of the simd construct on loops with loop-carried backward \n dependences.\n \u2022 The linear clause was added to the worksharing-loop construct (see Section 11.5).\n \u2022 The priority clause was added to the task construct (see Section 12.5) to support hints that \n specify the relative execution priority of explicit tasks.The \n omp_get_max_task_priority routine was added to return the maximum supported \nAPPENDIX B.FEATURES HISTORY 635 \n priority value (see Section 18.5.1) and the OMP_MAX_TASK_PRIORITY environment variable \n was added to control the maximum priority value allowed (see Section 21.2.9).\n \u2022 The taskloop construct (see Section 12.6) was added to support nestable parallel loops that \n create OpenMP tasks."}
{"section_title": "B.5 Version 4.0 to 4.5 Differences", "chunk": "\n \u2022 The taskloop construct (see Section 12.6) was added to support nestable parallel loops that \n create OpenMP tasks.\n \u2022 To support interaction with native device implementations, the use_device_ptr clause was \n added to the target data construct (see Section 13.5) and the is_device_ptr clause was \n added to the target construct (see Section 13.8).\n \u2022 The nowait and depend clauses were added to the target construct (see Section 13.8) to \n improve support for asynchronous execution of target regions.\n \u2022 The private, firstprivate and defaultmap clauses were added to the target \n construct (see Section 13.8).\n \u2022 The hint clause was added to the critical construct (see Section 15.2).\n \u2022 The source and sink dependence types were added to the depend clause (see \n Section 15.9.5) to support doacross loop nests."}
{"section_title": "B.5 Version 4.0 to 4.5 Differences", "chunk": "\n \u2022 The source and sink dependence types were added to the depend clause (see \n Section 15.9.5) to support doacross loop nests.\n \u2022 To support a more complete set of device construct shortcuts, the target parallel, target \n parallel worksharing-loop, target parallel worksharing-loop SIMD, and target simd (see \n Section 17.3) combined constructs were added.\n \u2022 Query functions for OpenMP thread affinity were added (see Section 18.3.2 to Section 18.3.7).\n \u2022 Device memory routines were added to allow explicit allocation, deallocation, memory transfers, \n and memory associations (see Section 18.8).\n \u2022 The lock API was extended with lock routines that support storing a hint with a lock to select a \n desired lock implementation for a lock\u2019s intended usage by the application code (see \n Section 18.9.2).\n \u2022 C/C++ Grammar (previously Appendix B) was moved to a separate document.\n"}
{"section_title": "B.6 Version 3.1 to 4.0 Differences", "chunk": "26 \u2022 Various changes throughout the specification were made to provide initial support of Fortran \n 2003 (see Section 1.7).\n \u2022 C/C++ array syntax was extended to support array sections (see Section 3.2.5).\n \u2022 The reduction clause (see Section 5.5.8) was extended and the declare reduction \n construct (see Section 5.5.11) was added to support user defined reductions.\n \u2022 The proc_bind clause (see Section 10.1.3), the OMP_PLACES environment variable (see \n Section 21.1.6), and the omp_get_proc_bind runtime routine (see Section 18.3.1) were \n added to support thread affinity policies.\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 SIMD directives were added to support SIMD parallelism (see Section 10.4).\n \u2022 Implementation defined task scheduling points for untied tasks were removed (see Section 12.9)."}
{"section_title": "B.6 Version 3.1 to 4.0 Differences", "chunk": "\n \u2022 Implementation defined task scheduling points for untied tasks were removed (see Section 12.9).\n \u2022 Device directives (see Chapter 13), the OMP_DEFAULT_DEVICE environment variable (see \n Section 21.2.7), and the omp_set_default_device, omp_get_default_device, \n omp_get_num_devices, omp_get_num_teams, omp_get_team_num, and \n omp_is_initial_device routines were added to support execution on devices.\n \u2022 The taskgroup construct (see Section 15.4) was added to support deep task synchronization.\n \u2022 The atomic construct (see Section 15.8.4) was extended to support atomic swap with the \n capture clause, to allow new atomic update and capture forms, and to support sequentially \n consistent atomic operations with a new seq_cst clause.\n \u2022 The depend clause (see Section 15.9.5) was added to support task dependences."}
{"section_title": "B.6 Version 3.1 to 4.0 Differences", "chunk": "\n \u2022 The depend clause (see Section 15.9.5) was added to support task dependences.\n \u2022 The cancel construct (see Section 16.1), the cancellation point construct (see \n Section 16.2), the omp_get_cancellation runtime routine (see Section 18.2.8), and the \n OMP_CANCELLATION environment variable (see Section 21.2.6) were added to support the \n concept of cancellation.\n \u2022 The OMP_DISPLAY_ENV environment variable (see Section 21.7) was added to display the \n value of ICVs associated with the OpenMP environment variables.\n \u2022 Examples (previously Appendix A) were moved to a separate document.\n"}
{"section_title": "B.7 Version 3.0 to 3.1 Differences", "chunk": "20 \u2022 The bind-var ICV (see Section 2.1) and the OMP_PROC_BIND environment variable (see \n Section 21.1.7) were added to support control of whether threads are bound to processors.\n \u2022 Data environment restrictions were changed to allow intent(in) and const-qualified types \n for the firstprivate clause (see Section 5.4.4).\n \u2022 Data environment restrictions were changed to allow Fortran pointers in firstprivate (see \n Section 5.4.4) and lastprivate (see Section 5.4.5) clauses.\n \u2022 New reduction operators min and max were added for C and C++ (see Section 5.5).\n \u2022 The nthreads-var ICV was modified to be a list of the number of threads to use at each nested \n parallel region level, and the algorithm for determining the number of threads used in a parallel \n region was modified to handle a list (see Section 10.1.1).\n \u2022 The final and mergeable clauses (see Section 12.5) were added to the task construct to \n support optimization of task data environments."}
{"section_title": "B.7 Version 3.0 to 3.1 Differences", "chunk": "\n \u2022 The final and mergeable clauses (see Section 12.5) were added to the task construct to \n support optimization of task data environments.\n \u2022 The taskyield construct (see Section 12.7) was added to allow user-defined task scheduling \n points.\nAPPENDIX B.FEATURES HISTORY 637 \n \u2022 The atomic construct (see Section 15.8.4) was extended to include read, write, and \n capture forms, and an update clause was added to apply the already existing form of the \n atomic construct.\n \u2022 The nesting restrictions in Section 17.1 were clarified to disallow closely-nested OpenMP \n regions within an atomic region so that an atomic region can be consistently defined with \n other OpenMP regions to include all code in the atomic construct.\n \u2022 The omp_in_final runtime library routine (see Section 18.5.3) was added to support \n specialization of final task regions.\n \u2022 Descriptions of examples (previously Appendix A) were expanded and clarified."}
{"section_title": "B.7 Version 3.0 to 3.1 Differences", "chunk": "\n \u2022 Descriptions of examples (previously Appendix A) were expanded and clarified.\n \u2022 Incorrect use of omp_integer_kind in Fortran interfaces was replaced with \n selected_int_kind(8).\n"}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "13 \u2022 The definition of active parallel region was changed so that a parallel region is active if \n it is executed by a team that consists of more than one thread (see Section 1.2.2).\n \u2022 The concept of tasks was added to the execution model (see Section 1.2.5 and Section 1.3).\n \u2022 The OpenMP memory model was extended to cover atomicity of memory accesses (see \n Section 1.4.1).The description of the behavior of volatile in terms of flush was removed.\n \u2022 The definition of the nest-var, dyn-var, nthreads-var and run-sched-var internal control variables \n (ICVs) were modified to provide one copy of these ICVs per task instead of one copy for the \n whole program (see Chapter 2).The omp_set_num_threads, omp_set_nested, and \n omp_set_dynamic runtime library routines were specified to support their use from inside a \n parallel region (see Section 18.2.1, Section 18.2.6 and Section 18.2.9)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "The omp_set_num_threads, omp_set_nested, and \n omp_set_dynamic runtime library routines were specified to support their use from inside a \n parallel region (see Section 18.2.1, Section 18.2.6 and Section 18.2.9).\n \u2022 The thread-limit-var ICV, the omp_get_thread_limit runtime library routine and the \n OMP_THREAD_LIMIT environment variable were added to support control of the maximum \n number of threads (see Section 2.1, Section 18.2.13 and Section 21.1.3).\n \u2022 The max-active-levels-var ICV, omp_set_max_active_levels and \n omp_get_max_active_levels runtime library routines, and \n OMP_MAX_ACTIVE_LEVELS environment variable were added to support control of the \n number of nested active parallel regions (see Section 2.1, Section 18.2.15, Section 18.2.16 \n and Section 21.1.4).\n \u2022 The stacksize-var ICV and the OMP_STACKSIZE environment variable were added to support \n control of thread stack sizes (see Section 2.1 and Section 21.2.2)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 The stacksize-var ICV and the OMP_STACKSIZE environment variable were added to support \n control of thread stack sizes (see Section 2.1 and Section 21.2.2).\n \u2022 The wait-policy-var ICV and the OMP_WAIT_POLICY environment variable were added to \n control the desired behavior of waiting threads (see Section 2.1 and Section 21.2.3).\n OpenMP API \u2013 Version 5.2 November 2021 \n \u2022 Predetermined data-sharing attributes were defined for Fortran assumed-size arrays (see \n Section 5.1.1).\n \u2022 Static class members variables were allowed in threadprivate directives (see Section 5.2).\n \u2022 Invocations of constructors and destructors for private and threadprivate class type variables was \n clarified (see Section 5.2, Section 5.4.3, Section 5.4.4, Section 5.7.1 and Section 5.7.2)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 Invocations of constructors and destructors for private and threadprivate class type variables was \n clarified (see Section 5.2, Section 5.4.3, Section 5.4.4, Section 5.7.1 and Section 5.7.2).\n \u2022 The use of Fortran allocatable arrays was allowed in private, firstprivate, \n lastprivate, reduction, copyin and copyprivate clauses (see Section 5.2, \n Section 5.4.3, Section 5.4.4, Section 5.4.5, Section 5.5.8, Section 5.7.1 and Section 5.7.2).\n \u2022 Support for firstprivate was added to the default clause in Fortran (see Section 5.4.1).\n \u2022 Implementations were precluded from using the storage of the original list item to hold the new \n list item on the primary thread for list items in the private clause, and the value was made \n well defined on exit from the parallel region if no attempt is made to reference the original \n list item inside the parallel region (see Section 5.4.3)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 Implementations were precluded from using the storage of the original list item to hold the new \n list item on the primary thread for list items in the private clause, and the value was made \n well defined on exit from the parallel region if no attempt is made to reference the original \n list item inside the parallel region (see Section 5.4.3).\n \u2022 Data environment restrictions were changed to allow intent(in) and const-qualified types \n for the firstprivate clause (see Section 5.4.4).\n \u2022 Data environment restrictions were changed to allow Fortran pointers in firstprivate (see \n Section 5.4.4) and lastprivate (see Section 5.4.5).\n \u2022 New reduction operators min and max were added for C and C++ (see Section 5.5).\n \u2022 Determination of the number of threads in parallel regions was updated (see Section 10.1.1).\n \u2022 The assignment of iterations to threads in a loop construct with a static schedule kind was \n made deterministic (see Section 11.5)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 The assignment of iterations to threads in a loop construct with a static schedule kind was \n made deterministic (see Section 11.5).\n \u2022 The worksharing-loop construct was extended to support association with more than one \n perfectly nested loop through the collapse clause (see Section 11.5).\n \u2022 Iteration variables for worksharing-loops were allowed to be random access iterators or of \n unsigned integer type (see Section 11.5).\n \u2022 The schedule kind auto was added to allow the implementation to choose any possible mapping \n of iterations in a loop construct to threads in the team (see Section 11.5).\n \u2022 The task construct (see Chapter 12) was added to support explicit tasks.\n \u2022 The taskwait construct (see Section 15.5) was added to support task synchronization.\n \u2022 The runtime library routines omp_set_schedule and omp_get_schedule were added to \n set and to retrieve the value of the run-sched-var ICV (see Section 18.2.11 and Section 18.2.12)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 The runtime library routines omp_set_schedule and omp_get_schedule were added to \n set and to retrieve the value of the run-sched-var ICV (see Section 18.2.11 and Section 18.2.12).\n \u2022 The omp_get_level runtime library routine was added to return the number of nested \n parallel regions that enclose the task that contains the call (see Section 18.2.17).\nAPPENDIX B.FEATURES HISTORY 639 \n \u2022 The omp_get_ancestor_thread_num runtime library routine was added to return the \n thread number of the ancestor of the current thread (see Section 18.2.18).\n \u2022 The omp_get_team_size runtime library routine was added to return the size of the thread \n team to which the ancestor of the current thread belongs (see Section 18.2.19).\n \u2022 The omp_get_active_level runtime library routine was added to return the number of \n active parallel regions that enclose the task that contains the call (see Section 18.2.20)."}
{"section_title": "B.8 Version 2.5 to 3.0 Differences", "chunk": "\n \u2022 The omp_get_active_level runtime library routine was added to return the number of \n active parallel regions that enclose the task that contains the call (see Section 18.2.20).\n \u2022 Lock ownership was defined in terms of tasks instead of threads (see Section 18.9).\n OpenMP API \u2013 Version 5.2 November 2021 \n"}
